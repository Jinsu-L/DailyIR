[
    {
        "title": "Sift or Get Off the PoC: Applying Information Retrieval to Vulnerability Research with SiftRank",
        "abstract": "Security research is fundamentally a problem of resource constraint and consequent prioritization. There is simply too much attack surface and too little time and energy to spend analyzing it all. The most effective security researchers are often those who are most skilled at intuitively deciding which part of an expansive attack surface to investigate. We demonstrate that this problem of selecting the most promising option from among many possibilities can be reframed as an information retrieval problem, and solved using document ranking techniques with LLMs performing the heavy lifting as general-purpose rankers. We present SiftRank, a ranking algorithm achieving O(n) complexity through three key mechanisms: listwise ranking using an LLM to order documents in small batches of approximately 10 items at a time; inflection-based convergence detection that adaptively terminates ranking when score distributions have stabilized; and iterative refinement that progressively focuses ranking effort on the most relevant documents. Unlike existing reranking approaches that require a separate first-stage retrieval step to narrow datasets to approximately 100 candidates, SiftRank operates directly on thousands of items, with each document evaluated across multiple randomized batches to mitigate inconsistent judgments by an LLM. We demonstrate practical effectiveness on N-day vulnerability analysis, successfully identifying a vulnerability-fixing function among 2,197 changed functions in a stripped binary firmware patch within 99 seconds at an inference cost of $0.82. Our approach enables scalable security prioritization for problems that are generally constrained by manual analysis, requiring only standard LLM API access without specialized infrastructure, embedding, or domain-specific fine-tuning. An open-source implementation of SiftRank may be found at https://github.com/noperator/siftrank.",
        "url": "http://arxiv.org/abs/2512.06155v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06155v1",
        "arxiv_id": "2512.06155v1",
        "authors": [
            "Caleb Gross"
        ],
        "submitted": "2025-12-05 21:09:32",
        "source": "arxiv",
        "comment": null,
        "score": 16,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'listwise' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to Information Retrieval, particularly in the application of ranking models and query understanding. The use of Learning to Rank (L2R) techniques and Large Language Models (LLMs) aligns with your research interests. However, the specific domain of vulnerability research and security prioritization is somewhat outside your primary focus on e-commerce and general IR applications."
    },
    {
        "title": "Modeling Contextual Passage Utility for Multihop Question Answering",
        "abstract": "Multihop Question Answering (QA) requires systems to identify and synthesize information from multiple text passages. While most prior retrieval methods assist in identifying relevant passages for QA, further assessing the utility of the passages can help in removing redundant ones, which may otherwise add to noise and inaccuracies in the generated answers. Existing utility prediction approaches model passage utility independently, overlooking a critical aspect of multihop reasoning: the utility of a passage can be context-dependent, influenced by its relation to other passages - whether it provides complementary information or forms a crucial link in conjunction with others. In this paper, we propose a lightweight approach to model contextual passage utility, accounting for inter-passage dependencies. We fine-tune a small transformer-based model to predict passage utility scores for multihop QA. We leverage the reasoning traces from an advanced reasoning model to capture the order in which passages are used to answer a question and obtain synthetic training data. Through comprehensive experiments, we demonstrate that our utility-based scoring of retrieved passages leads to improved reranking and downstream QA performance compared to relevance-based reranking methods.",
        "url": "http://arxiv.org/abs/2512.06464v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06464v1",
        "arxiv_id": "2512.06464v1",
        "authors": [
            "Akriti Jain",
            "Aparna Garimella"
        ],
        "submitted": "2025-12-06 14:54:47",
        "source": "arxiv",
        "comment": "Accepted at IJCNLP-AACL 2025",
        "score": 14,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to Information Retrieval, particularly in the context of Question Answering and passage utility modeling. The focus on contextual passage utility and inter-passage dependencies aligns with the user's interest in query understanding and ranking models. However, the specific application to multihop QA is somewhat outside the user's primary focus on e-commerce and real-time relevance optimization."
    },
    {
        "title": "An Index-based Approach for Efficient and Effective Web Content Extraction",
        "abstract": "As web agents (e.g., Deep Research) routinely consume massive volumes of web pages to gather and analyze information, LLM context management -- under large token budgets and low signal density -- emerges as a foundational, high-importance, and technically challenging problem for agentic and RAG pipelines. Existing solutions for extracting relevant content are inadequate: generative extraction models suffer from high latency, rule-based heuristics lack adaptability, and chunk-and-rerank methods are blind to webpage structure. To overcome these issues, we introduce Index-based Web Content Extraction to reframe the extraction process from slow, token-by-token generation into a highly efficient, discriminative task of index prediction, achieving both effectiveness and efficiency. We partition HTML into structure-aware, addressable segments, and extract only the positional indices of content relevant to a given query. This method decouples extraction latency from content length, enabling rapid, query-relevant extraction. We first evaluate our method as a post-retrieval processing component within an RAG QA system and find that it improves QA accuracy. Then we directly measure its match rate with the target content in two scenarios: main content extraction (ME) and query-relevant extraction (QE). Experimental results show that our method outperforms existing works in both accuracy and speed, effectively bridging the gap between LLMs and the vast webpages.",
        "url": "http://arxiv.org/abs/2512.06641v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06641v1",
        "arxiv_id": "2512.06641v1",
        "authors": [
            "Yihan Chen",
            "Benfeng Xu",
            "Xiaorui Wang",
            "Zhendong Mao"
        ],
        "submitted": "2025-12-07 03:18:19",
        "source": "arxiv",
        "comment": null,
        "score": 12,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses web content extraction, which is somewhat related to information retrieval and search technologies. However, the focus is on efficient extraction methods rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's relevance is also limited by its specific application to large language models and web agents, rather than a broader e-commerce or general IR context."
    },
    {
        "title": "Enhanced Multimodal Video Retrieval System: Integrating Query Expansion and Cross-modal Temporal Event Retrieval",
        "abstract": "Multimedia information retrieval from videos remains a challenging problem. While recent systems have advanced multimodal search through semantic, object, and OCR queries - and can retrieve temporally consecutive scenes - they often rely on a single query modality for an entire sequence, limiting robustness in complex temporal contexts. To overcome this, we propose a cross-modal temporal event retrieval framework that enables different query modalities to describe distinct scenes within a sequence. To determine decision thresholds for scene transition and slide change adaptively, we build Kernel Density Gaussian Mixture Thresholding (KDE-GMM) algorithm, ensuring optimal keyframe selection. These extracted keyframes act as compact, high-quality visual exemplars that retain each segment's semantic essence, improving retrieval precision and efficiency. Additionally, the system incorporates a large language model (LLM) to refine and expand user queries, enhancing overall retrieval performance. The proposed system's effectiveness and robustness were demonstrated through its strong results in the Ho Chi Minh AI Challenge 2025.",
        "url": "http://arxiv.org/abs/2512.06334v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06334v1",
        "arxiv_id": "2512.06334v1",
        "authors": [
            "Van-Thinh Vo",
            "Minh-Khoi Nguyen",
            "Minh-Huy Tran",
            "Anh-Quan Nguyen-Tran",
            "Duy-Tan Nguyen",
            "Khanh-Loi Nguyen",
            "Anh-Minh Phan"
        ],
        "submitted": "2025-12-06 07:46:51",
        "source": "arxiv",
        "comment": "11 pages, 6 figures, SOICT 2025",
        "score": 12,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to Information Retrieval, specifically in the context of multimodal video retrieval. However, it focuses on a specific application and does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The use of a large language model for query refinement is a tangential connection to NLP."
    },
    {
        "title": "Enhancing Information Retrieval in Digital Libraries through Unit Harmonisation in Scholarly Knowledge Graphs",
        "abstract": "Scientists have always used the studies and research of other researchers to achieve new objectives and perspectives. In particular, employing and operating the measured data in previous studies is so practical. Searching the content of other scientists' articles is a challenge that researchers have always struggled with. Nowadays, the use of knowledge graphs as a semantic database has helped a lot in saving and retrieving scholarly knowledge. Such technologies are crucial to upgrading traditional search systems to smart knowledge retrieval, which is crucial to getting the most relevant answers for a user query, especially in information and knowledge management. However, in most cases, only the metadata of a paper is searchable, and it is still cumbersome for scientists to have access to the content of the papers. In this paper, we present a novel method of faceted search \\emph{structured content} for comparing and filtering measured data in scholarly knowledge graphs while different units of measurement are used in different studies. This search system proposes applicable units as facets to the user and would dynamically integrate content from further remote knowledge graphs to materialize the scholarly knowledge graph and achieve a higher order of exploration usability on scholarly content, which can be filtered to better satisfy the user's information needs. The state of the art is that, by using our faceted search system, users can not only search the contents of scientific articles, but also compare and filter heterogeneous data.",
        "url": "http://arxiv.org/abs/2512.06395v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06395v1",
        "arxiv_id": "2512.06395v1",
        "authors": [
            "Golsa Heidari",
            "Markus Stocker",
            "SÃ¶ren Auer"
        ],
        "submitted": "2025-12-06 10:58:17",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of digital libraries and scholarly knowledge graphs. The focus on faceted search and unit harmonisation aligns with your interests in query understanding and ranking models. However, the paper's emphasis on knowledge graphs and semantic databases is not a central match with your primary focus on real-time relevance optimization."
    },
    {
        "title": "Automated PRO-CTCAE Symptom Selection based on Prior Adverse Event Profiles",
        "abstract": "The PRO-CTCAE is an NCI-developed patient-reported outcome system for capturing symptomatic adverse events in oncology trials. It comprises a large library drawn from the CTCAE vocabulary, and item selection for a given trial is typically guided by expected toxicity profiles from prior data. Selecting too many PRO-CTCAE items can burden patients and reduce compliance, while too few may miss important safety signals. We present an automated method to select a minimal yet comprehensive PRO-CTCAE subset based on historical safety data. Each candidate PRO-CTCAE symptom term is first mapped to its corresponding MedDRA Preferred Terms (PTs), which are then encoded into Safeterm, a high-dimensional semantic space capturing clinical and contextual diversity in MedDRA terminology. We score each candidate PRO item for relevance to the historical list of adverse event PTs and combine relevance and incidence into a utility function. Spectral analysis is then applied to the combined utility and diversity matrix to identify an orthogonal set of medical concepts that balances relevance and diversity. Symptoms are rank-ordered by importance, and a cut-off is suggested based on the explained information. The tool is implemented as part of the Safeterm trial-safety app. We evaluate its performance using simulations and oncology case studies in which PRO-CTCAE was employed. This automated approach can streamline PRO-CTCAE design by leveraging MedDRA semantics and historical data, providing an objective and reproducible method to balance signal coverage against patient burden.",
        "url": "http://arxiv.org/abs/2512.06919v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06919v1",
        "arxiv_id": "2512.06919v1",
        "authors": [
            "Francois Vandenhende",
            "Anna Georgiou",
            "Michalis Georgiou",
            "Theodoros Psaras",
            "Ellie Karekla"
        ],
        "submitted": "2025-12-07 16:56:27",
        "source": "arxiv",
        "comment": "13 pages, 2 figures",
        "score": 8,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on automated symptom selection for patient-reported outcomes in oncology trials, which is outside the scope of information retrieval, search technologies, and natural language processing. Although it mentions ranking and semantic understanding, the context is specific to medical terminology and does not align with your core research themes."
    },
    {
        "title": "Foresight Prediction Enhanced Live-Streaming Recommendation",
        "abstract": "Live-streaming, as an emerging media enabling real-time interaction between authors and users, has attracted significant attention. Unlike the stable playback time of traditional TV live or the fixed content of short video, live-streaming, due to the dynamics of content and time, poses higher requirements for the recommendation algorithm of the platform - understanding the ever-changing content in real time and push it to users at the appropriate moment. Through analysis, we find that users have a better experience and express more positive behaviors during highlight moments of the live-streaming. Furthermore, since the model lacks access to future content during recommendation, yet user engagement depends on how well subsequent content aligns with their interests, an intuitive solution is to predict future live-streaming content. Therefore, we perform semantic quantization on live-streaming segments to obtain Semantic ids (Sid), encode the historical Sid sequence to capture the author's characteristics, and model Sid evolution trend to enable foresight prediction of future content. This foresight enhances the ranking model through refined features. Extensive offline and online experiments demonstrate the effectiveness of our method.",
        "url": "http://arxiv.org/abs/2512.06700v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06700v1",
        "arxiv_id": "2512.06700v1",
        "authors": [
            "Jiangxia Cao",
            "Ruochen Yang",
            "Xiang Chen",
            "Changxin Lao",
            "Yueyang Liu",
            "Yusheng Huang",
            "Yuanhao Tian",
            "Xiangyu Wu",
            "Shuang Yang",
            "Zhaojie Liu",
            "Guorui Zhou"
        ],
        "submitted": "2025-12-07 07:25:38",
        "source": "arxiv",
        "comment": "Accepted by WSDM 2026",
        "score": 5,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Search technologies, particularly in the context of live-streaming recommendation. However, the focus on live-streaming and recommendation systems, while tangentially related to your work in e-commerce and user behavior modeling, is not a central match for your primary research themes in query understanding, ranking models, and deep semantic understanding."
    },
    {
        "title": "Towards Efficient Hypergraph and Multi-LLM Agent Recommender Systems",
        "abstract": "Recommender Systems (RSs) have become the cornerstone of various applications such as e-commerce and social media platforms. The evolution of RSs is paramount in the digital era, in which personalised user experience is tailored to the user's preferences. Large Language Models (LLMs) have sparked a new paradigm - generative retrieval and recommendation. Despite their potential, generative RS methods face issues such as hallucination, which degrades the recommendation performance, and high computational cost in practical scenarios. To address these issues, we introduce HGLMRec, a novel Multi-LLM agent-based RS that incorporates a hypergraph encoder designed to capture complex, multi-behaviour relationships between users and items. The HGLMRec model retrieves only the relevant tokens during inference, reducing computational overhead while enriching the retrieval context. Experimental results show performance improvement by HGLMRec against state-of-the-art baselines at lower computational cost.",
        "url": "http://arxiv.org/abs/2512.06590v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06590v1",
        "arxiv_id": "2512.06590v1",
        "authors": [
            "Tendai Mukande",
            "Esraa Ali",
            "Annalina Caputo",
            "Ruihai Dong",
            "Noel OConnor"
        ],
        "submitted": "2025-12-06 23:04:49",
        "source": "arxiv",
        "comment": "8 Pages",
        "score": 5,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses recommender systems, which is related to the user's interests in Information Retrieval and Search technologies. However, the focus on Large Language Models and hypergraph encoders is not a central match for the user's primary research themes, which include query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Beyond Existing Retrievals: Cross-Scenario Incremental Sample Learning Framework",
        "abstract": "The parallelized multi-retrieval architecture has been widely adopted in large-scale recommender systems for its computational efficiency and comprehensive coverage of user interests. Many retrieval methods typically integrate additional cross-scenario samples to enhance the overall performance ceiling. However, those model designs neglect the fact that a part of the cross-scenario samples have already been retrieved by existing models within a system, leading to diminishing marginal utility in delivering incremental performance gains. In this paper, we propose a novel retrieval framework IncRec, specifically for cross-scenario incremental sample learning. The innovations of IncRec can be highlighted as two aspects. Firstly, we construct extreme cross-scenario incremental samples that are not retrieved by any existing model. And we design an incremental sample learning framework which focuses on capturing incremental representation to improve the overall retrieval performance. Secondly, we introduce a consistency-aware alignment module to further make the model prefer incremental samples with high exposure probability. Extensive offline and online A/B tests validate the superiority of our framework over state-of-the-art retrieval methods. In particular, we deploy IncRec in the Taobao homepage recommendation, achieving a 1% increase in online transaction count, demonstrating its practical applicability.",
        "url": "http://arxiv.org/abs/2512.06381v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06381v1",
        "arxiv_id": "2512.06381v1",
        "authors": [
            "Tao Wang",
            "Xun Luo",
            "Jinlong Guo",
            "Yuliang Yan",
            "Jian Wu",
            "Yuning Jiang",
            "Bo Zheng"
        ],
        "submitted": "2025-12-06 10:26:18",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper proposes a novel retrieval framework for cross-scenario incremental sample learning, which is somewhat related to the user's interests in Information Retrieval and Search technologies. However, the focus on recommender systems and the lack of emphasis on deep semantic understanding and real-time relevance optimization limit its relevance to the user's core research themes."
    },
    {
        "title": "Structural and Disentangled Adaptation of Large Vision Language Models for Multimodal Recommendation",
        "abstract": "Multimodal recommendation enhances accuracy by leveraging visual and textual signals, and its success largely depends on learning high-quality cross-modal representations. Recent advances in Large Vision-Language Models (LVLMs) offer unified multimodal representation learning, making them a promising backbone. However, applying LVLMs to recommendation remains challenging due to (i) representation misalignment, where domain gaps between item data and general pre-training lead to unaligned embedding spaces, and (ii) gradient conflicts during fine-tuning, where shared adapters cause interference and a lack of discriminative power. To address this, we propose SDA, a lightweight framework for Structural and Disentangled Adaptation, which integrates two components: Cross-Modal Structural Alignment (CMSA) and Modality-Disentangled Adaptation. CMSA aligns embeddings using intra-modal structures as a soft teacher, while MoDA mitigates gradient conflicts via expertized, gated low-rank paths to disentangle gradient flows. Experiments on three public Amazon datasets show SDA integrates seamlessly with existing multimodal and sequential recommenders, yielding average gains of 6.15% in Hit@10 and 8.64% in NDCG@10. It also achieves up to 12.83% and 18.70% gains on long-tail items with minimal inference overhead. Our code and full experimental results are available at https://github.com/RaoZhongtao/SDA.",
        "url": "http://arxiv.org/abs/2512.06883v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06883v1",
        "arxiv_id": "2512.06883v1",
        "authors": [
            "Zhongtao Rao",
            "Peilin Zhou",
            "Dading Chong",
            "Zhiwei Chen",
            "Shoujin Wang",
            "Nan Tang"
        ],
        "submitted": "2025-12-07 15:18:04",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multimodal recommendation using Large Vision-Language Models, which is not directly related to the user's core research themes in Information Retrieval, query understanding, ranking models, and user behavior modeling. While it involves some aspects of NLP and data mining, the primary focus on recommender systems and visual-textual signals does not align with the user's interests in deep semantic understanding and real-time relevance optimization in the e-commerce domain."
    },
    {
        "title": "WisPaper: Your AI Scholar Search Engine",
        "abstract": "Researchers struggle to efficiently locate and manage relevant literature within the exponentially growing body of scientific publications. We present \\textsc{WisPaper}, an intelligent academic retrieval and literature management platform that addresses this challenge through three integrated capabilities: (1) \\textit{Scholar Search}, featuring both quick keyword-based and deep agentic search modes for efficient paper discovery; (2) \\textit{Library}, a customizable knowledge base for systematic literature organization; and (3) \\textit{AI Feeds}, an intelligent recommendation system that automatically delivers relevant new publications based on user interests. Unlike existing academic tools, \\textsc{WisPaper} provides a closed-loop workflow that seamlessly connects literature discovery, management, and continuous tracking of research frontiers. Our multilingual and multidisciplinary system significantly reduces the time researchers from diverse backgrounds spend on paper screening and management, enabling them to focus on their core research activities. The platform is publicly accessible and serves researchers across academia and industry.",
        "url": "http://arxiv.org/abs/2512.06879v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06879v1",
        "arxiv_id": "2512.06879v1",
        "authors": [
            "Li Ju",
            "Jun Zhao",
            "Mingxu Chai",
            "Ziyu Shen",
            "Xiangyang Wang",
            "Yage Geng",
            "Chunchun Ma",
            "Hao Peng",
            "Guangbin Li",
            "Tao Li",
            "Chengyong Liao",
            "Fu Wang",
            "Xiaolong Wang",
            "Junshen Chen",
            "Rui Gong",
            "Shijia Liang",
            "Feiyan Li",
            "Ming Zhang",
            "Kexin Tan",
            "Jujie Ye",
            "Zhiheng Xi",
            "Shihan Dou",
            "Tao Gui",
            "Yuankai Ying",
            "Yang Shi",
            "Yue Zhang",
            "Qi Zhang"
        ],
        "submitted": "2025-12-07 15:10:20",
        "source": "arxiv",
        "comment": "17 pages, 2 figures",
        "score": 4,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper presents a search engine for academic literature, which is related to Information Retrieval and Search technologies. However, the focus is more on literature management and recommendation systems rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest."
    },
    {
        "title": "LLM4SFC: Sequential Function Chart Generation via Large Language Models",
        "abstract": "While Large Language Models (LLMs) are increasingly used for synthesizing textual PLC programming languages like Structured Text (ST) code, other IEC 61131-3 standard graphical languages like Sequential Function Charts (SFCs) remain underexplored. Generating SFCs is challenging due to graphical nature and ST actions embedded within, which are not directly compatible with standard generation techniques, often leading to non-executable code that is incompatible with industrial tool-chains In this work, we introduce LLM4SFC, the first framework to receive natural-language descriptions of industrial workflows and provide executable SFCs. LLM4SFC is based on three components: (i) A reduced structured representation that captures essential topology and in-line ST and reduced textual verbosity; (ii) Fine-tuning and few-shot retrieval-augmented generation (RAG) for alignment with SFC programming conventions; and (iii) A structured generation approach that prunes illegal tokens in real-time to ensure compliance with the textual format of SFCs. We evaluate LLM4SFC on a dataset of real-world SFCs from automated manufacturing projects, using both open-source and proprietary LLMs. The results show that LLM4SFC reliably generates syntactically valid SFC programs effectively bridging graphical and textual PLC languages, achieving a generation generation success of 75% - 94%, paving the way for automated industrial programming.",
        "url": "http://arxiv.org/abs/2512.06787v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06787v1",
        "arxiv_id": "2512.06787v1",
        "authors": [
            "Ofek Glick",
            "Vladimir Tchuiev",
            "Marah Ghoummaid",
            "Michal Moshkovitz",
            "Dotan Di-Castro"
        ],
        "submitted": "2025-12-07 11:02:45",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval or Search technologies, but rather focuses on Large Language Models and their application in generating graphical languages for industrial programming. While it involves natural language processing, the context is quite different from the user's core research themes."
    },
    {
        "title": "When Distance Distracts: Representation Distance Bias in BT-Loss for Reward Models",
        "abstract": "Reward models are central to Large Language Model (LLM) alignment within the framework of RLHF. The standard objective used in reward modeling is the Bradley-Terry (BT) loss, which learns from pairwise data consisting of a pair of chosen and rejected responses. In this work, we analyze the per-sample gradient of BT-loss and show that its norm scales with two distinct components: (1) the difference in predicted rewards between chosen and rejected responses, which reflects the prediction error, and critically, (2) representation distance between the pair measured in the output space of the final layer. While the first term captures the intended training signal, we show that the second term can significantly impact the update magnitude and misalign learning. Specifically, pairs with small representation distance often receive vanishingly weak updates, even when misranked, while pairs with large distance receive disproportionately strong updates. This leads to gradients from large-distance pairs to overshadow those from small-distance pairs, where fine-grained distinctions are especially important. To overcome this limitation, we propose NormBT, an adaptive pair-wise normalization scheme that balances representation-driven effects and focuses learning signals on prediction error. NormBT is a lightweight, drop-in integration to BT loss with negligible overhead. Across various LLM backbones and datasets, NormBT improves reward model performance consistently, with notable gains of over 5% on the Reasoning category of RewardBench, which contains numerous small-distance pairs. This work reveals a key limitation in the widely used BT objective and provides a simple, effective correction.",
        "url": "http://arxiv.org/abs/2512.06343v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06343v1",
        "arxiv_id": "2512.06343v1",
        "authors": [
            "Tong Xie",
            "Andrew Bai",
            "Yuanhao Ban",
            "Yunqi Hong",
            "Haoyu Li",
            "Cho-jui Hsieh"
        ],
        "submitted": "2025-12-06 08:15:37",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or query understanding. While it touches on ranking models, the context is within the framework of Large Language Model alignment, which is not a primary focus of your research. The paper's relevance to your interests is limited."
    },
    {
        "title": "NeuroABench: A Multimodal Evaluation Benchmark for Neurosurgical Anatomy Identification",
        "abstract": "Multimodal Large Language Models (MLLMs) have shown significant potential in surgical video understanding. With improved zero-shot performance and more effective human-machine interaction, they provide a strong foundation for advancing surgical education and assistance. However, existing research and datasets primarily focus on understanding surgical procedures and workflows, while paying limited attention to the critical role of anatomical comprehension. In clinical practice, surgeons rely heavily on precise anatomical understanding to interpret, review, and learn from surgical videos. To fill this gap, we introduce the Neurosurgical Anatomy Benchmark (NeuroABench), the first multimodal benchmark explicitly created to evaluate anatomical understanding in the neurosurgical domain. NeuroABench consists of 9 hours of annotated neurosurgical videos covering 89 distinct procedures and is developed using a novel multimodal annotation pipeline with multiple review cycles. The benchmark evaluates the identification of 68 clinical anatomical structures, providing a rigorous and standardized framework for assessing model performance. Experiments on over 10 state-of-the-art MLLMs reveal significant limitations, with the best-performing model achieving only 40.87% accuracy in anatomical identification tasks. To further evaluate the benchmark, we extract a subset of the dataset and conduct an informative test with four neurosurgical trainees. The results show that the best-performing student achieves 56% accuracy, with the lowest scores of 28% and an average score of 46.5%. While the best MLLM performs comparably to the lowest-scoring student, it still lags significantly behind the group's average performance. This comparison underscores both the progress of MLLMs in anatomical understanding and the substantial gap that remains in achieving human-level performance.",
        "url": "http://arxiv.org/abs/2512.06921v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06921v1",
        "arxiv_id": "2512.06921v1",
        "authors": [
            "Ziyang Song",
            "Zelin Zang",
            "Xiaofan Ye",
            "Boqiang Xu",
            "Long Bai",
            "Jinlin Wu",
            "Hongliang Ren",
            "Hongbin Liu",
            "Jiebo Luo",
            "Zhen Lei"
        ],
        "submitted": "2025-12-07 17:00:25",
        "source": "arxiv",
        "comment": "Accepted by IEEE ICIA 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The focus on neurosurgical anatomy identification and multimodal evaluation benchmark for surgical video understanding does not align with your core research themes."
    },
    {
        "title": "Less Is More, but Where? Dynamic Token Compression via LLM-Guided Keyframe Prior",
        "abstract": "Recent advances in Video Large Language Models (VLLMs) have achieved remarkable video understanding capabilities, yet face critical efficiency bottlenecks due to quadratic computational growth with lengthy visual token sequences of long videos. While existing keyframe sampling methods can improve temporal modeling efficiency, additional computational cost is introduced before feature encoding, and the binary frame selection paradigm is found suboptimal. Therefore, in this work, we propose Dynamic Token compression via LLM-guided Keyframe prior (DyToK), a training-free paradigm that enables dynamic token compression by harnessing VLLMs' inherent attention mechanisms. Our analysis reveals that VLLM attention layers naturally encoding query-conditioned keyframe priors, by which DyToK dynamically adjusts per-frame token retention ratios, prioritizing semantically rich frames while suppressing redundancies. Extensive experiments demonstrate that DyToK achieves state-of-the-art efficiency-accuracy tradeoffs. DyToK shows plug-and-play compatibility with existing compression methods, such as VisionZip and FastV, attaining 4.3x faster inference while preserving accuracy across multiple VLLMs, such as LLaVA-OneVision and Qwen2.5-VL. Code is available at https://github.com/yu-lin-li/DyToK .",
        "url": "http://arxiv.org/abs/2512.06866v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06866v1",
        "arxiv_id": "2512.06866v1",
        "authors": [
            "Yulin Li",
            "Haokun Gui",
            "Ziyang Fan",
            "Junjie Wang",
            "Bin Kang",
            "Bin Chen",
            "Zhuotao Tian"
        ],
        "submitted": "2025-12-07 14:42:10",
        "source": "arxiv",
        "comment": "Accepted by NeurIPS 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. It focuses on video understanding and compression techniques using Large Language Models, which is outside your primary areas of interest."
    },
    {
        "title": "Becoming Experienced Judges: Selective Test-Time Learning for Evaluators",
        "abstract": "Automatic evaluation with large language models, commonly known as LLM-as-a-judge, is now standard across reasoning and alignment tasks. Despite evaluating many samples in deployment, these evaluators typically (i) treat each case independently, missing the opportunity to accumulate experience, and (ii) rely on a single fixed prompt for all cases, neglecting the need for sample-specific evaluation criteria. We introduce Learning While Evaluating (LWE), a framework that allows evaluators to improve sequentially at inference time without requiring training or validation sets. LWE maintains an evolving meta-prompt that (i) produces sample-specific evaluation instructions and (ii) refines itself through self-generated feedback. Furthermore, we propose Selective LWE, which updates the meta-prompt only on self-inconsistent cases, focusing computation where it matters most. This selective approach retains the benefits of sequential learning while being far more cost-effective. Across two pairwise comparison benchmarks, Selective LWE outperforms strong baselines, empirically demonstrating that evaluators can improve during sequential testing with a simple selective update, learning most from the cases they struggle with.",
        "url": "http://arxiv.org/abs/2512.06751v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06751v1",
        "arxiv_id": "2512.06751v1",
        "authors": [
            "Seungyeon Jwa",
            "Daechul Ahn",
            "Reokyoung Kim",
            "Dongyeop Kang",
            "Jonghyun Choi"
        ],
        "submitted": "2025-12-07 09:28:39",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper introduces a framework for improving the performance of large language models as evaluators through selective test-time learning. While it touches on aspects of query understanding and ranking models, its primary focus is on improving the evaluation process rather than information retrieval or search technologies. The paper's relevance to the user's interests is somewhat limited, but it may still be of interest due to its connection to NLP and deep semantic understanding."
    },
    {
        "title": "Enhancing Medical Cross-Modal Hashing Retrieval using Dropout-Voting Mixture-of-Experts Fusion",
        "abstract": "In recent years, cross-modal retrieval using images and text has become an active area of research, especially in the medical domain. The abundance of data in various modalities in this field has led to a growing importance of cross-modal retrieval for efficient image interpretation, data-driven diagnostic support, and medical education. In the context of the increasing integration of distributed medical data across healthcare facilities with the objective of enhancing interoperability, it is imperative to optimize the performance of retrieval systems in terms of the speed, memory efficiency, and accuracy of the retrieved data. This necessity arises in response to the substantial surge in data volume that characterizes contemporary medical practices. In this study, we propose a novel framework that incorporates dropout voting and mixture-of-experts (MoE) based contrastive fusion modules into a CLIP-based cross-modal hashing retrieval structure. We also propose the application of hybrid loss. So we now call our model MCMFH which is a medical cross-modal fusion hashing retrieval. Our method enables the simultaneous achievement of high accuracy and fast retrieval speed in low-memory environments. The model is demonstrated through experiments on radiological and non-radiological medical datasets.",
        "url": "http://arxiv.org/abs/2512.06449v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06449v1",
        "arxiv_id": "2512.06449v1",
        "authors": [
            "Jaewon Ahn",
            "Woosung Jang",
            "Beakcheol Jang"
        ],
        "submitted": "2025-12-06 14:23:44",
        "source": "arxiv",
        "comment": "5 pages, 1 figure, workshop paper (MMGenSR 2025)",
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on medical cross-modal hashing retrieval, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves retrieval and fusion, the context and application are specific to the medical domain and do not align with the user's interests in e-commerce or deep semantic understanding."
    },
    {
        "title": "LOCUS: A System and Method for Low-Cost Customization for Universal Specialization",
        "abstract": "We present LOCUS (LOw-cost Customization for Universal Specialization), a pipeline that consumes few-shot data to streamline the construction and training of NLP models through targeted retrieval, synthetic data generation, and parameter-efficient tuning. With only a small number of labeled examples, LOCUS discovers pertinent data in a broad repository, synthesizes additional training samples via in-context data generation, and fine-tunes models using either full or low-rank (LoRA) parameter adaptation. Our approach targets named entity recognition (NER) and text classification (TC) benchmarks, consistently outperforming strong baselines (including GPT-4o) while substantially lowering costs and model sizes. Our resultant memory-optimized models retain 99% of fully fine-tuned accuracy while using barely 5% of the memory footprint, also beating GPT-4o on several benchmarks with less than 1% of its parameters.",
        "url": "http://arxiv.org/abs/2512.06239v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06239v1",
        "arxiv_id": "2512.06239v1",
        "authors": [
            "Dhanasekar Sundararaman",
            "Keying Li",
            "Wayne Xiong",
            "Aashna Garg"
        ],
        "submitted": "2025-12-06 01:32:58",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper is somewhat related to the user's interests in Natural Language Processing (NLP) and data mining, but it focuses on model customization and optimization rather than query understanding, ranking models, or user behavior modeling. The paper's emphasis on low-cost customization and parameter-efficient tuning is also somewhat relevant to the user's interests in real-time relevance optimization."
    },
    {
        "title": "Empathy by Design: Aligning Large Language Models for Healthcare Dialogue",
        "abstract": "General-purpose large language models (LLMs) have demonstrated remarkable generative and reasoning capabilities but remain limited in healthcare and caregiving applications due to two key deficiencies: factual unreliability and a lack of empathetic communication. These shortcomings pose significant risks in sensitive contexts where users, particularly non-professionals and caregivers, seek medically relevant guidance or emotional reassurance. To address these challenges, we introduce a Direct Preference Optimization (DPO)-based alignment framework designed to improve factual correctness, semantic coherence, and human-centric qualities such as empathy, politeness, and simplicity in caregiver-patient dialogues. Our approach fine-tunes domain-adapted LLMs using pairwise preference data, where preferred responses reflect supportive and accessible communication styles while rejected ones represent prescriptive or overly technical tones. This direct optimization method aligns model outputs with human preferences more efficiently than traditional reinforcement-learning-based alignment. Empirical evaluations across multiple open and proprietary LLMs show that our DPO-tuned models achieve higher semantic alignment, improved factual accuracy, and stronger human-centric evaluation scores compared to baseline and commercial alternatives such as Google medical dialogue systems. These improvements demonstrate that preference-based alignment offers a scalable and transparent pathway toward developing trustworthy, empathetic, and clinically informed AI assistants for caregiver and healthcare communication. Our open-source code is available at: https://github.com/LeonG19/Empathy-by-Design",
        "url": "http://arxiv.org/abs/2512.06097v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06097v1",
        "arxiv_id": "2512.06097v1",
        "authors": [
            "Emre Umucu",
            "Guillermina Solis",
            "Leon Garza",
            "Emilia Rivas",
            "Beatrice Lee",
            "Anantaa Kotal",
            "Aritran Piplai"
        ],
        "submitted": "2025-12-05 19:04:28",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "While the paper explores the alignment of large language models for healthcare dialogue, it primarily focuses on empathetic communication and human-centric qualities, which is somewhat related to query understanding and user behavior modeling in Information Retrieval. However, the paper's emphasis on healthcare and caregiving applications, as well as its use of preference-based alignment, does not directly align with the user's core research themes in IR and Search technologies."
    },
    {
        "title": "MATEX: A Multi-Agent Framework for Explaining Ethereum Transactions",
        "abstract": "Understanding a complicated Ethereum transaction remains challenging: multi-hop token flows, nested contract calls, and opaque execution paths routinely lead users to blind signing. Based on interviews with everyday users, developers, and auditors, we identify the need for faithful, step-wise explanations grounded in both on-chain evidence and real-world protocol semantics. To meet this need, we introduce (matex, a cognitive multi-agent framework that models transaction understanding as a collaborative investigation-combining rapid hypothesis generation, dynamic off-chain knowledge retrieval, evidence-aware synthesis, and adversarial validation to produce faithful explanations.",
        "url": "http://arxiv.org/abs/2512.06933v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06933v1",
        "arxiv_id": "2512.06933v1",
        "authors": [
            "Zifan Peng"
        ],
        "submitted": "2025-12-07 17:23:55",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on explaining Ethereum transactions, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some form of understanding and explanation, it is more specific to blockchain and cryptocurrency transactions, and does not seem to align with your primary focus on deep semantic understanding and real-time relevance optimization in the context of IR."
    },
    {
        "title": "Rhea: Role-aware Heuristic Episodic Attention for Conversational LLMs",
        "abstract": "Large Language Models (LLMs) have achieved remarkable performance on single-turn tasks, yet their effectiveness deteriorates in multi-turn conversations. We define this phenomenon as cumulative contextual decay - a progressive degradation of contextual integrity caused by attention pollution, dilution, and drift. To address this challenge, we propose Rhea (Role-aware Heuristic Episodic Attention), a novel framework that decouples conversation history into two functionally independent memory modules: (1) an Instructional Memory (IM) that persistently stores high-fidelity global constraints via a structural priority mechanism, and (2) an Episodic Memory (EM) that dynamically manages user-model interactions via asymmetric noise control and heuristic context retrieval. During inference, Rhea constructs a high signal-to-noise context by applying its priority attention: selectively integrating relevant episodic information while always prioritizing global instructions. To validate this approach, experiments on multiple multi-turn conversation benchmarks - including MT-Eval and Long-MT-Bench+ - show that Rhea mitigates performance decay and improves overall accuracy by 1.04 points on a 10-point scale (a 16% relative gain over strong baselines). Moreover, Rhea maintains near-perfect instruction fidelity (IAR > 8.1) across long-horizon interactions. These results demonstrate that Rhea provides a principled and effective framework for building more precise, instruction-consistent conversational LLMs.",
        "url": "http://arxiv.org/abs/2512.06869v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06869v1",
        "arxiv_id": "2512.06869v1",
        "authors": [
            "Wanyang Hong",
            "Zhaoning Zhang",
            "Yi Chen",
            "Libo Zhang",
            "Baihui Liu",
            "Linbo Qiao",
            "Zhiliang Tian",
            "Dongsheng Li"
        ],
        "submitted": "2025-12-07 14:50:03",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and conversational systems, but it does not directly align with your primary focus on Information Retrieval (IR) and query understanding. The paper's focus on conversational LLMs and attention mechanisms is not a central match to your research themes."
    },
    {
        "title": "AquaFusionNet: Lightweight VisionSensor Fusion Framework for Real-Time Pathogen Detection and Water Quality Anomaly Prediction on Edge Devices",
        "abstract": "Evidence from many low and middle income regions shows that microbial contamination in small scale drinking water systems often fluctuates rapidly, yet existing monitoring tools capture only fragments of this behaviour. Microscopic imaging provides organism level visibility, whereas physicochemical sensors reveal shortterm changes in water chemistry; in practice, operators must interpret these streams separately, making realtime decision-making unreliable. This study introduces AquaFusionNet, a lightweight cross-modal framework that unifies both information sources inside a single edge deployable model. Unlike prior work that treats microscopic detection and water quality prediction as independent tasks, AquaFusionNet learns the statistical dependencies between microbial appearance and concurrent sensor dynamics through a gated crossattention mechanism designed specifically for lowpower hardware. The framework is trained on AquaMicro12K, a new dataset comprising 12,846 annotated 1000 micrographs curated for drinking water contexts, an area where publicly accessible microscopic datasets are scarce. Deployed for six months across seven facilities in East Java, Indonesia, the system processed 1.84 million frames and consistently detected contamination events with 94.8% mAP@0.5 and 96.3% anomaly prediction accuracy, while operating at 4.8 W on a Jetson Nano. Comparative experiments against representative lightweight detectors show that AquaFusionNet provides higher accuracy at comparable or lower power, and field results indicate that cross-modal coupling reduces common failure modes of unimodal detectors, particularly under fouling, turbidity spikes, and inconsistent illumination. All models, data, and hardware designs are released openly to facilitate replication and adaptation in decentralized water safety infrastructures.",
        "url": "http://arxiv.org/abs/2512.06848v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06848v1",
        "arxiv_id": "2512.06848v1",
        "authors": [
            "Sepyan Purnama Kristanto",
            "Lutfi Hakim",
            "Hermansyah"
        ],
        "submitted": "2025-12-07 14:03:26",
        "source": "arxiv",
        "comment": "9Pages, 3 figure, Politeknik Negeri Banyuwangi",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. It focuses on a vision-based framework for real-time pathogen detection and water quality anomaly prediction, which is outside your areas of expertise."
    },
    {
        "title": "Large Language Model-Based Generation of Discharge Summaries",
        "abstract": "Discharge Summaries are documents written by medical professionals that detail a patient's visit to a care facility. They contain a wealth of information crucial for patient care, and automating their generation could significantly reduce the effort required from healthcare professionals, minimize errors, and ensure that critical patient information is easily accessible and actionable. In this work, we explore the use of five Large Language Models on this task, from open-source models (Mistral, Llama 2) to proprietary systems (GPT-3, GPT-4, Gemini 1.5 Pro), leveraging MIMIC-III summaries and notes. We evaluate them using exact-match, soft-overlap, and reference-free metrics. Our results show that proprietary models, particularly Gemini with one-shot prompting, outperformed others, producing summaries with the highest similarity to the gold-standard ones. Open-source models, while promising, especially Mistral after fine-tuning, lagged in performance, often struggling with hallucinations and repeated information. Human evaluation by a clinical expert confirmed the practical utility of the summaries generated by proprietary models. Despite the challenges, such as hallucinations and missing information, the findings suggest that LLMs, especially proprietary models, are promising candidates for automatic discharge summary generation as long as data privacy is ensured.",
        "url": "http://arxiv.org/abs/2512.06812v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06812v1",
        "arxiv_id": "2512.06812v1",
        "authors": [
            "Tiago Rodrigues",
            "Carla Teixeira Lopes"
        ],
        "submitted": "2025-12-07 12:14:41",
        "source": "arxiv",
        "comment": "17 pages, 6 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on applying Large Language Models to automate discharge summary generation in healthcare, which is not directly related to Information Retrieval, Search technologies, or your other research interests. While it involves NLP, the context and application are quite different from your core themes."
    },
    {
        "title": "MMDuet2: Enhancing Proactive Interaction of Video MLLMs with Multi-Turn Reinforcement Learning",
        "abstract": "Recent advances in video multimodal large language models (Video MLLMs) have significantly enhanced video understanding and multi-modal interaction capabilities. While most existing systems operate in a turn-based manner where the model can only reply after user turns, proactively deciding when to reply during video playback presents a promising yet challenging direction for real-time applications. In this work, we propose a novel text-to-text approach to proactive interaction, where the model autonomously determines whether to respond or remain silent at each turn based on dialogue history and visual context up to current frame of an streaming video. To overcome difficulties in previous methods such as manually tuning response decision thresholds and annotating precise reply times, we introduce a multi-turn RL based training method that encourages timely and accurate responses without requiring precise response time annotations. We train our model MMDuet2 on a dataset of 52k videos with two types of dialogues via SFT and RL. Experimental results demonstrate that MMDuet2 outperforms existing proactive Video MLLM baselines in response timing and quality, achieving state-of-the-art performance on the ProactiveVideoQA benchmark.",
        "url": "http://arxiv.org/abs/2512.06810v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06810v1",
        "arxiv_id": "2512.06810v1",
        "authors": [
            "Yueqian Wang",
            "Songxiang Liu",
            "Disong Wang",
            "Nuo Xu",
            "Guanglu Wan",
            "Huishuai Zhang",
            "Dongyan Zhao"
        ],
        "submitted": "2025-12-07 12:03:04",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on proactive interaction of video multimodal large language models, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves text-to-text approach and reinforcement learning, the context is more aligned with NLP and multimodal interaction rather than IR or search technologies."
    },
    {
        "title": "One Word Is Not Enough: Simple Prompts Improve Word Embeddings",
        "abstract": "Text embedding models are designed for sentence-level applications like retrieval and semantic similarity, and are primarily evaluated on sentence-level benchmarks. Their behavior on isolated words is less understood. We show that simply prepending semantic prompts to words before embedding substantially improves word similarity correlations. Testing 7 text embedding models, including text-embedding-3-large (OpenAI), embed-english-v3.0 (Cohere), voyage-3(Voyage AI), all-mpnet-base-v2, and Qwen3-Embedding-8B, on 3 standard benchmarks (SimLex-999, WordSim-353, MEN-3000), we find that prompts like \"meaning: {word}\" or \"Represent the semantic concept: {word}\" improve Spearman correlations by up to +0.29 on SimLex-999. Some models fail completely on bare words (correlation = 0) but recover with prompts (+0.73 improvement). Our best results achieve correlation = 0.692 on SimLex-999 with embed-english-v3.0 (Cohere), correlation = 0.811 on WordSim-353, and correlation = 0.855 on MEN-3000 with text-embedding-3-large (OpenAI). These results outperform classic static embeddings like Word2Vec (correlation = 0.40) and even the best static method LexVec (correlation = 0.48) on SimLex-999, establishing a new state-of-the-art for pure embedding methods. This zero-shot technique requires no training and works with any text embedding model.",
        "url": "http://arxiv.org/abs/2512.06744v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06744v1",
        "arxiv_id": "2512.06744v1",
        "authors": [
            "Rajeev Ranjan"
        ],
        "submitted": "2025-12-07 09:17:10",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving word embeddings using semantic prompts, which is a topic in Natural Language Processing (NLP). While it touches on the broader concept of text embedding models, it doesn't directly relate to Information Retrieval (IR) or Search technologies, which are your primary research interests."
    },
    {
        "title": "Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics",
        "abstract": "The paper presents the formulation, implementation, and evaluation of the ArcGD optimiser. The evaluation is conducted initially on a non-convex benchmark function and subsequently on a real-world ML dataset. The initial comparative study using the Adam optimiser is conducted on a stochastic variant of the highly non-convex and notoriously challenging Rosenbrock function, renowned for its narrow, curved valley, across dimensions ranging from 2D to 1000D and an extreme case of 50,000D. Two configurations were evaluated to eliminate learning-rate bias: (i) both using ArcGD's effective learning rate and (ii) both using Adam's default learning rate. ArcGD consistently outperformed Adam under the first setting and, although slower under the second, achieved super ior final solutions in most cases. In the second evaluation, ArcGD is evaluated against state-of-the-art optimizers (Adam, AdamW, Lion, SGD) on the CIFAR-10 image classification dataset across 8 diverse MLP architectures ranging from 1 to 5 hidden layers. ArcGD achieved the highest average test accuracy (50.7%) at 20,000 iterations, outperforming AdamW (46.6%), Adam (46.8%), SGD (49.6%), and Lion (43.4%), winning or tying on 6 of 8 architectures. Notably, while Adam and AdamW showed strong early convergence at 5,000 iterations, but regressed with extended training, whereas ArcGD continued improving, demonstrating generalization and resistance to overfitting without requiring early stopping tuning. Strong performance on geometric stress tests and standard deep-learning benchmarks indicates broad applicability, highlighting the need for further exploration. Moreover, it is also shown that a variant of ArcGD can be interpreted as a special case of the Lion optimiser, highlighting connections between the inherent mechanisms of such optimisation methods.",
        "url": "http://arxiv.org/abs/2512.06737v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06737v1",
        "arxiv_id": "2512.06737v1",
        "authors": [
            "Nikhil Verma",
            "Joonas Linnosmaa",
            "Espinosa-Leal Leonardo",
            "Napat Vajragupta"
        ],
        "submitted": "2025-12-07 09:03:45",
        "source": "arxiv",
        "comment": "80 pages, 6 tables, 2 figures, 5 appendices, proof-of-concept",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "LLM scoring failed."
    },
    {
        "title": "Cognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents",
        "abstract": "Autonomous Large Language Model (LLM) agents exhibit significant vulnerability to Indirect Prompt Injection (IPI) attacks. These attacks hijack agent behavior by polluting external information sources, exploiting fundamental trade-offs between security and functionality in existing defense mechanisms. This leads to malicious and unauthorized tool invocations, diverting agents from their original objectives. The success of complex IPIs reveals a deeper systemic fragility: while current defenses demonstrate some effectiveness, most defense architectures are inherently fragmented. Consequently, they fail to provide full integrity assurance across the entire task execution pipeline, forcing unacceptable multi-dimensional compromises among security, functionality, and efficiency. Our method is predicated on a core insight: no matter how subtle an IPI attack, its pursuit of a malicious objective will ultimately manifest as a detectable deviation in the action trajectory, distinct from the expected legitimate plan. Based on this, we propose the Cognitive Control Architecture (CCA), a holistic framework achieving full-lifecycle cognitive supervision. CCA constructs an efficient, dual-layered defense system through two synergistic pillars: (i) proactive and preemptive control-flow and data-flow integrity enforcement via a pre-generated \"Intent Graph\"; and (ii) an innovative \"Tiered Adjudicator\" that, upon deviation detection, initiates deep reasoning based on multi-dimensional scoring, specifically designed to counter complex conditional attacks. Experiments on the AgentDojo benchmark substantiate that CCA not only effectively withstands sophisticated attacks that challenge other advanced defense methods but also achieves uncompromised security with notable efficiency and robustness, thereby reconciling the aforementioned multi-dimensional trade-off.",
        "url": "http://arxiv.org/abs/2512.06716v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06716v1",
        "arxiv_id": "2512.06716v1",
        "authors": [
            "Zhibo Liang",
            "Tianze Hu",
            "Zaiye Chen",
            "Mingjie Tang"
        ],
        "submitted": "2025-12-07 08:11:19",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on AI security and defense mechanisms against attacks, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves Large Language Models, the context is security and not query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "TopiCLEAR: Topic extraction by CLustering Embeddings with Adaptive dimensional Reduction",
        "abstract": "Rapid expansion of social media platforms such as X (formerly Twitter), Facebook, and Reddit has enabled large-scale analysis of public perceptions on diverse topics, including social issues, politics, natural disasters, and consumer sentiment. Topic modeling is a widely used approach for uncovering latent themes in text data, typically framed as an unsupervised classification task. However, traditional models, originally designed for longer and more formal documents, struggle with short social media posts due to limited co-occurrence statistics, fragmented semantics, inconsistent spelling, and informal language. To address these challenges, we propose a new method, TopiCLEAR: Topic extraction by CLustering Embeddings with Adaptive dimensional Reduction. Specifically, each text is embedded using Sentence-BERT (SBERT) and provisionally clustered using Gaussian Mixture Models (GMM). The clusters are then refined iteratively using a supervised projection based on linear discriminant analysis, followed by GMM-based clustering until convergence. Notably, our method operates directly on raw text, eliminating the need for preprocessing steps such as stop word removal. We evaluate our approach on four diverse datasets, 20News, AgNewsTitle, Reddit, and TweetTopic, each containing human-labeled topic information. Compared with seven baseline methods, including a recent SBERT-based method and a zero-shot generative AI method, our approach achieves the highest similarity to human-annotated topics, with significant improvements for both social media posts and online news articles. Additionally, qualitative analysis shows that our method produces more interpretable topics, highlighting its potential for applications in social media data and web content analytics.",
        "url": "http://arxiv.org/abs/2512.06694v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06694v1",
        "arxiv_id": "2512.06694v1",
        "authors": [
            "Aoi Fujita",
            "Taichi Yamamoto",
            "Yuri Nakayama",
            "Ryota Kobayashi"
        ],
        "submitted": "2025-12-07 07:01:28",
        "source": "arxiv",
        "comment": "15 pages, 4 figures, code available at https://github.com/aoi8716/TopiCLEAR",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper focuses on topic extraction from social media posts, using a novel method called TopiCLEAR. While it involves NLP techniques such as Sentence-BERT and Gaussian Mixture Models, its primary goal is not query understanding, ranking models, or user behavior modeling, which are core areas of interest. However, the paper's use of deep semantic understanding and clustering methods may be of interest to researchers in the IR community."
    },
    {
        "title": "CMV-Fuse: Cross Modal-View Fusion of AMR, Syntax, and Knowledge Representations for Aspect Based Sentiment Analysis",
        "abstract": "Natural language understanding inherently depends on integrating multiple complementary perspectives spanning from surface syntax to deep semantics and world knowledge. However, current Aspect-Based Sentiment Analysis (ABSA) systems typically exploit isolated linguistic views, thereby overlooking the intricate interplay between structural representations that humans naturally leverage. We propose CMV-Fuse, a Cross-Modal View fusion framework that emulates human language processing by systematically combining multiple linguistic perspectives. Our approach systematically orchestrates four linguistic perspectives: Abstract Meaning Representations, constituency parsing, dependency syntax, and semantic attention, enhanced with external knowledge integration. Through hierarchical gated attention fusion across local syntactic, intermediate semantic, and global knowledge levels, CMV-Fuse captures both fine-grained structural patterns and broad contextual understanding. A novel structure aware multi-view contrastive learning mechanism ensures consistency across complementary representations while maintaining computational efficiency. Extensive experiments demonstrate substantial improvements over strong baselines on standard benchmarks, with analysis revealing how each linguistic view contributes to more robust sentiment analysis.",
        "url": "http://arxiv.org/abs/2512.06679v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06679v1",
        "arxiv_id": "2512.06679v1",
        "authors": [
            "Smitha Muthya Sudheendra",
            "Mani Deep Cherukuri",
            "Jaideep Srivastava"
        ],
        "submitted": "2025-12-07 06:35:46",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Information Retrieval, particularly in the area of query understanding and deep semantic understanding. However, its focus on Aspect-Based Sentiment Analysis and cross-modal view fusion is not directly aligned with your primary interests in search technologies and ranking models."
    },
    {
        "title": "LLM-Upgraded Graph Reinforcement Learning for Carbon-Aware Job Scheduling in Smart Manufacturing",
        "abstract": "This paper presents \\textsc{Luca}, a \\underline{l}arge language model (LLM)-\\underline{u}pgraded graph reinforcement learning framework for \\underline{c}arbon-\\underline{a}ware flexible job shop scheduling. \\textsc{Luca} addresses the challenges of dynamic and sustainable scheduling in smart manufacturing systems by integrating a graph neural network and an LLM, guided by a carefully designed in-house prompting strategy, to produce a fused embedding that captures both structural characteristics and contextual semantics of the latest scheduling state. This expressive embedding is then processed by a deep reinforcement learning policy network, which generates real-time scheduling decisions optimized for both makespan and carbon emission objectives. To support sustainability goals, \\textsc{Luca} incorporates a dual-objective reward function that encourages both energy efficiency and scheduling timeliness. Experimental results on both synthetic and public datasets demonstrate that \\textsc{Luca} consistently outperforms comparison algorithms. For instance, on the synthetic dataset, it achieves an average of 4.1\\% and up to 12.2\\% lower makespan compared to the best-performing comparison algorithm while maintaining the same emission level. On public datasets, additional gains are observed for both makespan and emission. These results demonstrate that \\textsc{Luca} is effective and practical for carbon-aware scheduling in smart manufacturing.",
        "url": "http://arxiv.org/abs/2512.06351v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06351v1",
        "arxiv_id": "2512.06351v1",
        "authors": [
            "Zhiying Yang",
            "Fang Liu",
            "Wei Zhang",
            "Xin Lou",
            "Malcolm Yoke Hean Low",
            "Boon Ping Gan"
        ],
        "submitted": "2025-12-06 08:53:30",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on job scheduling in smart manufacturing, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves a large language model, the application is in a different domain and does not align with the user's core research themes."
    },
    {
        "title": "Nanbeige4-3B Technical Report: Exploring the Frontier of Small Language Models",
        "abstract": "We present Nanbeige4-3B, a family of small-scale but high-performing language models. Pretrained on 23T high-quality tokens and finetuned on over 30 million diverse instructions, we extend the boundary of the scaling law for small language models. In pre-training, we design a Fine-Grained Warmup-Stable-Decay (FG-WSD) training scheduler, which progressively refines data mixtures across stages to boost model performance. In post-training, to improve the quality of the SFT data, we design a joint mechanism that integrates deliberative generation refinement and chain-of-thought reconstruction, yielding substantial gains on complex tasks. Following SFT, we employ our flagship reasoning model to distill Nanbeige4-3B through our proposed Dual Preference Distillation (DPD) method, which leads to further performance gains. Finally, a multi-stage reinforcement learning phase was applied, leveraging verifiable rewards and preference modeling to strengthen abilities on both reasoning and human alignment. Extensive evaluations show that Nanbeige4-3B not only significantly outperforms models of comparable parameter scale but also rivals much larger models across a wide range of benchmarks. The model checkpoints are available at https://huggingface.co/Nanbeige.",
        "url": "http://arxiv.org/abs/2512.06266v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06266v1",
        "arxiv_id": "2512.06266v1",
        "authors": [
            "Chen Yang",
            "Guangyue Peng",
            "Jiaying Zhu",
            "Ran Le",
            "Ruixiang Feng",
            "Tao Zhang",
            "Wei Ruan",
            "Xiaoqi Liu",
            "Xiaoxue Cheng",
            "Xiyun Xu",
            "Yang Song",
            "Yanzipeng Gao",
            "Yiming Jia",
            "Yun Xing",
            "Yuntao Wen",
            "Zekai Wang",
            "Zhenwei An",
            "Zhicong Sun",
            "Zongchao Chen"
        ],
        "submitted": "2025-12-06 03:36:27",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on developing a small-scale language model, exploring training schedulers and distillation methods. While it touches on model performance and reasoning, it doesn't directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "Policy-based Sentence Simplification: Replacing Parallel Corpora with LLM-as-a-Judge",
        "abstract": "Sentence simplification aims to modify a sentence to make it easier to read and understand while preserving the meaning. Different applications require distinct simplification policies, such as replacing only complex words at the lexical level or rewriting the entire sentence while trading off details for simplicity. However, achieving such policy-driven control remains an open challenge. In this work, we introduce a simple yet powerful approach that leverages Large Language Model-as-a-Judge (LLM-as-a-Judge) to automatically construct policy-aligned training data, completely removing the need for costly human annotation or parallel corpora. Our method enables building simplification systems that adapt to diverse simplification policies. Remarkably, even small-scale open-source LLMs such as Phi-3-mini-3.8B surpass GPT-4o on lexical-oriented simplification, while achieving comparable performance on overall rewriting, as verified by both automatic metrics and human evaluations. The consistent improvements across model families and sizes demonstrate the robustness of our approach.",
        "url": "http://arxiv.org/abs/2512.06228v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06228v1",
        "arxiv_id": "2512.06228v1",
        "authors": [
            "Xuanxin Wu",
            "Yuki Arase",
            "Masaaki Nagata"
        ],
        "submitted": "2025-12-06 00:29:49",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, specifically in the area of text simplification and model evaluation. However, it does not directly address your core themes of query understanding, ranking models, or user behavior modeling. The use of Large Language Models is a relevant aspect, but the focus on sentence simplification and policy-driven control is not a central match for your research interests."
    },
    {
        "title": "Large Language Models and Forensic Linguistics: Navigating Opportunities and Threats in the Age of Generative AI",
        "abstract": "Large language models (LLMs) present a dual challenge for forensic linguistics. They serve as powerful analytical tools enabling scalable corpus analysis and embedding-based authorship attribution, while simultaneously destabilising foundational assumptions about idiolect through style mimicry, authorship obfuscation, and the proliferation of synthetic texts. Recent stylometric research indicates that LLMs can approximate surface stylistic features yet exhibit detectable differences from human writers, a tension with significant forensic implications. However, current AI-text detection techniques, whether classifier-based, stylometric, or watermarking approaches, face substantial limitations: high false positive rates for non-native English writers and vulnerability to adversarial strategies such as homoglyph substitution. These uncertainties raise concerns under legal admissibility standards, particularly the Daubert and Kumho Tire frameworks. The article concludes that forensic linguistics requires methodological reconfiguration to remain scientifically credible and legally admissible. Proposed adaptations include hybrid human-AI workflows, explainable detection paradigms beyond binary classification, and validation regimes measuring error and bias across diverse populations. The discipline's core insight, i.e., that language reveals information about its producer, remains valid but must accommodate increasingly complex chains of human and machine authorship.",
        "url": "http://arxiv.org/abs/2512.06922v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06922v1",
        "arxiv_id": "2512.06922v1",
        "authors": [
            "George Mikros"
        ],
        "submitted": "2025-12-07 17:05:31",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is primarily focused on the intersection of forensic linguistics and large language models, which is not a core area of interest for you. While it touches on some general AI-related topics, it does not align with your specific research themes in Information Retrieval, Search technologies, or Natural Language Processing."
    },
    {
        "title": "Think-While-Generating: On-the-Fly Reasoning for Personalized Long-Form Generation",
        "abstract": "Preference alignment has enabled large language models (LLMs) to better reflect human expectations, but current methods mostly optimize for population-level preferences, overlooking individual users. Personalization is essential, yet early approaches-such as prompt customization or fine-tuning-struggle to reason over implicit preferences, limiting real-world effectiveness. Recent \"think-then-generate\" methods address this by reasoning before response generation. However, they face challenges in long-form generation: their static one-shot reasoning must capture all relevant information for the full response generation, making learning difficult and limiting adaptability to evolving content. To address this issue, we propose FlyThinker, an efficient \"think-while-generating\" framework for personalized long-form generation. FlyThinker employs a separate reasoning model that generates latent token-level reasoning in parallel, which is fused into the generation model to dynamically guide response generation. This design enables reasoning and generation to run concurrently, ensuring inference efficiency. In addition, the reasoning model is designed to depend only on previous responses rather than its own prior outputs, which preserves training parallelism across different positions-allowing all reasoning tokens for training data to be produced in a single forward pass like standard LLM training, ensuring training efficiency. Extensive experiments on real-world benchmarks demonstrate that FlyThinker achieves better personalized generation while keeping training and inference efficiency.",
        "url": "http://arxiv.org/abs/2512.06690v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06690v1",
        "arxiv_id": "2512.06690v1",
        "authors": [
            "Chengbing Wang",
            "Yang Zhang",
            "Wenjie Wang",
            "Xiaoyan Zhao",
            "Fuli Feng",
            "Xiangnan He",
            "Tat-Seng Chua"
        ],
        "submitted": "2025-12-07 06:49:41",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores a novel approach to personalized long-form generation using a 'think-while-generating' framework. While it touches on aspects of deep semantic understanding and real-time relevance optimization, its primary focus is on natural language processing and generation, which is somewhat related to your interests in information retrieval and search technologies."
    },
    {
        "title": "PersonaMem-v2: Towards Personalized Intelligence via Learning Implicit User Personas and Agentic Memory",
        "abstract": "Personalization is one of the next milestones in advancing AI capability and alignment. We introduce PersonaMem-v2, the state-of-the-art dataset for LLM personalization that simulates 1,000 realistic user-chatbot interactions on 300+ scenarios, 20,000+ user preferences, and 128k-token context windows, where most user preferences are implicitly revealed to reflect real-world interactions. Using this data, we investigate how reinforcement fine-tuning enables a model to improve its long-context reasoning capabilities for user understanding and personalization. We also develop a framework for training an agentic memory system, which maintains a single, human-readable memory that grows with each user over time.\n  In our experiments, frontier LLMs still struggle with implicit personalization, achieving only 37-48% accuracy. While they support long context windows, reasoning remains the bottleneck for implicit personalization tasks. Using reinforcement fine-tuning, we successfully train Qwen3-4B to outperforms GPT-5, reaching 53% accuracy in implicit personalization. Moreover, our agentic memory framework achieves state-of-the-art 55% accuracy while using 16x fewer input tokens, relying on a 2k-token memory instead of full 32k conversation histories. These results underscore the impact of our dataset and demonstrate agentic memory as a scalable path toward real-world personalized intelligence.",
        "url": "http://arxiv.org/abs/2512.06688v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06688v1",
        "arxiv_id": "2512.06688v1",
        "authors": [
            "Bowen Jiang",
            "Yuan Yuan",
            "Maohao Shen",
            "Zhuoqun Hao",
            "Zhangchen Xu",
            "Zichen Chen",
            "Ziyi Liu",
            "Anvesh Rao Vijjini",
            "Jiashu He",
            "Hanchao Yu",
            "Radha Poovendran",
            "Gregory Wornell",
            "Lyle Ungar",
            "Dan Roth",
            "Sihao Chen",
            "Camillo Jose Taylor"
        ],
        "submitted": "2025-12-07 06:48:23",
        "source": "arxiv",
        "comment": "Data is available at https://huggingface.co/datasets/bowen-upenn/PersonaMem-v2",
        "score": 1,
        "keyword_reasons": [
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, particularly in the context of user understanding and personalization. However, the focus on reinforcement fine-tuning and agentic memory systems for long-context reasoning capabilities is not directly aligned with your primary interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Adapting AlignScore Mertic for Factual Consistency Evaluation of Text in Russian: A Student Abstract",
        "abstract": "Ensuring factual consistency in generated text is crucial for reliable natural language processing applications. However, there is a lack of evaluation tools for factual consistency in Russian texts, as existing tools primarily focus on English corpora. To bridge this gap, we introduce AlignRuScore, a comprehensive adaptation of the AlignScore metric for Russian. To adapt the metric, we fine-tuned a RuBERT-based alignment model with task-specific classification and regression heads on Russian and translated English datasets. Our results demonstrate that a unified alignment metric can be successfully ported to Russian, laying the groundwork for robust multilingual factual consistency evaluation. We release the translated corpora, model checkpoints, and code to support further research.",
        "url": "http://arxiv.org/abs/2512.06586v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06586v1",
        "arxiv_id": "2512.06586v1",
        "authors": [
            "Mikhail Zimin",
            "Milyausha Shamsutdinova",
            "Georgii Andriushchenko"
        ],
        "submitted": "2025-12-06 22:44:51",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Natural Language Processing (NLP), but it focuses on factual consistency evaluation in Russian, which is not a central match to the user's primary focus on information retrieval and query understanding. The paper's use of a multilingual alignment metric is relevant to the user's interests in deep semantic understanding, but the application is limited to factual consistency evaluation rather than search technologies or user behavior modeling."
    },
    {
        "title": "Morphologically-Informed Tokenizers for Languages with Non-Concatenative Morphology: A case study of YoloxÃ³chtil Mixtec ASR",
        "abstract": "This paper investigates the impact of using morphologically-informed tokenizers to aid and streamline the interlinear gloss annotation of an audio corpus of YoloxÃ³chitl Mixtec (YM) using a combination of ASR and text-based sequence-to-sequence tools, with the goal of improving efficiency while reducing the workload of a human annotator. We present two novel tokenization schemes that separate words in a nonlinear manner, preserving information about tonal morphology as much as possible. One of these approaches, a Segment and Melody tokenizer, simply extracts the tones without predicting segmentation. The other, a Sequence of Processes tokenizer, predicts segmentation for the words, which could allow an end-to-end ASR system to produce segmented and unsegmented transcriptions in a single pass. We find that these novel tokenizers are competitive with BPE and Unigram models, and the Segment-and-Melody model outperforms traditional tokenizers in terms of word error rate but does not reach the same character error rate. In addition, we analyze tokenizers on morphological and information-theoretic metrics to find predictive correlations with downstream performance. Our results suggest that nonlinear tokenizers designed specifically for the non-concatenative morphology of a language are competitive with conventional BPE and Unigram models for ASR. Further research will be necessary to determine the applicability of these tokenizers in downstream processing tasks.",
        "url": "http://arxiv.org/abs/2512.06169v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06169v1",
        "arxiv_id": "2512.06169v1",
        "authors": [
            "Chris Crawford"
        ],
        "submitted": "2025-12-05 21:35:42",
        "source": "arxiv",
        "comment": "67 pages, 5 figures, 6 tables",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. It focuses on speech recognition and tokenization for a specific language, which is outside your primary areas of interest."
    }
]