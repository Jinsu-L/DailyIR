[
    {
        "title": "Query Expansion in the Age of Pre-trained and Large Language Models: A Comprehensive Survey",
        "abstract": "Modern information retrieval (IR) must bridge short, ambiguous queries and\never more diverse, rapidly evolving corpora. Query Expansion (QE) remains a key\nmechanism for mitigating vocabulary mismatch, but the design space has shifted\nmarkedly with pre-trained language models (PLMs) and large language models\n(LLMs). This survey synthesizes the field from three angles: (i) a\nfour-dimensional framework of query expansion - from the point of injection\n(explicit vs. implicit QE), through grounding and interaction (knowledge bases,\nmodel-internal capabilities, multi-turn retrieval) and learning alignment, to\nknowledge graph-based argumentation; (ii) a model-centric taxonomy spanning\nencoder-only, encoder-decoder, decoder-only, instruction-tuned, and\ndomain/multilingual variants, highlighting their characteristic affordances for\nQE (contextual disambiguation, controllable generation, zero-/few-shot\nreasoning); and (iii) practice-oriented guidance on where and how neural QE\nhelps in first-stage retrieval, multi-query fusion, re-ranking, and\nretrieval-augmented generation (RAG). We compare traditional query expansion\nwith PLM/LLM-based methods across seven key aspects, and we map applications\nacross web search, biomedicine, e-commerce, open-domain QA/RAG, conversational\nand code search, and cross-lingual settings. The review distills design\ngrounding and interaction, alignment/distillation (SFT/PEFT/DPO), and KG\nconstraints - as robust remedies to topic drift and hallucination. We conclude\nwith an agenda on quality control, cost-aware invocation, domain/temporal\nadaptation, evaluation beyond end-task metrics, and fairness/privacy.\nCollectively, these insights provide a principled blueprint for selecting and\ncombining QE techniques under real-world constraints.",
        "url": "http://arxiv.org/abs/2509.07794v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07794v1",
        "arxiv_id": "2509.07794v1",
        "authors": [
            "Minghan Li",
            "Xinxuan Lv",
            "Junjie Zou",
            "Tongna Chen",
            "Chao Zhang",
            "Suchao An",
            "Ercong Nie",
            "Guodong Zhou"
        ],
        "submitted": "2025-09-09 14:31:11",
        "source": "arxiv",
        "comment": "38 pages,3 figures",
        "score": 21,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'web search' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 9,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly query understanding, ranking models, and user behavior modeling. The focus on query expansion, pre-trained language models, and large language models aligns well with your expertise in Search technologies and NLP."
    },
    {
        "title": "Benchmarking Information Retrieval Models on Complex Retrieval Tasks",
        "abstract": "Large language models (LLMs) are incredible and versatile tools for\ntext-based tasks that have enabled countless, previously unimaginable,\napplications. Retrieval models, in contrast, have not yet seen such capable\ngeneral-purpose models emerge. To achieve this goal, retrieval models must be\nable to perform complex retrieval tasks, where queries contain multiple parts,\nconstraints, or requirements in natural language. These tasks represent a\nnatural progression from the simple, single-aspect queries that are used in the\nvast majority of existing, commonly used evaluation sets. Complex queries\nnaturally arise as people expect search systems to handle more specific and\noften ambitious information requests, as is demonstrated by how people use\nLLM-based information systems. Despite the growing desire for retrieval models\nto expand their capabilities in complex retrieval tasks, there exist limited\nresources to assess the ability of retrieval models on a comprehensive set of\ndiverse complex tasks. The few resources that do exist feature a limited scope\nand often lack realistic settings making it hard to know the true capabilities\nof retrieval models on complex real-world retrieval tasks. To address this\nshortcoming and spur innovation in next-generation retrieval models, we\nconstruct a diverse and realistic set of complex retrieval tasks and benchmark\na representative set of state-of-the-art retrieval models. Additionally, we\nexplore the impact of LLM-based query expansion and rewriting on retrieval\nquality. Our results show that even the best models struggle to produce\nhigh-quality retrieval results with the highest average nDCG@10 of only 0.346\nand R@100 of only 0.587 across all tasks. Although LLM augmentation can help\nweaker models, the strongest model has decreased performance across all metrics\nwith all rewriting techniques.",
        "url": "http://arxiv.org/abs/2509.07253v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07253v1",
        "arxiv_id": "2509.07253v1",
        "authors": [
            "Julian Killingback",
            "Hamed Zamani"
        ],
        "submitted": "2025-09-08 22:11:10",
        "source": "arxiv",
        "comment": null,
        "score": 14,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in complex retrieval tasks and the evaluation of retrieval models. The paper's focus on benchmarking retrieval models and exploring the impact of LLM-based query expansion and rewriting aligns with your interests in query understanding and ranking models."
    },
    {
        "title": "Multi-view-guided Passage Reranking with Large Language Models",
        "abstract": "Recent advances in large language models (LLMs) have shown impressive\nperformance in passage reranking tasks. Despite their success, LLM-based\nmethods still face challenges in efficiency and sensitivity to external biases.\n(1) Existing models rely mostly on autoregressive generation and sliding window\nstrategies to rank passages, which incur heavy computational overhead as the\nnumber of passages increases. (2) External biases, such as position or\nselection bias, hinder the model's ability to accurately represent passages and\nincrease input-order sensitivity. To address these limitations, we introduce a\nnovel passage reranking model, called Multi-View-guided Passage Reranking\n(MVP). MVP is a non-generative LLM-based reranking method that encodes\nquery-passage information into diverse view embeddings without being influenced\nby external biases. For each view, it combines query-aware passage embeddings\nto produce a distinct anchor vector, which is then used to directly compute\nrelevance scores in a single decoding step. In addition, it employs an\northogonal loss to make the views more distinctive. Extensive experiments\ndemonstrate that MVP, with just 220M parameters, matches the performance of\nmuch larger 7B-scale fine-tuned models while achieving a 100x reduction in\ninference latency. Notably, the 3B-parameter variant of MVP achieves\nstate-of-the-art performance on both in-domain and out-of-domain benchmarks.\nThe source code is available at: https://github.com/bulbna/MVP",
        "url": "http://arxiv.org/abs/2509.07485v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07485v1",
        "arxiv_id": "2509.07485v1",
        "authors": [
            "Jeongwoo Na",
            "Jun Kwon",
            "Eunseong Choi",
            "Jongwuk Lee"
        ],
        "submitted": "2025-09-09 08:05:16",
        "source": "arxiv",
        "comment": null,
        "score": 13,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The use of large language models for passage reranking aligns with your focus on deep semantic understanding and real-time relevance optimization. The paper's emphasis on efficiency and sensitivity to external biases also resonates with your interests in user behavior modeling and click models."
    },
    {
        "title": "Beyond Sequential Reranking: Reranker-Guided Search Improves Reasoning Intensive Retrieval",
        "abstract": "The widely used retrieve-and-rerank pipeline faces two critical limitations:\nthey are constrained by the initial retrieval quality of the top-k documents,\nand the growing computational demands of LLM-based rerankers restrict the\nnumber of documents that can be effectively processed. We introduce\nReranker-Guided-Search (RGS), a novel approach that bypasses these limitations\nby directly retrieving documents according to reranker preferences rather than\nfollowing the traditional sequential reranking method. Our method uses a greedy\nsearch on proximity graphs generated by approximate nearest neighbor\nalgorithms, strategically prioritizing promising documents for reranking based\non document similarity. Experimental results demonstrate substantial\nperformance improvements across multiple benchmarks: 3.5 points on BRIGHT, 2.9\non FollowIR, and 5.1 on M-BEIR, all within a constrained reranker budget of 100\ndocuments. Our analysis suggests that, given a fixed pair of embedding and\nreranker models, strategically selecting documents to rerank can significantly\nimprove retrieval accuracy under limited reranker budget.",
        "url": "http://arxiv.org/abs/2509.07163v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07163v1",
        "arxiv_id": "2509.07163v1",
        "authors": [
            "Haike Xu",
            "Tong Chen"
        ],
        "submitted": "2025-09-08 19:24:09",
        "source": "arxiv",
        "comment": null,
        "score": 10,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to Information Retrieval, particularly in the context of ranking models and real-time relevance optimization. The introduction of Reranker-Guided-Search addresses limitations in traditional retrieve-and-rerank pipelines, which aligns with the user's interest in query understanding and ranking models. The experimental results and analysis also demonstrate the potential for improving retrieval accuracy, making this paper a useful contribution to the field."
    },
    {
        "title": "A Survey of Long-Document Retrieval in the PLM and LLM Era",
        "abstract": "The proliferation of long-form documents presents a fundamental challenge to\ninformation retrieval (IR), as their length, dispersed evidence, and complex\nstructures demand specialized methods beyond standard passage-level techniques.\nThis survey provides the first comprehensive treatment of long-document\nretrieval (LDR), consolidating methods, challenges, and applications across\nthree major eras. We systematize the evolution from classical lexical and early\nneural models to modern pre-trained (PLM) and large language models (LLMs),\ncovering key paradigms like passage aggregation, hierarchical encoding,\nefficient attention, and the latest LLM-driven re-ranking and retrieval\ntechniques. Beyond the models, we review domain-specific applications,\nspecialized evaluation resources, and outline critical open challenges such as\nefficiency trade-offs, multimodal alignment, and faithfulness. This survey aims\nto provide both a consolidated reference and a forward-looking agenda for\nadvancing long-document retrieval in the era of foundation models.",
        "url": "http://arxiv.org/abs/2509.07759v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07759v1",
        "arxiv_id": "2509.07759v1",
        "authors": [
            "Minghan Li",
            "Miyang Luo",
            "Tianrui Lv",
            "Yishuai Zhang",
            "Siqi Zhao",
            "Ercong Nie",
            "Guodong Zhou"
        ],
        "submitted": "2025-09-09 13:57:53",
        "source": "arxiv",
        "comment": "33 pages, 6 figures",
        "score": 9,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of long-document retrieval, which requires deep semantic understanding and real-time relevance optimization. The focus on pre-trained and large language models aligns with your interests in ranking models and query understanding. However, the paper's specific focus on long-document retrieval might not be a central match with your broader interests in user behavior modeling and click models."
    },
    {
        "title": "NOWJ@COLIEE 2025: A Multi-stage Framework Integrating Embedding Models and Large Language Models for Legal Retrieval and Entailment",
        "abstract": "This paper presents the methodologies and results of the NOWJ team's\nparticipation across all five tasks at the COLIEE 2025 competition, emphasizing\nadvancements in the Legal Case Entailment task (Task 2). Our comprehensive\napproach systematically integrates pre-ranking models (BM25, BERT, monoT5),\nembedding-based semantic representations (BGE-m3, LLM2Vec), and advanced Large\nLanguage Models (Qwen-2, QwQ-32B, DeepSeek-V3) for summarization, relevance\nscoring, and contextual re-ranking. Specifically, in Task 2, our two-stage\nretrieval system combined lexical-semantic filtering with contextualized LLM\nanalysis, achieving first place with an F1 score of 0.3195. Additionally, in\nother tasks--including Legal Case Retrieval, Statute Law Retrieval, Legal\nTextual Entailment, and Legal Judgment Prediction--we demonstrated robust\nperformance through carefully engineered ensembles and effective prompt-based\nreasoning strategies. Our findings highlight the potential of hybrid models\nintegrating traditional IR techniques with contemporary generative models,\nproviding a valuable reference for future advancements in legal information\nprocessing.",
        "url": "http://arxiv.org/abs/2509.08025v1",
        "pdf_url": "http://arxiv.org/pdf/2509.08025v1",
        "arxiv_id": "2509.08025v1",
        "authors": [
            "Hoang-Trung Nguyen",
            "Tan-Minh Nguyen",
            "Xuan-Bach Le",
            "Tuan-Kiet Le",
            "Khanh-Huyen Nguyen",
            "Ha-Thanh Nguyen",
            "Thi-Hai-Yen Vuong",
            "Le-Minh Nguyen"
        ],
        "submitted": "2025-09-09 12:05:52",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of legal retrieval and entailment. The use of hybrid models integrating traditional IR techniques with Large Language Models is also of interest. However, the focus on the legal domain is somewhat specific and may not be directly applicable to your e-commerce background."
    },
    {
        "title": "KLIPA: A Knowledge Graph and LLM-Driven QA Framework for IP Analysis",
        "abstract": "Effectively managing intellectual property is a significant challenge.\nTraditional methods for patent analysis depend on labor-intensive manual\nsearches and rigid keyword matching. These approaches are often inefficient and\nstruggle to reveal the complex relationships hidden within large patent\ndatasets, hindering strategic decision-making. To overcome these limitations,\nwe introduce KLIPA, a novel framework that leverages a knowledge graph and a\nlarge language model (LLM) to significantly advance patent analysis. Our\napproach integrates three key components: a structured knowledge graph to map\nexplicit relationships between patents, a retrieval-augmented generation(RAG)\nsystem to uncover contextual connections, and an intelligent agent that\ndynamically determines the optimal strategy for resolving user queries. We\nvalidated KLIPA on a comprehensive, real-world patent database, where it\ndemonstrated substantial improvements in knowledge extraction, discovery of\nnovel connections, and overall operational efficiency. This combination of\ntechnologies enhances retrieval accuracy, reduces reliance on domain experts,\nand provides a scalable, automated solution for any organization managing\nintellectual property, including technology corporations and legal firms,\nallowing them to better navigate the complexities of strategic innovation and\ncompetitive intelligence.",
        "url": "http://arxiv.org/abs/2509.07860v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07860v1",
        "arxiv_id": "2509.07860v1",
        "authors": [
            "Guanzhi Deng",
            "Yi Xie",
            "Yu-Keung Ng",
            "Mingyang Liu",
            "Peijun Zheng",
            "Jie Liu",
            "Dapeng Wu",
            "Yinqiao Li",
            "Linqi Song"
        ],
        "submitted": "2025-09-09 15:40:23",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper KLIPA explores a novel framework for patent analysis, leveraging knowledge graphs and large language models. While it touches on information retrieval and retrieval-augmented generation, its primary focus is on intellectual property analysis and knowledge extraction, which aligns somewhat with your interests in information retrieval and NLP. However, the specific domain and application are not directly related to your core research themes."
    },
    {
        "title": "ELEC: Efficient Large Language Model-Empowered Click-Through Rate Prediction",
        "abstract": "Click-through rate (CTR) prediction plays an important role in online\nadvertising systems. On the one hand, traditional CTR prediction models capture\nthe collaborative signals in tabular data via feature interaction modeling, but\nthey lose semantics in text. On the other hand, Large Language Models (LLMs)\nexcel in understanding the context and meaning behind text, but they face\nchallenges in capturing collaborative signals and they have long inference\nlatency. In this paper, we aim to leverage the benefits of both types of models\nand pursue collaboration, semantics and efficiency. We present ELEC, which is\nan Efficient LLM-Empowered CTR prediction framework. We first adapt an LLM for\nthe CTR prediction task. In order to leverage the ability of the LLM but\nsimultaneously keep efficiency, we utilize the pseudo-siamese network which\ncontains a gain network and a vanilla network. We inject the high-level\nrepresentation vector generated by the LLM into a collaborative CTR model to\nform the gain network such that it can take advantage of both tabular modeling\nand textual modeling. However, its reliance on the LLM limits its efficiency.\nWe then distill the knowledge from the gain network to the vanilla network on\nboth the score level and the representation level, such that the vanilla\nnetwork takes only tabular data as input, but can still generate comparable\nperformance as the gain network. Our approach is model-agnostic. It allows for\nthe integration with various existing LLMs and collaborative CTR models.\nExperiments on real-world datasets demonstrate the effectiveness and efficiency\nof ELEC for CTR prediction.",
        "url": "http://arxiv.org/abs/2509.07594v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07594v1",
        "arxiv_id": "2509.07594v1",
        "authors": [
            "Rui Dong",
            "Wentao Ouyang",
            "Xiangzheng Liu"
        ],
        "submitted": "2025-09-09 11:06:37",
        "source": "arxiv",
        "comment": "SIGIR 2025",
        "score": 8,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'click' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'click-through rate' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in click models and ranking models. The focus on leveraging Large Language Models for click-through rate prediction aligns with your interests in query understanding and real-time relevance optimization."
    },
    {
        "title": "From Detection to Mitigation: Addressing Gender Bias in Chinese Texts via Efficient Tuning and Voting-Based Rebalancing",
        "abstract": "This paper presents our team's solution to Shared Task 7 of NLPCC-2025, which\nfocuses on sentence-level gender bias detection and mitigation in Chinese. The\ntask aims to promote fairness and controllability in natural language\ngeneration by automatically detecting, classifying, and mitigating gender bias.\nTo address this challenge, we adopt a fine-tuning approach based on large\nlanguage models (LLMs), efficiently adapt to the bias detection task via\nLow-Rank Adaptation (LoRA). In terms of data processing, we construct a more\nbalanced training set to alleviate class imbalance and introduce heterogeneous\nsamples from multiple sources to enhance model generalization. For the\ndetection and classification sub-tasks, we employ a majority voting strategy\nthat integrates outputs from multiple expert models to boost performance.\nAdditionally, to improve bias generation detection and mitigation, we design a\nmulti-temperature sampling mechanism to capture potential variations in bias\nexpression styles. Experimental results demonstrate the effectiveness of our\napproach in bias detection, classification, and mitigation. Our method\nultimately achieves an average score of 47.90%, ranking fourth in the shared\ntask.",
        "url": "http://arxiv.org/abs/2509.07889v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07889v1",
        "arxiv_id": "2509.07889v1",
        "authors": [
            "Chengyan Wu",
            "Yiqiang Cai",
            "Yufei Cheng",
            "Yun Xue"
        ],
        "submitted": "2025-09-09 16:12:11",
        "source": "arxiv",
        "comment": "NLPCC 2025",
        "score": 6,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on addressing gender bias in Chinese texts, which is a task related to Natural Language Processing (NLP), but it does not align with the user's primary research interests in Information Retrieval (IR), query understanding, ranking models, and user behavior modeling. Although the paper involves fine-tuning large language models, it is not directly applicable to the user's areas of expertise."
    },
    {
        "title": "Towards End-to-End Model-Agnostic Explanations for RAG Systems",
        "abstract": "Retrieval Augmented Generation (RAG) systems, despite their growing\npopularity for enhancing model response reliability, often struggle with\ntrustworthiness and explainability. In this work, we present a novel, holistic,\nmodel-agnostic, post-hoc explanation framework leveraging perturbation-based\ntechniques to explain the retrieval and generation processes in a RAG system.\nWe propose different strategies to evaluate these explanations and discuss the\nsufficiency of model-agnostic explanations in RAG systems. With this work, we\nfurther aim to catalyze a collaborative effort to build reliable and\nexplainable RAG systems.",
        "url": "http://arxiv.org/abs/2509.07620v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07620v1",
        "arxiv_id": "2509.07620v1",
        "authors": [
            "Viju Sudhi",
            "Sinchana Ramakanth Bhat",
            "Max Rudat",
            "Roman Teucher",
            "Nicolas Flores-Herr"
        ],
        "submitted": "2025-09-09 11:47:40",
        "source": "arxiv",
        "comment": "Accepted to Workshop on Explainability in Information Retrieval\n  (WExIR), SIGIR 2025 - July 17, 2025",
        "score": 6,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval augmented generation' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, specifically in the context of Retrieval Augmented Generation (RAG) systems. While it doesn't directly focus on query understanding, ranking models, or user behavior modeling, it does address explainability in RAG systems, which is a relevant aspect of IR. However, the paper's primary focus on model-agnostic explanations and post-hoc techniques means it's not a central match for your interests."
    },
    {
        "title": "VeriOS: Query-Driven Proactive Human-Agent-GUI Interaction for Trustworthy OS Agents",
        "abstract": "With the rapid progress of multimodal large language models, operating system\n(OS) agents become increasingly capable of automating tasks through on-device\ngraphical user interfaces (GUIs). However, most existing OS agents are designed\nfor idealized settings, whereas real-world environments often present\nuntrustworthy conditions. To mitigate risks of over-execution in such\nscenarios, we propose a query-driven human-agent-GUI interaction framework that\nenables OS agents to decide when to query humans for more reliable task\ncompletion. Built upon this framework, we introduce VeriOS-Agent, a trustworthy\nOS agent trained with a two-stage learning paradigm that falicitate the\ndecoupling and utilization of meta-knowledge. Concretely, VeriOS-Agent\nautonomously executes actions in normal conditions while proactively querying\nhumans in untrustworthy scenarios. Experiments show that VeriOS-Agent improves\nthe average step-wise success rate by 20.64\\% in untrustworthy scenarios over\nthe state-of-the-art, without compromising normal performance. Analysis\nhighlights VeriOS-Agent's rationality, generalizability, and scalability. The\ncodes, datasets and models are available at\nhttps://github.com/Wuzheng02/VeriOS.",
        "url": "http://arxiv.org/abs/2509.07553v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07553v1",
        "arxiv_id": "2509.07553v1",
        "authors": [
            "Zheng Wu",
            "Heyuan Huang",
            "Xingyu Lou",
            "Xiangmou Qu",
            "Pengzhou Cheng",
            "Zongru Wu",
            "Weiwen Liu",
            "Weinan Zhang",
            "Jun Wang",
            "Zhaoxiang Wang",
            "Zhuosheng Zhang"
        ],
        "submitted": "2025-09-09 09:46:01",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on operating system agents and their interaction with humans, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves query-driven interaction, the context is more about human-agent interaction rather than query understanding or ranking models."
    },
    {
        "title": "ALLabel: Three-stage Active Learning for LLM-based Entity Recognition using Demonstration Retrieval",
        "abstract": "Many contemporary data-driven research efforts in the natural sciences, such\nas chemistry and materials science, require large-scale, high-performance\nentity recognition from scientific datasets. Large language models (LLMs) have\nincreasingly been adopted to solve the entity recognition task, with the same\ntrend being observed on all-spectrum NLP tasks. The prevailing entity\nrecognition LLMs rely on fine-tuned technology, yet the fine-tuning process\noften incurs significant cost. To achieve a best performance-cost trade-off, we\npropose ALLabel, a three-stage framework designed to select the most\ninformative and representative samples in preparing the demonstrations for LLM\nmodeling. The annotated examples are used to construct a ground-truth retrieval\ncorpus for LLM in-context learning. By sequentially employing three distinct\nactive learning strategies, ALLabel consistently outperforms all baselines\nunder the same annotation budget across three specialized domain datasets.\nExperimental results also demonstrate that selectively annotating only 5\\%-10\\%\nof the dataset with ALLabel can achieve performance comparable to the method\nannotating the entire dataset. Further analyses and ablation studies verify the\neffectiveness and generalizability of our proposal.",
        "url": "http://arxiv.org/abs/2509.07512v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07512v1",
        "arxiv_id": "2509.07512v1",
        "authors": [
            "Zihan Chen",
            "Lei Shi",
            "Weize Wu",
            "Qiji Zhou",
            "Yue Zhang"
        ],
        "submitted": "2025-09-09 08:47:13",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on entity recognition using Large Language Models (LLMs), which is a related topic to NLP. However, it doesn't directly align with the user's primary focus on Information Retrieval, especially query understanding, ranking models, and user behavior modeling. The paper's emphasis on entity recognition and active learning strategies is somewhat relevant but not a central match to the user's research interests."
    },
    {
        "title": "Avoiding Over-Personalization with Rule-Guided Knowledge Graph Adaptation for LLM Recommendations",
        "abstract": "We present a lightweight neuro-symbolic framework to mitigate\nover-personalization in LLM-based recommender systems by adapting user-side\nKnowledge Graphs (KGs) at inference time. Instead of retraining models or\nrelying on opaque heuristics, our method restructures a user's Personalized\nKnowledge Graph (PKG) to suppress feature co-occurrence patterns that reinforce\nPersonalized Information Environments (PIEs), i.e., algorithmically induced\nfilter bubbles that constrain content diversity. These adapted PKGs are used to\nconstruct structured prompts that steer the language model toward more diverse,\nOut-PIE recommendations while preserving topical relevance. We introduce a\nfamily of symbolic adaptation strategies, including soft reweighting, hard\ninversion, and targeted removal of biased triples, and a client-side learning\nalgorithm that optimizes their application per user. Experiments on a recipe\nrecommendation benchmark show that personalized PKG adaptations significantly\nincrease content novelty while maintaining recommendation quality,\noutperforming global adaptation and naive prompt-based methods.",
        "url": "http://arxiv.org/abs/2509.07133v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07133v1",
        "arxiv_id": "2509.07133v1",
        "authors": [
            "Fernando Spadea",
            "Oshani Seneviratne"
        ],
        "submitted": "2025-09-08 18:33:36",
        "source": "arxiv",
        "comment": "5 pages, 2 figures, ISWC",
        "score": 5,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores recommender systems, specifically addressing over-personalization using Knowledge Graphs, which is somewhat related to the user's interests in Information Retrieval and Search technologies. However, the focus on recommender systems and LLM-based recommendations is not the primary area of interest for the user, who has a stronger focus on query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Avoiding Knowledge Edit Skipping in Multi-hop Question Answering with Guided Decomposition",
        "abstract": "In a rapidly evolving world where information updates swiftly, knowledge in\nlarge language models (LLMs) becomes outdated quickly. Retraining LLMs is not a\ncost-effective option, making knowledge editing (KE) without modifying\nparameters particularly necessary. We find that although existing\nretrieval-augmented generation (RAG)-based KE methods excel at editing simple\nknowledge, they struggle with KE in multi-hop question answering due to the\nissue of \"edit skipping\", which refers to skipping the relevant edited fact in\ninference. In addition to the diversity of natural language expressions of\nknowledge, edit skipping also arises from the mismatch between the granularity\nof LLMs in problem-solving and the facts in the edited memory. To address this\nissue, we propose a novel Iterative Retrieval-Augmented Knowledge Editing\nmethod with guided decomposition (IRAKE) through the guidance from single\nedited facts and entire edited cases. Experimental results demonstrate that\nIRAKE mitigates the failure of editing caused by edit skipping and outperforms\nstate-of-the-art methods for KE in multi-hop question answering.",
        "url": "http://arxiv.org/abs/2509.07555v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07555v1",
        "arxiv_id": "2509.07555v1",
        "authors": [
            "Yi Liu",
            "Xiangrong Zhu",
            "Xiangyu Liu",
            "Wei Wei",
            "Wei Hu"
        ],
        "submitted": "2025-09-09 09:49:23",
        "source": "arxiv",
        "comment": "Accepted in EMNLP Findings 2025",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 3,
        "llm_reason": "The paper focuses on knowledge editing in large language models, which is somewhat related to information retrieval and query understanding. However, the specific context of multi-hop question answering and knowledge editing in language models is not directly aligned with the user's core research themes."
    },
    {
        "title": "HALT-RAG: A Task-Adaptable Framework for Hallucination Detection with Calibrated NLI Ensembles and Abstention",
        "abstract": "Detecting content that contradicts or is unsupported by a given source text\nis a critical challenge for the safe deployment of generative language models.\nWe introduce HALT-RAG, a post-hoc verification system designed to identify\nhallucinations in the outputs of Retrieval-Augmented Generation (RAG)\npipelines. Our flexible and task-adaptable framework uses a universal feature\nset derived from an ensemble of two frozen, off-the-shelf Natural Language\nInference (NLI) models and lightweight lexical signals. These features are used\nto train a simple, calibrated, and task-adapted meta-classifier. Using a\nrigorous 5-fold out-of-fold (OOF) training protocol to prevent data leakage and\nproduce unbiased estimates, we evaluate our system on the HaluEval benchmark.\nBy pairing our universal feature set with a lightweight, task-adapted\nclassifier and a precision-constrained decision policy, HALT-RAG achieves\nstrong OOF F1-scores of 0.7756, 0.9786, and 0.7391 on the summarization, QA,\nand dialogue tasks, respectively. The system's well-calibrated probabilities\nenable a practical abstention mechanism, providing a reliable tool for\nbalancing model performance with safety requirements.",
        "url": "http://arxiv.org/abs/2509.07475v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07475v1",
        "arxiv_id": "2509.07475v1",
        "authors": [
            "Saumya Goswami",
            "Siddharth Kurra"
        ],
        "submitted": "2025-09-09 07:58:46",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on detecting hallucinations in generative language models, which is a topic related to NLP, but it does not directly align with your core research interests in Information Retrieval, Search technologies, and query understanding."
    },
    {
        "title": "AIxcellent Vibes at GermEval 2025 Shared Task on Candy Speech Detection: Improving Model Performance by Span-Level Training",
        "abstract": "Positive, supportive online communication in social media (candy speech) has\nthe potential to foster civility, yet automated detection of such language\nremains underexplored, limiting systematic analysis of its impact. We\ninvestigate how candy speech can be reliably detected in a 46k-comment German\nYouTube corpus by monolingual and multilingual language models, including\nGBERT, Qwen3 Embedding, and XLM-RoBERTa. We find that a multilingual\nXLM-RoBERTa-Large model trained to detect candy speech at the span level\noutperforms other approaches, ranking first in both binary positive F1: 0.8906)\nand categorized span-based detection (strict F1: 0.6307) subtasks at the\nGermEval 2025 Shared Task on Candy Speech Detection. We speculate that\nspan-based training, multilingual capabilities, and emoji-aware tokenizers\nimproved detection performance. Our results demonstrate the effectiveness of\nmultilingual models in identifying positive, supportive language.",
        "url": "http://arxiv.org/abs/2509.07459v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07459v1",
        "arxiv_id": "2509.07459v1",
        "authors": [
            "Christian Rene Thelen",
            "Patrick Gustav Blaneck",
            "Tobias Bornheim",
            "Niklas Grieger",
            "Stephan Bialonski"
        ],
        "submitted": "2025-09-09 07:29:14",
        "source": "arxiv",
        "comment": "6 pages, 1 figure, 2 tables",
        "score": 4,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves NLP and model performance, its focus on candy speech detection in social media is not aligned with the user's interests in query understanding, ranking models, or real-time relevance optimization."
    },
    {
        "title": "LongEmotion: Measuring Emotional Intelligence of Large Language Models in Long-Context Interaction",
        "abstract": "Large language models (LLMs) make significant progress in Emotional\nIntelligence (EI) and long-context understanding. However, existing benchmarks\ntend to overlook certain aspects of EI in long-context scenarios, especially\nunder realistic, practical settings where interactions are lengthy, diverse,\nand often noisy. To move towards such realistic settings, we present\nLongEmotion, a benchmark specifically designed for long-context EI tasks. It\ncovers a diverse set of tasks, including Emotion Classification, Emotion\nDetection, Emotion QA, Emotion Conversation, Emotion Summary, and Emotion\nExpression. On average, the input length for these tasks reaches 8,777 tokens,\nwith long-form generation required for Emotion Expression. To enhance\nperformance under realistic constraints, we incorporate Retrieval-Augmented\nGeneration (RAG) and Collaborative Emotional Modeling (CoEM), and compare them\nwith standard prompt-based methods. Unlike conventional approaches, our RAG\nmethod leverages both the conversation context and the large language model\nitself as retrieval sources, avoiding reliance on external knowledge bases. The\nCoEM method further improves performance by decomposing the task into five\nstages, integrating both retrieval augmentation and limited knowledge\ninjection. Experimental results show that both RAG and CoEM consistently\nenhance EI-related performance across most long-context tasks, advancing LLMs\ntoward more practical and real-world EI applications. Furthermore, we conducted\na comparative case study experiment on the GPT series to demonstrate the\ndifferences among various models in terms of EI. Code is available on GitHub at\nhttps://github.com/LongEmotion/LongEmotion, and the project page can be found\nat https://longemotion.github.io/.",
        "url": "http://arxiv.org/abs/2509.07403v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07403v1",
        "arxiv_id": "2509.07403v1",
        "authors": [
            "Weichu Liu",
            "Jing Xiong",
            "Yuxuan Hu",
            "Zixuan Li",
            "Minghuan Tan",
            "Ningning Mao",
            "Chenyang Zhao",
            "Zhongwei Wan",
            "Chaofan Tao",
            "Wendong Xu",
            "Hui Shen",
            "Chengming Li",
            "Lingpeng Kong",
            "Ngai Wong"
        ],
        "submitted": "2025-09-09 05:32:45",
        "source": "arxiv",
        "comment": "Technical Report",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Emotional Intelligence in Large Language Models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on long-context interaction and emotional understanding is not directly aligned with the user's core research themes."
    },
    {
        "title": "Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search",
        "abstract": "Recent advances in large multimodal models have leveraged image-based tools\nwith reinforcement learning to tackle visual problems. However, existing\nopen-source approaches often exhibit monotonous reasoning patterns and allow\nonly a limited number of interaction turns, making them inadequate for\ndifficult tasks that require trial-and-error exploration. In this work, we\naddress this limitation by scaling up tool-based interactions and introduce\nMini-o3, a system that executes deep, multi-turn reasoning -- spanning tens of\nsteps -- and achieves state-of-the-art performance on challenging visual search\ntasks. Our recipe for reproducing OpenAI o3-style behaviors comprises three key\ncomponents. First, we construct the Visual Probe Dataset, a collection of\nthousands of challenging visual search problems designed for exploratory\nreasoning. Second, we develop an iterative data collection pipeline to obtain\ncold-start trajectories that exhibit diverse reasoning patterns, including\ndepth-first search, trial-and-error, and goal maintenance. Third, we propose an\nover-turn masking strategy that prevents penalization of over-turn responses\n(those that hit the maximum number of turns) during reinforcement learning,\nthereby balancing training-time efficiency with test-time scalability. Despite\ntraining with an upper bound of only six interaction turns, our model generates\ntrajectories that naturally scale to tens of turns at inference time, with\naccuracy improving as the number of turns increases. Extensive experiments\ndemonstrate that Mini-o3 produces rich reasoning patterns and deep thinking\npaths, effectively solving challenging visual search problems.",
        "url": "http://arxiv.org/abs/2509.07969v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07969v1",
        "arxiv_id": "2509.07969v1",
        "authors": [
            "Xin Lai",
            "Junyi Li",
            "Wei Li",
            "Tao Liu",
            "Tianjian Li",
            "Hengshuang Zhao"
        ],
        "submitted": "2025-09-09 17:54:21",
        "source": "arxiv",
        "comment": "Code, datasets, models are available at\n  https://github.com/Mini-o3/Mini-o3. Project Page: https://mini-o3.github.io/",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to information retrieval and search technologies, but its focus on visual search and multimodal models is not directly aligned with the user's core research themes. While it involves deep semantic understanding and real-time relevance optimization, the context is specific to visual search, which is not a primary area of interest for the user."
    },
    {
        "title": "SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and Relation Extraction in NLP",
        "abstract": "Structured information extraction from scientific literature is crucial for\ncapturing core concepts and emerging trends in specialized fields. While\nexisting datasets aid model development, most focus on specific publication\nsections due to domain complexity and the high cost of annotating scientific\ntexts. To address this limitation, we introduce SciNLP - a specialized\nbenchmark for full-text entity and relation extraction in the Natural Language\nProcessing (NLP) domain. The dataset comprises 60 manually annotated full-text\nNLP publications, covering 7,072 entities and 1,826 relations. Compared to\nexisting research, SciNLP is the first dataset providing full-text annotations\nof entities and their relationships in the NLP domain. To validate the\neffectiveness of SciNLP, we conducted comparative experiments with similar\ndatasets and evaluated the performance of state-of-the-art supervised models on\nthis dataset. Results reveal varying extraction capabilities of existing models\nacross academic texts of different lengths. Cross-comparisons with existing\ndatasets show that SciNLP achieves significant performance improvements on\ncertain baseline models. Using models trained on SciNLP, we implemented\nautomatic construction of a fine-grained knowledge graph for the NLP domain.\nOur KG has an average node degree of 3.2 per entity, indicating rich semantic\ntopological information that enhances downstream applications. The dataset is\npublicly available at https://github.com/AKADDC/SciNLP.",
        "url": "http://arxiv.org/abs/2509.07801v2",
        "pdf_url": "http://arxiv.org/pdf/2509.07801v2",
        "arxiv_id": "2509.07801v2",
        "authors": [
            "Decheng Duan",
            "Yingyi Zhang",
            "Jitong Peng",
            "Chengzhi Zhang"
        ],
        "submitted": "2025-09-09 14:41:40",
        "source": "arxiv",
        "comment": "EMNLP 2025 Main",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and data mining, but it focuses on a specific task of entity and relation extraction in scientific literature, which is not directly aligned with your primary focus on information retrieval and query understanding."
    },
    {
        "title": "FLeW: Facet-Level and Adaptive Weighted Representation Learning of Scientific Documents",
        "abstract": "Scientific document representation learning provides powerful embeddings for\nvarious tasks, while current methods face challenges across three approaches.\n1) Contrastive training with citation-structural signals underutilizes citation\ninformation and still generates single-vector representations. 2) Fine-grained\nrepresentation learning, which generates multiple vectors at the sentence or\naspect level, requires costly integration and lacks domain generalization. 3)\nTask-aware learning depends on manually predefined task categorization,\noverlooking nuanced task distinctions and requiring extra training data for\ntask-specific modules. To address these problems, we propose a new method that\nunifies the three approaches for better representations, namely FLeW.\nSpecifically, we introduce a novel triplet sampling method that leverages\ncitation intent and frequency to enhance citation-structural signals for\ntraining. Citation intents (background, method, result), aligned with the\ngeneral structure of scientific writing, facilitate a domain-generalized facet\npartition for fine-grained representation learning. Then, we adopt a simple\nweight search to adaptively integrate three facet-level embeddings into a\ntask-specific document embedding without task-aware fine-tuning. Experiments\nshow the applicability and robustness of FLeW across multiple scientific tasks\nand fields, compared to prior models.",
        "url": "http://arxiv.org/abs/2509.07531v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07531v1",
        "arxiv_id": "2509.07531v1",
        "authors": [
            "Zheng Dou",
            "Deqing Wang",
            "Fuzhen Zhuang",
            "Jian Ren",
            "Yanlin Hu"
        ],
        "submitted": "2025-09-09 09:08:44",
        "source": "arxiv",
        "comment": "Accepted by DASFAA2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a novel method for scientific document representation learning, which is somewhat related to information retrieval and NLP. However, it focuses on representation learning and does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. While it may have some indirect applications in IR, it is not a central match for the user's research themes."
    },
    {
        "title": "Astra: A Multi-Agent System for GPU Kernel Performance Optimization",
        "abstract": "GPU kernel optimization has long been a central challenge at the intersection\nof high-performance computing and machine learning. Efficient kernels are\ncrucial for accelerating large language model (LLM) training and serving, yet\nattaining high performance typically requires extensive manual tuning.\nCompiler-based systems reduce some of this burden, but still demand substantial\nmanual design and engineering effort. Recently, researchers have explored using\nLLMs for GPU kernel generation, though prior work has largely focused on\ntranslating high-level PyTorch modules into CUDA code. In this work, we\nintroduce Astra, the first LLM-based multi-agent system for GPU kernel\noptimization. Unlike previous approaches, Astra starts from existing CUDA\nimplementations extracted from SGLang, a widely deployed framework for serving\nLLMs, rather than treating PyTorch modules as the specification. Within Astra,\nspecialized LLM agents collaborate through iterative code generation, testing,\nprofiling, and planning to produce kernels that are both correct and\nhigh-performance. On kernels from SGLang, Astra achieves an average speedup of\n1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study\nfurther demonstrates that LLMs can autonomously apply loop transformations,\noptimize memory access patterns, exploit CUDA intrinsics, and leverage fast\nmath operations to yield substantial performance gains. Our work highlights\nmulti-agent LLM systems as a promising new paradigm for GPU kernel\noptimization.",
        "url": "http://arxiv.org/abs/2509.07506v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07506v1",
        "arxiv_id": "2509.07506v1",
        "authors": [
            "Anjiang Wei",
            "Tianran Sun",
            "Yogesh Seenichamy",
            "Hang Song",
            "Anne Ouyang",
            "Azalia Mirhoseini",
            "Ke Wang",
            "Alex Aiken"
        ],
        "submitted": "2025-09-09 08:39:50",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper focuses on GPU kernel optimization using multi-agent systems and large language models, which is unrelated to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "Causal Attention with Lookahead Keys",
        "abstract": "In standard causal attention, each token's query, key, and value (QKV) are\nstatic and encode only preceding context. We introduce CAuSal aTtention with\nLookahead kEys (CASTLE), an attention mechanism that continually updates each\ntoken's keys as the context unfolds. We term these updated keys lookahead keys\nbecause they belong to earlier positions yet integrate information from tokens\nthat appear later relative to those positions, while strictly preserving the\nautoregressive property. Although the mechanism appears sequential, we derive a\nmathematical equivalence that avoids explicitly materializing lookahead keys at\neach position and enables efficient parallel training. On language modeling\nbenchmarks, CASTLE consistently outperforms standard causal attention across\nmodel scales, reducing validation perplexity and improving performance on a\nrange of downstream tasks.",
        "url": "http://arxiv.org/abs/2509.07301v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07301v1",
        "arxiv_id": "2509.07301v1",
        "authors": [
            "Zhuoqing Song",
            "Peng Sun",
            "Huizhuo Yuan",
            "Quanquan Gu"
        ],
        "submitted": "2025-09-09 00:15:23",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on attention mechanisms in language modeling, which is related to Natural Language Processing, but does not directly address Information Retrieval, query understanding, ranking models, or user behavior modeling, which are core areas of interest."
    },
    {
        "title": "Neurocognitive Modeling for Text Generation: Deep Learning Architecture for EEG Data",
        "abstract": "Text generating capabilities have undergone a substantial transformation with\nthe introduction of large language models (LLMs). Electroencephalography\n(EEG)-based text production is still difficult, though, because it requires a\nlot of data and processing power. This paper introduces a new method that\ncombines the use of the Gemma 2B LLM with a classifier-LLM architecture to\nincorporate a Recurrent Neural Network (RNN) encoder. Our approach drastically\nlowers the amount of data and compute power needed while achieving performance\nclose to that of cutting-edge methods. Notably, compared to current\nmethodologies, our methodology delivers an overall performance improvement of\n10%. The suggested architecture demonstrates the possibility of effective\ntransfer learning for EEG-based text production, remaining strong and\nfunctional even in the face of data limits. This work highlights the potential\nof integrating LLMs with EEG decoding to improve assistive technologies and\nimprove independence and communication for those with severe motor limitations.\nOur method pushes the limits of present capabilities and opens new paths for\nresearch and application in brain-computer interfaces by efficiently using the\nstrengths of pre-trained language models. This makes EEG-based text production\nmore accessible and efficient.",
        "url": "http://arxiv.org/abs/2509.07202v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07202v1",
        "arxiv_id": "2509.07202v1",
        "authors": [
            "Khushiyant"
        ],
        "submitted": "2025-09-08 20:32:41",
        "source": "arxiv",
        "comment": "15 pages, 10 figures, 5 tables",
        "score": 3,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on text generation using EEG data and deep learning architectures, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves deep learning and language models, the context and application are distinct from the user's areas of focus."
    },
    {
        "title": "Towards EnergyGPT: A Large Language Model Specialized for the Energy Sector",
        "abstract": "Large Language Models have demonstrated impressive capabilities across\nvarious domains. However, their general-purpose nature often limits their\neffectiveness in specialized fields such as energy, where deep technical\nexpertise and precise domain knowledge are essential. In this paper, we\nintroduce EnergyGPT, a domain-specialized language model tailored for the\nenergy sector, developed by fine-tuning LLaMA 3.1-8B model using Supervised\nFine-Tuning on a high-quality, curated corpus of energy-related texts. We\npresent a complete development pipeline, including data collection and\ncuration, model fine-tuning, benchmark design and LLM-judge choice, evaluation\nand deployment. Through this work, we demonstrate that our training strategy\nenables improvements in domain relevance and performance without the need for\nlarge-scale infrastructure. By evaluating the performance of the model using\ndomain-specific question-answering benchmarks, our results demonstrate that\nEnergyGPT outperforms the base model in most of the energy-related language\nunderstanding and generation tasks.",
        "url": "http://arxiv.org/abs/2509.07177v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07177v1",
        "arxiv_id": "2509.07177v1",
        "authors": [
            "Amal Chebbi",
            "Babajide Kolade"
        ],
        "submitted": "2025-09-08 19:48:52",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on developing a domain-specialized language model for the energy sector, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves language understanding and generation tasks, the context is highly specialized and does not align with the user's interests in e-commerce, query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "That's So FETCH: Fashioning Ensemble Techniques for LLM Classification in Civil Legal Intake and Referral",
        "abstract": "Each year millions of people seek help for their legal problems by calling a\nlegal aid program hotline, walking into a legal aid office, or using a lawyer\nreferral service. The first step to match them to the right help is to identify\nthe legal problem the applicant is experiencing. Misdirection has consequences.\nApplicants may miss a deadline, experience physical abuse, lose housing or lose\ncustody of children while waiting to connect to the right legal help. We\nintroduce and evaluate the FETCH classifier for legal issue classification and\ndescribe two methods for improving accuracy: a hybrid LLM/ML ensemble\nclassification method, and the automatic generation of follow-up questions to\nenrich the initial problem narrative. We employ a novel data set of 419\nreal-world queries to a nonprofit lawyer referral service. Ultimately, we show\nclassification accuracy (hits@2) of 97.37\\% using a mix of inexpensive models,\nexceeding the performance of the current state-of-the-art GPT-5 model. Our\napproach shows promise in significantly reducing the cost of guiding users of\nthe legal system to the right resource for their problem while achieving high\naccuracy.",
        "url": "http://arxiv.org/abs/2509.07170v2",
        "pdf_url": "http://arxiv.org/pdf/2509.07170v2",
        "arxiv_id": "2509.07170v2",
        "authors": [
            "Quinten Steenhuis"
        ],
        "submitted": "2025-09-08 19:34:57",
        "source": "arxiv",
        "comment": "Submission to JURIX 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves LLM classification, the context is specific to legal issue classification and referral, which is not a central match to your areas of focus."
    },
    {
        "title": "Toward Purpose-oriented Topic Model Evaluation enabled by Large Language Models",
        "abstract": "This study presents a framework for automated evaluation of dynamically\nevolving topic models using Large Language Models (LLMs). Topic modeling is\nessential for organizing and retrieving scholarly content in digital library\nsystems, helping users navigate complex and evolving knowledge domains.\nHowever, widely used automated metrics, such as coherence and diversity, often\ncapture only narrow statistical patterns and fail to explain semantic failures\nin practice. We introduce a purpose-oriented evaluation framework that employs\nnine LLM-based metrics spanning four key dimensions of topic quality: lexical\nvalidity, intra-topic semantic soundness, inter-topic structural soundness, and\ndocument-topic alignment soundness. The framework is validated through\nadversarial and sampling-based protocols, and is applied across datasets\nspanning news articles, scholarly publications, and social media posts, as well\nas multiple topic modeling methods and open-source LLMs. Our analysis shows\nthat LLM-based metrics provide interpretable, robust, and task-relevant\nassessments, uncovering critical weaknesses in topic models such as redundancy\nand semantic drift, which are often missed by traditional metrics. These\nresults support the development of scalable, fine-grained evaluation tools for\nmaintaining topic relevance in dynamic datasets. All code and data supporting\nthis work are accessible at\nhttps://github.com/zhiyintan/topic-model-LLMjudgment.",
        "url": "http://arxiv.org/abs/2509.07142v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07142v1",
        "arxiv_id": "2509.07142v1",
        "authors": [
            "Zhiyin Tan",
            "Jennifer D'Souza"
        ],
        "submitted": "2025-09-08 18:46:08",
        "source": "arxiv",
        "comment": "Accepted for publication in International Journal on Digital\n  Libraries (IJDL)",
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper is somewhat related to the user's interests in Information Retrieval, particularly in the area of topic modeling and evaluation. The use of Large Language Models for topic model evaluation aligns with the user's focus on deep semantic understanding and real-time relevance optimization. However, the paper's primary focus on topic modeling in digital library systems and scholarly content retrieval is not directly related to the user's e-commerce background or recommender systems interests."
    },
    {
        "title": "Neuro-Symbolic Frameworks: Conceptual Characterization and Empirical Comparative Analysis",
        "abstract": "Neurosymbolic (NeSy) frameworks combine neural representations and learning\nwith symbolic representations and reasoning. Combining the reasoning\ncapacities, explainability, and interpretability of symbolic processing with\nthe flexibility and power of neural computing allows us to solve complex\nproblems with more reliability while being data-efficient. However, this\nrecently growing topic poses a challenge to developers with its learning curve,\nlack of user-friendly tools, libraries, and unifying frameworks. In this paper,\nwe characterize the technical facets of existing NeSy frameworks, such as the\nsymbolic representation language, integration with neural models, and the\nunderlying algorithms. A majority of the NeSy research focuses on algorithms\ninstead of providing generic frameworks for declarative problem specification\nto leverage problem solving. To highlight the key aspects of Neurosymbolic\nmodeling, we showcase three generic NeSy frameworks - \\textit{DeepProbLog},\n\\textit{Scallop}, and \\textit{DomiKnowS}. We identify the challenges within\neach facet that lay the foundation for identifying the expressivity of each\nframework in solving a variety of problems. Building on this foundation, we aim\nto spark transformative action and encourage the community to rethink this\nproblem in novel ways.",
        "url": "http://arxiv.org/abs/2509.07122v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07122v1",
        "arxiv_id": "2509.07122v1",
        "authors": [
            "Sania Sinha",
            "Tanawan Premsri",
            "Danial Kamali",
            "Parisa Kordjamshidi"
        ],
        "submitted": "2025-09-08 18:17:33",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is primarily focused on neurosymbolic frameworks, which is a topic in Natural Language Processing (NLP). While it touches on the intersection of symbolic and neural representations, it does not directly relate to information retrieval, search technologies, or query understanding, which are the core areas of your research interests."
    },
    {
        "title": "Instruction Agent: Enhancing Agent with Expert Demonstration",
        "abstract": "Graphical user interface (GUI) agents have advanced rapidly but still\nstruggle with complex tasks involving novel UI elements, long-horizon actions,\nand personalized trajectories. In this work, we introduce Instruction Agent, a\nGUI agent that leverages expert demonstrations to solve such tasks, enabling\ncompletion of otherwise difficult workflows. Given a single demonstration, the\nagent extracts step-by-step instructions and executes them by strictly\nfollowing the trajectory intended by the user, which avoids making mistakes\nduring execution. The agent leverages the verifier and backtracker modules\nfurther to improve robustness. Both modules are critical to understand the\ncurrent outcome from each action and handle unexpected interruptions(such as\npop-up windows) during execution. Our experiments show that Instruction Agent\nachieves a 60% success rate on a set of tasks in OSWorld that all top-ranked\nagents failed to complete. The Instruction Agent offers a practical and\nextensible framework, bridging the gap between current GUI agents and reliable\nreal-world GUI task automation.",
        "url": "http://arxiv.org/abs/2509.07098v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07098v1",
        "arxiv_id": "2509.07098v1",
        "authors": [
            "Yinheng Li",
            "Hailey Hultquist",
            "Justin Wagle",
            "Kazuhito Koishida"
        ],
        "submitted": "2025-09-08 18:00:12",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Graphical User Interface (GUI) agents and their ability to complete complex tasks with expert demonstrations. While it touches on automation and task completion, it does not align with the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "Parallel-R1: Towards Parallel Thinking via Reinforcement Learning",
        "abstract": "Parallel thinking has emerged as a novel approach for enhancing the reasoning\ncapabilities of large language models (LLMs) by exploring multiple reasoning\npaths concurrently. However, activating such capabilities through training\nremains challenging, as existing methods predominantly rely on supervised\nfine-tuning (SFT) over synthetic data, which encourages teacher-forced\nimitation rather than exploration and generalization. Different from them, we\npropose \\textbf{Parallel-R1}, the first reinforcement learning (RL) framework\nthat enables parallel thinking behaviors for complex real-world reasoning\ntasks. Our framework employs a progressive curriculum that explicitly addresses\nthe cold-start problem in training parallel thinking with RL. We first use SFT\non prompt-generated trajectories from easier tasks to instill the parallel\nthinking ability, then transition to RL to explore and generalize this skill on\nharder problems. Experiments on various math benchmarks, including MATH, AMC23,\nand AIME, show that Parallel-R1 successfully instills parallel thinking,\nleading to 8.4% accuracy improvements over the sequential thinking model\ntrained directly on challenging tasks with RL. Further analysis reveals a clear\nshift in the model's thinking behavior: at an early stage, it uses parallel\nthinking as an exploration strategy, while in a later stage, it uses the same\ncapability for multi-perspective verification. Most significantly, we validate\nparallel thinking as a \\textbf{mid-training exploration scaffold}, where this\ntemporary exploratory phase unlocks a higher performance ceiling after RL,\nyielding a 42.9% improvement over the baseline on AIME25. Our model, data, and\ncode will be open-source at https://github.com/zhengkid/Parallel-R1.",
        "url": "http://arxiv.org/abs/2509.07980v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07980v1",
        "arxiv_id": "2509.07980v1",
        "authors": [
            "Tong Zheng",
            "Hongming Zhang",
            "Wenhao Yu",
            "Xiaoyang Wang",
            "Xinyu Yang",
            "Runpeng Dai",
            "Rui Liu",
            "Huiwen Bao",
            "Chengsong Huang",
            "Heng Huang",
            "Dong Yu"
        ],
        "submitted": "2025-09-09 17:59:35",
        "source": "arxiv",
        "comment": "Project website: https://zhengkid.github.io/Parallel_R1.github.io/",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on enhancing the reasoning capabilities of large language models through reinforcement learning, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves deep semantic understanding, the context is different from the user's primary research interests."
    },
    {
        "title": "SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge",
        "abstract": "We introduce SimpleQA Verified, a 1,000-prompt benchmark for evaluating Large\nLanguage Model (LLM) short-form factuality based on OpenAI's SimpleQA. It\naddresses critical limitations in OpenAI's benchmark, including noisy and\nincorrect labels, topical biases, and question redundancy. SimpleQA Verified\nwas created through a rigorous multi-stage filtering process involving\nde-duplication, topic balancing, and source reconciliation to produce a more\nreliable and challenging evaluation set, alongside improvements in the\nautorater prompt. On this new benchmark, Gemini 2.5 Pro achieves a\nstate-of-the-art F1-score of 55.6, outperforming other frontier models,\nincluding GPT-5. This work provides the research community with a\nhigher-fidelity tool to track genuine progress in parametric model factuality\nand to mitigate hallucinations. The benchmark dataset, evaluation code, and\nleaderboard are available at:\nhttps://www.kaggle.com/benchmarks/deepmind/simpleqa-verified.",
        "url": "http://arxiv.org/abs/2509.07968v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07968v1",
        "arxiv_id": "2509.07968v1",
        "authors": [
            "Lukas Haas",
            "Gal Yona",
            "Giovanni D'Antonio",
            "Sasha Goldshtein",
            "Dipanjan Das"
        ],
        "submitted": "2025-09-09 17:53:58",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'search' (score: +1)",
            "Found 'www' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper introduces a benchmark for evaluating Large Language Model factuality, which is somewhat related to information retrieval and search technologies, particularly in the context of query understanding and ranking models. However, the focus on factuality and hallucinations in LLMs is not directly aligned with the user's primary research interests in IR and search technologies. The connection to NLP is relevant, but the paper's scope is more narrow than the user's broader interests."
    },
    {
        "title": "GENUINE: Graph Enhanced Multi-level Uncertainty Estimation for Large Language Models",
        "abstract": "Uncertainty estimation is essential for enhancing the reliability of Large\nLanguage Models (LLMs), particularly in high-stakes applications. Existing\nmethods often overlook semantic dependencies, relying on token-level\nprobability measures that fail to capture structural relationships within the\ngenerated text. We propose GENUINE: Graph ENhanced mUlti-level uncertaINty\nEstimation for Large Language Models, a structure-aware framework that\nleverages dependency parse trees and hierarchical graph pooling to refine\nuncertainty quantification. By incorporating supervised learning, GENUINE\neffectively models semantic and structural relationships, improving confidence\nassessments. Extensive experiments across NLP tasks show that GENUINE achieves\nup to 29% higher AUROC than semantic entropy-based approaches and reduces\ncalibration errors by over 15%, demonstrating the effectiveness of graph-based\nuncertainty modeling. The code is available at\nhttps://github.com/ODYSSEYWT/GUQ.",
        "url": "http://arxiv.org/abs/2509.07925v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07925v1",
        "arxiv_id": "2509.07925v1",
        "authors": [
            "Tuo Wang",
            "Adithya Kulkarni",
            "Tyler Cody",
            "Peter A. Beling",
            "Yujun Yan",
            "Dawei Zhou"
        ],
        "submitted": "2025-09-09 17:07:44",
        "source": "arxiv",
        "comment": "Accepted by EMNLP 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on uncertainty estimation for Large Language Models, which is related to my interests in NLP. However, it doesn't directly address query understanding, ranking models, or user behavior modeling, which are core areas of my research. While it explores a novel approach to uncertainty modeling, its relevance to my primary research themes is limited."
    },
    {
        "title": "M-BRe: Discovering Training Samples for Relation Extraction from Unlabeled Texts with Large Language Models",
        "abstract": "For Relation Extraction (RE), the manual annotation of training data may be\nprohibitively expensive, since the sentences that contain the target relations\nin texts can be very scarce and difficult to find. It is therefore beneficial\nto develop an efficient method that can automatically extract training\ninstances from unlabeled texts for training RE models. Recently, large language\nmodels (LLMs) have been adopted in various natural language processing tasks,\nwith RE also benefiting from their advances. However, when leveraging LLMs for\nRE with predefined relation categories, two key challenges arise. First, in a\nmulti-class classification setting, LLMs often struggle to comprehensively\ncapture the semantics of every relation, leading to suboptimal results. Second,\nalthough employing binary classification for each relation individually can\nmitigate this issue, it introduces significant computational overhead,\nresulting in impractical time complexity for real-world applications.\nTherefore, this paper proposes a framework called M-BRe to extract training\ninstances from unlabeled texts for RE. It utilizes three modules to combine the\nadvantages of both of the above classification approaches: Relation Grouping,\nRelation Extraction, and Label Decision. Extensive experiments confirm its\nsuperior capability in discovering high-quality training samples from unlabeled\ntexts for RE.",
        "url": "http://arxiv.org/abs/2509.07730v2",
        "pdf_url": "http://arxiv.org/pdf/2509.07730v2",
        "arxiv_id": "2509.07730v2",
        "authors": [
            "Zexuan Li",
            "Hongliang Dai",
            "Piji Li"
        ],
        "submitted": "2025-09-09 13:32:29",
        "source": "arxiv",
        "comment": "Accepted by EMNLP2025 Main Conference",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Relation Extraction, a task related to Information Retrieval, but its primary goal is to improve the efficiency of training data extraction for RE models. While it leverages large language models, which are relevant to NLP, the specific application and challenges addressed are not directly aligned with the user's core research themes in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values",
        "abstract": "The alignment of large language models (LLMs) with human values is critical\nfor their safe and effective deployment across diverse user populations.\nHowever, existing benchmarks often neglect cultural and demographic diversity,\nleading to limited understanding of how value alignment generalizes globally.\nIn this work, we introduce MVPBench, a novel benchmark that systematically\nevaluates LLMs' alignment with multi-dimensional human value preferences across\n75 countries. MVPBench contains 24,020 high-quality instances annotated with\nfine-grained value labels, personalized questions, and rich demographic\nmetadata, making it the most comprehensive resource of its kind to date. Using\nMVPBench, we conduct an in-depth analysis of several state-of-the-art LLMs,\nrevealing substantial disparities in alignment performance across geographic\nand demographic lines. We further demonstrate that lightweight fine-tuning\nmethods, such as Low-Rank Adaptation (LoRA) and Direct Preference Optimization\n(DPO), can significantly enhance value alignment in both in-domain and\nout-of-domain settings. Our findings underscore the necessity for\npopulation-aware alignment evaluation and provide actionable insights for\nbuilding culturally adaptive and value-sensitive LLMs. MVPBench serves as a\npractical foundation for future research on global alignment, personalized\nvalue modeling, and equitable AI development.",
        "url": "http://arxiv.org/abs/2509.08022v1",
        "pdf_url": "http://arxiv.org/pdf/2509.08022v1",
        "arxiv_id": "2509.08022v1",
        "authors": [
            "Yao Liang",
            "Dongcheng Zhao",
            "Feifei Zhao",
            "Guobin Shen",
            "Yuwei Wang",
            "Dongqi Liang",
            "Yi Zeng"
        ],
        "submitted": "2025-09-09 09:25:08",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, particularly in the context of large language models and their alignment with human values. However, the focus on value alignment and cultural diversity is not directly aligned with the user's primary research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "GLEAM: Learning to Match and Explain in Cross-View Geo-Localization",
        "abstract": "Cross-View Geo-Localization (CVGL) focuses on identifying correspondences\nbetween images captured from distinct perspectives of the same geographical\nlocation. However, existing CVGL approaches are typically restricted to a\nsingle view or modality, and their direct visual matching strategy lacks\ninterpretability: they merely predict whether two images correspond, without\nexplaining the rationale behind the match. In this paper, we present GLEAM-C, a\nfoundational CVGL model that unifies multiple views and modalities-including\nUAV imagery, street maps, panoramic views, and ground photographs-by aligning\nthem exclusively with satellite imagery. Our framework enhances training\nefficiency through optimized implementation while achieving accuracy comparable\nto prior modality-specific CVGL models through a two-phase training strategy.\nMoreover, to address the lack of interpretability in traditional CVGL methods,\nwe leverage the reasoning capabilities of multimodal large language models\n(MLLMs) to propose a new task, GLEAM-X, which combines cross-view\ncorrespondence prediction with explainable reasoning. To support this task, we\nconstruct a bilingual benchmark using GPT-4o and Doubao-1.5-Thinking-Vision-Pro\nto generate training and testing data. The test set is further refined through\ndetailed human revision, enabling systematic evaluation of explainable\ncross-view reasoning and advancing transparency and scalability in\ngeo-localization. Together, GLEAM-C and GLEAM-X form a comprehensive CVGL\npipeline that integrates multi-modal, multi-view alignment with interpretable\ncorrespondence analysis, unifying accurate cross-view matching with explainable\nreasoning and advancing Geo-Localization by enabling models to better Explain\nAnd Match. Code and datasets used in this work will be made publicly accessible\nat https://github.com/Lucky-Lance/GLEAM.",
        "url": "http://arxiv.org/abs/2509.07450v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07450v1",
        "arxiv_id": "2509.07450v1",
        "authors": [
            "Xudong Lu",
            "Zhi Zheng",
            "Yi Wan",
            "Yongxiang Yao",
            "Annan Wang",
            "Renrui Zhang",
            "Panwang Xia",
            "Qiong Wu",
            "Qingyun Li",
            "Weifeng Lin",
            "Xiangyu Zhao",
            "Xue Yang",
            "Hongsheng Li"
        ],
        "submitted": "2025-09-09 07:14:31",
        "source": "arxiv",
        "comment": "18 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Cross-View Geo-Localization, which is not directly related to Information Retrieval or Search technologies. While it involves multimodal large language models, the primary application is geo-localization, and the paper's emphasis on explainability and interpretability does not align with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Language Self-Play For Data-Free Training",
        "abstract": "Large language models (LLMs) have advanced rapidly in recent years, driven by\nscale, abundant high-quality training data, and reinforcement learning. Yet\nthis progress faces a fundamental bottleneck: the need for ever more data from\nwhich models can continue to learn. In this work, we propose a reinforcement\nlearning approach that removes this dependency by enabling models to improve\nwithout additional data. Our method leverages a game-theoretic framework of\nself-play, where a model's capabilities are cast as performance in a\ncompetitive game and stronger policies emerge by having the model play against\nitself - a process we call Language Self-Play (LSP). Experiments with\nLlama-3.2-3B-Instruct on instruction-following benchmarks show that pretrained\nmodels can not only enhance their performance on challenging tasks through\nself-play alone, but can also do so more effectively than data-driven\nbaselines.",
        "url": "http://arxiv.org/abs/2509.07414v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07414v1",
        "arxiv_id": "2509.07414v1",
        "authors": [
            "Jakub Grudzien Kuba",
            "Mengting Gu",
            "Qi Ma",
            "Yuandong Tian",
            "Vijai Mohan"
        ],
        "submitted": "2025-09-09 05:51:34",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on language models and data-free training, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context is more on model training and improvement rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "The Role of Exploration Modules in Small Language Models for Knowledge Graph Question Answering",
        "abstract": "Integrating knowledge graphs (KGs) into the reasoning processes of large\nlanguage models (LLMs) has emerged as a promising approach to mitigate\nhallucination. However, existing work in this area often relies on proprietary\nor extremely large models, limiting accessibility and scalability. In this\nstudy, we investigate the capabilities of existing integration methods for\nsmall language models (SLMs) in KG-based question answering and observe that\ntheir performance is often constrained by their limited ability to traverse and\nreason over knowledge graphs. To address this limitation, we propose leveraging\nsimple and efficient exploration modules to handle knowledge graph traversal in\nplace of the language model itself. Experiment results demonstrate that these\nlightweight modules effectively improve the performance of small language\nmodels on knowledge graph question answering tasks. Source code:\nhttps://github.com/yijie-cheng/SLM-ToG/.",
        "url": "http://arxiv.org/abs/2509.07399v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07399v1",
        "arxiv_id": "2509.07399v1",
        "authors": [
            "Yi-Jie Cheng",
            "Oscar Chew",
            "Yun-Nung Chen"
        ],
        "submitted": "2025-09-09 05:26:29",
        "source": "arxiv",
        "comment": "Extended from ACL 2025 SRW",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on knowledge graph question answering and the integration of knowledge graphs with language models, which is not directly related to the user's core research themes in Information Retrieval and Search technologies. While it touches on the idea of improving model performance, it does not address query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's interests."
    },
    {
        "title": "Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents",
        "abstract": "Existing evaluation studies on linguistic competence of large language models\n(LLM agents) have focused primarily on vocabulary learning, morphological rule\ninduction, syntactic generalization, pragmatic inference, and cross-linguistic\ntransfer. However, none assess whether LLM agents can acquire a language\nthrough pattern recognition and interactive feedback, a central feature of\nhuman language acquisition. We propose a novel experimental framework in which\nan LLM agent is evaluated on its ability to acquire and use a newly constructed\nlanguage (Tinkatongue) in conversation with a bot that understands only\nTinkatongue. Our findings show that LLM agents fail to establish a conversation\nwithin 100 responses, yet they adopt distinct strategies that mirror human\napproaches to language learning. The results suggest a new direction for\nevaluation benchmarks and open pathways to model designs that learn more\neffectively from interactive feedback.",
        "url": "http://arxiv.org/abs/2509.07389v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07389v1",
        "arxiv_id": "2509.07389v1",
        "authors": [
            "Sankalp Tattwadarshi Swain",
            "Anshika Krishnatray",
            "Dhruv Kumar",
            "Jagat Sesh Challa"
        ],
        "submitted": "2025-09-09 05:09:27",
        "source": "arxiv",
        "comment": "Under review",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves large language models, the focus is on linguistic acquisition and language learning, which is not a central theme in your research."
    },
    {
        "title": "Datasets for Navigating Sensitive Topics in Recommendation Systems",
        "abstract": "Personalized AI systems, from recommendation systems to chatbots, are a\nprevalent method for distributing content to users based on their learned\npreferences. However, there is growing concern about the adverse effects of\nthese systems, including their potential tendency to expose users to sensitive\nor harmful material, negatively impacting overall well-being. To address this\nconcern quantitatively, it is necessary to create datasets with relevant\nsensitivity labels for content, enabling researchers to evaluate personalized\nsystems beyond mere engagement metrics. To this end, we introduce two novel\ndatasets that include a taxonomy of sensitivity labels alongside user-content\nratings: one that integrates MovieLens rating data with content warnings from\nthe Does the Dog Die? community ratings website, and another that combines\nfan-fiction interaction data and user-generated warnings from Archive of Our\nOwn.",
        "url": "http://arxiv.org/abs/2509.07269v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07269v1",
        "arxiv_id": "2509.07269v1",
        "authors": [
            "Amelia Kovacs",
            "Jerry Chee",
            "Kimia Kazemian",
            "Sarah Dean"
        ],
        "submitted": "2025-09-08 22:58:17",
        "source": "arxiv",
        "comment": "Companion Proceedings of the ACM on Web Conference 2025, 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, but it focuses on recommender systems and sensitive topic navigation, which is not the user's primary focus. The paper's emphasis on dataset creation and sensitivity labels is also somewhat tangential to the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Rule-Based Moral Principles for Explaining Uncertainty in Natural Language Generation",
        "abstract": "Large language models (LLMs) are increasingly used in high-stakes settings,\nwhere explaining uncertainty is both technical and ethical. Probabilistic\nmethods are often opaque and misaligned with expectations of transparency. We\npropose a framework based on rule-based moral principles for handling\nuncertainty in LLM-generated text. Using insights from moral psychology and\nvirtue ethics, we define rules such as precaution, deference, and\nresponsibility to guide responses under epistemic or aleatoric uncertainty.\nThese rules are encoded in a lightweight Prolog engine, where uncertainty\nlevels (low, medium, high) trigger aligned system actions with plain-language\nrationales. Scenario-based simulations benchmark rule coverage, fairness, and\ntrust calibration. Use cases in clinical and legal domains illustrate how moral\nreasoning can improve trust and interpretability. Our approach offers a\ntransparent, lightweight alternative to probabilistic models for socially\nresponsible natural language generation.",
        "url": "http://arxiv.org/abs/2509.07190v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07190v1",
        "arxiv_id": "2509.07190v1",
        "authors": [
            "Zahra Atf",
            "Peter R Lewis"
        ],
        "submitted": "2025-09-08 20:14:03",
        "source": "arxiv",
        "comment": "This paper was accepted for presentation at the 35th IEEE\n  International Conference on Collaborative Advances in Software and Computing.\n  Conference website:https://conf.researchr.org/home/cascon-2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Natural Language Generation and uncertainty explanation, which, while related to NLP, is not directly aligned with your core research interests in Information Retrieval, Search technologies, and query understanding."
    },
    {
        "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
        "abstract": "Discharge communication is a critical yet underexplored component of patient\ncare, where the goal shifts from diagnosis to education. While recent large\nlanguage model (LLM) benchmarks emphasize in-visit diagnostic reasoning, they\nfail to evaluate models' ability to support patients after the visit. We\nintroduce DischargeSim, a novel benchmark that evaluates LLMs on their ability\nto act as personalized discharge educators. DischargeSim simulates post-visit,\nmulti-turn conversations between LLM-driven DoctorAgents and PatientAgents with\ndiverse psychosocial profiles (e.g., health literacy, education, emotion).\nInteractions are structured across six clinically grounded discharge topics and\nassessed along three axes: (1) dialogue quality via automatic and LLM-as-judge\nevaluation, (2) personalized document generation including free-text summaries\nand structured AHRQ checklists, and (3) patient comprehension through a\ndownstream multiple-choice exam. Experiments across 18 LLMs reveal significant\ngaps in discharge education capability, with performance varying widely across\npatient profiles. Notably, model size does not always yield better education\noutcomes, highlighting trade-offs in strategy use and content prioritization.\nDischargeSim offers a first step toward benchmarking LLMs in post-visit\nclinical education and promoting equitable, personalized patient support.",
        "url": "http://arxiv.org/abs/2509.07188v2",
        "pdf_url": "http://arxiv.org/pdf/2509.07188v2",
        "arxiv_id": "2509.07188v2",
        "authors": [
            "Zonghai Yao",
            "Michael Sun",
            "Won Seok Jang",
            "Sunjae Kwon",
            "Soie Kwon",
            "Hong Yu"
        ],
        "submitted": "2025-09-08 20:07:30",
        "source": "arxiv",
        "comment": "Equal contribution for the first two authors. To appear in the\n  proceedings of the Main Conference on Empirical Methods in Natural Language\n  Processing (EMNLP) 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be primarily focused on evaluating large language models in the context of educational doctor-patient communication at discharge. While it touches on aspects of language understanding and generation, it does not directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "SciGPT: A Large Language Model for Scientific Literature Understanding and Knowledge Discovery",
        "abstract": "Scientific literature is growing exponentially, creating a critical\nbottleneck for researchers to efficiently synthesize knowledge. While\ngeneral-purpose Large Language Models (LLMs) show potential in text processing,\nthey often fail to capture scientific domain-specific nuances (e.g., technical\njargon, methodological rigor) and struggle with complex scientific tasks,\nlimiting their utility for interdisciplinary research. To address these gaps,\nthis paper presents SciGPT, a domain-adapted foundation model for scientific\nliterature understanding and ScienceBench, an open source benchmark tailored to\nevaluate scientific LLMs.\n  Built on the Qwen3 architecture, SciGPT incorporates three key innovations:\n(1) low-cost domain distillation via a two-stage pipeline to balance\nperformance and efficiency; (2) a Sparse Mixture-of-Experts (SMoE) attention\nmechanism that cuts memory consumption by 55\\% for 32,000-token long-document\nreasoning; and (3) knowledge-aware adaptation integrating domain ontologies to\nbridge interdisciplinary knowledge gaps.\n  Experimental results on ScienceBench show that SciGPT outperforms GPT-4o in\ncore scientific tasks including sequence labeling, generation, and inference.\nIt also exhibits strong robustness in unseen scientific tasks, validating its\npotential to facilitate AI-augmented scientific discovery.",
        "url": "http://arxiv.org/abs/2509.08032v1",
        "pdf_url": "http://arxiv.org/pdf/2509.08032v1",
        "arxiv_id": "2509.08032v1",
        "authors": [
            "Fengyu She",
            "Nan Wang",
            "Hongfei Wu",
            "Ziyi Wan",
            "Jingmian Wang",
            "Chang Wang"
        ],
        "submitted": "2025-09-09 16:09:19",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper presents a large language model, SciGPT, specifically designed for scientific literature understanding and knowledge discovery. While not directly focused on information retrieval or search technologies, it aligns with your interests in NLP and deep semantic understanding. The model's innovations and experimental results demonstrate its potential to facilitate AI-augmented scientific discovery."
    },
    {
        "title": "Are Humans as Brittle as Large Language Models?",
        "abstract": "The output of large language models (LLM) is unstable, due to both\nnon-determinism of the decoding process as well as to prompt brittleness. While\nthe intrinsic non-determinism of LLM generation may mimic existing uncertainty\nin human annotations through distributional shifts in outputs, it is largely\nassumed, yet unexplored, that the prompt brittleness effect is unique to LLMs.\nThis raises the question: do human annotators show similar sensitivity to\ninstruction changes? If so, should prompt brittleness in LLMs be considered\nproblematic? One may alternatively hypothesize that prompt brittleness\ncorrectly reflects human annotation variances. To fill this research gap, we\nsystematically compare the effects of prompt modifications on LLMs and\nidentical instruction modifications for human annotators, focusing on the\nquestion of whether humans are similarly sensitive to prompt perturbations. To\nstudy this, we prompt both humans and LLMs for a set of text classification\ntasks conditioned on prompt variations. Our findings indicate that both humans\nand LLMs exhibit increased brittleness in response to specific types of prompt\nmodifications, particularly those involving the substitution of alternative\nlabel sets or label formats. However, the distribution of human judgments is\nless affected by typographical errors and reversed label order than that of\nLLMs.",
        "url": "http://arxiv.org/abs/2509.07869v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07869v1",
        "arxiv_id": "2509.07869v1",
        "authors": [
            "Jiahui Li",
            "Sean Papay",
            "Roman Klinger"
        ],
        "submitted": "2025-09-09 15:56:51",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper explores the brittleness of large language models and human annotators in response to prompt modifications, which is a topic in NLP. However, it does not directly relate to information retrieval, query understanding, ranking models, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "Small Open Models Achieve Near Parity with Large Models in Low Resource Literary Translation at a Fraction of the Cost",
        "abstract": "Literary translation has recently gained attention as a distinct and complex\ntask in machine translation research. However, the translation by small open\nmodels remains an open problem. We contribute to this ongoing research by\nintroducing TINYFABULIST TRANSLATION FRAMEWORK (TF2), a unified framework for\ndataset creation, fine tuning, and evaluation in English-Romanian literary\ntranslations, centred on the creation and open release of both a compact, fine\ntuned language model (TF2-12B) and large scale synthetic parallel datasets\n(DS-TF2-EN-RO-3M and DS-TF2-EN-RO-15K). Building on DS-TF1-EN-3M (TF1), the\nlargest collection of synthetic English fables to date, we address the need for\nrich, high quality literary datasets in low resource languages such as\nRomanian. Our pipeline first generates 15k high quality Romanian references\nfrom the TF1 pool using a high performing LLM. We then apply a two stage fine\ntuning process to a 12B parameter open weight model: (i) instruction tuning to\ncapture genre specific narrative style, and (ii) adapter compression for\nefficient deployment. Evaluation combines corpus level BLEU and a five\ndimension LLM based rubric (accuracy, fluency, coherence, style, cultural\nadaptation) to provide a nuanced assessment of translation quality. Results\nshow that our fine tuned model achieves fluency and adequacy competitive with\ntop performing large proprietary models, while being open, accessible, and\nsignificantly more cost effective. Alongside the fine tuned model and both\ndatasets, we publicly release all scripts and evaluation prompts. TF2 thus\nprovides an end-to-end, reproducible pipeline for research on cost efficient\ntranslation, cross lingual narrative generation, and the broad adoption of open\nmodels for culturally significant literary content in low resource settings.",
        "url": "http://arxiv.org/abs/2509.07829v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07829v1",
        "arxiv_id": "2509.07829v1",
        "authors": [
            "Mihai Nadas",
            "Laura Diosan",
            "Andreea Tomescu",
            "Andrei Piscoran"
        ],
        "submitted": "2025-09-09 15:07:14",
        "source": "arxiv",
        "comment": "25 pages, 8 figures, includes datasets and models released on Hugging\n  Face",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on machine translation, specifically in low resource languages, and does not directly relate to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing, particularly in areas requiring deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Understanding Stigmatizing Language Lexicons: A Comparative Analysis in Clinical Contexts",
        "abstract": "Stigmatizing language results in healthcare inequities, yet there is no\nuniversally accepted or standardized lexicon defining which words, terms, or\nphrases constitute stigmatizing language in healthcare. We conducted a\nsystematic search of the literature to identify existing stigmatizing language\nlexicons and then analyzed them comparatively to examine: 1) similarities and\ndiscrepancies between these lexicons, and 2) the distribution of positive,\nnegative, or neutral terms based on an established sentiment dataset. Our\nsearch identified four lexicons. The analysis results revealed moderate\nsemantic similarity among them, and that most stigmatizing terms are related to\njudgmental expressions by clinicians to describe perceived negative behaviors.\nSentiment analysis showed a predominant proportion of negatively classified\nterms, though variations exist across lexicons. Our findings underscore the\nneed for a standardized lexicon and highlight challenges in defining\nstigmatizing language in clinical texts.",
        "url": "http://arxiv.org/abs/2509.07462v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07462v1",
        "arxiv_id": "2509.07462v1",
        "authors": [
            "Yiliang Zhou",
            "Di Hu",
            "Tianchu Lyu",
            "Jasmine Dhillon",
            "Alexandra L. Beck",
            "Gelareh Sadigh",
            "Kai Zheng"
        ],
        "submitted": "2025-09-09 07:41:20",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing, as it focuses on stigmatizing language lexicons in clinical contexts, which does not align with your areas of expertise."
    },
    {
        "title": "MEGG: Replay via Maximally Extreme GGscore in Incremental Learning for Neural Recommendation Models",
        "abstract": "Neural Collaborative Filtering models are widely used in recommender systems\nbut are typically trained under static settings, assuming fixed data\ndistributions. This limits their applicability in dynamic environments where\nuser preferences evolve. Incremental learning offers a promising solution, yet\nconventional methods from computer vision or NLP face challenges in\nrecommendation tasks due to data sparsity and distinct task paradigms. Existing\napproaches for neural recommenders remain limited and often lack\ngeneralizability. To address this, we propose MEGG, Replay Samples with\nMaximally Extreme GGscore, an experience replay based incremental learning\nframework. MEGG introduces GGscore, a novel metric that quantifies sample\ninfluence, enabling the selective replay of highly influential samples to\nmitigate catastrophic forgetting. Being model-agnostic, MEGG integrates\nseamlessly across architectures and frameworks. Experiments on three neural\nmodels and four benchmark datasets show superior performance over\nstate-of-the-art baselines, with strong scalability, efficiency, and\nrobustness. Implementation will be released publicly upon acceptance.",
        "url": "http://arxiv.org/abs/2509.07319v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07319v1",
        "arxiv_id": "2509.07319v1",
        "authors": [
            "Yunxiao Shi",
            "Shuo Yang",
            "Haimin Zhang",
            "Li Wang",
            "Yongze Wang",
            "Qiang Wu",
            "Min Xu"
        ],
        "submitted": "2025-09-09 01:35:51",
        "source": "arxiv",
        "comment": "Accepted by Data Mining and Knowledge Discovery (DMKD) in Sep 2025",
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on recommender systems and incremental learning, which is somewhat related to your interests in Information Retrieval and Search technologies. However, it does not align with your core research themes, particularly query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "LLM Analysis of 150+ years of German Parliamentary Debates on Migration Reveals Shift from Post-War Solidarity to Anti-Solidarity in the Last Decade",
        "abstract": "Migration has been a core topic in German political debate, from millions of\nexpellees post World War II over labor migration to refugee movements in the\nrecent past. Studying political speech regarding such wide-ranging phenomena in\ndepth traditionally required extensive manual annotations, limiting the scope\nof analysis to small subsets of the data. Large language models (LLMs) have the\npotential to partially automate even complex annotation tasks. We provide an\nextensive evaluation of a multiple LLMs in annotating (anti-)solidarity\nsubtypes in German parliamentary debates compared to a large set of thousands\nof human reference annotations (gathered over a year). We evaluate the\ninfluence of model size, prompting differences, fine-tuning, historical versus\ncontemporary data; and we investigate systematic errors. Beyond methodological\nevaluation, we also interpret the resulting annotations from a social science\nlense, gaining deeper insight into (anti-)solidarity trends towards migrants in\nthe German post-World War II period and recent past. Our data reveals a high\ndegree of migrant-directed solidarity in the postwar period, as well as a\nstrong trend towards anti-solidarity in the German parliament since 2015,\nmotivating further research. These findings highlight the promise of LLMs for\npolitical text analysis and the importance of migration debates in Germany,\nwhere demographic decline and labor shortages coexist with rising polarization.",
        "url": "http://arxiv.org/abs/2509.07274v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07274v1",
        "arxiv_id": "2509.07274v1",
        "authors": [
            "Aida Kostikova",
            "Ole Pütz",
            "Steffen Eger",
            "Olga Sabelfeld",
            "Benjamin Paassen"
        ],
        "submitted": "2025-09-08 23:16:03",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing, as it focuses on political text analysis and social science interpretation of large language models in the context of migration debates in Germany."
    }
]