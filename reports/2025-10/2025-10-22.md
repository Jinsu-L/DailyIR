# Daily Papers Report - 2025-10-22

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. LLMs as Sparse Retrievers:A Framework for First-Stage Product Search

- **LLM Score**: 8
- **Keyword Score**: 19
- **Authors**: Hongru Song, Yu-an Liu, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Sen Li, Wenjun Peng, Fuyu Lv, Xueqi Cheng
- **URL**: <http://arxiv.org/abs/2510.18527v2>
- **Submitted**: 2025-10-21 11:13:21
- **Comment**: 16 pages
- **Topic Keywords**: retriever, sparse retrieval, queries, ltr, rag, retrieval, commerce, e-commerce, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of e-commerce product search. The proposed framework, PROSPER, addresses challenges in sparse retrieval and leverages large language models for semantic analysis, which aligns with your focus on deep semantic understanding and real-time relevance optimization.

#### Abstract
> Product search is a crucial component of modern e-commerce platforms, with
billions of user queries every day. In product search systems, first-stage
retrieval should achieve high recall while ensuring efficient online
deployment. Sparse retrieval is particularly attractive in this context due to
its interpretability and storage efficiency. However, sparse retrieval methods
suffer from severe vocabulary mismatch issues, leading to suboptimal
performance in product search scenarios. With their potential for semantic
analysis, large language models (LLMs) offer a promising avenue for mitigating
vocabulary mismatch issues and thereby improving retrieval quality. Directly
applying LLMs to sparse retrieval in product search exposes two key
challenges:(1)Queries and product titles are typically short and highly
susceptible to LLM-induced hallucinations, such as generating irrelevant
expansion terms or underweighting critical literal terms like brand names and
model numbers;(2)The large vocabulary space of LLMs leads to difficulty in
initializing training effectively, making it challenging to learn meaningful
sparse representations in such ultra-high-dimensional spaces.To address these
challenges, we propose PROSPER, a framework for PROduct search leveraging LLMs
as SParsE Retrievers. PROSPER incorporates: (1)A literal residual network that
alleviates hallucination in lexical expansion by reinforcing underweighted
literal terms through a residual compensation mechanism; and (2)A lexical
focusing window that facilitates effective training initialization via a
coarse-to-fine sparsification strategy.Extensive offline and online experiments
show that PROSPER significantly outperforms sparse baselines and achieves
recall performance comparable to advanced dense retrievers, while also
achieving revenue increments online.

---

### 2. WebSeer: Training Deeper Search Agents through Reinforcement Learning with Self-Reflection

- **LLM Score**: 8
- **Keyword Score**: 6
- **Authors**: Guanzhong He, Zhen Yang, Jinxin Liu, Bin Xu, Lei Hou, Juanzi Li
- **URL**: <http://arxiv.org/abs/2510.18798v1>
- **Submitted**: 2025-10-21 16:52:00
- **Topic Keywords**: information retrieval, retrieval, search
- **Reason**: This paper presents a novel approach to training search agents using reinforcement learning with self-reflection, which aligns with your interests in query understanding, ranking models, and user behavior modeling. The focus on real-world web-based environments and the use of a large annotated dataset also resonate with your background in e-commerce and NLP. However, the specific application to search agents and the emphasis on tool-use trajectories may not be directly related to your core research themes.

#### Abstract
> Search agents have achieved significant advancements in enabling intelligent
information retrieval and decision-making within interactive environments.
Although reinforcement learning has been employed to train agentic models
capable of more dynamic interactive retrieval, existing methods are limited by
shallow tool-use depth and the accumulation of errors over multiple iterative
interactions. In this paper, we present WebSeer, a more intelligent search
agent trained via reinforcement learning enhanced with a self-reflection
mechanism. Specifically, we construct a large dataset annotated with reflection
patterns and design a two-stage training framework that unifies cold start and
reinforcement learning within the self-reflection paradigm for real-world
web-based environments, which enables the model to generate longer and more
reflective tool-use trajectories. Our approach substantially extends tool-use
chains and improves answer accuracy. Using a single 14B model, we achieve
state-of-the-art results on HotpotQA and SimpleQA, with accuracies of 72.3% and
90.0%, respectively, and demonstrate strong generalization to
out-of-distribution datasets. The code is available at
https://github.com/99hgz/WebSeer

---

### 3. Evaluating LLM-Based Mobile App Recommendations: An Empirical Study

- **LLM Score**: 6
- **Keyword Score**: 8
- **Authors**: Quim Motger, Xavier Franch, Vincenzo Gervasi, Jordi Marco
- **URL**: <http://arxiv.org/abs/2510.18364v1>
- **Submitted**: 2025-10-21 07:35:19
- **Comment**: Under review
- **Topic Keywords**: ranking, rag, recommend, rank, search
- **Reason**: This paper explores the use of Large Language Models (LLMs) in mobile app recommendations, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the focus on recommender systems and conversational app discovery is not a central match to your primary research themes, which include query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large Language Models (LLMs) are increasingly used to recommend mobile
applications through natural language prompts, offering a flexible alternative
to keyword-based app store search. Yet, the reasoning behind these
recommendations remains opaque, raising questions about their consistency,
explainability, and alignment with traditional App Store Optimization (ASO)
metrics. In this paper, we present an empirical analysis of how widely-used
general purpose LLMs generate, justify, and rank mobile app recommendations.
Our contributions are: (i) a taxonomy of 16 generalizable ranking criteria
elicited from LLM outputs; (ii) a systematic evaluation framework to analyse
recommendation consistency and responsiveness to explicit ranking instructions;
and (iii) a replication package to support reproducibility and future research
on AI-based recommendation systems. Our findings reveal that LLMs rely on a
broad yet fragmented set of ranking criteria, only partially aligned with
standard ASO metrics. While top-ranked apps tend to be consistent across runs,
variability increases with ranking depth and search specificity. LLMs exhibit
varying sensitivity to explicit ranking instructions - ranging from substantial
adaptations to near-identical outputs - highlighting their complex reasoning
dynamics in conversational app discovery. Our results aim to support end-users,
app developers, and recommender-systems researchers in navigating the emerging
landscape of conversational app discovery.

---

### 4. Automatic Prompt Generation via Adaptive Selection of Prompting Techniques

- **LLM Score**: 6
- **Keyword Score**: 3
- **Authors**: Yohei Ikenoue, Hitomi Tashiro, Shigeru Kuroyanagi
- **URL**: <http://arxiv.org/abs/2510.18162v1>
- **Submitted**: 2025-10-20 23:28:23
- **Comment**: 35 pages, 29 figures, 5 tables
- **Topic Keywords**: rag, search
- **Reason**: This paper explores automatic prompt generation for large language models, which is related to query understanding and ranking models in Information Retrieval. However, the focus on NLP and prompt engineering is somewhat tangential to the user's core research themes, which are more centered around search technologies and user behavior modeling.

#### Abstract
> Prompt engineering is crucial for achieving reliable and effective outputs
from large language models (LLMs), but its design requires specialized
knowledge of prompting techniques and a deep understanding of target tasks. To
address this challenge, we propose a novel method that adaptively selects
task-appropriate prompting techniques based on users' abstract task
descriptions and automatically generates high-quality prompts without relying
on pre-existing templates or frameworks. The proposed method constructs a
knowledge base that associates task clusters, characterized by semantic
similarity across diverse tasks, with their corresponding prompting techniques.
When users input task descriptions, the system assigns them to the most
relevant task cluster and dynamically generates prompts by integrating
techniques drawn from the knowledge base. An experimental evaluation of the
proposed method on 23 tasks from BIG-Bench Extra Hard (BBEH) demonstrates
superior performance compared with standard prompts and existing automatic
prompt-generation tools, as measured by both arithmetic and harmonic mean
scores. This research establishes a foundation for streamlining and
standardizing prompt creation, enabling non-experts to effectively leverage
LLMs.

---

### 5. ECG-LLM -- training and evaluation of domain-specific large language models for electrocardiography

- **LLM Score**: 4
- **Keyword Score**: 16
- **Authors**: Lara Ahrens, Wilhelm Haverkamp, Nils Strodthoff
- **URL**: <http://arxiv.org/abs/2510.18339v1>
- **Submitted**: 2025-10-21 06:45:38
- **Comment**: 34 pages, 8 figures, code available at
  https://github.com/AI4HealthUOL/ecg-llm
- **Topic Keywords**: query, queries, ranking, rag, ctr, retrieval, rank
- **Reason**: The paper explores the application of large language models in electrocardiography, which is a domain-specific area. While it touches on aspects of query understanding and model evaluation, it is primarily focused on NLP and not directly related to the user's core research themes in Information Retrieval and Search technologies. The paper's relevance to the user's interests is somewhat limited.

#### Abstract
> Domain-adapted open-weight large language models (LLMs) offer promising
healthcare applications, from queryable knowledge bases to multimodal
assistants, with the crucial advantage of local deployment for privacy
preservation. However, optimal adaptation strategies, evaluation methodologies,
and performance relative to general-purpose LLMs remain poorly characterized.
We investigated these questions in electrocardiography, an important area of
cardiovascular medicine, by finetuning open-weight models on domain-specific
literature and implementing a multi-layered evaluation framework comparing
finetuned models, retrieval-augmented generation (RAG), and Claude Sonnet 3.7
as a representative general-purpose model. Finetuned Llama 3.1 70B achieved
superior performance on multiple-choice evaluations and automatic text metrics,
ranking second to Claude 3.7 in LLM-as-a-judge assessments. Human expert
evaluation favored Claude 3.7 and RAG approaches for complex queries. Finetuned
models significantly outperformed their base counterparts across nearly all
evaluation modes. Our findings reveal substantial performance heterogeneity
across evaluation methodologies, underscoring assessment complexity.
Nevertheless, domain-specific adaptation through finetuning and RAG achieves
competitive performance with proprietary models, supporting the viability of
privacy-preserving, locally deployable clinical solutions.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. KrishokBondhu: A Retrieval-Augmented Voice-Based Agricultural Advisory Call Center for Bengali Farmers

- **LLM Score**: 4
- **Keyword Score**: 13
- **Authors**: Mohd Ruhul Ameen, Akif Islam, Farjana Aktar, M. Saifuzzaman Rafat
- **URL**: <http://arxiv.org/abs/2510.18355v1>
- **Submitted**: 2025-10-21 07:24:55
- **Comment**: 6 pages, 7 figures, 5 tables, submitted to the 11th IEEE
  International Women in Engineering (WIE) Conference on Electrical and
  Computer Engineering (WIECON-ECE 2025)
- **Topic Keywords**: query, queries, relevance, rag, retrieval
- **Reason**: The paper presents a voice-based agricultural advisory call center, leveraging Retrieval-Augmented Generation (RAG) and semantic retrieval techniques. While it aligns with some aspects of Information Retrieval and NLP, the focus on agricultural guidance and multilingual voice interaction is somewhat niche and not directly related to the user's core research themes.

#### Abstract
> In Bangladesh, many farmers continue to face challenges in accessing timely,
expert-level agricultural guidance. This paper presents KrishokBondhu, a
voice-enabled, call-centre-integrated advisory platform built on a
Retrieval-Augmented Generation (RAG) framework, designed specifically for
Bengali-speaking farmers. The system aggregates authoritative agricultural
handbooks, extension manuals, and NGO publications; applies Optical Character
Recognition (OCR) and document-parsing pipelines to digitize and structure the
content; and indexes this corpus in a vector database for efficient semantic
retrieval. Through a simple phone-based interface, farmers can call the system
to receive real-time, context-aware advice: speech-to-text converts the Bengali
query, the RAG module retrieves relevant content, a large language model (Gemma
3-4B) generates a context-grounded response, and text-to-speech delivers the
answer in natural spoken Bengali. In a pilot evaluation, KrishokBondhu produced
high-quality responses for 72.7% of diverse agricultural queries covering crop
management, disease control, and cultivation practices. Compared to the
KisanQRS benchmark, the system achieved a composite score of 4.53 (vs. 3.13) on
a 5-point scale, a 44.7% improvement, with especially large gains in contextual
richness (+367%) and completeness (+100.4%), while maintaining comparable
relevance and technical specificity. Semantic similarity analysis further
revealed a strong correlation between retrieved context and answer quality,
emphasizing the importance of grounding generative responses in curated
documentation. KrishokBondhu demonstrates the feasibility of integrating
call-centre accessibility, multilingual voice interaction, and modern RAG
techniques to deliver expert-level agricultural guidance to remote Bangladeshi
farmers, paving the way toward a fully AI-driven agricultural advisory
ecosystem.

### 7. IMB: An Italian Medical Benchmark for Question Answering

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Antonio Romano, Giuseppe Riccio, Mariano Barone, Marco Postiglione, Vincenzo Moscato
- **URL**: <http://arxiv.org/abs/2510.18468v1>
- **Submitted**: 2025-10-21 09:45:59
- **Topic Keywords**: information retrieval, rag, retrieval augmented generation, retrieval, search
- **Reason**: The paper is somewhat related to the user's interests in Information Retrieval, particularly in the context of question answering and medical domains. However, the focus on question answering and the medical domain is not a central match with the user's primary research themes, which include query understanding, ranking models, and user behavior modeling.

#### Abstract
> Online medical forums have long served as vital platforms where patients seek
professional healthcare advice, generating vast amounts of valuable knowledge.
However, the informal nature and linguistic complexity of forum interactions
pose significant challenges for automated question answering systems,
especially when dealing with non-English languages. We present two
comprehensive Italian medical benchmarks: \textbf{IMB-QA}, containing 782,644
patient-doctor conversations from 77 medical categories, and \textbf{IMB-MCQA},
comprising 25,862 multiple-choice questions from medical specialty
examinations. We demonstrate how Large Language Models (LLMs) can be leveraged
to improve the clarity and consistency of medical forum data while retaining
their original meaning and conversational style, and compare a variety of LLM
architectures on both open and multiple-choice question answering tasks. Our
experiments with Retrieval Augmented Generation (RAG) and domain-specific
fine-tuning reveal that specialized adaptation strategies can outperform
larger, general-purpose models in medical question answering tasks. These
findings suggest that effective medical AI systems may benefit more from domain
expertise and efficient information retrieval than from increased model scale.
We release both datasets and evaluation frameworks in our GitHub repository to
support further research on multilingual medical question answering:
https://github.com/PRAISELab-PicusLab/IMB.

### 8. ChronoPlay: A Framework for Modeling Dual Dynamics and Authenticity in Game RAG Benchmarks

- **LLM Score**: 4
- **Keyword Score**: 9
- **Authors**: Liyang He, Yuren Zhang, Ziwei Zhu, Zhenghui Li, Shiwei Tong
- **URL**: <http://arxiv.org/abs/2510.18455v1>
- **Submitted**: 2025-10-21 09:28:13
- **Topic Keywords**: query, rag, retrieval augmented generation, retrieval
- **Reason**: This paper is somewhat related to information retrieval, specifically in the context of Retrieval Augmented Generation (RAG) systems, but its focus on game RAG benchmarks and dual dynamics is not directly aligned with the user's core research themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> Retrieval Augmented Generation (RAG) systems are increasingly vital in
dynamic domains like online gaming, yet the lack of a dedicated benchmark has
impeded standardized evaluation in this area. The core difficulty lies in Dual
Dynamics: the constant interplay between game content updates and the shifting
focus of the player community. Furthermore, the necessity of automating such a
benchmark introduces a critical requirement for player-centric authenticity to
ensure generated questions are realistic. To address this integrated challenge,
we introduce ChronoPlay, a novel framework for the automated and continuous
generation of game RAG benchmarks. ChronoPlay utilizes a dual-dynamic update
mechanism to track both forms of change, and a dual-source synthesis engine
that draws from official sources and player community to ensure both factual
correctness and authentic query patterns. We instantiate our framework on three
distinct games to create the first dynamic RAG benchmark for the gaming domain,
offering new insights into model performance under these complex and realistic
conditions. Code is avaliable at: https://github.com/hly1998/ChronoPlay.

### 9. Food4All: A Multi-Agent Framework for Real-time Free Food Discovery with Integrated Nutritional Metadata

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Zhengqing Yuan, Yiyang Li, Weixiang Sun, Zheyuan Zhang, Kaiwen Shi, Keerthiram Murugesan, Yanfang Ye
- **URL**: <http://arxiv.org/abs/2510.18289v1>
- **Submitted**: 2025-10-21 04:35:02
- **Topic Keywords**: rag, retrieval, recommend, search
- **Reason**: The paper focuses on real-time free food discovery, which is somewhat related to information retrieval and search technologies. However, the primary emphasis on addressing food insecurity and using multi-agent frameworks, reinforcement learning, and data aggregation from various sources makes it less directly relevant to the user's core research themes in IR and NLP.

#### Abstract
> Food insecurity remains a persistent public health emergency in the United
States, tightly interwoven with chronic disease, mental illness, and opioid
misuse. Yet despite the existence of thousands of food banks and pantries,
access remains fragmented: 1) current retrieval systems depend on static
directories or generic search engines, which provide incomplete and
geographically irrelevant results; 2) LLM-based chatbots offer only vague
nutritional suggestions and fail to adapt to real-world constraints such as
time, mobility, and transportation; and 3) existing food recommendation systems
optimize for culinary diversity but overlook survival-critical needs of
food-insecure populations, including immediate proximity, verified
availability, and contextual barriers. These limitations risk leaving the most
vulnerable individuals, those experiencing homelessness, addiction, or digital
illiteracy, unable to access urgently needed resources. To address this, we
introduce Food4All, the first multi-agent framework explicitly designed for
real-time, context-aware free food retrieval. Food4All unifies three
innovations: 1) heterogeneous data aggregation across official databases,
community platforms, and social media to provide a continuously updated pool of
food resources; 2) a lightweight reinforcement learning algorithm trained on
curated cases to optimize for both geographic accessibility and nutritional
correctness; and 3) an online feedback loop that dynamically adapts retrieval
policies to evolving user needs. By bridging information acquisition, semantic
analysis, and decision support, Food4All delivers nutritionally annotated and
guidance at the point of need. This framework establishes an urgent step toward
scalable, equitable, and intelligent systems that directly support populations
facing food insecurity and its compounding health risks.

### 10. Investigating LLM Capabilities on Long Context Comprehension for Medical Question Answering

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Feras AlMannaa, Talia Tseriotou, Jenny Chim, Maria Liakata
- **URL**: <http://arxiv.org/abs/2510.18691v1>
- **Submitted**: 2025-10-21 14:50:24
- **Topic Keywords**: relevance, rag
- **Reason**: The paper explores the capabilities of Large Language Models (LLMs) in medical question answering, which is somewhat related to the user's interests in Information Retrieval and Natural Language Processing. However, the focus on question answering and medical domain is not a central match to the user's primary research themes, which include query understanding, ranking models, and user behavior modeling.

#### Abstract
> This study is the first to investigate LLM comprehension capabilities over
long-context (LC) medical QA of clinical relevance. Our comprehensive
assessment spans a range of content-inclusion settings based on their
relevance, LLM models of varying capabilities and datasets across task
formulations, revealing insights on model size effects, limitations, underlying
memorization issues and the benefits of reasoning models. Importantly, we
examine the effect of RAG on medical LC comprehension, uncover best settings in
single versus multi-document reasoning datasets and showcase RAG strategies for
improvements over LC. We shed light into some of the evaluation aspects using a
multi-faceted approach. Our qualitative and error analyses address open
questions on when RAG is beneficial over LC, revealing common failure cases.

### 11. Enhancing Hotel Recommendations with AI: LLM-Based Review Summarization and Query-Driven Insights

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Nikolaos Belibasakis, Anastasios Giannaros, Ioanna Giannoukou, Spyros Sioutas
- **URL**: <http://arxiv.org/abs/2510.18277v1>
- **Submitted**: 2025-10-21 04:02:51
- **Topic Keywords**: query, recommend, search
- **Reason**: The paper explores the application of Large Language Models (LLMs) in summarizing user reviews for hotel recommendations, which is somewhat related to information retrieval and query understanding. However, the focus on recommender systems and user reviews is not a central match for your primary research interests in IR, ranking models, and user behavior modeling.

#### Abstract
> The increasing number of data a booking platform such as Booking.com and
AirBnB offers make it challenging for interested parties to browse through the
available accommodations and analyze reviews in an efficient way. Efforts have
been made from the booking platform providers to utilize recommender systems in
an effort to enable the user to filter the results by factors such as stars,
amenities, cost but most valuable insights can be provided by the unstructured
text-based reviews. Going through these reviews one-by-one requires a
substantial amount of time to be devoted while a respectable percentage of the
reviews won't provide to the user what they are actually looking for.
  This research publication explores how Large Language Models (LLMs) can
enhance short rental apartments recommendations by summarizing and mining key
insights from user reviews. The web application presented in this paper, named
"instaGuide", automates the procedure of isolating the text-based user reviews
from a property on the Booking.com platform, synthesizing the summary of the
reviews, and enabling the user to query specific aspects of the property in an
effort to gain feedback on their personal questions/criteria.
  During the development of the instaGuide tool, numerous LLM models were
evaluated based on accuracy, cost, and response quality. The results suggest
that the LLM-powered summarization reduces significantly the amount of time the
users need to devote on their search for the right short rental apartment,
improving the overall decision-making procedure.

### 12. Zero-Shot Vehicle Model Recognition via Text-Based Retrieval-Augmented Generation

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Wei-Chia Chang, Yan-Ann Chen
- **URL**: <http://arxiv.org/abs/2510.18502v1>
- **Submitted**: 2025-10-21 10:39:39
- **Comment**: Accepted by The 38th Conference of Open Innovations Association
  FRUCT, 2025
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper explores a novel application of Retrieval-Augmented Generation (RAG) in zero-shot vehicle model recognition. While it leverages vision-language models and text-based reasoning, its focus on vehicle make and model recognition is somewhat tangential to the user's core research interests in Information Retrieval and Search technologies. The paper's emphasis on scalable VMMR in smart-city applications also hints at a broader interest in real-world applications, but it does not directly align with the user's primary focus on deep semantic understanding and real-time relevance optimization.

#### Abstract
> Vehicle make and model recognition (VMMR) is an important task in intelligent
transportation systems, but existing approaches struggle to adapt to newly
released models. Contrastive Language-Image Pretraining (CLIP) provides strong
visual-text alignment, yet its fixed pretrained weights limit performance
without costly image-specific finetuning. We propose a pipeline that integrates
vision language models (VLMs) with Retrieval-Augmented Generation (RAG) to
support zero-shot recognition through text-based reasoning. A VLM converts
vehicle images into descriptive attributes, which are compared against a
database of textual features. Relevant entries are retrieved and combined with
the description to form a prompt, and a language model (LM) infers the make and
model. This design avoids large-scale retraining and enables rapid updates by
adding textual descriptions of new vehicles. Experiments show that the proposed
method improves recognition by nearly 20% over the CLIP baseline, demonstrating
the potential of RAG-enhanced LM reasoning for scalable VMMR in smart-city
applications.

### 13. Combining Distantly Supervised Models with In Context Learning for Monolingual and Cross-Lingual Relation Extraction

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Vipul Rathore, Malik Hammad Faisal, Parag Singla, Mausam
- **URL**: <http://arxiv.org/abs/2510.18344v1>
- **Submitted**: 2025-10-21 06:55:19
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and data mining, but it does not directly align with their primary focus on Information Retrieval (IR), query understanding, or ranking models. The paper's focus on relation extraction and distant supervision is tangentially related to the user's interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> Distantly Supervised Relation Extraction (DSRE) remains a long-standing
challenge in NLP, where models must learn from noisy bag-level annotations
while making sentence-level predictions. While existing state-of-the-art (SoTA)
DSRE models rely on task-specific training, their integration with in-context
learning (ICL) using large language models (LLMs) remains underexplored. A key
challenge is that the LLM may not learn relation semantics correctly, due to
noisy annotation.
  In response, we propose HYDRE -- HYbrid Distantly Supervised Relation
Extraction framework. It first uses a trained DSRE model to identify the top-k
candidate relations for a given test sentence, then uses a novel dynamic
exemplar retrieval strategy that extracts reliable, sentence-level exemplars
from training data, which are then provided in LLM prompt for outputting the
final relation(s).
  We further extend HYDRE to cross-lingual settings for RE in low-resource
languages. Using available English DSRE training data, we evaluate all methods
on English as well as a newly curated benchmark covering four diverse
low-resource Indic languages -- Oriya, Santali, Manipuri, and Tulu. HYDRE
achieves up to 20 F1 point gains in English and, on average, 17 F1 points on
Indic languages over prior SoTA DSRE models. Detailed ablations exhibit HYDRE's
efficacy compared to other prompting strategies.

### 14. From Retrieval to Generation: Unifying External and Parametric Knowledge for Medical Question Answering

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Lei Li, Xiao Zhou, Yingying Zhang, Xian Wu
- **URL**: <http://arxiv.org/abs/2510.18297v1>
- **Submitted**: 2025-10-21 04:58:29
- **Comment**: 13 pages, 4 figures
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper explores a unified framework for medical question answering, combining retrieval and generation. While it touches on knowledge retrieval and generation, which are related to information retrieval, the focus is on question answering and knowledge-intensive reasoning, which is somewhat relevant to your interests but not a central match.

#### Abstract
> Medical question answering (QA) requires extensive access to domain-specific
knowledge. A promising direction is to enhance large language models (LLMs)
with external knowledge retrieved from medical corpora or parametric knowledge
stored in model parameters. Existing approaches typically fall into two
categories: Retrieval-Augmented Generation (RAG), which grounds model reasoning
on externally retrieved evidence, and Generation-Augmented Generation (GAG),
which depends solely on the models internal knowledge to generate contextual
documents. However, RAG often suffers from noisy or incomplete retrieval, while
GAG is vulnerable to hallucinated or inaccurate information due to
unconstrained generation. Both issues can mislead reasoning and undermine
answer reliability. To address these challenges, we propose MedRGAG, a unified
retrieval-generation augmented framework that seamlessly integrates external
and parametric knowledge for medical QA. MedRGAG comprises two key modules:
Knowledge-Guided Context Completion (KGCC), which directs the generator to
produce background documents that complement the missing knowledge revealed by
retrieval; and Knowledge-Aware Document Selection (KADS), which adaptively
selects an optimal combination of retrieved and generated documents to form
concise yet comprehensive evidence for answer generation. Extensive experiments
on five medical QA benchmarks demonstrate that MedRGAG achieves a 12.5%
improvement over MedRAG and a 4.5% gain over MedGENIE, highlighting the
effectiveness of unifying retrieval and generation for knowledge-intensive
reasoning. Our code and data are publicly available at
https://anonymous.4open.science/r/MedRGAG

### 15. Towards Faithful and Controllable Personalization via Critique-Post-Edit Reinforcement Learning

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Chenghao Zhu, Meiling Tao, Tiannan Wang, Dongyi Ding, Yuchen Eleanor Jiang, Wangchunshu Zhou
- **URL**: <http://arxiv.org/abs/2510.18849v1>
- **Submitted**: 2025-10-21 17:40:03
- **Comment**: work in progress
- **Topic Keywords**: rag, personalization
- **Reason**: This paper explores personalization in large language models, which is related to information retrieval and search technologies. However, the focus on reinforcement learning and reward hacking is more aligned with recommender systems than the user's core research themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> Faithfully personalizing large language models (LLMs) to align with
individual user preferences is a critical but challenging task. While
supervised fine-tuning (SFT) quickly reaches a performance plateau, standard
reinforcement learning from human feedback (RLHF) also struggles with the
nuances of personalization. Scalar-based reward models are prone to reward
hacking which leads to verbose and superficially personalized responses. To
address these limitations, we propose Critique-Post-Edit, a robust
reinforcement learning framework that enables more faithful and controllable
personalization. Our framework integrates two key components: (1) a
Personalized Generative Reward Model (GRM) that provides multi-dimensional
scores and textual critiques to resist reward hacking, and (2) a
Critique-Post-Edit mechanism where the policy model revises its own outputs
based on these critiques for more targeted and efficient learning. Under a
rigorous length-controlled evaluation, our method substantially outperforms
standard PPO on personalization benchmarks. Personalized Qwen2.5-7B achieves an
average 11\% win-rate improvement, and personalized Qwen2.5-14B model surpasses
the performance of GPT-4.1. These results demonstrate a practical path to
faithful, efficient, and controllable personalization.

### 16. Contrastive Decoding Mitigates Score Range Bias in LLM-as-a-Judge

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Yoshinari Fujinuma
- **URL**: <http://arxiv.org/abs/2510.18196v1>
- **Submitted**: 2025-10-21 00:47:11
- **Topic Keywords**: rag, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it involves the use of Large Language Models (LLMs) in evaluation tasks. However, the focus on mitigating score range bias in LLM-as-a-judge is not directly related to your core areas of interest in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large Language Models (LLMs) are commonly used as evaluators in various
applications, but the reliability of the outcomes remains a challenge. One such
challenge is using LLMs-as-judges for direct assessment, i.e., assigning scores
from a specified range without any references. We first show that this
challenge stems from LLM judge outputs being associated with score range bias,
i.e., LLM judge outputs are highly sensitive to pre-defined score ranges,
preventing the search for optimal score ranges. We also show that similar
biases exist among models from the same family. We then mitigate this bias
through contrastive decoding, achieving up to 11.3% relative improvement on
average in Spearman correlation with human judgments across different score
ranges.

### 17. Language Models as Semantic Augmenters for Sequential Recommenders

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Mahsa Valizadeh, Xiangjue Dong, Rui Tuo, James Caverlee
- **URL**: <http://arxiv.org/abs/2510.18046v1>
- **Submitted**: 2025-10-20 19:36:38
- **Topic Keywords**: rag, recommend
- **Reason**: This paper explores the application of large language models in sequential recommenders, which is somewhat related to your interests in information retrieval and search technologies. However, the focus on recommender systems and sequential modeling is not a central match to your primary research themes. The use of language models for semantic enrichment is an interesting aspect, but it doesn't directly align with your expertise in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large Language Models (LLMs) excel at capturing latent semantics and
contextual relationships across diverse modalities. However, in modeling user
behavior from sequential interaction data, performance often suffers when such
semantic context is limited or absent. We introduce LaMAR, a LLM-driven
semantic enrichment framework designed to enrich such sequences automatically.
LaMAR leverages LLMs in a few-shot setting to generate auxiliary contextual
signals by inferring latent semantic aspects of a user's intent and item
relationships from existing metadata. These generated signals, such as inferred
usage scenarios, item intents, or thematic summaries, augment the original
sequences with greater contextual depth. We demonstrate the utility of this
generated resource by integrating it into benchmark sequential modeling tasks,
where it consistently improves performance. Further analysis shows that
LLM-generated signals exhibit high semantic novelty and diversity, enhancing
the representational capacity of the downstream models. This work represents a
new data-centric paradigm where LLMs serve as intelligent context generators,
contributing a new method for the semi-automatic creation of training data and
language resources.

### 18. CodeRL+: Improving Code Generation via Reinforcement with Execution Semantics Alignment

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Xue Jiang, Yihong Dong, Mengyang Liu, Hongyi Deng, Tian Wang, Yongding Tao, Rongyu Cao, Binhua Li, Zhi Jin, Wenpin Jiao, Fei Huang, Yongbin Li, Ge Li
- **URL**: <http://arxiv.org/abs/2510.18471v1>
- **Submitted**: 2025-10-21 09:48:06
- **Topic Keywords**: rag
- **Reason**: This paper focuses on code generation and reinforcement learning, which is somewhat related to information retrieval and search technologies. However, the specific application domain and techniques used are not directly aligned with the user's core research themes, such as query understanding, ranking models, and user behavior modeling.

#### Abstract
> While Large Language Models (LLMs) excel at code generation by learning from
vast code corpora, a fundamental semantic gap remains between their training on
textual patterns and the goal of functional correctness, which is governed by
formal execution semantics. Reinforcement Learning with Verifiable Rewards
(RLVR) approaches attempt to bridge this gap using outcome rewards from
executing test cases. However, solely relying on binary pass/fail signals is
inefficient for establishing a well-aligned connection between the textual
representation of code and its execution semantics, especially for subtle
logical errors within the code. In this paper, we propose CodeRL+, a novel
approach that integrates execution semantics alignment into the RLVR training
pipeline for code generation. CodeRL+ enables the model to infer variable-level
execution trajectory, providing a direct learning signal of execution
semantics. CodeRL+ can construct execution semantics alignment directly using
existing on-policy rollouts and integrates seamlessly with various RL
algorithms. Extensive experiments demonstrate that CodeRL+ outperforms
post-training baselines (including RLVR and Distillation), achieving a 4.6%
average relative improvement in pass@1. CodeRL+ generalizes effectively to
other coding tasks, yielding 15.5% and 4.4% higher accuracy on code-reasoning
and test-output-generation benchmarks, respectively. CodeRL+ shows strong
applicability across diverse RL algorithms and LLMs. Furthermore, probe
analyses provide compelling evidence that CodeRL+ strengthens the alignment
between code's textual representations and its underlying execution semantics.

### 19. LIME: Link-based user-item Interaction Modeling with decoupled xor attention for Efficient test time scaling

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Yunjiang Jiang, Ayush Agarwal, Yang Liu, Bi Xue
- **URL**: <http://arxiv.org/abs/2510.18239v1>
- **Submitted**: 2025-10-21 02:53:17
- **Comment**: 16 pages
- **Topic Keywords**: recommend, rank
- **Reason**: The paper focuses on recommendation systems, specifically addressing scalability issues with transformers. While it touches on attention mechanisms and user-item interactions, it doesn't directly relate to query understanding, ranking models, or deep semantic understanding in information retrieval, which are core areas of your research interests.

#### Abstract
> Scaling large recommendation systems requires advancing three major
frontiers: processing longer user histories, expanding candidate sets, and
increasing model capacity. While promising, transformers' computational cost
scales quadratically with the user sequence length and linearly with the number
of candidates. This trade-off makes it prohibitively expensive to expand
candidate sets or increase sequence length at inference, despite the
significant performance improvements.
  We introduce \textbf{LIME}, a novel architecture that resolves this
trade-off. Through two key innovations, LIME fundamentally reduces
computational complexity. First, low-rank ``link embeddings" enable
pre-computation of attention weights by decoupling user and candidate
interactions, making the inference cost nearly independent of candidate set
size. Second, a linear attention mechanism, \textbf{LIME-XOR}, reduces the
complexity with respect to user sequence length from quadratic ($O(N^2)$) to
linear ($O(N)$).
  Experiments on public and industrial datasets show LIME achieves near-parity
with state-of-the-art transformers but with a 10$\times$ inference speedup on
large candidate sets or long sequence lengths. When tested on a major
recommendation platform, LIME improved user engagement while maintaining
minimal inference costs with respect to candidate set size and user history
length, establishing a new paradigm for efficient and expressive recommendation
systems.

### 20. KoSimpleQA: A Korean Factuality Benchmark with an Analysis of Reasoning LLMs

- **LLM Score**: 3
- **Keyword Score**: 5
- **Authors**: Donghyeon Ko, Yeguk Jin, Kyubyung Chae, Byungwook Lee, Chansong Jo, Sookyo In, Jaehong Lee, Taesup Kim, Donghyun Kwak
- **URL**: <http://arxiv.org/abs/2510.18368v1>
- **Submitted**: 2025-10-21 07:37:51
- **Topic Keywords**: ranking, rank, korea
- **Reason**: This paper presents a Korean factuality benchmark, KoSimpleQA, which evaluates the performance of large language models (LLMs) in understanding and generating accurate answers to fact-seeking questions. While it touches on aspects of query understanding and model performance, it is primarily focused on the evaluation of LLMs rather than information retrieval or search technologies. The paper's emphasis on NLP and cultural knowledge makes it somewhat relevant to your interests, but it does not align closely with your core research themes.

#### Abstract
> We present $\textbf{Korean SimpleQA (KoSimpleQA)}$, a benchmark for
evaluating factuality in large language models (LLMs) with a focus on Korean
cultural knowledge. KoSimpleQA is designed to be challenging yet easy to grade,
consisting of 1,000 short, fact-seeking questions with unambiguous answers. We
conduct a comprehensive evaluation across a diverse set of open-source LLMs of
varying sizes that support Korean, and find that even the strongest model
generates correct answer only 33.7% of the time, underscoring the challenging
nature of KoSimpleQA. Notably, performance rankings on KoSimpleQA differ
substantially from those on the English SimpleQA, highlighting the unique value
of our dataset. Furthermore, our analysis of reasoning LLMs shows that engaging
reasoning capabilities in the factual QA task can both help models better
elicit their latent knowledge and improve their ability to abstain when
uncertain. KoSimpleQA can be found at
https://anonymous.4open.science/r/KoSimpleQA-62EB.

### 21. Topoformer: brain-like topographic organization in Transformer language models through spatial querying and reweighting

- **LLM Score**: 2
- **Keyword Score**: 9
- **Authors**: Taha Binhuraib, Greta Tuckute, Nicholas Blauch
- **URL**: <http://arxiv.org/abs/2510.18745v1>
- **Submitted**: 2025-10-21 15:54:57
- **Comment**: ICLR 2024 Workshop on Representational Alignment (Re-Align) Camera
  Ready
- **Topic Keywords**: query, queries, rag, search
- **Reason**: This paper focuses on developing a novel form of self-attention for Transformers, which is a topic in Natural Language Processing (NLP). However, it does not directly relate to Information Retrieval (IR), query understanding, ranking models, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Spatial functional organization is a hallmark of biological brains: neurons
are arranged topographically according to their response properties, at
multiple scales. In contrast, representations within most machine learning
models lack spatial biases, instead manifesting as disorganized vector spaces
that are difficult to visualize and interpret. Here, we propose a novel form of
self-attention that turns Transformers into "Topoformers" with topographic
organization. We introduce spatial querying - where keys and queries are
arranged on 2D grids, and local pools of queries are associated with a given
key - and spatial reweighting, where we convert the standard fully connected
layer of self-attention into a locally connected layer. We first demonstrate
the feasibility of our approach by training a 1-layer Topoformer on a sentiment
classification task. Training with spatial querying encourages topographic
organization in the queries and keys, and spatial reweighting separately
encourages topographic organization in the values and self-attention outputs.
We then apply the Topoformer motifs at scale, training a BERT architecture with
a masked language modeling objective. We find that the topographic variant
performs on par with a non-topographic control model on NLP benchmarks, yet
produces interpretable topographic organization as evaluated via eight
linguistic test suites. Finally, analyzing an fMRI dataset of human brain
responses to a large set of naturalistic sentences, we demonstrate alignment
between low-dimensional topographic variability in the Topoformer model and
human brain language network. Scaling up Topoformers further holds promise for
greater interpretability in NLP research, and for more accurate models of the
organization of linguistic information in the human brain.

### 22. ImageGem: In-the-wild Generative Image Interaction Dataset for Generative Model Personalization

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Yuanhe Guo, Linxi Xie, Zhuoran Chen, Kangrui Yu, Ryan Po, Guandao Yang, Gordon Wetztein, Hongyi Wen
- **URL**: <http://arxiv.org/abs/2510.18433v1>
- **Submitted**: 2025-10-21 09:08:01
- **Topic Keywords**: rag, retrieval, recommend, personalization
- **Reason**: This paper is not directly related to Information Retrieval or Search technologies, but rather focuses on Generative Models and Personalization in the context of image interaction. While it involves user behavior modeling, it's more specific to image generation and preference alignment, which doesn't align with the user's core research themes.

#### Abstract
> We introduce ImageGem, a dataset for studying generative models that
understand fine-grained individual preferences. We posit that a key challenge
hindering the development of such a generative model is the lack of in-the-wild
and fine-grained user preference annotations. Our dataset features real-world
interaction data from 57K users, who collectively have built 242K customized
LoRAs, written 3M text prompts, and created 5M generated images. With user
preference annotations from our dataset, we were able to train better
preference alignment models. In addition, leveraging individual user
preference, we investigated the performance of retrieval models and a
vision-language model on personalized image retrieval and generative model
recommendation. Finally, we propose an end-to-end framework for editing
customized diffusion models in a latent weight space to align with individual
user preferences. Our results demonstrate that the ImageGem dataset enables,
for the first time, a new paradigm for generative model personalization.

### 23. MTraining: Distributed Dynamic Sparse Attention for Efficient Ultra-Long Context Training

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Wenxuan Li, Chengruidong Zhang, Huiqiang Jiang, Yucheng Li, Yuqing Yang, Lili Qiu
- **URL**: <http://arxiv.org/abs/2510.18830v1>
- **Submitted**: 2025-10-21 17:25:32
- **Topic Keywords**: ltr, rag
- **Reason**: This paper focuses on efficient training of Large Language Models with ultra-long contexts using distributed dynamic sparse attention. While it touches on the concept of long context windows, which is related to information retrieval, the primary focus is on model training efficiency and scalability, which is not directly aligned with your core research themes in IR and search technologies.

#### Abstract
> The adoption of long context windows has become a standard feature in Large
Language Models (LLMs), as extended contexts significantly enhance their
capacity for complex reasoning and broaden their applicability across diverse
scenarios. Dynamic sparse attention is a promising approach for reducing the
computational cost of long-context. However, efficiently training LLMs with
dynamic sparse attention on ultra-long contexts-especially in distributed
settings-remains a significant challenge, due in large part to worker- and
step-level imbalance. This paper introduces MTraining, a novel distributed
methodology leveraging dynamic sparse attention to enable efficient training
for LLMs with ultra-long contexts. Specifically, MTraining integrates three key
components: a dynamic sparse training pattern, balanced sparse ring attention,
and hierarchical sparse ring attention. These components are designed to
synergistically address the computational imbalance and communication overheads
inherent in dynamic sparse attention mechanisms during the training of models
with extensive context lengths. We demonstrate the efficacy of MTraining by
training Qwen2.5-3B, successfully expanding its context window from 32K to 512K
tokens on a cluster of 32 A100 GPUs. Our evaluations on a comprehensive suite
of downstream tasks, including RULER, PG-19, InfiniteBench, and Needle In A
Haystack, reveal that MTraining achieves up to a 6x higher training throughput
while preserving model accuracy. Our code is available at
https://github.com/microsoft/MInference/tree/main/MTraining.

### 24. DART: A Structured Dataset of Regulatory Drug Documents in Italian for Clinical NLP

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Mariano Barone, Antonio Laudante, Giuseppe Riccio, Antonio Romano, Marco Postiglione, Vincenzo Moscato
- **URL**: <http://arxiv.org/abs/2510.18475v1>
- **Submitted**: 2025-10-21 09:53:17
- **Topic Keywords**: rag, retrieval, search
- **Reason**: This paper is primarily focused on clinical NLP and the creation of a dataset for regulatory drug documents in Italian, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and query understanding.

#### Abstract
> The extraction of pharmacological knowledge from regulatory documents has
become a key focus in biomedical natural language processing, with applications
ranging from adverse event monitoring to AI-assisted clinical decision support.
However, research in this field has predominantly relied on English-language
corpora such as DrugBank, leaving a significant gap in resources tailored to
other healthcare systems. To address this limitation, we introduce DART (Drug
Annotation from Regulatory Texts), the first structured corpus of Italian
Summaries of Product Characteristics derived from the official repository of
the Italian Medicines Agency (AIFA). The dataset was built through a
reproducible pipeline encompassing web-scale document retrieval, semantic
segmentation of regulatory sections, and clinical summarization using a
few-shot-tuned large language model with low-temperature decoding. DART
provides structured information on key pharmacological domains such as
indications, adverse drug reactions, and drug-drug interactions. To validate
its utility, we implemented an LLM-based drug interaction checker that
leverages the dataset to infer clinically meaningful interactions. Experimental
results show that instruction-tuned LLMs can accurately infer potential
interactions and their clinical implications when grounded in the structured
textual fields of DART. We publicly release our code on GitHub:
https://github.com/PRAISELab-PicusLab/DART.

### 25. Adamas: Hadamard Sparse Attention for Efficient Long-Context Inference

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Siyuan Yan, Guo-Qing Jiang, Yuchen Zhang, Xiaoxing Ma, Ran Zhu, Chun Cao, Jingwei Xu
- **URL**: <http://arxiv.org/abs/2510.18413v1>
- **Submitted**: 2025-10-21 08:44:47
- **Topic Keywords**: query, rag
- **Reason**: This paper focuses on improving the efficiency of large language models through a novel sparse attention mechanism, but it does not appear to be directly related to information retrieval, query understanding, ranking models, or user behavior modeling, which are the core areas of your research interests.

#### Abstract
> Large language models (LLMs) now support context windows of hundreds of
thousands to millions of tokens, enabling applications such as long-document
summarization, large-scale code synthesis, multi-document question answering
and persistent multi-turn dialogue. However, such extended contexts exacerbate
the quadratic cost of self-attention, leading to severe latency in
autoregressive decoding. Existing sparse attention methods alleviate these
costs but rely on heuristic patterns that struggle to recall critical key-value
(KV) pairs for each query, resulting in accuracy degradation. We introduce
Adamas, a lightweight yet highly accurate sparse attention mechanism designed
for long-context inference. Adamas applies the Hadamard transform,
bucketization and 2-bit compression to produce compact representations, and
leverages Manhattan-distance estimation for efficient top-k selections.
Experiments show that Adamas matches the accuracy of full attention with only a
64-token budget, achieves near-lossless performance at 128, and supports up to
8x higher sparsity than prior state-of-the-art (SOTA) methods while delivering
up to 4.4x self-attention and 1.5x end-to-end speedups on 32K-length sequences.
Remarkably, Adamas attains comparable or even lower perplexity than full
attention, underscoring its effectiveness in maintaining accuracy under
aggressive sparsity.

### 26. LightMem: Lightweight and Efficient Memory-Augmented Generation

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Jizhan Fang, Xinle Deng, Haoming Xu, Ziyan Jiang, Yuqi Tang, Ziwen Xu, Shumin Deng, Yunzhi Yao, Mengru Wang, Shuofei Qiao, Huajun Chen, Ningyu Zhang
- **URL**: <http://arxiv.org/abs/2510.18866v1>
- **Submitted**: 2025-10-21 17:58:17
- **Comment**: Work in progress
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper focuses on memory-augmented generation for Large Language Models, which is outside the scope of your primary research interests in Information Retrieval and Search technologies. While it touches on the topic of memory systems, it's more relevant to NLP and deep learning, and doesn't seem to address real-time relevance optimization or query understanding, which are key areas of interest for you.

#### Abstract
> Despite their remarkable capabilities, Large Language Models (LLMs) struggle
to effectively leverage historical interaction information in dynamic and
complex environments. Memory systems enable LLMs to move beyond stateless
interactions by introducing persistent information storage, retrieval, and
utilization mechanisms. However, existing memory systems often introduce
substantial time and computational overhead. To this end, we introduce a new
memory system called LightMem, which strikes a balance between the performance
and efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of
human memory, LightMem organizes memory into three complementary stages. First,
cognition-inspired sensory memory rapidly filters irrelevant information
through lightweight compression and groups information according to their
topics. Next, topic-aware short-term memory consolidates these topic-based
groups, organizing and summarizing content for more structured access. Finally,
long-term memory with sleep-time update employs an offline procedure that
decouples consolidation from online inference. Experiments on LongMemEval with
GPT and Qwen backbones show that LightMem outperforms strong baselines in
accuracy (up to 10.9% gains) while reducing token usage by up to 117x, API
calls by up to 159x, and runtime by over 12x. The code is available at
https://github.com/zjunlp/LightMem.

### 27. SemiAdapt and SemiLoRA: Efficient Domain Adaptation for Transformer-based Low-Resource Language Translation with a Case Study on Irish

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Josh McGiff, Nikola S. Nikolov
- **URL**: <http://arxiv.org/abs/2510.18725v1>
- **Submitted**: 2025-10-21 15:24:15
- **Comment**: 8 pages
- **Topic Keywords**: rag, rank, search
- **Reason**: This paper focuses on domain adaptation for low-resource language translation, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves fine-tuning large language models, the context is specific to machine translation and does not align with the user's primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Fine-tuning is widely used to tailor large language models for specific tasks
such as neural machine translation (NMT). However, leveraging transfer learning
is computationally expensive when fine-tuning large multilingual models with
billions of parameters, thus creating a barrier to entry for researchers
working on low-resource domains such as Irish translation. Parameter-efficient
fine-tuning (PEFT) bridges this gap by training on a fraction of the original
model parameters, with the Low-Rank Adaptation (LoRA) approach introducing
small, trainable adapter layers. We introduce SemiAdapt and SemiLoRA as
semi-supervised inference-efficient approaches that strengthen domain
adaptation and lead to improved overall performance in NMT. We demonstrate that
SemiAdapt can outperform full-domain fine-tuning, while most notably, SemiLoRA
can propel PEFT methods to match or even outperform full-model fine-tuning. We
further evaluate domain-by-dataset fine-tuning and demonstrate that our
embedding-based inference methods perform especially well on larger and noisier
corpora. All Irish translation models developed in this work are released as
open resources. These methods aim to make high-quality domain adaptation and
fine-tuning more accessible to researchers working with low-resource languages.

### 28. Towards Fair ASR For Second Language Speakers Using Fairness Prompted Finetuning

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Monorama Swain, Bubai Maji, Jagabandhu Mishra, Markus Schedl, Anders S√∏gaard, Jesper Rindom Jensen
- **URL**: <http://arxiv.org/abs/2510.18374v1>
- **Submitted**: 2025-10-21 07:45:21
- **Comment**: Submitted to ICASSP 2026
- **Topic Keywords**: rag, ctr
- **Reason**: This paper focuses on speech recognition for second-language speakers, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific application and techniques used are not aligned with your areas of focus.

#### Abstract
> In this work, we address the challenge of building fair English ASR systems
for second-language speakers. Our analysis of widely used ASR models, Whisper
and Seamless-M4T, reveals large fluctuations in word error rate (WER) across 26
accent groups, indicating significant fairness gaps. To mitigate this, we
propose fairness-prompted finetuning with lightweight adapters, incorporating
Spectral Decoupling (SD), Group Distributionally Robust Optimization
(Group-DRO), and Invariant Risk Minimization (IRM). Our proposed fusion of
traditional empirical risk minimization (ERM) with cross-entropy and
fairness-driven objectives (SD, Group DRO, and IRM) enhances fairness across
accent groups while maintaining overall recognition accuracy. In terms of
macro-averaged word error rate, our approach achieves a relative improvement of
58.7% and 58.5% over the large pretrained Whisper and SeamlessM4T, and 9.7% and
7.8% over them, finetuning with standard empirical risk minimization with
cross-entropy loss.

### 29. How Do LLMs Use Their Depth?

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Akshat Gupta, Jay Yeung, Gopala Anumanchipalli, Anna Ivanova
- **URL**: <http://arxiv.org/abs/2510.18871v1>
- **Submitted**: 2025-10-21 17:59:05
- **Topic Keywords**: rag, rank
- **Reason**: This paper focuses on the internal workings of Large Language Models (LLMs), specifically their layer-wise prediction dynamics, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. While it touches on deep semantic understanding, it's more relevant to NLP and model efficiency, which is not a primary focus of your research interests.

#### Abstract
> Growing evidence suggests that large language models do not use their depth
uniformly, yet we still lack a fine-grained understanding of their layer-wise
prediction dynamics. In this paper, we trace the intermediate representations
of several open-weight models during inference and reveal a structured and
nuanced use of depth. Specifically, we propose a "Guess-then-Refine" framework
that explains how LLMs internally structure their computations to make
predictions. We first show that the top-ranked predictions in early LLM layers
are composed primarily of high-frequency tokens, which act as statistical
guesses proposed by the model early on due to the lack of appropriate
contextual information. As contextual information develops deeper into the
model, these initial guesses get refined into contextually appropriate tokens.
Even high-frequency token predictions from early layers get refined >70% of the
time, indicating that correct token prediction is not "one-and-done". We then
go beyond frequency-based prediction to examine the dynamic usage of layer
depth across three case studies. (i) Part-of-speech analysis shows that
function words are, on average, the earliest to be predicted correctly. (ii)
Fact recall task analysis shows that, in a multi-token answer, the first token
requires more computational depth than the rest. (iii) Multiple-choice task
analysis shows that the model identifies the format of the response within the
first half of the layers, but finalizes its response only toward the end.
Together, our results provide a detailed view of depth usage in LLMs, shedding
light on the layer-by-layer computations that underlie successful predictions
and providing insights for future works to improve computational efficiency in
transformer-based models.

### 30. Beyond the Explicit: A Bilingual Dataset for Dehumanization Detection in Social Media

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Dennis Assenmacher, Paloma Piot, Katarina Laken, David Jurgens, Claudia Wagner
- **URL**: <http://arxiv.org/abs/2510.18582v1>
- **Submitted**: 2025-10-21 12:35:30
- **Topic Keywords**: ctr, search
- **Reason**: This paper focuses on dehumanization detection in social media, which is a topic in Natural Language Processing (NLP), but it does not directly relate to your core research interests in Information Retrieval (IR), query understanding, ranking models, or user behavior modeling. While it involves machine learning models, the context is specific to dehumanization detection and not directly applicable to your areas of focus.

#### Abstract
> Digital dehumanization, although a critical issue, remains largely overlooked
within the field of computational linguistics and Natural Language Processing.
The prevailing approach in current research concentrating primarily on a single
aspect of dehumanization that identifies overtly negative statements as its
core marker. This focus, while crucial for understanding harmful online
communications, inadequately addresses the broader spectrum of dehumanization.
Specifically, it overlooks the subtler forms of dehumanization that, despite
not being overtly offensive, still perpetuate harmful biases against
marginalized groups in online interactions. These subtler forms can insidiously
reinforce negative stereotypes and biases without explicit offensiveness,
making them harder to detect yet equally damaging. Recognizing this gap, we use
different sampling methods to collect a theory-informed bilingual dataset from
Twitter and Reddit. Using crowdworkers and experts to annotate 16,000 instances
on a document- and span-level, we show that our dataset covers the different
dimensions of dehumanization. This dataset serves as both a training resource
for machine learning models and a benchmark for evaluating future
dehumanization detection techniques. To demonstrate its effectiveness, we
fine-tune ML models on this dataset, achieving performance that surpasses
state-of-the-art models in zero and few-shot in-context settings.

### 31. From AutoRecSys to AutoRecLab: A Call to Build, Evaluate, and Govern Autonomous Recommender-Systems Research Labs

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Joeran Beel, Bela Gipp, Tobias Vente, Moritz Baumgart, Philipp Meister
- **URL**: <http://arxiv.org/abs/2510.18104v1>
- **Submitted**: 2025-10-20 20:58:50
- **Topic Keywords**: recommend, search, recsys
- **Reason**: This paper is primarily focused on recommender systems and the automation of the research process, which is somewhat related to the user's interests in Information Retrieval and Search technologies. However, it does not align with the user's core research themes, particularly query understanding, ranking models, and user behavior modeling.

#### Abstract
> Recommender-systems research has accelerated model and evaluation advances,
yet largely neglects automating the research process itself. We argue for a
shift from narrow AutoRecSys tools -- focused on algorithm selection and
hyper-parameter tuning -- to an Autonomous Recommender-Systems Research Lab
(AutoRecLab) that integrates end-to-end automation: problem ideation,
literature analysis, experimental design and execution, result interpretation,
manuscript drafting, and provenance logging. Drawing on recent progress in
automated science (e.g., multi-agent AI Scientist and AI Co-Scientist systems),
we outline an agenda for the RecSys community: (1) build open AutoRecLab
prototypes that combine LLM-driven ideation and reporting with automated
experimentation; (2) establish benchmarks and competitions that evaluate agents
on producing reproducible RecSys findings with minimal human input; (3) create
review venues for transparently AI-generated submissions; (4) define standards
for attribution and reproducibility via detailed research logs and metadata;
and (5) foster interdisciplinary dialogue on ethics, governance, privacy, and
fairness in autonomous research. Advancing this agenda can increase research
throughput, surface non-obvious insights, and position RecSys to contribute to
emerging Artificial Research Intelligence. We conclude with a call to organise
a community retreat to coordinate next steps and co-author guidance for the
responsible integration of automated research systems.

### 32. SimBA: Simplifying Benchmark Analysis Using Performance Matrices Alone

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Nishant Subramani, Alfredo Gomez, Mona Diab
- **URL**: <http://arxiv.org/abs/2510.17998v1>
- **Submitted**: 2025-10-20 18:23:27
- **Comment**: EMNLP 2025 Findings
- **Topic Keywords**: rag, rank
- **Reason**: This paper focuses on benchmark analysis for language models, which is not directly related to information retrieval, search technologies, or query understanding. While it involves performance evaluation and model comparison, the context is specific to natural language processing and model development, making it less relevant to your core research interests.

#### Abstract
> Modern language models are evaluated on large benchmarks, which are difficult
to make sense of, especially for model selection. Looking at the raw evaluation
numbers themselves using a model-centric lens, we propose SimBA, a three phase
framework to Simplify Benchmark Analysis. The three phases of SimBA are: stalk,
where we conduct dataset & model comparisons, prowl, where we discover a
representative subset, and pounce, where we use the representative subset to
predict performance on a held-out set of models. Applying SimBA to three
popular LM benchmarks: HELM, MMLU, and BigBenchLite reveals that across all
three benchmarks, datasets and models relate strongly to one another (stalk).
We develop an representative set discovery algorithm which covers a benchmark
using raw evaluation scores alone. Using our algorithm, we find that with 6.25%
(1/16), 1.7% (1/58), and 28.4% (21/74) of the datasets for HELM, MMLU, and
BigBenchLite respectively, we achieve coverage levels of at least 95% (prowl).
Additionally, using just these representative subsets, we can both preserve
model ranks and predict performance on a held-out set of models with near zero
mean-squared error (pounce). Taken together, SimBA can help model developers
improve efficiency during model training and dataset creators validate whether
their newly created dataset differs from existing datasets in a benchmark. Our
code is open source, available at https://github.com/nishantsubramani/simba.

### 33. Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Haochen Wang, Yuhao Wang, Tao Zhang, Yikang Zhou, Yanwei Li, Jiacong Wang, Jiani Zheng, Ye Tian, Jiahao Meng, Zilong Huang, Guangcan Mai, Anran Wang, Yunhai Tong, Zhuochen Wang, Xiangtai Li, Zhaoxiang Zhang
- **URL**: <http://arxiv.org/abs/2510.18876v2>
- **Submitted**: 2025-10-21 17:59:59
- **Topic Keywords**: rag
- **Reason**: This paper focuses on multimodal large language models and visual understanding, which is not directly related to your primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some form of understanding and modeling, the context and application are quite different from your areas of expertise.

#### Abstract
> While Multimodal Large Language Models (MLLMs) excel at holistic
understanding, they struggle in capturing the dense world with complex scenes,
requiring fine-grained analysis of intricate details and object
inter-relationships. Region-level MLLMs have been a promising step. However,
previous attempts are generally optimized to understand given regions in
isolation, neglecting crucial global contexts. To address this, we introduce
Grasp Any Region (GAR) for comprehen- sive region-level visual understanding.
Empowered by an effective RoI-aligned feature replay technique, GAR supports
(1) precise perception by leveraging necessary global contexts, and (2)
modeling interactions between multiple prompts. Together, it then naturally
achieves (3) advanced compositional reasoning to answer specific free-form
questions about any region, shifting the paradigm from passive description to
active dialogue. Moreover, we construct GAR-Bench, which not only provides a
more accurate evaluation of single-region comprehension, but also, more
importantly, measures interactions and complex reasoning across multiple
regions. Extensive experiments have demonstrated that GAR-1B not only maintains
the state-of-the-art captioning capabilities, e.g., outperforming DAM-3B +4.5
on DLC-Bench, but also excels at modeling relationships between multiple
prompts with advanced comprehension capabilities, even surpassing InternVL3-78B
on GAR-Bench-VQA. More importantly, our zero-shot GAR-8B even outperforms
in-domain VideoRefer-7B on VideoRefer-BenchQ, indicating its strong
capabilities can be easily transferred to videos.

### 34. See the Text: From Tokenization to Visual Reading

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ling Xing, Alex Jinpeng Wang, Rui Yan, Hongyu Qu, Zechao Li, Jinhui Tang
- **URL**: <http://arxiv.org/abs/2510.18840v1>
- **Submitted**: 2025-10-21 17:34:48
- **Topic Keywords**: rag
- **Reason**: This paper focuses on a vision-centric approach to text processing, leveraging multimodal LLMs and OCR abilities. While it touches on language models, it doesn't directly relate to query understanding, ranking models, or user behavior modeling in information retrieval, which are core areas of your research interests.

#### Abstract
> People see text. Humans read by recognizing words as visual objects,
including their shapes, layouts, and patterns, before connecting them to
meaning, which enables us to handle typos, distorted fonts, and various scripts
effectively. Modern large language models (LLMs), however, rely on subword
tokenization, fragmenting text into pieces from a fixed vocabulary. While
effective for high-resource languages, this approach over-segments low-resource
languages, yielding long, linguistically meaningless sequences and inflating
computation. In this work, we challenge this entrenched paradigm and move
toward a vision-centric alternative. Our method, SeeTok, renders text as images
(visual-text) and leverages pretrained multimodal LLMs to interpret them,
reusing strong OCR and text-vision alignment abilities learned from large-scale
multimodal training. Across three different language tasks, SeeTok matches or
surpasses subword tokenizers while requiring 4.43 times fewer tokens and
reducing FLOPs by 70.5%, with additional gains in cross-lingual generalization,
robustness to typographic noise, and linguistic hierarchy. SeeTok signals a
shift from symbolic tokenization to human-like visual reading, and takes a step
toward more natural and cognitively inspired language models.

### 35. Fine-Tuned Thoughts: Leveraging Chain-of-Thought Reasoning for Industrial Asset Health Monitoring

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Shuxin Lin, Dhaval Patel, Christodoulos Constantinides
- **URL**: <http://arxiv.org/abs/2510.18817v1>
- **Submitted**: 2025-10-21 17:18:24
- **Comment**: Accepted at EMNLP 2025
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests as it focuses on industrial asset health monitoring and knowledge distillation for small language models, which is outside your primary areas of interest in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Small Language Models (SLMs) are becoming increasingly popular in specialized
fields, such as industrial applications, due to their efficiency, lower
computational requirements, and ability to be fine-tuned for domain-specific
tasks, enabling accurate and cost-effective solutions. However, performing
complex reasoning using SLMs in specialized fields such as Industry 4.0 remains
challenging. In this paper, we propose a knowledge distillation framework for
industrial asset health, which transfers reasoning capabilities via
Chain-of-Thought (CoT) distillation from Large Language Models (LLMs) to
smaller, more efficient models (SLMs). We discuss the advantages and the
process of distilling LLMs using multi-choice question answering (MCQA) prompts
to enhance reasoning and refine decision-making. We also perform in-context
learning to verify the quality of the generated knowledge and benchmark the
performance of fine-tuned SLMs with generated knowledge against widely used
LLMs. The results show that the fine-tuned SLMs with CoT reasoning outperform
the base models by a significant margin, narrowing the gap to their LLM
counterparts. Our code is open-sourced at:
https://github.com/IBM/FailureSensorIQ.

### 36. Verifiable Accuracy and Abstention Rewards in Curriculum RL to Alleviate Lost-in-Conversation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ming Li
- **URL**: <http://arxiv.org/abs/2510.18731v1>
- **Submitted**: 2025-10-21 15:32:26
- **Topic Keywords**: rag
- **Reason**: This paper focuses on improving the performance of Large Language Models in multi-turn conversations, using a reinforcement learning approach. While it touches on the idea of 'lost-in-conversation' which might be related to query understanding, the paper's primary focus is on improving the reliability and trustworthiness of LLMs, which doesn't directly align with the user's interests in Information Retrieval and Search technologies.

#### Abstract
> Large Language Models demonstrate strong capabilities in single-turn
instruction following but suffer from Lost-in-Conversation (LiC), a degradation
in performance as information is revealed progressively in multi-turn settings.
Motivated by the current progress on Reinforcement Learning with Verifiable
Rewards (RLVR), we propose Curriculum Reinforcement Learning with Verifiable
Accuracy and Abstention Rewards (RLAAR), a framework that encourages models not
only to generate correct answers, but also to judge the solvability of
questions in the multi-turn conversation setting. Our approach employs a
competence-gated curriculum that incrementally increases dialogue difficulty
(in terms of instruction shards), stabilizing training while promoting
reliability. Using multi-turn, on-policy rollouts and a mixed-reward system,
RLAAR teaches models to balance problem-solving with informed abstention,
reducing premature answering behaviors that cause LiC. Evaluated on LiC
benchmarks, RLAAR significantly mitigates LiC performance decay (62.6% to
75.1%) and improves calibrated abstention rates (33.5% to 73.4%). Together,
these results provide a practical recipe for building multi-turn reliable and
trustworthy LLMs.

### 37. MLMA: Towards Multilingual with Mamba Based Architectures

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Mohamed Nabih Ali, Daniele Falavigna, Alessio Brutti
- **URL**: <http://arxiv.org/abs/2510.18684v1>
- **Submitted**: 2025-10-21 14:44:16
- **Comment**: The paper is under review at ICASSP 2026
- **Topic Keywords**: rag
- **Reason**: This paper focuses on multilingual automatic speech recognition using a novel architecture, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves sequence modeling and language-aware conditioning, the context is speech recognition, not query understanding, ranking models, or user behavior modeling.

#### Abstract
> Multilingual automatic speech recognition (ASR) remains a challenging task,
especially when balancing performance across high- and low-resource languages.
Recent advances in sequence modeling suggest that architectures beyond
Transformers may offer better scalability and efficiency. In this work, we
introduce MLMA (Multilingual Language Modeling with Mamba for ASR), a new
approach that leverages the Mamba architecture -- an efficient state-space
model optimized for long-context sequence processing -- for multilingual ASR.
Using Mamba, MLMA implicitly incorporates language-aware conditioning and
shared representations to support robust recognition across diverse languages.
Experiments on standard multilingual benchmarks show that MLMA achieves
competitive performance compared to Transformer-based architectures. These
results highlight Mamba's potential as a strong backbone for scalable,
efficient, and accurate multilingual speech recognition.

### 38. Building Trust in Clinical LLMs: Bias Analysis and Dataset Transparency

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Svetlana Maslenkova, Clement Christophe, Marco AF Pimentel, Tathagata Raha, Muhammad Umar Salman, Ahmed Al Mahrooqi, Avani Gupta, Shadab Khan, Ronnie Rajan, Praveenkumar Kanithi
- **URL**: <http://arxiv.org/abs/2510.18556v1>
- **Submitted**: 2025-10-21 12:08:39
- **Comment**: Accepted to EMNLP Main 2025
- **Topic Keywords**: rag
- **Reason**: This paper focuses on bias analysis and dataset transparency in clinical language models, which is outside the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific application and context are not aligned with the user's core themes.

#### Abstract
> Large language models offer transformative potential for healthcare, yet
their responsible and equitable development depends critically on a deeper
understanding of how training data characteristics influence model behavior,
including the potential for bias. Current practices in dataset curation and
bias assessment often lack the necessary transparency, creating an urgent need
for comprehensive evaluation frameworks to foster trust and guide improvements.
In this study, we present an in-depth analysis of potential downstream biases
in clinical language models, with a focus on differential opioid prescription
tendencies across diverse demographic groups, such as ethnicity, gender, and
age. As part of this investigation, we introduce HC4: Healthcare Comprehensive
Commons Corpus, a novel and extensively curated pretraining dataset exceeding
89 billion tokens. Our evaluation leverages both established general benchmarks
and a novel, healthcare-specific methodology, offering crucial insights to
support fairness and safety in clinical AI applications.

### 39. Probabilistic Modeling of Intentions in Socially Intelligent LLM Agents

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Feifan Xia, Yuyang Fang, Defang Li, Yantong Xie, Weikang Li, Yang Li, Deguo Xia, Jizhou Huang
- **URL**: <http://arxiv.org/abs/2510.18476v1>
- **Submitted**: 2025-10-21 09:54:44
- **Topic Keywords**: acl
- **Reason**: This paper focuses on probabilistic intent modeling for large language model agents in social dialogue, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing, the context is social dialogue and not search or e-commerce, making it somewhat tangential to the user's primary research interests.

#### Abstract
> We present a probabilistic intent modeling framework for large language model
(LLM) agents in multi-turn social dialogue. The framework maintains a belief
distribution over a partner's latent intentions, initialized from contextual
priors and dynamically updated through likelihood estimation after each
utterance. The evolving distribution provides additional contextual grounding
for the policy, enabling adaptive dialogue strategies under uncertainty.
Preliminary experiments in the SOTOPIA environment show consistent
improvements: the proposed framework increases the Overall score by 9.0% on
SOTOPIA-All and 4.1% on SOTOPIA-Hard compared with the Qwen2.5-7B baseline, and
slightly surpasses an oracle agent that directly observes partner intentions.
These early results suggest that probabilistic intent modeling can contribute
to the development of socially intelligent LLM agents.

### 40. Chain-of-Conceptual-Thought: Eliciting the Agent to Deeply Think within the Response

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Qingqing Gu, Dan Wang, Yue Zhao, Xiaoyu Wang, Zhonglin Jiang, Yong Chen, Hongyan Li, Luo Ji
- **URL**: <http://arxiv.org/abs/2510.18434v1>
- **Submitted**: 2025-10-21 09:08:21
- **Topic Keywords**: rag
- **Reason**: This paper focuses on a prompt-based paradigm for improving LLMs in open-domain tasks, which is not directly related to Information Retrieval or Search technologies. While it involves deep thinking and strategic generation, it's more aligned with NLP and LLM capabilities rather than IR or user behavior modeling.

#### Abstract
> Chain-of-Thought (CoT) is widely applied to improve the LLM capability in
math, coding and reasoning tasks. However, its performance is limited for
open-domain tasks since there are no clearly defined reasoning steps or logical
transitions. To mitigate such challenges, we propose another prompt-based
paradigm called Chain of Conceptual Thought (CoCT), where the LLM first tags a
concept, then generates the detailed content. The chain of concepts is allowed
within the utterance, encouraging the LLM's deep and strategic thinking. We
experiment with this paradigm in daily and emotional support conversations
where the concept is comprised of emotions, strategies and topics. Automatic,
human and model evaluations suggest that CoCT surpasses baselines such as
Self-Refine, ECoT, ToT, SoT and RAG, suggesting a potential effective
prompt-based paradigm of LLM for a wider scope of tasks.

### 41. The Impact of Image Resolution on Biomedical Multimodal Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Liangyu Chen, James Burgess, Jeffrey J Nirschl, Orr Zohar, Serena Yeung-Levy
- **URL**: <http://arxiv.org/abs/2510.18304v1>
- **Submitted**: 2025-10-21 05:19:43
- **Comment**: Proceedings of the 10th Machine Learning for Healthcare Conference,
  PMLR 298, 2025
- **Topic Keywords**: recommend, search
- **Reason**: This paper is not relevant to your research interests as it focuses on the impact of image resolution on biomedical multimodal large language models, which is outside the scope of information retrieval, search technologies, and natural language processing.

#### Abstract
> Imaging technologies are fundamental to biomedical research and modern
medicine, requiring analysis of high-resolution images across various
modalities. While multimodal large language models (MLLMs) show promise for
biomedical image analysis, most are designed for low-resolution images from
general-purpose datasets, risking critical information loss. We investigate how
image resolution affects MLLM performance in biomedical applications and
demonstrate that: (1) native-resolution training and inference significantly
improve performance across multiple tasks, (2) misalignment between training
and inference resolutions severely degrades performance, and (3)
mixed-resolution training effectively mitigates misalignment and balances
computational constraints with performance requirements. Based on these
findings, we recommend prioritizing native-resolution inference and
mixed-resolution datasets to optimize biomedical MLLMs for transformative
impact in scientific research and clinical applications.

### 42. Text or Pixels? It Takes Half: On the Token Efficiency of Visual Text Inputs in Multimodal LLMs

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yanhong Li, Zixuan Lan, Jiawei Zhou
- **URL**: <http://arxiv.org/abs/2510.18279v2>
- **Submitted**: 2025-10-21 04:07:20
- **Comment**: Accepted to EMNLP 2025 Findings ("Text or Pixels? Evaluating
  Efficiency and Understanding of LLMs with Visual Text Inputs")
- **Topic Keywords**: retrieval
- **Reason**: This paper explores the idea of compressing textual inputs by representing them as images, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves large language models, the focus is on input compression rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> Large language models (LLMs) and their multimodal variants can now process
visual inputs, including images of text. This raises an intriguing question:
can we compress textual inputs by feeding them as images to reduce token usage
while preserving performance? In this paper, we show that visual text
representations are a practical and surprisingly effective form of input
compression for decoder LLMs. We exploit the idea of rendering long text inputs
as a single image and provide it directly to the model. This leads to
dramatically reduced number of decoder tokens required, offering a new form of
input compression. Through experiments on two distinct benchmarks RULER
(long-context retrieval) and CNN/DailyMail (document summarization) we
demonstrate that this text-as-image method yields substantial token savings
(often nearly half) without degrading task performance.

### 43. Does Reasoning Help LLM Agents Play Dungeons and Dragons? A Prompt Engineering Experiment

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Patricia Delafuente, Arya Honraopatil, Lara J. Martin
- **URL**: <http://arxiv.org/abs/2510.18112v1>
- **Submitted**: 2025-10-20 21:23:23
- **Comment**: Published at the Wordplay: When Language Meets Games Workshop (EMNLP
  2025)
- **Topic Keywords**: rag
- **Reason**: This paper appears to be unrelated to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing, as it focuses on a specific application of Large Language Models in a game context.

#### Abstract
> This paper explores the application of Large Language Models (LLMs) and
reasoning to predict Dungeons & Dragons (DnD) player actions and format them as
Avrae Discord bot commands. Using the FIREBALL dataset, we evaluated a
reasoning model, DeepSeek-R1-Distill-LLaMA-8B, and an instruct model,
LLaMA-3.1-8B-Instruct, for command generation. Our findings highlight the
importance of providing specific instructions to models, that even single
sentence changes in prompts can greatly affect the output of models, and that
instruct models are sufficient for this task compared to reasoning models.

### 44. Chain-of-Thought Reasoning Improves Context-Aware Translation with Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Shabnam Ataee, Andrei Popescu-Belis
- **URL**: <http://arxiv.org/abs/2510.18077v1>
- **Submitted**: 2025-10-20 20:14:46
- **Topic Keywords**: rag
- **Reason**: This paper focuses on large language models for translation tasks, which is related to NLP, but does not directly align with the user's core research interests in Information Retrieval, query understanding, and ranking models. While it touches on deep semantic understanding, the context is translation rather than search or e-commerce. The paper's relevance is somewhat tangential to the user's primary research themes.

#### Abstract
> This paper assesses the capacity of large language models (LLMs) to translate
texts that include inter-sentential dependencies. We use the English-French
DiscEvalMT benchmark (Bawden et al., 2018) with pairs of sentences containing
translation challenges either for pronominal anaphora or for lexical cohesion.
We evaluate 12 LLMs from the DeepSeek-R1, GPT, Llama, Mistral and Phi families
on two tasks: (1) distinguishing a correct translation from a wrong but
plausible one; (2) generating a correct translation. We compare prompts that
encourage chain-of-thought reasoning with those that do not. The best models
take advantage of reasoning and reach about 90% accuracy on the first task, and
COMET scores of about 92% on the second task, with GPT-4, GPT-4o and Phi
standing out. Moreover, we observe a "wise get wiser" effect: the improvements
through reasoning are positively correlated with the scores of the models
without reasoning.

### 45. Is Multilingual LLM Watermarking Truly Multilingual? A Simple Back-Translation Solution

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Asim Mohamed, Martin Gubri
- **URL**: <http://arxiv.org/abs/2510.18019v1>
- **Submitted**: 2025-10-20 18:51:20
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to information retrieval, search technologies, or user behavior modeling, which are the core areas of your research interests. While it involves natural language processing, the focus is on watermarking large language models, which is a specific application in NLP. The paper's relevance to your broader interests in IR and related topics is limited.

#### Abstract
> Multilingual watermarking aims to make large language model (LLM) outputs
traceable across languages, yet current methods still fall short. Despite
claims of cross-lingual robustness, they are evaluated only on high-resource
languages. We show that existing multilingual watermarking methods are not
truly multilingual: they fail to remain robust under translation attacks in
medium- and low-resource languages. We trace this failure to semantic
clustering, which fails when the tokenizer vocabulary contains too few
full-word tokens for a given language. To address this, we introduce STEAM, a
back-translation-based detection method that restores watermark strength lost
through translation. STEAM is compatible with any watermarking method, robust
across different tokenizers and languages, non-invasive, and easily extendable
to new languages. With average gains of +0.19 AUC and +40%p TPR@1% on 17
languages, STEAM provides a simple and robust path toward fairer watermarking
across diverse languages.

### 46. Every Step Evolves: Scaling Reinforcement Learning for Trillion-Scale Thinking Model

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Ling Team, Anqi Shen, Baihui Li, Bin Hu, Bin Jing, Cai Chen, Chao Huang, Chao Zhang, Chaokun Yang, Cheng Lin, Chengyao Wen, Congqi Li, Deng Zhao, Dingbo Yuan, Donghai You, Fagui Mao, Fanzhuang Meng, Feng Xu, Guojie Li, Guowei Wang, Hao Dai, Haonan Zheng, Hong Liu, Jia Guo, Jiaming Liu, Jian Liu, Jianhao Fu, Jiannan Shi, Jianwen Wang, Jianxin Lai, Jin Yang, Jun Mei, Jun Zhou, Junbo Zhao, Junping Zhao, Kuan Xu, Le Su, Lei Chen, Li Tang, Liang Jiang, Liangcheng Fu, Lianhao Xu, Linfeng Shi, Lisha Liao, Longfei Zheng, Meng Li, Mingchun Chen, Qi Zuo, Qiang Cheng, Qianggang Cao, Qitao Shi, Quanrui Guo, Senlin Zhu, Shaofei Wang, Shaomian Zheng, Shuaicheng Li, Shuwei Gu, Siba Chen, Tao Wu, Tao Zhang, Tianyu Zhang, Tianyu Zhou, Tiwei Bie, Tongkai Yang, Wang Hong, Wang Ren, Weihua Chen, Wenbo Yu, Wengang Zheng, Xiangchun Wang, Xiaodong Yan, Xiaopei Wan, Xin Zhao, Xinyu Kong, Xinyu Tang, Xudong Han, Xudong Wang, Xuemin Yang, Xueyu Hu, Yalin Zhang, Yan Sun, Yicheng Shan, Yilong Wang, Yingying Xu, Yongkang Liu, Yongzhen Guo, Yuanyuan Wang, Yuchen Yan, Yuefan Wang, Yuhong Guo, Zehuan Li, Zhankai Xu, Zhe Li, Zhenduo Zhang, Zhengke Gui, Zhenxuan Pan, Zhenyu Huang, Zhenzhong Lan, Zhiqiang Ding, Zhiqiang Zhang, Zhixun Li, Zhizhen Liu, Zihao Wang, Zujie Wen
- **URL**: <http://arxiv.org/abs/2510.18855v1>
- **Submitted**: 2025-10-21 17:46:14
- **Comment**: Technical Report
- **Topic Keywords**: search
- **Reason**: This paper focuses on scaling reinforcement learning for a trillion-scale thinking model, which is not directly related to information retrieval, query understanding, or ranking models. While it involves large-scale model training, the context is more aligned with NLP and AI reasoning, but the specific innovations and applications do not seem to intersect with the user's core research themes.

#### Abstract
> We present Ring-1T, the first open-source, state-of-the-art thinking model
with a trillion-scale parameter. It features 1 trillion total parameters and
activates approximately 50 billion per token. Training such models at a
trillion-parameter scale introduces unprecedented challenges, including
train-inference misalignment, inefficiencies in rollout processing, and
bottlenecks in the RL system. To address these, we pioneer three interconnected
innovations: (1) IcePop stabilizes RL training via token-level discrepancy
masking and clipping, resolving instability from training-inference mismatches;
(2) C3PO++ improves resource utilization for long rollouts under a token budget
by dynamically partitioning them, thereby obtaining high time efficiency; and
(3) ASystem, a high-performance RL framework designed to overcome the systemic
bottlenecks that impede trillion-parameter model training. Ring-1T delivers
breakthrough results across critical benchmarks: 93.4 on AIME-2025, 86.72 on
HMMT-2025, 2088 on CodeForces, and 55.94 on ARC-AGI-v1. Notably, it attains a
silver medal-level result on the IMO-2025, underscoring its exceptional
reasoning capabilities. By releasing the complete 1T parameter MoE model to the
community, we provide the research community with direct access to cutting-edge
reasoning capabilities. This contribution marks a significant milestone in
democratizing large-scale reasoning intelligence and establishes a new baseline
for open-source model performance.

### 47. Dynamical model parameters from ultrasound tongue kinematics

- **LLM Score**: 0
- **Keyword Score**: 5
- **Authors**: Sam Kirkham, Patrycja Strycharczuk
- **URL**: <http://arxiv.org/abs/2510.18629v1>
- **Submitted**: 2025-10-21 13:34:13
- **Comment**: Accepted for publication in JASA Express Letters
- **Topic Keywords**: ltr, ctr
- **Reason**: This paper is unrelated to Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing, which are the primary areas of interest.

#### Abstract
> The control of speech can be modelled as a dynamical system in which
articulators are driven toward target positions. These models are typically
evaluated using fleshpoint data, such as electromagnetic articulography (EMA),
but recent methodological advances make ultrasound imaging a promising
alternative. We evaluate whether the parameters of a linear harmonic oscillator
can be reliably estimated from ultrasound tongue kinematics and compare these
with parameters estimated from simultaneously-recorded EMA data. We find that
ultrasound and EMA yield comparable dynamical parameters, while mandibular
short tendon tracking also adequately captures jaw motion. This supports using
ultrasound kinematics to evaluate dynamical articulatory models.

### 48. SafeCoop: Unravelling Full Stack Safety in Agentic Collaborative Driving

- **LLM Score**: 0
- **Keyword Score**: 3
- **Authors**: Xiangbo Gao, Tzu-Hsiang Lin, Ruojing Song, Yuheng Wu, Kuan-Ru Huang, Zicheng Jin, Fangzhou Lin, Shinan Liu, Zhengzhong Tu
- **URL**: <http://arxiv.org/abs/2510.18123v1>
- **Submitted**: 2025-10-20 21:41:28
- **Topic Keywords**: rag, search
- **Reason**: This paper is not related to Information Retrieval, Search technologies, or Natural Language Processing, which are the primary areas of interest. The paper focuses on collaborative driving systems and safety, which is outside the user's research domain.

#### Abstract
> Collaborative driving systems leverage vehicle-to-everything (V2X)
communication across multiple agents to enhance driving safety and efficiency.
Traditional V2X systems take raw sensor data, neural features, or perception
results as communication media, which face persistent challenges, including
high bandwidth demands, semantic loss, and interoperability issues. Recent
advances investigate natural language as a promising medium, which can provide
semantic richness, decision-level reasoning, and human-machine interoperability
at significantly lower bandwidth. Despite great promise, this paradigm shift
also introduces new vulnerabilities within language communication, including
message loss, hallucinations, semantic manipulation, and adversarial attacks.
In this work, we present the first systematic study of full-stack safety and
security issues in natural-language-based collaborative driving. Specifically,
we develop a comprehensive taxonomy of attack strategies, including connection
disruption, relay/replay interference, content spoofing, and multi-connection
forgery. To mitigate these risks, we introduce an agentic defense pipeline,
which we call SafeCoop, that integrates a semantic firewall,
language-perception consistency checks, and multi-source consensus, enabled by
an agentic transformation function for cross-frame spatial alignment. We
systematically evaluate SafeCoop in closed-loop CARLA simulation across 32
critical scenarios, achieving 69.15% driving score improvement under malicious
attacks and up to 67.32% F1 score for malicious detection. This study provides
guidance for advancing research on safe, secure, and trustworthy
language-driven collaboration in transportation systems. Our project page is
https://xiangbogaobarry.github.io/SafeCoop.

### 49. Adapting Language Balance in Code-Switching Speech

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Enes Yavuz Ugan, Ngoc-Quan Pham, Alexander Waibel
- **URL**: <http://arxiv.org/abs/2510.18724v1>
- **Submitted**: 2025-10-21 15:23:55
- **Comment**: Submitted to ICASSP 2026
- **Topic Keywords**: rag
- **Reason**: This paper focuses on adapting language balance in code-switching speech, which is a topic in Natural Language Processing (NLP). However, it does not relate to the user's core research interests in Information Retrieval (IR), Search technologies, query understanding, ranking models, or user behavior modeling.

#### Abstract
> Despite achieving impressive results on standard benchmarks, large
foundational models still struggle against code-switching test cases. When data
scarcity cannot be used as the usual justification for poor performance, the
reason may lie in the infrequent occurrence of code-switched moments, where the
embedding of the second language appears subtly. Instead of expecting the
models to learn this infrequency on their own, it might be beneficial to
provide the training process with labels. Evaluating model performance on
code-switching data requires careful localization of code-switching points
where recognition errors are most consequential, so that the analysis
emphasizes mistakes occurring at those moments. Building on this observation,
we leverage the difference between the embedded and the main language to
highlight those code-switching points and thereby emphasize learning at those
locations. This simple yet effective differentiable surrogate mitigates context
bias during generation -- the central challenge in code-switching -- thereby
improving the model's robustness. Our experiments with Arabic and
Chinese-English showed that the models are able to predict the switching places
more correctly, reflected by the reduced substitution error.

### 50. Saber: An Efficient Sampling with Adaptive Acceleration and Backtracking Enhanced Remasking for Diffusion Language Model

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Yihong Dong, Zhaoyu Ma, Xue Jiang, Zhiyuan Fan, Jiaru Qian, Yongmin Li, Jianha Xiao, Zhi Jin, Rongyu Cao, Binhua Li, Fei Huang, Yongbin Li, Ge Li
- **URL**: <http://arxiv.org/abs/2510.18165v1>
- **Submitted**: 2025-10-20 23:38:12
- **Topic Keywords**: rag
- **Reason**: This paper is about a novel sampling algorithm for diffusion language models, focusing on code generation tasks. It does not relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Diffusion language models (DLMs) are emerging as a powerful and promising
alternative to the dominant autoregressive paradigm, offering inherent
advantages in parallel generation and bidirectional context modeling. However,
the performance of DLMs on code generation tasks, which have stronger
structural constraints, is significantly hampered by the critical trade-off
between inference speed and output quality. We observed that accelerating the
code generation process by reducing the number of sampling steps usually leads
to a catastrophic collapse in performance. In this paper, we introduce
efficient Sampling with Adaptive acceleration and Backtracking Enhanced
Remasking (i.e., Saber), a novel training-free sampling algorithm for DLMs to
achieve better inference speed and output quality in code generation.
Specifically, Saber is motivated by two key insights in the DLM generation
process: 1) it can be adaptively accelerated as more of the code context is
established; 2) it requires a backtracking mechanism to reverse the generated
tokens. Extensive experiments on multiple mainstream code generation benchmarks
show that Saber boosts Pass@1 accuracy by an average improvement of 1.9% over
mainstream DLM sampling methods, meanwhile achieving an average 251.4%
inference speedup. By leveraging the inherent advantages of DLMs, our work
significantly narrows the performance gap with autoregressive models in code
generation.

---

