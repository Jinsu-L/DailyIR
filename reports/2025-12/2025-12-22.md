# Daily Papers Report - 2025-12-22

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Research on a hybrid LSTM-CNN-Attention model for text-based web content classification

- **LLM Score**: 8
- **Keyword Score**: 1
- **Authors**: Mykola Kuz, Ihor Lazarovych, Mykola Kozlenko, Mykola Pikuliak, Andrii Kvasniuk
- **URL**: <http://arxiv.org/abs/2512.18475v1>
- **Submitted**: 2025-12-20 19:38:07
- **Comment**: 10 pages, 5 figures, 2 tables. Accepted by Radio Electronics Computer Science Control 2025
- **Topic Keywords**: search
- **Reason**: This paper presents a deep learning architecture for text-based web content classification, leveraging LSTM, CNN, and Attention mechanisms. While primarily focused on NLP, the model's emphasis on real-time relevance optimization and semantic understanding aligns with your interests in Information Retrieval and Search technologies. The paper's findings on the effectiveness of hybrid deep learning approaches in NLP applications are also relevant to your research.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Advancements in computer science research, focusing on natural language processing (NLP), deep learning, machine learning, and cybersecurity applications.
- **Aim**: To synthesize recent innovations in NLP, deep learning architectures, and their applications in text analytics, phishing detection, and signal processing.
- **Rationale**: The compilation addresses the growing need for structured insights into interdisciplinary research, bridging foundational NLP techniques (e.g., word embeddings) with applied domains like cybersecurity and communications.
- **Ground**: Foundational works include word embeddings (GloVe, word2vec), attention mechanisms, convolutional neural networks (CNNs), and ensemble methods. Earlier studies (e.g., Zhang et al. 2016) on dependency-sensitive CNNs and recent works (2020‚Äì2025) on deep learning for phishing detection and signal processing form the basis.
- **Experiment**: Methods include CNNs for phishing detection (Gurumurthy et al. 2024), attention-based neural machine translation (Kang et al. 2022), deep contrastive learning (Giorgi et al. 2020), and ensemble learning for uncertainty estimation (Dutschmann et al. 2023). Signal processing applications involve CNNs for weak radio signal demodulation (Kozlenko et al. 2020, 2025).
- **Takeaway**: The research highlights the efficacy of deep learning in NLP tasks (e.g., text classification, sentiment analysis) and cybersecurity (phishing detection). Innovations in attention mechanisms, ensemble methods, and signal processing demonstrate interdisciplinary applications, underscoring the importance of foundational techniques like word embeddings and CNNs in modern AI.

#### Abstract
> This study presents a hybrid deep learning architecture that integrates LSTM, CNN, and an Attention mechanism to enhance the classification of web content based on text. Pretrained GloVe embeddings are used to represent words as dense vectors that preserve semantic similarity. The CNN layer extracts local n-gram patterns and lexical features, while the LSTM layer models long-range dependencies and sequential structure. The integrated Attention mechanism enables the model to focus selectively on the most informative parts of the input sequence. A 5-fold cross-validation setup was used to assess the robustness and generalizability of the proposed solution. Experimental results show that the hybrid LSTM-CNN-Attention model achieved outstanding performance, with an accuracy of 0.98, precision of 0.94, recall of 0.92, and F1-score of 0.93. These results surpass the performance of baseline models based solely on CNNs, LSTMs, or transformer-based classifiers such as BERT. The combination of neural network components enabled the model to effectively capture both fine-grained text structures and broader semantic context. Furthermore, the use of GloVe embeddings provided an efficient and effective representation of textual data, making the model suitable for integration into systems with real-time or near-real-time requirements. The proposed hybrid architecture demonstrates high effectiveness in text-based web content classification, particularly in tasks requiring both syntactic feature extraction and semantic interpretation. By combining presented mechanisms, the model addresses the limitations of individual architectures and achieves improved generalization. These findings support the broader use of hybrid deep learning approaches in NLP applications, especially where complex, unstructured textual data must be processed and classified with high reliability.

---

### 2. LIR$^3$AG: A Lightweight Rerank Reasoning Strategy Framework for Retrieval-Augmented Generation

- **LLM Score**: 6
- **Keyword Score**: 8
- **Authors**: Guo Chen, Junjie Huang, Huaijin Xie, Fei Sun, Tao Jia
- **URL**: <http://arxiv.org/abs/2512.18329v1>
- **Submitted**: 2025-12-20 11:53:37
- **Comment**: AAAI2026
- **Topic Keywords**: rerank, rag, retrieval, rank
- **Reason**: The paper explores Retrieval-Augmented Generation (RAG) and reasoning strategies for multi-hop QA tasks, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the focus on RAG and reasoning models is not a central match to your primary research themes, but it does touch on aspects of query understanding and ranking models.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: LIR3AG: A Dual-Module Retrieval-Augmented Generation Framework for Multi-Hop Question Answering
- **Aim**: Enhance non-reasoning large language models (LLMs) for multi-hop QA by introducing a dual-module architecture (Reranker and Reasoning Constructor) to simulate structured reasoning without explicit reasoning capabilities.
- **Rationale**: Existing non-reasoning LLMs struggle with multi-hop QA due to limited structured reasoning and reliance on retrieved contexts. LIR3AG addresses this by combining reranking for context filtering and a reasoning constructor to assemble evidence, improving accuracy and efficiency.
- **Ground**: Evaluated on four datasets (HotpotQA, 2WikiMultihopQA, MultiHop-RAG, MuSiQue) and compared against baselines (Direct Output, Vanilla RAG). Experiments use Qwen3 variants (8B, 32B) to assess performance, cost efficiency, and module contributions.
- **Experiment**: LIR3AG achieves state-of-the-art results on all datasets, outperforming baselines with significant improvements in Exact Match (EM) and F1 scores. Ablation studies confirm the necessity of both modules, while parameter sensitivity analysis highlights trade-offs between Top-k values, model size, and computational cost.
- **Takeaway**: LIR3AG demonstrates that non-reasoning LLMs can achieve robust multi-hop QA performance through structured reasoning simulation. Key contributions include cost efficiency, modular design, and reduced hallucinations. Future work includes integrating advanced RAG systems and optimizing efficiency.

#### Abstract
> Retrieval-Augmented Generation (RAG) effectively enhances Large Language Models (LLMs) by incorporating retrieved external knowledge into the generation process. Reasoning models improve LLM performance in multi-hop QA tasks, which require integrating and reasoning over multiple pieces of evidence across different documents to answer a complex question. However, they often introduce substantial computational costs, including increased token consumption and inference latency. To better understand and mitigate this trade-off, we conduct a comprehensive study of reasoning strategies for reasoning models in RAG multi-hop QA tasks. Our findings reveal that reasoning models adopt structured strategies to integrate retrieved and internal knowledge, primarily following two modes: Context-Grounded Reasoning, which relies directly on retrieved content, and Knowledge-Reconciled Reasoning, which resolves conflicts or gaps using internal knowledge. To this end, we propose a novel Lightweight Rerank Reasoning Strategy Framework for RAG (LiR$^3$AG) to enable non-reasoning models to transfer reasoning strategies by restructuring retrieved evidence into coherent reasoning chains. LiR$^3$AG significantly reduce the average 98% output tokens overhead and 58.6% inferencing time while improving 8B non-reasoning model's F1 performance ranging from 6.2% to 22.5% to surpass the performance of 32B reasoning model in RAG, offering a practical and efficient path forward for RAG systems.

---

### 3. Factorized Transport Alignment for Multimodal and Multiview E-commerce Representation Learning

- **LLM Score**: 6
- **Keyword Score**: 8
- **Authors**: Xiwen Chen, Yen-Chieh Lien, Susan Liu, Mar√≠a Casta√±os, Abolfazl Razi, Xiaoting Zhao, Congzhe Su
- **URL**: <http://arxiv.org/abs/2512.18117v1>
- **Submitted**: 2025-12-19 22:50:49
- **Comment**: Accepted by WSDM'26
- **Topic Keywords**: query, retrieval, commerce, e-commerce, search
- **Reason**: This paper proposes a framework for multimodal and multi-view representation learning in e-commerce, which is somewhat related to your interests in Information Retrieval and Search technologies. While it focuses on e-commerce, it explores a specific aspect of query understanding and ranking models, but its primary contribution is in representation learning rather than deep semantic understanding or real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Advancing multimodal learning and vision-language models for real-world applications like ad personalization and e-commerce, with a focus on transfer learning, multilingual support, and scalable deployment.
- **Aim**: To develop robust, adaptable vision-language models and foundation models that address cross-modal alignment, multilingual generalization, and efficient adaptation for industrial-scale tasks.
- **Rationale**: Current challenges in cross-modal alignment, domain-specific adaptation, and multilingual support necessitate novel methods like optimal transport, low-rank adaptations (LORA), and data augmentation to bridge theoretical advancements with practical implementations in systems such as Meta‚Äôs ads and Amazon‚Äôs visual search.
- **Ground**: Foundational work includes CLIP-based models, multilingual embeddings via LORA, and techniques like augmentation, weighting, and transportation. These build on prior research in transfer learning, optimal transport, and low-rank methods to unify multimodal architectures.
- **Experiment**: Applications include Meta‚Äôs user representation for ad personalization, Amazon‚Äôs multimodal visual search system, and e-commerce product embeddings. Experiments validate improvements in cross-modal alignment, multilingual performance, and scalable reranking systems.
- **Takeaway**: The works collectively demonstrate the efficacy of transfer learning, optimal transport, and low-rank adaptations in achieving efficient, domain-aware models. They highlight the importance of unifying multimodal architectures and deploying them in real-world systems, as evidenced by their publication in ICML, PMLR, arXiv, and the ACM Web Conference.

#### Abstract
> The rapid growth of e-commerce requires robust multimodal representations that capture diverse signals from user-generated listings. Existing vision-language models (VLMs) typically align titles with primary images, i.e., single-view, but overlook non-primary images and auxiliary textual views that provide critical semantics in open marketplaces such as Etsy or Poshmark. To this end, we propose a framework that unifies multimodal and multi-view learning through Factorized Transport, a lightweight approximation of optimal transport, designed for scalability and deployment efficiency. During training, the method emphasizes primary views while stochastically sampling auxiliary ones, reducing training cost from quadratic in the number of views to constant per item. At inference, all views are fused into a single cached embedding, preserving the efficiency of two-tower retrieval with no additional online overhead. On an industrial dataset of 1M product listings and 0.3M interactions, our approach delivers consistent improvements in cross-view and query-to-item retrieval, achieving up to +7.9% Recall@500 over strong multimodal baselines. Overall, our framework bridges scalability with optimal transport-based learning, making multi-view pretraining practical for large-scale e-commerce search.

---

### 4. InstructNet: A Novel Approach for Multi-Label Instruction Classification through Advanced Deep Learning

- **LLM Score**: 6
- **Keyword Score**: 3
- **Authors**: Tanjim Taharat Aurpa, Md Shoaib Ahmed, Md Mahbubur Rahman, Md. Golam Moazzam
- **URL**: <http://arxiv.org/abs/2512.18301v1>
- **Submitted**: 2025-12-20 10:16:09
- **Topic Keywords**: rag, search
- **Reason**: This paper explores multi-label instruction classification, which is related to query understanding and ranking models in Information Retrieval. However, the focus on instructional text categorization and deep learning architectures, while relevant to NLP, does not directly align with the user's primary research interests in search technologies and real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Multilabel Instructional Text Classification Using Transformer Models
- **Aim**: To address class imbalance and sparse data in multilabel classification through transformer-based models (BERT, XLNet) and LSTM, validated on the HowSumm dataset.
- **Rationale**: Class imbalance and sparse label distributions in instructional texts hinder model performance. Transformer architectures (e.g., BERT, XLNet) and permutation-based training (XLNet) offer solutions for long-text processing and underrepresented labels.
- **Ground**: The HowSumm dataset (11,121 observations, 6,000+ labels) is filtered to retain 67 underrepresented labels (‚â•500 instances). Binary vectors (67-dimensional 0/1 arrays) encode labels, with sigmoid activation and binary cross-entropy loss. Metrics include binary accuracy, macro/micro F1, precision, and recall.
- **Experiment**: XLNet achieves 97.30% accuracy on HowSumm, outperforming BERT (97.17%), ELECTRA, RoBERTa, and LSTM. Training uses AdamW optimizer (learning rates: 5e-04 for BERT, 4e-04 for XLNet), batch size 48, and max sequence length 512. XLNet‚Äôs permutation-based training handles sequences beyond 512 tokens. The framework is validated on arXiv, Twitter, and Toxic Comment datasets.
- **Takeaway**: XLNet/BERT-based models with optimized hyperparameters and label filtering achieve state-of-the-art results in multilabel classification. The framework adapts to diverse domains (instructional texts, toxic comments) and highlights the need for label-semantic-aware pre-training and model compression in future work.

#### Abstract
> People use search engines for various topics and items, from daily essentials to more aspirational and specialized objects. Therefore, search engines have taken over as peoples preferred resource. The How To prefix has become familiar and widely used in various search styles to find solutions to particular problems. This search allows people to find sequential instructions by providing detailed guidelines to accomplish specific tasks. Categorizing instructional text is also essential for task-oriented learning and creating knowledge bases. This study uses the How To articles to determine the multi-label instruction category. We have brought this work with a dataset comprising 11,121 observations from wikiHow, where each record has multiple categories. To find out the multi-label category meticulously, we employ some transformer-based deep neural architectures, such as Generalized Autoregressive Pretraining for Language Understanding (XLNet), Bidirectional Encoder Representation from Transformers (BERT), etc. In our multi-label instruction classification process, we have reckoned our proposed architectures using accuracy and macro f1-score as the performance metrics. This thorough evaluation showed us much about our strategys strengths and drawbacks. Specifically, our implementation of the XLNet architecture has demonstrated unprecedented performance, achieving an accuracy of 97.30% and micro and macro average scores of 89.02% and 93%, a noteworthy accomplishment in multi-label classification. This high level of accuracy and macro average score is a testament to the effectiveness of the XLNet architecture in our proposed InstructNet approach. By employing a multi-level strategy in our evaluation process, we have gained a more comprehensive knowledge of the effectiveness of our proposed architectures and identified areas for forthcoming improvement and refinement.

---

### 5. Improving Data Reusability in Interactive Information Retrieval: Insights from the Community

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Tianji Jiang, Wenqi Li, Jiqun Liu
- **URL**: <http://arxiv.org/abs/2512.18283v1>
- **Submitted**: 2025-12-20 09:12:33
- **Comment**: Accepted by CHIIR 2025
- **Topic Keywords**: information retrieval, retrieval, search
- **Reason**: The paper is somewhat related to Information Retrieval (IR) but focuses on data reusability and community practices, which is not a central match to your primary research interests in query understanding, ranking models, and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Data sharing and reuse in Interactive Information Retrieval (IIR), focusing on informal community practices and barriers to effective data reuse.
- **Aim**: To identify challenges and opportunities for improving data reusability in IIR by analyzing community practices and proposing infrastructure solutions.
- **Rationale**: Informal community practices (e.g., conferences, publications) dominate data discovery and validation in IIR, but fragmented resources and poor documentation hinder reuse. Addressing these gaps can enhance collaboration and innovation.
- **Ground**: The study is based on semi-structured interviews and self-reported data from IIR researchers, with planned future work involving on-site observations. References include foundational works on IIR, data evaluation, and experimental methodologies.
- **Experiment**: Methods include semi-structured interviews and analysis of self-reported data, with limitations acknowledged (e.g., potential bias). Future experiments will incorporate on-site observations to validate findings.
- **Takeaway**: Knowledge infrastructures should leverage existing community practices to improve data visibility, persistence, and accessibility, fostering sustainable and ethical data reuse in IIR.

#### Abstract
> In this study, we conducted semi-structured interviews with 21 IIR researchers to investigate their data reuse practices. This study aims to expand upon current findings by exploring IIR researchers' information-obtaining behaviors regarding data reuse. We identified the information about shared data characteristics that IIR researchers need when evaluating data reusability, as well as the sources they typically consult to obtain this information. We consider this work to be an initial step toward revealing IIR researchers' data reuse practices and identifying what the community needs to do to promote data reuse. We hope that this study, as well as future research, will inspire more individuals to contribute to ongoing efforts aimed at designing standards, infrastructures, and policies, as well as fostering a sustainable culture of data sharing and reuse in this field.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. CIRR: Causal-Invariant Retrieval-Augmented Recommendation with Faithful Explanations under Distribution Shift

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Sebastian Sun
- **URL**: <http://arxiv.org/abs/2512.18683v1>
- **Submitted**: 2025-12-21 10:41:05
- **Topic Keywords**: rag, retrieval, recommend
- **Reason**: The paper explores retrieval-augmented recommendation systems, which is related to your interests in Information Retrieval and Search technologies. However, the focus on causal inference and faithful explanations, while interesting, is not directly aligned with your core research themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> Recent advances in retrieval-augmented generation (RAG) have shown promise in enhancing recommendation systems with external knowledge. However, existing RAG-based recommenders face two critical challenges: (1) vulnerability to distribution shifts across different environments (e.g., time periods, user segments), leading to performance degradation in out-of-distribution (OOD) scenarios, and (2) lack of faithful explanations that can be verified against retrieved evidence. In this paper, we propose CIRR, a Causal-Invariant Retrieval-Augmented Recommendation framework that addresses both challenges simultaneously. CIRR learns environment-invariant user preference representations through causal inference, which guide a debiased retrieval process to select relevant evidence from multiple sources. Furthermore, we introduce consistency constraints that enforce faithfulness between retrieved evidence, generated explanations, and recommendation outputs. Extensive experiments on two real-world datasets demonstrate that CIRR achieves robust performance under distribution shifts, reducing performance degradation from 15.4% (baseline) to only 5.6% in OOD scenarios, while providing more faithful and interpretable explanations (26% improvement in faithfulness score) compared to state-of-the-art baselines.

### 7. A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Thanh Dat Hoang, Thanh Trung Huynh, Matthias Weidlich, Thanh Tam Nguyen, Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen
- **URL**: <http://arxiv.org/abs/2512.18622v1>
- **Submitted**: 2025-12-21 06:43:47
- **Topic Keywords**: queries
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Information Retrieval (IR), but it primarily focuses on the Text2SQL task, which is not a central match to your core research themes. The use of small language models and multi-agent mechanisms is an interesting aspect, but it does not directly relate to query understanding, ranking models, or user behavior modeling.

#### Abstract
> Text2SQL, the task of generating SQL queries from natural language text, is a critical challenge in data engineering. Recently, Large Language Models (LLMs) have demonstrated superior performance for this task due to their advanced comprehension and generation capabilities. However, privacy and cost considerations prevent companies from using Text2SQL solutions based on external LLMs offered as a service. Rather, small LLMs (SLMs) that are openly available and can hosted in-house are adopted. These SLMs, in turn, lack the generalization capabilities of larger LLMs, which impairs their effectiveness for complex tasks such as Text2SQL. To address these limitations, we propose MATS, a novel Text2SQL framework designed specifically for SLMs. MATS uses a multi-agent mechanism that assigns specialized roles to auxiliary agents, reducing individual workloads and fostering interaction. A training scheme based on reinforcement learning aligns these agents using feedback obtained during execution, thereby maintaining competitive performance despite a limited LLM size. Evaluation results using on benchmark datasets show that MATS, deployed on a single- GPU server, yields accuracy that are on-par with large-scale LLMs when using significantly fewer parameters. Our source code and data are available at https://github.com/thanhdath/mats-sql.

### 8. From Word to World: Can Large Language Models be Implicit Text-based World Models?

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Yixia Li, Hongru Wang, Jiahao Qiu, Zhenfei Yin, Dongdong Zhang, Cheng Qian, Zeping Li, Pony Ma, Guanhua Chen, Heng Ji, Mengdi Wang
- **URL**: <http://arxiv.org/abs/2512.18832v1>
- **Submitted**: 2025-12-21 17:28:42
- **Topic Keywords**: rag
- **Reason**: This paper explores the application of large language models as world models in text-based environments, which is somewhat related to information retrieval and search technologies. However, the focus on reinforcement learning and world modeling is not directly aligned with the user's core research themes in query understanding, ranking models, and user behavior modeling. The connection to natural language processing is more relevant, but still not a central match.

#### Abstract
> Agentic reinforcement learning increasingly relies on experience-driven scaling, yet real-world environments remain non-adaptive, limited in coverage, and difficult to scale. World models offer a potential way to improve learning efficiency through simulated experience, but it remains unclear whether large language models can reliably serve this role and under what conditions they meaningfully benefit agents. We study these questions in text-based environments, which provide a controlled setting to reinterpret language modeling as next-state prediction under interaction. We introduce a three-level framework for evaluating LLM-based world models: (i) fidelity and consistency, (ii) scalability and robustness, and (iii) agent utility. Across five representative environments, we find that sufficiently trained world models maintain coherent latent state, scale predictably with data and model size, and improve agent performance via action verification, synthetic trajectory generation, and warm-starting reinforcement learning. Meanwhile, these gains depend critically on behavioral coverage and environment complexity, delineating clear boundry on when world modeling effectively supports agent learning.

### 9. InSight-o3: Empowering Multimodal Foundation Models with Generalized Visual Search

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Kaican Li, Lewei Yao, Jiannan Wu, Tiezheng Yu, Jierun Chen, Haoli Bai, Lu Hou, Lanqing Hong, Wei Zhang, Nevin L. Zhang
- **URL**: <http://arxiv.org/abs/2512.18745v1>
- **Submitted**: 2025-12-21 14:23:07
- **Topic Keywords**: search
- **Reason**: The paper explores multimodal reasoning and visual search, which is somewhat related to information retrieval and search technologies. However, the focus on multimodal foundation models and visual search is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling. While it touches on deep semantic understanding, the context is different from the user's core research themes.

#### Abstract
> The ability for AI agents to "think with images" requires a sophisticated blend of reasoning and perception. However, current open multimodal agents still largely fall short on the reasoning aspect crucial for real-world tasks like analyzing documents with dense charts/diagrams and navigating maps. To address this gap, we introduce O3-Bench, a new benchmark designed to evaluate multimodal reasoning with interleaved attention to visual details. O3-Bench features challenging problems that require agents to piece together subtle visual information from distinct image areas through multi-step reasoning. The problems are highly challenging even for frontier systems like OpenAI o3, which only obtains 40.8% accuracy on O3-Bench. To make progress, we propose InSight-o3, a multi-agent framework consisting of a visual reasoning agent (vReasoner) and a visual search agent (vSearcher) for which we introduce the task of generalized visual search -- locating relational, fuzzy, or conceptual regions described in free-form language, beyond just simple objects or figures in natural images. We then present a multimodal LLM purpose-trained for this task via reinforcement learning. As a plug-and-play agent, our vSearcher empowers frontier multimodal models (as vReasoners), significantly improving their performance on a wide range of benchmarks. This marks a concrete step towards powerful o3-like open systems. Our code and dataset can be found at https://github.com/m-Just/InSight-o3 .

### 10. AraToken: Optimizing Arabic Tokenization with Normalization Pipeline and Language Extension for Qwen3

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Mark Kashirskiy, Artiom Lipinski, Ilya Makarov
- **URL**: <http://arxiv.org/abs/2512.18399v1>
- **Submitted**: 2025-12-20 15:32:10
- **Comment**: 8 pages, 8 figures, 5 tables
- **Topic Keywords**: search
- **Reason**: This paper is somewhat related to Information Retrieval and Natural Language Processing, but its focus on Arabic tokenization and language extension is not directly aligned with the user's core research themes. While it touches on the importance of preprocessing steps for large language models, the specific application to Arabic languages and tokenization algorithms is not a central match for the user's interests.

#### Abstract
> Tokenization is a critical preprocessing step for large language models (LLMs), directly impacting training efficiency and downstream performance. General-purpose tokenizers trained predominantly on English and Latin-script languages exhibit suboptimal performance on morphologically rich languages such as Arabic, resulting in inflated token sequences and reduced compression efficiency. In this work, we present AraToken, an Arabic-optimized tokenizer built on SentencePiece Unigram algorithm with a comprehensive normalization pipeline addressing Arabic-specific orthographic variations including Alif variants, diacritics, and Arabic-Indic numerals. We systematically compare BPE, WordPiece, and SentencePiece algorithms across multiple configurations, demonstrating that SentencePiece with normalization achieves 18% lower fertility (1.199 vs 1.35 tokens/word) compared to unnormalized baselines. Furthermore, we introduce the Language Extension Pipeline (LEP), a method for integrating the optimized tokenizer into Qwen3-0.6B through vocabulary extension with mean subtoken initialization and selective transformer layer unfreezing. Our experiments show that LEP reduces evaluation loss from 8.28 to 2.43 within 800 training steps on 100K Arabic samples. We release our tokenizer, training scripts, and model checkpoints to facilitate Arabic NLP research.

### 11. Datasets for machine learning and for assessing the intelligence level of automatic patent search systems

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Boris Genin, Alexander Gorbunov, Dmitry Zolkin, Igor Nekrasov
- **URL**: <http://arxiv.org/abs/2512.18384v1>
- **Submitted**: 2025-12-20 14:51:57
- **Comment**: 14 pages, 3 figures, 2 tables
- **Topic Keywords**: search
- **Reason**: The paper discusses the development of datasets for machine learning in the context of patent search systems, which is somewhat related to information retrieval. However, the focus is on patent search and prior art identification, which is not a central match to the user's core research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> The key to success in automating prior art search in patent research using artificial intelligence lies in developing large datasets for machine learning and ensuring their availability. This work is dedicated to providing a comprehensive solution to the problem of creating infrastructure for research in this field, including datasets and tools for calculating search quality criteria. The paper discusses the concept of semantic clusters of patent documents that determine the state of the art in a given subject, as proposed by the authors. A definition of such semantic clusters is also provided. Prior art search is presented as the task of identifying elements within a semantic cluster of patent documents in the subject area specified by the document under consideration. A generator of user-configurable datasets for machine learning, based on collections of U.S. and Russian patent documents, is described. The dataset generator creates a database of links to documents in semantic clusters. Then, based on user-defined parameters, it forms a dataset of semantic clusters in JSON format for machine learning. To evaluate machine learning outcomes, it is proposed to calculate search quality scores that account for semantic clusters of the documents being searched. To automate the evaluation process, the paper describes a utility developed by the authors for assessing the quality of prior art document search.

### 12. From Natural Language to Control Signals: A Conceptual Framework for Semantic Channel Finding in Complex Experimental Infrastructure

- **LLM Score**: 2
- **Keyword Score**: 11
- **Authors**: Thorsten Hellert, Nikolay Agladze, Alex Giovannone, Jan Jug, Frank Mayet, Mark Sherwin, Antonin Sulc, Chris Tennant
- **URL**: <http://arxiv.org/abs/2512.18779v1>
- **Submitted**: 2025-12-21 15:46:33
- **Topic Keywords**: semantic search, queries, rag, ctr, search
- **Reason**: This paper is not directly related to your core research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves semantic understanding and mapping natural-language intent to concrete signals, the context is specific to complex experimental infrastructure and control systems, which is not a primary focus of your research.

#### Abstract
> Modern experimental platforms such as particle accelerators, fusion devices, telescopes, and industrial process control systems expose tens to hundreds of thousands of control and diagnostic channels accumulated over decades of evolution. Operators and AI systems rely on informal expert knowledge, inconsistent naming conventions, and fragmented documentation to locate signals for monitoring, troubleshooting, and automated control, creating a persistent bottleneck for reliability, scalability, and language-model-driven interfaces. We formalize semantic channel finding-mapping natural-language intent to concrete control-system signals-as a general problem in complex experimental infrastructure, and introduce a four-paradigm framework to guide architecture selection across facility-specific data regimes. The paradigms span (i) direct in-context lookup over curated channel dictionaries, (ii) constrained hierarchical navigation through structured trees, (iii) interactive agent exploration using iterative reasoning and tool-based database queries, and (iv) ontology-grounded semantic search that decouples channel meaning from facility-specific naming conventions. We demonstrate each paradigm through proof-of-concept implementations at four operational facilities spanning two orders of magnitude in scale-from compact free-electron lasers to large synchrotron light sources-and diverse control-system architectures, from clean hierarchies to legacy environments. These implementations achieve 90-97% accuracy on expert-curated operational queries.

### 13. TICL+: A Case Study On Speech In-Context Learning for Children's Speech Recognition

- **LLM Score**: 2
- **Keyword Score**: 9
- **Authors**: Haolong Zheng, Yekaterina Yegorova, Mark Hasegawa-Johnson
- **URL**: <http://arxiv.org/abs/2512.18263v1>
- **Submitted**: 2025-12-20 08:03:07
- **Comment**: Published at IEEE ASRU 2025 Satellite Workshop-AI for Children's Speech and Language
- **Topic Keywords**: ranking, rerank, retrieval, rank
- **Reason**: This paper focuses on speech recognition for children, using a retrieval-based method for Speech In-Context Learning. While it involves semantic and acoustic alignment, it is not directly related to information retrieval, search technologies, or user behavior modeling, which are the core areas of your research interests.

#### Abstract
> Children's speech recognition remains challenging due to substantial acoustic and linguistic variability, limited labeled data, and significant differences from adult speech. Speech foundation models can address these challenges through Speech In-Context Learning (SICL), allowing adaptation to new domains without fine-tuning. However, the effectiveness of SICL depends on how in-context examples are selected. We extend an existing retrieval-based method, Text-Embedding KNN for SICL (TICL), introducing an acoustic reranking step to create TICL+. This extension prioritizes examples that are both semantically and acoustically aligned with the test input. Experiments on four children's speech corpora show that TICL+ achieves up to a 53.3% relative word error rate reduction over zero-shot performance and 37.6% over baseline TICL, highlighting the value of combining semantic and acoustic information for robust, scalable ASR in children's speech.

### 14. Remedy-R: Generative Reasoning for Machine Translation Evaluation without Error Annotations

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Shaomu Tan, Ryosuke Mitani, Ritvik Choudhary, Qiyu Wu, Toshiyuki Sekiya, Christof Monz
- **URL**: <http://arxiv.org/abs/2512.18906v1>
- **Submitted**: 2025-12-21 22:37:38
- **Topic Keywords**: pairwise, rag
- **Reason**: This paper is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves machine translation and evaluation, the focus is on generative reasoning for machine translation evaluation, which is not a central match to your research themes.

#### Abstract
> Over the years, automatic MT metrics have hillclimbed benchmarks and presented strong and sometimes human-level agreement with human ratings. Yet they remain black-box, offering little insight into their decision-making and often failing under real-world out-of-distribution (OOD) inputs. We introduce Remedy-R, a reasoning-driven generative MT metric trained with reinforcement learning from pairwise translation preferences, without requiring error-span annotations or distillation from closed LLMs. Remedy-R produces step-by-step analyses of accuracy, fluency, and completeness, followed by a final score, enabling more interpretable assessments. With only 60K training pairs across two language pairs, Remedy-R remains competitive with top scalar metrics and GPT-4-based judges on WMT22-24 meta-evaluation, generalizes to other languages, and exhibits strong robustness on OOD stress tests. Moreover, Remedy-R models generate self-reflective feedback that can be reused for translation improvement. Building on this finding, we introduce Remedy-R Agent, a simple evaluate-revise pipeline that leverages Remedy-R's evaluation analysis to refine translations. This agent consistently improves translation quality across diverse models, including Qwen2.5, ALMA-R, GPT-4o-mini, and Gemini-2.0-Flash, suggesting that Remedy-R's reasoning captures translation-relevant information and is practically useful.

### 15. brat: Aligned Multi-View Embeddings for Brain MRI Analysis

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Maxime Kayser, Maksim Gridnev, Wanting Wang, Max Bain, Aneesh Rangnekar, Avijit Chatterjee, Aleksandr Petrov, Harini Veeraraghavan, Nathaniel C. Swinburne
- **URL**: <http://arxiv.org/abs/2512.18679v1>
- **Submitted**: 2025-12-21 10:37:31
- **Comment**: First round accept at WACV 2026
- **Topic Keywords**: query, retrieval
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions a multi-view pre-training approach inspired by document retrieval, the context is in the domain of brain MRI analysis, which is unrelated to your e-commerce background and focus on deep semantic understanding and real-time relevance optimization.

#### Abstract
> We present brat (brain report alignment transformer), a multi-view representation learning framework for brain magnetic resonance imaging (MRI) trained on MRIs paired with clinical reports. Brain MRIs present unique challenges due to the presence of numerous, highly varied, and often subtle abnormalities that are localized to a few slices within a 3D volume. To address these challenges, we introduce a brain MRI dataset $10\times$ larger than existing ones, containing approximately 80,000 3D scans with corresponding radiology reports, and propose a multi-view pre-training approach inspired by advances in document retrieval. We develop an implicit query-feature matching mechanism and adopt concepts from quality-diversity to obtain multi-view embeddings of MRIs that are aligned with the clinical features given by report sentences. We evaluate our approach across multiple vision-language and vision tasks, demonstrating substantial performance improvements. The brat foundation models are publicly released.

### 16. DACE For Railway Acronym Disambiguation

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: El Mokhtar Hribach, Oussama Mechhour, Mohammed Elmonstaser, Yassine El Boudouri, Othmane Kabal
- **URL**: <http://arxiv.org/abs/2512.18357v1>
- **Submitted**: 2025-12-20 12:56:06
- **Topic Keywords**: retrieval augmented generation, retrieval, rank
- **Reason**: This paper focuses on Acronym Disambiguation in the context of railway documentation, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves Large Language Models and ensemble predictions, the specific application and goal of the paper do not align with the user's interests.

#### Abstract
> Acronym Disambiguation (AD) is a fundamental challenge in technical text processing, particularly in specialized sectors where high ambiguity complicates automated analysis. This paper addresses AD within the context of the TextMine'26 competition on French railway documentation. We present DACE (Dynamic Prompting, Retrieval Augmented Generation, Contextual Selection, and Ensemble Aggregation), a framework that enhances Large Language Models through adaptive in-context learning and external domain knowledge injection. By dynamically tailoring prompts to acronym ambiguity and aggregating ensemble predictions, DACE mitigates hallucination and effectively handles low-resource scenarios. Our approach secured the top rank in the competition with an F1 score of 0.9069.

### 17. Neologism Learning as a Parameter-Efficient Alternative to Fine-Tuning for Model Steering

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Sungjoon Park, Varun Ramamurthi, Owen Terry
- **URL**: <http://arxiv.org/abs/2512.18551v1>
- **Submitted**: 2025-12-21 00:45:23
- **Topic Keywords**: rag, rank
- **Reason**: This paper appears to be focused on language modeling and model steering, which is somewhat related to your interests in NLP and query understanding. However, the specific topic of neologism learning and model steering does not seem to align closely with your core research themes in Information Retrieval and Search technologies.

#### Abstract
> In language modeling, neologisms are new tokens trained to represent a concept not already included in a given model's vocabulary. Neologisms can be used to encourage specific behavior in models, for example by appending prompts with "Give me a neologism answer." Behavioral steering can also be achieved through fine-tuning, albeit with more compute and less flexibility: learning a neologism only trains d parameters and allows the user to still access the model's default behavior. We compare the performance of neologism learning against low-rank adaptation (LoRA) fine-tuning, finding that neologisms outperform fine-tuned models under a matched training setup (same data and hyperparameters). We also investigate self-verbalizations of neologisms, and observe that the model will occasionally make up its own new words when asked about a neologism.

### 18. Efficient Optimization of Hierarchical Identifiers for Generative Recommendation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Federica Valeau, Odysseas Boufalis, Polytimi Gkotsi, Joshua Rosenthal, David Vos
- **URL**: <http://arxiv.org/abs/2512.18434v1>
- **Submitted**: 2025-12-20 17:21:41
- **Comment**: Accepted at ECIR 2026 Reproducibility Track (to appear)
- **Topic Keywords**: retrieval, recommend
- **Reason**: This paper focuses on generative recommendation and retrieval quality, but it does not align with the user's primary research interests in Information Retrieval, particularly query understanding, ranking models, and user behavior modeling. Although it touches on retrieval quality, the context is recommendation systems, which is a related but secondary interest. The paper's emphasis on tree construction and optimization does not seem to require deep semantic understanding or real-time relevance optimization.

#### Abstract
> SEATER is a generative retrieval model that improves recommendation inference efficiency and retrieval quality by utilizing balanced tree-structured item identifiers and contrastive training objectives. We reproduce and validate SEATER's reported improvements in retrieval quality over strong baselines across all datasets from the original work, and extend the evaluation to Yambda, a large-scale music recommendation dataset. Our experiments verify SEATER's strong performance, but show that its tree construction step during training becomes a major bottleneck as the number of items grows. To address this, we implement and evaluate two alternative construction algorithms: a greedy method optimized for minimal build time, and a hybrid method that combines greedy clustering at high levels with more precise grouping at lower levels. The greedy method reduces tree construction time to less than 2% of the original with only a minor drop in quality on the dataset with the largest item collection. The hybrid method achieves retrieval quality on par with the original, and even improves on the largest dataset, while cutting construction time to just 5-8%. All data and code are publicly available for full reproducibility at https://github.com/joshrosie/re-seater.

### 19. FASTRIC: Prompt Specification Language for Verifiable LLM Interactions

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Wen-Long Jin
- **URL**: <http://arxiv.org/abs/2512.18940v1>
- **Submitted**: 2025-12-22 01:19:50
- **Comment**: 13 pages, 3 figures. Supplementary materials at https://doi.org/10.17605/OSF.IO/PV6R3
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Large Language Models (LLMs) and their interactions, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context and application are quite different from your areas of focus.

#### Abstract
> Large Language Models (LLMs) execute complex multi-turn interaction protocols but lack formal specifications to verify execution against designer intent. We introduce FASTRIC, a Prompt Specification Language that makes implicit Finite State Machines (FSMs) explicit in natural language prompts, enabling conformance verification through execution trace analysis. The LLM serves as intelligent execution agent: interpreting designer-encoded FSMs to execute specified behavioral roles. Unlike symbolic specification languages requiring parsers and compilers, FASTRIC leverages LLMs as unified infrastructure-simultaneously parser, interpreter, runtime environment, and development assistant. FASTRIC guides designers to articulate seven FSM elements (Final States, Agents, States, Triggers, Roles, Initial State, Constraints) structuring multi-turn interactions. Specification formality-ranging from implicit descriptions that frontier models infer to explicit step-by-step instructions for weaker models-serves as a design parameter. We introduce procedural conformance as verification metric measuring execution adherence to FSM specifications. Testing a 3-state kindergarten tutoring FSM across four formality levels and three model scales (14.7B, 685B, 1T+ parameters) reveals optimal specification formality is a function of model capacity. DeepSeek-V3.2 (685B) achieves perfect conformance (1.00) at L2-L4; ChatGPT-5 (~1T) peaks at L3 (0.90) before collapsing at L4 (0.39); Phi4 (14.7B) shows no stable optimum with high variance (SD=0.16-0.36). These findings reveal model-specific formality ranges-"Goldilocks zones"-where specifications provide sufficient structure without over-constraint, establishing Prompt Specification Engineering for creating verifiable interaction protocols, transforming multi-turn interaction design from heuristic art to systematic engineering with measurable procedural guarantees.

### 20. Explainable Transformer-CNN Fusion for Noise-Robust Speech Emotion Recognition

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sudip Chakrabarty, Pappu Bishwas, Rajdeep Chatterjee
- **URL**: <http://arxiv.org/abs/2512.18298v1>
- **Submitted**: 2025-12-20 10:05:58
- **Topic Keywords**: ctr
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topic of Speech Emotion Recognition and noise-robust speech processing is outside your primary focus areas, and the paper's methods and techniques are not directly applicable to your research themes.

#### Abstract
> Speech Emotion Recognition (SER) systems often degrade in performance when exposed to the unpredictable acoustic interference found in real-world environments. Additionally, the opacity of deep learning models hinders their adoption in trust-sensitive applications. To bridge this gap, we propose a Hybrid Transformer-CNN framework that unifies the contextual modeling of Wav2Vec 2.0 with the spectral stability of 1D-Convolutional Neural Networks. Our dual-stream architecture processes raw waveforms to capture long-range temporal dependencies while simultaneously extracting noise-resistant spectral features (MFCC, ZCR, RMSE) via a custom Attentive Temporal Pooling mechanism. We conducted extensive validation across four diverse benchmark datasets: RAVDESS, TESS, SAVEE, and CREMA-D. To rigorously test robustness, we subjected the model to non-stationary acoustic interference using real-world noise profiles from the SAS-KIIT dataset. The proposed framework demonstrates superior generalization and state-of-the-art accuracy across all datasets, significantly outperforming single-branch baselines under realistic environmental interference. Furthermore, we address the ``black-box" problem by integrating SHAP and Score-CAM into the evaluation pipeline. These tools provide granular visual explanations, revealing how the model strategically shifts attention between temporal and spectral cues to maintain reliability in the presence of complex environmental noise.

### 21. Distributed Asymmetric Allocation: A Topic Model for Large Imbalanced Corpora in Social Sciences

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Kohei Watanabe
- **URL**: <http://arxiv.org/abs/2512.18119v1>
- **Submitted**: 2025-12-19 22:56:57
- **Comment**: 34 pages
- **Topic Keywords**: rag
- **Reason**: This paper focuses on a topic model for social sciences, addressing challenges in large imbalanced corpora. While it involves natural language processing and topic modeling, it does not directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of interest.

#### Abstract
> Social scientists employ latent Dirichlet allocation (LDA) to find highly specific topics in large corpora, but they often struggle in this task because (1) LDA, in general, takes a significant amount of time to fit on large corpora; (2) unsupervised LDA fragments topics into sub-topics in short documents; (3) semi-supervised LDA fails to identify specific topics defined using seed words. To solve these problems, I have developed a new topic model called distributed asymmetric allocation (DAA) that integrates multiple algorithms for efficiently identifying sentences about important topics in large corpora. I evaluate the ability of DAA to identify politically important topics by fitting it to the transcripts of speeches at the United Nations General Assembly between 1991 and 2017. The results show that DAA can classify sentences significantly more accurately and quickly than LDA thanks to the new algorithms. More generally, the results demonstrate that it is important for social scientists to optimize Dirichlet priors of LDA to perform content analysis accurately.

### 22. Toward Human-Centered AI-Assisted Terminology Work

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Antonio San Martin
- **URL**: <http://arxiv.org/abs/2512.18859v1>
- **Submitted**: 2025-12-21 19:16:40
- **Topic Keywords**: search
- **Reason**: This paper focuses on the human-centered approach to artificial intelligence in terminology work, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> The rapid diffusion of generative artificial intelligence is transforming terminology work. While this technology promises gains in efficiency, its unstructured adoption risks weakening professional autonomy, amplifying bias, and eroding linguistic and conceptual diversity. This paper argues that a human-centered approach to artificial intelligence has become a necessity for terminology work. Building on research in artificial intelligence and translation studies, it proposes a human-centered framework that conceptualizes artificial intelligence as a means of amplifying the terminologist's capabilities, rather than replacing them. The framework is organized around three interrelated dimensions: the augmented terminologist, ethical AI, and human-centered design. Together, these dimensions emphasize the compatibility of high automation with strong human control, the central role of terminologists in bias mitigation, and the importance of designing AI tools and workflows around the needs, values, and well-being of the terminologist. The paper concludes by stressing that current choices in AI adoption will shape not only terminological practice, but also the preservation of accuracy, adequacy, and diversity in terminology and specialized knowledge.

### 23. Code2Doc: A Quality-First Curated Dataset for Code Documentation

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Recep Kaan Karaman, Meftun Akarsu
- **URL**: <http://arxiv.org/abs/2512.18748v1>
- **Submitted**: 2025-12-21 14:28:51
- **Topic Keywords**: search
- **Reason**: This paper focuses on code documentation generation, which is not a central match to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context is specific to code documentation and does not align with your primary focus on deep semantic understanding and real-time relevance optimization.

#### Abstract
> The performance of automatic code documentation generation models depends critically on the quality of the training data used for supervision. However, most existing code documentation datasets are constructed through large scale scraping of public repositories with limited quality control. As a result, they often contain noisy documentation, extensive duplication, and increasing contamination from AI generated content. These issues weaken the supervision signal available to learning-based models and complicate evaluation.
  We introduce \textbf{Code2Doc}, a quality-first curated dataset for function-level code documentation generation. Code2Doc consists of 13,358 high-quality function-documentation pairs extracted from widely used open-source repositories spanning five programming languages: Python, Java, TypeScript, JavaScript, and C++. The dataset is constructed using a four-stage curation pipeline that enforces documentation completeness and clarity, filters functions based on structural and complexity criteria, removes exact and near-duplicate code, and identifies documentation likely to be AI generated. Starting from 52,069 extracted candidates, only 25.6 percent satisfy all quality constraints.
  We provide a detailed analysis of the resulting dataset, which achieves a mean documentation quality score of 6.93 out of 10. Overall, 86.9% of samples contain explicit type annotations, and only 2.9\% are flagged as potentially AI generated. Baseline experiments show that fine-tuning a large language model on Code2Doc yields relative improvements of 29.47% in BLEU and 24.04% in ROUGE-L over zero shot performance, despite the modest dataset size. We release both the dataset and the full curation pipeline to support reproducible research on automatic code documentation generation.

### 24. MemEvolve: Meta-Evolution of Agent Memory Systems

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Guibin Zhang, Haotian Ren, Chong Zhan, Zhenhong Zhou, Junhao Wang, He Zhu, Wangchunshu Zhou, Shuicheng Yan
- **URL**: <http://arxiv.org/abs/2512.18746v1>
- **Submitted**: 2025-12-21 14:26:14
- **Topic Keywords**: search
- **Reason**: This paper focuses on meta-evolution of agent memory systems, which is not directly related to information retrieval, search technologies, or query understanding. While it involves large language models, the primary goal is to improve agent performance in diverse tasks, rather than addressing real-time relevance optimization or deep semantic understanding in search.

#### Abstract
> Self-evolving memory systems are unprecedentedly reshaping the evolutionary paradigm of large language model (LLM)-based agents. Prior work has predominantly relied on manually engineered memory architectures to store trajectories, distill experience, and synthesize reusable tools, enabling agents to evolve on the fly within environment interactions. However, this paradigm is fundamentally constrained by the staticity of the memory system itself: while memory facilitates agent-level evolving, the underlying memory architecture cannot be meta-adapted to diverse task contexts. To address this gap, we propose MemEvolve, a meta-evolutionary framework that jointly evolves agents' experiential knowledge and their memory architecture, allowing agent systems not only to accumulate experience but also to progressively refine how they learn from it. To ground MemEvolve in prior research and foster openness in future self-evolving systems, we introduce EvolveLab, a unified self-evolving memory codebase that distills twelve representative memory systems into a modular design space (encode, store, retrieve, manage), providing both a standardized implementation substrate and a fair experimental arena. Extensive evaluations on four challenging agentic benchmarks demonstrate that MemEvolve achieves (I) substantial performance gains, improving frameworks such as SmolAgent and Flash-Searcher by up to $17.06\%$; and (II) strong cross-task and cross-LLM generalization, designing memory architectures that transfer effectively across diverse benchmarks and backbone models.

### 25. SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Scott Thornton
- **URL**: <http://arxiv.org/abs/2512.18542v1>
- **Submitted**: 2025-12-20 23:52:12
- **Comment**: 37 pages, 5 figures. Dataset available at https://huggingface.co/datasets/scthornton/securecode-v2. Code and validation tools at https://github.com/scthornton/securecode-v2
- **Topic Keywords**: recommend
- **Reason**: This paper focuses on secure code generation and security-aware models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the topic is not central to the user's research interests, and the paper's focus on security and code generation does not align with the user's primary focus on deep semantic understanding and real-time relevance optimization in IR.

#### Abstract
> AI assistants produce vulnerable code in 45% of security-relevant scenarios, introducing flaws into production systems at scale. Yet existing secure coding datasets fall short. They lack incident grounding, don't provide the scale modern training requires, and miss the operational security context developers need for production deployments. We present SecureCode v2.0, a production-grade dataset of 1,215 security-focused coding examples that passed structural validation and expert security review. Every example ties to actual documented security incidents with CVE references, provides vulnerable and secure implementations, demonstrates concrete attacks, and includes defense-in-depth operational guidance. The dataset covers 11 vulnerability categories (complete OWASP Top 10:2025 plus AI/ML Security Threats) across 11 languages (Python, JavaScript, Java, Go, PHP, C#, TypeScript, Ruby, Rust, Kotlin, and YAML for infrastructure-as-code).
  Our quality assurance framework ensures complete incident grounding. Each example includes SIEM integration strategies, infrastructure hardening recommendations (Docker, AppArmor, WAF configurations), and testing approaches using language-appropriate frameworks. The dataset uses a 4-turn conversational structure mirroring actual developer-AI interactions, escalating from basic implementations to advanced security considerations and defense-in-depth guidance.
  Our contributions: (1) 1,215 rigorously validated examples split into 989 training, 122 validation, and 104 test sets, (2) an automated validation framework ensuring dataset consistency, (3) a 4-turn conversational structure capturing realistic security workflows, (4) comprehensive operational security guidance with SIEM integration strategies, (5) complete language-specific implementation fidelity, and (6) open-source release of data, validation tools, and benchmarking protocols.

### 26. Teaching and Critiquing Conceptualization and Operationalization in NLP

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Vagrant Gautam
- **URL**: <http://arxiv.org/abs/2512.18505v1>
- **Submitted**: 2025-12-20 20:47:01
- **Topic Keywords**: search
- **Reason**: This paper focuses on conceptualization and operationalization in NLP, which is somewhat related to your interests in NLP. However, it does not directly address your core research themes in Information Retrieval, query understanding, ranking models, or user behavior modeling.

#### Abstract
> NLP researchers regularly invoke abstract concepts like "interpretability," "bias," "reasoning," and "stereotypes," without defining them. Each subfield has a shared understanding or conceptualization of what these terms mean and how we should treat them, and this shared understanding is the basis on which operational decisions are made: Datasets are built to evaluate these concepts, metrics are proposed to quantify them, and claims are made about systems. But what do they mean, what should they mean, and how should we measure them? I outline a seminar I created for students to explore these questions of conceptualization and operationalization, with an interdisciplinary reading list and an emphasis on discussion and critique.

### 27. SRS-Stories: Vocabulary-constrained multilingual story generation for language learning

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Wiktor Kamzela, Mateusz Lango, Ondrej Dusek
- **URL**: <http://arxiv.org/abs/2512.18362v1>
- **Submitted**: 2025-12-20 13:24:59
- **Comment**: EMNLP 2025
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing, as it focuses on multilingual story generation for language learning and vocabulary review.

#### Abstract
> In this paper, we use large language models to generate personalized stories for language learners, using only the vocabulary they know. The generated texts are specifically written to teach the user new vocabulary by simply reading stories where it appears in context, while at the same time seamlessly reviewing recently learned vocabulary. The generated stories are enjoyable to read and the vocabulary reviewing/learning is optimized by a Spaced Repetition System. The experiments are conducted in three languages: English, Chinese and Polish, evaluating three story generation methods and three strategies for enforcing lexical constraints. The results show that the generated stories are more grammatical, coherent, and provide better examples of word usage than texts generated by the standard constrained beam search approach

### 28. An Agentic AI Framework for Training General Practitioner Student Skills

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Victor De Marez, Jens Van Nooten, Luna De Bruyne, Walter Daelemans
- **URL**: <http://arxiv.org/abs/2512.18440v1>
- **Submitted**: 2025-12-20 17:26:39
- **Topic Keywords**: retrieval
- **Reason**: This paper focuses on medical education and the development of virtual simulated patients, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Advancements in large language models offer strong potential for enhancing virtual simulated patients (VSPs) in medical education by providing scalable alternatives to resource-intensive traditional methods. However, current VSPs often struggle with medical accuracy, consistent roleplaying, scenario generation for VSP use, and educationally structured feedback. We introduce an agentic framework for training general practitioner student skills that unifies (i) configurable, evidence-based vignette generation, (ii) controlled persona-driven patient dialogue with optional retrieval grounding, and (iii) standards-based assessment and feedback for both communication and clinical reasoning. We instantiate the framework in an interactive spoken consultation setting and evaluate it with medical students ($\mathbf{N{=}14}$). Participants reported realistic and vignette-faithful dialogue, appropriate difficulty calibration, a stable personality signal, and highly useful example-rich feedback, alongside excellent overall usability. These results support agentic separation of scenario control, interaction control, and standards-based assessment as a practical pattern for building dependable and pedagogically valuable VSP training tools.

### 29. Merge on workspaces as Hopf algebra Markov chain

- **LLM Score**: 0
- **Keyword Score**: 1
- **Authors**: Matilde Marcolli, David Skigin
- **URL**: <http://arxiv.org/abs/2512.18861v1>
- **Submitted**: 2025-12-21 19:26:41
- **Comment**: 80 pages, LaTeX, 1 png figure
- **Topic Keywords**: search
- **Reason**: This paper appears to be unrelated to Information Retrieval, Search technologies, or any of the user's core research themes. The topic revolves around generative linguistics, Hopf algebra Markov chain, and syntax formation, which do not align with the user's interests in NLP, data mining, or IR.

#### Abstract
> We study the dynamical properties of a Hopf algebra Markov chain with state space the binary rooted forests with labelled leaves. This Markovian dynamical system describes the core computational process of structure formation and transformation in syntax via the Merge operation, according to Chomsky's Minimalism model of generative linguistics. The dynamics decomposes into an ergodic dynamical system with uniform stationary distribution, given by the action of Internal Merge, while the contributions of External Merge and (a minimal form of) Sideward Merge reduce to a simpler Markov chain with state space the set of partitions and with combinatorial weights. The Sideward Merge part of the dynamics prevents convergence to fully formed connected structures (trees), unless the different forms of Merge are weighted by a cost function, as predicted by linguistic theory. Results on the asymptotic behavior of the Perron-Frobenius eigenvalue and eigenvector in this weighted case, obtained in terms of an associated Perron-Frobenius problem in the tropical semiring, show that the usual cost functions (Minimal Search and Resource Restrictions) proposed in the linguistic literature do not suffice to obtain convergence to the tree structures, while an additional optimization property based on the Shannon entropy achieves the expected result for the dynamics. We also comment on the introduction of continuous parameters related to semantic embedding and other computational models, and also on some filtering of the dynamics by coloring rules that model the linguistic filtering by theta roles and phase structure, and on parametric variation and the process of parameter setting in Externalization.

---

