[
    {
        "title": "GraphSearch: Agentic Search-Augmented Reasoning for Zero-Shot Graph Learning",
        "abstract": "Recent advances in search-augmented large reasoning models (LRMs) enable the retrieval of external knowledge to reduce hallucinations in multistep reasoning. However, their ability to operate on graph-structured data, prevalent in domains such as e-commerce, social networks, and scientific citations, remains underexplored. Unlike plain text corpora, graphs encode rich topological signals that connect related entities and can serve as valuable priors for retrieval, enabling more targeted search and improved reasoning efficiency. Yet, effectively leveraging such structure poses unique challenges, including the difficulty of generating graph-expressive queries and ensuring reliable retrieval that balances structural and semantic relevance. To address this gap, we introduce GraphSearch, the first framework that extends search-augmented reasoning to graph learning, enabling zero-shot graph learning without task-specific fine-tuning. GraphSearch combines a Graph-aware Query Planner, which disentangles search space (e.g., 1-hop, multi-hop, or global neighbors) from semantic queries, with a Graph-aware Retriever, which constructs candidate sets based on topology and ranks them using a hybrid scoring function. We further instantiate two traversal modes: GraphSearch-R, which recursively expands neighborhoods hop by hop, and GraphSearch-F, which flexibly retrieves across local and global neighborhoods without hop constraints. Extensive experiments across diverse benchmarks show that GraphSearch achieves competitive or even superior performance compared to supervised graph learning methods, setting state-of-the-art results in zero-shot node classification and link prediction. These findings position GraphSearch as a flexible and generalizable paradigm for agentic reasoning over graphs.",
        "url": "http://arxiv.org/abs/2601.08621v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08621v1",
        "arxiv_id": "2601.08621v1",
        "authors": [
            "Jiajin Liu",
            "Yuanfu Sun",
            "Dongzhe Fan",
            "Qiaoyu Tan"
        ],
        "submitted": "2026-01-13 15:00:57",
        "source": "arxiv",
        "comment": "16 pages, 5 pages",
        "score": 20,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of search-augmented reasoning and graph learning. Although it doesn't directly focus on query understanding, ranking models, or user behavior modeling, it explores the application of search technologies to graph-structured data, which is relevant to your background in e-commerce and broader interests in NLP and data mining."
    },
    {
        "title": "MLPlatt: Simple Calibration Framework for Ranking Models",
        "abstract": "Ranking models are extensively used in e-commerce for relevance estimation. These models often suffer from poor interpretability and no scale calibration, particularly when trained with typical ranking loss functions. This paper addresses the problem of post-hoc calibration of ranking models. We introduce MLPlatt: a simple yet effective ranking model calibration method that preserves the item ordering and converts ranker outputs to interpretable click-through rate (CTR) probabilities usable in downstream tasks. The method is context-aware by design and achieves good calibration metrics globally, and within strata corresponding to different values of a selected categorical field (such as user country or device), which is often important from a business perspective of an E-commerce platform. We demonstrate the superiority of MLPlatt over existing approaches on two datasets, achieving an improvement of over 10\\% in F-ECE (Field Expected Calibration Error) compared to other methods. Most importantly, we show that high-quality calibration can be achieved without compromising the ranking quality.",
        "url": "http://arxiv.org/abs/2601.08345v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08345v1",
        "arxiv_id": "2601.08345v1",
        "authors": [
            "Piotr Bajger",
            "Roman Dusek",
            "Krzysztof Galias",
            "Paweł Młyniec",
            "Aleksander Wawer",
            "Paweł Zawistowski"
        ],
        "submitted": "2026-01-13 09:04:42",
        "source": "arxiv",
        "comment": null,
        "score": 15,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'click' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'click-through rate' (score: +2)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, specifically ranking models and calibration. The focus on e-commerce is a secondary match, but the discussion of click-through rate probabilities and calibration metrics aligns with your interests in query understanding and real-time relevance optimization."
    },
    {
        "title": "TableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL",
        "abstract": "In Text-to-SQL tasks, existing LLM-based methods often include extensive database schemas in prompts, leading to long context lengths and increased prefilling latency. While user queries typically focus on recurrent table sets-offering an opportunity for KV cache sharing across queries-current inference engines, such as SGLang and vLLM, generate redundant prefix cache copies when processing user queries with varying table orders. To address this inefficiency, we propose precomputing table representations as KV caches offline and querying the required ones online. A key aspect of our approach is the computation of table caches while preserving primary foreign key relationships between tables. Additionally, we construct a Table Trie structure to facilitate efficient KV cache lookups during inference. To enhance cache performance, we introduce a cache management system with a query reranking strategy to improve cache hit rates and a computation loading pipeline for parallelizing model inference and cache loading. Experimental results show that our proposed TableCache achieves up to a 3.62x speedup in Time to First Token (TTFT) with negligible performance degradation.",
        "url": "http://arxiv.org/abs/2601.08743v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08743v1",
        "arxiv_id": "2601.08743v1",
        "authors": [
            "Jinbo Su",
            "Yuxuan Hu",
            "Cuiping Li",
            "Hong Chen",
            "Jia Li",
            "Lintao Ma",
            "Jing Zhang"
        ],
        "submitted": "2026-01-13 17:20:55",
        "source": "arxiv",
        "comment": null,
        "score": 13,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on optimizing Text-to-SQL tasks using a KV cache, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves query understanding and ranking models, the context is specific to Text-to-SQL and database schema, which is not a primary focus of the user's research interests."
    },
    {
        "title": "Query Suggestion for Retrieval-Augmented Generation via Dynamic In-Context Learning",
        "abstract": "Retrieval-augmented generation with tool-calling agents (agentic RAG) has become increasingly powerful in understanding, processing, and responding to user queries. However, the scope of the grounding knowledge is limited and asking questions that exceed this scope may lead to issues like hallucination. While guardrail frameworks aim to block out-of-scope questions (Rodriguez et al., 2024), no research has investigated the question of suggesting answerable queries in order to complete the user interaction.\n  In this paper, we initiate the study of query suggestion for agentic RAG. We consider the setting where user questions are not answerable, and the suggested queries should be similar to aid the user interaction. Such scenarios are frequent for tool-calling LLMs as communicating the restrictions of the tools or the underlying datasets to the user is difficult, and adding query suggestions enhances the interaction with the RAG agent. As opposed to traditional settings for query recommendations such as in search engines, ensuring that the suggested queries are answerable is a major challenge due to the RAG's multi-step workflow that demands a nuanced understanding of the RAG as a whole, which the executing LLM lacks. As such, we introduce robust dynamic few-shot learning which retrieves examples from relevant workflows. We show that our system can be self-learned, for instance on prior user queries, and is therefore easily applicable in practice. We evaluate our approach on three benchmark datasets based on two unlabeled question datasets collected from real-world user queries. Experiments on real-world datasets confirm that our method produces more relevant and answerable suggestions, outperforming few-shot and retrieval-only baselines, and thus enable safer, more effective user interaction with agentic RAG.",
        "url": "http://arxiv.org/abs/2601.08105v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08105v1",
        "arxiv_id": "2601.08105v1",
        "authors": [
            "Fabian Spaeh",
            "Tianyi Chen",
            "Chen-Hao Chiang",
            "Bin Shen"
        ],
        "submitted": "2026-01-13 00:56:38",
        "source": "arxiv",
        "comment": null,
        "score": 12,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The focus on query suggestion for Retrieval-Augmented Generation is closely related to your work on query understanding and user behavior modeling. Although the paper's primary focus is on a specific application (agentic RAG), the underlying concepts and challenges are aligned with your broader interests in IR and NLP."
    },
    {
        "title": "PosIR: Position-Aware Heterogeneous Information Retrieval Benchmark",
        "abstract": "While dense retrieval models have achieved remarkable success, rigorous evaluation of their sensitivity to the position of relevant information (i.e., position bias) remains largely unexplored. Existing benchmarks typically employ position-agnostic relevance labels, conflating the challenge of processing long contexts with the bias against specific evidence locations. To address this challenge, we introduce PosIR (Position-Aware Information Retrieval), a comprehensive benchmark designed to diagnose position bias in diverse retrieval scenarios. PosIR comprises 310 datasets spanning 10 languages and 31 domains, constructed through a rigorous pipeline that ties relevance to precise reference spans, enabling the strict disentanglement of document length from information position. Extensive experiments with 10 state-of-the-art embedding models reveal that: (1) Performance on PosIR in long-context settings correlates poorly with the MMTEB benchmark, exposing limitations in current short-text benchmarks; (2) Position bias is pervasive and intensifies with document length, with most models exhibiting primacy bias while certain models show unexpected recency bias; (3) Gradient-based saliency analysis further uncovers the distinct internal attention mechanisms driving these positional preferences. In summary, PosIR serves as a valuable diagnostic framework to foster the development of position-robust retrieval systems.",
        "url": "http://arxiv.org/abs/2601.08363v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08363v1",
        "arxiv_id": "2601.08363v1",
        "authors": [
            "Ziyang Zeng",
            "Dun Zhang",
            "Yu Yan",
            "Xu Sun",
            "Yudong Zhou",
            "Yuqing Yang"
        ],
        "submitted": "2026-01-13 09:22:16",
        "source": "arxiv",
        "comment": "This research is driven by a strong academic interest, and we welcome further exchange and discussion with peers",
        "score": 11,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'dense retrieval' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to Information Retrieval, specifically addressing position bias in dense retrieval models. The introduction of PosIR, a comprehensive benchmark, aligns with the user's interest in query understanding and ranking models. While not directly focused on user behavior modeling or e-commerce, the paper's emphasis on position-aware retrieval is closely related to the user's core research themes."
    },
    {
        "title": "SwiftMem: Fast Agentic Memory via Query-aware Indexing",
        "abstract": "Agentic memory systems have become critical for enabling LLM agents to maintain long-term context and retrieve relevant information efficiently. However, existing memory frameworks suffer from a fundamental limitation: they perform exhaustive retrieval across the entire storage layer regardless of query characteristics. This brute-force approach creates severe latency bottlenecks as memory grows, hindering real-time agent interactions. We propose SwiftMem, a query-aware agentic memory system that achieves sub-linear retrieval through specialized indexing over temporal and semantic dimensions. Our temporal index enables logarithmic-time range queries for time-sensitive retrieval, while the semantic DAG-Tag index maps queries to relevant topics through hierarchical tag structures. To address memory fragmentation during growth, we introduce an embedding-tag co-consolidation mechanism that reorganizes storage based on semantic clusters to improve cache locality. Experiments on LoCoMo and LongMemEval benchmarks demonstrate that SwiftMem achieves 47$\\times$ faster search compared to state-of-the-art baselines while maintaining competitive accuracy, enabling practical deployment of memory-augmented LLM agents.",
        "url": "http://arxiv.org/abs/2601.08160v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08160v1",
        "arxiv_id": "2601.08160v1",
        "authors": [
            "Anxin Tian",
            "Yiming Li",
            "Xing Li",
            "Hui-Ling Zhen",
            "Lei Chen",
            "Xianzhi Yu",
            "Zhenhua Dong",
            "Mingxuan Yuan"
        ],
        "submitted": "2026-01-13 02:51:04",
        "source": "arxiv",
        "comment": null,
        "score": 11,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a memory system for LLM agents, which is somewhat related to information retrieval, particularly in the context of query understanding and real-time relevance optimization. However, the focus is on memory systems rather than traditional IR techniques, and the paper's emphasis on LLM agents and agentic memory systems makes it less directly relevant to the user's core research themes."
    },
    {
        "title": "CSQL: Mapping Documents into Causal Databases",
        "abstract": "We describe a novel system, CSQL, which automatically converts a collection of unstructured text documents into an SQL-queryable causal database (CDB). A CDB differs from a traditional DB: it is designed to answer \"why'' questions via causal interventions and structured causal queries. CSQL builds on our earlier system, DEMOCRITUS, which converts documents into thousands of local causal models derived from causal discourse. Unlike RAG-based systems or knowledge-graph based approaches, CSQL supports causal analysis over document collections rather than purely associative retrieval. For example, given an article on the origins of human bipedal walking, CSQL enables queries such as: \"What are the strongest causal influences on bipedalism?'' or \"Which variables act as causal hubs with the largest downstream influence?'' Beyond single-document case studies, we show that CSQL can also ingest RAG/IE-compiled causal corpora at scale by compiling the Testing Causal Claims (TCC) dataset of economics papers into a causal database containing 265,656 claim instances spanning 45,319 papers, 44 years, and 1,575 reported method strings, thereby enabling corpus-level causal queries and longitudinal analyses in CSQL. Viewed abstractly, CSQL functions as a compiler from unstructured documents into a causal database equipped with a principled algebra of queries, and can be applied broadly across many domains ranging from business, humanities, and science.",
        "url": "http://arxiv.org/abs/2601.08109v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08109v1",
        "arxiv_id": "2601.08109v1",
        "authors": [
            "Sridhar Mahadevan"
        ],
        "submitted": "2026-01-13 01:00:38",
        "source": "arxiv",
        "comment": "26 pages",
        "score": 10,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a system for converting unstructured text documents into a causal database, enabling causal analysis and queries. While it touches on information retrieval and document processing, the primary focus is on causal analysis and database construction, which is somewhat related to the user's interests in query understanding and ranking models, but not a central match."
    },
    {
        "title": "D$^2$Plan: Dual-Agent Dynamic Global Planning for Complex Retrieval-Augmented Reasoning",
        "abstract": "Recent search-augmented LLMs trained with reinforcement learning (RL) can interleave searching and reasoning for multi-hop reasoning tasks. However, they face two critical failure modes as the accumulating context becomes flooded with both crucial evidence and irrelevant information: (1) ineffective search chain construction that produces incorrect queries or omits retrieval of critical information, and (2) reasoning hijacking by peripheral evidence that causes models to misidentify distractors as valid evidence. To address these challenges, we propose **D$^2$Plan**, a **D**ual-agent **D**ynamic global **Plan**ning paradigm for complex retrieval-augmented reasoning. **D$^2$Plan** operates through the collaboration of a *Reasoner* and a *Purifier*: the *Reasoner* constructs explicit global plans during reasoning and dynamically adapts them based on retrieval feedback; the *Purifier* assesses retrieval relevance and condenses key information for the *Reasoner*. We further introduce a two-stage training framework consisting of supervised fine-tuning (SFT) cold-start on synthesized trajectories and RL with plan-oriented rewards to teach LLMs to master the **D$^2$Plan** paradigm. Extensive experiments demonstrate that **D$^2$Plan** enables more coherent multi-step reasoning and stronger resilience to irrelevant information, thereby achieving superior performance on challenging QA benchmarks.",
        "url": "http://arxiv.org/abs/2601.08282v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08282v1",
        "arxiv_id": "2601.08282v1",
        "authors": [
            "Kangcheng Luo",
            "Tinglang Wu",
            "Yansong Feng"
        ],
        "submitted": "2026-01-13 07:17:51",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to the field of Information Retrieval, particularly in the context of query understanding and ranking models. The proposed D^2Plan paradigm addresses challenges in search-augmented reasoning, which aligns with the user's interests in deep semantic understanding and real-time relevance optimization. However, the focus on reinforcement learning and LLMs is somewhat outside the user's primary area of focus on traditional IR and search technologies."
    },
    {
        "title": "Generation-Augmented Generation: A Plug-and-Play Framework for Private Knowledge Injection in Large Language Models",
        "abstract": "In domains such as biomedicine, materials, and finance, high-stakes deployment of large language models (LLMs) requires injecting private, domain-specific knowledge that is proprietary, fast-evolving, and under-represented in public pretraining. However, the two dominant paradigms for private knowledge injection each have pronounced drawbacks: fine-tuning is expensive to iterate, and continual updates risk catastrophic forgetting and general-capability regression; retrieval-augmented generation (RAG) keeps the base model intact but is brittle in specialized private corpora due to chunk-induced evidence fragmentation, retrieval drift, and long-context pressure that yields query-dependent prompt inflation. Inspired by how multimodal LLMs align heterogeneous modalities into a shared semantic space, we propose Generation-Augmented Generation (GAG), which treats private expertise as an additional expert modality and injects it via a compact, representation-level interface aligned to the frozen base model, avoiding prompt-time evidence serialization while enabling plug-and-play specialization and scalable multi-domain composition with reliable selective activation. Across two private scientific QA benchmarks (immunology adjuvant and catalytic materials) and mixed-domain evaluations, GAG improves specialist performance over strong RAG baselines by 15.34% and 14.86% on the two benchmarks, respectively, while maintaining performance on six open general benchmarks and enabling near-oracle selective activation for scalable multi-domain deployment.",
        "url": "http://arxiv.org/abs/2601.08209v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08209v1",
        "arxiv_id": "2601.08209v1",
        "authors": [
            "Rongji Li",
            "Jian Xu",
            "Xueqing Chen",
            "Yisheng Yang",
            "Jiayi Wang",
            "Xingyu Chen",
            "Chunyu Xie",
            "Dawei Leng",
            "Xu-Yao Zhang"
        ],
        "submitted": "2026-01-13 04:23:36",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on private knowledge injection in large language models, which is not directly related to your primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve language models, the context is more aligned with NLP and knowledge injection rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "AgriLens: Semantic Retrieval in Agricultural Texts Using Topic Modeling and Language Models",
        "abstract": "As the volume of unstructured text continues to grow across domains, there is an urgent need for scalable methods that enable interpretable organization, summarization, and retrieval of information. This work presents a unified framework for interpretable topic modeling, zero-shot topic labeling, and topic-guided semantic retrieval over large agricultural text corpora. Leveraging BERTopic, we extract semantically coherent topics. Each topic is converted into a structured prompt, enabling a language model to generate meaningful topic labels and summaries in a zero-shot manner. Querying and document exploration are supported via dense embeddings and vector search, while a dedicated evaluation module assesses topical coherence and bias. This framework supports scalable and interpretable information access in specialized domains where labeled data is limited.",
        "url": "http://arxiv.org/abs/2601.08283v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08283v1",
        "arxiv_id": "2601.08283v1",
        "authors": [
            "Heba Shakeel",
            "Tanvir Ahmad",
            "Tanya Liyaqat",
            "Chandni Saxena"
        ],
        "submitted": "2026-01-13 07:18:59",
        "source": "arxiv",
        "comment": "8 Pages, 1st workshop on Democratizing GenAI and Scalable NLP with HiPC for Societal Impact; 32nd IEEE International Conference on High Performance Computing, Data, & Analytics",
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper aligns well with your interests in Information Retrieval, particularly in areas requiring deep semantic understanding. The use of topic modeling and language models to enable interpretable organization and retrieval of information in a specialized domain is relevant to your research. However, the focus on agricultural texts is somewhat specific and may not be directly applicable to your broader interests in e-commerce and general search technologies."
    },
    {
        "title": "From Rows to Reasoning: A Retrieval-Augmented Multimodal Framework for Spreadsheet Understanding",
        "abstract": "Large Language Models (LLMs) struggle to reason over large-scale enterprise spreadsheets containing thousands of numeric rows, multiple linked sheets, and embedded visual content such as charts and receipts. Prior state-of-the-art spreadsheet reasoning approaches typically rely on single-sheet compression or full-context encoding, which limits scalability and fails to reflect how real users interact with complex, multimodal workbooks. We introduce FRTR-Bench, the first large-scale benchmark for multimodal spreadsheet reasoning, comprising 30 enterprise-grade Excel workbooks spanning nearly four million cells and more than 50 embedded images. To address these challenges, we present From Rows to Reasoning (FRTR), an advanced, multimodal retrieval-augmented generation framework that decomposes Excel workbooks into granular row, column, and block embeddings, employs hybrid lexical-dense retrieval with Reciprocal Rank Fusion (RRF), and integrates multimodal embeddings to reason over both numerical and visual information. We tested FRTR on six LLMs, achieving 74% answer accuracy on FRTR-Bench with Claude Sonnet 4.5, a substantial improvement over prior state-of-the-art approaches that reached only 24%. On the SpreadsheetLLM benchmark, FRTR achieved 87% accuracy with GPT-5 while reducing token usage by roughly 50% compared to context-compression methods.",
        "url": "http://arxiv.org/abs/2601.08741v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08741v1",
        "arxiv_id": "2601.08741v1",
        "authors": [
            "Anmol Gulati",
            "Sahil Sen",
            "Waqar Sarguroh",
            "Kevin Paul"
        ],
        "submitted": "2026-01-13 17:18:14",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'dense retrieval' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on spreadsheet understanding and multimodal reasoning, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves retrieval-augmented generation, the context is specific to spreadsheets and does not align with the user's interests in query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "From Tool to Teacher: Rethinking Search Systems as Instructive Interfaces",
        "abstract": "Information access systems such as search engines and generative AI are central to how people seek, evaluate, and interpret information. Yet most systems are designed to optimise retrieval rather than to help users develop better search strategies or critical awareness. This paper introduces a pedagogical perspective on information access, conceptualising search and conversational systems as instructive interfaces that can teach, guide, and scaffold users' learning. We draw on seven didactic frameworks from education and behavioural science to analyse how existing and emerging system features, including query suggestions, source labels, and conversational or agentic AI, support or limit user learning. Using two illustrative search tasks, we demonstrate how different design choices promote skills such as critical evaluation, metacognitive reflection, and strategy transfer. The paper contributes a conceptual lens for evaluating the instructional value of information access systems and outlines design implications for technologies that foster more effective, reflective, and resilient information seekers.",
        "url": "http://arxiv.org/abs/2601.08035v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08035v1",
        "arxiv_id": "2601.08035v1",
        "authors": [
            "David Elsweiler"
        ],
        "submitted": "2026-01-12 22:06:13",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the concept of search systems as instructive interfaces, which aligns with your interest in Information Retrieval and Search technologies. However, the focus on pedagogy and user learning is somewhat tangential to your core research themes of query understanding, ranking models, and user behavior modeling. While it touches on related topics, it doesn't directly address your primary areas of interest."
    },
    {
        "title": "MemRec: Collaborative Memory-Augmented Agentic Recommender System",
        "abstract": "The evolution of recommender systems has shifted preference storage from rating matrices and dense embeddings to semantic memory in the agentic era. Yet existing agents rely on isolated memory, overlooking crucial collaborative signals. Bridging this gap is hindered by the dual challenges of distilling vast graph contexts without overwhelming reasoning agents with cognitive load, and evolving the collaborative memory efficiently without incurring prohibitive computational costs. To address this, we propose MemRec, a framework that architecturally decouples reasoning from memory management to enable efficient collaborative augmentation. MemRec introduces a dedicated, cost-effective LM_Mem to manage a dynamic collaborative memory graph, serving synthesized, high-signal context to a downstream LLM_Rec. The framework operates via a practical pipeline featuring efficient retrieval and cost-effective asynchronous graph propagation that evolves memory in the background. Extensive experiments on four benchmarks demonstrate that MemRec achieves state-of-the-art performance. Furthermore, architectural analysis confirms its flexibility, establishing a new Pareto frontier that balances reasoning quality, cost, and privacy through support for diverse deployments, including local open-source models. Code:https://github.com/rutgerswiselab/memrec and Homepage: https://memrec.weixinchen.com",
        "url": "http://arxiv.org/abs/2601.08816v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08816v1",
        "arxiv_id": "2601.08816v1",
        "authors": [
            "Weixin Chen",
            "Yuhan Zhao",
            "Jingyuan Huang",
            "Zihe Ye",
            "Clark Mingxuan Ju",
            "Tong Zhao",
            "Neil Shah",
            "Li Chen",
            "Yongfeng Zhang"
        ],
        "submitted": "2026-01-13 18:51:16",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper MemRec focuses on collaborative memory-augmented recommender systems, which is somewhat related to the user's interests in recommender systems. However, it does not directly align with the user's primary focus on information retrieval, especially in areas requiring deep semantic understanding and real-time relevance optimization. The paper's emphasis on collaborative memory and graph contexts is more relevant to recommender systems than the user's core research themes."
    },
    {
        "title": "To Retrieve or To Think? An Agentic Approach for Context Evolution",
        "abstract": "Current context augmentation methods, such as retrieval-augmented generation, are essential for solving knowledge-intensive reasoning tasks. However, they typically adhere to a rigid, brute-force strategy that executes retrieval at every step. This indiscriminate approach not only incurs unnecessary computational costs but also degrades performance by saturating the context with irrelevant noise. To address these limitations, we introduce Agentic Context Evolution (ACE), a framework inspired by human metacognition that dynamically determines whether to seek new evidence or reason with existing knowledge. ACE employs a central orchestrator agent to make decisions strategically via majority voting. It aims to alternate between activating a retriever agent for external retrieval and a reasoner agent for internal analysis and refinement. By eliminating redundant retrieval steps, ACE maintains a concise and evolved context. Extensive experiments on challenging multi-hop QA benchmarks demonstrate that ACE significantly outperforms competitive baselines in accuracy while achieving efficient token consumption. Our work provides valuable insights into advancing context-evolved generation for complex, knowledge-intensive tasks.",
        "url": "http://arxiv.org/abs/2601.08747v2",
        "pdf_url": "https://arxiv.org/pdf/2601.08747v2",
        "arxiv_id": "2601.08747v2",
        "authors": [
            "Rubing Chen",
            "Jian Wang",
            "Wenjie Li",
            "Xiao-Yong Wei",
            "Qing Li"
        ],
        "submitted": "2026-01-13 17:25:57",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores context evolution in knowledge-intensive tasks, which is somewhat related to information retrieval and query understanding. However, the focus is on retrieval-augmented generation and context augmentation, rather than ranking models or user behavior modeling. While the work involves NLP and data mining, the primary application is in question answering, which is not a central match to the user's research interests."
    },
    {
        "title": "Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought",
        "abstract": "Despite notable advancements in prompting methods for Large Language Models (LLMs), such as Chain-of-Thought (CoT), existing strategies still suffer from excessive token usage and limited generalisability across diverse reasoning tasks. To address these limitations, we propose an Adaptive Causal Prompting with Sketch-of-Thought (ACPS) framework, which leverages structural causal models to infer the causal effect of a query on its answer and adaptively select an appropriate intervention (i.e., standard front-door and conditional front-door adjustments). This design enables generalisable causal reasoning across heterogeneous tasks without task-specific retraining. By replacing verbose CoT with concise Sketch-of-Thought, ACPS enables efficient reasoning that significantly reduces token usage and inference cost. Extensive experiments on multiple reasoning benchmarks and LLMs demonstrate that ACPS consistently outperforms existing prompting baselines in terms of accuracy, robustness, and computational efficiency.",
        "url": "http://arxiv.org/abs/2601.08108v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08108v1",
        "arxiv_id": "2601.08108v1",
        "authors": [
            "Bowen Li",
            "Ziqi Xu",
            "Jing Ren",
            "Renqiang Luo",
            "Xikun Zhang",
            "Xiuzhen Zhang",
            "Yongli Ren",
            "Feng Xia"
        ],
        "submitted": "2026-01-13 00:58:43",
        "source": "arxiv",
        "comment": "Accepted by Findings of EACL 2026",
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper proposes a method for debiasing Large Language Models, which is somewhat related to information retrieval, particularly in areas that require deep semantic understanding. However, the focus on causal reasoning and debiasing is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling. While it touches on NLP, it is not a central match for the user's research themes."
    },
    {
        "title": "Exploiting DINOv3-Based Self-Supervised Features for Robust Few-Shot Medical Image Segmentation",
        "abstract": "Deep learning-based automatic medical image segmentation plays a critical role in clinical diagnosis and treatment planning but remains challenging in few-shot scenarios due to the scarcity of annotated training data. Recently, self-supervised foundation models such as DINOv3, which were trained on large natural image datasets, have shown strong potential for dense feature extraction that can help with the few-shot learning challenge. Yet, their direct application to medical images is hindered by domain differences. In this work, we propose DINO-AugSeg, a novel framework that leverages DINOv3 features to address the few-shot medical image segmentation challenge. Specifically, we introduce WT-Aug, a wavelet-based feature-level augmentation module that enriches the diversity of DINOv3-extracted features by perturbing frequency components, and CG-Fuse, a contextual information-guided fusion module that exploits cross-attention to integrate semantic-rich low-resolution features with spatially detailed high-resolution features. Extensive experiments on six public benchmarks spanning five imaging modalities, including MRI, CT, ultrasound, endoscopy, and dermoscopy, demonstrate that DINO-AugSeg consistently outperforms existing methods under limited-sample conditions. The results highlight the effectiveness of incorporating wavelet-domain augmentation and contextual fusion for robust feature representation, suggesting DINO-AugSeg as a promising direction for advancing few-shot medical image segmentation. Code and data will be made available on https://github.com/apple1986/DINO-AugSeg.",
        "url": "http://arxiv.org/abs/2601.08078v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08078v1",
        "arxiv_id": "2601.08078v1",
        "authors": [
            "Guoping Xu",
            "Jayaram K. Udupa",
            "Weiguo Lu",
            "You Zhang"
        ],
        "submitted": "2026-01-12 23:44:25",
        "source": "arxiv",
        "comment": "36 pages, 11 figures",
        "score": 5,
        "keyword_reasons": [
            "Found 'ltr' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on few-shot medical image segmentation using self-supervised features, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves deep learning, the application domain (medical image segmentation) and the specific techniques used (wavelet-based feature-level augmentation and contextual information-guided fusion) do not align with the user's core research themes."
    },
    {
        "title": "DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs",
        "abstract": "Large Language Models (LLMs) often exhibit increased response latency and degraded answer quality as dialogue length grows, making effective context management essential. However, existing methods rely on extra LLM calls to build memory or perform offline memory construction without considering the current user utterance, which can introduce inefficiencies or disrupt conversational continuity. We introduce DyCP, a lightweight context management method that dynamically segment and retrieve relevant memory at query time. It preserves the sequential structure of dialogue without predefined topic boundaries and supports efficient, adaptive context retrieval. Across three long-form dialogue benchmarks, LoCoMo, MT-Bench+, and SCM4LLMs, and multiple LLMs, DyCP consistently improves answer quality while reducing response latency. We also examine the gap between modern LLMs' expanded context windows and their actual long-context processing capacity, highlighting the continued importance of effective context management.",
        "url": "http://arxiv.org/abs/2601.07994v2",
        "pdf_url": "https://arxiv.org/pdf/2601.07994v2",
        "arxiv_id": "2601.07994v2",
        "authors": [
            "Nayoung Choi",
            "Jonathan Zhang",
            "Jinho D. Choi"
        ],
        "submitted": "2026-01-12 20:47:50",
        "source": "arxiv",
        "comment": "Accepted (B) to TACL 2026",
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat relevant to your research interests in Information Retrieval, particularly in the context of query understanding and ranking models. However, its focus on Large Language Models (LLMs) and dialogue management is not directly aligned with your primary interests in search technologies and user behavior modeling. While it touches on the concept of context management, which is related to your interests in real-time relevance optimization, the paper's application to dialogue systems is not a central match for your research themes."
    },
    {
        "title": "PrivGemo: Privacy-Preserving Dual-Tower Graph Retrieval for Empowering LLM Reasoning with Memory Augmentation",
        "abstract": "Knowledge graphs (KGs) provide structured evidence that can ground large language model (LLM) reasoning for knowledge-intensive question answering. However, many practical KGs are private, and sending retrieved triples or exploration traces to closed-source LLM APIs introduces leakage risk. Existing privacy treatments focus on masking entity names, but they still face four limitations: structural leakage under semantic masking, uncontrollable remote interaction, fragile multi-hop and multi-entity reasoning, and limited experience reuse for stability and efficiency. To address these issues, we propose PrivGemo, a privacy-preserving retrieval-augmented framework for KG-grounded reasoning with memory-guided exposure control. PrivGemo uses a dual-tower design to keep raw KG knowledge local while enabling remote reasoning over an anonymized view that goes beyond name masking to limit both semantic and structural exposure. PrivGemo supports multi-hop, multi-entity reasoning by retrieving anonymized long-hop paths that connect all topic entities, while keeping grounding and verification on the local KG. A hierarchical controller and a privacy-aware experience memory further reduce unnecessary exploration and remote interactions. Comprehensive experiments on six benchmarks show that PrivGemo achieves overall state-of-the-art results, outperforming the strongest baseline by up to 17.1%. Furthermore, PrivGemo enables smaller models (e.g., Qwen3-4B) to achieve reasoning performance comparable to that of GPT-4-Turbo.",
        "url": "http://arxiv.org/abs/2601.08739v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08739v1",
        "arxiv_id": "2601.08739v1",
        "authors": [
            "Xingyu Tan",
            "Xiaoyang Wang",
            "Qing Liu",
            "Xiwei Xu",
            "Xin Yuan",
            "Liming Zhu",
            "Wenjie Zhang"
        ],
        "submitted": "2026-01-13 17:14:23",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a privacy-preserving framework for knowledge graph retrieval, which is somewhat related to information retrieval and NLP. However, the focus on privacy and knowledge graph reasoning does not directly align with the user's primary interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "RAGShaper: Eliciting Sophisticated Agentic RAG Skills via Automated Data Synthesis",
        "abstract": "Agentic Retrieval-Augmented Generation (RAG) empowers large language models to autonomously plan and retrieve information for complex problem-solving. However, the development of robust agents is hindered by the scarcity of high-quality training data that reflects the noise and complexity of real-world retrieval environments. Conventional manual annotation is unscalable and often fails to capture the dynamic reasoning strategies required to handle retrieval failures. To bridge this gap, we introduce RAGShaper, a novel data synthesis framework designed to automate the construction of RAG tasks and robust agent trajectories. RAGShaper incorporates an InfoCurator to build dense information trees enriched with adversarial distractors spanning Perception and Cognition levels. Furthermore, we propose a constrained navigation strategy that forces a teacher agent to confront these distractors, thereby eliciting trajectories that explicitly demonstrate error correction and noise rejection. Comprehensive experiments confirm that models trained on our synthesized corpus significantly outperform existing baselines, exhibiting superior robustness in noise-intensive and complex retrieval tasks.",
        "url": "http://arxiv.org/abs/2601.08699v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08699v1",
        "arxiv_id": "2601.08699v1",
        "authors": [
            "Zhengwei Tao",
            "Bo Li",
            "Jialong Wu",
            "Guochen Yan",
            "Huanyao Zhang",
            "Jiahao Xu",
            "Haitao Mi",
            "Wentao Zhang"
        ],
        "submitted": "2026-01-13 16:25:07",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Retrieval-Augmented Generation (RAG), which is related to query understanding and ranking models. However, the primary focus is on data synthesis for robust agent development, which is somewhat relevant to user behavior modeling but not directly related to the user's core research themes in IR and NLP."
    },
    {
        "title": "Parallel Context-of-Experts Decoding for Retrieval Augmented Generation",
        "abstract": "Retrieval Augmented Generation faces a trade-off: concatenating documents in a long prompt enables multi-document reasoning but creates prefill bottlenecks, while encoding document KV caches separately offers speed but breaks cross-document interaction. We propose Parallel Context-of-Experts Decoding (Pced), a training-free framework that shifts evidence aggregation from the attention mechanism to the decoding. Pced treats retrieved documents as isolated \"experts\", synchronizing their predictions via a novel retrieval-aware contrastive decoding rule that weighs expert logits against the model prior. This approach recovers cross-document reasoning capabilities without constructing a shared attention across documents.",
        "url": "http://arxiv.org/abs/2601.08670v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08670v1",
        "arxiv_id": "2601.08670v1",
        "authors": [
            "Giulio Corallo",
            "Paolo Papotti"
        ],
        "submitted": "2026-01-13 15:46:59",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'retrieval augmented generation' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses Retrieval Augmented Generation, which is a related topic to Information Retrieval. However, the focus on generation and decoding mechanisms, while relevant to query understanding, is not a central match to the user's primary research interests in ranking models and user behavior modeling."
    },
    {
        "title": "It's All About the Confidence: An Unsupervised Approach for Multilingual Historical Entity Linking using Large Language Models",
        "abstract": "Despite the recent advancements in NLP with the advent of Large Language Models (LLMs), Entity Linking (EL) for historical texts remains challenging due to linguistic variation, noisy inputs, and evolving semantic conventions. Existing solutions either require substantial training data or rely on domain-specific rules that limit scalability. In this paper, we present MHEL-LLaMo (Multilingual Historical Entity Linking with Large Language MOdels), an unsupervised ensemble approach combining a Small Language Model (SLM) and an LLM. MHEL-LLaMo leverages a multilingual bi-encoder (BELA) for candidate retrieval and an instruction-tuned LLM for NIL prediction and candidate selection via prompt chaining. Our system uses SLM's confidence scores to discriminate between easy and hard samples, applying an LLM only for hard cases. This strategy reduces computational costs while preventing hallucinations on straightforward cases. We evaluate MHEL-LLaMo on four established benchmarks in six European languages (English, Finnish, French, German, Italian and Swedish) from the 19th and 20th centuries. Results demonstrate that MHEL-LLaMo outperforms state-of-the-art models without requiring fine-tuning, offering a scalable solution for low-resource historical EL. The implementation of MHEL-LLaMo is available on Github.",
        "url": "http://arxiv.org/abs/2601.08500v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08500v1",
        "arxiv_id": "2601.08500v1",
        "authors": [
            "Cristian Santini",
            "Marieke Van Erp",
            "Mehwish Alam"
        ],
        "submitted": "2026-01-13 12:36:38",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Entity Linking for historical texts using Large Language Models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing, particularly in areas requiring deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Demystifying the Slash Pattern in Attention: The Role of RoPE",
        "abstract": "Large Language Models (LLMs) often exhibit slash attention patterns, where attention scores concentrate along the $Δ$-th sub-diagonal for some offset $Δ$. These patterns play a key role in passing information across tokens. But why do they emerge? In this paper, we demystify the emergence of these Slash-Dominant Heads (SDHs) from both empirical and theoretical perspectives. First, by analyzing open-source LLMs, we find that SDHs are intrinsic to models and generalize to out-of-distribution prompts. To explain the intrinsic emergence, we analyze the queries, keys, and Rotary Position Embedding (RoPE), which jointly determine attention scores. Our empirical analysis reveals two characteristic conditions of SDHs: (1) Queries and keys are almost rank-one, and (2) RoPE is dominated by medium- and high-frequency components. Under these conditions, queries and keys are nearly identical across tokens, and interactions between medium- and high-frequency components of RoPE give rise to SDHs. Beyond empirical evidence, we theoretically show that these conditions are sufficient to ensure the emergence of SDHs by formalizing them as our modeling assumptions. Particularly, we analyze the training dynamics of a shallow Transformer equipped with RoPE under these conditions, and prove that models trained via gradient descent exhibit SDHs. The SDHs generalize to out-of-distribution prompts.",
        "url": "http://arxiv.org/abs/2601.08297v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08297v1",
        "arxiv_id": "2601.08297v1",
        "authors": [
            "Yuan Cheng",
            "Fengzhuo Zhang",
            "Yunlong Hou",
            "Cunxiao Du",
            "Chao Du",
            "Tianyu Pang",
            "Aixin Sun",
            "Zhuoran Yang"
        ],
        "submitted": "2026-01-13 07:40:57",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the behavior of Large Language Models, specifically the emergence of slash attention patterns. While it touches on attention mechanisms, which are related to ranking models, the focus is on understanding the intrinsic behavior of LLMs rather than query understanding or ranking models. The connection to information retrieval is indirect, making it somewhat relevant but not a central match."
    },
    {
        "title": "Med-CoReasoner: Reducing Language Disparities in Medical Reasoning via Language-Informed Co-Reasoning",
        "abstract": "While reasoning-enhanced large language models perform strongly on English medical tasks, a persistent multilingual gap remains, with substantially weaker reasoning in local languages, limiting equitable global medical deployment. To bridge this gap, we introduce Med-CoReasoner, a language-informed co-reasoning framework that elicits parallel English and local-language reasoning, abstracts them into structured concepts, and integrates local clinical knowledge into an English logical scaffold via concept-level alignment and retrieval. This design combines the structural robustness of English reasoning with the practice-grounded expertise encoded in local languages. To evaluate multilingual medical reasoning beyond multiple-choice settings, we construct MultiMed-X, a benchmark covering seven languages with expert-annotated long-form question answering and natural language inference tasks, comprising 350 instances per language. Experiments across three benchmarks show that Med-CoReasoner improves multilingual reasoning performance by an average of 5%, with particularly substantial gains in low-resource languages. Moreover, model distillation and expert evaluation analysis further confirm that Med-CoReasoner produces clinically sound and culturally grounded reasoning traces.",
        "url": "http://arxiv.org/abs/2601.08267v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08267v1",
        "arxiv_id": "2601.08267v1",
        "authors": [
            "Fan Gao",
            "Sherry T. Tong",
            "Jiwoong Sohn",
            "Jiahao Huang",
            "Junfeng Jiang",
            "Ding Xia",
            "Piyalitt Ittichaiwong",
            "Kanyakorn Veerakanjana",
            "Hyunjae Kim",
            "Qingyu Chen",
            "Edison Marrese Taylor",
            "Kazuma Kobayashi",
            "Akkiko Aizawa",
            "Irene Li"
        ],
        "submitted": "2026-01-13 06:51:40",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multilingual medical reasoning and language-informed co-reasoning, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context is specific to medical reasoning and deployment, which is not a primary area of interest for the user."
    },
    {
        "title": "Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models",
        "abstract": "Rich and informative profiling to capture user preferences is essential for improving recommendation quality. However, there is still no consensus on how best to construct and utilize such profiles. To address this, we revisit recent profiling-based approaches in recommender systems along four dimensions: 1) knowledge base, 2) preference indicator, 3) impact range, and 4) subject. We argue that large language models (LLMs) are effective at extracting compressed rationales from diverse knowledge sources, while knowledge graphs (KGs) are better suited for propagating these profiles to extend their reach. Building on this insight, we propose a new recommendation model, called SPiKE. SPiKE consists of three core components: i) Entity profile generation, which uses LLMs to generate semantic profiles for all KG entities; ii) Profile-aware KG aggregation, which integrates these profiles into the KG; and iii) Pairwise profile preference matching, which aligns LLM- and KG-based representations during training. In experiments, we demonstrate that SPiKE consistently outperforms state-of-the-art KG- and LLM-based recommenders in real-world settings.",
        "url": "http://arxiv.org/abs/2601.08148v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08148v1",
        "arxiv_id": "2601.08148v1",
        "authors": [
            "Seokho Ahn",
            "Sungbok Shin",
            "Young-Duk Seo"
        ],
        "submitted": "2026-01-13 02:23:32",
        "source": "arxiv",
        "comment": "Accepted at KDD 2026",
        "score": 4,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Information Retrieval and Recommender Systems, but it focuses more on the application of Large Language Models in Recommender Systems, which is not the user's primary focus. The paper's emphasis on knowledge graphs and recommender systems is somewhat relevant to the user's background in e-commerce and interests in NLP, but it does not align with the user's core research themes in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Attention Projection Mixing and Exogenous Anchors",
        "abstract": "Transformers that reuse early-layer attention projections as residuals face a fundamental tension: the first layer must simultaneously serve as a stable reference for all deeper layers and as an effective computational block. To resolve this, we propose ExoFormer, which learns dedicated exogenous anchor projections outside the sequential layer stack, decoupling the anchor role from computational refinement. Through a unified normalized mixing framework (studying different coefficient granularities: elementwise, headwise, scalar) across all attention pathways (queries, keys, values, and gate logits), ExoFormer variants consistently outperform their internal-anchor counterparts. Moreover, the dynamic variant achieves a 2.13-point increase in downstream accuracy over the baseline and demonstrates superior data efficiency, matching baseline validation loss with 1.84x fewer tokens. ExoFormer also achieves a 2x reduction in attention sink compared to standard Gated Attention. Paradoxically, all ExoFormer variants exhibit signs of representation collapse. We explain this via an Offloading Hypothesis: external anchors preserve essential token identity, allowing layers to specialize exclusively in computational refinement. We release codes and models to facilitate future research.",
        "url": "http://arxiv.org/abs/2601.08131v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08131v1",
        "arxiv_id": "2601.08131v1",
        "authors": [
            "Jonathan Su"
        ],
        "submitted": "2026-01-13 01:52:19",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving transformer architectures, specifically addressing issues with early-layer attention projections. While it touches on attention mechanisms, which are related to ranking models, the paper's primary contribution is in the area of natural language processing and transformer design, which is not a central match to your research interests in information retrieval and search technologies."
    },
    {
        "title": "Navigating Ideation Space: Decomposed Conceptual Representations for Positioning Scientific Ideas",
        "abstract": "Scientific discovery is a cumulative process and requires new ideas to be situated within an ever-expanding landscape of existing knowledge. An emerging and critical challenge is how to identify conceptually relevant prior work from rapidly growing literature, and assess how a new idea differentiates from existing research. Current embedding approaches typically conflate distinct conceptual aspects into single representations and cannot support fine-grained literature retrieval; meanwhile, LLM-based evaluators are subject to sycophancy biases, failing to provide discriminative novelty assessment. To tackle these challenges, we introduce the Ideation Space, a structured representation that decomposes scientific knowledge into three distinct dimensions, i.e., research problem, methodology, and core findings, each learned through contrastive training. This framework enables principled measurement of conceptual distance between ideas, and modeling of ideation transitions that capture the logical connections within a proposed idea. Building upon this representation, we propose a Hierarchical Sub-Space Retrieval framework for efficient, targeted literature retrieval, and a Decomposed Novelty Assessment algorithm that identifies which aspects of an idea are novel. Extensive experiments demonstrate substantial improvements, where our approach achieves Recall@30 of 0.329 (16.7% over baselines), our ideation transition retrieval reaches Hit Rate@30 of 0.643, and novelty assessment attains 0.37 correlation with expert judgments. In summary, our work provides a promising paradigm for future research on accelerating and evaluating scientific discovery.",
        "url": "http://arxiv.org/abs/2601.08901v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08901v1",
        "arxiv_id": "2601.08901v1",
        "authors": [
            "Yuexi Shen",
            "Minqian Liu",
            "Dawei Zhou",
            "Lifu Huang"
        ],
        "submitted": "2026-01-13 18:56:11",
        "source": "arxiv",
        "comment": "21 pages, 6 tables",
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on a structured representation of scientific knowledge, addressing challenges in literature retrieval and novelty assessment. While it involves some aspects of information retrieval, its primary focus is on scientific discovery and knowledge representation, which aligns with the broader scope of information retrieval but is not directly related to query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "FusID: Modality-Fused Semantic IDs for Generative Music Recommendation",
        "abstract": "Generative recommendation systems have achieved significant advances by leveraging semantic IDs to represent items. However, existing approaches that tokenize each modality independently face two critical limitations: (1) redundancy across modalities that reduces efficiency, and (2) failure to capture inter-modal interactions that limits item representation. We introduce FusID, a modality-fused semantic ID framework that addresses these limitations through three key components: (i) multimodal fusion that learns unified representations by jointly encoding information across modalities, (ii) representation learning that brings frequently co-occurring item embeddings closer while maintaining distinctiveness and preventing feature redundancy, and (iii) product quantization that converts the fused continuous embeddings into multiple discrete tokens to mitigate ID conflict. Evaluated on a multimodal next-song recommendation (i.e., playlist continuation) benchmark, FusID achieves zero ID conflicts, ensuring that each token sequence maps to exactly one song, mitigates codebook underutilization, and outperforms baselines in terms of MRR and Recall@k (k = 1, 5, 10, 20).",
        "url": "http://arxiv.org/abs/2601.08764v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08764v1",
        "arxiv_id": "2601.08764v1",
        "authors": [
            "Haven Kim",
            "Yupeng Hou",
            "Julian McAuley"
        ],
        "submitted": "2026-01-13 17:51:07",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on generative music recommendation using a modality-fused semantic ID framework, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves representation learning and optimization, the context is specific to music recommendation and does not align with the user's interests in e-commerce or real-time relevance optimization."
    },
    {
        "title": "RMBRec: Robust Multi-Behavior Recommendation towards Target Behaviors",
        "abstract": "Multi-behavior recommendation faces a critical challenge in practice: auxiliary behaviors (e.g., clicks, carts) are often noisy, weakly correlated, or semantically misaligned with the target behavior (e.g., purchase), which leads to biased preference learning and suboptimal performance. While existing methods attempt to fuse these heterogeneous signals, they inherently lack a principled mechanism to ensure robustness against such behavioral inconsistency.\n  In this work, we propose Robust Multi-Behavior Recommendation towards Target Behaviors (RMBRec), a robust multi-behavior recommendation framework grounded in an information-theoretic robustness principle. We interpret robustness as a joint process of maximizing predictive information while minimizing its variance across heterogeneous behavioral environments. Under this perspective, the Representation Robustness Module (RRM) enhances local semantic consistency by maximizing the mutual information between users' auxiliary and target representations, whereas the Optimization Robustness Module (ORM) enforces global stability by minimizing the variance of predictive risks across behaviors, which is an efficient approximation to invariant risk minimization. This local-global collaboration bridges representation purification and optimization invariance in a theoretically coherent way. Extensive experiments on three real-world datasets demonstrate that RMBRec not only outperforms state-of-the-art methods in accuracy but also maintains remarkable stability under various noise perturbations. For reproducibility, our code is available at https://github.com/miaomiao-cai2/RMBRec/.",
        "url": "http://arxiv.org/abs/2601.08705v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08705v1",
        "arxiv_id": "2601.08705v1",
        "authors": [
            "Miaomiao Cai",
            "Zhijie Zhang",
            "Junfeng Fang",
            "Zhiyong Cheng",
            "Xiang Wang",
            "Meng Wang"
        ],
        "submitted": "2026-01-13 16:34:17",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'click' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper RMBRec: Robust Multi-Behavior Recommendation towards Target Behaviors is somewhat related to the user's interests in Information Retrieval and Search technologies, particularly in the context of recommender systems. However, the focus on robust multi-behavior recommendation and its application in e-commerce does not directly align with the user's primary research themes of query understanding, ranking models, and user behavior modeling in the context of search technologies."
    },
    {
        "title": "Nationality and Region Prediction from Names: A Comparative Study of Neural Models and Large Language Models",
        "abstract": "Predicting nationality from personal names has practical value in marketing, demographic research, and genealogical studies. Conventional neural models learn statistical correspondences between names and nationalities from task-specific training data, posing challenges in generalizing to low-frequency nationalities and distinguishing similar nationalities within the same region. Large language models (LLMs) have the potential to address these challenges by leveraging world knowledge acquired during pre-training. In this study, we comprehensively compare neural models and LLMs on nationality prediction, evaluating six neural models and six LLM prompting strategies across three granularity levels (nationality, region, and continent), with frequency-based stratified analysis and error analysis. Results show that LLMs outperform neural models at all granularity levels, with the gap narrowing as granularity becomes coarser. Simple machine learning methods exhibit the highest frequency robustness, while pre-trained models and LLMs show degradation for low-frequency nationalities. Error analysis reveals that LLMs tend to make ``near-miss'' errors, predicting the correct region even when nationality is incorrect, whereas neural models exhibit more cross-regional errors and bias toward high-frequency classes. These findings indicate that LLM superiority stems from world knowledge, model selection should consider required granularity, and evaluation should account for error quality beyond accuracy.",
        "url": "http://arxiv.org/abs/2601.08692v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08692v1",
        "arxiv_id": "2601.08692v1",
        "authors": [
            "Keito Inoshita"
        ],
        "submitted": "2026-01-13 16:17:04",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling. While it involves machine learning and NLP, the focus is on nationality and region prediction from names, which is outside your primary areas of interest."
    },
    {
        "title": "QuantEval: A Benchmark for Financial Quantitative Tasks in Large Language Models",
        "abstract": "Large Language Models (LLMs) have shown strong capabilities across many domains, yet their evaluation in financial quantitative tasks remains fragmented and mostly limited to knowledge-centric question answering. We introduce QuantEval, a benchmark that evaluates LLMs across three essential dimensions of quantitative finance: knowledge-based QA, quantitative mathematical reasoning, and quantitative strategy coding. Unlike prior financial benchmarks, QuantEval integrates a CTA-style backtesting framework that executes model-generated strategies and evaluates them using financial performance metrics, enabling a more realistic assessment of quantitative coding ability. We evaluate some state-of-the-art open-source and proprietary LLMs and observe substantial gaps to human experts, particularly in reasoning and strategy coding. Finally, we conduct large-scale supervised fine-tuning and reinforcement learning experiments on domain-aligned data, demonstrating consistent improvements. We hope QuantEval will facilitate research on LLMs' quantitative finance capabilities and accelerate their practical adoption in real-world trading workflows. We additionally release the full deterministic backtesting configuration (asset universe, cost model, and metric definitions) to ensure strict reproducibility.",
        "url": "http://arxiv.org/abs/2601.08689v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08689v1",
        "arxiv_id": "2601.08689v1",
        "authors": [
            "Zhaolu Kang",
            "Junhao Gong",
            "Wenqing Hu",
            "Shuo Yin",
            "Kehan Jiang",
            "Zhicheng Fang",
            "Yingjie He",
            "Chunlei Meng",
            "Rong Fu",
            "Dongyang Chen",
            "Leqi Zheng",
            "Eric Hanchen Jiang",
            "Yunfei Feng",
            "Yitong Leng",
            "Junfan Zhu",
            "Xiaoyou Chen",
            "Xi Yang",
            "Richeng Xuan"
        ],
        "submitted": "2026-01-13 16:14:23",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on evaluating Large Language Models in financial quantitative tasks, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves NLP, the context and application are quite different from the user's areas of focus."
    },
    {
        "title": "Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement",
        "abstract": "With the development of large language models (LLMs) in the field of programming, intelligent programming coaching systems have gained widespread attention. However, most research focuses on repairing the buggy code of programming learners without providing the underlying causes of the bugs. To address this gap, we introduce a novel task, namely \\textbf{LPR} (\\textbf{L}earner-Tailored \\textbf{P}rogram \\textbf{R}epair). We then propose a novel and effective framework, \\textbf{\\textsc{\\MethodName{}}} (\\textbf{L}earner-Tailored \\textbf{S}olution \\textbf{G}enerator), to enhance program repair while offering the bug descriptions for the buggy code. In the first stage, we utilize a repair solution retrieval framework to construct a solution retrieval database and then employ an edit-driven code retrieval approach to retrieve valuable solutions, guiding LLMs in identifying and fixing the bugs in buggy code. In the second stage, we propose a solution-guided program repair method, which fixes the code and provides explanations under the guidance of retrieval solutions. Moreover, we propose an Iterative Retrieval Enhancement method that utilizes evaluation results of the generated code to iteratively optimize the retrieval direction and explore more suitable repair strategies, improving performance in practical programming coaching scenarios. The experimental results show that our approach outperforms a set of baselines by a large margin, validating the effectiveness of our framework for the newly proposed LPR task.",
        "url": "http://arxiv.org/abs/2601.08545v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08545v1",
        "arxiv_id": "2601.08545v1",
        "authors": [
            "Zhenlong Dai",
            "Zhuoluo Zhao",
            "Hengning Wang",
            "Xiu Tang",
            "Sai Wu",
            "Chang Yao",
            "Zhipeng Gao",
            "Jingyuan Chen"
        ],
        "submitted": "2026-01-13 13:31:11",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on programming repair and coaching systems, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves retrieval and optimization, the context is specific to programming and does not align with your broader interests in e-commerce, query understanding, and real-time relevance optimization."
    },
    {
        "title": "GraphFusionSBR: Denoising Multi-Channel Graphs for Session-Based Recommendation",
        "abstract": "Session-based recommendation systems must capture implicit user intents from sessions. However, existing models suffer from issues such as item interaction dominance and noisy sessions. We propose a multi-channel recommendation model, including a knowledge graph channel, a session hypergraph channel, and a session line graph channel, to capture information from multiple sources. Our model adaptively removes redundant edges in the knowledge graph channel to reduce noise. Knowledge graph representations cooperate with hypergraph representations for prediction to alleviate item dominance. We also generate in-session attention for denoising. Finally, we maximize mutual information between the hypergraph and line graph channels as an auxiliary task. Experiments demonstrate that our method enhances the accuracy of various recommendations, including e-commerce and multimedia recommendations. We release the code on GitHub for reproducibility.\\footnote{https://github.com/hohehohe0509/DSR-HK}",
        "url": "http://arxiv.org/abs/2601.08497v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08497v1",
        "arxiv_id": "2601.08497v1",
        "authors": [
            "Jia-Xin He",
            "Hung-Hsuan Chen"
        ],
        "submitted": "2026-01-13 12:32:31",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on session-based recommendation systems, which is somewhat related to information retrieval, but it primarily deals with recommender systems and graph-based models. While it touches on user behavior modeling, it's not directly related to query understanding, ranking models, or click models. The use of knowledge graphs and hypergraphs is interesting, but it's not a central match for the user's research interests."
    },
    {
        "title": "JudgeRLVR: Judge First, Generate Second for Efficient Reasoning",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has become a standard paradigm for reasoning in Large Language Models. However, optimizing solely for final-answer correctness often drives models into aimless, verbose exploration, where they rely on exhaustive trial-and-error tactics rather than structured planning to reach solutions. While heuristic constraints like length penalties can reduce verbosity, they often truncate essential reasoning steps, creating a difficult trade-off between efficiency and verification. In this paper, we argue that discriminative capability is a prerequisite for efficient generation: by learning to distinguish valid solutions, a model can internalize a guidance signal that prunes the search space. We propose JudgeRLVR, a two-stage judge-then-generate paradigm. In the first stage, we train the model to judge solution responses with verifiable answers. In the second stage, we fine-tune the same model with vanilla generating RLVR initialized from the judge. Compared to Vanilla RLVR using the same math-domain training data, JudgeRLVR achieves a better quality--efficiency trade-off for Qwen3-30B-A3B: on in-domain math, it delivers about +3.7 points average accuracy gain with -42\\% average generation length; on out-of-domain benchmarks, it delivers about +4.5 points average accuracy improvement, demonstrating enhanced generalization.",
        "url": "http://arxiv.org/abs/2601.08468v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08468v1",
        "arxiv_id": "2601.08468v1",
        "authors": [
            "Jiangshan Duo",
            "Hanyu Li",
            "Hailin Zhang",
            "Yudong Wang",
            "Sujian Li",
            "Liang Zhao"
        ],
        "submitted": "2026-01-13 11:47:42",
        "source": "arxiv",
        "comment": "16 pages, 5 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores a novel approach to reasoning in Large Language Models, focusing on efficient generation and verification. While it touches on aspects of query understanding and ranking models, its primary focus is on NLP and generation, which aligns with your interests but is not a central match. The paper's emphasis on efficiency and verification is somewhat related to your interests in real-time relevance optimization, but the connection is not strong enough to warrant a higher score."
    },
    {
        "title": "An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English",
        "abstract": "Digital platforms have an ever-expanding user base, and act as a hub for communication, business, and connectivity. However, this has also allowed for the spread of hate speech and misogyny. Artificial intelligence models have emerged as an effective solution for countering online hate speech but are under explored for low resource and code-mixed languages and suffer from a lack of interpretability. Explainable Artificial Intelligence (XAI) can enhance transparency in the decisions of deep learning models, which is crucial for a sensitive domain such as hate speech detection. In this paper, we present a multi-modal and explainable web application for detecting misogyny in text and memes in code-mixed Hindi and English. The system leverages state-of-the-art transformer-based models that support multilingual and multimodal settings. For text-based misogyny identification, the system utilizes XLM-RoBERTa (XLM-R) and multilingual Bidirectional Encoder Representations from Transformers (mBERT) on a dataset of approximately 4,193 comments. For multimodal misogyny identification from memes, the system utilizes mBERT + EfficientNet, and mBERT + ResNET trained on a dataset of approximately 4,218 memes. It also provides feature importance scores using explainability techniques including Shapley Additive Values (SHAP) and Local Interpretable Model Agnostic Explanations (LIME). The application aims to serve as a tool for both researchers and content moderators, to promote further research in the field, combat gender based digital violence, and ensure a safe digital space. The system has been evaluated using human evaluators who provided their responses on Chatbot Usability Questionnaire (CUQ) and User Experience Questionnaire (UEQ) to determine overall usability.",
        "url": "http://arxiv.org/abs/2601.08457v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08457v1",
        "arxiv_id": "2601.08457v1",
        "authors": [
            "Sargam Yadav",
            "Abhishek Kaushik",
            "Kevin Mc Daid"
        ],
        "submitted": "2026-01-13 11:31:55",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on explainable multimodal misogyny detection in code-mixed Hindi-English, which is not directly related to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves deep learning models and explainability techniques, the application domain and specific problem addressed are not aligned with your primary research interests."
    },
    {
        "title": "Scalable Sequential Recommendation under Latency and Memory Constraints",
        "abstract": "Sequential recommender systems must model long-range user behavior while operating under strict memory and latency constraints. Transformer-based approaches achieve strong accuracy but suffer from quadratic attention complexity, forcing aggressive truncation of user histories and limiting their practicality for long-horizon modeling. This paper presents HoloMambaRec, a lightweight sequential recommendation architecture that combines holographic reduced representations for attribute-aware embedding with a selective state space encoder for linear-time sequence processing. Item and attribute information are bound using circular convolution, preserving embedding dimensionality while encoding structured metadata. A shallow selective state space backbone, inspired by recent Mamba-style models, enables efficient training and constant-time recurrent inference. Experiments on Amazon Beauty and MovieLens-1M datasets demonstrate that HoloMambaRec consistently outperforms SASRec and achieves competitive performance with GRU4Rec under a constrained 10-epoch training budget, while maintaining substantially lower memory complexity. The design further incorporates forward-compatible mechanisms for temporal bundling and inference-time compression, positioning HoloMambaRec as a practical and extensible alternative for scalable, metadata-aware sequential recommendation.",
        "url": "http://arxiv.org/abs/2601.08360v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08360v1",
        "arxiv_id": "2601.08360v1",
        "authors": [
            "Adithya Parthasarathy",
            "Aswathnarayan Muthukrishnan Kirubakaran",
            "Vinoth Punniyamoorthy",
            "Nachiappan Chockalingam",
            "Lokesh Butra",
            "Kabilan Kannan",
            "Abhirup Mazumder",
            "Sumit Saha"
        ],
        "submitted": "2026-01-13 09:16:49",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'user behavior' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on sequential recommendation, which is a related but distinct area from information retrieval. While it touches on some aspects of deep semantic understanding, its primary contribution is in recommender systems, which is not the user's primary focus. The paper's emphasis on scalability and memory constraints is also not directly relevant to the user's interests in IR and search technologies."
    },
    {
        "title": "CLaS-Bench: A Cross-Lingual Alignment and Steering Benchmark",
        "abstract": "Understanding and controlling the behavior of large language models (LLMs) is an increasingly important topic in multilingual NLP. Beyond prompting or fine-tuning, , i.e.,~manipulating internal representations during inference, has emerged as a more efficient and interpretable technique for adapting models to a target language. Yet, no dedicated benchmarks or evaluation protocols exist to quantify the effectiveness of steering techniques. We introduce CLaS-Bench, a lightweight parallel-question benchmark for evaluating language-forcing behavior in LLMs across 32 languages, enabling systematic evaluation of multilingual steering methods. We evaluate a broad array of steering techniques, including residual-stream DiffMean interventions, probe-derived directions, language-specific neurons, PCA/LDA vectors, Sparse Autoencoders, and prompting baselines. Steering performance is measured along two axes: language control and semantic relevance, combined into a single harmonic-mean steering score. We find that across languages simple residual-based DiffMean method consistently outperforms all other methods. Moreover, a layer-wise analysis reveals that language-specific structure emerges predominantly in later layers and steering directions cluster based on language family. CLaS-Bench is the first standardized benchmark for multilingual steering, enabling both rigorous scientific analysis of language representations and practical evaluation of steering as a low-cost adaptation alternative.",
        "url": "http://arxiv.org/abs/2601.08331v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08331v1",
        "arxiv_id": "2601.08331v1",
        "authors": [
            "Daniil Gurgurov",
            "Yusser Al Ghussin",
            "Tanja Baeumel",
            "Cheng-Ting Chou",
            "Patrick Schramowski",
            "Marius Mosbach",
            "Josef van Genabith",
            "Simon Ostermann"
        ],
        "submitted": "2026-01-13 08:42:03",
        "source": "arxiv",
        "comment": "pre-print",
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper CLaS-Bench is somewhat related to the user's interests in Natural Language Processing (NLP) and deep semantic understanding, but it does not directly align with the user's primary focus on Information Retrieval (IR), query understanding, and ranking models. The paper's focus on language model steering and multilingual NLP is relevant, but it does not appear to be a central match for the user's research interests."
    },
    {
        "title": "Mechanisms are Transferable: Data-Efficient Low-Resource Adaptation via Circuit-Targeted Supervised Fine-Tuning",
        "abstract": "Adapting LLMs to low-resource languages is difficult: labeled data is scarce, full-model fine-tuning is unstable, and continued cross-lingual tuning can cause catastrophic forgetting. We propose Circuit-Targeted Supervised Fine-Tuning (CT-SFT): a counterfactual-free adaptation of CD-T (Contextual Decomposition Transformer) that uses a label-balanced mean baseline and task-directional relevance scoring to identify a sparse set of task-relevant attention heads in a proxy-language checkpoint, then transfer learns to a target language by updating only those heads (plus LayerNorm) via head-level gradient masking. Across NusaX-Senti and XNLI, CT-SFT improves cross-lingual accuracy over continued full fine-tuning while updating only a small subset of model parameters. We find an editing-preserving trade-off: harder transfers favor editing circuit heads, while easier transfers often favor near-zero (i.e., low-relevance heads) updates, preserving the source mechanism. CT-SFT also substantially reduces catastrophic forgetting, preserving proxy/source-language competence during transfer.",
        "url": "http://arxiv.org/abs/2601.08146v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08146v1",
        "arxiv_id": "2601.08146v1",
        "authors": [
            "Khumaisa Nur'aini",
            "Ayu Purwarianti",
            "Alham Fikri Aji",
            "Derry Wijaya"
        ],
        "submitted": "2026-01-13 02:20:53",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on adapting Large Language Models (LLMs) to low-resource languages, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. While it involves fine-tuning and relevance scoring, the context is NLP and language adaptation, making it somewhat tangential to the user's core research interests."
    },
    {
        "title": "FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures",
        "abstract": "Scientific compound figures combine multiple labeled panels into a single image, but captions in real pipelines are often missing or only provide figure-level summaries, making panel-level understanding difficult. In this paper, we propose FigEx2, visual-conditioned framework that localizes panels and generates panel-wise captions directly from the compound figure. To mitigate the impact of diverse phrasing in open-ended captioning, we introduce a noise-aware gated fusion module that adaptively filters token-level features to stabilize the detection query space. Furthermore, we employ a staged optimization strategy combining supervised learning with reinforcement learning (RL), utilizing CLIP-based alignment and BERTScore-based semantic rewards to enforce strict multimodal consistency. To support high-quality supervision, we curate BioSci-Fig-Cap, a refined benchmark for panel-level grounding, alongside cross-disciplinary test suites in physics and chemistry. Experimental results demonstrate that FigEx2 achieves a superior 0.726 mAP@0.5:0.95 for detection and significantly outperforms Qwen3-VL-8B by 0.51 in METEOR and 0.24 in BERTScore. Notably, FigEx2 exhibits remarkable zero-shot transferability to out-of-distribution scientific domains without any fine-tuning.",
        "url": "http://arxiv.org/abs/2601.08026v2",
        "pdf_url": "https://arxiv.org/pdf/2601.08026v2",
        "arxiv_id": "2601.08026v2",
        "authors": [
            "Jifeng Song",
            "Arun Das",
            "Pan Wang",
            "Hui Ji",
            "Kun Zhao",
            "Yufei Huang"
        ],
        "submitted": "2026-01-12 21:57:52",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on visual panel detection and captioning for scientific compound figures, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some NLP aspects, such as caption generation, it is more aligned with computer vision and multimodal learning, and does not seem to address your primary research themes of query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Spatial Context Improves the Integration of Text with Remote Sensing for Mapping Environmental Variables",
        "abstract": "Recent developments in natural language processing highlight text as an emerging data source for ecology. Textual resources carry unique information that can be used in complementarity with geospatial data sources, thus providing insights at the local scale into environmental conditions and properties hidden from more traditional data sources. Leveraging textual information in a spatial context presents several challenges. First, the contribution of textual data remains poorly defined in an ecological context, and it is unclear for which tasks it should be incorporated. Unlike ubiquitous satellite imagery or environmental covariates, the availability of textual data is sparse and irregular; its integration with geospatial data is not straightforward. In response to these challenges, this work proposes an attention-based approach that combines aerial imagery and geolocated text within a spatial neighbourhood, i.e. integrating contributions from several nearby observations. Our approach combines vision and text representations with a geolocation encoding, with an attention-based module that dynamically selects spatial neighbours that are useful for predictive tasks.The proposed approach is applied to the EcoWikiRS dataset, which combines high-resolution aerial imagery with sentences extracted from Wikipedia describing local environmental conditions across Switzerland. Our model is evaluated on the task of predicting 103 environmental variables from the SWECO25 data cube. Our approach consistently outperforms single-location or unimodal, i.e. image-only or text-only, baselines. When analysing variables by thematic groups, results show a significant improvement in performance for climatic, edaphic, population and land use/land cover variables, underscoring the benefit of including the spatial context when combining text and image data.",
        "url": "http://arxiv.org/abs/2601.08750v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08750v1",
        "arxiv_id": "2601.08750v1",
        "authors": [
            "Valerie Zermatten",
            "Chiara Vanalli",
            "Gencer Sumbul",
            "Diego Marcos",
            "Devis Tuia"
        ],
        "submitted": "2026-01-13 17:27:16",
        "source": "arxiv",
        "comment": "submitted",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it involves text integration with geospatial data and attention-based approaches. However, the focus on environmental variables and remote sensing is not a central match to your core research themes."
    },
    {
        "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents",
        "abstract": "Attributional inference, the ability to predict latent intentions behind observed actions, is a critical yet underexplored capability for large language models (LLMs) operating in multi-agent environments. Traditional natural language inference (NLI), in fact, fails to capture the nuanced, intention-driven reasoning essential for complex interactive systems. To address this gap, we introduce Attributional NLI (Att-NLI), a framework that extends NLI with principles from social psychology to assess an agent's capacity for abductive intentional inference (generating hypotheses about latent intentions), and subsequent deductive verification (drawing valid logical conclusions). We instantiate Att-NLI via a textual game, Undercover-V, experimenting with three types of LLM agents with varying reasoning capabilities and access to external tools: a standard NLI agent using only deductive inference, an Att-NLI agent employing abductive-deductive inference, and a neuro-symbolic Att-NLI agent performing abductive-deductive inference with external theorem provers. Extensive experiments demonstrate a clear hierarchy of attributional inference capabilities, with neuro-symbolic agents consistently outperforming others, achieving an average win rate of 17.08%. Our results underscore the role that Att-NLI can play in developing agents with sophisticated reasoning capabilities, highlighting, at the same time, the potential impact of neuro-symbolic AI in building rational LLM agents acting in multi-agent environments.",
        "url": "http://arxiv.org/abs/2601.08742v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08742v1",
        "arxiv_id": "2601.08742v1",
        "authors": [
            "Xin Quan",
            "Jiafeng Xiong",
            "Marco Valentino",
            "André Freitas"
        ],
        "submitted": "2026-01-13 17:18:38",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores attributional natural language inference, which is somewhat related to query understanding and ranking models in Information Retrieval. However, it primarily focuses on developing agents with sophisticated reasoning capabilities for multi-agent environments, which is not a central match to your research interests. The paper's emphasis on social psychology and neuro-symbolic AI also diverges from your core areas of interest in IR and NLP."
    },
    {
        "title": "A Parallel Cross-Lingual Benchmark for Multimodal Idiomaticity Understanding",
        "abstract": "Potentially idiomatic expressions (PIEs) construe meanings inherently tied to the everyday experience of a given language community. As such, they constitute an interesting challenge for assessing the linguistic (and to some extent cultural) capabilities of NLP systems. In this paper, we present XMPIE, a parallel multilingual and multimodal dataset of potentially idiomatic expressions. The dataset, containing 34 languages and over ten thousand items, allows comparative analyses of idiomatic patterns among language-specific realisations and preferences in order to gather insights about shared cultural aspects. This parallel dataset allows to evaluate model performance for a given PIE in different languages and whether idiomatic understanding in one language can be transferred to another. Moreover, the dataset supports the study of PIEs across textual and visual modalities, to measure to what extent PIE understanding in one modality transfers or implies in understanding in another modality (text vs. image). The data was created by language experts, with both textual and visual components crafted under multilingual guidelines, and each PIE is accompanied by five images representing a spectrum from idiomatic to literal meanings, including semantically related and random distractors. The result is a high-quality benchmark for evaluating multilingual and multimodal idiomatic language understanding.",
        "url": "http://arxiv.org/abs/2601.08645v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08645v1",
        "arxiv_id": "2601.08645v1",
        "authors": [
            "Dilara Torunoğlu-Selamet",
            "Dogukan Arslan",
            "Rodrigo Wilkens",
            "Wei He",
            "Doruk Eryiğit",
            "Thomas Pickard",
            "Adriana S. Pagano",
            "Aline Villavicencio",
            "Gülşen Eryiğit",
            "Ágnes Abuczki",
            "Aida Cardoso",
            "Alesia Lazarenka",
            "Dina Almassova",
            "Amalia Mendes",
            "Anna Kanellopoulou",
            "Antoni Brosa-Rodríguez",
            "Baiba Saulite",
            "Beata Wojtowicz",
            "Bolette Pedersen",
            "Carlos Manuel Hidalgo-Ternero",
            "Chaya Liebeskind",
            "Danka Jokić",
            "Diego Alves",
            "Eleni Triantafyllidi",
            "Erik Velldal",
            "Fred Philippy",
            "Giedre Valunaite Oleskeviciene",
            "Ieva Rizgeliene",
            "Inguna Skadina",
            "Irina Lobzhanidze",
            "Isabell Stinessen Haugen",
            "Jauza Akbar Krito",
            "Jelena M. Marković",
            "Johanna Monti",
            "Josue Alejandro Sauca",
            "Kaja Dobrovoljc",
            "Kingsley O. Ugwuanyi",
            "Laura Rituma",
            "Lilja Øvrelid",
            "Maha Tufail Agro",
            "Manzura Abjalova",
            "Maria Chatzigrigoriou",
            "María del Mar Sánchez Ramos",
            "Marija Pendevska",
            "Masoumeh Seyyedrezaei",
            "Mehrnoush Shamsfard",
            "Momina Ahsan",
            "Muhammad Ahsan Riaz Khan",
            "Nathalie Carmen Hau Norman",
            "Nilay Erdem Ayyıldız",
            "Nina Hosseini-Kivanani",
            "Noémi Ligeti-Nagy",
            "Numaan Naeem",
            "Olha Kanishcheva",
            "Olha Yatsyshyna",
            "Daniil Orel",
            "Petra Giommarelli",
            "Petya Osenova",
            "Radovan Garabik",
            "Regina E. Semou",
            "Rozane Rebechi",
            "Salsabila Zahirah Pranida",
            "Samia Touileb",
            "Sanni Nimb",
            "Sarfraz Ahmad",
            "Sarvinoz Nematkhonova",
            "Shahar Golan",
            "Shaoxiong Ji",
            "Sopuruchi Christian Aboh",
            "Srdjan Sucur",
            "Stella Markantonatou",
            "Sussi Olsen",
            "Vahide Tajalli",
            "Veronika Lipp",
            "Voula Giouli",
            "Yelda Yeşildal Eraydın",
            "Zahra Saaberi",
            "Zhuohan Xie"
        ],
        "submitted": "2026-01-13 15:20:28",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on multimodal idiomaticity understanding, which is not directly related to the user's core research themes in Information Retrieval and Search technologies. Although it involves Natural Language Processing, the specific topic of idiomatic expressions and their understanding across languages and modalities does not align closely with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "VeriTaS: The First Dynamic Benchmark for Multimodal Automated Fact-Checking",
        "abstract": "The growing scale of online misinformation urgently demands Automated Fact-Checking (AFC). Existing benchmarks for evaluating AFC systems, however, are largely limited in terms of task scope, modalities, domain, language diversity, realism, or coverage of misinformation types. Critically, they are static, thus subject to data leakage as their claims enter the pretraining corpora of LLMs. As a result, benchmark performance no longer reliably reflects the actual ability to verify claims. We introduce Verified Theses and Statements (VeriTaS), the first dynamic benchmark for multimodal AFC, designed to remain robust under ongoing large-scale pretraining of foundation models. VeriTaS currently comprises 24,000 real-world claims from 108 professional fact-checking organizations across 54 languages, covering textual and audiovisual content. Claims are added quarterly via a fully automated seven-stage pipeline that normalizes claim formulation, retrieves original media, and maps heterogeneous expert verdicts to a novel, standardized, and disentangled scoring scheme with textual justifications. Through human evaluation, we demonstrate that the automated annotations closely match human judgments. We commit to update VeriTaS in the future, establishing a leakage-resistant benchmark, supporting meaningful AFC evaluation in the era of rapidly evolving foundation models. We will make the code and data publicly available.",
        "url": "http://arxiv.org/abs/2601.08611v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08611v1",
        "arxiv_id": "2601.08611v1",
        "authors": [
            "Mark Rothermel",
            "Marcus Kornmann",
            "Marcus Rohrbach",
            "Anna Rohrbach"
        ],
        "submitted": "2026-01-13 14:56:40",
        "source": "arxiv",
        "comment": "Preprint under review",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Automated Fact-Checking, which is not a core area of interest for you. While it involves multimodal content and real-world claims, it does not directly relate to your primary research themes in Information Retrieval, Search technologies, or Natural Language Processing."
    },
    {
        "title": "Spectral Generative Flow Models: A Physics-Inspired Replacement for Vectorized Large Language Models",
        "abstract": "We introduce Spectral Generative Flow Models (SGFMs), a physics-inspired alternative to transformer-based large language models. Instead of representing text or video as sequences of discrete tokens processed by attention, SGFMs treat generation as the evolution of a continuous field governed by constrained stochastic dynamics in a multiscale wavelet basis. This formulation replaces global attention with local operators, spectral projections, and Navier--Stokes-like transport, yielding a generative mechanism grounded in continuity, geometry, and physical structure.\n  Our framework provides three key innovations: (i) a field-theoretic ontology in which text and video are unified as trajectories of a stochastic partial differential equation; (ii) a wavelet-domain representation that induces sparsity, scale separation, and computational efficiency; and (iii) a constrained stochastic flow that enforces stability, coherence, and uncertainty propagation. Together, these components define a generative architecture that departs fundamentally from autoregressive modeling and diffusion-based approaches. SGFMs offer a principled path toward long-range coherence, multimodal generality, and physically structured inductive bias in next-generation generative models.",
        "url": "http://arxiv.org/abs/2601.08893v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08893v1",
        "arxiv_id": "2601.08893v1",
        "authors": [
            "Andrew Kiruluta"
        ],
        "submitted": "2026-01-13 12:50:24",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on generative models for text and video, leveraging physics-inspired concepts. While it touches on the idea of representation and processing, it doesn't seem to align with the user's primary research interests in Information Retrieval, Search technologies, and related topics. The paper's focus on generative models and multimodal generality doesn't directly relate to the user's core themes."
    },
    {
        "title": "What If TSF: A Benchmark for Reframing Forecasting as Scenario-Guided Multimodal Forecasting",
        "abstract": "Time series forecasting is critical to real-world decision making, yet most existing approaches remain unimodal and rely on extrapolating historical patterns. While recent progress in large language models (LLMs) highlights the potential for multimodal forecasting, existing benchmarks largely provide retrospective or misaligned raw context, making it unclear whether such models meaningfully leverage textual inputs. In practice, human experts incorporate what-if scenarios with historical evidence, often producing distinct forecasts from the same observations under different scenarios. Inspired by this, we introduce What If TSF (WIT), a multimodal forecasting benchmark designed to evaluate whether models can condition their forecasts on contextual text, especially future scenarios. By providing expert-crafted plausible or counterfactual scenarios, WIT offers a rigorous testbed for scenario-guided multimodal forecasting. The benchmark is available at https://github.com/jinkwan1115/WhatIfTSF.",
        "url": "http://arxiv.org/abs/2601.08509v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08509v1",
        "arxiv_id": "2601.08509v1",
        "authors": [
            "Jinkwan Jang",
            "Hyunbin Jin",
            "Hyungjin Park",
            "Kyubyung Chae",
            "Taesup Kim"
        ],
        "submitted": "2026-01-13 12:47:43",
        "source": "arxiv",
        "comment": "30 pages, 5 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on time series forecasting and multimodal forecasting, which is outside your primary research interests in Information Retrieval and Search technologies. Although it involves large language models, the context is not related to query understanding, ranking models, or user behavior modeling, making it less relevant to your core research themes."
    },
    {
        "title": "Surgical Refusal Ablation: Disentangling Safety from Intelligence via Concept-Guided Spectral Cleaning",
        "abstract": "Safety-aligned language models systematically refuse harmful requests. While activation steering can modulate refusal, ablating the raw \"refusal vector\" calculated from contrastive harmful and harmless prompts often causes collateral damage and distribution drift. We argue this degradation occurs because the raw vector is polysemantic, entangling the refusal signal with core capability circuits and linguistic style.\n  We introduce Surgical Refusal Ablation (SRA) to distill these steering directions. SRA constructs a registry of independent Concept Atoms representing protected capabilities and stylistic confounds, then uses ridge-regularized spectral residualization to orthogonalize the refusal vector against these directions. This yields a clean refusal direction that targets refusal-relevant structure while minimizing disruption to the model's semantic geometry.\n  Across five models (Qwen3-VL and Ministral series), SRA achieves deep refusal reduction (0-2%) with negligible perplexity impact on Wikitext-2 (mean delta PPL approx. 0.02) and minimal distribution drift. Notably, standard ablation on Qwen3-VL-4B induces severe drift (first-token KL = 2.088), whereas SRA maintains the original distribution (KL = 0.044) while achieving the same 0% refusal rate. Using teacher-forced perplexity on GSM8K and MBPP as a high-resolution capability proxy, we show SRA preserves math and code distributions. These results suggest that common \"model damage\" is often \"Ghost Noise,\" defined as the spectral bleeding of the dirty refusal direction into capability subspaces.",
        "url": "http://arxiv.org/abs/2601.08489v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08489v1",
        "arxiv_id": "2601.08489v1",
        "authors": [
            "Tony Cristofano"
        ],
        "submitted": "2026-01-13 12:21:44",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be unrelated to your primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language models and spectral cleaning, the focus is on safety-aligned language models and refusal vectors, which does not align with your core themes."
    },
    {
        "title": "Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models",
        "abstract": "Mixture-of-Experts (MoE) architectures decouple model capacity from per-token computation, enabling scaling beyond the computational limits imposed by dense scaling laws. Yet how MoE architectures shape knowledge acquisition during pre-training, and how this process differs from dense architectures, remains unknown. To address this issue, we introduce Gated-LPI (Log-Probability Increase), a neuron-level attribution metric that decomposes log-probability increase across neurons. We present a time-resolved comparison of knowledge acquisition dynamics in MoE and dense architectures, tracking checkpoints over 1.2M training steps (~ 5.0T tokens) and 600K training steps (~ 2.5T tokens), respectively. Our experiments uncover three patterns: (1) Low-entropy backbone. The top approximately 1% of MoE neurons capture over 45% of positive updates, forming a high-utility core, which is absent in the dense baseline. (2) Early consolidation. The MoE model locks into a stable importance profile within < 100K steps, whereas the dense model remains volatile throughout training. (3) Functional robustness. Masking the ten most important MoE attention heads reduces relational HIT@10 by < 10%, compared with > 50% for the dense model, showing that sparsity fosters distributed -- rather than brittle -- knowledge storage. These patterns collectively demonstrate that sparsity fosters an intrinsically stable and distributed computational backbone from early in training, helping bridge the gap between sparse architectures and training-time interpretability.",
        "url": "http://arxiv.org/abs/2601.08383v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08383v1",
        "arxiv_id": "2601.08383v1",
        "authors": [
            "Bo Wang",
            "Junzhuo Li",
            "Hong Chen",
            "Yuanlin Chu",
            "Yuxuan Fan",
            "Xuming Hu"
        ],
        "submitted": "2026-01-13 09:44:00",
        "source": "arxiv",
        "comment": "Accepted by AAAI26",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Mixture-of-Experts (MoE) architectures and their knowledge acquisition during pre-training, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. While it touches on deep learning and model interpretability, it doesn't align with the user's core research themes."
    },
    {
        "title": "Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis",
        "abstract": "The integration of large language models (LLMs) into autonomous agents has enabled complex tool use, yet in high-stakes domains, these systems must strictly adhere to regulatory standards beyond simple functional correctness. However, existing benchmarks often overlook implicit regulatory compliance, thus failing to evaluate whether LLMs can autonomously enforce mandatory safety constraints. To fill this gap, we introduce LogiSafetyGen, a framework that converts unstructured regulations into Linear Temporal Logic oracles and employs logic-guided fuzzing to synthesize valid, safety-critical traces. Building on this framework, we construct LogiSafetyBench, a benchmark comprising 240 human-verified tasks that require LLMs to generate Python programs that satisfy both functional objectives and latent compliance rules. Evaluations of 13 state-of-the-art (SOTA) LLMs reveal that larger models, despite achieving better functional correctness, frequently prioritize task completion over safety, which results in non-compliant behavior.",
        "url": "http://arxiv.org/abs/2601.08196v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08196v1",
        "arxiv_id": "2601.08196v1",
        "authors": [
            "Da Song",
            "Yuheng Huang",
            "Boqi Chen",
            "Tianshuo Cong",
            "Randy Goebel",
            "Lei Ma",
            "Foutse Khomh"
        ],
        "submitted": "2026-01-13 03:55:18",
        "source": "arxiv",
        "comment": "11 pages, 3 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. The focus on regulatory compliance and safety constraints in large language models is outside your primary areas of interest."
    },
    {
        "title": "Qalb: Largest State-of-the-Art Urdu Large Language Model for 230M Speakers with Systematic Continued Pre-training",
        "abstract": "Despite remarkable progress in large language models, Urdu-a language spoken by over 230 million people-remains critically underrepresented in modern NLP systems. Existing multilingual models demonstrate poor performance on Urdu-specific tasks, struggling with the language's complex morphology, right-to-left Nastaliq script, and rich literary traditions. Even the base LLaMA-3.1 8B-Instruct model shows limited capability in generating fluent, contextually appropriate Urdu text. We introduce Qalb, an Urdu language model developed through a two-stage approach: continued pre-training followed by supervised fine-tuning. Starting from LLaMA 3.1 8B, we perform continued pre-training on a dataset of 1.97 billion tokens. This corpus comprises 1.84 billion tokens of diverse Urdu text-spanning news archives, classical and contemporary literature, government documents, and social media-combined with 140 million tokens of English Wikipedia data to prevent catastrophic forgetting. We then fine-tune the resulting model on the Alif Urdu-instruct dataset. Through extensive evaluation on Urdu-specific benchmarks, Qalb demonstrates substantial improvements, achieving a weighted average score of 90.34 and outperforming the previous state-of-the-art Alif-1.0-Instruct model (87.1) by 3.24 points, while also surpassing the base LLaMA-3.1 8B-Instruct model by 44.64 points. Qalb achieves state-of-the-art performance with comprehensive evaluation across seven diverse tasks including Classification, Sentiment Analysis, and Reasoning. Our results demonstrate that continued pre-training on diverse, high-quality language data, combined with targeted instruction fine-tuning, effectively adapts foundation models to low-resource languages.",
        "url": "http://arxiv.org/abs/2601.08141v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08141v1",
        "arxiv_id": "2601.08141v1",
        "authors": [
            "Muhammad Taimoor Hassan",
            "Jawad Ahmed",
            "Muhammad Awais"
        ],
        "submitted": "2026-01-13 02:05:05",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on developing a large language model for the Urdu language, which is not directly related to information retrieval, search technologies, or query understanding. While it does involve natural language processing, the primary goal is to improve language understanding in a low-resource language, which is not a central match for the user's research interests."
    },
    {
        "title": "Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models",
        "abstract": "Chain-of-Thought (CoT) prompting has improved the reasoning performance of large language models (LLMs), but it remains unclear why it works and whether it is the unique mechanism for triggering reasoning in large language models. In this work, we study this question by directly analyzing and intervening on the internal representations of LLMs with Sparse Autoencoders (SAEs), identifying a small set of latent features that are causally associated with LLM reasoning behavior. Across multiple model families and reasoning benchmarks, we find that steering a single reasoning-related latent feature can substantially improve accuracy without explicit CoT prompting. For large models, latent steering achieves performance comparable to standard CoT prompting while producing more efficient outputs. We further observe that this reasoning-oriented internal state is triggered early in generation and can override prompt-level instructions that discourage explicit reasoning. Overall, our results suggest that multi-step reasoning in LLMs is supported by latent internal activations that can be externally activated, while CoT prompting is one effective, but not unique, way of activating this mechanism rather than its necessary cause.",
        "url": "http://arxiv.org/abs/2601.08058v1",
        "pdf_url": "https://arxiv.org/pdf/2601.08058v1",
        "arxiv_id": "2601.08058v1",
        "authors": [
            "Zhenghao He",
            "Guangzhi Xiong",
            "Bohan Liu",
            "Sanchit Sinha",
            "Aidong Zhang"
        ],
        "submitted": "2026-01-12 23:01:21",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing, as it focuses on the internal workings of Large Language Models and their reasoning capabilities. While it touches on the topic of deep semantic understanding, it does not address real-time relevance optimization or query understanding, making it only loosely relevant to your research."
    },
    {
        "title": "VULCA-Bench: A Multicultural Vision-Language Benchmark for Evaluating Cultural Understanding",
        "abstract": "We introduce VULCA-Bench, a multicultural art-critique benchmark for evaluating Vision-Language Models' (VLMs) cultural understanding beyond surface-level visual perception. Existing VLM benchmarks predominantly measure L1-L2 capabilities (object recognition, scene description, and factual question answering) while under-evaluate higher-order cultural interpretation. VULCA-Bench contains 7,410 matched image-critique pairs spanning eight cultural traditions, with Chinese-English bilingual coverage. We operationalise cultural understanding using a five-layer framework (L1-L5, from Visual Perception to Philosophical Aesthetics), instantiated as 225 culture-specific dimensions and supported by expert-written bilingual critiques. Our pilot results indicate that higher-layer reasoning (L3-L5) is consistently more challenging than visual and technical analysis (L1-L2). The dataset, evaluation scripts, and annotation tools are available under CC BY 4.0 in the supplementary materials.",
        "url": "http://arxiv.org/abs/2601.07986v1",
        "pdf_url": "https://arxiv.org/pdf/2601.07986v1",
        "arxiv_id": "2601.07986v1",
        "authors": [
            "Haorui Yu",
            "Ramon Ruiz-Dolz",
            "Diji Yang",
            "Hang He",
            "Fengrui Zhang",
            "Qiufeng Yi"
        ],
        "submitted": "2026-01-12 20:36:30",
        "source": "arxiv",
        "comment": "8 pages, 4 figures, submitted to ACL 2026 Dataset Track",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on evaluating cultural understanding in Vision-Language Models, which is outside the primary scope of your research interests in Information Retrieval and Search technologies. While it touches on the intersection of vision and language, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of your research."
    }
]