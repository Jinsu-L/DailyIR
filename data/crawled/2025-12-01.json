[
    {
        "title": "Generalized Medical Phrase Grounding",
        "abstract": "Medical phrase grounding (MPG) maps textual descriptions of radiological findings to corresponding image regions. These grounded reports are easier to interpret, especially for non-experts. Existing MPG systems mostly follow the referring expression comprehension (REC) paradigm and return exactly one bounding box per phrase. Real reports often violate this assumption. They contain multi-region findings, non-diagnostic text, and non-groundable phrases, such as negations or descriptions of normal anatomy. Motivated by this, we reformulate the task as generalised medical phrase grounding (GMPG), where each sentence is mapped to zero, one, or multiple scored regions. To realise this formulation, we introduce the first GMPG model: MedGrounder. We adopted a two-stage training regime: pre-training on report sentence--anatomy box alignment datasets and fine-tuning on report sentence--human annotated box datasets. Experiments on PadChest-GR and MS-CXR show that MedGrounder achieves strong zero-shot transfer and outperforms REC-style and grounded report generation baselines on multi-region and non-groundable phrases, while using far fewer human box annotations. Finally, we show that MedGrounder can be composed with existing report generators to produce grounded reports without retraining the generator.",
        "url": "http://arxiv.org/abs/2512.01085v1",
        "pdf_url": "https://arxiv.org/pdf/2512.01085v1",
        "arxiv_id": "2512.01085v1",
        "authors": [
            "Wenjun Zhang",
            "Shekhar S. Chandra",
            "Aaron Nicolson"
        ],
        "submitted": "2025-11-30 21:09:41",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Testing the Machine Consciousness Hypothesis",
        "abstract": "The Machine Consciousness Hypothesis states that consciousness is a substrate-free functional property of computational systems capable of second-order perception. I propose a research program to investigate this idea in silico by studying how collective self-models (coherent, self-referential representations) emerge from distributed learning systems embedded within universal self-organizing environments. The theory outlined here starts from the supposition that consciousness is an emergent property of collective intelligence systems undergoing synchronization of prediction through communication. It is not an epiphenomenon of individual modeling but a property of the language that a system evolves to internally describe itself. For a model of base reality, I begin with a minimal but general computational world: a cellular automaton, which exhibits both computational irreducibility and local reducibility. On top of this computational substrate, I introduce a network of local, predictive, representational (neural) models capable of communication and adaptation. I use this layered model to study how collective intelligence gives rise to self-representation as a direct consequence of inter-agent alignment. I suggest that consciousness does not emerge from modeling per se, but from communication. It arises from the noisy, lossy exchange of predictive messages between groups of local observers describing persistent patterns in the underlying computational substrate (base reality). It is through this representational dialogue that a shared model arises, aligning many partial views of the world. The broader goal is to develop empirically testable theories of machine consciousness, by studying how internal self-models may form in distributed systems without centralized control.",
        "url": "http://arxiv.org/abs/2512.01081v1",
        "pdf_url": "https://arxiv.org/pdf/2512.01081v1",
        "arxiv_id": "2512.01081v1",
        "authors": [
            "Stephen Fitz"
        ],
        "submitted": "2025-11-30 21:05:48",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "ELR-1000: A Community-Generated Dataset for Endangered Indic Indigenous Languages",
        "abstract": "We present a culturally-grounded multimodal dataset of 1,060 traditional recipes crowdsourced from rural communities across remote regions of Eastern India, spanning 10 endangered languages. These recipes, rich in linguistic and cultural nuance, were collected using a mobile interface designed for contributors with low digital literacy. Endangered Language Recipes (ELR)-1000 -- captures not only culinary practices but also the socio-cultural context embedded in indigenous food traditions. We evaluate the performance of several state-of-the-art large language models (LLMs) on translating these recipes into English and find the following: despite the models' capabilities, they struggle with low-resource, culturally-specific language. However, we observe that providing targeted context -- including background information about the languages, translation examples, and guidelines for cultural preservation -- leads to significant improvements in translation quality. Our results underscore the need for benchmarks that cater to underrepresented languages and domains to advance equitable and culturally-aware language technologies. As part of this work, we release the ELR-1000 dataset to the NLP community, hoping it motivates the development of language technologies for endangered languages.",
        "url": "http://arxiv.org/abs/2512.01077v1",
        "pdf_url": "https://arxiv.org/pdf/2512.01077v1",
        "arxiv_id": "2512.01077v1",
        "authors": [
            "Neha Joshi",
            "Pamir Gogoi",
            "Aasim Mirza",
            "Aayush Jansari",
            "Aditya Yadavalli",
            "Ayushi Pandey",
            "Arunima Shukla",
            "Deepthi Sudharsan",
            "Kalika Bali",
            "Vivek Seshadri"
        ],
        "submitted": "2025-11-30 20:51:20",
        "source": "arxiv",
        "comment": "Accepted at AACL 2025 (Main)"
    },
    {
        "title": "When Safety Blocks Sense: Measuring Semantic Confusion in LLM Refusals",
        "abstract": "Safety-aligned language models often refuse prompts that are actually harmless. Current evaluations mostly report global rates such as false rejection or compliance. These scores treat each prompt alone and miss local inconsistency, where a model accepts one phrasing of an intent but rejects a close paraphrase. This gap limits diagnosis and tuning. We introduce \"semantic confusion,\" a failure mode that captures such local inconsistency, and a framework to measure it. We build ParaGuard, a 10k-prompt corpus of controlled paraphrase clusters that hold intent fixed while varying surface form. We then propose three model-agnostic metrics at the token level: Confusion Index, Confusion Rate, and Confusion Depth. These metrics compare each refusal to its nearest accepted neighbors and use token embeddings, next-token probabilities, and perplexity signals. Experiments across diverse model families and deployment guards show that global false-rejection rate hides critical structure. Our metrics reveal globally unstable boundaries in some settings, localized pockets of inconsistency in others, and cases where stricter refusal does not increase inconsistency. We also show how confusion-aware auditing separates how often a system refuses from how sensibly it refuses. This gives developers a practical signal to reduce false refusals while preserving safety.",
        "url": "http://arxiv.org/abs/2512.01037v1",
        "pdf_url": "https://arxiv.org/pdf/2512.01037v1",
        "arxiv_id": "2512.01037v1",
        "authors": [
            "Riad Ahmed Anonto",
            "Md Labid Al Nahiyan",
            "Md Tanvir Hassan",
            "Ch. Md. Rakin Haider"
        ],
        "submitted": "2025-11-30 19:11:45",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Associative Syntax and Maximal Repetitions reveal context-dependent complexity in fruit bat communication",
        "abstract": "This study presents an unsupervised method to infer discreteness, syntax and temporal structures of fruit-bats vocalizations, as a case study of graded vocal systems, and evaluates the complexity of communication patterns in relation with behavioral context. The method improved the baseline for unsupervised labeling of vocal units (i.e. syllables) through manifold learning, by investigating how dimen- sionality reduction on mel-spectrograms affects labeling, and comparing it with unsupervised labels based on acoustic similarity. We then encoded vocalizations as syllabic sequences to analyze the type of syntax, and extracted the Maximal Repetitions (MRs) to evaluate syntactical structures. We found evidence for: i) associative syntax, rather than combinatorial (context classification is unaffected by permutation of sequences, F 1 > 0.9); ii) context-dependent use of syllables (Wilcoxon rank-sum tests, p-value < 0.05); iii) heavy-tail distribution of MRs (truncated power-law, exponent Î± < 2), indicative of mechanism encoding com- binatorial complexity. Analysis of MRs and syllabic transition networks revealed that mother-pupil interactions were characterized by repetitions, while commu- nication in conflict-contexts exhibited higher complexity (longer MRs and more interconnected vocal sequences) than non-agonistic contexts. We propose that communicative complexity is higher in scenarios of disagreement, reflecting lower compressibility of information.",
        "url": "http://arxiv.org/abs/2512.01033v1",
        "pdf_url": "https://arxiv.org/pdf/2512.01033v1",
        "arxiv_id": "2512.01033v1",
        "authors": [
            "Luigi Assom"
        ],
        "submitted": "2025-11-30 19:01:59",
        "source": "arxiv",
        "comment": "Accepted for a lightning talk at the NeurIPS 2025 Workshop: \"AI for Non-Human Animal Communication\""
    },
    {
        "title": "Evaluating Legal Reasoning Traces with Legal Issue Tree Rubrics",
        "abstract": "Evaluating the quality of LLM-generated reasoning traces in expert domains (e.g., law) is essential for ensuring credibility and explainability, yet remains challenging due to the inherent complexity of such reasoning tasks. We introduce LEGIT (LEGal Issue Trees), a novel large-scale (24K instances) expert-level legal reasoning dataset with an emphasis on reasoning trace evaluation. We convert court judgments into hierarchical trees of opposing parties' arguments and the court's conclusions, which serve as rubrics for evaluating the issue coverage and correctness of the reasoning traces. We verify the reliability of these rubrics via human expert annotations and comparison with coarse, less informative rubrics. Using the LEGIT dataset, we show that (1) LLMs' legal reasoning ability is seriously affected by both legal issue coverage and correctness, and that (2) retrieval-augmented generation (RAG) and RL with rubrics bring complementary benefits for legal reasoning abilities, where RAG improves overall reasoning capability, whereas RL improves correctness albeit with reduced coverage.",
        "url": "http://arxiv.org/abs/2512.01020v1",
        "pdf_url": "https://arxiv.org/pdf/2512.01020v1",
        "arxiv_id": "2512.01020v1",
        "authors": [
            "Jinu Lee",
            "Kyoung-Woon On",
            "Simeng Han",
            "Arman Cohan",
            "Julia Hockenmaier"
        ],
        "submitted": "2025-11-30 18:32:43",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Advancing Academic Chatbots: Evaluation of Non Traditional Outputs",
        "abstract": "Most evaluations of large language models focus on standard tasks such as factual question answering or short summarization. This research expands that scope in two directions: first, by comparing two retrieval strategies, Graph RAG, structured knowledge-graph based, and Advanced RAG, hybrid keyword-semantic search, for QA; and second, by evaluating whether LLMs can generate high quality non-traditional academic outputs, specifically slide decks and podcast scripts. We implemented a prototype combining Meta's LLaMA 3 70B open weight and OpenAI's GPT 4o mini API based. QA performance was evaluated using both human ratings across eleven quality dimensions and large language model judges for scalable cross validation. GPT 4o mini with Advanced RAG produced the most accurate responses. Graph RAG offered limited improvements and led to more hallucinations, partly due to its structural complexity and manual setup. Slide and podcast generation was tested with document grounded retrieval. GPT 4o mini again performed best, though LLaMA 3 showed promise in narrative coherence. Human reviewers were crucial for detecting layout and stylistic flaws, highlighting the need for combined human LLM evaluation in assessing emerging academic outputs.",
        "url": "http://arxiv.org/abs/2512.00991v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00991v1",
        "arxiv_id": "2512.00991v1",
        "authors": [
            "Nicole Favero",
            "Francesca Salute",
            "Daniel Hardt"
        ],
        "submitted": "2025-11-30 17:25:23",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Dr.Mi-Bench: A Modular-integrated Benchmark for Scientific Deep Research Agent",
        "abstract": "The explosive growth in academic literature necessitates automated deep research (DR) agents, yet their evaluation remains a significant challenge. First, existing benchmarks often focus narrowly on retrieval while neglecting high-level planning and reasoning. Second, existing benchmarks favor general domains over the scientific domains that are the core application for DR agents. To address these gaps, we introduce Dr.Mi-Bench, a Modular-integrated benchmark for scientific DR agents. Grounded in academic literature, our benchmark uses a human-annotated dataset of 200 instances across 10 scientific domains, including both research and review papers. Besides, we also propose a Modular-integrated Evaluation Paradigm for DR Agents (Dr.Mi-Eval), a novel modular-integrated evaluation paradigm, which leverages the rich structure of academic papers to assess the core competencies of planning, retrieval, and reasoning through two complementary modes: an end-to-end evaluation for DR agents and an isolated evaluation for foundational LLMs as potential backbones. Experimental results reveal a fragmented performance landscape: agents exhibit specialized strengths but share critical weaknesses, most notably in performing the multi-source retrieval required for review-style tasks and performing consistently across diverse scientific fields. Moreover, improving high-level planning capability is the crucial factor for unlocking the reasoning potential of foundational LLMs as backbones. By exposing these actionable failure modes, Dr.Mi-Bench provides a diagnostic tool to guide the development of more reliable academic research assistants.",
        "url": "http://arxiv.org/abs/2512.00986v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00986v1",
        "arxiv_id": "2512.00986v1",
        "authors": [
            "Zhihan Guo",
            "Feiyang Xu",
            "Yifan Li",
            "Muzhi Li",
            "Shuai Zou",
            "Jiele Wu",
            "Han Shi",
            "Haoli Bai",
            "Ho-fung Leung",
            "Irwin King"
        ],
        "submitted": "2025-11-30 17:16:47",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Optimizing Generative Ranking Relevance via Reinforcement Learning in Xiaohongshu Search",
        "abstract": "Ranking relevance is a fundamental task in search engines, aiming to identify the items most relevant to a given user query. Traditional relevance models typically produce scalar scores or directly predict relevance labels, limiting both interpretability and the modeling of complex relevance signals. Inspired by recent advances in Chain-of-Thought (CoT) reasoning for complex tasks, we investigate whether explicit reasoning can enhance both interpretability and performance in relevance modeling. However, existing reasoning-based Generative Relevance Models (GRMs) primarily rely on supervised fine-tuning on large amounts of human-annotated or synthetic CoT data, which often leads to limited generalization. Moreover, domain-agnostic, free-form reasoning tends to be overly generic and insufficiently grounded, limiting its potential to handle the diverse and ambiguous cases prevalent in open-domain search. In this work, we formulate relevance modeling in Xiaohongshu search as a reasoning task and introduce a Reinforcement Learning (RL)-based training framework to enhance the grounded reasoning capabilities of GRMs. Specifically, we incorporate practical business-specific relevance criteria into the multi-step reasoning prompt design and propose Stepwise Advantage Masking (SAM), a lightweight process-supervision strategy which facilitates effective learning of these criteria through improved credit assignment. To enable industrial deployment, we further distill the large-scale RL-tuned model to a lightweight version suitable for real-world search systems. Extensive experiments on industrial datasets, along with online A/B tests, demonstrate the effectiveness of our approach.",
        "url": "http://arxiv.org/abs/2512.00968v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00968v1",
        "arxiv_id": "2512.00968v1",
        "authors": [
            "Ziyang Zeng",
            "Heming Jing",
            "Jindong Chen",
            "Xiangli Li",
            "Hongyu Liu",
            "Yixuan He",
            "Zhengyu Li",
            "Yige Sun",
            "Zheyong Xie",
            "Yuqing Yang",
            "Shaosheng Cao",
            "Jun Fan",
            "Yi Wu",
            "Yao Hu"
        ],
        "submitted": "2025-11-30 16:31:16",
        "source": "arxiv",
        "comment": "Accepted by KDD 2026 ADS Track"
    },
    {
        "title": "Table as a Modality for Large Language Models",
        "abstract": "To migrate the remarkable successes of Large Language Models (LLMs), the community has made numerous efforts to generalize them to the table reasoning tasks for the widely deployed tabular data. Despite that, in this work, by showing a probing experiment on our proposed StructQA benchmark, we postulate that even the most advanced LLMs (such as GPTs) may still fall short of coping with tabular data. More specifically, the current scheme often simply relies on serializing the tabular data, together with the meta information, then inputting them through the LLMs. We argue that the loss of structural information is the root of this shortcoming. In this work, we further propose TAMO, which bears an ideology to treat the tables as an independent modality integrated with the text tokens. The resulting model in TAMO is a multimodal framework consisting of a hypergraph neural network as the global table encoder seamlessly integrated with the mainstream LLM. Empirical results on various benchmarking datasets, including HiTab, WikiTQ, WikiSQL, FeTaQA, and StructQA, have demonstrated significant improvements on generalization with an average relative gain of 42.65%.",
        "url": "http://arxiv.org/abs/2512.00947v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00947v1",
        "arxiv_id": "2512.00947v1",
        "authors": [
            "Liyao Li",
            "Chao Ye",
            "Wentao Ye",
            "Yifei Sun",
            "Zhe Jiang",
            "Haobo Wang",
            "Jiaming Tian",
            "Yiming Zhang",
            "Ningtao Wang",
            "Xing Fu",
            "Gang Chen",
            "Junbo Zhao"
        ],
        "submitted": "2025-11-30 15:59:56",
        "source": "arxiv",
        "comment": "Accepted to NeurIPS 2025"
    },
    {
        "title": "Fine-tuning of lightweight large language models for sentiment classification on heterogeneous financial textual data",
        "abstract": "Large language models (LLMs) play an increasingly important role in finan- cial markets analysis by capturing signals from complex and heterogeneous textual data sources, such as tweets, news articles, reports, and microblogs. However, their performance is dependent on large computational resources and proprietary datasets, which are costly, restricted, and therefore inacces- sible to many researchers and practitioners. To reflect realistic situations we investigate the ability of lightweight open-source LLMs - smaller and publicly available models designed to operate with limited computational resources - to generalize sentiment understanding from financial datasets of varying sizes, sources, formats, and languages. We compare the benchmark finance natural language processing (NLP) model, FinBERT, and three open-source lightweight LLMs, DeepSeek-LLM 7B, Llama3 8B Instruct, and Qwen3 8B on five publicly available datasets: FinancialPhraseBank, Financial Question Answering, Gold News Sentiment, Twitter Sentiment and Chinese Finance Sentiment. We find that LLMs, specially Qwen3 8B and Llama3 8B, perform best in most scenarios, even from using only 5% of the available training data. These results hold in zero-shot and few-shot learning scenarios. Our findings indicate that lightweight, open-source large language models (LLMs) consti- tute a cost-effective option, as they can achieve competitive performance on heterogeneous textual data even when trained on only a limited subset of the extensive annotated corpora that are typically deemed necessary.",
        "url": "http://arxiv.org/abs/2512.00946v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00946v1",
        "arxiv_id": "2512.00946v1",
        "authors": [
            "Alvaro Paredes Amorin",
            "Andre Python",
            "Christoph Weisser"
        ],
        "submitted": "2025-11-30 15:58:22",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "DeformAr: Rethinking NER Evaluation through Component Analysis and Visual Analytics",
        "abstract": "Transformer models have significantly advanced Natural Language Processing (NLP), demonstrating strong performance in English. However, their effectiveness in Arabic, particularly for Named Entity Recognition (NER), remains limited, even with larger pre-trained models. This performance gap stems from multiple factors, including tokenisation, dataset quality, and annotation inconsistencies. Existing studies often analyze these issues in isolation, failing to capture their joint effect on system behaviour and performance.\n  We introduce DeformAr (Debugging and Evaluation Framework for Transformer-based NER Systems), a novel framework designed to investigate and explain the performance discrepancy between Arabic and English NER systems. DeformAr integrates a data extraction library and an interactive dashboard, supporting two modes of evaluation: cross-component analysis and behavioural analysis. The framework divides each language into dataset and model components to examine their interactions.\n  The analysis proceeds in two stages. First, cross-component analysis provides systematic diagnostic measures across data and model subcomponents, addressing the \"what,\" \"how,\" and \"why\" behind observed discrepancies. The second stage applies behavioural analysis by combining interpretability techniques with token-level metrics, interactive visualisations, and representation space analysis. These stages enable a component-aware diagnostic process that detects model behaviours and explains them by linking them to underlying representational patterns and data factors. DeformAr is the first Arabic-specific, component-based interpretability tool, offering a crucial resource for advancing model analysis in under-resourced languages.",
        "url": "http://arxiv.org/abs/2512.00938v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00938v1",
        "arxiv_id": "2512.00938v1",
        "authors": [
            "Ahmed Mustafa Younes"
        ],
        "submitted": "2025-11-30 15:39:28",
        "source": "arxiv",
        "comment": "PhD Thesis, University of Sussex, 2025. 311 pages, 140 figures, 32 tables. Submitted as a PDF-only. First supervisor: Julie Weeds. Second supervisor: David Weir"
    },
    {
        "title": "Mitigating Hallucinations in Zero-Shot Scientific Summarisation: A Pilot Study",
        "abstract": "Large language models (LLMs) produce context inconsistency hallucinations, which are LLM generated outputs that are misaligned with the user prompt. This research project investigates whether prompt engineering (PE) methods can mitigate context inconsistency hallucinations in zero-shot LLM summarisation of scientific texts, where zero-shot indicates that the LLM relies purely on its pre-training data. Across eight yeast biotechnology research paper abstracts, six instruction-tuned LLMs were prompted with seven methods: a base- line prompt, two levels of increasing instruction complexity (PE-1 and PE-2), two levels of context repetition (CR-K1 and CR-K2), and two levels of random addition (RA-K1 and RA-K2). Context repetition involved the identification and repetition of K key sentences from the abstract, whereas random addition involved the repetition of K randomly selected sentences from the abstract, where K is 1 or 2. A total of 336 LLM-generated summaries were evaluated using six metrics: ROUGE-1, ROUGE-2, ROUGE-L, BERTScore, METEOR, and cosine similarity, which were used to compute the lexical and semantic alignment be- tween the summaries and the abstracts. Four hypotheses on the effects of prompt methods on summary alignment with the reference text were tested. Statistical analysis on 3744 collected datapoints was performed using bias-corrected and accelerated (BCa) bootstrap confidence intervals and Wilcoxon signed-rank tests with Bonferroni-Holm correction. The results demonstrated that CR and RA significantly improve the lexical alignment of LLM-generated summaries with the abstracts. These findings indicate that prompt engineering has the potential to impact hallucinations in zero-shot scientific summarisation tasks.",
        "url": "http://arxiv.org/abs/2512.00931v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00931v1",
        "arxiv_id": "2512.00931v1",
        "authors": [
            "Imane Jaaouine",
            "Ross D. King"
        ],
        "submitted": "2025-11-30 15:19:41",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Reward Auditor: Inference on Reward Modeling Suitability in Real-World Perturbed Scenarios",
        "abstract": "Reliable reward models (RMs) are critical for ensuring the safe alignment of large language models (LLMs). However, current evaluation methods focus solely on preference perception accuracies in given specific scenarios, obscuring the critical vulnerabilities of RMs in real-world scenarios. We identify the true challenge lies in assessing a novel dimension: Suitability, defined as conditional reliability under specific real-world perturbations. To this end, we introduce Reward Auditor, a hypothesis-testing framework specifically designed for RM suitability inference. Rather than answering \"How accurate is the RM's preference perception for given samples?\", it employs scientific auditing to answer: \"Can we infer RMs exhibit systematic vulnerabilities in specific real-world scenarios?\". Under real-world perturbed scenarios, Reward Auditor quantifies statistical significance and effect size by auditing distribution degradation of RM preference perception confidence. This enables inference of both the certainty and severity of RM vulnerabilities across diverse real-world scenarios. This lays a solid foundation for building next-generation LLM alignment systems that are verifiably safe, more robust, and trustworthy.",
        "url": "http://arxiv.org/abs/2512.00920v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00920v1",
        "arxiv_id": "2512.00920v1",
        "authors": [
            "Jianxiang Zang",
            "Yongda Wei",
            "Ruxue Bai",
            "Shiyu Jiang",
            "Nijia Mo",
            "Binhong Li",
            "Qiang Sun",
            "Hui Liu"
        ],
        "submitted": "2025-11-30 14:54:12",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Towards Active Synthetic Data Generation for Finetuning Language Models",
        "abstract": "A common and effective means for improving language model capabilities involves finetuning a ``student'' language model's parameters on generations from a more proficient ``teacher'' model. Termed ``synthetic data'', these generations are often produced before any student finetuning, but some work has considered generating new synthetic samples as training progresses. This paper studies and advocates for the latter case, where data are generated in an iterative, closed-loop fashion that is guided by the current state of the student model. For a fixed budget of generated samples, or a budget in terms of compute spent querying a teacher, we show that this curation of finetuning data affords improved student performance over static generation. Further, while there have been several LLM-specific methods proposed that operate in this regime, we find that simple, inexpensive selection criteria from the active learning literature tend to be most performant. We validate these claims across four mathematical and logical reasoning datasets using four different small language models.",
        "url": "http://arxiv.org/abs/2512.00884v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00884v1",
        "arxiv_id": "2512.00884v1",
        "authors": [
            "Samuel Kessler",
            "Menglin Xia",
            "Daniel Madrigal Diaz",
            "Dongge Han",
            "Helia Heshemi",
            "Saravan Rajmohan",
            "Victor Ruehle",
            "Jordan T. Ash"
        ],
        "submitted": "2025-11-30 13:13:00",
        "source": "arxiv",
        "comment": "14 figures, 36 pages"
    },
    {
        "title": "Less is More: Resource-Efficient Low-Rank Adaptation",
        "abstract": "Low-Rank Adaptation (LoRA) is a widely adopted parameter-efficient fine-tuning (PEFT) method for Large Language Models (LLMs), but it still incurs notable overhead and suffers from parameter interference in complex datasets. While re- cent works decouple LoRA update matrices to exploit matrix-wise asymmetry, training costs remain high. We revisit LoRA from the perspective of inter-matrix and intra-layer parameter redundancy and propose Resource-Efficient Low-Rank Adaptation, EffiLoRA, a lightweight and generalizable approach for language, multimodal, and diffusion models. EffiLoRA employs a unified A matrix across all transformer layers and introduces a runtime selective B matrices up- date to dynamically trade-off the system resource budget and model performance. EffiLoRA consistently outperforms LoRA across diverse modalities, including commonsense reasoning, visual instruction tuning, and image generation, demon- strating improved efficiency and robustness.",
        "url": "http://arxiv.org/abs/2512.00878v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00878v1",
        "arxiv_id": "2512.00878v1",
        "authors": [
            "Chunlin Tian",
            "Xuyang Wei",
            "Huanrong Liu",
            "Zhijiang Guo",
            "Li Li"
        ],
        "submitted": "2025-11-30 12:52:04",
        "source": "arxiv",
        "comment": "18 pages, 7 figures"
    },
    {
        "title": "One Swallow Does Not Make a Summer: Understanding Semantic Structures in Embedding Spaces",
        "abstract": "Embedding spaces are fundamental to modern AI, translating raw data into high-dimensional vectors that encode rich semantic relationships. Yet, their internal structures remain opaque, with existing approaches often sacrificing semantic coherence for structural regularity or incurring high computational overhead to improve interpretability. To address these challenges, we introduce the Semantic Field Subspace (SFS), a geometry-preserving, context-aware representation that captures local semantic neighborhoods within the embedding space. We also propose SAFARI (SemAntic Field subspAce deteRmInation), an unsupervised, modality-agnostic algorithm that uncovers hierarchical semantic structures using a novel metric called Semantic Shift, which quantifies how semantics evolve as SFSes evolve. To ensure scalability, we develop an efficient approximation of Semantic Shift that replaces costly SVD computations, achieving a 15~30x speedup with average errors below 0.01. Extensive evaluations across six real-world text and image datasets show that SFSes outperform standard classifiers not only in classification but also in nuanced tasks such as political bias detection, while SAFARI consistently reveals interpretable and generalizable semantic hierarchies. This work presents a unified framework for structuring, analyzing, and scaling semantic understanding in embedding spaces.",
        "url": "http://arxiv.org/abs/2512.00852v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00852v1",
        "arxiv_id": "2512.00852v1",
        "authors": [
            "Yandong Sun",
            "Qiang Huang",
            "Ziwei Xu",
            "Yiqun Sun",
            "Yixuan Tang",
            "Anthony K. H. Tung"
        ],
        "submitted": "2025-11-30 11:48:00",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "WaterSearch: A Quality-Aware Search-based Watermarking Framework for Large Language Models",
        "abstract": "Watermarking acts as a critical safeguard in text generated by Large Language Models (LLMs). By embedding identifiable signals into model outputs, watermarking enables reliable attribution and enhances the security of machine-generated content. Existing approaches typically embed signals by manipulating token generation probabilities. Despite their effectiveness, these methods inherently face a trade-off between detectability and text quality: the signal strength and randomness required for robust watermarking tend to degrade the performance of downstream tasks.\n  In this paper, we design a novel embedding scheme that controls seed pools to facilitate diverse parallel generation of watermarked text. Based on that scheme, we propose WaterSearch, a sentence-level, search-based watermarking framework adaptable to a wide range of existing methods. WaterSearch enhances text quality by jointly optimizing two key aspects: 1) distribution fidelity and 2) watermark signal characteristics. Furthermore, WaterSearch is complemented by a sentence-level detection method with strong attack robustness. We evaluate our method on three popular LLMs across ten diverse tasks. Extensive experiments demonstrate that our method achieves an average performance improvement of 51.01\\% over state-of-the-art baselines at a watermark detectability strength of 95\\%. In challenging scenarios such as short text generation and low-entropy output generation, our method yields performance gains of 47.78\\% and 36.47\\%, respectively. Moreover, under different attack senarios including insertion, synonym substitution and paraphrase attasks, WaterSearch maintains high detectability, further validating its robust anti-attack capabilities. Our code is available at \\href{https://github.com/Yukang-Lin/WaterSearch}{https://github.com/Yukang-Lin/WaterSearch}.",
        "url": "http://arxiv.org/abs/2512.00837v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00837v1",
        "arxiv_id": "2512.00837v1",
        "authors": [
            "Yukang Lin",
            "Jiahao Shao",
            "Shuoran Jiang",
            "Wentao Zhu",
            "Bingjie Lu",
            "Xiangping Wu",
            "Joanna Siebert",
            "Qingcai Chen"
        ],
        "submitted": "2025-11-30 11:11:21",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Accelerating Bangla NLP Tasks with Automatic Mixed Precision: Resource-Efficient Training Preserving Model Efficacy",
        "abstract": "Training models for Natural Language Processing (NLP) requires substantial computational resources and time, posing significant challenges, especially for NLP development in Bangla, where access to high-end hardware is often limited. In this work, we explore automatic mixed precision (AMP) training as a means to improve computational efficiency without sacrificing model performance. By leveraging a dynamic mix of 16-bit and 32-bit floating-point computations, AMP lowers GPU memory requirements and speeds up training without degrading model performance. We evaluate AMP across four standard Bangla NLP tasks, namely sentiment analysis, named entity recognition, error classification, and question answering, using four transformer-based models: BanglaBERT, BanglishBERT, XLM-R, and mBERT. Our results demonstrate that AMP accelerates training by 44.5% and reduces memory consumption by 17.6%, while maintaining F-1 score within 99.7% of the full-precision baselines. This empirical study highlights AMP's potential to democratize access to state-of-the-art NLP capabilities in hardware-constrained settings by lowering computational barriers.",
        "url": "http://arxiv.org/abs/2512.00829v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00829v1",
        "arxiv_id": "2512.00829v1",
        "authors": [
            "Md Mehrab Hossain Opi",
            "Sumaiya Khan",
            "Moshammad Farzana Rahman"
        ],
        "submitted": "2025-11-30 10:34:08",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Auxiliary-Hyperparameter-Free Sampling: Entropy Equilibrium for Text Generation",
        "abstract": "Token sampling strategies critically influence text generation quality in large language models (LLMs). However, existing methods introduce additional hyperparameters, requiring extensive tuning and complicating deployment. We present Entropy Equilibrium Sampling (EES), an auxiliary hyperparameter-free approach inspired by information theory that can dynamically adjust candidate sets by balancing normalized entropy with probability mass. We evaluate EES on both reasoning and generation tasks across a range of model architectures. Our results show that EES consistently performs well across temperature settings, delivering competitive accuracy and coherence while maintaining diversity. By eliminating the need for hyperparameter tuning, EES greatly simplifies deployment while improving performance. Code is available at https://github.com/shuanncai/EES",
        "url": "http://arxiv.org/abs/2512.00789v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00789v1",
        "arxiv_id": "2512.00789v1",
        "authors": [
            "Xiaodong Cai",
            "Hai Lin",
            "Shaoxiong Zhan",
            "Weiqi Luo",
            "Hong-Gee Kim",
            "Hongyan Hao",
            "Yu Yang",
            "Hai-Tao Zheng"
        ],
        "submitted": "2025-11-30 08:58:08",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "SHRAG: AFrameworkfor Combining Human-Inspired Search with RAG",
        "abstract": "Retrieval-Augmented Generation (RAG) is gaining recognition as one of the key technological axes for next generation information retrieval, owing to its ability to mitigate the hallucination phenomenon in Large Language\n  Models (LLMs)and effectively incorporate up-to-date information. However, specialized expertise is necessary to\n  construct ahigh-quality retrieval system independently; moreover, RAGdemonstratesrelativelyslowerprocessing\n  speeds compared to conventional pure retrieval systems because it involves both retrieval and generation stages.\n  Accordingly, this study proposes SHRAG, a novel framework designed to facilitate the seamless integration of\n  Information Retrieval and RAG while simultaneously securing precise retrieval performance. SHRAG utilizes a\n  Large Language Model as a Query Strategist to automatically transform unstructured natural language queries\n  into logically structured search queries, subsequently performing Boolean retrieval to emulate the search process\n  of an expert human searcher. Furthermore, it incorporates multilingual query expansion and a multilingual\n  embedding model, enabling it to perform efficient cross-lingual question answering within the multilingual\n  dataset environment of the ScienceON Challenge. Experimental results demonstrate that the proposed method,\n  combining logical retrieval capabilities and generative reasoning, can significantly enhance the accuracy and\n  reliability of RAG systems. Furthermore, SHRAG movesbeyondconventionaldocument-centric retrieval methods,\n  presenting the potential for a new search paradigm capable of providing direct and reliable responses to queries.",
        "url": "http://arxiv.org/abs/2512.00772v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00772v1",
        "arxiv_id": "2512.00772v1",
        "authors": [
            "Hyunseok Ryu",
            "Wonjune Shin",
            "Hyun Park"
        ],
        "submitted": "2025-11-30 08:06:47",
        "source": "arxiv",
        "comment": "10 pages, 4 figures, 1 table, 1 algorithm, 3 prompts"
    },
    {
        "title": "Text Mining Analysis of Symptom Patterns in Medical Chatbot Conversations",
        "abstract": "The fast growth of digital health systems has led to a need to better comprehend how they interpret and represent patient-reported symptoms. Chatbots have been used in healthcare to provide clinical support and enhance the user experience, making it possible to provide meaningful clinical patterns from text-based data through chatbots. The proposed research utilises several different natural language processing methods to study the occurrences of symptom descriptions in medicine as well as analyse the patterns that emerge through these conversations within medical bots. Through the use of the Medical Conversations to Disease Dataset which contains 960 multi-turn dialogues divided into 24 Clinical Conditions, a standardised representation of conversations between patient and bot is created for further analysis by computational means. The multi-method approach uses a variety of tools, including Latent Dirichlet Allocation (LDA) to identify latent symptom themes, K-Means to group symptom descriptions by similarity, Transformer-based Named Entity Recognition (NER) to extract medical concepts, and the Apriori algorithm to discover frequent symptom pairs. Findings from the analysis indicate a coherent structure of clinically relevant topics, moderate levels of clustering cohesiveness and several high confidence rates on the relationships between symptoms like fever headache and rash itchiness. The results support the notion that conversational medical data can be a valuable diagnostic signal for early symptom interpretation, assist in strengthening decision support and improve how users interact with tele-health technology. By demonstrating a method for converting unstructured free-flowing dialogue into actionable knowledge regarding symptoms this work provides an extensible framework to further enhance future performance, dependability and clinical utility of selecting medical chatbots.",
        "url": "http://arxiv.org/abs/2512.00768v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00768v1",
        "arxiv_id": "2512.00768v1",
        "authors": [
            "Hamed Razavi"
        ],
        "submitted": "2025-11-30 07:40:02",
        "source": "arxiv",
        "comment": "9 pages, 4 tables"
    },
    {
        "title": "FastPOS: Language-Agnostic Scalable POS Tagging Framework Low-Resource Use Case",
        "abstract": "This study proposes a language-agnostic transformer-based POS tagging framework designed for low-resource languages, using Bangla and Hindi as case studies. With only three lines of framework-specific code, the model was adapted from Bangla to Hindi, demonstrating effective portability with minimal modification. The framework achieves 96.85 percent and 97 percent token-level accuracy across POS categories in Bangla and Hindi while sustaining strong F1 scores despite dataset imbalance and linguistic overlap. A performance discrepancy in a specific POS category underscores ongoing challenges in dataset curation. The strong results stem from the underlying transformer architecture, which can be replaced with limited code adjustments. Its modular and open-source design enables rapid cross-lingual adaptation while reducing model design and tuning overhead, allowing researchers to focus on linguistic preprocessing and dataset refinement, which are essential for advancing NLP in underrepresented languages.",
        "url": "http://arxiv.org/abs/2512.00745v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00745v1",
        "arxiv_id": "2512.00745v1",
        "authors": [
            "Md Abdullah Al Kafi",
            "Sumit Kumar Banshal"
        ],
        "submitted": "2025-11-30 05:48:12",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Probing the \"Psyche'' of Large Reasoning Models: Understanding Through a Human Lens",
        "abstract": "Large reasoning models (LRMs) have garnered significant attention from researchers owing to their exceptional capability in addressing complex tasks. Motivated by the observed human-like behaviors in their reasoning processes, this paper introduces a comprehensive taxonomy to characterize atomic reasoning steps and probe the ``psyche'' of LRM intelligence. Specifically, it comprises five groups and seventeen categories derived from human mental processes, thereby grounding the understanding of LRMs in an interdisciplinary perspective. The taxonomy is then applied for an in-depth understanding of current LRMs, resulting in a distinct labeled dataset that comprises 277,534 atomic reasoning steps. Using this resource, we analyze contemporary LRMs and distill several actionable takeaways for improving training and post-training of reasoning models. Notably, our analysis reveals that prevailing post-answer ``double-checks'' (self-monitoring evaluations) are largely superficial and rarely yield substantive revisions. Thus, incentivizing comprehensive multi-step reflection, rather than simple self-monitoring, may offer a more effective path forward. To complement the taxonomy, an automatic annotation framework, named CAPO, is proposed to leverage large language models (LLMs) for generating the taxonomy-based annotations. Experimental results demonstrate that CAPO achieves higher consistency with human experts compared to baselines, facilitating a scalable and comprehensive analysis of LRMs from a human cognitive perspective. Together, the taxonomy, CAPO, and the derived insights provide a principled, scalable path toward understanding and advancing LRM reasoning.",
        "url": "http://arxiv.org/abs/2512.00729v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00729v1",
        "arxiv_id": "2512.00729v1",
        "authors": [
            "Yuxiang Chen",
            "Zuohan Wu",
            "Ziwei Wang",
            "Xiangning Yu",
            "Xujia Li",
            "Linyi Yang",
            "Mengyue Yang",
            "Jun Wang",
            "Lei Chen"
        ],
        "submitted": "2025-11-30 04:49:44",
        "source": "arxiv",
        "comment": "13 pages"
    },
    {
        "title": "Upcycled and Merged MoE Reward Model for Mitigating Reward Hacking",
        "abstract": "Reward models play a critical role in Reinforcement Learning from Human Feedback (RLHF) by assessing the consistency between generated outputs and human preferences. However, conventional reward models are prone to reward hacking or over-optimization, where the policy exploits shortcut patterns to obtain high reward scores that do not reflect true human preference. Although Mixture-of-Experts (MoE)-based reward models can enhance discriminative capability, they typically introduce substantial computational overhead. To address these challenges, we propose an upcycle and merge MoE reward modeling approach. We first upcycle a dense reward model into a MoE architecture, where a shared expert captures general knowledge, while normal experts specialize in instruction-specific patterns. We then apply routing-weight normalization and merge experts back into a dense model through a learnable weight-averaging mechanism, preserving performance gains while significantly reducing inference cost. Experimental results demonstrate that our method effectively mitigates reward hacking across various model scales. Our work highlights the potential of upcycle and merge MoE structures for improving both robustness and efficiency of RLHF reward models.",
        "url": "http://arxiv.org/abs/2512.00724v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00724v1",
        "arxiv_id": "2512.00724v1",
        "authors": [
            "Lingling Fu"
        ],
        "submitted": "2025-11-30 04:36:37",
        "source": "arxiv",
        "comment": "9 pages,5 figures"
    },
    {
        "title": "Cross-Domain Federated Semantic Communication with Global Representation Alignment and Domain-Aware Aggregation",
        "abstract": "Semantic communication can significantly improve bandwidth utilization in wireless systems by exploiting the meaning behind raw data. However, the advancements achieved through semantic communication are closely dependent on the development of deep learning (DL) models for joint source-channel coding (JSCC) encoder/decoder techniques, which require a large amount of data for training. To address this data-intensive nature of DL models, federated learning (FL) has been proposed to train a model in a distributed manner, where the server broadcasts the DL model to clients in the network for training with their local data. However, the conventional FL approaches suffer from catastrophic degradation when client data are from different domains. In contrast, in this paper, a novel FL framework is proposed to address this domain shift by constructing the global representation, which aligns with the local features of the clients to preserve the semantics of different data domains. In addition, the dominance problem of client domains with a large number of samples is identified and, then, addressed with a domain-aware aggregation approach. This work is the first to consider the domain shift in training the semantic communication system for the image reconstruction task. Finally, simulation results demonstrate that the proposed approach outperforms the model-contrastive FL (MOON) framework by 0.5 for PSNR values under three domains at an SNR of 1 dB, and this gap continues to widen as the channel quality improves.",
        "url": "http://arxiv.org/abs/2512.00711v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00711v1",
        "arxiv_id": "2512.00711v1",
        "authors": [
            "Loc X. Nguyen",
            "Ji Su Yoon",
            "Huy Q. Le",
            "Yu Qiao",
            "Avi Deb Raha",
            "Eui-Nam Huh",
            "Walid Saad",
            "Dusit Niyato",
            "Zhu Han",
            "Choong Seon Hong"
        ],
        "submitted": "2025-11-30 03:19:59",
        "source": "arxiv",
        "comment": "13 pages, 7 figures, 6 tables"
    },
    {
        "title": "ProEx: A Unified Framework Leveraging Large Language Model with Profile Extrapolation for Recommendation",
        "abstract": "The powerful text understanding and generation capabilities of large language models (LLMs) have brought new vitality to general recommendation with implicit feedback. One possible strategy involves generating a unique user (or item) profile from historical interaction data, which is then mapped to a semantic representation in the language space. However, a single-instance profile may be insufficient to comprehensively capture the complex intentions behind a user's interacted items. Moreover, due to the inherent instability of LLMs, a biased or misinterpreted profile could even undermine the original recommendation performance. Consequently, an intuitive solution is to generate multiple profiles for each user (or item), each reflecting a distinct aspect of their characteristics. In light of this, we propose a unified recommendation framework with multi-faceted profile extrapolation (ProEx) in this paper. By leveraging chain-of-thought reasoning, we construct multiple distinct profiles for each user and item. These new profiles are subsequently mapped into semantic vectors, extrapolating from the position of the original profile to explore a broader region of the language space. Subsequently, we introduce the concept of environments, where each environment represents a possible linear combination of all profiles. The differences across environments are minimized to reveal the inherent invariance of user preferences. We apply ProEx to three discriminative methods and three generative methods, and conduct extensive experiments on three datasets. The experimental results demonstrate that ProEx significantly enhances the performance of these base recommendation models.",
        "url": "http://arxiv.org/abs/2512.00679v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00679v1",
        "arxiv_id": "2512.00679v1",
        "authors": [
            "Yi Zhang",
            "Yiwen Zhang",
            "Yu Wang",
            "Tong Chen",
            "Hongzhi Yin"
        ],
        "submitted": "2025-11-30 00:24:24",
        "source": "arxiv",
        "comment": "Accepted by KDD 2026 (First Cycle)"
    },
    {
        "title": "A Comparison of Human and ChatGPT Classification Performance on Complex Social Media Data",
        "abstract": "Generative artificial intelligence tools, like ChatGPT, are an increasingly utilized resource among computational social scientists. Nevertheless, there remains space for improved understanding of the performance of ChatGPT in complex tasks such as classifying and annotating datasets containing nuanced language. Method. In this paper, we measure the performance of GPT-4 on one such task and compare results to human annotators. We investigate ChatGPT versions 3.5, 4, and 4o to examine performance given rapid changes in technological advancement of large language models. We craft four prompt styles as input and evaluate precision, recall, and F1 scores. Both quantitative and qualitative evaluations of results demonstrate that while including label definitions in prompts may help performance, overall GPT-4 has difficulty classifying nuanced language. Qualitative analysis reveals four specific findings. Our results suggest the use of ChatGPT in classification tasks involving nuanced language should be conducted with prudence.",
        "url": "http://arxiv.org/abs/2512.00673v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00673v1",
        "arxiv_id": "2512.00673v1",
        "authors": [
            "Breanna E. Green",
            "Ashley L. Shea",
            "Pengfei Zhao",
            "Drew B. Margolin"
        ],
        "submitted": "2025-11-29 23:59:58",
        "source": "arxiv",
        "comment": "About 15 pages, draft version of accepted conference full paper. Published paper to follow"
    },
    {
        "title": "Graphing the Truth: Structured Visualizations for Automated Hallucination Detection in LLMs",
        "abstract": "Large Language Models have rapidly advanced in their ability to interpret and generate natural language. In enterprise settings, they are frequently augmented with closed-source domain knowledge to deliver more contextually informed responses. However, operational constraints such as limited context windows and inconsistencies between pre-training data and supplied knowledge often lead to hallucinations, some of which appear highly credible and escape routine human review. Current mitigation strategies either depend on costly, large-scale gold-standard Q\\&A curation or rely on secondary model verification, neither of which offers deterministic assurance. This paper introduces a framework that organizes proprietary knowledge and model-generated content into interactive visual knowledge graphs. The objective is to provide end users with a clear, intuitive view of potential hallucination zones by linking model assertions to underlying sources of truth and indicating confidence levels. Through this visual interface, users can diagnose inconsistencies, identify weak reasoning chains, and supply corrective feedback. The resulting human-in-the-loop workflow creates a structured feedback loop that can enhance model reliability and continuously improve response quality.",
        "url": "http://arxiv.org/abs/2512.00663v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00663v1",
        "arxiv_id": "2512.00663v1",
        "authors": [
            "Tanmay Agrawal"
        ],
        "submitted": "2025-11-29 23:09:15",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Sycophancy Claims about Language Models: The Missing Human-in-the-Loop",
        "abstract": "Sycophantic response patterns in Large Language Models (LLMs) have been increasingly claimed in the literature. We review methodological challenges in measuring LLM sycophancy and identify five core operationalizations. Despite sycophancy being inherently human-centric, current research does not evaluate human perception. Our analysis highlights the difficulties in distinguishing sycophantic responses from related concepts in AI alignment and offers actionable recommendations for future research.",
        "url": "http://arxiv.org/abs/2512.00656v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00656v1",
        "arxiv_id": "2512.00656v1",
        "authors": [
            "Jan Batzner",
            "Volker Stocker",
            "Stefan Schmid",
            "Gjergji Kasneci"
        ],
        "submitted": "2025-11-29 22:40:53",
        "source": "arxiv",
        "comment": "NeurIPS 2025 Workshop on LLM Evaluation and ICLR 2025 Workshop on Bi-Directional Human-AI Alignment"
    },
    {
        "title": "Melody or Machine: Detecting Synthetic Music with Dual-Stream Contrastive Learning",
        "abstract": "The rapid evolution of end-to-end AI music generation poses an escalating threat to artistic authenticity and copyright, demanding detection methods that can keep pace. While foundational, existing models like SpecTTTra falter when faced with the diverse and rapidly advancing ecosystem of new generators, exhibiting significant performance drops on out-of-distribution (OOD) content. This generalization failure highlights a critical gap: the need for more challenging benchmarks and more robust detection architectures. To address this, we first introduce Melody or Machine (MoM), a new large-scale benchmark of over 130,000 songs (6,665 hours). MoM is the most diverse dataset to date, built with a mix of open and closed-source models and a curated OOD test set designed specifically to foster the development of truly generalizable detectors. Alongside this benchmark, we introduce CLAM, a novel dual-stream detection architecture. We hypothesize that subtle, machine-induced inconsistencies between vocal and instrumental elements, often imperceptible in a mixed signal, offer a powerful tell-tale sign of synthesis. CLAM is designed to test this hypothesis by employing two distinct pre-trained audio encoders (MERT and Wave2Vec2) to create parallel representations of the audio. These representations are fused by a learnable cross-aggregation module that models their inter-dependencies. The model is trained with a dual-loss objective: a standard binary cross-entropy loss for classification, complemented by a contrastive triplet loss which trains the model to distinguish between coherent and artificially mismatched stream pairings, enhancing its sensitivity to synthetic artifacts without presuming a simple feature alignment. CLAM establishes a new state-of-the-art in synthetic music forensics. It achieves an F1 score of 0.925 on our challenging MoM benchmark.",
        "url": "http://arxiv.org/abs/2512.00621v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00621v1",
        "arxiv_id": "2512.00621v1",
        "authors": [
            "Arnesh Batra",
            "Dev Sharma",
            "Krish Thukral",
            "Ruhani Bhatia",
            "Naman Batra",
            "Aditya Gautam"
        ],
        "submitted": "2025-11-29 20:25:20",
        "source": "arxiv",
        "comment": "Accepted at Transactions on Machine Learning Research (TMLR)"
    },
    {
        "title": "ART: Adaptive Response Tuning Framework -- A Multi-Agent Tournament-Based Approach to LLM Response Optimization",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation. However, single-model responses often exhibit inconsistencies, hallucinations, and varying quality across different query domains. This paper presents ART (Adaptive Response Tuning), a novel framework that employs tournament-style ELO ranking and multi-agent reasoning to systematically optimize LLM outputs. By enabling multiple LLM agents to compete, critique, and collaborate through structured tournament workflows, ART produces consensus responses that outperform individual model outputs. Our framework introduces configurable tournament parameters, dynamic agent selection, and multiple consensus fusion strategies. Experimental evaluations demonstrate significant improvements in response accuracy, coherence, and reliability compared to baseline single-model approaches. The ART framework provides a scalable, production-ready solution for applications requiring high-quality, vetted LLM responses, achieving an 8.4% improvement in overall quality metrics and R22 values exceeding 0.96 in ELO rating convergence.",
        "url": "http://arxiv.org/abs/2512.00617v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00617v1",
        "arxiv_id": "2512.00617v1",
        "authors": [
            "Omer Jauhar Khan"
        ],
        "submitted": "2025-11-29 20:16:11",
        "source": "arxiv",
        "comment": "8 pages, 5 figures, 5 tables. Conference-style paper"
    },
    {
        "title": "Prism: A Minimal Compositional Metalanguage for Specifying Agent Behavior",
        "abstract": "Prism is a small, compositional metalanguage for specifying the behaviour of tool-using software agents. Rather than introducing ad hoc control constructs, Prism is built around a fixed core context, Core1, which provides a minimal background grammar of categories numbers, strings, user prompts, tools together with abstract combinators for booleans, predicates, pairs, and lists. Agent policies are written as ordinary expressions using a single abstraction operator so that conditionals appear as selections between alternatives instead of imperative if-else blocks. Domains extend the core by defining their own context-mini-grammars that introduce new categories, predicates, and external tools while reusing the same compositional machinery. We illustrate this with worked examples from thermostat control, home security, e-commerce recommendation, and medical monitoring, showing how natural language decision rules can be mapped to inspectable, executable policies. From a linguistic perspective, Prism enforces a clear separation between a reusable grammar-like core and domain specific lexicons and treats tools as bridges between internal policy representations and the external world. From an engineering perspective, it offers a compact interface language for agent control, making the space of possible actions explicit and amenable to analysis, verification, and safety constraints.",
        "url": "http://arxiv.org/abs/2512.00611v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00611v1",
        "arxiv_id": "2512.00611v1",
        "authors": [
            "Franck Binard",
            "Vanja Kljajevic"
        ],
        "submitted": "2025-11-29 19:52:21",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "DLRREC: Denoising Latent Representations via Multi-Modal Knowledge Fusion in Deep Recommender Systems",
        "abstract": "Modern recommender systems struggle to effectively utilize the rich, yet high-dimensional and noisy, multi-modal features generated by Large Language Models (LLMs). Treating these features as static inputs decouples them from the core recommendation task. We address this limitation with a novel framework built on a key insight: deeply fusing multi-modal and collaborative knowledge for representation denoising. Our unified architecture introduces two primary technical innovations. First, we integrate dimensionality reduction directly into the recommendation model, enabling end-to-end co-training that makes the reduction process aware of the final ranking objective. Second, we introduce a contrastive learning objective that explicitly incorporates the collaborative filtering signal into the latent space. This synergistic process refines raw LLM embeddings, filtering noise while amplifying task-relevant signals. Extensive experiments confirm our method's superior discriminative power, proving that this integrated fusion and denoising strategy is critical for achieving state-of-the-art performance. Our work provides a foundational paradigm for effectively harnessing LLMs in recommender systems.",
        "url": "http://arxiv.org/abs/2512.00596v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00596v1",
        "arxiv_id": "2512.00596v1",
        "authors": [
            "Jiahao Tian",
            "Zhenkai Wang"
        ],
        "submitted": "2025-11-29 18:57:42",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Wikontic: Constructing Wikidata-Aligned, Ontology-Aware Knowledge Graphs with Large Language Models",
        "abstract": "Knowledge graphs (KGs) provide structured, verifiable grounding for large language models (LLMs), but current LLM-based systems commonly use KGs as auxiliary structures for text retrieval, leaving their intrinsic quality underexplored. In this work, we propose Wikontic, a multi-stage pipeline that constructs KGs from open-domain text by extracting candidate triplets with qualifiers, enforcing Wikidata-based type and relation constraints, and normalizing entities to reduce duplication. The resulting KGs are compact, ontology-consistent, and well-connected; on MuSiQue, the correct answer entity appears in 96% of generated triplets. On HotpotQA, our triplets-only setup achieves 76.0 F1, and on MuSiQue 59.8 F1, matching or surpassing several retrieval-augmented generation baselines that still require textual context. In addition, Wikontic attains state-of-the-art information-retention performance on the MINE-1 benchmark (86%), outperforming prior KG construction methods. Wikontic is also efficient at build time: KG construction uses less than 1,000 output tokens, about 3$\\times$ fewer than AriGraph and $<$1/20 of GraphRAG. The proposed pipeline enhances the quality of the generated KG and offers a scalable solution for leveraging structured knowledge in LLMs.",
        "url": "http://arxiv.org/abs/2512.00590v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00590v1",
        "arxiv_id": "2512.00590v1",
        "authors": [
            "Alla Chepurova",
            "Aydar Bulatov",
            "Yuri Kuratov",
            "Mikhail Burtsev"
        ],
        "submitted": "2025-11-29 18:44:25",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Statistical NLP for Optimization of Clinical Trial Success Prediction in Pharmaceutical R&D",
        "abstract": "This work presents the development and evaluation of an NLP-enabled probabilistic classifier designed to estimate the probability of technical and regulatory success (pTRS) for clinical trials in the field of neuroscience. While pharmaceutical R&D is plagued by high attrition rates and enormous costs, particularly within neuroscience, where success rates are below 10%, timely identification of promising programs can streamline resource allocation and reduce financial risk. Leveraging data from the ClinicalTrials.gov database and success labels from the recently developed Clinical Trial Outcome dataset, the classifier extracts text-based clinical trial features using statistical NLP techniques. These features were integrated into several non-LLM frameworks (logistic regression, gradient boosting, and random forest) to generate calibrated probability scores. Model performance was assessed on a retrospective dataset of 101,145 completed clinical trials spanning 1976-2024, achieving an overall ROC-AUC of 0.64. An LLM-based predictive model was then built using BioBERT, a domain-specific language representation encoder. The BioBERT-based model achieved an overall ROC-AUC of 0.74 and a Brier Score of 0.185, indicating its predictions had, on average, 40% less squared error than would be observed using industry benchmarks. The BioBERT-based model also made trial outcome predictions that were superior to benchmark values 70% of the time overall. By integrating NLP-driven insights into drug development decision-making, this work aims to enhance strategic planning and optimize investment allocation in neuroscience programs.",
        "url": "http://arxiv.org/abs/2512.00586v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00586v1",
        "arxiv_id": "2512.00586v1",
        "authors": [
            "Michael R. Doane"
        ],
        "submitted": "2025-11-29 18:40:42",
        "source": "arxiv",
        "comment": "Doctor of Engineering Praxis Dissertation, The George Washington University. 122 pages. Present affiliation: Iambic Therapeutics"
    },
    {
        "title": "Slovak Conceptual Dictionary",
        "abstract": "When solving tasks in the field of natural language processing, we sometimes need dictionary tools, such as lexicons, word form dictionaries or knowledge bases. However, the availability of dictionary data is insufficient in many languages, especially in the case of low resourced languages. In this article, we introduce a new conceptual dictionary for the Slovak language as the first linguistic tool of this kind. Since Slovak language is a language with limited linguistic resources and there are currently not available any machine-readable linguistic data sources with a sufficiently large volume of data, many tasks which require automated processing of Slovak text achieve weaker results compared to other languages and are almost impossible to solve.",
        "url": "http://arxiv.org/abs/2512.00579v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00579v1",
        "arxiv_id": "2512.00579v1",
        "authors": [
            "Miroslav BlÅ¡tÃ¡k"
        ],
        "submitted": "2025-11-29 18:15:28",
        "source": "arxiv",
        "comment": "7 pages, 2 figures"
    },
    {
        "title": "Bias Testing and Mitigation in Black Box LLMs using Metamorphic Relations",
        "abstract": "The widespread deployment of Large Language Models (LLMs) has intensified concerns about subtle social biases embedded in their outputs. Existing guardrails often fail when faced with indirect or contextually complex bias-inducing prompts. To address these limitations, we propose a unified framework for both systematic bias evaluation and targeted mitigation. Our approach introduces six novel Metamorphic Relations (MRs) that, based on metamorphic testing principles, transform direct bias-inducing inputs into semantically equivalent yet adversarially challenging variants. These transformations enable an automated method for exposing hidden model biases: when an LLM responds inconsistently or unfairly across MR-generated variants, the underlying bias becomes detectable. We further show that the same MRs can be used to generate diverse bias-inducing samples for fine-tuning, directly linking the testing process to mitigation. Using six state-of-the-art LLMs - spanning open-source and proprietary models - and a representative subset of 385 questions from the 8,978-item BiasAsker benchmark covering seven protected groups, our MRs reveal up to 14% more hidden biases compared to existing tools. Moreover, fine-tuning with both original and MR-mutated samples significantly enhances bias resiliency, increasing safe response rates from 54.7% to over 88.9% across models. These results highlight metamorphic relations as a practical mechanism for improving fairness in conversational AI.",
        "url": "http://arxiv.org/abs/2512.00556v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00556v1",
        "arxiv_id": "2512.00556v1",
        "authors": [
            "Sina Salimian",
            "Gias Uddin",
            "Sumon Biswas",
            "Henry Leung"
        ],
        "submitted": "2025-11-29 16:56:38",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Catch Me If You Can: How Smaller Reasoning Models Pretend to Reason with Mathematical Fidelity",
        "abstract": "Current evaluation of mathematical reasoning in language models relies primarily on answer accuracy, potentially masking fundamental failures in logical computation. We introduce a diagnostic framework that distinguishes genuine mathematical reasoning from superficial pattern matching through four complementary axes: forward-backward consistency, transitivity coverage, counterfactual sensitivity, and perturbation robustness. Through a case study applying this framework to Qwen3-0.6B on the MenatQA dataset, we reveal a striking disconnect between surface performance and reasoning fidelity. While the model achieves reasonable answer accuracy (70%+), it demonstrates poor backward consistency (15%), limited transitivity coverage (32.2%), and brittle sensitivity to perturbations. Our diagnostics expose reasoning failures invisible to traditional accuracy metrics, suggesting that this small model relies heavily on pattern matching rather than genuine logical computation. While our empirical findings are based on a single 600M-parameter model, the diagnostic framework itself is model-agnostic and generalizable. We release our evaluation protocols to enable the research community to assess reasoning fidelity across different model scales and architectures, moving beyond surface-level accuracy toward verifiable mathematical reasoning.",
        "url": "http://arxiv.org/abs/2512.00552v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00552v1",
        "arxiv_id": "2512.00552v1",
        "authors": [
            "Subramanyam Sahoo",
            "Vinija Jain",
            "Saanidhya Vats",
            "Siddharth Mohapatra",
            "Rui Min",
            "Aman Chadha",
            "Divya Chaudhary"
        ],
        "submitted": "2025-11-29 16:47:01",
        "source": "arxiv",
        "comment": "8 pages, 5 figures. A preprint. Initial Work"
    },
    {
        "title": "Rep3Net: An Approach Exploiting Multimodal Representation for Molecular Bioactivity Prediction",
        "abstract": "In early stage drug discovery, bioactivity prediction of molecules against target proteins plays a crucial role. Trdaitional QSAR models that utilizes molecular descriptor based data often struggles to predict bioactivity of molecules effectively due to its limitation in capturing structural and contextual information embedded within each compound. To address this challenge, we propose Rep3Net, a unified deep learning architecture that not only incorporates descriptor data but also includes spatial and relational information through graph-based represenation of compounds and contextual information through ChemBERTa generated embeddings from SMILES strings. Our model employing multimodal concatenated features produce reliable bioactivity prediction on Poly [ADP-ribose] polymerase 1 (PARP-1) dataset. PARP-1 is a crucial agent in DNA damage repair and has become a significant theraputic target in malignancies that depend on it for survival and growth. A comprehensive analysis and comparison with conventional standalone models including GCN, GAT, XGBoost, etc. demonstrates that our architecture achieves the highest predictive performance. In computational screening of compounds in drug discovery, our architecture provides a scalable framework for bioactivity prediction.",
        "url": "http://arxiv.org/abs/2512.00521v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00521v1",
        "arxiv_id": "2512.00521v1",
        "authors": [
            "Sabrina Islam",
            "Md. Atiqur Rahman",
            "Md. Bakhtiar Hasan",
            "Md. Hasanul Kabir"
        ],
        "submitted": "2025-11-29 15:39:48",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Developing a Comprehensive Framework for Sentiment Analysis in Turkish",
        "abstract": "In this thesis, we developed a comprehensive framework for sentiment analysis that takes its many aspects into account mainly for Turkish. We have also proposed several approaches specific to sentiment analysis in English only. We have accordingly made five major and three minor contributions. We generated a novel and effective feature set by combining unsupervised, semi-supervised, and supervised metrics. We then fed them as input into classical machine learning methods, and outperformed neural network models for datasets of different genres in both Turkish and English. We created a polarity lexicon with a semi-supervised domain-specific method, which has been the first approach applied for corpora in Turkish. We performed a fine morphological analysis for the sentiment classification task in Turkish by determining the polarities of morphemes. This can be adapted to other morphologically-rich or agglutinative languages as well. We have built a novel neural network architecture, which combines recurrent and recursive neural network models for English. We built novel word embeddings that exploit sentiment, syntactic, semantic, and lexical characteristics for both Turkish and English. We also redefined context windows as subclauses in modelling word representations in English. This can also be applied to other linguistic fields and natural language processing tasks. We have achieved state-of-the-art and significant results for all these original approaches. Our minor contributions include methods related to aspect-based sentiment in Turkish, parameter redefinition in the semi-supervised approach, and aspect term extraction techniques for English. This thesis can be considered the most detailed and comprehensive study made on sentiment analysis in Turkish as of July, 2020. Our work has also contributed to the opinion classification problem in English.",
        "url": "http://arxiv.org/abs/2512.00515v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00515v1",
        "arxiv_id": "2512.00515v1",
        "authors": [
            "Cem Rifki Aydin"
        ],
        "submitted": "2025-11-29 15:14:57",
        "source": "arxiv",
        "comment": "Ph.D. Thesis, Bogazici University, 2020"
    },
    {
        "title": "G-KV: Decoding-Time KV Cache Eviction with Global Attention",
        "abstract": "Recent reasoning large language models (LLMs) excel in complex tasks but encounter significant computational and memory challenges due to long sequence lengths. KV cache compression has emerged as an effective approach to greatly enhance the efficiency of reasoning. However, existing methods often focus on prompt compression or token eviction with local attention score, overlooking the long-term importance of tokens. We propose G-KV, a KV cache eviction method that employs a global scoring mechanism, combining local and historical attention scores to more accurately assess token importance. Additionally, we introduce post-training techniques, including reinforcement learning and distillation, to optimize models for compressed KV cache settings. The code of this paper is available on: https://github.com/microsoft/G-KV.",
        "url": "http://arxiv.org/abs/2512.00504v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00504v1",
        "arxiv_id": "2512.00504v1",
        "authors": [
            "Mengqi Liao",
            "Lu Wang",
            "Chaoyun Zhang",
            "Zekai Shen",
            "Xiaowei Mao",
            "Si Qin",
            "Qingwei Lin",
            "Saravan Rajmohan",
            "Dongmei Zhang",
            "Huaiyu Wan"
        ],
        "submitted": "2025-11-29 14:21:33",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "CACARA: Cross-Modal Alignment Leveraging a Text-Centric Approach for Cost-Effective Multimodal and Multilingual Learning",
        "abstract": "As deep learning models evolve, new applications and challenges are rapidly emerging. Tasks that once relied on a single modality, such as text, images, or audio, are now enriched by seamless interactions between multimodal data. These connections bridge information gaps: an image can visually materialize a text, while audio can add context to an image. Researchers have developed numerous multimodal models, but most rely on resource-intensive training across multiple modalities. Similarly, extending these models to new languages often follows the same resource-heavy training strategy. In this work, we propose a multimodal and multilingual architecture, CACARA, trained through emergent alignment learning, enabling the seamless integration of new modalities into an existing bimodal/multimodal model without requiring full retraining. This work breaks new ground by demonstrating that this emergent alignment paradigm can unlock multilingual capabilities from monolingual training. By fine-tuning the newly incorporated modality only on data aligned with the English language, our model develops support for over 100 languages without explicit multilingual pretraining or tuning of the text encoder. Such emergent multimodal and multilingual properties are gained efficiently, preserving previously learned knowledge at a training cost comparable to that of a monolingual model. Our strategy achieves up to a 14.24 percentage points improvement in R@1 audio-to-text retrieval, outperforming state-of-the-art multimodal models -- all without the heavy computational cost of retraining across every modality and language.",
        "url": "http://arxiv.org/abs/2512.00496v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00496v1",
        "arxiv_id": "2512.00496v1",
        "authors": [
            "Diego A. B. Moreira",
            "Alef I. Ferreira",
            "Jhessica Silva",
            "Gabriel O. dos Santos",
            "Gustavo Bonil",
            "JoÃ£o Gondim",
            "Marina dos Santos",
            "Helena Maia",
            "Simone Hashiguti",
            "NÃ¡dia da Silva",
            "Carolina Scarton",
            "Helio Pedrini",
            "Sandra Avila"
        ],
        "submitted": "2025-11-29 14:04:27",
        "source": "arxiv",
        "comment": "25 pages, 12 tables, 5 figures"
    },
    {
        "title": "SCALE: Selective Resource Allocation for Overcoming Performance Bottlenecks in Mathematical Test-time Scaling",
        "abstract": "Test-time compute scaling has emerged as a powerful paradigm for enhancing mathematical reasoning in large language models (LLMs) by allocating additional computational resources during inference. However, current methods employ uniform resource distribution across all reasoning sub-problems, creating fundamental bottlenecks where challenging sub-problems receive insufficient attention while routine operations consume disproportionate resources. This uniform allocation creates performance bottlenecks where additional computational resources yield diminishing returns. Inspired by dual-process theory, we propose \\textbf{SCALE} (Selective Resource Allocation), a framework that selectively allocates computational resources based on sub-problem difficulty. SCALE operates through four stages: (1) problem decomposition into sequential reasoning sub-problems, (2) difficulty assessment of each sub-problem to distinguish between routine operations and computationally challenging sub-problems, (3) selective processing mode assignment between System 1 for simple sub-problems and System 2 for complex ones, and (4) sequential execution with context propagation. By concentrating resources on challenging sub-problems while processing routine operations efficiently, SCALE achieves substantial performance improvements with superior resource utilization. Extensive experiments demonstrate that SCALE significantly outperforms uniform scaling baselines, achieving accuracy improvements of up to 13.75 percentage points (57.50% to 71.25% on AIME25) while reducing computational costs by 33%-53%, representing a major advance in test-time scaling that addresses fundamental limitations of current approaches.",
        "url": "http://arxiv.org/abs/2512.00466v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00466v1",
        "arxiv_id": "2512.00466v1",
        "authors": [
            "Yang Xiao",
            "Chunpu Xu",
            "Ruifeng Yuan",
            "Jiashuo Wang",
            "Wenjie Li",
            "Pengfei Liu"
        ],
        "submitted": "2025-11-29 12:38:07",
        "source": "arxiv",
        "comment": "accepted by AAAI 2026"
    },
    {
        "title": "Whose Personae? Synthetic Persona Experiments in LLM Research and Pathways to Transparency",
        "abstract": "Synthetic personae experiments have become a prominent method in Large Language Model alignment research, yet the representativeness and ecological validity of these personae vary considerably between studies. Through a review of 63 peer-reviewed studies published between 2023 and 2025 in leading NLP and AI venues, we reveal a critical gap: task and population of interest are often underspecified in persona-based experiments, despite personalization being fundamentally dependent on these criteria. Our analysis shows substantial differences in user representation, with most studies focusing on limited sociodemographic attributes and only 35% discussing the representativeness of their LLM personae. Based on our findings, we introduce a persona transparency checklist that emphasizes representative sampling, explicit grounding in empirical data, and enhanced ecological validity. Our work provides both a comprehensive assessment of current practices and practical guidelines to improve the rigor and ecological validity of persona-based evaluations in language model alignment research.",
        "url": "http://arxiv.org/abs/2512.00461v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00461v1",
        "arxiv_id": "2512.00461v1",
        "authors": [
            "Jan Batzner",
            "Volker Stocker",
            "Bingjun Tang",
            "Anusha Natarajan",
            "Qinhao Chen",
            "Stefan Schmid",
            "Gjergji Kasneci"
        ],
        "submitted": "2025-11-29 12:27:34",
        "source": "arxiv",
        "comment": "Published at AAAI/ACM AIES 2025. Presented at NeurIPS 2025 Workshop Evaluating the Evolving LLM Lifecycle: Benchmarks, Emergent Abilities, and Scaling"
    },
    {
        "title": "PEOAT: Personalization-Guided Evolutionary Question Assembly for One-Shot Adaptive Testing",
        "abstract": "With the rapid advancement of intelligent education, Computerized Adaptive Testing (CAT) has attracted increasing attention by integrating educational psychology with deep learning technologies. Unlike traditional paper-and-pencil testing, CAT aims to efficiently and accurately assess examinee abilities by adaptively selecting the most suitable items during the assessment process. However, its real-time and sequential nature presents limitations in practical scenarios, particularly in large-scale assessments where interaction costs are high, or in sensitive domains such as psychological evaluations where minimizing noise and interference is essential. These challenges constrain the applicability of conventional CAT methods in time-sensitive or resourceconstrained environments. To this end, we first introduce a novel task called one-shot adaptive testing (OAT), which aims to select a fixed set of optimal items for each test-taker in a one-time selection. Meanwhile, we propose PEOAT, a Personalization-guided Evolutionary question assembly framework for One-shot Adaptive Testing from the perspective of combinatorial optimization. Specifically, we began by designing a personalization-aware initialization strategy that integrates differences between examinee ability and exercise difficulty, using multi-strategy sampling to construct a diverse and informative initial population. Building on this, we proposed a cognitive-enhanced evolutionary framework incorporating schema-preserving crossover and cognitively guided mutation to enable efficient exploration through informative signals. To maintain diversity without compromising fitness, we further introduced a diversity-aware environmental selection mechanism. The effectiveness of PEOAT is validated through extensive experiments on two datasets, complemented by case studies that uncovered valuable insights.",
        "url": "http://arxiv.org/abs/2512.00439v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00439v1",
        "arxiv_id": "2512.00439v1",
        "authors": [
            "Xiaoshan Yu",
            "Ziwei Huang",
            "Shangshang Yang",
            "Ziwen Wang",
            "Haiping Ma",
            "Xingyi Zhang"
        ],
        "submitted": "2025-11-29 10:38:25",
        "source": "arxiv",
        "comment": "AAAI-2026, 9 pages"
    },
    {
        "title": "CryptoBench: A Dynamic Benchmark for Expert-Level Evaluation of LLM Agents in Cryptocurrency",
        "abstract": "This paper introduces CryptoBench, the first expert-curated, dynamic benchmark designed to rigorously evaluate the real-world capabilities of Large Language Model (LLM) agents in the uniquely demanding and fast-paced cryptocurrency domain. Unlike general-purpose agent benchmarks for search and prediction, professional crypto analysis presents specific challenges: \\emph{extreme time-sensitivity}, \\emph{a highly adversarial information environment}, and the critical need to synthesize data from \\emph{diverse, specialized sources}, such as on-chain intelligence platforms and real-time Decentralized Finance (DeFi) dashboards. CryptoBench thus serves as a much more challenging and valuable scenario for LLM agent assessment. To address these challenges, we constructed a live, dynamic benchmark featuring 50 questions per month, expertly designed by crypto-native professionals to mirror actual analyst workflows. These tasks are rigorously categorized within a four-quadrant system: Simple Retrieval, Complex Retrieval, Simple Prediction, and Complex Prediction. This granular categorization enables a precise assessment of an LLM agent's foundational data-gathering capabilities alongside its advanced analytical and forecasting skills.\n  Our evaluation of ten LLMs, both directly and within an agentic framework, reveals a performance hierarchy and uncovers a failure mode. We observe a \\textit{retrieval-prediction imbalance}, where many leading models, despite being proficient at data retrieval, demonstrate a pronounced weakness in tasks requiring predictive analysis. This highlights a problematic tendency for agents to appear factually grounded while lacking the deeper analytical capabilities to synthesize information.",
        "url": "http://arxiv.org/abs/2512.00417v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00417v1",
        "arxiv_id": "2512.00417v1",
        "authors": [
            "Jiacheng Guo",
            "Suozhi Huang",
            "Zixin Yao",
            "Yifan Zhang",
            "Yifu Lu",
            "Jiashuo Liu",
            "Zihao Li",
            "Yanyan Deng",
            "Qixin Xiao",
            "Jia Tian",
            "Kanghong Zhan",
            "Tianyi Li",
            "Xiaochen Liu",
            "Jason Ge",
            "Chaoyang He",
            "Kaixuan Huang",
            "Lin Yang",
            "Wenhao Huang",
            "Mengdi Wang"
        ],
        "submitted": "2025-11-29 09:52:34",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "A Taxonomy of Errors in English as she is spoke: Toward an AI-Based Method of Error Analysis for EFL Writing Instruction",
        "abstract": "This study describes the development of an AI-assisted error analysis system designed to identify, categorize, and correct writing errors in English. Utilizing Large Language Models (LLMs) like Claude 3.5 Sonnet and DeepSeek R1, the system employs a detailed taxonomy grounded in linguistic theories from Corder (1967), Richards (1971), and James (1998). Errors are classified at both word and sentence levels, covering spelling, grammar, and punctuation. Implemented through Python-coded API calls, the system provides granular feedback beyond traditional rubric-based assessments. Initial testing on isolated errors refined the taxonomy, addressing challenges like overlapping categories. Final testing used \"English as she is spoke\" by Jose da Fonseca (1855), a text rich with authentic linguistic errors, to evaluate the system's capacity for handling complex, multi-layered analysis. The AI successfully identified diverse error types but showed limitations in contextual understanding and occasionally generated new error categories when encountering uncoded errors. This research demonstrates AI's potential to transform EFL instruction by automating detailed error analysis and feedback. While promising, further development is needed to improve contextual accuracy and expand the taxonomy to stylistic and discourse-level errors.",
        "url": "http://arxiv.org/abs/2512.00392v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00392v1",
        "arxiv_id": "2512.00392v1",
        "authors": [
            "Damian Heywood",
            "Joseph Andrew Carrier",
            "Kyu-Hong Hwang"
        ],
        "submitted": "2025-11-29 08:45:00",
        "source": "arxiv",
        "comment": "Metadata at \"Replication Data for: A Taxonomy of Errors in English as she is spoke: An AI-Based System for Error Analysis for EFL Writing Instruction\", https://doi.org/10.7910/DVN/N5O7C4, Harvard Dataverse, V1"
    },
    {
        "title": "Mitigating the Threshold Priming Effect in Large Language Model-Based Relevance Judgments via Personality Infusing",
        "abstract": "Recent research has explored LLMs as scalable tools for relevance labeling, but studies indicate they are susceptible to priming effects, where prior relevance judgments influence later ones. Although psychological theories link personality traits to such biases, it is unclear whether simulated personalities in LLMs exhibit similar effects. We investigate how Big Five personality profiles in LLMs influence priming in relevance labeling, using multiple LLMs on TREC 2021 and 2022 Deep Learning Track datasets. Our results show that certain profiles, such as High Openness and Low Neuroticism, consistently reduce priming susceptibility. Additionally, the most effective personality in mitigating priming may vary across models and task types. Based on these findings, we propose personality prompting as a method to mitigate threshold priming, connecting psychological evidence with LLM-based evaluation practices.",
        "url": "http://arxiv.org/abs/2512.00390v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00390v1",
        "arxiv_id": "2512.00390v1",
        "authors": [
            "Nuo Chen",
            "Hanpei Fang",
            "Jiqun Liu",
            "Wilson Wei",
            "Tetsuya Sakai",
            "Xiao-Ming Wu"
        ],
        "submitted": "2025-11-29 08:37:51",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "The Information Theory of Similarity",
        "abstract": "We establish a precise mathematical equivalence between witness-based similarity systems (REWA) and Shannon's information theory. We prove that witness overlap is mutual information, that REWA bit complexity bounds arise from channel capacity limitations, and that ranking-preserving encodings obey rate-distortion constraints. This unification reveals that fifty years of similarity search research -- from Bloom filters to locality-sensitive hashing to neural retrieval -- implicitly developed information theory for relational data. We derive fundamental lower bounds showing that REWA's $O(Î^{-2} \\log N)$ complexity is optimal: no encoding scheme can preserve similarity rankings with fewer bits. The framework establishes that semantic similarity has physical units (bits of mutual information), search is communication (query transmission over a noisy channel), and retrieval systems face fundamental capacity limits analogous to Shannon's channel coding theorem.",
        "url": "http://arxiv.org/abs/2512.00378v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00378v1",
        "arxiv_id": "2512.00378v1",
        "authors": [
            "Nikit Phadke"
        ],
        "submitted": "2025-11-29 08:12:45",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Breaking It Down: Domain-Aware Semantic Segmentation for Retrieval Augmented Generation",
        "abstract": "Document chunking is a crucial component of Retrieval-Augmented Generation (RAG), as it directly affects the retrieval of relevant and precise context. Conventional fixed-length and recursive splitters often produce arbitrary, incoherent segments that fail to preserve semantic structure. Although semantic chunking has gained traction, its influence on generation quality remains underexplored. This paper introduces two efficient semantic chunking methods, Projected Similarity Chunking (PSC) and Metric Fusion Chunking (MFC), trained on PubMed data using three different embedding models. We further present an evaluation framework that measures the effect of chunking on both retrieval and generation by augmenting PubMedQA with full-text PubMed Central articles. Our results show substantial retrieval improvements (24x with PSC) in MRR and higher Hits@k on PubMedQA. We provide a comprehensive analysis, including statistical significance and response-time comparisons with common chunking libraries. Despite being trained on a single domain, PSC and MFC also generalize well, achieving strong out-of-domain generation performance across multiple datasets. Overall, our findings confirm that our semantic chunkers, especially PSC, consistently deliver superior performance.",
        "url": "http://arxiv.org/abs/2512.00367v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00367v1",
        "arxiv_id": "2512.00367v1",
        "authors": [
            "Aparajitha Allamraju",
            "Maitreya Prafulla Chitale",
            "Hiranmai Sri Adibhatla",
            "Rahul Mishra",
            "Manish Shrivastava"
        ],
        "submitted": "2025-11-29 07:30:37",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "CourseTimeQA: A Lecture-Video Benchmark and a Latency-Constrained Cross-Modal Fusion Method for Timestamped QA",
        "abstract": "We study timestamped question answering over educational lecture videos under a single-GPU latency/memory budget. Given a natural-language query, the system retrieves relevant timestamped segments and synthesizes a grounded answer. We present CourseTimeQA (52.3 h, 902 queries across six courses) and a lightweight, latency-constrained cross-modal retriever (CrossFusion-RAG) that combines frozen encoders, a learned 512->768 vision projection, shallow query-agnostic cross-attention over ASR and frames with a temporal-consistency regularizer, and a small cross-attentive reranker. On CourseTimeQA, CrossFusion-RAG improves nDCG@10 by 0.10 and MRR by 0.08 over a strong BLIP-2 retriever while achieving approximately 1.55 s median end-to-end latency on a single A100. Closest comparators (zero-shot CLIP multi-frame pooling; CLIP + cross-encoder reranker + MMR; learned late-fusion gating; text-only hybrid with cross-encoder reranking and its MMR variant; caption-augmented text retrieval; non-learned temporal smoothing) are evaluated under matched hardware and indexing. We report robustness across ASR noise (WER quartiles), diagnostics for temporal localization, and full training/tuning details to support reproducible comparison.",
        "url": "http://arxiv.org/abs/2512.00360v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00360v1",
        "arxiv_id": "2512.00360v1",
        "authors": [
            "Vsevolod Kovalev",
            "Parteek Kumar"
        ],
        "submitted": "2025-11-29 07:06:51",
        "source": "arxiv",
        "comment": "5 figures, 8 tables"
    },
    {
        "title": "IndicParam: Benchmark to evaluate LLMs on low-resource Indic Languages",
        "abstract": "While large language models excel on high-resource multilingual tasks, low- and extremely low-resource Indic languages remain severely under-evaluated. We present IndicParam, a human-curated benchmark of over 13,000 multiple-choice questions covering 11 such languages (Nepali, Gujarati, Marathi, Odia as low-resource; Dogri, Maithili, Rajasthani, Sanskrit, Bodo, Santali, Konkani as extremely low-resource) plus Sanskrit-English code-mixed set. We evaluated 19 LLMs, both proprietary and open-weights, which reveals that even the top-performing GPT-5 reaches only 45.0% average accuracy, followed by DeepSeek-3.2 (43.1) and Claude-4.5 (42.7). We additionally label each question as knowledge-oriented or purely linguistic to discriminate factual recall from grammatical proficiency. Further, we assess the ability of LLMs to handle diverse question formats-such as list-based matching, assertion-reason pairs, and sequence ordering-alongside conventional multiple-choice questions. IndicParam provides insights into limitations of cross-lingual transfer and establishes a challenging benchmark for Indic languages. The dataset is available at https://huggingface.co/datasets/bharatgenai/IndicParam. Scripts to run benchmark are present at https://github.com/ayushbits/IndicParam.",
        "url": "http://arxiv.org/abs/2512.00333v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00333v1",
        "arxiv_id": "2512.00333v1",
        "authors": [
            "Ayush Maheshwari",
            "Kaushal Sharma",
            "Vivek Patel",
            "Aditya Maheshwari"
        ],
        "submitted": "2025-11-29 05:49:50",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Assertion-Conditioned Compliance: A Provenance-Aware Vulnerability in Multi-Turn Tool-Calling Agents",
        "abstract": "Multi-turn tool-calling LLMs (models capable of invoking external APIs or tools across several user turns) have emerged as a key feature in modern AI assistants, enabling extended dialogues from benign tasks to critical business, medical, and financial operations. Yet implementing multi-turn pipelines remains difficult for many safety-critical industries due to ongoing concerns regarding model resilience. While standardized benchmarks such as the Berkeley Function-Calling Leaderboard (BFCL) have underpinned confidence concerning advanced function-calling models (like Salesforce's xLAM V2), there is still a lack of visibility into multi-turn conversation-level robustness, especially given their exposure to real-world systems. In this paper, we introduce Assertion-Conditioned Compliance (A-CC), a novel evaluation paradigm for multi-turn function-calling dialogues. A-CC provides holistic metrics that evaluate a model's behavior when confronted with misleading assertions originating from two distinct vectors: (1) user-sourced assertions (USAs), which measure sycophancy toward plausible but misinformed user beliefs, and (2) function-sourced assertions (FSAs), which measure compliance with plausible but contradictory system policies (e.g., stale hints from unmaintained tools). Our results show that models are highly vulnerable to both USA sycophancy and FSA policy conflicts, confirming A-CC as a critical, latent vulnerability in deployed agents.",
        "url": "http://arxiv.org/abs/2512.00332v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00332v1",
        "arxiv_id": "2512.00332v1",
        "authors": [
            "Daud Waqas",
            "Aaryamaan Golthi",
            "Erika Hayashida",
            "Huanzhi Mao"
        ],
        "submitted": "2025-11-29 05:44:37",
        "source": "arxiv",
        "comment": "15 pages (incl. Appendix), 2 figures, 7 tables"
    },
    {
        "title": "Evidence-Guided Schema Normalization for Temporal Tabular Reasoning",
        "abstract": "Temporal reasoning over evolving semi-structured tables poses a challenge to current QA systems. We propose a SQL-based approach that involves (1) generating a 3NF schema from Wikipedia infoboxes, (2) generating SQL queries, and (3) query execution. Our central finding challenges model scaling assumptions: the quality of schema design has a greater impact on QA precision than model capacity. We establish three evidence-based principles: normalization that preserves context, semantic naming that reduces ambiguity, and consistent temporal anchoring. Our best configuration (Gemini 2.5 Flash schema + Gemini-2.0-Flash queries) achieves 80.39 EM, a 16.8\\% improvement over the baseline (68.89 EM).",
        "url": "http://arxiv.org/abs/2512.00329v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00329v1",
        "arxiv_id": "2512.00329v1",
        "authors": [
            "Ashish Thanga",
            "Vibhu Dixit",
            "Abhilash Shankarampeta",
            "Vivek Gupta"
        ],
        "submitted": "2025-11-29 05:40:08",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Progressive Code Integration for Abstractive Bug Report Summarization",
        "abstract": "Bug reports are often unstructured and verbose, making it challenging for developers to efficiently comprehend software issues. Existing summarization approaches typically rely on surface-level textual cues, resulting in incomplete or redundant summaries, and they frequently ignore associated code snippets, which are essential for accurate defect diagnosis. To address these limitations, we propose a progressive code-integration framework for LLM-based abstractive bug report summarization. Our approach incrementally incorporates long code snippets alongside textual content, overcoming standard LLM context window constraints and producing semantically rich summaries. Evaluated on four benchmark datasets using eight LLMs, our pipeline outperforms extractive baselines by 7.5%-58.2% and achieves performance comparable to state-of-the-art abstractive methods, highlighting the benefits of jointly leveraging textual and code information for enhanced bug comprehension.",
        "url": "http://arxiv.org/abs/2512.00325v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00325v1",
        "arxiv_id": "2512.00325v1",
        "authors": [
            "Shaira Sadia Karim",
            "Abrar Mahmud Rahim",
            "Lamia Alam",
            "Ishmam Tashdeed",
            "Lutfun Nahar Lota",
            "Md. Abu Raihan M. Kamal",
            "Md. Azam Hossain"
        ],
        "submitted": "2025-11-29 05:35:36",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Comparative Analysis of 47 Context-Based Question Answer Models Across 8 Diverse Datasets",
        "abstract": "Context-based question answering (CBQA) models provide more accurate and relevant answers by considering the contextual information. They effectively extract specific information given a context, making them functional in various applications involving user support, information retrieval, and educational platforms. In this manuscript, we benchmarked the performance of 47 CBQA models from Hugging Face on eight different datasets. This study aims to identify the best-performing model across diverse datasets without additional fine-tuning. It is valuable for practical applications where the need to retrain models for specific datasets is minimized, streamlining the implementation of these models in various contexts. The best-performing models were trained on the SQuAD v2 or SQuAD v1 datasets. The best-performing model was ahotrod/electra_large_discriminator_squad2_512, which yielded 43\\% accuracy across all datasets. We observed that the computation time of all models depends on the context length and the model size. The model's performance usually decreases with an increase in the answer length. Moreover, the model's performance depends on the context complexity. We also used the Genetic algorithm to improve the overall accuracy by integrating responses from other models. ahotrod/electra_large_discriminator_squad2_512 generated the best results for bioasq10b-factoid (65.92\\%), biomedical\\_cpgQA (96.45\\%), QuAC (11.13\\%), and Question Answer Dataset (41.6\\%). Bert-large-uncased-whole-word-masking-finetuned-squad achieved an accuracy of 82\\% on the IELTS dataset.",
        "url": "http://arxiv.org/abs/2512.00323v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00323v1",
        "arxiv_id": "2512.00323v1",
        "authors": [
            "Muhammad Muneeb",
            "David B. Ascher",
            "Ahsan Baidar Bakht"
        ],
        "submitted": "2025-11-29 05:31:45",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Evolving Paradigms in Task-Based Search and Learning: A Comparative Analysis of Traditional Search Engine with LLM-Enhanced Conversational Search System",
        "abstract": "Large Language Models (LLMs) are rapidly reshaping information retrieval by enabling interactive, generative, and inference-driven search. While traditional keyword-based search remains central to web and academic information access, it often struggles to support multi-step reasoning and exploratory learning tasks. LLM-powered search interfaces, such as ChatGPT and Claude, introduce new capabilities that may influence how users formulate queries, navigate information, and construct knowledge. However, empirical understanding of these effects is still limited. This study compares search behavior and learning outcomes in two environments: a standard search engine and an LLM-powered search system. We investigate (1) how search strategies, query formulation, and evaluation behaviors differ across systems, and (2) how LLM use affects comprehension, knowledge integration, and critical thinking during search-based learning tasks. Findings offer insight into how generative AI shapes information-seeking processes and contribute to ongoing discussions in information retrieval, human-AI interaction, and technology-supported learning.",
        "url": "http://arxiv.org/abs/2512.00313v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00313v1",
        "arxiv_id": "2512.00313v1",
        "authors": [
            "Zhitong Guan",
            "Yi Wang"
        ],
        "submitted": "2025-11-29 04:14:14",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Challenges of Heterogeneity in Big Data: A Comparative Study of Classification in Large-Scale Structured and Unstructured Domains",
        "abstract": "This study analyzes the impact of heterogeneity (\"Variety\") in Big Data by comparing classification strategies across structured (Epsilon) and unstructured (Rest-Mex, IMDB) domains. A dual methodology was implemented: evolutionary and Bayesian hyperparameter optimization (Genetic Algorithms, Optuna) in Python for numerical data, and distributed processing in Apache Spark for massive textual corpora. The results reveal a \"complexity paradox\": in high-dimensional spaces, optimized linear models (SVM, Logistic Regression) outperformed deep architectures and Gradient Boosting. Conversely, in text-based domains, the constraints of distributed fine-tuning led to overfitting in complex models, whereas robust feature engineering -- specifically Transformer-based embeddings (ROBERTa) and Bayesian Target Encoding -- enabled simpler models to generalize effectively. This work provides a unified framework for algorithm selection based on data nature and infrastructure constraints.",
        "url": "http://arxiv.org/abs/2512.00298v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00298v1",
        "arxiv_id": "2512.00298v1",
        "authors": [
            "GonzÃ¡lez Trigueros JesÃºs Eduardo",
            "Alonso SÃ¡nchez Alejandro",
            "MuÃ±oz Rivera Emilio",
            "PeÃ±arÃ¡n Prieto Mariana Jaqueline",
            "Mendoza GonzÃ¡lez Camila Natalia"
        ],
        "submitted": "2025-11-29 03:41:17",
        "source": "arxiv",
        "comment": "13 pages, 1 figure, 3 tables. Comparative study involving Apache Spark and Hyperparameter Optimization. Keywords: Big Data, NLP, Tabular Data"
    },
    {
        "title": "EduEval: A Hierarchical Cognitive Benchmark for Evaluating Large Language Models in Chinese Education",
        "abstract": "Large language models (LLMs) demonstrate significant potential for educational applications. However, their unscrutinized deployment poses risks to educational standards, underscoring the need for rigorous evaluation. We introduce EduEval, a comprehensive hierarchical benchmark for evaluating LLMs in Chinese K-12 education. This benchmark makes three key contributions: (1) Cognitive Framework: We propose the EduAbility Taxonomy, which unifies Bloom's Taxonomy and Webb's Depth of Knowledge to organize tasks across six cognitive dimensions including Memorization, Understanding, Application, Reasoning, Creativity, and Ethics. (2) Authenticity: Our benchmark integrates real exam questions, classroom conversation, student essays, and expert-designed prompts to reflect genuine educational challenges; (3) Scale: EduEval comprises 24 distinct task types with over 11,000 questions spanning primary to high school levels. We evaluate 14 leading LLMs under both zero-shot and few-shot settings, revealing that while models perform well on factual tasks, they struggle with classroom dialogue classification and exhibit inconsistent results in creative content generation. Interestingly, several open source models outperform proprietary systems on complex educational reasoning. Few-shot prompting shows varying effectiveness across cognitive dimensions, suggesting that different educational objectives require tailored approaches. These findings provide targeted benchmarking metrics for developing LLMs specifically optimized for diverse Chinese educational tasks.",
        "url": "http://arxiv.org/abs/2512.00290v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00290v1",
        "arxiv_id": "2512.00290v1",
        "authors": [
            "Guoqing Ma",
            "Jia Zhu",
            "Hanghui Guo",
            "Weijie Shi",
            "Yue Cui",
            "Jiawei Shen",
            "Zilong Li",
            "Yidan Liang"
        ],
        "submitted": "2025-11-29 03:09:50",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Lost without translation -- Can transformer (language models) understand mood states?",
        "abstract": "Background: Large Language Models show promise in psychiatry but are English-centric. Their ability to understand mood states in other languages is unclear, as different languages have their own idioms of distress. Aim: To quantify the ability of language models to faithfully represent phrases (idioms of distress) of four distinct mood states (depression, euthymia, euphoric mania, dysphoric mania) expressed in Indian languages. Methods: We collected 247 unique phrases for the four mood states across 11 Indic languages. We tested seven experimental conditions, comparing k-means clustering performance on: (a) direct embeddings of native and Romanised scripts (using multilingual and Indic-specific models) and (b) embeddings of phrases translated to English and Chinese. Performance was measured using a composite score based on Adjusted Rand Index, Normalised Mutual Information, Homogeneity and Completeness. Results: Direct embedding of Indic languages failed to cluster mood states (Composite Score = 0.002). All translation-based approaches showed significant improvement. High performance was achieved using Gemini-translated English (Composite=0.60) and human-translated English (Composite=0.61) embedded with gemini-001. Surprisingly, human-translated English, further translated into Chinese and embedded with a Chinese model, performed best (Composite = 0.67). Specialised Indic models (IndicBERT and Sarvam-M) performed poorly. Conclusion: Current models cannot meaningfully represent mood states directly from Indic languages, posing a fundamental barrier to their psychiatric application for diagnostic or therapeutic purposes in India. While high-quality translation bridges this gap, reliance on proprietary models or complex translation pipelines is unsustainable. Models must first be built to understand diverse local languages to be effective in global mental health.",
        "url": "http://arxiv.org/abs/2512.00274v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00274v1",
        "arxiv_id": "2512.00274v1",
        "authors": [
            "Prakrithi Shivaprakash",
            "Diptadhi Mukherjee",
            "Lekhansh Shukla",
            "Animesh Mukherjee",
            "Prabhat Chand",
            "Pratima Murthy"
        ],
        "submitted": "2025-11-29 01:55:11",
        "source": "arxiv",
        "comment": "33 pages, 3 figures, 2 tables"
    },
    {
        "title": "OmniFusion: Simultaneous Multilingual Multimodal Translations via Modular Fusion",
        "abstract": "There has been significant progress in open-source text-only translation large language models (LLMs) with better language coverage and quality. However, these models can be only used in cascaded pipelines for speech translation (ST), performing automatic speech recognition first followed by translation. This introduces additional latency, which is particularly critical in simultaneous ST (SimulST), and prevents the model from exploiting multimodal context, such as images, which can aid disambiguation. Pretrained multimodal foundation models (MMFMs) already possess strong perception and reasoning capabilities across multiple modalities, but generally lack the multilingual coverage and specialized translation performance of dedicated translation LLMs. To build an effective multimodal translation system, we propose an end-to-end approach that fuses MMFMs with translation LLMs. We introduce a novel fusion strategy that connects hidden states from multiple layers of a pretrained MMFM to a translation LLM, enabling joint end-to-end training. The resulting model, OmniFusion, built on Omni 2.5-7B as the MMFM and SeedX PPO-7B as the translation LLM, can perform speech-to-text, speech-and-image-to-text, and text-and-image-to-text translation. Experiments demonstrate that OmniFusion effectively leverages both audio and visual inputs, achieves a 1-second latency reduction in SimulST compared to cascaded pipelines and also improves the overall translation quality\\footnote{Code is available at https://github.com/saikoneru/OmniFusion}.",
        "url": "http://arxiv.org/abs/2512.00234v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00234v1",
        "arxiv_id": "2512.00234v1",
        "authors": [
            "Sai Koneru",
            "Matthias Huck",
            "Jan Niehues"
        ],
        "submitted": "2025-11-28 22:39:12",
        "source": "arxiv",
        "comment": "Preprint for ACL 2026"
    },
    {
        "title": "Minimal-Edit Instruction Tuning for Low-Resource Indic GEC",
        "abstract": "Grammatical error correction for Indic languages faces limited supervision, diverse scripts, and rich morphology. We propose an augmentation-free setup that uses instruction-tuned large language models and conservative decoding. A 12B GEMMA 3 model is instruction-tuned in bnb 4-bit precision with parameter-efficient fine-tuning (PEFT) and Alpaca-style formatting. Decoding follows a deterministic, constraint-aware procedure with a lightweight normaliser that encourages minimal, meaning-preserving edits. We operationalise inference, subsequent to instruction fine-tuning (IFT), via a fixed, language-specific prompt directly synthesised from a deterministic error classifier's taxonomy, label distributions, and precedence ordering computed on the training corpus.\n  Under the official untuned GLEU evaluation, the system scores 92.41 on Malayalam, sixth overall, and 81.44 on Hindi, third overall. These results indicate that classifier-informed prompt design, adapter-based instruction tuning, and deterministic decoding provide a reproducible and a computationally efficient alternative to augmentation-centred pipelines for Indic GEC. The approach also motivates future work on stronger morphosyntactic constraints and human-centred evaluation of conservative edits.",
        "url": "http://arxiv.org/abs/2512.00219v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00219v1",
        "arxiv_id": "2512.00219v1",
        "authors": [
            "Akhil Rajeev P"
        ],
        "submitted": "2025-11-28 21:38:27",
        "source": "arxiv",
        "comment": "Submitted to AACL-IJCNLP Bhasha Workshop Shared Task1 :GEC"
    },
    {
        "title": "Towards Corpus-Grounded Agentic LLMs for Multilingual Grammatical Analysis",
        "abstract": "Empirical grammar research has become increasingly data-driven, but the systematic analysis of annotated corpora still requires substantial methodological and technical effort. We explore how agentic large language models (LLMs) can streamline this process by reasoning over annotated corpora and producing interpretable, data-grounded answers to linguistic questions. We introduce an agentic framework for corpus-grounded grammatical analysis that integrates concepts such as natural-language task interpretation, code generation, and data-driven reasoning. As a proof of concept, we apply it to Universal Dependencies (UD) corpora, testing it on multilingual grammatical tasks inspired by the World Atlas of Language Structures (WALS). The evaluation spans 13 word-order features and over 170 languages, assessing system performance across three complementary dimensions - dominant-order accuracy, order-coverage completeness, and distributional fidelity - which reflect how well the system generalizes, identifies, and quantifies word-order variations. The results demonstrate the feasibility of combining LLM reasoning with structured linguistic data, offering a first step toward interpretable, scalable automation of corpus-based grammatical inquiry.",
        "url": "http://arxiv.org/abs/2512.00214v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00214v1",
        "arxiv_id": "2512.00214v1",
        "authors": [
            "Matej Klemen",
            "TjaÅ¡a ArÄon",
            "Luka TerÄon",
            "Marko Robnik-Å ikonja",
            "Kaja Dobrovoljc"
        ],
        "submitted": "2025-11-28 21:27:58",
        "source": "arxiv",
        "comment": "Pre-print, submission under review"
    },
    {
        "title": "Tree Matching Networks for Natural Language Inference: Parameter-Efficient Semantic Understanding via Dependency Parse Trees",
        "abstract": "In creating sentence embeddings for Natural Language Inference (NLI) tasks, using transformer-based models like BERT leads to high accuracy, but require hundreds of millions of parameters. These models take in sentences as a sequence of tokens, and learn to encode the meaning of the sequence into embeddings such that those embeddings can be used reliably for NLI tasks. Essentially, every word is considered against every other word in the sequence, and the transformer model is able to determine the relationships between them, entirely from scratch. However, a model that accepts explicit linguistic structures like dependency parse trees may be able to leverage prior encoded information about these relationships, without having to learn them from scratch, thus improving learning efficiency. To investigate this, we adapt Graph Matching Networks (GMN) to operate on dependency parse trees, creating Tree Matching Networks (TMN). We compare TMN to a BERT based model on the SNLI entailment task and on the SemEval similarity task. TMN is able to achieve significantly better results with a significantly reduced memory footprint and much less training time than the BERT based model on the SNLI task, while both models struggled to preform well on the SemEval. Explicit structural representations significantly outperform sequence-based models at comparable scales, but current aggregation methods limit scalability. We propose multi-headed attention aggregation to address this limitation.",
        "url": "http://arxiv.org/abs/2512.00204v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00204v1",
        "arxiv_id": "2512.00204v1",
        "authors": [
            "Jason Lunder"
        ],
        "submitted": "2025-11-28 21:06:11",
        "source": "arxiv",
        "comment": "16 pages, preprint"
    },
    {
        "title": "Measuring What LLMs Think They Do: SHAP Faithfulness and Deployability on Financial Tabular Classification",
        "abstract": "Large Language Models (LLMs) have attracted significant attention for classification tasks, offering a flexible alternative to trusted classical machine learning models like LightGBM through zero-shot prompting. However, their reliability for structured tabular data remains unclear, particularly in high stakes applications like financial risk assessment. Our study systematically evaluates LLMs and generates their SHAP values on financial classification tasks. Our analysis shows a divergence between LLMs self-explanation of feature impact and their SHAP values, as well as notable differences between LLMs and LightGBM SHAP values. These findings highlight the limitations of LLMs as standalone classifiers for structured financial modeling, but also instill optimism that improved explainability mechanisms coupled with few-shot prompting will make LLMs usable in risk-sensitive domains.",
        "url": "http://arxiv.org/abs/2512.00163v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00163v1",
        "arxiv_id": "2512.00163v1",
        "authors": [
            "Saeed AlMarri",
            "Mathieu Ravaut",
            "Kristof Juhasz",
            "Gautier Marti",
            "Hamdan Al Ahbabi",
            "Ibrahim Elfadel"
        ],
        "submitted": "2025-11-28 19:04:25",
        "source": "arxiv",
        "comment": "7 pages, 3 figures, 3 tables, AAAI 2026 Deployable AI Workshop"
    }
]