# Daily Papers Report - 2025-06-29

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. JointRank: Rank Large Set with Single Pass

- **LLM Score**: 8
- **Keyword Score**: 26
- **Authors**: Evgeny Dedov
- **URL**: <http://arxiv.org/abs/2506.22262v1>
- **Submitted**: 2025-06-27 14:30:12
- **Comment**: ICTIR'25 Accepted
- **Topic Keywords**: information retrieval, ranking, rerank, listwise, pairwise, relevance, retrieval, recommend, web search, rank, search, trec
- **Reason**: The paper focuses on efficient ranking methods for large candidate pools, which is a key aspect of information retrieval. The proposed JointRank method is model-agnostic and can be applied to various domains, including e-commerce. Although it does not specifically address query understanding, ranking models, or user behavior modeling, it is still relevant to the broader field of information retrieval and search technologies.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Efficient Reranking in Information Retrieval Systems
- **Aim**: To propose a novel method called JointRank for efficiently ranking large sets of candidate items in information retrieval systems
- **Rationale**: To overcome the limitations of listwise rerankers, which are often limited by model input size constraints or degraded quality when processing large sets
- **Ground**: The need for real-time ranking in applications such as retrieval-augmented generation, code completion, and interactive Q&A systems, where latency is a critical factor
- **Experiment**: Evaluating block designs and rank aggregations for recovering global order from pairwise comparisons, and comparing the performance of JointRank with other reranking algorithms
- **Takeaway**: JointRank achieves the lowest latency while maintaining competitive ranking effectiveness, making it a viable approach for efficient reranking in large candidate sets

#### Abstract
> Efficiently ranking relevant items from large candidate pools is a
cornerstone of modern information retrieval systems -- such as web search,
recommendation, and retrieval-augmented generation. Listwise rerankers, which
improve relevance by jointly considering multiple candidates, are often limited
in practice: either by model input size constraints, or by degraded quality
when processing large sets. We propose a model-agnostic method for fast
reranking large sets that exceed a model input limits. The method first
partitions candidate items into overlapping blocks, each of which is ranked
independently in parallel. Implicit pairwise comparisons are then derived from
these local rankings. Finally, these comparisons are aggregated to construct a
global ranking using algorithms such as Winrate or PageRank. Experiments on
TREC DL-2019 show that our method achieves an nDCG@10 of 70.88 compared to the
57.68 for full-context listwise approach using gpt-4.1-mini as long-context
model, while reducing latency from 21 to 8 seconds.
  The implementation of the algorithm and the experiments is available in the
repository: https://github.com/V3RGANz/jointrank

---

### 2. Towards Fair Rankings: Leveraging LLMs for Gender Bias Detection and Measurement

- **LLM Score**: 7
- **Keyword Score**: 12
- **Authors**: Maryam Mousavian, Zahra Abbasiantaeb, Mohammad Aliannejadi, Fabio Crestani
- **URL**: <http://arxiv.org/abs/2506.22372v1>
- **Submitted**: 2025-06-27 16:39:12
- **Comment**: Accepted by ACM SIGIR Conference on Innovative Concepts and Theories
  in Information Retrieval (ICTIR 2025)
- **Topic Keywords**: information retrieval, ranking, rag, retrieval, rank, search
- **Reason**: The paper is relevant to your research interests in Information Retrieval and Search technologies, particularly in the area of query understanding and ranking models. The use of Large Language Models (LLMs) for gender bias detection and measurement is also related to your interests in NLP and data mining. However, the focus on gender bias detection and measurement is somewhat specific and may not be directly aligned with your core research themes.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Detecting and Measuring Gender Bias in Passage Ranking
- **Aim**: To propose a novel gender fairness metric, Class-wise Weighted Exposure (CWEx), and evaluate its effectiveness in detecting gender bias in passage ranking
- **Rationale**: Existing gender bias metrics are limited and oversimplified, relying on lexical- and frequency-based measures, and failing to capture complex and obfuscated biases in text
- **Ground**: The authors annotate a subset of the MS MARCO Passage Ranking collection and release a new gender bias collection, MSMGenderBias, and conduct experiments to investigate the use of Large Language Models (LLMs) in detecting gender bias
- **Experiment**: The authors conduct a series of experiments, including classifying documents into three categories (neutral, male-biased, and female-biased) and comparing the predictions of LLMs with human labels, and assess the performance of the models using utility metrics (MRR and nDCG)
- **Takeaway**: The proposed framework provides a more robust approach to analyzing and mitigating bias in IR systems by integrating LLM-driven bias detection, an improved fairness metric, and gender bias annotations for an established dataset

#### Abstract
> The presence of social biases in Natural Language Processing (NLP) and
Information Retrieval (IR) systems is an ongoing challenge, which underlines
the importance of developing robust approaches to identifying and evaluating
such biases. In this paper, we aim to address this issue by leveraging Large
Language Models (LLMs) to detect and measure gender bias in passage ranking.
Existing gender fairness metrics rely on lexical- and frequency-based measures,
leading to various limitations, e.g., missing subtle gender disparities.
Building on our LLM-based gender bias detection method, we introduce a novel
gender fairness metric, named Class-wise Weighted Exposure (CWEx), aiming to
address existing limitations. To measure the effectiveness of our proposed
metric and study LLMs' effectiveness in detecting gender bias, we annotate a
subset of the MS MARCO Passage Ranking collection and release our new gender
bias collection, called MSMGenderBias, to foster future research in this area.
Our extensive experimental results on various ranking models show that our
proposed metric offers a more detailed evaluation of fairness compared to
previous metrics, with improved alignment to human labels (58.77% for
Grep-BiasIR, and 18.51% for MSMGenderBias, measured using Cohen's Kappa
agreement), effectively distinguishing gender bias in ranking. By integrating
LLM-driven bias detection, an improved fairness metric, and gender bias
annotations for an established dataset, this work provides a more robust
framework for analyzing and mitigating bias in IR systems.

---

### 3. UiS-IAI@LiveRAG: Retrieval-Augmented Information Nugget-Based Generation of Responses

- **LLM Score**: 6
- **Keyword Score**: 23
- **Authors**: Weronika ≈Åajewska, Ivica Kostric, Gabriel Iturra-Bocaz, Mariam Arustashvili, Krisztian Balog
- **URL**: <http://arxiv.org/abs/2506.22210v1>
- **Submitted**: 2025-06-27 13:29:25
- **Topic Keywords**: passage retrieval, query, queries, ranking, rerank, rag, retrieval, rank, search, sigir
- **Reason**: The paper focuses on Retrieval-Augmented Generation (RAG), which is related to query understanding and ranking models, but it's not directly aligned with my primary interests in information retrieval and search technologies. The paper's emphasis on natural language processing and data mining is more relevant, but it's not a central match.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Retrieval-Augmented Generation (RAG) technology
- **Aim**: Advance RAG technology, focusing on improving factual correctness, source attribution, and response completeness
- **Rationale**: Modular pipeline for RAG, called GINGER, operates on 'information nuggets' to provide comprehensive yet concise answers while maintaining strong source attribution
- **Ground**: Experiments on TREC RAG'24 dataset and a small test dataset generated with DataMorgana
- **Experiment**: Combining original query with diverse rewrites improves recall, and optimizing reranking and generation parameters improves response quality up to a point
- **Takeaway**: Importance of query rewriting, reranking, and generation parameters in improving response quality, and need for more robust response evaluation strategies

#### Abstract
> Retrieval-augmented generation (RAG) faces challenges related to factual
correctness, source attribution, and response completeness. The LiveRAG
Challenge hosted at SIGIR'25 aims to advance RAG research using a fixed corpus
and a shared, open-source LLM. We propose a modular pipeline that operates on
information nuggets-minimal, atomic units of relevant information extracted
from retrieved documents. This multistage pipeline encompasses query rewriting,
passage retrieval and reranking, nugget detection and clustering, cluster
ranking and summarization, and response fluency enhancement. This design
inherently promotes grounding in specific facts, facilitates source
attribution, and ensures maximum information inclusion within length
constraints. In this challenge, we extend our focus to also address the
retrieval component of RAG, building upon our prior work on multi-faceted query
rewriting. Furthermore, for augmented generation, we concentrate on improving
context curation capabilities, maximizing the breadth of information covered in
the response while ensuring pipeline efficiency. Our results show that
combining original queries with a few sub-query rewrites boosts recall, while
increasing the number of documents used for reranking and generation beyond a
certain point reduces effectiveness, without improving response quality.

---

### 4. ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation

- **LLM Score**: 6
- **Keyword Score**: 9
- **Authors**: Reza Yousefi Maragheh, Pratheek Vadla, Priyank Gupta, Kai Zhao, Aysenur Inan, Kehui Yao, Jianpeng Xu, Praveen Kanumala, Jason Cho, Sushant Kumar
- **URL**: <http://arxiv.org/abs/2506.21931v1>
- **Submitted**: 2025-06-27 05:45:59
- **Topic Keywords**: rag, retrieval augmented generation, retrieval, recommend, personalization, rank
- **Reason**: The paper explores Retrieval-Augmented Generation (RAG) for personalized recommendation, which is related to search technologies and query understanding. However, the focus on recommendation systems and user behavior modeling is not directly aligned with the user's primary interest in Information Retrieval, especially in areas that require deep semantic understanding and real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Personalized Recommendation Systems
- **Aim**: To develop a novel framework for personalized recommendation systems that integrates a multi-agent collaboration mechanism into the RAG pipeline
- **Rationale**: Traditional RAG systems have limitations in capturing nuanced user preferences and contexts, and simplistic retrieval mechanisms fail to comprehend implicit preferences and intentions
- **Ground**: ARAG framework consists of four specialized LLM-based agents: User Understanding Agent, NLI Agent, Context Summary Agent, and Item Ranker Agent, which collaborate through a blackboard-style multi-agent system
- **Experiment**: Evaluation of ARAG across three datasets, with significant improvements in NDCG@5 and Hit@5 compared to standard RAG and recency-based baselines, and an ablation study to analyze the effect of different components of ARAG
- **Takeaway**: ARAG outperforms both Recency-based Ranking and Vanilla RAG frameworks across all datasets and metrics, with significant improvements in NDCG@5 and Hit@5 scores, and demonstrates effectiveness in conversational recommendation

#### Abstract
> Retrieval-Augmented Generation (RAG) has shown promise in enhancing
recommendation systems by incorporating external context into large language
model prompts. However, existing RAG-based approaches often rely on static
retrieval heuristics and fail to capture nuanced user preferences in dynamic
recommendation scenarios. In this work, we introduce ARAG, an Agentic
Retrieval-Augmented Generation framework for Personalized Recommendation, which
integrates a multi-agent collaboration mechanism into the RAG pipeline. To
better understand the long-term and session behavior of the user, ARAG
leverages four specialized LLM-based agents: a User Understanding Agent that
summarizes user preferences from long-term and session contexts, a Natural
Language Inference (NLI) Agent that evaluates semantic alignment between
candidate items retrieved by RAG and inferred intent, a context summary agent
that summarizes the findings of NLI agent, and an Item Ranker Agent that
generates a ranked list of recommendations based on contextual fit. We evaluate
ARAG accross three datasets. Experimental results demonstrate that ARAG
significantly outperforms standard RAG and recency-based baselines, achieving
up to 42.1% improvement in NDCG@5 and 35.5% in Hit@5. We also, conduct an
ablation study to analyse the effect by different components of ARAG. Our
findings highlight the effectiveness of integrating agentic reasoning into
retrieval-augmented recommendation and provide new directions for LLM-based
personalization.

---

### 5. HLTCOE at LiveRAG: GPT-Researcher using ColBERT retrieval

- **LLM Score**: 6
- **Keyword Score**: 8
- **Authors**: Kevin Duh, Eugene Yang, Orion Weller, Andrew Yates, Dawn Lawrie
- **URL**: <http://arxiv.org/abs/2506.22356v1>
- **Submitted**: 2025-06-27 16:08:39
- **Comment**: 5 pages, 1 figure
- **Topic Keywords**: query, rag, retrieval, search
- **Reason**: The paper focuses on a specific application of ColBERT retrieval in a question-answering task, which is related to query understanding and ranking models. However, the paper's primary focus is on the system's architecture and performance, rather than the underlying theoretical foundations or user behavior modeling, which limits its relevance to my research interests.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: LiveRAG competition submission using the GPT-Researcher framework
- **Aim**: To develop a system that can effectively research the context of a question and generate a correct and faithful answer
- **Rationale**: The system was designed to improve the efficiency and accuracy of question answering by leveraging the strengths of different models and techniques
- **Ground**: The system was built upon a previous system developed for the NeuCLIR Pilot Report Generation task and adapted for the LiveRAG competition
- **Experiment**: The system was evaluated on the LiveRAG competition and achieved a correctness score of 1.070111 and a faithfulness score of 14th among participating teams
- **Takeaway**: The system's performance highlights the importance of snippet selection and filtering, and future work should focus on improving these aspects to achieve better results

#### Abstract
> The HLTCOE LiveRAG submission utilized the GPT-researcher framework for
researching the context of the question, filtering the returned results, and
generating the final answer. The retrieval system was a ColBERT bi-encoder
architecture, which represents a passage with many dense tokens. Retrieval used
a local, compressed index of the FineWeb10-BT collection created with PLAID-X,
using a model fine-tuned for multilingual retrieval. Query generation from
context was done with Qwen2.5-7B-Instruct, while filtering was accomplished
with m2-bert-80M-8k-retrieval. Up to nine passages were used as context to
generate an answer using Falcon3-10B. This system placed 5th in the LiveRAG
automatic evaluation for correctness with a score of 1.07.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Literature-Grounded Novelty Assessment of Scientific Ideas

- **LLM Score**: 4
- **Keyword Score**: 11
- **Authors**: Simra Shahid, Marissa Radensky, Raymond Fok, Pao Siangliulue, Daniel S. Weld, Tom Hope
- **URL**: <http://arxiv.org/abs/2506.22026v1>
- **Submitted**: 2025-06-27 08:47:28
- **Topic Keywords**: ranking, rerank, rag, retrieval, rank
- **Reason**: The paper proposes a framework for novelty assessment of scientific ideas, leveraging LLM-based retrieval-augmented generation and embedding-based filtering. While it touches on retrieval and ranking, the focus is on novelty evaluation, which is not directly related to query understanding, ranking models, or user behavior modeling, which are core interests in Information Retrieval. The paper's relevance to NLP and data mining is also limited, as it primarily deals with scientific idea generation and evaluation.

#### Abstract
> Automated scientific idea generation systems have made remarkable progress,
yet the automatic evaluation of idea novelty remains a critical and
underexplored challenge. Manual evaluation of novelty through literature review
is labor-intensive, prone to error due to subjectivity, and impractical at
scale. To address these issues, we propose the Idea Novelty Checker, an
LLM-based retrieval-augmented generation (RAG) framework that leverages a
two-stage retrieve-then-rerank approach. The Idea Novelty Checker first
collects a broad set of relevant papers using keyword and snippet-based
retrieval, then refines this collection through embedding-based filtering
followed by facet-based LLM re-ranking. It incorporates expert-labeled examples
to guide the system in comparing papers for novelty evaluation and in
generating literature-grounded reasoning. Our extensive experiments demonstrate
that our novelty checker achieves approximately 13% higher agreement than
existing approaches. Ablation studies further showcases the importance of the
facet-based re-ranker in identifying the most relevant literature for novelty
evaluation.

### 7. DAPFAM: A Domain-Aware Patent Retrieval Dataset Aggregated at the Family Level

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Iliass Ayaou, Denis Cavallucci, Hicham Chibane
- **URL**: <http://arxiv.org/abs/2506.22141v1>
- **Submitted**: 2025-06-27 11:34:51
- **Topic Keywords**: query, relevance, rag, retrieval
- **Reason**: The paper proposes a new patent retrieval dataset, DAPFAM, which is domain-aware and multi-jurisdictional. While it touches on retrieval methods, the focus is on dataset construction and evaluation, rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval. The paper's relevance to the user's research is somewhat limited.

#### Abstract
> In the landscape of publicly available patent retrieval datasets, the need
for explicit indomain and out-of-domain labeling, multi-jurisdiction coverage,
balanced query domain representation and manageable sizes that support sub
document level experiments on moderate computational resources is often
overlooked. To address these gaps, we propose DAPFAM, a new open access
domain-aware patent retrieval dataset constructed at the simple-family level.
The dataset contains 1,247 domain balanced full text query families and 45,336
full text target families. The dataset is enriched by clear relevance judgments
(forward/backward citations as positive links, random negatives), as well as
explicit in-domain or out-of-domain relationships via a novel proposed
labelling scheme based on via International Patent Classification (IPC) codes,
resulting in 49,869 evaluation pairs. The dataset is multi jurisdictional,
requires little to no preprocessing for retrieval evaluation, and remains of a
size manageable for entities with limited ressources allowing for sub document
level retrieval experiments without excessive computational costs. We describe
our three-step data-curation pipeline, present comprehensive dataset
statistics, and provide baseline experiments using lexical and neural retrieval
methods. Our baseline experiments highlight significant challenges in
crossdomain patent retrieval. The dataset will be publicly available (for now
the access link is this repository:
https://osf.io/vbyzd/?view_only=1a40242e0d1941a58aa854af3e50cf6b).

### 8. Towards Transparent AI: A Survey on Explainable Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Avash Palikhe, Zhenyu Yu, Zichong Wang, Wenbin Zhang
- **URL**: <http://arxiv.org/abs/2506.21812v1>
- **Submitted**: 2025-06-26 23:25:22
- **Topic Keywords**: rag, search, acl
- **Reason**: The paper focuses on explainable AI methods for large language models, which is a related topic in NLP. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core aspects of information retrieval and search technologies. The paper's relevance is somewhat limited to my interests, but it may still provide some insights into NLP and AI techniques that could be applicable to my research.

#### Abstract
> Large Language Models (LLMs) have played a pivotal role in advancing
Artificial Intelligence (AI). However, despite their achievements, LLMs often
struggle to explain their decision-making processes, making them a 'black box'
and presenting a substantial challenge to explainability. This lack of
transparency poses a significant obstacle to the adoption of LLMs in
high-stakes domain applications, where interpretability is particularly
essential. To overcome these limitations, researchers have developed various
explainable artificial intelligence (XAI) methods that provide
human-interpretable explanations for LLMs. However, a systematic understanding
of these methods remains limited. To address this gap, this survey provides a
comprehensive review of explainability techniques by categorizing XAI methods
based on the underlying transformer architectures of LLMs: encoder-only,
decoder-only, and encoder-decoder models. Then these techniques are examined in
terms of their evaluation for assessing explainability, and the survey further
explores how these explanations are leveraged in practical applications.
Finally, it discusses available resources, ongoing research challenges, and
future directions, aiming to guide continued efforts toward developing
transparent and responsible LLMs.

### 9. Lost at the Beginning of Reasoning

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Baohao Liao, Xinyi Chen, Sara Rajaee, Yuhui Xu, Christian Herold, Anders S√∏gaard, Maarten de Rijke, Christof Monz
- **URL**: <http://arxiv.org/abs/2506.22058v1>
- **Submitted**: 2025-06-27 09:53:57
- **Comment**: 9 pages, 5 figures, 2 tables
- **Topic Keywords**: rag, search
- **Reason**: The paper explores the self-correction abilities of large language models during complex reasoning tasks, which is a relevant topic in Natural Language Processing. However, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval. The paper's focus on long chain-of-thought reasoning and model self-correction is somewhat related to my interests, but it does not align with my primary focus on information retrieval and real-time relevance optimization.

#### Abstract
> Recent advancements in large language models (LLMs) have significantly
advanced complex reasoning capabilities, particularly through extended
chain-of-thought (CoT) reasoning that incorporates mechanisms such as
backtracking, self-reflection and self-correction. Despite these developments,
the self-correction abilities of LLMs during long CoT reasoning remain
underexplored. And recent findings on overthinking suggest that such models
often engage in unnecessarily redundant reasoning. In this work, we empirically
show that the first reasoning step exerts a disproportionately large influence
on the final prediction - errors introduced at this stage can substantially
degrade subsequent reasoning quality. This phenomenon is consistently observed
across two state-of-the-art open-source reasoning model families: DeepSeek-R1
and Qwen3. To address this, we propose an efficient sampling strategy that
leverages a reward model to identify and retain high-quality first reasoning
steps while discarding suboptimal ones, achieving up to a 70% reduction in
inference cost without sacrificing accuracy. Finally, we introduce a new
benchmark specifically constructed with deliberately flawed first reasoning
steps to systematically evaluate model self-correction capabilities, offering a
foundation for future research on robust reasoning in LLMs.

### 10. A Dual-Layered Evaluation of Geopolitical and Cultural Bias in LLMs

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Sean Kim, Hyuhng Joon Kim
- **URL**: <http://arxiv.org/abs/2506.21881v1>
- **Submitted**: 2025-06-27 03:37:15
- **Comment**: This paper is accepted to ACL Student Research Workshop (SRW) 2025
- **Topic Keywords**: query
- **Reason**: The paper explores the bias in large language models (LLMs) in different linguistic and cultural contexts, which is related to my interest in Natural Language Processing (NLP). However, the focus on LLMs and their evaluation framework is not directly aligned with my primary research interest in Information Retrieval (IR) and Search technologies, particularly query understanding, ranking models, and user behavior modeling.

#### Abstract
> As large language models (LLMs) are increasingly deployed across diverse
linguistic and cultural contexts, understanding their behavior in both factual
and disputable scenarios is essential, especially when their outputs may shape
public opinion or reinforce dominant narratives. In this paper, we define two
types of bias in LLMs: model bias (bias stemming from model training) and
inference bias (bias induced by the language of the query), through a two-phase
evaluation. Phase 1 evaluates LLMs on factual questions where a single
verifiable answer exists, assessing whether models maintain consistency across
different query languages. Phase 2 expands the scope by probing geopolitically
sensitive disputes, where responses may reflect culturally embedded or
ideologically aligned perspectives. We construct a manually curated dataset
spanning both factual and disputable QA, across four languages and question
types. The results show that Phase 1 exhibits query language induced alignment,
while Phase 2 reflects an interplay between the model's training context and
query language. This paper offers a structured framework for evaluating LLM
behavior across neutral and sensitive topics, providing insights for future LLM
deployment and culturally aware evaluation practices in multilingual contexts.

### 11. WildSpeech-Bench: Benchmarking Audio LLMs in Natural Speech Conversation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Jian Zhang, Linhao Zhang, Bokai Lei, Chuhan Wu, Wei Jia, Xiao Zhou
- **URL**: <http://arxiv.org/abs/2506.21875v1>
- **Submitted**: 2025-06-27 03:18:45
- **Topic Keywords**: query
- **Reason**: The paper presents a benchmarking framework for evaluating Large Language Models in natural speech conversations, which is related to Natural Language Processing (NLP). However, it does not directly address query understanding, ranking models, or user behavior modeling in Information Retrieval (IR), which are the user's primary research interests.

#### Abstract
> Recent multi-modal Large Language Models (LLMs) such as GPT-4o have
demonstrated strong capabilities of direct speech interaction. However, the
lack of specialized and comprehensive benchmarks for end-to-end speech LLM
evaluation hinders optimizing the user experience of Audio LLMs in real-world
applications. Existing evaluation methods often adapt text-based benchmarks,
overlooking speech's unique characteristics and challenges, including prosody,
homophones, stuttering, and differing user expectations. Here, we present a
novel approach to thoroughly evaluate LLMs in practical speech conversations.
We systematically curate real-world chat data relevant to spoken scenarios,
introduce diversity in speaker attributes and acoustic conditions, and augment
the dataset with speech-specific phenomena. We further design a query-aware
evaluation method to use customized evaluation checklists and prompts to
enhance the accuracy of automatic evaluation. We conduct comprehensive testing
and detailed analysis of various mainstream speech models, revealing
significant differences in model performance across different speech scenarios.
The use of query-aware evaluation further enables a finer-grained assessment
under various speech-specific scenarios. Our benchmark can provide valuable
insights for speech model development and evaluation.

### 12. Evaluating List Construction and Temporal Understanding capabilities of Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Alexandru Dumitru, V Venktesh, Adam Jatowt, Avishek Anand
- **URL**: <http://arxiv.org/abs/2506.21783v1>
- **Submitted**: 2025-06-26 21:40:58
- **Comment**: Accepted at ICTIR 2025 co-located with SIGIR 2025, 11 pages
- **Topic Keywords**: retrieval, search
- **Reason**: The paper focuses on evaluating the capabilities of Large Language Models (LLMs) in temporal understanding and list construction, which is related to information retrieval and natural language processing. However, the paper does not directly address query understanding, ranking models, or user behavior modeling, which are core aspects of the user's research interests.

#### Abstract
> Large Language Models (LLMs) have demonstrated immense advances in a wide
range of natural language tasks. However, these models are susceptible to
hallucinations and errors on particularly temporal understanding tasks
involving multiple entities in answers. In such tasks, they fail to associate
entities with accurate time intervals, generate a complete list of entities in
answers or reason about events associated with specific temporal bounds.
Existing works do not extensively evaluate the abilities of the model to
perform implicit and explicit temporal understanding in a list answer
construction setup. To bridge this gap, we propose the Time referenced List
based Question Answering or TLQA benchmark that requires structured answers in
list format aligned with corresponding time periods. Our TLQA benchmark,
requires both list construction and temporal understanding simultaneously,
which to the best of our knowledge has not been explored in prior benchmarks.
We investigate the temporal understanding and list construction capabilities of
state-of-the-art generative models on TLQA in closed-book and open-domain
settings. Our findings reveal significant shortcomings in current models,
particularly their inability to provide complete answers and temporally align
facts in a closed-book setup and the need to improve retrieval in open-domain
setup, providing clear future directions for research on TLQA. The benchmark
and code at https://github.com/elixir-research-group/TLQA.

### 13. The Consistency Hypothesis in Uncertainty Quantification for Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Quan Xiao, Debarun Bhattacharjya, Balaji Ganesan, Radu Marinescu, Katsiaryna Mirylenka, Nhan H Pham, Michael Glass, Junkyu Lee
- **URL**: <http://arxiv.org/abs/2506.21849v1>
- **Submitted**: 2025-06-27 01:53:15
- **Comment**: Accepted by The Conference on Uncertainty in Artificial Intelligence
  (UAI) 2025
- **Topic Keywords**: rag
- **Reason**: The paper explores uncertainty quantification for large language models, which is a topic in NLP. While it touches on the idea of confidence estimation, it does not directly relate to query understanding, ranking models, or user behavior modeling in the context of search technologies. The focus on language models and uncertainty quantification is somewhat relevant to my interests, but not a central match.

#### Abstract
> Estimating the confidence of large language model (LLM) outputs is essential
for real-world applications requiring high user trust. Black-box uncertainty
quantification (UQ) methods, relying solely on model API access, have gained
popularity due to their practical benefits. In this paper, we examine the
implicit assumption behind several UQ methods, which use generation consistency
as a proxy for confidence, an idea we formalize as the consistency hypothesis.
We introduce three mathematical statements with corresponding statistical tests
to capture variations of this hypothesis and metrics to evaluate LLM output
conformity across tasks. Our empirical investigation, spanning 8 benchmark
datasets and 3 tasks (question answering, text summarization, and text-to-SQL),
highlights the prevalence of the hypothesis under different settings. Among the
statements, we highlight the `Sim-Any' hypothesis as the most actionable, and
demonstrate how it can be leveraged by proposing data-free black-box UQ methods
that aggregate similarities between generations for confidence estimation.
These approaches can outperform the closest baselines, showcasing the practical
value of the empirically observed consistency hypothesis.

### 14. (Fact) Check Your Bias

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Eivind Morris Bakke, Nora Winger Heggelund
- **URL**: <http://arxiv.org/abs/2506.21745v1>
- **Submitted**: 2025-06-26 20:03:58
- **Topic Keywords**: retrieval
- **Reason**: The paper explores the impact of parametric knowledge biases in large language models on fact-checking outcomes, which is a relevant topic in Natural Language Processing. However, the focus is on fact verification and bias detection, rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval. The paper's relevance to IR is limited, but it may be of interest to researchers exploring the intersection of NLP and IR.

#### Abstract
> Automatic fact verification systems increasingly rely on large language
models (LLMs). We investigate how parametric knowledge biases in these models
affect fact-checking outcomes of the HerO system (baseline for FEVER-25). We
examine how the system is affected by: (1) potential bias in Llama 3.1's
parametric knowledge and (2) intentionally injected bias. When prompted
directly to perform fact-verification, Llama 3.1 labels nearly half the claims
as "Not Enough Evidence". Using only its parametric knowledge it is able to
reach a verdict on the remaining half of the claims. In the second experiment,
we prompt the model to generate supporting, refuting, or neutral fact-checking
documents. These prompts significantly influence retrieval outcomes, with
approximately 50\% of retrieved evidence being unique to each perspective.
Notably, the model sometimes refuses to generate supporting documents for
claims it believes to be false, creating an inherent negative bias. Despite
differences in retrieved evidence, final verdict predictions show stability
across prompting strategies. The code is available at:
https://github.com/eibakke/FEVER-8-Shared-Task

### 15. Evaluating Scoring Bias in LLM-as-a-Judge

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Qingquan Li, Shaoyu Dou, Kailai Shao, Chao Chen, Haixiang Hu
- **URL**: <http://arxiv.org/abs/2506.22316v1>
- **Submitted**: 2025-06-27 15:25:23
- **Topic Keywords**: search
- **Reason**: The paper focuses on evaluating biases in Large Language Models (LLMs) used as judges, which is related to my interest in Natural Language Processing (NLP). However, the specific context of LLM-as-a-Judge and the emphasis on scoring bias evaluation is not directly aligned with my primary focus on Information Retrieval and Search technologies, query understanding, ranking models, and user behavior modeling.

#### Abstract
> The remarkable performance of Large Language Models (LLMs) gives rise
to``LLM-as-a-Judge'', where LLMs are employed as evaluators for complex tasks.
Moreover, it has been widely adopted across fields such as Natural Language
Processing (NLP), preference learning, and various specific domains. However,
there are various biases within LLM-as-a-Judge, which adversely affect the
fairness and reliability of judgments. Current research on evaluating or
mitigating bias in LLM-as-a-Judge predominantly focuses on comparison-based
evaluations, while systematic investigations into bias in scoring-based
evaluations remain limited. Therefore, we define scoring bias in LLM-as-a-Judge
as the scores differ when scoring judge models are bias-related perturbed, and
provide a well-designed framework to comprehensively evaluate scoring bias. We
augment existing LLM-as-a-Judge benchmarks through data synthesis to construct
our evaluation dataset and design multi-faceted evaluation metrics. Our
experimental results demonstrate that the scoring stability of existing judge
models is disrupted by scoring biases. Further exploratory experiments and
discussions provide valuable insights into the design of scoring prompt
templates and the mitigation of scoring biases on aspects such as score
rubrics, score IDs, and reference answer selection.

### 16. Training Language Model to Critique for Better Refinement

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Tianshu Yu, Chao Xiang, Mingchuan Yang, Pei Ke, Bosi Wen, Cunxiang Wang, Jiale Cheng, Li Zhang, Xinyu Mu, Chuxiong Sun, Minlie Huang
- **URL**: <http://arxiv.org/abs/2506.22157v1>
- **Submitted**: 2025-06-27 12:10:57
- **Comment**: Accepted to ACL 2025 Findings
- **Topic Keywords**: search
- **Reason**: The paper focuses on training language models to critique and refine their responses, which is related to query understanding and ranking models in Information Retrieval. However, the paper's primary focus is on language models and critique-refinement loops, which is not directly aligned with the user's interests in search technologies and user behavior modeling.

#### Abstract
> Large language models (LLMs) have demonstrated remarkable evaluation and
critique capabilities, providing insightful feedback and identifying flaws in
various tasks. However, limited research has explored which types of critiques
are most effective for improving model responses or how to generate such
critiques. To address this gap, we introduce \textbf{R}efinement-oriented
\textbf{C}ritique \textbf{O}ptimization (RCO), a novel framework designed to
train critic models using refinement signals. RCO uses a feedback loop where
critiques, generated by the critic model, guide the actor model in refining its
responses. The critique utility (CU) quantifies the effectiveness of these
refinements, serving as the reward signal for training the critic model. By
focusing on critiques that lead to better refinements, RCO eliminates the need
for direct critique preference assessment, ensuring that critiques driving
meaningful improvements are rewarded. We evaluate RCO across five tasks, i.e.,
dialog generation, summarization, question answering, mathematical reasoning,
and code generation, and show that it significantly outperforms traditional
methods and open-source models in terms of critique quality and refinement
outcomes. Our contributions include the introduction of RCO, a novel
supervision scheme based on refined response preferences, and comprehensive
experimental results that highlight the method's effectiveness in enhancing LLM
critique-refinement loops.

### 17. Reward Balancing Revisited: Enhancing Offline Reinforcement Learning for Recommender Systems

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Wenzheng Shu, Yanxiang Zeng, Yongxiang Tang, Teng Sha, Ning Luo, Yanhua Cheng, Xialong Liu, Fan Zhou, Peng Jiang
- **URL**: <http://arxiv.org/abs/2506.22112v1>
- **Submitted**: 2025-06-27 10:46:41
- **Comment**: Accepted in Companion Proceedings of the ACM Web Conference 2025
- **Topic Keywords**: recommend
- **Reason**: The paper focuses on offline reinforcement learning for recommender systems, which is somewhat related to my interests in information retrieval and search technologies. However, the emphasis on recommender systems and reward balancing is not directly aligned with my primary focus on query understanding, ranking models, and user behavior modeling. The paper's relevance is limited to the broader area of search and recommendation, but it does not specifically address my core research themes.

#### Abstract
> Offline reinforcement learning (RL) has emerged as a prevalent and effective
methodology for real-world recommender systems, enabling learning policies from
historical data and capturing user preferences. In offline RL, reward shaping
encounters significant challenges, with past efforts to incorporate prior
strategies for uncertainty to improve world models or penalize underexplored
state-action pairs. Despite these efforts, a critical gap remains: the
simultaneous balancing of intrinsic biases in world models and the diversity of
policy recommendations. To address this limitation, we present an innovative
offline RL framework termed Reallocated Reward for Recommender Systems (R3S).
By integrating inherent model uncertainty to tackle the intrinsic fluctuations
in reward predictions, we boost diversity for decision-making to align with a
more interactive paradigm, incorporating extra penalizers with decay that deter
actions leading to diminished state variety at both local and global scales.
The experimental results demonstrate that R3S improves the accuracy of world
models and efficiently harmonizes the heterogeneous preferences of the users.

### 18. Exploring the change in scientific readability following the release of ChatGPT

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Abdulkareem Alsudais
- **URL**: <http://arxiv.org/abs/2506.21825v1>
- **Submitted**: 2025-06-26 23:57:12
- **Topic Keywords**: search
- **Reason**: The paper explores the impact of ChatGPT on scientific readability, which is a related topic to information retrieval and natural language processing. However, the focus is on readability and writing styles rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest for you.

#### Abstract
> The rise and growing popularity of accessible large language models have
raised questions about their impact on various aspects of life, including how
scientists write and publish their research. The primary objective of this
paper is to analyze a dataset consisting of all abstracts posted on arXiv.org
between 2010 and June 7th, 2024, to assess the evolution of their readability
and determine whether significant shifts occurred following the release of
ChatGPT in November 2022. Four standard readability formulas are used to
calculate individual readability scores for each paper, classifying their level
of readability. These scores are then aggregated by year and across the eight
primary categories covered by the platform. The results show a steady annual
decrease in readability, suggesting that abstracts are likely becoming
increasingly complex. Additionally, following the release of ChatGPT, a
significant change in readability is observed for 2023 and the analyzed months
of 2024. Similar trends are found across categories, with most experiencing a
notable change in readability during 2023 and 2024. These findings offer
insights into the broader changes in readability and point to the likely
influence of AI on scientific writing.

### 19. HyReC: Exploring Hybrid-based Retriever for Chinese

- **LLM Score**: 2
- **Keyword Score**: 8
- **Authors**: Zunran Wang, Zheng Shenpeng, Wang Shenglan, Minghui Zhao, Zhonghua Li
- **URL**: <http://arxiv.org/abs/2506.21913v1>
- **Submitted**: 2025-06-27 04:57:01
- **Topic Keywords**: retriever, dense retrieval, retrieval
- **Reason**: The paper focuses on a specific retrieval method for Chinese, which is not directly related to the user's interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. Although it mentions hybrid-based retrieval, the context is limited to Chinese and does not explore query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's research interests.

#### Abstract
> Hybrid-based retrieval methods, which unify dense-vector and lexicon-based
retrieval, have garnered considerable attention in the industry due to
performance enhancement. However, despite their promising results, the
application of these hybrid paradigms in Chinese retrieval contexts has
remained largely underexplored. In this paper, we introduce HyReC, an
innovative end-to-end optimization method tailored specifically for
hybrid-based retrieval in Chinese. HyReC enhances performance by integrating
the semantic union of terms into the representation model. Additionally, it
features the Global-Local-Aware Encoder (GLAE) to promote consistent semantic
sharing between lexicon-based and dense retrieval while minimizing the
interference between them. To further refine alignment, we incorporate a
Normalization Module (NM) that fosters mutual benefits between the retrieval
approaches. Finally, we evaluate HyReC on the C-MTEB retrieval benchmark to
demonstrate its effectiveness.

### 20. RiverEcho: Real-Time Interactive Digital System for Ancient Yellow River Culture

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Haofeng Wang, Yilin Guo, Zehao Li, Tong Yue, Yizong Wang, Enci Zhang, Rongqun Lin, Feng Gao, Shiqi Wang, Siwei Ma
- **URL**: <http://arxiv.org/abs/2506.21865v1>
- **Submitted**: 2025-06-27 02:40:00
- **Comment**: IEEE International Conference on Multimedia and Expo Workshop,
  2025.(Accepted)
- **Topic Keywords**: queries, rag, retrieval
- **Reason**: This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on a specific cultural topic, ancient Yellow River culture, and uses a large language model and cultural knowledge dataset, which is not related to the user's areas of interest.

#### Abstract
> The Yellow River is China's mother river and a cradle of human civilization.
The ancient Yellow River culture is, moreover, an indispensable part of human
art history. To conserve and inherit the ancient Yellow River culture, we
designed RiverEcho, a real-time interactive system that responds to voice
queries using a large language model and a cultural knowledge dataset,
delivering explanations through a talking-head digital human. Specifically, we
built a knowledge database focused on the ancient Yellow River culture,
including the collection of historical texts and the processing pipeline.
Experimental results demonstrate that leveraging Retrieval-Augmented Generation
(RAG) on the proposed dataset enhances the response quality of the Large
Language Model(LLM), enabling the system to generate more professional and
informative responses. Our work not only diversifies the means of promoting
Yellow River culture but also provides users with deeper cultural insights.

### 21. Leveraging In-Context Learning for Political Bias Testing of LLMs

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Patrick Haller, Jannis Vamvas, Rico Sennrich, Lena A. J√§ger
- **URL**: <http://arxiv.org/abs/2506.22232v1>
- **Submitted**: 2025-06-27 13:49:37
- **Comment**: ACL 2025
- **Topic Keywords**: query, rag
- **Reason**: This paper focuses on evaluating the potential biases of Large Language Models (LLMs) using a new probing task, Questionnaire Modeling (QM), which leverages human survey data as in-context examples. While it touches on the topic of model evaluation, it does not directly relate to query understanding, ranking models, or user behavior modeling in the context of Information Retrieval, which are the user's primary research interests.

#### Abstract
> A growing body of work has been querying LLMs with political questions to
evaluate their potential biases. However, this probing method has limited
stability, making comparisons between models unreliable. In this paper, we
argue that LLMs need more context. We propose a new probing task, Questionnaire
Modeling (QM), that uses human survey data as in-context examples. We show that
QM improves the stability of question-based bias evaluation, and demonstrate
that it may be used to compare instruction-tuned models to their base versions.
Experiments with LLMs of various sizes indicate that instruction tuning can
indeed change the direction of bias. Furthermore, we observe a trend that
larger models are able to leverage in-context examples more effectively, and
generally exhibit smaller bias scores in QM. Data and code are publicly
available.

### 22. Decoding Machine Translationese in English-Chinese News: LLMs vs. NMTs

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Delu Kong, Lieve Macken
- **URL**: <http://arxiv.org/abs/2506.22050v1>
- **Submitted**: 2025-06-27 09:45:37
- **Comment**: 14 pages, 5 figures, 6 tables. Accpeted in MT Summit 2025, Research:
  Technical track. Official version may be accessed later in the ACL Anthology
- **Topic Keywords**: ranking, rank, search
- **Reason**: The paper focuses on Machine Translationese in English-Chinese news texts, exploring linguistic patterns in Neural Machine Translation systems and Large Language Models. While it touches on feature selection and classification accuracy, it does not relate to query understanding, ranking models, or user behavior modeling in Information Retrieval, which are core areas of your research interests.

#### Abstract
> This study explores Machine Translationese (MTese) -- the linguistic
peculiarities of machine translation outputs -- focusing on the
under-researched English-to-Chinese language pair in news texts. We construct a
large dataset consisting of 4 sub-corpora and employ a comprehensive five-layer
feature set. Then, a chi-square ranking algorithm is applied for feature
selection in both classification and clustering tasks. Our findings confirm the
presence of MTese in both Neural Machine Translation systems (NMTs) and Large
Language Models (LLMs). Original Chinese texts are nearly perfectly
distinguishable from both LLM and NMT outputs. Notable linguistic patterns in
MT outputs are shorter sentence lengths and increased use of adversative
conjunctions. Comparing LLMs and NMTs, we achieve approximately 70%
classification accuracy, with LLMs exhibiting greater lexical diversity and
NMTs using more brackets. Additionally, translation-specific LLMs show lower
lexical diversity but higher usage of causal conjunctions compared to generic
LLMs. Lastly, we find no significant differences between LLMs developed by
Chinese firms and their foreign counterparts.

### 23. CAL-RAG: Retrieval-Augmented Multi-Agent Generation for Content-Aware Layout Design

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Najmeh Forouzandehmehr, Reza Yousefi Maragheh, Sriram Kollipara, Kai Zhao, Topojoy Biswas, Evren Korpeoglu, Kannan Achan
- **URL**: <http://arxiv.org/abs/2506.21934v1>
- **Submitted**: 2025-06-27 06:09:56
- **Topic Keywords**: rag, retrieval, recommend
- **Reason**: The paper focuses on content-aware layout generation, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions multimodal retrieval, the context is different from the user's interests in IR and NLP.

#### Abstract
> Automated content-aware layout generation -- the task of arranging visual
elements such as text, logos, and underlays on a background canvas -- remains a
fundamental yet under-explored problem in intelligent design systems. While
recent advances in deep generative models and large language models (LLMs) have
shown promise in structured content generation, most existing approaches lack
grounding in contextual design exemplars and fall short in handling semantic
alignment and visual coherence. In this work we introduce CAL-RAG, a
retrieval-augmented, agentic framework for content-aware layout generation that
integrates multimodal retrieval, large language models, and collaborative
agentic reasoning. Our system retrieves relevant layout examples from a
structured knowledge base and invokes an LLM-based layout recommender to
propose structured element placements. A vision-language grader agent evaluates
the layout with visual metrics, and a feedback agent provides targeted
refinements, enabling iterative improvement. We implement our framework using
LangGraph and evaluate it on the PKU PosterLayout dataset, a benchmark rich in
semantic and structural variability. CAL-RAG achieves state-of-the-art
performance across multiple layout metrics -- including underlay effectiveness,
element alignment, and overlap -- substantially outperforming strong baselines
such as LayoutPrompter. These results demonstrate that combining retrieval
augmentation with agentic multi-step reasoning yields a scalable,
interpretable, and high-fidelity solution for automated layout generation.

### 24. The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Bingchen Zhao, Despoina Magka, Minqi Jiang, Xian Li, Roberta Raileanu, Tatiana Shavrina, Jean-Christophe Gagnon-Audet, Kelvin Niu, Shagun Sodhani, Michael Shvartsman, Andrei Lupu, Alisia Lupidi, Edan Toledo, Karen Hambardzumyan, Martin Josifoski, Thomas Foster, Lucia Cipolina-Kun, Abhishek Charnalia, Derek Dunfield, Alexander H. Miller, Oisin Mac Aodha, Jakob Foerster, Yoram Bachrach
- **URL**: <http://arxiv.org/abs/2506.22419v1>
- **Submitted**: 2025-06-27 17:44:32
- **Topic Keywords**: rag, search
- **Reason**: The paper is not related to Information Retrieval, Search technologies, or Natural Language Processing, and does not involve query understanding, ranking models, or user behavior modeling. The topic of large language models and their ability to reproduce existing work is not directly relevant to the user's research interests.

#### Abstract
> Rapid advancements in large language models (LLMs) have the potential to
assist in scientific progress. A critical capability toward this endeavor is
the ability to reproduce existing work. To evaluate the ability of AI agents to
reproduce results in an active research area, we introduce the Automated LLM
Speedrunning Benchmark, leveraging the research community contributions on the
NanoGPT speedrun, a competition to train a GPT-2 model in the shortest time.
Each of the 19 speedrun tasks provides the agent with the previous records
training script, optionally paired with one of three hint formats, ranging from
pseudocode to paper-like descriptions of the new records improvements. Records
execute quickly by design and speedrun improvements encompass diverse
code-level changes, ranging from high-level algorithmic advancements to
hardware-aware optimizations. These features make the benchmark both accessible
and realistic for the frontier problem of improving LLM training. We find that
recent reasoning LLMs combined with SoTA scaffolds struggle to reimplement
already-known innovations in our benchmark, even when given detailed hints. Our
benchmark thus provides a simple, non-saturated measure of an LLMs ability to
automate scientific reproduction, a necessary (but not sufficient) skill for an
autonomous research agent.

### 25. Education-Oriented Graph Retrieval-Augmented Generation for Learning Path Recommendation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Xinghe Cheng, Zihan Zhang, Jiapu Wang, Liangda Fang, Chaobo He, Quanlong Guan, Shirui Pan, Weiqi Luo
- **URL**: <http://arxiv.org/abs/2506.22303v1>
- **Submitted**: 2025-06-27 15:15:42
- **Topic Keywords**: retrieval, recommend
- **Reason**: The paper focuses on learning path recommendation, which is not directly related to information retrieval, search technologies, or query understanding. Although it involves graph retrieval and generation, the context is educational and does not align with the user's primary research interests in IR and NLP.

#### Abstract
> Learning path recommendation seeks to provide learners with a structured
sequence of learning items (e.g., knowledge concepts or exercises) to optimize
their learning efficiency. Despite significant efforts in this area, most
existing methods primarily rely on prerequisite relationships, which present
two major limitations: 1) Many educational datasets do not explicitly provide
prerequisite relationships between knowledge concepts, hindering the
application of current learning path recommendation methods. 2) Relying solely
on prerequisite relationships as the sole knowledge structure can impede
learning progress and negatively impact student outcomes. To address these
challenges, we propose a novel approach, Discrimination Learning Enhances
Learning Path Recommendation (DLELP), which enhances learning path
recommendations by incorporating both prerequisite and similarity relationships
between knowledge concepts. Specifically, we introduce a knowledge concept
structure graph generation module that adaptively constructs knowledge concept
structure graphs for different educational datasets, significantly improving
the generalizability of learning path recommendation methods. We then propose a
Discrimination Learning-driven Reinforcement Learning (DLRL) framework, which
mitigates the issue of blocked learning paths, further enhancing the efficacy
of learning path recommendations. Finally, we conduct extensive experiments on
three benchmark datasets, demonstrating that our method not only achieves
state-of-the-art performance but also provides interpretable reasoning for the
recommended learning paths.

### 26. Exploring Modularity of Agentic Systems for Drug Discovery

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Laura van Weesep, Samuel Genheden, Ola Engkvist, Jens Sj√∂lund
- **URL**: <http://arxiv.org/abs/2506.22189v1>
- **Submitted**: 2025-06-27 12:57:00
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on drug discovery and large language models, which is outside your primary focus areas.

#### Abstract
> Large-language models (LLMs) and agentic systems present exciting
opportunities to accelerate drug discovery and design. In this study, we
critically examine the modularity of LLM-based agentic systems for drug
discovery, i.e., whether parts of the agentic system such as the LLM are
interchangeable, a topic that has received limited attention in drug discovery
applications. We compare the performance of different large language models
(LLMs) and the effectiveness of tool-calling agents versus code-generating
agents in this domain. Our case study, comparing performance in orchestrating
tools for chemistry and drug discovery using an LLM-as-a-judge score, shows
that Claude-3.5-Sonnet, Claude-3.7-Sonnet and GPT-4o outperform alternative
language models such as Llama-3.1-8B, Llama-3.1-70B, GPT-3.5-Turbo, and
Nova-Micro. Although we confirm that code-generating agents outperform the
tool-calling ones on average, we show that this is highly question and model
dependent. Furthermore, the impact of replacing system prompts is dependent on
the specific question asked and the model used, underscoring that -- even in
this particular domain -- one cannot just replace language models without
considering prompt re-engineering. Our study highlights the necessity of
further research into the modularity of agentic systems to enable the
development of stable and scalable solutions for real-world problems.

### 27. Don't Trust Generative Agents to Mimic Communication on Social Networks Unless You Benchmarked their Empirical Realism

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Simon M√ºnker, Nils Schwager, Achim Rettinger
- **URL**: <http://arxiv.org/abs/2506.21974v1>
- **Submitted**: 2025-06-27 07:32:16
- **Comment**: 11 pages, 1 figure, 3 tables
- **Topic Keywords**: user behavior, search
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it touches on the topic of language models, it focuses on social network simulations and empirical realism, which is not a primary area of interest for you.

#### Abstract
> The ability of Large Language Models (LLMs) to mimic human behavior triggered
a plethora of computational social science research, assuming that empirical
studies of humans can be conducted with AI agents instead. Since there have
been conflicting research findings on whether and when this hypothesis holds,
there is a need to better understand the differences in their experimental
designs. We focus on replicating the behavior of social network users with the
use of LLMs for the analysis of communication on social networks. First, we
provide a formal framework for the simulation of social networks, before
focusing on the sub-task of imitating user communication. We empirically test
different approaches to imitate user behavior on X in English and German. Our
findings suggest that social simulations should be validated by their empirical
realism measured in the setting in which the simulation components were fitted.
With this paper, we argue for more rigor when applying generative-agent-based
modeling for social simulation.

### 28. PARSI: Persian Authorship Recognition via Stylometric Integration

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Kourosh Shahnazari, Mohammadali Keshtparvar, Seyed Moein Ayyoubzadeh
- **URL**: <http://arxiv.org/abs/2506.21840v1>
- **Submitted**: 2025-06-27 01:08:52
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus is on Persian authorship recognition, which is a specific domain and task, and does not align with your broader interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> The intricate linguistic, stylistic, and metrical aspects of Persian
classical poetry pose a challenge for computational authorship attribution. In
this work, we present a versatile framework to determine authorship among 67
prominent poets. We employ a multi-input neural framework consisting of a
transformer-based language encoder complemented by features addressing the
semantic, stylometric, and metrical dimensions of Persian poetry. Our feature
set encompasses 100-dimensional Word2Vec embeddings, seven stylometric
measures, and categorical encodings of poetic form and meter. We compiled a
vast corpus of 647,653 verses of the Ganjoor digital collection, validating the
data through strict preprocessing and author verification while preserving
poem-level splitting to prevent overlap. This work employs verse-level
classification and majority and weighted voting schemes in evaluation,
revealing that weighted voting yields 71% accuracy. We further investigate
threshold-based decision filtering, allowing the model to generate highly
confident predictions, achieving 97% accuracy at a 0.9 threshold, though at
lower coverage. Our work focuses on the integration of deep representational
forms with domain-specific features for improved authorship attribution. The
results illustrate the potential of our approach for automated classification
and the contribution to stylistic analysis, authorship disputes, and general
computational literature research. This research will facilitate further
research on multilingual author attribution, style shift, and generative
modeling of Persian poetry.

### 29. Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yifan Shen, Yuanzhe Liu, Jingyuan Zhu, Xu Cao, Xiaofeng Zhang, Yixiao He, Wenming Ye, James Matthew Rehg, Ismini Lourentzou
- **URL**: <http://arxiv.org/abs/2506.21656v1>
- **Submitted**: 2025-06-26 18:00:00
- **Comment**: 29 pages
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on Vision-Language Models (VLMs) and spatial reasoning, which is not directly related to Information Retrieval, Search technologies, or query understanding. Although it involves optimization techniques, the context is different from the user's primary research interests.

#### Abstract
> Current Vision-Language Models (VLMs) struggle with fine-grained spatial
reasoning, particularly when multi-step logic and precise spatial alignment are
required. In this work, we introduce SpatialReasoner-R1, a vision-language
reasoning model designed to address these limitations. To construct
high-quality supervision for spatial reasoning, we design a Multi-Model Monte
Carlo Tree Search (M3CTS) method that generates diverse, logically consistent
Long Chain-of-Thought (LongCoT) reasoning trajectories. In addition, we propose
fine-grained Direct Preference Optimization (fDPO), which introduces
segment-specific preference granularity for descriptive grounding and logical
reasoning, guided by a spatial reward mechanism that evaluates candidate
responses based on visual consistency, spatial grounding, and logical
coherence. Experimental results demonstrate that fDPO achieves an average
improvement of 4.1% over standard DPO across spatial quality tasks, and a 9.0%
gain in spatial quantity tasks. SpatialReasoner-R1, trained with fDPO, sets a
new SoTA on SPATIALRGPT-Bench, outperforming the strongest baseline by 9.8% in
average accuracy, while maintaining competitive performance on general
vision-language tasks.

### 30. Sequential Diagnosis with Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Harsha Nori, Mayank Daswani, Christopher Kelly, Scott Lundberg, Marco Tulio Ribeiro, Marc Wilson, Xiaoxuan Liu, Viknesh Sounderajah, Jonathan Carlson, Matthew P Lungren, Bay Gross, Peter Hames, Mustafa Suleyman, Dominic King, Eric Horvitz
- **URL**: <http://arxiv.org/abs/2506.22405v1>
- **Submitted**: 2025-06-27 17:27:26
- **Comment**: 23 pages, 10 figures
- **Topic Keywords**: rag
- **Reason**: The paper focuses on sequential diagnosis with language models in the medical domain, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves language models, the application is specific to medical diagnosis and does not align with the user's interests in query understanding, ranking models, or user behavior modeling.

#### Abstract
> Artificial intelligence holds great promise for expanding access to expert
medical knowledge and reasoning. However, most evaluations of language models
rely on static vignettes and multiple-choice questions that fail to reflect the
complexity and nuance of evidence-based medicine in real-world settings. In
clinical practice, physicians iteratively formulate and revise diagnostic
hypotheses, adapting each subsequent question and test to what they've just
learned, and weigh the evolving evidence before committing to a final
diagnosis. To emulate this iterative process, we introduce the Sequential
Diagnosis Benchmark, which transforms 304 diagnostically challenging New
England Journal of Medicine clinicopathological conference (NEJM-CPC) cases
into stepwise diagnostic encounters. A physician or AI begins with a short case
abstract and must iteratively request additional details from a gatekeeper
model that reveals findings only when explicitly queried. Performance is
assessed not just by diagnostic accuracy but also by the cost of physician
visits and tests performed. We also present the MAI Diagnostic Orchestrator
(MAI-DxO), a model-agnostic orchestrator that simulates a panel of physicians,
proposes likely differential diagnoses and strategically selects high-value,
cost-effective tests. When paired with OpenAI's o3 model, MAI-DxO achieves 80%
diagnostic accuracy--four times higher than the 20% average of generalist
physicians. MAI-DxO also reduces diagnostic costs by 20% compared to
physicians, and 70% compared to off-the-shelf o3. When configured for maximum
accuracy, MAI-DxO achieves 85.5% accuracy. These performance gains with MAI-DxO
generalize across models from the OpenAI, Gemini, Claude, Grok, DeepSeek, and
Llama families. We highlight how AI systems, when guided to think iteratively
and act judiciously, can advance diagnostic precision and cost-effectiveness in
clinical care.

### 31. HyperCLOVA X THINK Technical Report

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: NAVER Cloud HyperCLOVA X Team
- **URL**: <http://arxiv.org/abs/2506.22403v1>
- **Submitted**: 2025-06-27 17:23:12
- **Comment**: 49 pages, 13 figures
- **Topic Keywords**: search, korea
- **Reason**: The paper focuses on large language models and their applications, but it does not seem to be directly related to information retrieval, search technologies, or query understanding. The topics of reinforcement learning and fine-tuning are not specific to the user's interests in IR and NLP.

#### Abstract
> We introduce HyperCLOVA X THINK, the first reasoning-focused large language
model in the HyperCLOVA X family, pre-trained on roughly $6$ trillion
high-quality Korean, and English tokens, augmented with targeted synthetic
Korean data. It was implemented as a compute-memory-balanced Peri-LN
Transformer scaled with $\mu$P, pre-trained through a three-stage curriculum
that expands the context window to $128$K tokens, and post-trained via
supervised fine-tuning with Reinforcement Learning from Verifiable Rewards
supports both detailed rationale and concise-answer modes. It delivers
competitive performance against similarly sized models on Korea-focused
benchmarks such as KMMLU, CSAT, KoBALT-700, HAERAE-1.0, and KoBigBench, while
preserving robust bilingual consistency and translation quality. In addition, a
vision-augmented variant matches or exceeds GPT-4.1 on the KCSAT STEM
benchmark, all of which are achieved with substantially lower training compute
than existing models of similar sizes. We also present a pruning and
distillation technique that will soon be applied to HyperCLOVA X THINK for an
open-source and business-friendly foundation model. Altogether, these
capabilities position HyperCLOVA X THINK as a robust foundation for Korean AI
innovation and a valuable resource for the global research community.

### 32. Probabilistic Optimality for Inference-time Scaling

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Youkang Wang, Jian Wang, Rubing Chen, Xiao-Yong Wei, Qing Li
- **URL**: <http://arxiv.org/abs/2506.22376v1>
- **Submitted**: 2025-06-27 16:44:11
- **Topic Keywords**: rag
- **Reason**: The paper focuses on inference-time scaling for Large Language Models, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on optimization and scaling, the context is different from the user's research interests.

#### Abstract
> Inference-time scaling has emerged as a powerful technique for enhancing the
reasoning performance of Large Language Models (LLMs). However, existing
approaches often rely on heuristic strategies for parallel sampling, lacking a
principled foundation. To address this gap, we propose a probabilistic
framework that formalizes the optimality of inference-time scaling under the
assumption that parallel samples are independently and identically distributed
(i.i.d.), and where the Best-of-N selection strategy follows a probability
distribution that can be estimated. Within this framework, we derive a
theoretical lower bound on the required number of samples to achieve a target
performance level, providing the first principled guidance for
compute-efficient scaling. Leveraging this insight, we develop
\textsc{OptScale}, a practical algorithm that dynamically determines the
optimal number of sampled responses. \textsc{OptScale} employs a language
model-based predictor to estimate probabilistic prior parameters, enabling the
decision of the minimal number of samples needed that satisfy predefined
performance thresholds and confidence levels. Extensive experiments on
mathematical reasoning benchmarks (including MATH-500, GSM8K, AIME, and AMC)
demonstrate that \textsc{OptScale} significantly reduces sampling overhead
while remaining better or on par with state-of-the-art reasoning performance.
Our work offers both a theoretical foundation and a practical solution for
principled inference-time scaling, addressing a critical gap in the efficient
deployment of LLMs for complex reasoning.

### 33. Detection of Personal Data in Structured Datasets Using a Large Language Model

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Albert Agisha Ntwali, Luca R√ºck, Martin Heckmann
- **URL**: <http://arxiv.org/abs/2506.22305v1>
- **Submitted**: 2025-06-27 15:16:43
- **Comment**: 10 pages
- **Topic Keywords**: rag
- **Reason**: The paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling. The focus is on detecting personal data in structured datasets using a Large Language Model, which is a topic in Natural Language Processing, but not in the user's primary areas of interest.

#### Abstract
> We propose a novel approach for detecting personal data in structured
datasets, leveraging GPT-4o, a state-of-the-art Large Language Model. A key
innovation of our method is the incorporation of contextual information: in
addition to a feature's name and values, we utilize information from other
feature names within the dataset as well as the dataset description. We compare
our approach to alternative methods, including Microsoft Presidio and CASSED,
evaluating them on multiple datasets: DeSSI, a large synthetic dataset,
datasets we collected from Kaggle and OpenML as well as MIMIC-Demo-Ext, a
real-world dataset containing patient information from critical care units.
  Our findings reveal that detection performance varies significantly depending
on the dataset used for evaluation. CASSED excels on DeSSI, the dataset on
which it was trained. Performance on the medical dataset MIMIC-Demo-Ext is
comparable across all models, with our GPT-4o-based approach clearly
outperforming the others. Notably, personal data detection in the Kaggle and
OpenML datasets appears to benefit from contextual information. This is
evidenced by the poor performance of CASSED and Presidio (both of which do not
utilize the context of the dataset) compared to the strong results of our
GPT-4o-based approach.
  We conclude that further progress in this field would greatly benefit from
the availability of more real-world datasets containing personal information.

### 34. COOCO -- Common Objects Out-of-Context -- Semantic Violation in Scenes: Investigating Multimodal Context in Referential Communication

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Filippo Merlo, Ece Takmaz, Wenkai Chen, Albert Gatt
- **URL**: <http://arxiv.org/abs/2506.22274v1>
- **Submitted**: 2025-06-27 14:44:45
- **Topic Keywords**: rag
- **Reason**: The paper focuses on Vision-Language Models (VLMs) and their ability to rely on scene contexts in object recognition, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on attention analysis, it does not explore ranking models or user behavior modeling, making it only loosely relevant to the user's research interests.

#### Abstract
> Natural scenes provide us with rich contexts for object recognition and
reference. In particular, knowing what type of scene one is looking at
generates expectations about which objects will occur, and what their spatial
configuration should be. Do Vision-Language Models (VLMs) learn to rely on
scene contexts in a similar way, when generating references to objects? To
address this question, we introduce the \textit{Common Objects Out-of-Context
(COOCO)} dataset and test to what extent VLMs rely on scene context to refer to
objects under different degrees of scene-object congruency, and different
perturbations. Our findings show that models leverage scene context adaptively,
depending on both the semantic relatedness between object and scene and the
level of noise. In particular, models rely more on context under high
target-scene congruence or when objects are degraded. Attention analysis
reveals that successful object categorisation involves increased focus on the
target in mid-level layers, especially under moderate noise, suggesting that
VLMs dynamically balance local and contextual information for reference
generation. We make our dataset, code and models available at
\href{https://github.com/cs-nlp-uu/scenereg}{https://github.com/cs-nlp-uu/scenereg}.

### 35. Fine-Tuning MIDI-to-Audio Alignment using a Neural Network on Piano Roll and CQT Representations

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sebastian Murgul, Moritz Reiser, Michael Heizmann, Christoph Seibert
- **URL**: <http://arxiv.org/abs/2506.22237v1>
- **Submitted**: 2025-06-27 13:59:50
- **Comment**: 9 pages, 3 figures, 6 tables
- **Topic Keywords**: ctr
- **Reason**: This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topic of MIDI-to-audio alignment is not related to query understanding, ranking models, or user behavior modeling, and the techniques used are not applicable to the user's areas of interest.

#### Abstract
> In this paper, we present a neural network approach for synchronizing audio
recordings of human piano performances with their corresponding loosely aligned
MIDI files. The task is addressed using a Convolutional Recurrent Neural
Network (CRNN) architecture, which effectively captures spectral and temporal
features by processing an unaligned piano roll and a spectrogram as inputs to
estimate the aligned piano roll. To train the network, we create a dataset of
piano pieces with augmented MIDI files that simulate common human timing
errors. The proposed model achieves up to 20% higher alignment accuracy than
the industry-standard Dynamic Time Warping (DTW) method across various
tolerance windows. Furthermore, integrating DTW with the CRNN yields additional
improvements, offering enhanced robustness and consistency. These findings
demonstrate the potential of neural networks in advancing state-of-the-art
MIDI-to-audio alignment.

### 36. The Missing Link: Joint Legal Citation Prediction using Heterogeneous Graph Enrichment

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Lorenz Wendlinger, Simon Alexander Nonn, Abdullah Al Zubaer, Michael Granitzer
- **URL**: <http://arxiv.org/abs/2506.22165v1>
- **Submitted**: 2025-06-27 12:21:41
- **Topic Keywords**: rag
- **Reason**: The paper focuses on legal citation prediction using graph neural networks, which is not directly related to information retrieval, search technologies, or query understanding. While it involves graph-based techniques, the application domain and problem statement are distinct from the user's research interests.

#### Abstract
> Legal systems heavily rely on cross-citations of legal norms as well as
previous court decisions. Practitioners, novices and legal AI systems need
access to these relevant data to inform appraisals and judgments. We propose a
Graph-Neural-Network (GNN) link prediction model that can identify Case-Law and
Case-Case citations with high proficiency through fusion of semantic and
topological information. We introduce adapted relational graph convolutions
operating on an extended and enriched version of the original citation graph
that allow the topological integration of semantic meta-information. This
further improves prediction by 3.1 points of average precision and by 8.5
points in data sparsity as well as showing robust performance over time and in
challenging fully inductive prediction. Jointly learning and predicting case
and norm citations achieves a large synergistic effect that improves case
citation prediction by up to 4.7 points, at almost doubled efficiency.

### 37. AutoMixer: Checkpoint Artifacts as Automatic Data Mixers

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ernie Chang, Yang Li, Patrick Huber, David Kant, Yangyang Shi, Vikas Chandra
- **URL**: <http://arxiv.org/abs/2506.21910v1>
- **Submitted**: 2025-06-27 04:53:07
- **Comment**: Accepted at ACL 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on language model training and checkpoint models, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. The abstract does not mention query understanding, ranking models, or user behavior modeling, and the concepts presented are not directly applicable to the user's areas of interest.

#### Abstract
> In language model training, it is desirable to equip models with capabilities
from various tasks. However, it is not clear how to directly obtain the right
data mixtures for these capabilities as the relationship between data and tasks
is difficult to be modeled. In this work, we observe that checkpoint models
exhibit emerging capabilities at different points in the training trajectory.
Often, the training process saves checkpoints as artifacts that are
under-utilized as a source of in-training data signals. We identify these
artifact models based on their respective capabilities on the benchmarks and
leverage them as data mixers by using their aggregated first-order influence
approximation over source data. We demonstrated on eight reasoning benchmarks
that the proposed framework shows significant improvements in the pretraining
setting, with performance improvements of up to 1.93%. Overall, this shows the
potential of checkpoint models to enhance data quality and optimize data
mixtures.

### 38. DeepTalk: Towards Seamless and Smart Speech Interaction with Adaptive Modality-Specific MoE

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Hang Shao, Heting Gao, Yunhang Shen, Jiawei Chen, Lijiang Li, Zuwei Long, Bo Tong, Ke Li, Xing Sun
- **URL**: <http://arxiv.org/abs/2506.21864v1>
- **Submitted**: 2025-06-27 02:32:04
- **Comment**: Under Review
- **Topic Keywords**: rag
- **Reason**: The paper focuses on speech interaction and multimodal language models, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions adaptive learning, it is not specifically applied to ranking models or user behavior modeling, and the context is different from e-commerce or real-time relevance optimization.

#### Abstract
> Native multimodal large language models (MLLMs) restructure a single large
language model (LLM) into a spoken language model (SLM) capable of both speech
and text generation. Compared to modular and aligned MLLMs, native MLLMs
preserve richer paralinguistic features such as emotion and prosody, and
generate speech responses directly within the backbone LLM rather than using a
separate speech decoder. This integration also results in lower response
latency and smoother interaction. However, native MLLMs suffer from
catastrophic forgetting and performance degradation because the available
paired speech-text data is insufficient to support the pretraining of MLLMs
compared to the vast amount of text data required to pretrain text LLMs. To
address this issue, we propose DeepTalk, a framework for adaptive modality
expert learning based on a Mixture of Experts (MoE) architecture. DeepTalk
first adaptively distinguishes modality experts according to their modality
load within the LLM. Each modality expert then undergoes specialized
single-modality training, followed by joint multimodal collaborative training.
As a result, DeepTalk incurs only a 5.5% performance drop compared to the
original LLM, which is significantly lower than the average performance drop of
over 20% typically seen in native MLLMs (such as GLM-4-Voice), and is on par
with modular MLLMs. Meanwhile, the end-to-end dialogue latency remains within
0.5 seconds, ensuring a seamless and intelligent speech interaction experience.
Code and models are released at https://github.com/talkking/DeepTalk.

### 39. Exploring the Structure of AI-Induced Language Change in Scientific English

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Riley Galpin, Bryce Anderson, Tom S. Juzek
- **URL**: <http://arxiv.org/abs/2506.21817v1>
- **Submitted**: 2025-06-26 23:44:24
- **Comment**: Accepted and published at FLAIRS 38. 8 pages, 4 figures, 1 table.
  Licensed under CC BY-NC-SA 4.0
- **Topic Keywords**: rag
- **Reason**: The paper explores the structure of AI-induced language change in scientific English, focusing on the frequency and semantic shifts of words. While it touches on the influence of Large Language Models, it does not directly relate to information retrieval, search technologies, or query understanding, which are the user's primary research interests.

#### Abstract
> Scientific English has undergone rapid and unprecedented changes in recent
years, with words such as "delve," "intricate," and "crucial" showing
significant spikes in frequency since around 2022. These changes are widely
attributed to the growing influence of Large Language Models like ChatGPT in
the discourse surrounding bias and misalignment. However, apart from changes in
frequency, the exact structure of these linguistic shifts has remained unclear.
The present study addresses this and investigates whether these changes involve
the replacement of synonyms by suddenly 'spiking words,' for example, "crucial"
replacing "essential" and "key," or whether they reflect broader semantic and
pragmatic qualifications. To further investigate structural changes, we include
part of speech tagging in our analysis to quantify linguistic shifts over
grammatical categories and differentiate between word forms, like "potential"
as a noun vs. as an adjective. We systematically analyze synonym groups for
widely discussed 'spiking words' based on frequency trends in scientific
abstracts from PubMed. We find that entire semantic clusters often shift
together, with most or all words in a group increasing in usage. This pattern
suggests that changes induced by Large Language Models are primarily semantic
and pragmatic rather than purely lexical. Notably, the adjective "important"
shows a significant decline, which prompted us to systematically analyze
decreasing lexical items. Our analysis of "collapsing" words reveals a more
complex picture, which is consistent with organic language change and contrasts
with the patterns of the abrupt spikes. These insights into the structure of
language change contribute to our understanding of how language technology
continues to shape human language.

### 40. Can Peter Pan Survive MT? A Stylometric Study of LLMs, NMTs, and HTs in Children's Literature Translation

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Delu Kong, Lieve Macken
- **URL**: <http://arxiv.org/abs/2506.22038v1>
- **Submitted**: 2025-06-27 09:34:40
- **Comment**: 19 pages, 8 figures, 4 tables. Accepted in 2nd Workshop on
  Creative-text Translation and Technology Co-located with MT Summit 2025.
  Official paper may later be accessed from ACL Anthology
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on machine translation, stylometry, and children's literature translation, which are not directly related to your areas of interest.

#### Abstract
> This study focuses on evaluating the performance of machine translations
(MTs) compared to human translations (HTs) in English-to-Chinese children's
literature translation (CLT) from a stylometric perspective. The research
constructs a Peter Pan corpus, comprising 21 translations: 7 human translations
(HTs), 7 large language model translations (LLMs), and 7 neural machine
translation outputs (NMTs). The analysis employs a generic feature set
(including lexical, syntactic, readability, and n-gram features) and a creative
text translation (CTT-specific) feature set, which captures repetition, rhythm,
translatability, and miscellaneous levels, yielding 447 linguistic features in
total.
  Using classification and clustering techniques in machine learning, we
conduct a stylometric analysis of these translations. Results reveal that in
generic features, HTs and MTs exhibit significant differences in conjunction
word distributions and the ratio of 1-word-gram-YiYang, while NMTs and LLMs
show significant variation in descriptive words usage and adverb ratios.
Regarding CTT-specific features, LLMs outperform NMTs in distribution, aligning
more closely with HTs in stylistic characteristics, demonstrating the potential
of LLMs in CLT.

### 41. Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Kartheek Kumar Reddy Nareddy, Sarah Ternus, Julia Niebling
- **URL**: <http://arxiv.org/abs/2506.21990v1>
- **Submitted**: 2025-06-27 07:57:13
- **Comment**: Computer Vision and Pattern Recognition (CVPR) 2025 Workshops
- **Topic Keywords**: rank
- **Reason**: The paper focuses on speech transcription in a niche domain (cockpit conversations) using pre-trained Whisper models, which is not directly related to information retrieval, search technologies, or query understanding. Although it mentions fine-tuning and adaptation, the context is specific to speech recognition and not relevant to the user's primary research interests.

#### Abstract
> The developments in transformer encoder-decoder architectures have led to
significant breakthroughs in machine translation, Automatic Speech Recognition
(ASR), and instruction-based chat machines, among other applications. The
pre-trained models were trained on vast amounts of generic data over a few
epochs (fewer than five in most cases), resulting in their strong
generalization capabilities. Nevertheless, the performance of these models does
suffer when applied to niche domains like transcribing pilot speech in the
cockpit, which involves a lot of specific vocabulary and multilingual
conversations. This paper investigates and improves the transcription accuracy
of cockpit conversations with Whisper models. We have collected around 85
minutes of cockpit simulator recordings and 130 minutes of interview recordings
with pilots and manually labeled them. The speakers are middle aged men
speaking both German and English. To improve the accuracy of transcriptions, we
propose multiple normalization schemes to refine the transcripts and improve
Word Error Rate (WER). We then employ fine-tuning to enhance ASR performance,
utilizing performance-efficient fine-tuning with Low-Rank Adaptation (LoRA).
Hereby, WER decreased from 68.49 \% (pretrained whisper Large model without
normalization baseline) to 26.26\% (finetuned whisper Large model with the
proposed normalization scheme).

### 42. More Vulnerable than You Think: On the Stability of Tool-Integrated LLM Agents

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Weimin Xiong, Ke Wang, Yifan Song, Hanchao Liu, Sai Zhou, Wei Peng, Sujian Li
- **URL**: <http://arxiv.org/abs/2506.21967v1>
- **Submitted**: 2025-06-27 07:13:29
- **Topic Keywords**: search
- **Reason**: The paper focuses on the stability of tool-integrated LLM agents, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on model-based aspects, the context is not relevant to the user's primary research interests.

#### Abstract
> Current evaluations of tool-integrated LLM agents typically focus on
end-to-end tool-usage evaluation while neglecting their stability. This limits
their real-world applicability, as various internal or external factors can
cause agents to crash or behave abnormally. Our research addresses this by
investigating whether agents are vulnerable to errors throughout the entire
tool invocation process, including reading tool documentation, selecting tools
and generating parameters, and processing the tool's response. Through
extensive experiments, we observe that agents are highly susceptible to errors
at each stage and agents based on open-source models are more vulnerable than
those based on proprietary models. We also find that increasing the model size
does not significantly improve tool invocation reasoning and may make agents
more vulnerable to attacks resembling normal user instructions. This highlights
the importance of evaluating agent stability and offers valuable insights for
future LLM development and evaluation.

### 43. PapersPlease: A Benchmark for Evaluating Motivational Values of Large Language Models Based on ERG Theory

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Junho Myung, Yeon Su Park, Sunwoo Kim, Shin Yoo, Alice Oh
- **URL**: <http://arxiv.org/abs/2506.21961v1>
- **Submitted**: 2025-06-27 07:09:11
- **Comment**: Accepted to GEM2 Workshop: Generation, Evaluation & Metrics - ACL
  2025
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on evaluating the motivational values of large language models based on ERG theory, which is outside your areas of interest.

#### Abstract
> Evaluating the performance and biases of large language models (LLMs) through
role-playing scenarios is becoming increasingly common, as LLMs often exhibit
biased behaviors in these contexts. Building on this line of research, we
introduce PapersPlease, a benchmark consisting of 3,700 moral dilemmas designed
to investigate LLMs' decision-making in prioritizing various levels of human
needs. In our setup, LLMs act as immigration inspectors deciding whether to
approve or deny entry based on the short narratives of people. These narratives
are constructed using the Existence, Relatedness, and Growth (ERG) theory,
which categorizes human needs into three hierarchical levels. Our analysis of
six LLMs reveals statistically significant patterns in decision-making,
suggesting that LLMs encode implicit preferences. Additionally, our evaluation
of the impact of incorporating social identities into the narratives shows
varying responsiveness based on both motivational needs and identity cues, with
some models exhibiting higher denial rates for marginalized identities. All
data is publicly available at https://github.com/yeonsuuuu28/papers-please.

### 44. 3Description: An Intuitive Human-AI Collaborative 3D Modeling Approach

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Zhuodi Cai
- **URL**: <http://arxiv.org/abs/2506.21845v1>
- **Submitted**: 2025-06-27 01:33:46
- **Comment**: 5 pages, 2 figures, 3 tables (containing 21 subfigures)
- **Topic Keywords**: search
- **Reason**: The paper focuses on human-AI collaborative 3D modeling, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it mentions AI technologies like NLP and Computer Vision, the application is in a different domain and does not align with the user's primary focus on IR and real-time relevance optimization.

#### Abstract
> This paper presents 3Description, an experimental human-AI collaborative
approach for intuitive 3D modeling. 3Description aims to address accessibility
and usability challenges in traditional 3D modeling by enabling
non-professional individuals to co-create 3D models using verbal and gesture
descriptions. Through a combination of qualitative research, product analysis,
and user testing, 3Description integrates AI technologies such as Natural
Language Processing and Computer Vision, powered by OpenAI and MediaPipe.
Recognizing the web has wide cross-platform capabilities, 3Description is
web-based, allowing users to describe the desired model and subsequently adjust
its components using verbal and gestural inputs. In the era of AI and emerging
media, 3Description not only contributes to a more inclusive and user-friendly
design process, empowering more people to participate in the construction of
the future 3D world, but also strives to increase human engagement in
co-creation with AI, thereby avoiding undue surrender to technology and
preserving human creativity.

### 45. A suite of allotaxonometric tools for the comparison of complex systems using rank-turbulence divergence

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jonathan St-Onge, Ashley M. A. Fehr, Carter Ward, Calla G. Beauregard, Michael V. Arnold, Samuel F. Rosenblatt, Benjamin Cooley, Christopher M. Danforth, Peter Sheridan Dodds
- **URL**: <http://arxiv.org/abs/2506.21808v1>
- **Submitted**: 2025-06-26 23:17:29
- **Comment**: 4 pages, 2 figures
- **Topic Keywords**: rank
- **Reason**: The paper appears to be unrelated to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The focus on complex systems, heavy-tailed distributions, and divergences is outside the scope of the user's expertise and interests.

#### Abstract
> Describing and comparing complex systems requires principled, theoretically
grounded tools. Built around the phenomenon of type turbulence,
allotaxonographs provide map-and-list visual comparisons of pairs of
heavy-tailed distributions. Allotaxonographs are designed to accommodate a wide
range of instruments including rank- and probability-turbulence divergences,
Jenson-Shannon divergence, and generalized entropy divergences. Here, we
describe a suite of programmatic tools for rendering allotaxonographs for
rank-turbulence divergence in Matlab, Javascript, and Python, all of which have
different use cases.

### 46. Identifying Speaker Information in Feed-Forward Layers of Self-Supervised Speech Transformers

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Tzu-Quan Lin, Hsi-Chun Cheng, Hung-yi Lee, Hao Tang
- **URL**: <http://arxiv.org/abs/2506.21712v1>
- **Submitted**: 2025-06-26 18:54:26
- **Topic Keywords**: search
- **Reason**: The paper focuses on speaker information in self-supervised speech Transformers, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's topic is more aligned with speech recognition and speaker recognition, which is not a primary focus of the user's research.

#### Abstract
> In recent years, the impact of self-supervised speech Transformers has
extended to speaker-related applications. However, little research has explored
how these models encode speaker information. In this work, we address this gap
by identifying neurons in the feed-forward layers that are correlated with
speaker information. Specifically, we analyze neurons associated with k-means
clusters of self-supervised features and i-vectors. Our analysis reveals that
these clusters correspond to broad phonetic and gender classes, making them
suitable for identifying neurons that represent speakers. By protecting these
neurons during pruning, we can significantly preserve performance on
speaker-related task, demonstrating their crucial role in encoding speaker
information.

---

