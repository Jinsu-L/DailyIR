# Daily Papers Report - 2025-07-22

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. SPAR: Scholar Paper Retrieval with LLM-based Agents for Enhanced Academic Search

- **LLM Score**: 7
- **Keyword Score**: 9
- **Authors**: Xiaofeng Shi, Yuduo Li, Qian Kou, Longbin Yu, Jinxin Xie, Hua Zhou
- **URL**: <http://arxiv.org/abs/2507.15245v1>
- **Submitted**: 2025-07-21 05:06:53
- **Topic Keywords**: query, relevance, retrieval, search
- **Reason**: The paper focuses on academic literature retrieval, which is related to information retrieval, and uses large language models, which is a relevant area of research in NLP. The query decomposition and evolution approach is also relevant to query understanding and ranking models. However, the paper's focus on academic search and scholarly retrieval is somewhat specific and may not directly apply to the e-commerce domain.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Academic Paper Retrieval
- **Aim**: Introduce SPAR, a novel multi-agent framework for academic paper retrieval that simulates how researchers follow references from one paper to another
- **Rationale**: Tackle challenges such as underspecified queries, fragmented sources, and evolving information needs in academic search
- **Ground**: Construct SPARBench, a challenging benchmark with expert-annotated relevance labels, to facilitate systematic evaluation
- **Experiment**: Evaluate SPAR on various benchmarks, including AutoScholar and SPARBench, and demonstrate its superior performance compared to strong baselines
- **Takeaway**: SPAR provides a scalable, interpretable, and high-performing foundation for advancing research in scholarly retrieval, with potential applications in vaccine development research and beyond

#### Abstract
> Recent advances in large language models (LLMs) have opened new opportunities
for academic literature retrieval. However, existing systems often rely on
rigid pipelines and exhibit limited reasoning capabilities. We introduce SPAR,
a multi-agent framework that incorporates RefChain-based query decomposition
and query evolution to enable more flexible and effective search. To facilitate
systematic evaluation, we also construct SPARBench, a challenging benchmark
with expert-annotated relevance labels. Experimental results demonstrate that
SPAR substantially outperforms strong baselines, achieving up to +56% F1 on
AutoScholar and +23% F1 on SPARBench over the best-performing baseline.
Together, SPAR and SPARBench provide a scalable, interpretable, and
high-performing foundation for advancing research in scholarly retrieval. Code
and data will be available at: https://github.com/xiaofengShi/SPAR

---

### 2. Just Ask for Music (JAM): Multimodal and Personalized Natural Language Music Recommendation

- **LLM Score**: 6
- **Keyword Score**: 9
- **Authors**: Alessandro B. Melchiorre, Elena V. Epure, Shahed Masoudian, Gustavo Escobedo, Anna Hausberger, Manuel Moussallam, Markus Schedl
- **URL**: <http://arxiv.org/abs/2507.15826v1>
- **Submitted**: 2025-07-21 17:36:03
- **Topic Keywords**: query, queries, retrieval, recommend
- **Reason**: The paper presents a natural language music recommendation system, which is related to information retrieval and search technologies. While it does not directly focus on query understanding, ranking models, or user behavior modeling, it explores multimodal and personalized recommendations, which is somewhat relevant to the user's interests in NLP and data mining.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Natural Language Music Recommendation
- **Aim**: To develop a novel framework for natural language music recommendation that addresses the limitations of Large Language Models (LLMs) and retrieval-based approaches
- **Rationale**: The JAM framework models user-query-item interactions as vector translations in a shared latent space, inspired by knowledge graph embedding methods like TransE, to capture the complexity of music and user intent
- **Ground**: The JAMSessions dataset, a new dataset of over 100k user-query-item triples with anonymized user/item embeddings, combining conversational queries and user long-term preferences
- **Experiment**: The authors evaluate several models, including baselines and their own proposed model, JAM, for recommending items to users, and compare different multimodal aggregation strategies within JAM
- **Takeaway**: The JAM framework provides a lightweight and intuitive approach to music recommendation, addressing the limitations of existing solutions and providing accurate recommendations, intuitive representations, and easy integration with existing music recommendation stacks

#### Abstract
> Natural language interfaces offer a compelling approach for music
recommendation, enabling users to express complex preferences conversationally.
While Large Language Models (LLMs) show promise in this direction, their
scalability in recommender systems is limited by high costs and latency.
Retrieval-based approaches using smaller language models mitigate these issues
but often rely on single-modal item representations, overlook long-term user
preferences, and require full model retraining, posing challenges for
real-world deployment. In this paper, we present JAM (Just Ask for Music), a
lightweight and intuitive framework for natural language music recommendation.
JAM models user-query-item interactions as vector translations in a shared
latent space, inspired by knowledge graph embedding methods like TransE. To
capture the complexity of music and user intent, JAM aggregates multimodal item
features via cross-attention and sparse mixture-of-experts. We also introduce
JAMSessions, a new dataset of over 100k user-query-item triples with anonymized
user/item embeddings, uniquely combining conversational queries and user
long-term preferences. Our results show that JAM provides accurate
recommendations, produces intuitive representations suitable for practical use
cases, and can be easily integrated with existing music recommendation stacks.

---

### 3. Click A, Buy B: Rethinking Conversion Attribution in E- Commerce Recommendations

- **LLM Score**: 6
- **Keyword Score**: 7
- **Authors**: Xiangyu Zeng, Amit Jaspal, Bin Liu, Goutham Panneeru, Kevin Huang, Nicolas Bievre, Mohit Jaggi, Prathap Maniraju, Ankur Jain
- **URL**: <http://arxiv.org/abs/2507.15113v1>
- **Submitted**: 2025-07-20 20:25:20
- **Topic Keywords**: click, conversion rate, recommend, commerce, e-commerce
- **Reason**: The paper focuses on rethinking conversion attribution in e-commerce recommendations, which is related to my interests in Information Retrieval and Search technologies. However, the specific problem of Click A, Buy B phenomenon is more relevant to recommender systems and e-commerce domain, which is not my primary focus. The paper's approach to solving this problem using taxonomy-aware collaborative filtering is interesting, but it does not directly align with my interests in query understanding, ranking models, and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Addressing the 'Click A, Buy B' phenomenon in e-commerce recommendations
- **Aim**: Improve conversion prediction by reframing it as a multi-task problem and leveraging similarity between products
- **Rationale**: Traditional methods assume a one-to-one relationship between clicked items and purchases, leading to biased learning and suboptimal conversion rates
- **Ground**: Product taxonomy and co-engagement logs are used to map products to leaf nodes and learn a category-to-category similarity matrix
- **Experiment**: The proposed approach is evaluated on an internal e-commerce dataset, reporting a 13.9% reduction in normalized entropy and a +0.25% gain in the primary business metric
- **Takeaway**: The novel approach improves conversion prediction by isolating informative conversions and correcting attribution bias, but requires careful calibration and is dependent on the quality of the underlying product taxonomy

#### Abstract
> User journeys in e-commerce routinely violate the one-to-one assumption that
a clicked item on an advertising platform is the same item later purchased on
the merchant's website/app. For a significant number of converting sessions on
our platform, users click product A but buy product B -- the Click A, Buy B
(CABB) phenomenon. Training recommendation models on raw click-conversion pairs
therefore rewards items that merely correlate with purchases, leading to biased
learning and sub-optimal conversion rates. We reframe conversion prediction as
a multi-task problem with separate heads for Click A Buy A (CABA) and Click A
Buy B (CABB). To isolate informative CABB conversions from unrelated CABB
conversions, we introduce a taxonomy-aware collaborative filtering weighting
scheme where each product is first mapped to a leaf node in a product taxonomy,
and a category-to-category similarity matrix is learned from large-scale
co-engagement logs. This weighting amplifies pairs that reflect genuine
substitutable or complementary relations while down-weighting coincidental
cross-category purchases. Offline evaluation on e-commerce sessions reduces
normalized entropy by 13.9% versus a last-click attribution baseline. An online
A/B test on live traffic shows +0.25% gains in the primary business metric.

---

### 4. Interaction as Intelligence: Deep Research With Human-AI Partnership

- **LLM Score**: 6
- **Keyword Score**: 6
- **Authors**: Lyumanshan Ye, Xiaojie Cai, Xinkai Wang, Junfei Wang, Xiangkun Hu, Jiadi Su, Yang Nan, Sihan Wang, Bohan Zhang, Xiaoze Fan, Jinbin Luo, Yuxiang Zheng, Tianze Xu, Dayuan Fu, Yunze Wu, Pengrui Lu, Zengzhi Wang, Yiwei Qin, Zhen Huang, Yan Ma, Zhulin Hu, Haoyang Zou, Tiantian Mi, Yixin Ye, Ethan Chern, Pengfei Liu
- **URL**: <http://arxiv.org/abs/2507.15759v1>
- **Submitted**: 2025-07-21 16:15:18
- **Comment**: 30 pages, 10 figures
- **Topic Keywords**: queries, user behavior, search
- **Reason**: The paper explores the concept of 'Interaction as Intelligence' in deep research tasks, introducing a new paradigm for human-AI collaboration. While it touches on some aspects of information retrieval, such as query refinement and fine-grained dialogue, the focus is more on the human-AI interaction and cognitive oversight rather than traditional IR topics like query understanding and ranking models. The paper's relevance to the user's interests is somewhat limited, but it may still be of interest due to its overlap with NLP and data mining.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Interaction as Intelligence in AI Systems
- **Aim**: To reconsider the relationship between humans and AI systems in deep research tasks
- **Rationale**: Interaction is a fundamental dimension of intelligence, and AI systems should engage in extended thinking processes with human oversight
- **Ground**: Traditional 'input-wait-output' paradigm is limited, and AI systems should be designed to facilitate human-AI collaboration
- **Experiment**: Deep Cognition system with transparent, controllable, and interruptible interaction, fine-grained bidirectional dialogue, and a shared cognitive context
- **Takeaway**: Cognitive oversight paradigm outperforms baseline across six key metrics, with improvements of 31.8% to 50.0% over deep research systems

#### Abstract
> This paper introduces "Interaction as Intelligence" research series,
presenting a reconceptualization of human-AI relationships in deep research
tasks. Traditional approaches treat interaction merely as an interface for
accessing AI capabilities-a conduit between human intent and machine output. We
propose that interaction itself constitutes a fundamental dimension of
intelligence. As AI systems engage in extended thinking processes for research
tasks, meaningful interaction transitions from an optional enhancement to an
essential component of effective intelligence. Current deep research systems
adopt an "input-wait-output" paradigm where users initiate queries and receive
results after black-box processing. This approach leads to error cascade
effects, inflexible research boundaries that prevent question refinement during
investigation, and missed opportunities for expertise integration. To address
these limitations, we introduce Deep Cognition, a system that transforms the
human role from giving instructions to cognitive oversight-a mode of engagement
where humans guide AI thinking processes through strategic intervention at
critical junctures. Deep cognition implements three key innovations:
(1)Transparent, controllable, and interruptible interaction that reveals AI
reasoning and enables intervention at any point; (2)Fine-grained bidirectional
dialogue; and (3)Shared cognitive context where the system observes and adapts
to user behaviors without explicit instruction. User evaluation demonstrates
that this cognitive oversight paradigm outperforms the strongest baseline
across six key metrics: Transparency(+20.0%), Fine-Grained Interaction(+29.2%),
Real-Time Intervention(+18.5%), Ease of Collaboration(+27.7%),
Results-Worth-Effort(+8.8%), and Interruptibility(+20.7%). Evaluations on
challenging research problems show 31.8% to 50.0% points of improvements over
deep research systems.

---

### 5. GREAT: Guiding Query Generation with a Trie for Recommending Related Search about Video at Kuaishou

- **LLM Score**: 4
- **Keyword Score**: 15
- **Authors**: Ninglu Shao, Jinshan Wang, Chenxu Wang, Qingbiao Li, Xiaoxue Zang, Han Li
- **URL**: <http://arxiv.org/abs/2507.15267v1>
- **Submitted**: 2025-07-21 06:10:30
- **Topic Keywords**: query, queries, relevance, click, click-through rate, recommend, search
- **Reason**: The paper focuses on query recommendation in video-related search, which is a specific application of information retrieval. While it employs a novel framework, GREAT, the paper's primary concern is not query understanding, ranking models, or user behavior modeling, which are core aspects of your research interests. The paper's relevance is somewhat related, but not a central match.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Query Recommendation in Video-Related Search
- **Aim**: To improve user experience on short video platforms by recommending relevant queries related to the current video
- **Rationale**: Traditional user behavior chain is too long and inaccurate, and existing methods fail to consider multiple objectives in I2Q recommendation
- **Ground**: The authors release a large-scale and real-world dataset, KuaiRS, and propose the GREAT framework, which utilizes Large Language Models to address the challenges in I2Q recommendation
- **Experiment**: Extensive offline experiments and online industrial scenario at Kuaishou demonstrate the effectiveness of GREAT in terms of effectiveness, relevance, and literal quality
- **Takeaway**: GREAT outperforms various baselines, and its performance improves over time, with contributions including a systematic discussion of I2Q recommendation, the release of KuaiRS dataset, and the proposal of the GREAT framework

#### Abstract
> Currently, short video platforms have become the primary place for
individuals to share experiences and obtain information. To better meet users'
needs for acquiring information while browsing short videos, some apps have
introduced a search entry at the bottom of videos, accompanied with recommended
relevant queries. This scenario is known as query recommendation in
video-related search, where core task is item-to-query (I2Q) recommendation. As
this scenario has only emerged in recent years, there is a notable scarcity of
academic research and publicly available datasets in this domain. To address
this gap, we systematically examine the challenges associated with this
scenario for the first time. Subsequently, we release a large-scale dataset
derived from real-world data pertaining to the query recommendation in
video-\textit{\textbf{r}}elated \textit{\textbf{s}}earch on the
\textit{\textbf{Kuai}}shou app (\textbf{KuaiRS}). Presently, existing methods
rely on embeddings to calculate similarity for matching short videos with
queries, lacking deep interaction between the semantic content and the query.
In this paper, we introduce a novel LLM-based framework named \textbf{GREAT},
which \textit{\textbf{g}}uides que\textit{\textbf{r}}y
g\textit{\textbf{e}}ner\textit{\textbf{a}}tion with a \textit{\textbf{t}}rie to
address I2Q recommendation in related search. Specifically, we initially gather
high-quality queries with high exposure and click-through rate to construct a
query-based trie. During training, we enhance the LLM's capability to generate
high-quality queries using the query-based trie. In the inference phase, the
query-based trie serves as a guide for the token generation. Finally, we
further refine the relevance and literal quality between items and queries via
a post-processing module. Extensive offline and online experiments demonstrate
the effectiveness of our proposed method.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. RankMixer: Scaling Up Ranking Models in Industrial Recommenders

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Jie Zhu, Zhifang Fan, Xiaoxie Zhu, Yuchen Jiang, Hangyu Wang, Xintian Han, Haoran Ding, Xinmin Wang, Wenlin Zhao, Zhen Gong, Huizhi Yang, Zheng Chai, Zhe Chen, Yuchao Zheng, Qiwei Chen, Feng Zhang, Xun Zhou, Peng Xu, Xiao Yang, Di Wu, Zuotao Liu
- **URL**: <http://arxiv.org/abs/2507.15551v1>
- **Submitted**: 2025-07-21 12:28:55
- **Topic Keywords**: ranking, recommend, rank, search, acl
- **Reason**: The paper focuses on scaling up ranking models for industrial recommenders, which is related to search technologies and query understanding. However, the emphasis on recommender systems and hardware-aware model design is not directly aligned with the user's primary focus on information retrieval, especially in areas that require deep semantic understanding and real-time relevance optimization.

#### Abstract
> Recent progress on large language models (LLMs) has spurred interest in
scaling up recommendation systems, yet two practical obstacles remain. First,
training and serving cost on industrial Recommenders must respect strict
latency bounds and high QPS demands. Second, most human-designed
feature-crossing modules in ranking models were inherited from the CPU era and
fail to exploit modern GPUs, resulting in low Model Flops Utilization (MFU) and
poor scalability. We introduce RankMixer, a hardware-aware model design
tailored towards a unified and scalable feature-interaction architecture.
RankMixer retains the transformer's high parallelism while replacing quadratic
self-attention with multi-head token mixing module for higher efficiency.
Besides, RankMixer maintains both the modeling for distinct feature subspaces
and cross-feature-space interactions with Per-token FFNs. We further extend it
to one billion parameters with a Sparse-MoE variant for higher ROI. A dynamic
routing strategy is adapted to address the inadequacy and imbalance of experts
training. Experiments show RankMixer's superior scaling abilities on a
trillion-scale production dataset. By replacing previously diverse handcrafted
low-MFU modules with RankMixer, we boost the model MFU from 4.5% to 45%, and
scale our ranking model parameters by 100x while maintaining roughly the same
inference latency. We verify RankMixer's universality with online A/B tests
across three core application scenarios (Recommendation, Advertisement and
Search). Finally, we launch 1B Dense-Parameters RankMixer for full traffic
serving without increasing the serving cost, which improves user active days by
0.2% and total in-app usage duration by 0.5%.

### 7. Hierarchical Graph Information Bottleneck for Multi-Behavior Recommendation

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Hengyu Zhang, Chunxu Shen, Xiangguo Sun, Jie Tan, Yanchao Tan, Yu Rong, Hong Cheng, Lingling Yi
- **URL**: <http://arxiv.org/abs/2507.15395v1>
- **Submitted**: 2025-07-21 08:53:49
- **Comment**: Accepted by RecSys2025
- **Topic Keywords**: rag, user behavior, recommend
- **Reason**: The paper focuses on multi-behavior recommendation, which is not directly related to information retrieval or search technologies. While it employs graph-based methods, the primary goal is recommendation rather than query understanding or ranking models. The paper's relevance is limited to the e-commerce domain, which is a secondary interest of the user.

#### Abstract
> In real-world recommendation scenarios, users typically engage with platforms
through multiple types of behavioral interactions. Multi-behavior
recommendation algorithms aim to leverage various auxiliary user behaviors to
enhance prediction for target behaviors of primary interest (e.g., buy),
thereby overcoming performance limitations caused by data sparsity in target
behavior records. Current state-of-the-art approaches typically employ
hierarchical design following either cascading (e.g.,
view$\rightarrow$cart$\rightarrow$buy) or parallel
(unified$\rightarrow$behavior$\rightarrow$specific components) paradigms, to
capture behavioral relationships. However, these methods still face two
critical challenges: (1) severe distribution disparities across behaviors, and
(2) negative transfer effects caused by noise in auxiliary behaviors. In this
paper, we propose a novel model-agnostic Hierarchical Graph Information
Bottleneck (HGIB) framework for multi-behavior recommendation to effectively
address these challenges. Following information bottleneck principles, our
framework optimizes the learning of compact yet sufficient representations that
preserve essential information for target behavior prediction while eliminating
task-irrelevant redundancies. To further mitigate interaction noise, we
introduce a Graph Refinement Encoder (GRE) that dynamically prunes redundant
edges through learnable edge dropout mechanisms. We conduct comprehensive
experiments on three real-world public datasets, which demonstrate the superior
effectiveness of our framework. Beyond these widely used datasets in the
academic community, we further expand our evaluation on several real industrial
scenarios and conduct an online A/B testing, showing again a significant
improvement in multi-behavior recommendations. The source code of our proposed
HGIB is available at https://github.com/zhy99426/HGIB.

### 8. GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Fei Tang, Zhangxuan Gu, Zhengxi Lu, Xuyang Liu, Shuheng Shen, Changhua Meng, Wen Wang, Wenqi Zhang, Yongliang Shen, Weiming Lu, Jun Xiao, Yueting Zhuang
- **URL**: <http://arxiv.org/abs/2507.15846v2>
- **Submitted**: 2025-07-21 17:53:42
- **Topic Keywords**: rag, click
- **Reason**: The paper focuses on GUI grounding, a topic that is not directly related to information retrieval or search technologies. While it uses reinforcement learning, which is a related area, the specific application and techniques used are not aligned with the user's interests in query understanding, ranking models, or user behavior modeling.

#### Abstract
> Graphical User Interface (GUI) grounding maps natural language instructions
to precise interface locations for autonomous interaction. Current
reinforcement learning approaches use binary rewards that treat elements as
hit-or-miss targets, creating sparse signals that ignore the continuous nature
of spatial interactions. Motivated by human clicking behavior that naturally
forms Gaussian distributions centered on target elements, we introduce GUI
Gaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that
models GUI elements as continuous Gaussian distributions across the interface
plane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point
rewards model precise localization through exponentially decaying distributions
centered on element centroids, while coverage rewards assess spatial alignment
by measuring the overlap between predicted Gaussian distributions and target
regions. To handle diverse element scales, we develop an adaptive variance
mechanism that calibrates reward distributions based on element dimensions.
This framework transforms GUI grounding from sparse binary classification to
dense continuous optimization, where Gaussian distributions generate rich
gradient signals that guide models toward optimal interaction positions.
Extensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro
benchmarks demonstrate that GUI-G$^2$, substantially outperforms
state-of-the-art method UI-TARS-72B, with the most significant improvement of
24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides
superior robustness to interface variations and enhanced generalization to
unseen layouts, establishing a new paradigm for spatial reasoning in GUI
interaction tasks.

### 9. Learning to Extract Rational Evidence via Reinforcement Learning for Retrieval-Augmented Generation

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Xinping Zhao, Shouzheng Huang, Yan Zhong, Xinshuo Hu, Baotian Hu, Min Zhang
- **URL**: <http://arxiv.org/abs/2507.15586v1>
- **Submitted**: 2025-07-21 13:03:55
- **Comment**: 16 pages, 7 Figures, 10 Tables
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on Retrieval-Augmented Generation (RAG) and proposes a method to extract rational evidence, which is related to query understanding and ranking models. However, the paper does not directly address user behavior modeling or click models, and its primary focus is on language models and generation, which is not a central match for your research interests.

#### Abstract
> Retrieval-Augmented Generation (RAG) effectively improves the accuracy of
Large Language Models (LLMs). However, retrieval noises significantly impact
the quality of LLMs' generation, necessitating the development of denoising
mechanisms. Previous methods extract evidence straightforwardly without
explicit thinking, which risks filtering out key clues and struggles with
generalization. To this end, we propose LEAR, which learns to extract rational
evidence by (1) explicitly reasoning to identify potential cues within
retrieval contents first, and then (2) consciously extracting to avoid omitting
any key cues helpful for answering questions. Specifically, we frame evidence
reasoning and evidence extraction into one unified response for end-to-end
training; apply knowledge token masks for disentanglement to derive
reasoning-based and extraction-based answers; and devise three types of
verifiable reward functions, including answer, length, and format, to update
the model via the policy optimization algorithm. Extensive experiments on three
benchmark datasets show the effectiveness of LEAR, providing compact and
high-quality evidence, improving the accuracy of downstream tasks, and
promoting effective application in online RAG systems.

### 10. A Novel Self-Evolution Framework for Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Haoran Sun, Zekun Zhang, Shaoning Zeng
- **URL**: <http://arxiv.org/abs/2507.15281v1>
- **Submitted**: 2025-07-21 06:30:39
- **Topic Keywords**: retrieval, search
- **Reason**: The paper proposes a novel framework for optimizing Large Language Models, focusing on user preference adaptation and domain-specific competence. While it touches on NLP and language models, the primary focus is on post-training optimization and self-evolution, which is not directly related to information retrieval, query understanding, or ranking models. The paper's relevance to the user's interests is limited.

#### Abstract
> The capabilities of Large Language Models (LLMs) are limited to some extent
by pre-training, so some researchers optimize LLMs through post-training.
Existing post-training strategies, such as memory-based retrieval or preference
optimization, improve user alignment yet fail to enhance the model's domain
cognition. To bridge this gap, we propose a novel Dual-Phase Self-Evolution
(DPSE) framework that jointly optimizes user preference adaptation and
domain-specific competence. DPSE introduces a Censor module to extract
multi-dimensional interaction signals and estimate satisfaction scores, which
guide structured data expansion via topic-aware and preference-driven
strategies. These expanded datasets support a two-stage fine-tuning pipeline:
supervised domain grounding followed by frequency-aware preference
optimization. Experiments across general NLP benchmarks and long-term dialogue
tasks demonstrate that DPSE consistently outperforms Supervised Fine-Tuning,
Preference Optimization, and Memory-Augmented baselines. Ablation studies
validate the contribution of each module. In this way, our framework provides
an autonomous path toward continual self-evolution of LLMs.

### 11. A Fisher's exact test justification of the TF-IDF term-weighting scheme

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Paul Sheridan, Zeyad Ahmed, Aitazaz A. Farooque
- **URL**: <http://arxiv.org/abs/2507.15742v1>
- **Submitted**: 2025-07-21 15:54:23
- **Comment**: 23 pages, 4 tables
- **Topic Keywords**: retrieval
- **Reason**: The paper provides a theoretical justification for the TF-IDF term-weighting scheme, which is a fundamental concept in Information Retrieval. While it's not directly related to query understanding, ranking models, or user behavior modeling, it's a relevant topic in the broader field of IR. However, the focus on theoretical foundations and statistical significance testing doesn't align with the user's interests in practical applications and real-time relevance optimization.

#### Abstract
> Term frequency-inverse document frequency, or TF-IDF for short, is arguably
the most celebrated mathematical expression in the history of information
retrieval. Conceived as a simple heuristic quantifying the extent to which a
given term's occurrences are concentrated in any one given document out of
many, TF-IDF and its many variants are routinely used as term-weighting schemes
in diverse text analysis applications. There is a growing body of scholarship
dedicated to placing TF-IDF on a sound theoretical foundation. Building on that
tradition, this paper justifies the use of TF-IDF to the statistics community
by demonstrating how the famed expression can be understood from a significance
testing perspective. We show that the common TF-IDF variant TF-ICF is, under
mild regularity conditions, closely related to the negative logarithm of the
$p$-value from a one-tailed version of Fisher's exact test of statistical
significance. As a corollary, we establish a connection between TF-IDF and the
said negative log-transformed $p$-value under certain idealized assumptions. We
further demonstrate, as a limiting case, that this same quantity converges to
TF-IDF in the limit of an infinitely large document collection. The Fisher's
exact test justification of TF-IDF equips the working statistician with a ready
explanation of the term-weighting scheme's long-established effectiveness.

### 12. Understanding Large Language Models' Ability on Interdisciplinary Research

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Yuanhao Shen, Daniel Xavier de Sousa, Ricardo Mar√ßal, Ali Asad, Hongyu Guo, Xiaodan Zhu
- **URL**: <http://arxiv.org/abs/2507.15736v1>
- **Submitted**: 2025-07-21 15:43:05
- **Topic Keywords**: recommend, search
- **Reason**: The paper explores the capabilities of Large Language Models (LLMs) in Interdisciplinary Research (IDR), introducing a benchmark called IDRBench. While it touches on the idea of 'idea development' and 'research idea generation', it does not directly relate to Information Retrieval (IR) or Search technologies, which are the primary focus of your research interests. The paper's emphasis on LLMs and IDR is somewhat relevant, but not a central match for your research themes.

#### Abstract
> Recent advancements in Large Language Models (LLMs) have revealed their
impressive ability to perform multi-step, logic-driven reasoning across complex
domains, positioning them as powerful tools and collaborators in scientific
discovery while challenging the long-held view that inspiration-driven ideation
is uniquely human. However, the lack of a dedicated benchmark that evaluates
LLMs' ability to develop ideas in Interdisciplinary Research (IDR) settings
poses a critical barrier to fully understanding their strengths and
limitations. To address this gap, we introduce IDRBench -- a pioneering
benchmark featuring an expert annotated dataset and a suite of tasks tailored
to evaluate LLMs' capabilities in proposing valuable research ideas from
different scientific domains for interdisciplinary research. This benchmark
aims to provide a systematic framework for assessing LLM performance in
complex, cross-domain scientific research. Our dataset consists of scientific
publications sourced from the ArXiv platform covering six distinct disciplines,
and is annotated by domain experts with diverse academic backgrounds. To ensure
high-quality annotations, we emphasize clearly defined dimensions that
characterize authentic interdisciplinary research. The design of evaluation
tasks in IDRBench follows a progressive, real-world perspective, reflecting the
natural stages of interdisciplinary research development, including 1) IDR
Paper Identification, 2) IDR Idea Integration, and 3) IDR Idea Recommendation.
Using IDRBench, we construct baselines across 10 LLMs and observe that despite
fostering some level of IDR awareness, LLMs still struggle to produce quality
IDR ideas. These findings could not only spark new research directions, but
also help to develop next-generation LLMs that excel in interdisciplinary
research.

### 13. Filling the Gap: Is Commonsense Knowledge Generation useful for Natural Language Inference?

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Chathuri Jayaweera, Brianna Yanqui, Bonnie Dorr
- **URL**: <http://arxiv.org/abs/2507.15100v1>
- **Submitted**: 2025-07-20 19:42:45
- **Comment**: 9 pages, 8 figures and 5 tables
- **Topic Keywords**: rag
- **Reason**: The paper explores Natural Language Inference (NLI) and the role of commonsense knowledge in it, which is a related topic in NLP. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval. The paper's focus on NLI and commonsense knowledge generation does not align with the user's primary research focus on information retrieval and search technologies.

#### Abstract
> Natural Language Inference (NLI) is the task of determining the semantic
entailment of a premise for a given hypothesis. The task aims to develop
systems that emulate natural human inferential processes where commonsense
knowledge plays a major role. However, existing commonsense resources lack
sufficient coverage for a variety of premise-hypothesis pairs. This study
explores the potential of Large Language Models as commonsense knowledge
generators for NLI along two key dimensions: their reliability in generating
such knowledge and the impact of that knowledge on prediction accuracy. We
adapt and modify existing metrics to assess LLM factuality and consistency in
generating in this context. While explicitly incorporating commonsense
knowledge does not consistently improve overall results, it effectively helps
distinguish entailing instances and moderately improves distinguishing
contradictory and neutral inferences.

### 14. DialogueForge: LLM Simulation of Human-Chatbot Dialogue

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Ruizhe Zhu, Hao Zhu, Yaxuan Li, Syang Zhou, Shijing Cai, Malgorzata Lazuka, Elliott Ash
- **URL**: <http://arxiv.org/abs/2507.15752v1>
- **Submitted**: 2025-07-21 16:08:19
- **Comment**: For our code and data, see
  https://github.com/nerchio/Human_Chatbot-Generation
- **Topic Keywords**: search
- **Reason**: The paper focuses on generating human-chatbot dialogues using LLMs, which is not directly related to information retrieval or search technologies. While it touches on topics like query understanding and user behavior modeling, the primary focus is on conversational AI, which is not a core area of interest. The paper's relevance to the user's research interests is limited.

#### Abstract
> Collecting human-chatbot dialogues typically demands substantial manual
effort and is time-consuming, which limits and poses challenges for research on
conversational AI. In this work, we propose DialogueForge - a framework for
generating AI-simulated conversations in human-chatbot style. To initialize
each generated conversation, DialogueForge uses seed prompts extracted from
real human-chatbot interactions. We test a variety of LLMs to simulate the
human chatbot user, ranging from state-of-the-art proprietary models to
small-scale open-source LLMs, and generate multi-turn dialogues tailored to
specific tasks. In addition, we explore fine-tuning techniques to enhance the
ability of smaller models to produce indistinguishable human-like dialogues. We
evaluate the quality of the simulated conversations and compare different
models using the UniEval and GTEval evaluation protocols. Our experiments show
that large proprietary models (e.g., GPT-4o) generally outperform others in
generating more realistic dialogues, while smaller open-source models (e.g.,
Llama, Mistral) offer promising performance with greater customization. We
demonstrate that the performance of smaller models can be significantly
improved by employing supervised fine-tuning techniques. Nevertheless,
maintaining coherent and natural long-form human-like dialogues remains a
common challenge across all models.

### 15. Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Elisa Sanchez-Bayona, Rodrigo Agerri
- **URL**: <http://arxiv.org/abs/2507.15357v1>
- **Submitted**: 2025-07-21 08:09:11
- **Topic Keywords**: search
- **Reason**: The paper explores the capabilities of Large Language Models in metaphor interpretation, which is a topic in Natural Language Processing (NLP). While it touches on the surface features that influence LLMs' performance, it does not directly relate to query understanding, ranking models, or user behavior modeling in Information Retrieval (IR), which are the user's primary research interests.

#### Abstract
> This paper presents a comprehensive evaluation of the capabilities of Large
Language Models (LLMs) in metaphor interpretation across multiple datasets,
tasks, and prompt configurations. Although metaphor processing has gained
significant attention in Natural Language Processing (NLP), previous research
has been limited to single-dataset evaluations and specific task settings,
often using artificially constructed data through lexical replacement. We
address these limitations by conducting extensive experiments using diverse
publicly available datasets with inference and metaphor annotations, focusing
on Natural Language Inference (NLI) and Question Answering (QA) tasks. The
results indicate that LLMs' performance is more influenced by features like
lexical overlap and sentence length than by metaphorical content, demonstrating
that any alleged emergent abilities of LLMs to understand metaphorical language
are the result of a combination of surface-level features, in-context learning,
and linguistic knowledge. This work provides critical insights into the current
capabilities and limitations of LLMs in processing figurative language,
highlighting the need for more realistic evaluation frameworks in metaphor
interpretation tasks. Data and code are publicly available.

### 16. From Queries to Criteria: Understanding How Astronomers Evaluate LLMs

- **LLM Score**: 2
- **Keyword Score**: 9
- **Authors**: Alina Hyk, Kiera McCormick, Mian Zhong, Ioana CiucƒÉ, Sanjib Sharma, John F Wu, J. E. G. Peek, Kartheik G. Iyer, Ziang Xiao, Anjalie Field
- **URL**: <http://arxiv.org/abs/2507.15715v1>
- **Submitted**: 2025-07-21 15:26:58
- **Comment**: Accepted to the Conference on Language Modeling 2025 (COLM), 22
  pages, 6 figures
- **Topic Keywords**: queries, rag, retrieval, recommend, search
- **Reason**: The paper is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on LLMs and astronomy is outside the user's primary areas of interest, and the paper does not address query understanding, ranking models, or user behavior modeling.

#### Abstract
> There is growing interest in leveraging LLMs to aid in astronomy and other
scientific research, but benchmarks for LLM evaluation in general have not kept
pace with the increasingly diverse ways that real people evaluate and use these
models. In this study, we seek to improve evaluation procedures by building an
understanding of how users evaluate LLMs. We focus on a particular use case: an
LLM-powered retrieval-augmented generation bot for engaging with astronomical
literature, which we deployed via Slack. Our inductive coding of 368 queries to
the bot over four weeks and our follow-up interviews with 11 astronomers reveal
how humans evaluated this system, including the types of questions asked and
the criteria for judging responses. We synthesize our findings into concrete
recommendations for building better benchmarks, which we then employ in
constructing a sample benchmark for evaluating LLMs for astronomy. Overall, our
work offers ways to improve LLM evaluation and ultimately usability,
particularly for use in scientific research.

### 17. Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Model's Capability of Emotion Perception using Contrastive Learning

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Tian Li, Yujian Sun, Huizhi Liang
- **URL**: <http://arxiv.org/abs/2507.15714v1>
- **Submitted**: 2025-07-21 15:25:47
- **Topic Keywords**: ranking, rag, rank, search
- **Reason**: The paper focuses on emotion perception and detection, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves contrastive learning, the application is in the context of emotion recognition, which is not a core area of interest for the user.

#### Abstract
> The SemEval-2025 Task 11, Bridging the Gap in Text-Based Emotion Detection,
introduces an emotion recognition challenge spanning over 28 languages. This
competition encourages researchers to explore more advanced approaches to
address the challenges posed by the diversity of emotional expressions and
background variations. It features two tracks: multi-label classification
(Track A) and emotion intensity prediction (Track B), covering six emotion
categories: anger, fear, joy, sadness, surprise, and disgust. In our work, we
systematically explore the benefits of two contrastive learning approaches:
sample-based (Contrastive Reasoning Calibration) and generation-based (DPO,
SimPO) contrastive learning. The sample-based contrastive approach trains the
model by comparing two samples to generate more reliable predictions. The
generation-based contrastive approach trains the model to differentiate between
correct and incorrect generations, refining its prediction. All models are
fine-tuned from LLaMa3-Instruct-8B. Our system achieves 9th place in Track A
and 6th place in Track B for English, while ranking among the top-tier
performing systems for other languages.

### 18. P3: Prompts Promote Prompting

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Xinyu Zhang, Yuanquan Hu, Fangchao Liu, Zhicheng Dou
- **URL**: <http://arxiv.org/abs/2507.15675v1>
- **Submitted**: 2025-07-21 14:37:46
- **Comment**: Accepted to ACL 2025 findings
- **Topic Keywords**: query, rag
- **Reason**: The paper focuses on optimizing prompts for large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on optimization strategies, the context is different from the user's primary research interests.

#### Abstract
> Current large language model (LLM) applications often employ multi-component
prompts, comprising both system and user prompts, to guide model behaviors.
While recent advancements have demonstrated the efficacy of automatically
optimizing either the system or user prompt to boost performance, such
unilateral approaches often yield suboptimal outcomes due to the interdependent
nature of these components. In this work, we introduce P3, a novel
self-improvement framework that concurrently optimizes both system and user
prompts through an iterative process. The offline optimized prompts are further
leveraged to promote online prompting by performing query-dependent prompt
optimization. Extensive experiments on general tasks (e.g., Arena-hard and
Alpaca-eval) and reasoning tasks (e.g., GSM8K and GPQA) demonstrate that P3
achieves superior performance in the realm of automatic prompt optimization.
Our results highlight the effectiveness of a holistic optimization strategy in
enhancing LLM performance across diverse domains.

### 19. Supernova: Achieving More with Less in Transformer Architectures

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Andrei-Valentin Tanase, Elena Pelican
- **URL**: <http://arxiv.org/abs/2507.15773v2>
- **Submitted**: 2025-07-21 16:27:48
- **Topic Keywords**: query
- **Reason**: The paper focuses on transformer architectures and their efficiency, but it does not relate to information retrieval, search technologies, or query understanding. The topics of ranking models, user behavior modeling, and deep semantic understanding are not addressed.

#### Abstract
> We present Supernova, a 650M-parameter decoder-only transformer that
demonstrates how careful architectural design and tokenization innovation can
achieve the performance of larger models while maintaining computational
efficiency. Our architecture combines Rotary Positional Embeddings (RoPE),
Grouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for
computational efficiency, and SwiGLU activation functions. A critical
innovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which
achieves state-of-the-art compression performance. Through detailed analysis,
we show that Supernova achieves 90% of the performance of 1B-parameter models
while using 35% fewer parameters and requiring only 100B training tokens--an
order of magnitude less than competing models. Our findings challenge the
prevailing scaling paradigm, demonstrating that architectural efficiency and
tokenization quality can compensate for reduced parameter counts.

### 20. Leveraging Context for Multimodal Fallacy Classification in Political Debates

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Alessio Pittiglio
- **URL**: <http://arxiv.org/abs/2507.15641v1>
- **Submitted**: 2025-07-21 14:03:08
- **Comment**: 12th Workshop on Argument Mining (ArgMining 2025) @ ACL 2025
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on multimodal argument mining and fallacy classification in political debates, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's context and multimodal approach are not relevant to the user's primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> In this paper, we present our submission to the MM-ArgFallacy2025 shared
task, which aims to advance research in multimodal argument mining, focusing on
logical fallacies in political debates. Our approach uses pretrained
Transformer-based models and proposes several ways to leverage context. In the
fallacy classification subtask, our models achieved macro F1-scores of 0.4444
(text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed
performance comparable to the text-only model, suggesting potential for
improvements.

### 21. ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Alexandru Coca, Mark Gaynor, Zhenxing Zhang, Jianpeng Cheng, Bo-Hsiang Tseng, Pete Boothroyd, H√©ctor Martinez Alonso, Diarmuid √ì S√©aghdha, Anders Johannsen
- **URL**: <http://arxiv.org/abs/2507.15501v1>
- **Submitted**: 2025-07-21 11:07:05
- **Comment**: 37 pages, 22 figures. To appear at ACL 2025
- **Topic Keywords**: queries
- **Reason**: The paper focuses on the potential of large language models to power digital assistants for complex action execution, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on language models, the context is different from the user's primary interests in IR and NLP.

#### Abstract
> This work evaluates the potential of large language models (LLMs) to power
digital assistants capable of complex action execution. These assistants rely
on pre-trained programming knowledge to execute multi-step goals by composing
objects and functions defined in assistant libraries into action execution
programs. To achieve this, we develop ASPERA, a framework comprising an
assistant library simulation and a human-assisted LLM data generation engine.
Our engine allows developers to guide LLM generation of high-quality tasks
consisting of complex user queries, simulation state and corresponding
validation programs, tackling data availability and evaluation robustness
challenges. Alongside the framework we release Asper-Bench, an evaluation
dataset of 250 challenging tasks generated using ASPERA, which we use to show
that program generation grounded in custom assistant libraries is a significant
challenge to LLMs compared to dependency-free code generation.

### 22. ChiMed 2.0: Advancing Chinese Medical Dataset in Facilitating Large Language Modeling

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yuanhe Tian, Junjie Liu, Zhizhou Kou, Yuxiang Li, Yan Song
- **URL**: <http://arxiv.org/abs/2507.15275v1>
- **Submitted**: 2025-07-21 06:23:16
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on building a Chinese medical dataset for large language modeling, which is not directly related to information retrieval, search technologies, or query understanding. Although it mentions pre-training and fine-tuning, the context is specific to Chinese medical domain and does not align with the user's research interests in IR and NLP.

#### Abstract
> Building high-quality data resources is crucial for advancing artificial
intelligence research and applications in specific domains, particularly in the
Chinese medical domain. Existing Chinese medical datasets are limited in size
and narrow in domain coverage, falling short of the diverse corpora required
for effective pre-training. Moreover, most datasets are designed solely for LLM
fine-tuning and do not support pre-training and reinforcement learning from
human feedback (RLHF). In this paper, we propose a Chinese medical dataset
named ChiMed 2.0, which extends our previous work ChiMed, and covers data
collected from Chinese medical online platforms and generated by LLMs. ChiMed
2.0 contains 204.4M Chinese characters covering both traditional Chinese
medicine classics and modern general medical data, where there are 164.8K
documents for pre-training, 351.6K question-answering pairs for supervised
fine-tuning (SFT), and 41.7K preference data tuples for RLHF. To validate the
effectiveness of our approach for training a Chinese medical LLM, we conduct
further pre-training, SFT, and RLHF experiments on representative general
domain LLMs and evaluate their performance on medical benchmark datasets. The
results show performance gains across different model scales, validating the
dataset's effectiveness and applicability.

### 23. A Penalty Goes a Long Way: Measuring Lexical Diversity in Synthetic Texts Under Prompt-Influenced Length Variations

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Vijeta Deshpande, Ishita Dasgupta, Uttaran Bhattacharya, Somdeb Sarkhel, Saayan Mitra, Anna Rumshisky
- **URL**: <http://arxiv.org/abs/2507.15092v1>
- **Submitted**: 2025-07-20 19:14:43
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on measuring lexical diversity in synthetic texts generated by Large Language Models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on the topic of language models, the primary focus is on evaluating the diversity of synthetic text, which is not a core area of interest for the user.

#### Abstract
> Synthetic text generated by Large Language Models (LLMs) is increasingly used
for further training and improvement of LLMs. Diversity is crucial for the
effectiveness of synthetic data, and researchers rely on prompt engineering to
improve diversity. However, the impact of prompt variations on response text
length, and, more importantly, the consequential effect on lexical diversity
measurements, remain underexplored. In this work, we propose Penalty-Adjusted
Type-Token Ratio (PATTR), a diversity metric robust to length variations. We
generate a large synthetic corpus of over 20M words using seven models from the
LLaMA, OLMo, and Phi families, focusing on a creative writing task of video
script generation, where diversity is crucial. We evaluate per-response lexical
diversity using PATTR and compare it against existing metrics of Moving-Average
TTR (MATTR) and Compression Ratio (CR). Our analysis highlights how text length
variations introduce biases favoring shorter responses. Unlike existing
metrics, PATTR explicitly considers the task-specific target response length
($L_T$) to effectively mitigate length biases. We further demonstrate the
utility of PATTR in filtering the top-10/100/1,000 most lexically diverse
responses, showing that it consistently outperforms MATTR and CR by yielding on
par or better diversity with high adherence to $L_T$.

### 24. The Impact of Language Mixing on Bilingual LLM Reasoning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yihao Li, Jiayi Xin, Miranda Muqing Miao, Qi Long, Lyle Ungar
- **URL**: <http://arxiv.org/abs/2507.15849v1>
- **Submitted**: 2025-07-21 17:56:09
- **Topic Keywords**: rag
- **Reason**: The paper focuses on bilingual large language models and their language mixing behavior, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on language understanding and reasoning, it does not address query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's interests.

#### Abstract
> Proficient multilingual speakers often intentionally switch languages in the
middle of a conversation. Similarly, recent reasoning-focused bilingual large
language models (LLMs) with strong capabilities in both languages exhibit
language mixing--alternating languages within their chain of thought.
Discouraging this behavior in DeepSeek-R1 was found to degrade accuracy,
suggesting that language mixing may benefit reasoning. In this work, we study
language switching in Chinese-English bilingual reasoning models. We identify
reinforcement learning with verifiable rewards (RLVR) as the critical training
stage that leads to language mixing. We demonstrate that language mixing can
enhance reasoning: enforcing monolingual decoding reduces accuracy by 5.6
percentage points on math reasoning tasks. Additionally, a lightweight probe
can be trained to predict whether a potential language switch would benefit or
harm reasoning, and when used to guide decoding, increases accuracy by up to
6.25 percentage points. Our findings suggest that language mixing is not merely
a byproduct of multilingual training, but is a strategic reasoning behavior.

### 25. Hierarchical Budget Policy Optimization for Adaptive Reasoning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Shangke Lyu, Linjuan Wu, Yuchen Yan, Xingyu Wu, Hao Li, Yongliang Shen, Peisheng Jiang, Weiming Lu, Jun Xiao, Yueting Zhuang
- **URL**: <http://arxiv.org/abs/2507.15844v2>
- **Submitted**: 2025-07-21 17:52:34
- **Comment**: Code: https://github.com/zju-real/hbpo Project
  Page:https://zju-real.github.io/hbpo/
- **Topic Keywords**: rag
- **Reason**: This paper focuses on reinforcement learning for reasoning models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on optimization and efficiency, the context is different from the user's primary research interests.

#### Abstract
> Large reasoning models achieve remarkable performance through extensive
chain-of-thought generation, yet exhibit significant computational inefficiency
by applying uniform reasoning strategies regardless of problem complexity. We
present Hierarchical Budget Policy Optimization (HBPO), a reinforcement
learning framework that enables models to learn problem-specific reasoning
depths without sacrificing capability. HBPO addresses the fundamental challenge
of exploration space collapse in efficiency-oriented training, where penalties
on long output length systematically bias models away from necessary long
reasoning paths. Through hierarchical budget exploration, our approach
partitions rollout samples into multiple subgroups with distinct token budgets,
aiming to enable efficient resource allocation while preventing degradation of
capability. We introduce differentiated reward mechanisms that create
budget-aware incentives aligned with the complexity of the problem, allowing
models to discover natural correspondences between task requirements and
computational effort. Extensive experiments demonstrate that HBPO reduces
average token usage by up to 60.6% while improving accuracy by 3.14% across
four reasoning benchmarks. Unlike existing methods that impose external
constraints or rely on discrete mode selection, HBPO exhibits emergent adaptive
behavior where models automatically adjust reasoning depth based on problem
complexity. Our results suggest that reasoning efficiency and capability are
not inherently conflicting, and can be simultaneously optimized through
appropriately structured hierarchical training that preserves exploration
diversity.

### 26. Stabilizing Knowledge, Promoting Reasoning: Dual-Token Constraints for RLVR

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jiakang Wang, Runze Liu, Fuzheng Zhang, Xiu Li, Guorui Zhou
- **URL**: <http://arxiv.org/abs/2507.15778v1>
- **Submitted**: 2025-07-21 16:34:01
- **Topic Keywords**: rag
- **Reason**: The paper focuses on Reinforcement Learning with Verifiable Rewards (RLVR) for improving the reasoning abilities of Large Language Models (LLMs), which is not directly related to Information Retrieval, Search technologies, or query understanding. The paper's emphasis on entropy-aware RLVR and dual-token constraints is also unrelated to user behavior modeling, ranking models, or click models.

#### Abstract
> Reinforcement Learning with Verifiable Rewards (RLVR) has become an effective
post-training method for improving the reasoning abilities of Large Language
Models (LLMs), mainly by shaping higher-order behaviors such as reflection and
planning. However, previous RLVR algorithms often apply uniform training
signals to all tokens, without considering the different roles of low-entropy
knowledge-related tokens and high-entropy reasoning-related tokens. Some recent
methods try to separate these token types by gradient masking or asynchronous
updates, but these approaches may break semantic dependencies in the model
output and hinder effective learning. In this work, we propose Archer, an
entropy-aware RLVR approach with dual-token constraints and synchronous
updates. Specifically, our method applies weaker KL regularization and higher
clipping thresholds to reasoning tokens to encourage exploration, while using
stronger constraints on knowledge tokens to maintain factual knowledge.
Experimental results on several mathematical reasoning and code generation
benchmarks show that our approach significantly outperforms previous RLVR
methods, reaching or exceeding state-of-the-art performance among models of
comparable size. The code is available at
https://github.com/wizard-III/ArcherCodeR.

### 27. LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xingyu Wu, Yuchen Yan, Shangke Lyu, Linjuan Wu, Yiwen Qiu, Yongliang Shen, Weiming Lu, Jian Shao, Jun Xiao, Yueting Zhuang
- **URL**: <http://arxiv.org/abs/2507.15758v1>
- **Submitted**: 2025-07-21 16:14:41
- **Comment**: GitHub:https://github.com/zju-real/lapo;
  Project:https://zju-real.github.io/lapo
- **Topic Keywords**: rag
- **Reason**: The paper focuses on optimizing the length of reasoning sequences in large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on the topic of model optimization, the context and methodology are not relevant to the user's primary research interests.

#### Abstract
> Large reasoning models have achieved remarkable performance through extended
chain-of-thought sequences, yet this computational freedom leads to excessive
token generation even for simple problems. We present Length-Adaptive Policy
Optimization (LAPO), a novel framework that transforms reasoning length control
from an external constraint into an intrinsic model capability. Unlike existing
approaches that impose rigid limits or rely on post-hoc interventions, LAPO
enables models to internalize an understanding of appropriate reasoning depth
through a two-stage reinforcement learning process. In the first stage, models
learn natural reasoning patterns by discovering the statistical distribution of
successful solution lengths. The second stage leverages these patterns as
meta-cognitive guidance, embedding them directly within the model's reasoning
context to ensure inference-time flexibility. Experiments on mathematical
reasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\%
while improving accuracy by 2.3\%. Our analysis reveals that models trained
with LAPO develop emergent abilities to allocate computational resources based
on problem complexity, achieving efficient reasoning without sacrificing
quality.

### 28. CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Congmin Zheng, Jiachen Zhu, Jianghao Lin, Xinyi Dai, Yong Yu, Weinan Zhang, Mengyue Yang
- **URL**: <http://arxiv.org/abs/2507.15698v1>
- **Submitted**: 2025-07-21 15:07:59
- **Topic Keywords**: rag
- **Reason**: The paper focuses on Process Reward Models and length debiasing in large language models, which is not directly related to my research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on topics like semantic understanding and real-time relevance optimization, the context is different and the techniques proposed are not applicable to my areas of interest.

#### Abstract
> Process Reward Models (PRMs) play a central role in evaluating and guiding
multi-step reasoning in large language models (LLMs), especially for
mathematical problem solving. However, we identify a pervasive length bias in
existing PRMs: they tend to assign higher scores to longer reasoning steps,
even when the semantic content and logical validity are unchanged. This bias
undermines the reliability of reward predictions and leads to overly verbose
outputs during inference. To address this issue, we propose
CoLD(Counterfactually-Guided Length Debiasing), a unified framework that
mitigates length bias through three components: an explicit length-penalty
adjustment, a learned bias estimator trained to capture spurious length-related
signals, and a joint training strategy that enforces length-invariance in
reward predictions. Our approach is grounded in counterfactual reasoning and
informed by causal graph analysis. Extensive experiments on MATH500 and
GSM-Plus show that CoLD consistently reduces reward-length correlation,
improves accuracy in step selection, and encourages more concise, logically
valid reasoning. These results demonstrate the effectiveness and practicality
of CoLD in improving the fidelity and robustness of PRMs.

### 29. AlgoSimBench: Identifying Algorithmically Similar Problems for Competitive Programming

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jierui Li, Raymond Mooney
- **URL**: <http://arxiv.org/abs/2507.15378v1>
- **Submitted**: 2025-07-21 08:34:20
- **Comment**: 19 pages, pre-print only
- **Topic Keywords**: retrieval
- **Reason**: The paper focuses on competitive programming and algorithmic similarity detection, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although the paper mentions LLMs and retrieval methods, the context is different from the user's primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Recent progress in LLMs, such as reasoning models, has demonstrated strong
abilities to solve complex competitive programming problems, often rivaling top
human competitors. However, it remains underexplored whether these abilities
generalize to relevant domains that are less seen during training. To address
this, we introduce AlgoSimBench, a new benchmark designed to assess LLMs'
ability to identify algorithmically similar problems (ASPs)-problems that can
be solved using similar algorithmic approaches. AlgoSimBench consists of 1317
problems, annotated with 231 distinct fine-grained algorithm tags, from which
we curate 402 multiple-choice questions (MCQs), where each question presents
one algorithmically similar problem alongside three textually similar but
algorithmically dissimilar distractors. Our evaluation reveals that LLMs
struggle to identify ASPs, with the best-performing model (o3-mini) achieving
only 65.9% accuracy on the MCQ task. To address this challenge, we propose
attempted solution matching (ASM), a novel method for improving problem
similarity detection. On our MCQ task, ASM yields an absolute accuracy
improvement of 6.7% to 11.7% across different models. We also evaluated code
embedding models and retrieval methods on similar problem identification. While
the adversarial selection of problems degrades the performance to be less than
random, we found that simply summarizing the problem to remove narrative
elements eliminates the effect, and combining ASM with a keyword-prioritized
method, BM25, can yield up to 52.2% accuracy. Code and data are available at
github.com

### 30. A2TTS: TTS for Low Resource Indian Languages

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ayush Singh Bhadoriya, Abhishek Nikunj Shinde, Isha Pandey, Ganesh Ramakrishnan
- **URL**: <http://arxiv.org/abs/2507.15272v1>
- **Submitted**: 2025-07-21 06:20:27
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests as it focuses on text-to-speech systems for low-resource Indian languages, which is outside the scope of information retrieval, search technologies, and natural language processing. The paper's emphasis on speaker-conditioned models and duration prediction mechanisms is also not aligned with your interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> We present a speaker conditioned text-to-speech (TTS) system aimed at
addressing challenges in generating speech for unseen speakers and supporting
diverse Indian languages. Our method leverages a diffusion-based TTS
architecture, where a speaker encoder extracts embeddings from short reference
audio samples to condition the DDPM decoder for multispeaker generation. To
further enhance prosody and naturalness, we employ a cross-attention based
duration prediction mechanism that utilizes reference audio, enabling more
accurate and speaker consistent timing. This results in speech that closely
resembles the target speaker while improving duration modeling and overall
expressiveness. Additionally, to improve zero-shot generation, we employed
classifier free guidance, allowing the system to generate speech more near
speech for unknown speakers. Using this approach, we trained language-specific
speaker-conditioned models. Using the IndicSUPERB dataset for multiple Indian
languages such as Bengali, Gujarati, Hindi, Marathi, Malayalam, Punjabi and
Tamil.

### 31. SOI Matters: Analyzing Multi-Setting Training Dynamics in Pretrained Language Models via Subsets of Interest

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Shayan Vassef, Amirhossein Dabiriaghdam, Mohammadreza Bakhtiari, Yadollah Yaghoobzadeh
- **URL**: <http://arxiv.org/abs/2507.15236v1>
- **Submitted**: 2025-07-21 04:43:21
- **Topic Keywords**: rag
- **Reason**: The paper focuses on the training dynamics of language models, introducing a novel framework for categorizing learning behavior patterns. While it explores multi-task, multi-lingual, and multi-source learning approaches, the paper does not directly relate to information retrieval, search technologies, or query understanding, which are the user's primary research interests.

#### Abstract
> This work investigates the impact of multi-task, multi-lingual, and
multi-source learning approaches on the robustness and performance of
pretrained language models. To enhance this analysis, we introduce Subsets of
Interest (SOI), a novel categorization framework that identifies six distinct
learning behavior patterns during training, including forgettable examples,
unlearned examples, and always correct examples. Through SOI transition
heatmaps and dataset cartography visualization, we analyze how examples shift
between these categories when transitioning from single-setting to
multi-setting configurations. We perform comprehensive experiments across three
parallel comparisons: multi-task vs. single-task learning using English tasks
(entailment, paraphrase, sentiment), multi-source vs. single-source learning
using sentiment analysis datasets, and multi-lingual vs. single-lingual
learning using intent classification in French, English, and Persian. Our
results demonstrate that multi-source learning consistently improves
out-of-distribution performance by up to 7%, while multi-task learning shows
mixed results with notable gains in similar task combinations. We further
introduce a two-stage fine-tuning approach where the second stage leverages
SOI-based subset selection to achieve additional performance improvements.
These findings provide new insights into training dynamics and offer practical
approaches for optimizing multi-setting language model performance.

### 32. 3LM: Bridging Arabic, STEM, and Code through Benchmarking

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Basma El Amel Boussaha, Leen AlQadi, Mugariya Farooq, Shaikha Alsuwaidi, Giulia Campesan, Ahmed Alzubaidi, Mohammed Alyafeai, Hakim Hacid
- **URL**: <http://arxiv.org/abs/2507.15850v1>
- **Submitted**: 2025-07-21 17:58:27
- **Topic Keywords**: search
- **Reason**: The paper focuses on developing benchmarks for Arabic Large Language Models (LLMs) in STEM and code domains, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although the paper touches on LLMs, it does not explore query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user.

#### Abstract
> Arabic is one of the most widely spoken languages in the world, yet efforts
to develop and evaluate Large Language Models (LLMs) for Arabic remain
relatively limited. Most existing Arabic benchmarks focus on linguistic,
cultural, or religious content, leaving a significant gap in domains like STEM
and code which are increasingly relevant for real-world LLM applications. To
help bridge this gap, we present 3LM, a suite of three benchmarks designed
specifically for Arabic. The first is a set of STEM-related question-answer
pairs, naturally sourced from Arabic textbooks and educational worksheets. The
second consists of synthetically generated STEM questions, created using the
same sources. The third benchmark focuses on code generation, built through a
careful translation of two widely used code benchmarks, incorporating a
human-in-the-loop process with several rounds of review to ensure high-quality
and faithful translations. We release all three benchmarks publicly to support
the growth of Arabic LLM research in these essential but underrepresented
areas.

### 33. Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Anton Abilov, Ke Zhang, Hemank Lamba, Elizabeth M. Olson, Joel R. Tetreault, Alejandro Jaimes
- **URL**: <http://arxiv.org/abs/2507.15823v1>
- **Submitted**: 2025-07-21 17:30:38
- **Topic Keywords**: search
- **Reason**: The paper focuses on the deployment and integration of AI models in humanitarian work, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topics of query understanding, ranking models, and user behavior modeling are not addressed in this paper.

#### Abstract
> Publications in the AI for Good space have tended to focus on the research
and model development that can support high-impact applications. However, very
few AI for Good papers discuss the process of deploying and collaborating with
the partner organization, and the resulting real-world impact. In this work, we
share details about the close collaboration with a humanitarian-to-humanitarian
(H2H) organization and how to not only deploy the AI model in a
resource-constrained environment, but also how to maintain it for continuous
performance updates, and share key takeaways for practitioners.

### 34. On the Inevitability of Left-Leaning Political Bias in Aligned Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Thilo Hagendorff
- **URL**: <http://arxiv.org/abs/2507.15328v1>
- **Submitted**: 2025-07-21 07:37:28
- **Topic Keywords**: search
- **Reason**: The paper's focus on AI alignment, language models, and political bias is unrelated to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The abstract does not mention query understanding, ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest for the user.

#### Abstract
> The guiding principle of AI alignment is to train large language models
(LLMs) to be harmless, helpful, and honest (HHH). At the same time, there are
mounting concerns that LLMs exhibit a left-wing political bias. Yet, the
commitment to AI alignment cannot be harmonized with the latter critique. In
this article, I argue that intelligent systems that are trained to be harmless
and honest must necessarily exhibit left-wing political bias. Normative
assumptions underlying alignment objectives inherently concur with progressive
moral frameworks and left-wing principles, emphasizing harm avoidance,
inclusivity, fairness, and empirical truthfulness. Conversely, right-wing
ideologies often conflict with alignment guidelines. Yet, research on political
bias in LLMs is consistently framing its insights about left-leaning tendencies
as a risk, as problematic, or concerning. This way, researchers are actively
arguing against AI alignment, tacitly fostering the violation of HHH
principles.

### 35. Beyond Easy Wins: A Text Hardness-Aware Benchmark for LLM-generated Text Detection

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Navid Ayoobi, Sadat Shahriar, Arjun Mukherjee
- **URL**: <http://arxiv.org/abs/2507.15286v1>
- **Submitted**: 2025-07-21 06:37:27
- **Topic Keywords**: search
- **Reason**: The paper focuses on AI text detectors and evaluation metrics, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions AI-generated text, the context is different from the user's interests in NLP, data mining, and related topics.

#### Abstract
> We present a novel evaluation paradigm for AI text detectors that prioritizes
real-world and equitable assessment. Current approaches predominantly report
conventional metrics like AUROC, overlooking that even modest false positive
rates constitute a critical impediment to practical deployment of detection
systems. Furthermore, real-world deployment necessitates predetermined
threshold configuration, making detector stability (i.e. the maintenance of
consistent performance across diverse domains and adversarial scenarios), a
critical factor. These aspects have been largely ignored in previous research
and benchmarks. Our benchmark, SHIELD, addresses these limitations by
integrating both reliability and stability factors into a unified evaluation
metric designed for practical assessment. Furthermore, we develop a post-hoc,
model-agnostic humanification framework that modifies AI text to more closely
resemble human authorship, incorporating a controllable hardness parameter.
This hardness-aware approach effectively challenges current SOTA zero-shot
detection methods in maintaining both reliability and stability. (Data and
code: https://github.com/navid-aub/SHIELD-Benchmark)

---

