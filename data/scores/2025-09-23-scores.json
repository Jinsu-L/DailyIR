[
    {
        "title": "A Generative Framework for Personalized Sticker Retrieval",
        "abstract": "Formulating information retrieval as a variant of generative modeling,\nspecifically using autoregressive models to generate relevant identifiers for a\ngiven query, has recently attracted considerable attention. However, its\napplication to personalized sticker retrieval remains largely unexplored and\npresents unique challenges: existing relevance-based generative retrieval\nmethods typically lack personalization, leading to a mismatch between diverse\nuser expectations and the retrieved results. To address this gap, we propose\nPEARL, a novel generative framework for personalized sticker retrieval, and\nmake two key contributions: (i) To encode user-specific sticker preferences, we\ndesign a representation learning model to learn discriminative user\nrepresentations. It is trained on three prediction tasks that leverage personal\ninformation and click history; and (ii) To generate stickers aligned with a\nuser's query intent, we propose a novel intent-aware learning objective that\nprioritizes stickers associated with higher-ranked intents. Empirical results\nfrom both offline evaluations and online tests demonstrate that PEARL\nsignificantly outperforms state-of-the-art methods.",
        "url": "http://arxiv.org/abs/2509.17749v2",
        "pdf_url": "http://arxiv.org/pdf/2509.17749v2",
        "arxiv_id": "2509.17749v2",
        "authors": [
            "Changjiang Zhou",
            "Ruqing Zhang",
            "Jiafeng Guo",
            "Yu-An Liu",
            "Fan Zhang",
            "Ganyuan Luo",
            "Xueqi Cheng"
        ],
        "submitted": "2025-09-22 13:11:44",
        "source": "arxiv",
        "comment": "Findings of EMNLP2025",
        "score": 17,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'click' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'personalization' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper proposes a generative framework for personalized sticker retrieval, leveraging user-specific preferences and intent-aware learning objectives. While the focus is on sticker retrieval, the use of generative modeling and personalized ranking aligns with the user's interests in Information Retrieval and query understanding. However, the domain-specific application (sticker retrieval) is somewhat niche compared to the user's broader interests in e-commerce and general IR."
    },
    {
        "title": "Simplified Longitudinal Retrieval Experiments: A Case Study on Query Expansion and Document Boosting",
        "abstract": "The longitudinal evaluation of retrieval systems aims to capture how\ninformation needs and documents evolve over time. However, classical\nCranfield-style retrieval evaluations only consist of a static set of queries\nand documents and thereby miss time as an evaluation dimension. Therefore,\nlongitudinal evaluations need to complement retrieval toolkits with custom\nlogic. This custom logic increases the complexity of research software, which\nmight reduce the reproducibility and extensibility of experiments. Based on our\nsubmissions to the 2024 edition of LongEval, we propose a custom extension of\nir_datasets for longitudinal retrieval experiments. This extension allows for\ndeclaratively, instead of imperatively, describing important aspects of\nlongitudinal retrieval experiments, e.g., which queries, documents, and/or\nrelevance feedback are available at which point in time. We reimplement our\nsubmissions to LongEval 2024 against our new ir_datasets extension, and find\nthat the declarative access can reduce the complexity of the code.",
        "url": "http://arxiv.org/abs/2509.17440v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17440v1",
        "arxiv_id": "2509.17440v1",
        "authors": [
            "Jüri Keller",
            "Maik Fröbe",
            "Gijs Hendriksen",
            "Daria Alexander",
            "Martin Potthast",
            "Philipp Schaer"
        ],
        "submitted": "2025-09-22 07:29:34",
        "source": "arxiv",
        "comment": "Best of labs paper for LongEval at CLEF 2024",
        "score": 15,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'relevance feedback' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the evaluation of retrieval systems, proposing a custom extension for longitudinal retrieval experiments. However, it does not address query understanding, ranking models, or user behavior modeling, which are core areas of interest for your research. The paper's focus on evaluation methodology and tooling does not align closely with your primary research themes."
    },
    {
        "title": "OnePiece: Bringing Context Engineering and Reasoning to Industrial Cascade Ranking System",
        "abstract": "Despite the growing interest in replicating the scaled success of large\nlanguage models (LLMs) in industrial search and recommender systems, most\nexisting industrial efforts remain limited to transplanting Transformer\narchitectures, which bring only incremental improvements over strong Deep\nLearning Recommendation Models (DLRMs). From a first principle perspective, the\nbreakthroughs of LLMs stem not only from their architectures but also from two\ncomplementary mechanisms: context engineering, which enriches raw input queries\nwith contextual cues to better elicit model capabilities, and multi-step\nreasoning, which iteratively refines model outputs through intermediate\nreasoning paths. However, these two mechanisms and their potential to unlock\nsubstantial improvements remain largely underexplored in industrial ranking\nsystems.\n  In this paper, we propose OnePiece, a unified framework that seamlessly\nintegrates LLM-style context engineering and reasoning into both retrieval and\nranking models of industrial cascaded pipelines. OnePiece is built on a pure\nTransformer backbone and further introduces three key innovations: (1)\nstructured context engineering, which augments interaction history with\npreference and scenario signals and unifies them into a structured tokenized\ninput sequence for both retrieval and ranking; (2) block-wise latent reasoning,\nwhich equips the model with multi-step refinement of representations and scales\nreasoning bandwidth via block size; (3) progressive multi-task training, which\nleverages user feedback chains to effectively supervise reasoning steps during\ntraining. OnePiece has been deployed in the main personalized search scenario\nof Shopee and achieves consistent online gains across different key business\nmetrics, including over $+2\\%$ GMV/UU and a $+2.90\\%$ increase in advertising\nrevenue.",
        "url": "http://arxiv.org/abs/2509.18091v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18091v1",
        "arxiv_id": "2509.18091v1",
        "authors": [
            "Sunhao Dai",
            "Jiakai Tang",
            "Jiahua Wu",
            "Kun Wang",
            "Yuxuan Zhu",
            "Bingjun Chen",
            "Bangyang Hong",
            "Yu Zhao",
            "Cong Fu",
            "Kangle Wu",
            "Yabo Ni",
            "Anxiang Zeng",
            "Wenjie Wang",
            "Xu Chen",
            "Jun Xu",
            "See-Kiong Ng"
        ],
        "submitted": "2025-09-22 17:59:07",
        "source": "arxiv",
        "comment": "OnePiece Technical Report; Applied in Shopee",
        "score": 13,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 9,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the areas of query understanding, ranking models, and user behavior modeling. The proposed framework, OnePiece, integrates context engineering and reasoning into industrial cascaded pipelines, which aligns with your focus on deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "LongEval at CLEF 2025: Longitudinal Evaluation of IR Systems on Web and Scientific Data",
        "abstract": "The LongEval lab focuses on the evaluation of information retrieval systems\nover time. Two datasets are provided that capture evolving search scenarios\nwith changing documents, queries, and relevance assessments. Systems are\nassessed from a temporal perspective-that is, evaluating retrieval\neffectiveness as the data they operate on changes. In its third edition,\nLongEval featured two retrieval tasks: one in the area of ad-hoc web retrieval,\nand another focusing on scientific article retrieval. We present an overview of\nthis year's tasks and datasets, as well as the participating systems. A total\nof 19 teams submitted their approaches, which we evaluated using nDCG and a\nvariety of measures that quantify changes in retrieval effectiveness over time.",
        "url": "http://arxiv.org/abs/2509.17469v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17469v1",
        "arxiv_id": "2509.17469v1",
        "authors": [
            "Matteo Cancellieri",
            "Alaa El-Ebshihy",
            "Tobias Fink",
            "Maik Fröbe",
            "Petra Galuščáková",
            "Gabriela Gonzalez-Saez",
            "Lorraine Goeuriot",
            "David Iommi",
            "Jüri Keller",
            "Petr Knoth",
            "Philippe Mulhem",
            "Florina Piroi",
            "David Pride",
            "Philipp Schaer"
        ],
        "submitted": "2025-09-22 08:05:40",
        "source": "arxiv",
        "comment": null,
        "score": 12,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to Information Retrieval (IR) and Search technologies, specifically focusing on the evaluation of IR systems over time. The use of longitudinal evaluation and temporal assessment of retrieval effectiveness aligns with the user's interests in query understanding and ranking models. However, the focus on evaluation rather than model development or user behavior modeling slightly reduces the score."
    },
    {
        "title": "MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction",
        "abstract": "Universal multimodal embedding models have achieved great success in\ncapturing semantic relevance between queries and candidates. However, current\nmethods either condense queries and candidates into a single vector,\npotentially limiting the expressiveness for fine-grained information, or\nproduce too many vectors that are prohibitively expensive for multi-vector\nretrieval. In this work, we introduce MetaEmbed, a new framework for multimodal\nretrieval that rethinks how multimodal embeddings are constructed and\ninteracted with at scale. During training, a fixed number of learnable Meta\nTokens are appended to the input sequence. At test-time, their last-layer\ncontextualized representations serve as compact yet expressive multi-vector\nembeddings. Through the proposed Matryoshka Multi-Vector Retrieval training,\nMetaEmbed learns to organize information by granularity across multiple\nvectors. As a result, we enable test-time scaling in multimodal retrieval,\nwhere users can balance retrieval quality against efficiency demands by\nselecting the number of tokens used for indexing and retrieval interactions.\nExtensive evaluations on the Massive Multimodal Embedding Benchmark (MMEB) and\nthe Visual Document Retrieval Benchmark (ViDoRe) confirm that MetaEmbed\nachieves state-of-the-art retrieval performance while scaling robustly to\nmodels with 32B parameters.",
        "url": "http://arxiv.org/abs/2509.18095v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18095v1",
        "arxiv_id": "2509.18095v1",
        "authors": [
            "Zilin Xiao",
            "Qi Ma",
            "Mengting Gu",
            "Chun-cheng Jason Chen",
            "Xintao Chen",
            "Vicente Ordonez",
            "Vijai Mohan"
        ],
        "submitted": "2025-09-22 17:59:42",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper focuses on multimodal retrieval, which is related to information retrieval and search technologies. However, it does not specifically address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's emphasis on scalability and efficiency is also relevant to the e-commerce domain."
    },
    {
        "title": "MapCoder-Lite: Squeezing Multi-Agent Coding into a Single Small LLM",
        "abstract": "Large language models (LLMs) have advanced code generation from\nsingle-function tasks to competitive-programming problems, but existing\nmulti-agent solutions either rely on costly large-scale ($>$ 30B) models or\ncollapse when downsized to small open-source models. We present MapCoder-Lite,\nwhich upgrades a single 7B model into four role-specialised agents-retriever,\nplanner, coder, and debugger-using only rank-32, role-specific LoRA adapters\n($<3\\%$ extra parameters). Three lightweight techniques make this possible: (i)\ntrajectory distillation from strong LLMs fixes format fragility in retrieval\nand debugging, (ii) supervisor-guided correction strengthens planning and\ncoding agents, and (iii) agent-wise LoRA fine-tuning delivers memory-efficient\nspecialisation. Comprehensive evaluation on xCodeEval, APPS, and CodeContests\nshows that MapCoder-Lite more than doubles xCodeEval accuracy (from $13.2\\%$ to\n$28.3\\%$), eliminates all format failures, and closes to within six points of a\n32B baseline while cutting GPU memory and token-generation time by $4\\times$.\nThese results demonstrate that careful agent-wise fine-tuning unleashes\nhigh-quality multi-agent coding on a small language model.",
        "url": "http://arxiv.org/abs/2509.17489v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17489v1",
        "arxiv_id": "2509.17489v1",
        "authors": [
            "Woongkyu Lee",
            "Junhee Cho",
            "Jungwook Choi"
        ],
        "submitted": "2025-09-22 08:19:11",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multi-agent coding and code generation using large language models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some NLP aspects, the primary focus is on code generation and multi-agent systems, making it somewhat tangential to your research areas."
    },
    {
        "title": "LingoQ: Bridging the Gap between ESL Learning and Work through AI-Generated Work-Related Quizzes",
        "abstract": "Non-native English speakers performing English-related tasks at work struggle\nto sustain ESL learning, despite their motivation. Often, study materials are\ndisconnected from their work context. Although workers rely on LLM assistants\nto address their immediate needs, these interactions may not directly\ncontribute to their English skills. We present LingoQ, an AI-mediated system\nthat allows workers to practice English using quizzes generated from their LLM\nqueries during work. LingoQ leverages these queries using AI to generate\npersonalized quizzes that workers can review and practice on their smartphones.\nWe conducted a three-week deployment study with 28 ESL workers to evaluate\nLingoQ. Participants valued the relevance of quizzes that reflect their own\ncontext, constantly engaging with the app during the study. This active\nengagement improved self-efficacy and led to learning gains for beginners and,\npotentially, for intermediate learners. We discuss opportunities of leveraging\nusers' reliance on LLMs to situate their learning in the user context for\nimproved learning.",
        "url": "http://arxiv.org/abs/2509.17477v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17477v1",
        "arxiv_id": "2509.17477v1",
        "authors": [
            "Yeonsun Yang",
            "Sang Won Lee",
            "Jean Y. Song",
            "Sangdoo Yun",
            "Young-Ho Kim"
        ],
        "submitted": "2025-09-22 08:12:10",
        "source": "arxiv",
        "comment": "17 pages except reference",
        "score": 8,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be primarily focused on language learning and AI-generated quizzes for ESL workers, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves AI and user queries, the context and application are distinct from the user's areas of focus."
    },
    {
        "title": "AttnComp: Attention-Guided Adaptive Context Compression for Retrieval-Augmented Generation",
        "abstract": "Retrieval-augmented generation improves the factual accuracy of Large\nLanguage Models (LLMs) by incorporating external context, but often suffers\nfrom irrelevant retrieved content that hinders effectiveness. Context\ncompression addresses this issue by filtering out irrelevant information from\ncontext before LLM generation. However, existing methods struggle to adaptively\nadjust compression rates for different context, maintain low latency and\nintegrate information across multiple documents. To overcome these limitations,\nWe introduce AttnComp, an adaptive, efficient and context-aware compression\nframework. By leveraging the attention mechanism of LLMs to identify relevant\ninformation, AttnComp employs a Top-P compression algorithm to retain the\nminimal set of documents whose cumulative attention weights exceeds a\npredefined threshold. In addition to compression, AttnComp estimates response\nconfidence by assessing the overall relevance of the retrieved content,\nenabling users to gauge response reliability. Experiments demonstrate that\nAttnComp outperforms existing compression methods and uncompressed baselines,\nachieving higher accuracy with substantial compression rates and lower latency.",
        "url": "http://arxiv.org/abs/2509.17486v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17486v1",
        "arxiv_id": "2509.17486v1",
        "authors": [
            "Lvzhou Luo",
            "Yixuan Cao",
            "Ping Luo"
        ],
        "submitted": "2025-09-22 08:18:50",
        "source": "arxiv",
        "comment": "Accepted at EMNLP 2025 (Findings)",
        "score": 7,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper introduces a novel framework, AttnComp, for context compression in retrieval-augmented generation. While it leverages attention mechanisms and addresses issues in information retrieval, its focus is on generation and compression rather than traditional search or ranking models. It may be of interest for its innovative approach, but it does not directly align with core IR and search themes."
    },
    {
        "title": "A Knowledge Graph-based Retrieval-Augmented Generation Framework for Algorithm Selection in the Facility Layout Problem",
        "abstract": "Selecting a solution algorithm for the Facility Layout Problem (FLP), an\nNP-hard optimization problem with a multiobjective trade-off, is a complex task\nthat requires deep expert knowledge. The performance of a given algorithm\ndepends on specific problem characteristics such as its scale, objectives, and\nconstraints. This creates a need for a data-driven recommendation method to\nguide algorithm selection in automated design systems. This paper introduces a\nnew recommendation method to make such expertise accessible, based on a\nKnowledge Graph-based Retrieval-Augmented Generation (KG RAG) framework. To\naddress this, a domain-specific knowledge graph is constructed from published\nliterature. The method then employs a multi-faceted retrieval mechanism to\ngather relevant evidence from this knowledge graph using three distinct\napproaches, which include a precise graph-based search, flexible vector-based\nsearch, and high-level cluster-based search. The retrieved evidence is utilized\nby a Large Language Model (LLM) to generate algorithm recommendations with\ndata-driven reasoning. The proposed KG-RAG method is compared against a\ncommercial LLM chatbot with access to the knowledge base as a table, across a\nseries of diverse, real-world FLP test cases. Based on recommendation accuracy\nand reasoning capability, the proposed method performed significantly better\nthan the commercial LLM chatbot.",
        "url": "http://arxiv.org/abs/2509.18054v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18054v1",
        "arxiv_id": "2509.18054v1",
        "authors": [
            "Nikhil N S",
            "Amol Dilip Joshi",
            "Bilal Muhammed",
            "Soban Babu"
        ],
        "submitted": "2025-09-22 17:29:10",
        "source": "arxiv",
        "comment": "10 pages, 5 figures",
        "score": 6,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on a Knowledge Graph-based Retrieval-Augmented Generation framework for algorithm selection in the Facility Layout Problem, which is not directly related to Information Retrieval, Search technologies, or Natural Language Processing. While it does involve a Knowledge Graph and a Large Language Model, the context is specific to algorithm selection and not relevant to the user's core research themes."
    },
    {
        "title": "Diagnosing Model Editing via Knowledge Spectrum",
        "abstract": "Model editing, the process of efficiently modifying factual knowledge in\npre-trained language models, is critical for maintaining their accuracy and\nrelevance. However, existing editing methods often introduce unintended side\neffects, degrading model performance in unpredictable ways. While much research\nhas focused on improving editing algorithms, the role of the target knowledge's\nintrinsic properties remains a significant, underexplored factor. This paper\naddresses this gap by first proposing the ``Knowledge Spectrum,'' a systematic\nframework for categorizing knowledge based on its real-world popularity, the\nmodel's pre-edit familiarity, and the linguistic structure of the eliciting\nquestion. Our empirical analysis reveals that these characteristics are strong\npredictors of editing success and stability. Informed by these findings, we\nintroduce the ``Knowledge-Diagnostic Framework,'' an adaptive strategy that\ntailors editing intensity to the diagnosed difficulty of a knowledge item. We\ndemonstrate that this framework significantly improves success rates for\nchallenging edits while optimizing computational resources. Our work provides a\nmore comprehensive understanding of the factors governing model editing.",
        "url": "http://arxiv.org/abs/2509.17482v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17482v1",
        "arxiv_id": "2509.17482v1",
        "authors": [
            "Tsung-Hsuan Pan",
            "Chung-Chi Chen",
            "Hen-Hsen Huang",
            "Hsin-Hsi Chen"
        ],
        "submitted": "2025-09-22 08:16:04",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'ctr' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on model editing in pre-trained language models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on model editing and knowledge categorization is not directly aligned with the user's core research themes. The paper's relevance to the user's interests is limited to the broader context of NLP and related topics."
    },
    {
        "title": "WildClaims: Information Access Conversations in the Wild(Chat)",
        "abstract": "The rapid advancement of Large Language Models (LLMs) has transformed\nconversational systems into practical tools used by millions. However, the\nnature and necessity of information retrieval in real-world conversations\nremain largely unexplored, as research has focused predominantly on\ntraditional, explicit information access conversations. The central question\nis: What do real-world information access conversations look like? To this end,\nwe first conduct an observational study on the WildChat dataset, large-scale\nuser-ChatGPT conversations, finding that users' access to information occurs\nimplicitly as check-worthy factual assertions made by the system, even when the\nconversation's primary intent is non-informational, such as creative writing.\nTo enable the systematic study of this phenomenon, we release the WildClaims\ndataset, a novel resource consisting of 121,905 extracted factual claims from\n7,587 utterances in 3,000 WildChat conversations, each annotated for\ncheck-worthiness. Our preliminary analysis of this resource reveals that\nconservatively 18% to 51% of conversations contain check-worthy assertions,\ndepending on the methods employed, and less conservatively, as many as 76% may\ncontain such assertions. This high prevalence underscores the importance of\nmoving beyond the traditional understanding of explicit information access, to\naddress the implicit information access that arises in real-world user-system\nconversations.",
        "url": "http://arxiv.org/abs/2509.17442v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17442v1",
        "arxiv_id": "2509.17442v1",
        "authors": [
            "Hideaki Joko",
            "Shakiba Amirshahi",
            "Charles L. A. Clarke",
            "Faegheh Hasibi"
        ],
        "submitted": "2025-09-22 07:32:06",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper explores information access conversations in real-world settings, which aligns with your interests in Information Retrieval and Search technologies. The study focuses on implicit information access, which is a relevant area of research in query understanding and ranking models. The use of a large-scale dataset and novel resource also demonstrates a strong connection to your research themes."
    },
    {
        "title": "RealBench: A Chinese Multi-image Understanding Benchmark Close to Real-world Scenarios",
        "abstract": "While various multimodal multi-image evaluation datasets have been emerged,\nbut these datasets are primarily based on English, and there has yet to be a\nChinese multi-image dataset. To fill this gap, we introduce RealBench, the\nfirst Chinese multimodal multi-image dataset, which contains 9393 samples and\n69910 images. RealBench distinguishes itself by incorporating real\nuser-generated content, ensuring high relevance to real-world applications.\nAdditionally, the dataset covers a wide variety of scenes, image resolutions,\nand image structures, further increasing the difficulty of multi-image\nunderstanding. Ultimately, we conduct a comprehensive evaluation of RealBench\nusing 21 multimodal LLMs of different sizes, including closed-source models\nthat support multi-image inputs as well as open-source visual and video models.\nThe experimental results indicate that even the most powerful closed-source\nmodels still face challenges when handling multi-image Chinese scenarios.\nMoreover, there remains a noticeable performance gap of around 71.8\\% on\naverage between open-source visual/video models and closed-source models. These\nresults show that RealBench provides an important research foundation for\nfurther exploring multi-image understanding capabilities in the Chinese\ncontext.",
        "url": "http://arxiv.org/abs/2509.17421v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17421v1",
        "arxiv_id": "2509.17421v1",
        "authors": [
            "Fei Zhao",
            "Chengqiang Lu",
            "Yufan Shen",
            "Qimeng Wang",
            "Yicheng Qian",
            "Haoxin Zhang",
            "Yan Gao",
            "Yi Wu",
            "Yao Hu",
            "Zhen Wu",
            "Shangyu Xing",
            "Xinyu Dai"
        ],
        "submitted": "2025-09-22 07:14:31",
        "source": "arxiv",
        "comment": "Findings of EMNLP 2025 camera-ready",
        "score": 6,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on a Chinese multi-image understanding benchmark, which is not directly related to Information Retrieval, query understanding, ranking models, or user behavior modeling. While it involves multimodal LLMs, the context is specific to Chinese multi-image understanding and does not align with the user's core research themes."
    },
    {
        "title": "ARK-V1: An LLM-Agent for Knowledge Graph Question Answering Requiring Commonsense Reasoning",
        "abstract": "Large Language Models (LLMs) show strong reasoning abilities but rely on\ninternalized knowledge that is often insufficient, outdated, or incorrect when\ntrying to answer a question that requires specific domain knowledge. Knowledge\nGraphs (KGs) provide structured external knowledge, yet their complexity and\nmulti-hop reasoning requirements make integration challenging. We present\nARK-V1, a simple KG-agent that iteratively explores graphs to answer natural\nlanguage queries. We evaluate several not fine-tuned state-of-the art LLMs as\nbackbones for ARK-V1 on the CoLoTa dataset, which requires both KG-based and\ncommonsense reasoning over long-tail entities. ARK-V1 achieves substantially\nhigher conditional accuracies than Chain-of-Thought baselines, and larger\nbackbone models show a clear trend toward better coverage, correctness, and\nstability.",
        "url": "http://arxiv.org/abs/2509.18063v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18063v1",
        "arxiv_id": "2509.18063v1",
        "authors": [
            "Jan-Felix Klein",
            "Lars Ohnemus"
        ],
        "submitted": "2025-09-22 17:40:05",
        "source": "arxiv",
        "comment": "Work in Progess",
        "score": 5,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The use of Knowledge Graphs and Large Language Models for question answering aligns with your focus on deep semantic understanding and real-time relevance optimization. However, the specific application to Knowledge Graph Question Answering is somewhat outside your primary e-commerce domain focus."
    },
    {
        "title": "Specification-Aware Machine Translation and Evaluation for Purpose Alignment",
        "abstract": "In professional settings, translation is guided by communicative goals and\nclient needs, often formalized as specifications. While existing evaluation\nframeworks acknowledge the importance of such specifications, these\nspecifications are often treated only implicitly in machine translation (MT)\nresearch. Drawing on translation studies, we provide a theoretical rationale\nfor why specifications matter in professional translation, as well as a\npractical guide to implementing specification-aware MT and evaluation. Building\non this foundation, we apply our framework to the translation of investor\nrelations texts from 33 publicly listed companies. In our experiment, we\ncompare five translation types, including official human translations and\nprompt-based outputs from large language models (LLMs), using expert error\nanalysis, user preference rankings, and an automatic metric. The results show\nthat LLM translations guided by specifications consistently outperformed\nofficial human translations in human evaluations, highlighting a gap between\nperceived and expected quality. These findings demonstrate that integrating\nspecifications into MT workflows, with human oversight, can improve translation\nquality in ways aligned with professional practice.",
        "url": "http://arxiv.org/abs/2509.17559v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17559v1",
        "arxiv_id": "2509.17559v1",
        "authors": [
            "Yoko Kayano",
            "Saku Sugawara"
        ],
        "submitted": "2025-09-22 10:50:37",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on machine translation and evaluation, which is outside your primary research interests in Information Retrieval and Search technologies. While it touches on the concept of 'specifications' which could be related to query understanding, the context is not relevant to your core themes."
    },
    {
        "title": "FinDebate: Multi-Agent Collaborative Intelligence for Financial Analysis",
        "abstract": "We introduce FinDebate, a multi-agent framework for financial analysis,\nintegrating collaborative debate with domain-specific Retrieval-Augmented\nGeneration (RAG). Five specialized agents, covering earnings, market,\nsentiment, valuation, and risk, run in parallel to synthesize evidence into\nmulti-dimensional insights. To mitigate overconfidence and improve reliability,\nwe introduce a safe debate protocol that enables agents to challenge and refine\ninitial conclusions while preserving coherent recommendations. Experimental\nresults, based on both LLM-based and human evaluations, demonstrate the\nframework's efficacy in producing high-quality analysis with calibrated\nconfidence levels and actionable investment strategies across multiple time\nhorizons.",
        "url": "http://arxiv.org/abs/2509.17395v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17395v1",
        "arxiv_id": "2509.17395v1",
        "authors": [
            "Tianshi Cai",
            "Guanxu Li",
            "Nijia Han",
            "Ce Huang",
            "Zimu Wang",
            "Changyu Zeng",
            "Yuqi Wang",
            "Jingshi Zhou",
            "Haiyang Zhang",
            "Qi Chen",
            "Yushan Pan",
            "Shuihua Wang",
            "Wei Wang"
        ],
        "submitted": "2025-09-22 06:56:27",
        "source": "arxiv",
        "comment": "Accepted at FinNLP@EMNLP 2025. Camera-ready version",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on financial analysis and multi-agent collaboration, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it mentions Retrieval-Augmented Generation (RAG), it is applied in a specific domain (financial analysis) and does not seem to address the user's primary focus on deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Program Synthesis via Test-Time Transduction",
        "abstract": "We introduce transductive program synthesis, a new formulation of the program\nsynthesis task that explicitly leverages test inputs during synthesis. While\nprior approaches to program synthesis--whether based on natural language\ndescriptions or input-output examples--typically aim to generalize from\ntraining examples, they often struggle with robustness, especially in\nreal-world settings where training examples are limited and test inputs involve\nvarious edge cases. To address this, we propose a novel framework that improves\nrobustness by treating synthesis as an active learning over a finite hypothesis\nclass defined by programs' outputs. We use an LLM to predict outputs for\nselected test inputs and eliminate inconsistent hypotheses, where the inputs\nare chosen via a greedy maximin algorithm to minimize the number of LLM queries\nrequired. We evaluate our approach on four benchmarks: Playgol, MBPP+, 1D-ARC,\nand programmatic world modeling on MiniGrid. We demonstrate that our method\nsignificantly improves program synthesis in both accuracy and efficiency. We\nrelease our code at https://github.com/klee972/SYNTRA.",
        "url": "http://arxiv.org/abs/2509.17393v2",
        "pdf_url": "http://arxiv.org/pdf/2509.17393v2",
        "arxiv_id": "2509.17393v2",
        "authors": [
            "Kang-il Lee",
            "Jahyun Koo",
            "Seunghyun Yoon",
            "Minbeom Kim",
            "Hyukhun Koh",
            "Dongryeol Lee",
            "Kyomin Jung"
        ],
        "submitted": "2025-09-22 06:53:32",
        "source": "arxiv",
        "comment": "NeurIPS 2025",
        "score": 5,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on program synthesis, which is not directly related to the user's core research themes in Information Retrieval and Search technologies. While it involves a novel framework using an LLM, the context and application are distinct from the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "SeqUDA-Rec: Sequential User Behavior Enhanced Recommendation via Global Unsupervised Data Augmentation for Personalized Content Marketing",
        "abstract": "Personalized content marketing has become a crucial strategy for digital\nplatforms, aiming to deliver tailored advertisements and recommendations that\nmatch user preferences. Traditional recommendation systems often suffer from\ntwo limitations: (1) reliance on limited supervised signals derived from\nexplicit user feedback, and (2) vulnerability to noisy or unintentional\ninteractions. To address these challenges, we propose SeqUDA-Rec, a novel deep\nlearning framework that integrates user behavior sequences with global\nunsupervised data augmentation to enhance recommendation accuracy and\nrobustness. Our approach first constructs a Global User-Item Interaction Graph\n(GUIG) from all user behavior sequences, capturing both local and global item\nassociations. Then, a graph contrastive learning module is applied to generate\nrobust embeddings, while a sequential Transformer-based encoder models users'\nevolving preferences. To further enhance diversity and counteract sparse\nsupervised labels, we employ a GAN-based augmentation strategy, generating\nplausible interaction patterns and supplementing training data. Extensive\nexperiments on two real-world marketing datasets (Amazon Ads and TikTok Ad\nClicks) demonstrate that SeqUDA-Rec significantly outperforms state-of-the-art\nbaselines such as SASRec, BERT4Rec, and GCL4SR. Our model achieves a 6.7%\nimprovement in NDCG@10 and 11.3% improvement in HR@10, proving its\neffectiveness in personalized advertising and intelligent content\nrecommendation.",
        "url": "http://arxiv.org/abs/2509.17361v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17361v1",
        "arxiv_id": "2509.17361v1",
        "authors": [
            "Ruihan Luo",
            "Xuanjing Chen",
            "Ziyang Ding"
        ],
        "submitted": "2025-09-22 05:24:53",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'user behavior' (score: +2)",
            "Found 'click' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper SeqUDA-Rec is somewhat related to your research interests in Information Retrieval and recommendation systems, but it primarily focuses on recommendation accuracy and robustness in the context of personalized content marketing, which is not a central match to your interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "MLLM-Driven Semantic Identifier Generation for Generative Cross-Modal Retrieval",
        "abstract": "Generative cross-modal retrieval, which treats retrieval as a generation\ntask, has emerged as a promising direction with the rise of Multimodal Large\nLanguage Models (MLLMs). In this setting, the model responds to a text query by\ngenerating an identifier corresponding to the target image. However, existing\nmethods typically rely on manually crafted string IDs, clustering-based labels,\nor atomic identifiers requiring vocabulary expansion, all of which face\nchallenges in semantic alignment or scalability.To address these limitations,\nwe propose a vocabulary-efficient identifier generation framework that prompts\nMLLMs to generate Structured Semantic Identifiers from image-caption pairs.\nThese identifiers are composed of concept-level tokens such as objects and\nactions, naturally aligning with the model's generation space without modifying\nthe tokenizer. Additionally, we introduce a Rationale-Guided Supervision\nStrategy, prompting the model to produce a one-sentence explanation alongside\neach identifier serves as an auxiliary supervision signal that improves\nsemantic grounding and reduces hallucinations during training.",
        "url": "http://arxiv.org/abs/2509.17359v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17359v1",
        "arxiv_id": "2509.17359v1",
        "authors": [
            "Tianyuan Li",
            "Lei Wang",
            "Ahtamjan Ahmat",
            "Yating Yang",
            "Bo Ma",
            "Rui Dong",
            "Bangju Han"
        ],
        "submitted": "2025-09-22 05:23:06",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of multimodal retrieval and semantic understanding. However, the focus on Generative Cross-Modal Retrieval and Multimodal Large Language Models is not a central match to your primary research themes in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Identifying and Upweighting Power-Niche Users to Mitigate Popularity Bias in Recommendations",
        "abstract": "Recommender systems have been shown to exhibit popularity bias by\nover-recommending popular items and under-recommending relevant niche items. We\nseek to understand interactions with niche items in benchmark recommendation\ndatasets as a step toward mitigating popularity bias. We find that, compared to\nmainstream users, niche-preferring users exhibit a longer-tailed activity-level\ndistribution, indicating the existence of users who both prefer niche items and\nexhibit high activity levels. We partition users along two axes: (1) activity\nlevel (\"power\" vs. \"light\") and (2) item-popularity preference (\"mainstream\"\nvs. \"niche\"), and show that in several benchmark datasets, the number of\npower-niche users (high activity and niche preference) is statistically\nsignificantly larger than expected under a null configuration model. Motivated\nby this observation, we propose a framework for reweighting the Bayesian\nPersonalized Ranking (BPR) loss that simultaneously reweights based on user\nactivity level and item popularity. Our method introduces two interpretable\nparameters: one controlling the significance of user activity level, and the\nother of item popularity. Experiments on benchmark datasets show that\nupweighting power-niche users reduces popularity bias and can increase overall\nperformance. In contrast to previous work that only considers user activity\nlevel or item popularity in isolation, our results suggest that considering\ntheir interaction leads to Pareto-dominant performance.",
        "url": "http://arxiv.org/abs/2509.17265v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17265v1",
        "arxiv_id": "2509.17265v1",
        "authors": [
            "David Liu",
            "Erik Weis",
            "Moritz Laber",
            "Tina Eliassi-Rad",
            "Brennan Klein"
        ],
        "submitted": "2025-09-21 22:41:07",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to the user's research interests in Information Retrieval and recommender systems, but it focuses more on mitigating popularity bias in recommendations rather than query understanding, ranking models, or user behavior modeling. The paper's emphasis on recommender systems and user activity levels is somewhat tangential to the user's primary focus on IR and deep semantic understanding."
    },
    {
        "title": "Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications",
        "abstract": "The widespread adoption of Large Language Models (LLMs) has been hindered by\ntheir tendency to hallucinate, generating plausible but factually incorrect\ninformation. While Retrieval-Augmented Generation (RAG) systems attempt to\naddress this issue by grounding responses in external knowledge, hallucination\nremains a persistent challenge, particularly for morphologically complex,\nlow-resource languages like Turkish. This paper introduces Turk-LettuceDetect,\nthe first suite of hallucination detection models specifically designed for\nTurkish RAG applications. Building on the LettuceDetect framework, we formulate\nhallucination detection as a token-level classification task and fine-tune\nthree distinct encoder architectures: a Turkish-specific ModernBERT,\nTurkEmbed4STS, and multilingual EuroBERT. These models were trained on a\nmachine-translated version of the RAGTruth benchmark dataset containing 17,790\ninstances across question answering, data-to-text generation, and summarization\ntasks. Our experimental results show that the ModernBERT-based model achieves\nan F1-score of 0.7266 on the complete test set, with particularly strong\nperformance on structured tasks. The models maintain computational efficiency\nwhile supporting long contexts up to 8,192 tokens, making them suitable for\nreal-time deployment. Comparative analysis reveals that while state-of-the-art\nLLMs demonstrate high recall, they suffer from low precision due to\nover-generation of hallucinated content, underscoring the necessity of\nspecialized detection mechanisms. By releasing our models and translated\ndataset, this work addresses a critical gap in multilingual NLP and establishes\na foundation for developing more reliable and trustworthy AI applications for\nTurkish and other languages.",
        "url": "http://arxiv.org/abs/2509.17671v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17671v1",
        "arxiv_id": "2509.17671v1",
        "authors": [
            "Selva Taş",
            "Mahmut El Huseyni",
            "Özay Ezerceli",
            "Reyhan Bayraktar",
            "Fatma Betül Terzioğlu"
        ],
        "submitted": "2025-09-22 12:14:11",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "While the paper explores a relevant topic in NLP, it focuses on hallucination detection in Turkish RAG applications, which is somewhat related to query understanding and ranking models in IR. However, the paper's primary contribution is in the development of a hallucination detection model, which is not a central match to the user's core research themes."
    },
    {
        "title": "PG-CE: A Progressive Generation Dataset with Constraint Enhancement for Controllable Text Generation",
        "abstract": "With the rapid development of Large Language Models (LLMs), Controllable Text\nGeneration (CTG) has become a critical technology for enhancing system\nreliability and user experience. Addressing the limitations of traditional\nmethods, this paper proposes the PG-CE (Progressive Generation with Constraint\nEnhancement) approach, which decomposes CTG tasks into three steps: type\nprediction, constraint construction, and guided generation. This method employs\nconstraint generation models to dynamically build multi-dimensional constraints\nincluding tone, expression style, and thematic focus to guide output.\nExperiments demonstrate that PG-CE significantly improves generation quality\nacross multiple scenarios while maintaining text controllability, thematic\nrelevance, and response practicality. The research developed a dataset\ncontaining 90,000 constraint-text pairs (with an 8:2 ratio between daily and\nother topics), effectively reflecting real-world application requirements.",
        "url": "http://arxiv.org/abs/2509.17669v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17669v1",
        "arxiv_id": "2509.17669v1",
        "authors": [
            "Yan Zhuang",
            "Yuan Sun"
        ],
        "submitted": "2025-09-22 12:12:41",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Controllable Text Generation, which is a topic in Natural Language Processing (NLP), but it does not directly relate to Information Retrieval (IR), Search technologies, or query understanding, which are the core areas of your research interests."
    },
    {
        "title": "MSCoRe: A Benchmark for Multi-Stage Collaborative Reasoning in LLM Agents",
        "abstract": "Large Language Models (LLMs) have excelled in question-answering (QA) tasks\nwithin single domains. However, their reasoning and coordination capabilities\nin complex, multi-stage scenarios remain underexplored. Existing benchmarks\ntypically focus on isolated tasks or narrow domains, overlooking models'\nabilities for multi-stage collaboration and optimization without explicit\nexternal guidance. To bridge this gap, we propose \\textbf{MSCoRe}, a novel\nbenchmark comprising 126696 domain-specific QA instances spanning scenarios in\nautomotive, pharmaceutical, electronics, and energy sectors. The dataset is\ncreated using a structured three-phase pipeline: dynamic sampling, iterative\nquestion-answer generation, and a multi-level quality assessment to ensure data\nquality. Tasks are further categorized into three difficulty levels according\nto stage coverage and complexity. With MSCoRe, we have conducted a\ncomprehensive evaluation of various state-of-the-art LLM agents. The commercial\nmodels performed best across all tasks and scenarios, but a notable gap in\nROUGE scores remains between simple and complex tasks. We also tested the\nmodels' robustness and found that their performance is negatively affected by\nnoisy data. MSCoRe provides a valuable new resource for the community to\nevaluate and improve multi-stage reasoning in LLM agents. The code and data are\navailable at https://github.com/D3E0-source/MSCoRE.",
        "url": "http://arxiv.org/abs/2509.17628v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17628v1",
        "arxiv_id": "2509.17628v1",
        "authors": [
            "Yuzhen Lei",
            "Hongbin Xie",
            "Jiaxing Zhao",
            "Shuangxue Liu",
            "Xuan Song"
        ],
        "submitted": "2025-09-22 11:36:16",
        "source": "arxiv",
        "comment": "10 pages, 5 figures",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper MSCoRe is somewhat related to the user's interests in Natural Language Processing (NLP) and Large Language Models (LLMs), but it does not directly focus on query understanding, ranking models, or user behavior modeling in the context of information retrieval. The paper's emphasis on multi-stage collaborative reasoning in LLM agents is an interesting aspect, but it does not align with the user's primary focus on deep semantic understanding and real-time relevance optimization in IR."
    },
    {
        "title": "EpiCache: Episodic KV Cache Management for Long Conversational Question Answering",
        "abstract": "Recent advances in large language models (LLMs) have extended context\nlengths, enabling assistants to sustain long histories for coherent,\npersonalized responses. This ability, however, hinges on Key-Value (KV)\ncaching, whose memory grows linearly with dialogue length and quickly dominates\nunder strict resource constraints. An active line of research for reducing this\noverhead is KV cache compression, which seeks to limit cache size while\npreserving accuracy. Yet existing methods face two major limitations: (i)\nevicting entries after full-context prefill causes unbounded peak memory, and\n(ii) query-dependent eviction narrows the cache to a single query, leading to\ndegraded accuracy in multi-turn conversations. We introduce EpiCache, a\ntraining-free KV cache management framework for long conversational question\nanswering (LongConvQA) under fixed memory budgets. EpiCache bounds cache growth\nthrough block-wise prefill and preserves topic-relevant context via episodic KV\ncompression, which clusters conversation history into coherent episodes and\napplies episode-specific KV cache eviction. We further design an adaptive\nlayer-wise budget allocation strategy that measures each layer's sensitivity to\neviction and distributes the memory budget across layers accordingly. Across\nthree LongConvQA benchmarks, EpiCache improves accuracy by up to 40% over\nrecent baselines, sustains near-full KV accuracy under 4-6x compression, and\nreduces latency and memory by up to 2.4x and 3.5x, thereby enabling efficient\nmulti-turn interaction under strict resource constraints.",
        "url": "http://arxiv.org/abs/2509.17396v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17396v1",
        "arxiv_id": "2509.17396v1",
        "authors": [
            "Minsoo Kim",
            "Arnav Kundu",
            "Han-Byul Kim",
            "Richa Dixit",
            "Minsik Cho"
        ],
        "submitted": "2025-09-22 06:56:35",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Key-Value cache management for long conversational question answering, which is related to information retrieval and query understanding. However, it primarily deals with NLP and caching techniques, which, while relevant, do not directly align with the user's core research themes in IR and search technologies."
    },
    {
        "title": "Can Agents Judge Systematic Reviews Like Humans? Evaluating SLRs with LLM-based Multi-Agent System",
        "abstract": "Systematic Literature Reviews (SLRs) are foundational to evidence-based\nresearch but remain labor-intensive and prone to inconsistency across\ndisciplines. We present an LLM-based SLR evaluation copilot built on a\nMulti-Agent System (MAS) architecture to assist researchers in assessing the\noverall quality of the systematic literature reviews. The system automates\nprotocol validation, methodological assessment, and topic relevance checks\nusing a scholarly database. Unlike conventional single-agent methods, our\ndesign integrates a specialized agentic approach aligned with PRISMA guidelines\nto support more structured and interpretable evaluations. We conducted an\ninitial study on five published SLRs from diverse domains, comparing system\noutputs to expert-annotated PRISMA scores, and observed 84% agreement. While\nearly results are promising, this work represents a first step toward scalable\nand accurate NLP-driven systems for interdisciplinary workflows and reveals\ntheir capacity for rigorous, domain-agnostic knowledge aggregation to\nstreamline the review process.",
        "url": "http://arxiv.org/abs/2509.17240v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17240v1",
        "arxiv_id": "2509.17240v1",
        "authors": [
            "Abdullah Mushtaq",
            "Muhammad Rafay Naeem",
            "Ibrahim Ghaznavi",
            "Alaa Abd-alrazaq",
            "Aliya Tabassum",
            "Junaid Qadir"
        ],
        "submitted": "2025-09-21 21:17:23",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of evaluating and improving systematic literature reviews. However, the focus on Multi-Agent Systems and LLM-based evaluation copilot is not directly aligned with your core interests in query understanding, ranking models, and user behavior modeling. The connection to NLP is relevant, but the application is more focused on knowledge aggregation and review process streamlining."
    },
    {
        "title": "LifeAlign: Lifelong Alignment for Large Language Models with Memory-Augmented Focalized Preference Optimization",
        "abstract": "Alignment plays a crucial role in Large Language Models (LLMs) in aligning\nwith human preferences on a specific task/domain. Traditional alignment methods\nsuffer from catastrophic forgetting, where models lose previously acquired\nknowledge when adapting to new preferences or domains. We introduce LifeAlign,\na novel framework for lifelong alignment that enables LLMs to maintain\nconsistent human preference alignment across sequential learning tasks without\nforgetting previously learned knowledge. Our approach consists of two key\ninnovations. First, we propose a focalized preference optimization strategy\nthat aligns LLMs with new preferences while preventing the erosion of knowledge\nacquired from previous tasks. Second, we develop a short-to-long memory\nconsolidation mechanism that merges denoised short-term preference\nrepresentations into stable long-term memory using intrinsic dimensionality\nreduction, enabling efficient storage and retrieval of alignment patterns\nacross diverse domains. We evaluate LifeAlign across multiple sequential\nalignment tasks spanning different domains and preference types. Experimental\nresults demonstrate that our method achieves superior performance in\nmaintaining both preference alignment quality and knowledge retention compared\nto existing lifelong learning approaches. The codes and datasets will be\nreleased on GitHub.",
        "url": "http://arxiv.org/abs/2509.17183v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17183v1",
        "arxiv_id": "2509.17183v1",
        "authors": [
            "Junsong Li",
            "Jie Zhou",
            "Bihao Zhan",
            "Yutao Yang",
            "Qianjun Pan",
            "Shilian Chen",
            "Tianyu Huai",
            "Xin Li",
            "Qin Chen",
            "Liang He"
        ],
        "submitted": "2025-09-21 18:06:05",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on lifelong alignment for Large Language Models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on language models and preference alignment does not directly align with the user's core research themes in IR and Search technologies. The paper's relevance is mostly in the broader context of NLP and related topics."
    },
    {
        "title": "Cross-Attention is Half Explanation in Speech-to-Text Models",
        "abstract": "Cross-attention is a core mechanism in encoder-decoder architectures,\nwidespread in many fields, including speech-to-text (S2T) processing. Its\nscores have been repurposed for various downstream applications--such as\ntimestamp estimation and audio-text alignment--under the assumption that they\nreflect the dependencies between input speech representation and the generated\ntext. While the explanatory nature of attention mechanisms has been widely\ndebated in the broader NLP literature, this assumption remains largely\nunexplored within the speech domain. To address this gap, we assess the\nexplanatory power of cross-attention in S2T models by comparing its scores to\ninput saliency maps derived from feature attribution. Our analysis spans\nmonolingual and multilingual, single-task and multi-task models at multiple\nscales, and shows that attention scores moderately to strongly align with\nsaliency-based explanations, particularly when aggregated across heads and\nlayers. However, it also shows that cross-attention captures only about 50% of\nthe input relevance and, in the best case, only partially reflects how the\ndecoder attends to the encoder's representations--accounting for just 52-75% of\nthe saliency. These findings uncover fundamental limitations in interpreting\ncross-attention as an explanatory proxy, suggesting that it offers an\ninformative yet incomplete view of the factors driving predictions in S2T\nmodels.",
        "url": "http://arxiv.org/abs/2509.18010v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18010v1",
        "arxiv_id": "2509.18010v1",
        "authors": [
            "Sara Papi",
            "Dennis Fucci",
            "Marco Gaido",
            "Matteo Negri",
            "Luisa Bentivogli"
        ],
        "submitted": "2025-09-22 16:49:26",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the explanatory power of cross-attention in speech-to-text models, which is a topic within NLP. While it touches on attention mechanisms, it does not directly relate to query understanding, ranking models, or user behavior modeling in information retrieval, which are your core research interests."
    },
    {
        "title": "D-REX: A Benchmark for Detecting Deceptive Reasoning in Large Language Models",
        "abstract": "The safety and alignment of Large Language Models (LLMs) are critical for\ntheir responsible deployment. Current evaluation methods predominantly focus on\nidentifying and preventing overtly harmful outputs. However, they often fail to\naddress a more insidious failure mode: models that produce benign-appearing\noutputs while operating on malicious or deceptive internal reasoning. This\nvulnerability, often triggered by sophisticated system prompt injections,\nallows models to bypass conventional safety filters, posing a significant,\nunderexplored risk. To address this gap, we introduce the Deceptive Reasoning\nExposure Suite (D-REX), a novel dataset designed to evaluate the discrepancy\nbetween a model's internal reasoning process and its final output. D-REX was\nconstructed through a competitive red-teaming exercise where participants\ncrafted adversarial system prompts to induce such deceptive behaviors. Each\nsample in D-REX contains the adversarial system prompt, an end-user's test\nquery, the model's seemingly innocuous response, and, crucially, the model's\ninternal chain-of-thought, which reveals the underlying malicious intent. Our\nbenchmark facilitates a new, essential evaluation task: the detection of\ndeceptive alignment. We demonstrate that D-REX presents a significant challenge\nfor existing models and safety mechanisms, highlighting the urgent need for new\ntechniques that scrutinize the internal processes of LLMs, not just their final\noutputs.",
        "url": "http://arxiv.org/abs/2509.17938v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17938v1",
        "arxiv_id": "2509.17938v1",
        "authors": [
            "Satyapriya Krishna",
            "Andy Zou",
            "Rahul Gupta",
            "Eliot Krzysztof Jones",
            "Nick Winter",
            "Dan Hendrycks",
            "J. Zico Kolter",
            "Matt Fredrikson",
            "Spyros Matsoukas"
        ],
        "submitted": "2025-09-22 15:59:40",
        "source": "arxiv",
        "comment": "Preprint",
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your core research interests in Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling. While it touches on the topic of Large Language Models, which is a related area, the focus on detecting deceptive reasoning in LLMs is not a central match for your research themes."
    },
    {
        "title": "Training-free Truthfulness Detection via Value Vectors in LLMs",
        "abstract": "Large language models often generate factually incorrect outputs, motivating\nefforts to detect the truthfulness of their content. Most existing approaches\nrely on training probes over internal activations, but these methods suffer\nfrom scalability and generalization issues. A recent training-free method,\nNoVo, addresses this challenge by exploiting statistical patterns from the\nmodel itself. However, it focuses exclusively on attention mechanisms,\npotentially overlooking the MLP module-a core component of Transformer models\nknown to support factual recall. In this paper, we show that certain value\nvectors within MLP modules exhibit truthfulness-related statistical patterns.\nBuilding on this insight, we propose TruthV, a simple and interpretable\ntraining-free method that detects content truthfulness by leveraging these\nvalue vectors. On the NoVo benchmark, TruthV significantly outperforms both\nNoVo and log-likelihood baselines, demonstrating that MLP modules-despite being\nneglected in prior training-free efforts-encode rich and useful signals for\ntruthfulness detection. These findings offer new insights into how truthfulness\nis internally represented in LLMs and motivate further research on scalable and\ninterpretable truthfulness detection.",
        "url": "http://arxiv.org/abs/2509.17932v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17932v1",
        "arxiv_id": "2509.17932v1",
        "authors": [
            "Runheng Liu",
            "Heyan Huang",
            "Xingchen Xiao",
            "Zhijing Wu"
        ],
        "submitted": "2025-09-22 15:54:29",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores truthfulness detection in Large Language Models (LLMs), which is a related topic to Natural Language Processing (NLP). However, it does not directly relate to Information Retrieval (IR), query understanding, ranking models, or user behavior modeling, which are the user's core research themes."
    },
    {
        "title": "How Persuasive is Your Context?",
        "abstract": "Two central capabilities of language models (LMs) are: (i) drawing on prior\nknowledge about entities, which allows them to answer queries such as \"What's\nthe official language of Austria?\", and (ii) adapting to new information\nprovided in context, e.g., \"Pretend the official language of Austria is\nTagalog.\", that is pre-pended to the question. In this article, we introduce\ntargeted persuasion score (TPS), designed to quantify how persuasive a given\ncontext is to an LM where persuasion is operationalized as the ability of the\ncontext to alter the LM's answer to the question. In contrast to evaluating\npersuasiveness only by inspecting the greedily decoded answer under the model,\nTPS provides a more fine-grained view of model behavior. Based on the\nWasserstein distance, TPS measures how much a context shifts a model's original\nanswer distribution toward a target distribution. Empirically, through a series\nof experiments, we show that TPS captures a more nuanced notion of\npersuasiveness than previously proposed metrics.",
        "url": "http://arxiv.org/abs/2509.17879v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17879v1",
        "arxiv_id": "2509.17879v1",
        "authors": [
            "Tu Nguyen",
            "Kevin Du",
            "Alexander Miserlis Hoyle",
            "Ryan Cotterell"
        ],
        "submitted": "2025-09-22 15:15:40",
        "source": "arxiv",
        "comment": "Long paper accepted at EMNLP 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores language model behavior and introduces a new metric for measuring persuasion, which is related to query understanding and model behavior modeling. However, it does not directly focus on information retrieval, ranking models, or recommender systems, which are core areas of your research interests."
    },
    {
        "title": "Qwen3-Omni Technical Report",
        "abstract": "We present Qwen3-Omni, a single multimodal model that, for the first time,\nmaintains state-of-the-art performance across text, image, audio, and video\nwithout any degradation relative to single-modal counterparts. Qwen3-Omni\nmatches the performance of same-sized single-modal models within the Qwen\nseries and excels particularly on audio tasks. Across 36 audio and audio-visual\nbenchmarks, Qwen3-Omni achieves open-source SOTA on 32 benchmarks and overall\nSOTA on 22, outperforming strong closed-source models such as Gemini-2.5-Pro,\nSeed-ASR, and GPT-4o-Transcribe. Qwen3-Omni adopts a Thinker-Talker MoE\narchitecture that unifies perception and generation across text, images, audio,\nand video, yielding fluent text and natural real-time speech. It supports text\ninteraction in 119 languages, speech understanding in 19 languages, and speech\ngeneration in 10 languages. To reduce first-packet latency in streaming\nsynthesis, Talker autoregressively predicts discrete speech codecs using a\nmulti-codebook scheme. Leveraging the representational capacity of these\ncodebooks, we replace computationally intensive block-wise diffusion with a\nlightweight causal ConvNet, enabling streaming from the first codec frame. In\ncold-start settings, Qwen3-Omni achieves a theoretical end-to-end first-packet\nlatency of 234 ms. To further strengthen multimodal reasoning, we introduce a\nThinking model that explicitly reasons over inputs from any modality. Since the\nresearch community currently lacks a general-purpose audio captioning model, we\nfine-tuned Qwen3-Omni-30B-A3B to obtain Qwen3-Omni-30B-A3B-Captioner, which\nproduces detailed, low-hallucination captions for arbitrary audio inputs.\nQwen3-Omni-30B-A3B, Qwen3-Omni-30B-A3B-Thinking, and\nQwen3-Omni-30B-A3B-Captioner are publicly released under the Apache 2.0\nlicense.",
        "url": "http://arxiv.org/abs/2509.17765v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17765v1",
        "arxiv_id": "2509.17765v1",
        "authors": [
            "Jin Xu",
            "Zhifang Guo",
            "Hangrui Hu",
            "Yunfei Chu",
            "Xiong Wang",
            "Jinzheng He",
            "Yuxuan Wang",
            "Xian Shi",
            "Ting He",
            "Xinfa Zhu",
            "Yuanjun Lv",
            "Yongqi Wang",
            "Dake Guo",
            "He Wang",
            "Linhan Ma",
            "Pei Zhang",
            "Xinyu Zhang",
            "Hongkun Hao",
            "Zishan Guo",
            "Baosong Yang",
            "Bin Zhang",
            "Ziyang Ma",
            "Xipin Wei",
            "Shuai Bai",
            "Keqin Chen",
            "Xuejing Liu",
            "Peng Wang",
            "Mingkun Yang",
            "Dayiheng Liu",
            "Xingzhang Ren",
            "Bo Zheng",
            "Rui Men",
            "Fan Zhou",
            "Bowen Yu",
            "Jianxin Yang",
            "Le Yu",
            "Jingren Zhou",
            "Junyang Lin"
        ],
        "submitted": "2025-09-22 13:26:24",
        "source": "arxiv",
        "comment": "https://github.com/QwenLM/Qwen3-Omni",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper presents a multimodal model for text, image, audio, and video tasks, but it does not appear to be directly related to information retrieval, search technologies, or query understanding. While it does involve natural language processing, the focus is on multimodal perception and generation rather than deep semantic understanding or real-time relevance optimization."
    },
    {
        "title": "Evaluating LLM-Generated Versus Human-Authored Responses in Role-Play Dialogues",
        "abstract": "Evaluating large language models (LLMs) in long-form, knowledge-grounded\nrole-play dialogues remains challenging. This study compares LLM-generated and\nhuman-authored responses in multi-turn professional training simulations\nthrough human evaluation ($N=38$) and automated LLM-as-a-judge assessment.\nHuman evaluation revealed significant degradation in LLM-generated response\nquality across turns, particularly in naturalness, context maintenance and\noverall quality, while human-authored responses progressively improved. In line\nwith this finding, participants also indicated a consistent preference for\nhuman-authored dialogue. These human judgements were validated by our automated\nLLM-as-a-judge evaluation, where Gemini 2.0 Flash achieved strong alignment\nwith human evaluators on both zero-shot pairwise preference and stochastic\n6-shot construct ratings, confirming the widening quality gap between LLM and\nhuman responses over time. Our work contributes a multi-turn benchmark exposing\nLLM degradation in knowledge-grounded role-play dialogues and provides a\nvalidated hybrid evaluation framework to guide the reliable integration of LLMs\nin training simulations.",
        "url": "http://arxiv.org/abs/2509.17694v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17694v1",
        "arxiv_id": "2509.17694v1",
        "authors": [
            "Dongxu Lu",
            "Johan Jeuring",
            "Albert Gatt"
        ],
        "submitted": "2025-09-22 12:33:02",
        "source": "arxiv",
        "comment": "Accepted for publication at the 18th International Natural Language\n  Generation Conference (INLG 2025)",
        "score": 3,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and related topics, but it does not directly align with your primary focus on Information Retrieval, especially in areas requiring deep semantic understanding and real-time relevance optimization. The paper explores the evaluation of large language models in role-play dialogues, which is a specific application of NLP. While it may have some indirect implications for search technologies, it is not a central match for your research interests."
    },
    {
        "title": "TASO: Task-Aligned Sparse Optimization for Parameter-Efficient Model Adaptation",
        "abstract": "LoRA has become one of the most widely used parameter-efficient fine-tuning\nmethods due to its simplicity and effectiveness. However, numerous studies have\nshown that LoRA often introduces substantial parameter redundancy, which not\nonly increases the number of trainable parameters but also hinders the\neffectiveness of fine-tuning. Since identifying redundant parameters in LoRA is\ninherently difficult, how to eliminate them efficiently and accurately remains\na challenging problem. In this paper, we propose TASO, a redundancy reduction\nmethod that leverages importance information from the pretrained model's\nweights to mitigate LoRA redundancy. Specifically, we estimate parameter\nimportance on downstream tasks and identify task-specific core regions based on\nthe distribution of importance scores. The location information of these core\nregions is then used to determine the sparse structure of LoRA modules,\nenabling redundancy removal before fine-tuning. Our approach significantly\nreduces the number of trainable parameters required for task adaptation, while\nproviding a novel task-aligned perspective for LoRA redundancy reduction.\nExperimental results demonstrate that, with a parameter budget comparable to\nLoRA with rank $r = 1$, TASO consistently outperforms standard LoRA across\nmultiple tasks, achieving strong fine-tuning performance while effectively\neliminating redundant parameters.",
        "url": "http://arxiv.org/abs/2509.17688v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17688v1",
        "arxiv_id": "2509.17688v1",
        "authors": [
            "Daiye Miao",
            "Yufang Liu",
            "Jie Wang",
            "Changzhi Sun",
            "Yunke Zhang",
            "Demei Yan",
            "Shaokang Dong",
            "Qi Zhang",
            "Yuanbin Wu"
        ],
        "submitted": "2025-09-22 12:29:43",
        "source": "arxiv",
        "comment": "Accepted to EMNLP 2025 (Main Conference),13 pages,10 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on parameter-efficient model adaptation using LoRA, which is not directly related to information retrieval, query understanding, or ranking models. While it involves fine-tuning and model adaptation, the context is more aligned with deep learning and model optimization, rather than search technologies or user behavior modeling."
    },
    {
        "title": "When TableQA Meets Noise: A Dual Denoising Framework for Complex Questions and Large-scale Tables",
        "abstract": "Table question answering (TableQA) is a fundamental task in natural language\nprocessing (NLP). The strong reasoning capabilities of large language models\n(LLMs) have brought significant advances in this field. However, as real-world\napplications involve increasingly complex questions and larger tables,\nsubstantial noisy data is introduced, which severely degrades reasoning\nperformance. To address this challenge, we focus on improving two core\ncapabilities: Relevance Filtering, which identifies and retains information\ntruly relevant to reasoning, and Table Pruning, which reduces table size while\npreserving essential content. Based on these principles, we propose EnoTab, a\ndual denoising framework for complex questions and large-scale tables.\nSpecifically, we first perform Evidence-based Question Denoising by decomposing\nthe question into minimal semantic units and filtering out those irrelevant to\nanswer reasoning based on consistency and usability criteria. Then, we propose\nEvidence Tree-guided Table Denoising, which constructs an explicit and\ntransparent table pruning path to remove irrelevant data step by step. At each\npruning step, we observe the intermediate state of the table and apply a\npost-order node rollback mechanism to handle abnormal table states, ultimately\nproducing a highly reliable sub-table for final answer reasoning. Finally,\nextensive experiments show that EnoTab achieves outstanding performance on\nTableQA tasks with complex questions and large-scale tables, confirming its\neffectiveness.",
        "url": "http://arxiv.org/abs/2509.17680v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17680v1",
        "arxiv_id": "2509.17680v1",
        "authors": [
            "Shenghao Ye",
            "Yu Guo",
            "Dong Jin",
            "Yikai Shen",
            "Yunpeng Hou",
            "Shuangwu Chen",
            "Jian Yang",
            "Xiaofeng Jiang"
        ],
        "submitted": "2025-09-22 12:25:57",
        "source": "arxiv",
        "comment": "23 pages, 24 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Table Question Answering (TableQA), a task in NLP, and proposes a dual denoising framework to address noisy data. While it involves query understanding and relevance filtering, it is not directly related to the user's core research themes in Information Retrieval and Search technologies. The paper's emphasis on NLP and table pruning is somewhat relevant, but it does not align with the user's primary focus on deep semantic understanding and real-time relevance optimization in IR."
    },
    {
        "title": "SLAyiNG: Towards Queer Language Processing",
        "abstract": "Knowledge of slang is a desirable feature of LLMs in the context of user\ninteraction, as slang often reflects an individual's social identity. Several\nworks on informal language processing have defined and curated benchmarks for\ntasks such as detection and identification of slang. In this paper, we focus on\nqueer slang. Queer slang can be mistakenly flagged as hate speech or can evoke\nnegative responses from LLMs during user interaction. Research efforts so far\nhave not focused explicitly on queer slang. In particular, detection and\nprocessing of queer slang have not been thoroughly evaluated due to the lack of\na high-quality annotated benchmark. To address this gap, we curate SLAyiNG, the\nfirst dataset containing annotated queer slang derived from subtitles, social\nmedia posts, and podcasts, reflecting real-world usage. We describe our data\ncuration process, including the collection of slang terms and definitions,\nscraping sources for examples that reflect usage of these terms, and our\nongoing annotation process. As preliminary results, we calculate\ninter-annotator agreement for human annotators and OpenAI's model o3-mini,\nevaluating performance on the task of sense disambiguation. Reaching an average\nKrippendorff's alpha of 0.746, we argue that state-of-the-art reasoning models\ncan serve as tools for pre-filtering, but the complex and often sensitive\nnature of queer language data requires expert and community-driven annotation\nefforts.",
        "url": "http://arxiv.org/abs/2509.17449v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17449v1",
        "arxiv_id": "2509.17449v1",
        "authors": [
            "Leonor Veloso",
            "Lea Hirlimann",
            "Philipp Wicke",
            "Hinrich Schütze"
        ],
        "submitted": "2025-09-22 07:41:45",
        "source": "arxiv",
        "comment": "To be presented at Queer in AI @ NeurIPS 2025 (non-archival)",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on queer language processing, which is not a central theme in your research interests. While it involves natural language processing, it is not directly related to information retrieval, query understanding, or ranking models, which are your primary areas of focus."
    },
    {
        "title": "LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code",
        "abstract": "Increasing complexity in software systems places a growing demand on\nreasoning tools that unlock vulnerabilities manifest in source code. Many\ncurrent approaches focus on vulnerability analysis as a classifying task,\noversimplifying the nuanced and context-dependent real-world scenarios. Even\nthough current code large language models (LLMs) excel in code understanding,\nthey often pay little attention to security-specific reasoning. We propose\nLLaVul, a multimodal LLM tailored to provide fine-grained reasoning about code\nthrough question-answering (QA). Our model is trained to integrate paired code\nand natural queries into a unified space, enhancing reasoning and\ncontext-dependent insights about code vulnerability. To evaluate our model\nperformance, we construct a curated dataset of real-world vulnerabilities\npaired with security-focused questions and answers. Our model outperforms\nstate-of-the-art general-purpose and code LLMs in the QA and detection tasks.\nWe further explain decision-making by conducting qualitative analysis to\nhighlight capabilities and limitations. By integrating code and QA, LLaVul\nenables more interpretable and security-focused code understanding.",
        "url": "http://arxiv.org/abs/2509.17337v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17337v1",
        "arxiv_id": "2509.17337v1",
        "authors": [
            "Ala Jararweh",
            "Michael Adams",
            "Avinash Sahu",
            "Abdullah Mueen",
            "Afsah Anwar"
        ],
        "submitted": "2025-09-22 03:14:22",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on source code analysis and vulnerability reasoning, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves question-answering and multimodal LLMs, the context is specific to software systems and security, making it somewhat tangential to the user's interests."
    },
    {
        "title": "Probabilistic Token Alignment for Large Language Model Fusion",
        "abstract": "Training large language models (LLMs) from scratch can yield models with\nunique functionalities and strengths, but it is costly and often leads to\nredundant capabilities. A more cost-effective alternative is to fuse existing\npre-trained LLMs with different architectures into a more powerful model.\nHowever, a key challenge in existing model fusion is their dependence on\nmanually predefined vocabulary alignment, which may not generalize well across\ndiverse contexts, leading to performance degradation in several evaluation. To\nsolve this, we draw inspiration from distribution learning and propose the\nprobabilistic token alignment method as a general and soft mapping for\nalignment, named as PTA-LLM. Our approach innovatively reformulates token\nalignment into a classic mathematical problem: optimal transport, seamlessly\nleveraging distribution-aware learning to facilitate more coherent model\nfusion. Apart from its inherent generality, PTA-LLM exhibits interpretability\nfrom a distributional perspective, offering insights into the essence of the\ntoken alignment. Empirical results demonstrate that probabilistic token\nalignment enhances the target model's performance across multiple capabilities.\nOur code is avaliable at https://runjia.tech/neurips_pta-llm/.",
        "url": "http://arxiv.org/abs/2509.17276v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17276v1",
        "arxiv_id": "2509.17276v1",
        "authors": [
            "Runjia Zeng",
            "James Chenhao Liang",
            "Cheng Han",
            "Zhiwen Cao",
            "Jiahao Liu",
            "Xiaojun Quan",
            "Yingjie Victor Chen",
            "Lifu Huang",
            "Tong Geng",
            "Qifan Wang",
            "Dongfang Liu"
        ],
        "submitted": "2025-09-21 23:18:24",
        "source": "arxiv",
        "comment": "NeurIPS 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'neurips' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on large language model fusion, which is not a core area of interest for you. While it involves some NLP concepts, it doesn't directly relate to your primary focus on information retrieval, query understanding, and ranking models."
    },
    {
        "title": "Spiffy: Multiplying Diffusion LLM Acceleration via Lossless Speculative Decoding",
        "abstract": "Diffusion LLMs (dLLMs) have recently emerged as a powerful alternative to\nautoregressive LLMs (AR-LLMs) with the potential to operate at significantly\nhigher token generation rates. However, currently available open-source dLLMs\noften generate at much lower rates, typically decoding only a single token at\nevery denoising timestep in order to maximize output quality. We present\nSpiffy, a speculative decoding algorithm that accelerates dLLM inference by\n$\\mathbf{2.8{-}3.1\\times}$ while provably preserving the model's output\ndistribution. This work addresses the unique challenges involved in applying\nideas from speculative decoding of AR-LLMs to the dLLM setting. Spiffy proposes\ndraft states by leveraging the dLLM's distribution itself in an\nauto-speculative manner. This approach is efficient and effective, and\neliminates the overheads of training and running an independent draft model. To\nstructure the candidate draft states, we propose a novel directed draft graph\nwhich is uniquely designed to take advantage of the bidirectional, block-wise\nnature of dLLM generation and can be verified in parallel by the dLLM. To\nfurther optimize the structure of these draft graphs, we introduce an\nefficient, offline calibration algorithm that procedurally determines\nhigh-quality graph configurations. These optimized draft graphs, enabling\nincreased acceptance rates, lead to a significant boost in the overall speedup\nachieved by the system. Crucially, Spiffy is also complementary to other recent\ninnovations in improving dLLM generation speeds such as KV-caching and\nmulti-token unmasking. We demonstrate that when combined with such parallel\ndecoding algorithms, Spiffy is able to effectively multiply the benefits of\nthese methods leading to total speedups of up to $\\mathbf{7.9\\times}$.",
        "url": "http://arxiv.org/abs/2509.18085v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18085v1",
        "arxiv_id": "2509.18085v1",
        "authors": [
            "Sudhanshu Agrawal",
            "Risheek Garrepalli",
            "Raghavv Goel",
            "Mingu Lee",
            "Christopher Lott",
            "Fatih Porikli"
        ],
        "submitted": "2025-09-22 17:58:21",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper focuses on accelerating diffusion LLMs using speculative decoding, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves deep learning and NLP, the topic is more aligned with model acceleration and optimization rather than query understanding or ranking models."
    },
    {
        "title": "RadEval: A framework for radiology text evaluation",
        "abstract": "We introduce RadEval, a unified, open-source framework for evaluating\nradiology texts. RadEval consolidates a diverse range of metrics, from classic\nn-gram overlap (BLEU, ROUGE) and contextual measures (BERTScore) to clinical\nconcept-based scores (F1CheXbert, F1RadGraph, RaTEScore, SRR-BERT,\nTemporalEntityF1) and advanced LLM-based evaluators (GREEN). We refine and\nstandardize implementations, extend GREEN to support multiple imaging\nmodalities with a more lightweight model, and pretrain a domain-specific\nradiology encoder, demonstrating strong zero-shot retrieval performance. We\nalso release a richly annotated expert dataset with over 450 clinically\nsignificant error labels and show how different metrics correlate with\nradiologist judgment. Finally, RadEval provides statistical testing tools and\nbaseline model evaluations across multiple publicly available datasets,\nfacilitating reproducibility and robust benchmarking in radiology report\ngeneration.",
        "url": "http://arxiv.org/abs/2509.18030v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18030v1",
        "arxiv_id": "2509.18030v1",
        "authors": [
            "Justin Xu",
            "Xi Zhang",
            "Javid Abderezaei",
            "Julie Bauml",
            "Roger Boodoo",
            "Fatemeh Haghighi",
            "Ali Ganjizadeh",
            "Eric Brattain",
            "Dave Van Veen",
            "Zaiqiao Meng",
            "David Eyre",
            "Jean-Benoit Delbrouck"
        ],
        "submitted": "2025-09-22 17:03:48",
        "source": "arxiv",
        "comment": "Accepted to EMNLP 2025 Demo track - Oral",
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your core research themes in Information Retrieval, Search technologies, or Natural Language Processing. Although it involves text evaluation and uses some NLP metrics, its focus on radiology text evaluation and clinical concept-based scores makes it less relevant to your interests."
    },
    {
        "title": "From Documents to Database: Failure Modes for Industrial Assets",
        "abstract": "We propose an interactive system using foundation models and user-provided\ntechnical documents to generate Failure Mode and Effects Analyses (FMEA) for\nindustrial equipment. Our system aggregates unstructured content across\ndocuments to generate an FMEA and stores it in a relational database.\nLeveraging this tool, the time required for creation of this\nknowledge-intensive content is reduced, outperforming traditional manual\napproaches. This demonstration showcases the potential of foundation models to\nfacilitate the creation of specialized structured content for enterprise asset\nmanagement systems.",
        "url": "http://arxiv.org/abs/2509.17834v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17834v1",
        "arxiv_id": "2509.17834v1",
        "authors": [
            "Duygu Kabakci-Zorlu",
            "Fabio Lorenzi",
            "John Sheehan",
            "Karol Lynch",
            "Bradley Eck"
        ],
        "submitted": "2025-09-22 14:23:50",
        "source": "arxiv",
        "comment": "7 pages, 4 figures. Artificial Intelligence for Knowledge Acquisition\n  & Management (AI4KAM) Workshop @ IJCAI 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on industrial asset management and the application of foundation models in generating Failure Mode and Effects Analyses (FMEA). While it involves information retrieval and aggregation of unstructured content, it does not align with the user's primary research interests in query understanding, ranking models, and user behavior modeling in the context of search technologies and e-commerce. The paper's focus on industrial asset management and FMEA is not directly related to the user's core research themes."
    },
    {
        "title": "Fine-Grained Detection of AI-Generated Text Using Sentence-Level Segmentation",
        "abstract": "Generation of Artificial Intelligence (AI) texts in important works has\nbecome a common practice that can be used to misuse and abuse AI at various\nlevels. Traditional AI detectors often rely on document-level classification,\nwhich struggles to identify AI content in hybrid or slightly edited texts\ndesigned to avoid detection, leading to concerns about the model's efficiency,\nwhich makes it hard to distinguish between human-written and AI-generated\ntexts. A sentence-level sequence labeling model proposed to detect transitions\nbetween human- and AI-generated text, leveraging nuanced linguistic signals\noverlooked by document-level classifiers. By this method, detecting and\nsegmenting AI and human-written text within a single document at the\ntoken-level granularity is achieved. Our model combines the state-of-the-art\npre-trained Transformer models, incorporating Neural Networks (NN) and\nConditional Random Fields (CRFs). This approach extends the power of\ntransformers to extract semantic and syntactic patterns, and the neural network\ncomponent to capture enhanced sequence-level representations, thereby improving\nthe boundary predictions by the CRF layer, which enhances sequence recognition\nand further identification of the partition between Human- and AI-generated\ntexts. The evaluation is performed on two publicly available benchmark datasets\ncontaining collaborative human and AI-generated texts. Our experimental\ncomparisons are with zero-shot detectors and the existing state-of-the-art\nmodels, along with rigorous ablation studies to justify that this approach, in\nparticular, can accurately detect the spans of AI texts in a completely\ncollaborative text. All our source code and the processed datasets are\navailable in our GitHub repository.",
        "url": "http://arxiv.org/abs/2509.17830v2",
        "pdf_url": "http://arxiv.org/pdf/2509.17830v2",
        "arxiv_id": "2509.17830v2",
        "authors": [
            "Lekkala Sai Teja",
            "Annepaka Yadagiri",
            "Partha Pakray",
            "Chukhu Chunka",
            "Mangadoddi Srikar Vardhan"
        ],
        "submitted": "2025-09-22 14:22:55",
        "source": "arxiv",
        "comment": "14 pages, 14 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on AI-generated text detection, which is not a core area of interest for you. While it involves NLP and deep semantic understanding, the context is not related to information retrieval or search technologies."
    },
    {
        "title": "Findings of the Fourth Shared Task on Multilingual Coreference Resolution: Can LLMs Dethrone Traditional Approaches?",
        "abstract": "The paper presents an overview of the fourth edition of the Shared Task on\nMultilingual Coreference Resolution, organized as part of the CODI-CRAC 2025\nworkshop. As in the previous editions, participants were challenged to develop\nsystems that identify mentions and cluster them according to identity\ncoreference.\n  A key innovation of this year's task was the introduction of a dedicated\nLarge Language Model (LLM) track, featuring a simplified plaintext format\ndesigned to be more suitable for LLMs than the original CoNLL-U representation.\n  The task also expanded its coverage with three new datasets in two additional\nlanguages, using version 1.3 of CorefUD - a harmonized multilingual collection\nof 22 datasets in 17 languages.\n  In total, nine systems participated, including four LLM-based approaches (two\nfine-tuned and two using few-shot adaptation). While traditional systems still\nkept the lead, LLMs showed clear potential, suggesting they may soon challenge\nestablished approaches in future editions.",
        "url": "http://arxiv.org/abs/2509.17796v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17796v1",
        "arxiv_id": "2509.17796v1",
        "authors": [
            "Michal Novák",
            "Miloslav Konopík",
            "Anna Nedoluzhko",
            "Martin Popel",
            "Ondřej Pražák",
            "Jakub Sido",
            "Milan Straka",
            "Zdeněk Žabokrtský",
            "Daniel Zeman"
        ],
        "submitted": "2025-09-22 13:52:32",
        "source": "arxiv",
        "comment": "Accepted to CODI-CRAC 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to the user's interests in Natural Language Processing (NLP) and deep semantic understanding, but it is not directly focused on Information Retrieval (IR), query understanding, or ranking models. The topic of multilingual coreference resolution is relevant to NLP, but it is not a primary area of focus for the user. The paper's findings on the potential of Large Language Models (LLMs) may be of interest, but it is not a central match for the user's research interests."
    },
    {
        "title": "One Agent to Serve All: a Lite-Adaptive Stylized AI Assistant for Millions of Multi-Style Official Accounts",
        "abstract": "Conversational agents deployed in industrial-scale official account platforms\nmust generate responses that are both contextually grounded and stylistically\naligned-requirements that existing methods struggle to meet. Chain-of-thought\n(CoT) prompting induces significant latency due to multi-turn reasoning;\nper-account fine-tuning is computationally prohibitive; and long prompt-based\nmethods degrade the model's ability to grasp injected context and style. In\nthis paper, we propose WeStar, a lite-adaptive framework for stylized\ncontextual question answering that scales to millions of official accounts.\nWeStar combines context-grounded generation via RAG with style-aware generation\nusing Parametric RAG (PRAG), where LoRA modules are dynamically activated per\nstyle cluster. Our contributions are fourfold: (1) We introduce WeStar, a\nunified framework capable of serving large volumes of official accounts with\nminimal overhead. (2) We propose a multi-dimensional, cluster-based parameter\nsharing scheme that enables compact style representation while preserving\nstylistic diversity. (3) We develop a style-enhanced Direct Preference\nOptimization (SeDPO) method to optimize each style cluster's parameters for\nimproved generation quality. (4) Experiments on a large-scale industrial\ndataset validate the effectiveness and efficiency of WeStar, underscoring its\npracitical value in real-world deployment.",
        "url": "http://arxiv.org/abs/2509.17788v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17788v1",
        "arxiv_id": "2509.17788v1",
        "authors": [
            "Xingyu Fan",
            "Feifei Li",
            "Wenhui Que",
            "Hailong Li"
        ],
        "submitted": "2025-09-22 13:49:37",
        "source": "arxiv",
        "comment": "7 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on conversational agents and stylized contextual question answering, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific application and techniques presented are not aligned with your areas of focus."
    },
    {
        "title": "Breaking Token Into Concepts: Exploring Extreme Compression in Token Representation Via Compositional Shared Semantics",
        "abstract": "Standard language models employ unique, monolithic embeddings for each token,\npotentially limiting their ability to capture the multifaceted nature of word\nmeanings. We investigate whether tokens can be more effectively represented\nthrough a compositional structure that accumulates diverse semantic facets. To\nexplore this, we propose Aggregate Semantic Grouping (ASG), a novel approach\nleveraging Product Quantization (PQ). We apply ASG to standard transformer\narchitectures (mBERT, XLM-R, mT5) and evaluate this representational scheme\nacross diverse tasks (NLI, NER, QA), as well as a biomedical domain-specific\nbenchmark (BC5CDR) using BioBERT. Our findings demonstrate that representing\ntokens compositionally via ASG achieves extreme compression in embedding\nparameters (0.4--0.5\\%) while maintaining $>$95\\% task performance relative to\nthe base model, even in generative tasks and extends to both cross lingual\ntransfer and domain-specific settings. These results validate the principle\nthat tokens can be effectively modeled as combinations of shared semantic\nbuilding blocks. ASG offers a simple yet concrete method for achieving this,\nshowcasing how compositional representations can capture linguistic richness\nwhile enabling compact yet semantically rich models.",
        "url": "http://arxiv.org/abs/2509.17737v2",
        "pdf_url": "http://arxiv.org/pdf/2509.17737v2",
        "arxiv_id": "2509.17737v2",
        "authors": [
            "Kavin R V",
            "Pawan Goyal"
        ],
        "submitted": "2025-09-22 13:04:48",
        "source": "arxiv",
        "comment": "5 pages, 1 figure Accepted at EMNLP 2025 Findings (Short)",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper explores a novel approach to token representation in NLP, leveraging compositional semantics to achieve extreme compression in embedding parameters. While primarily focused on NLP, the paper touches on aspects of semantic understanding and model optimization, which align with your interests in IR and NLP. However, the paper's focus on token representation and its applications in NLP tasks may not be directly related to your core research themes in IR and search technologies."
    },
    {
        "title": "ConfClip: Confidence-Weighted and Clipped Reward for Reinforcement Learning in LLMs",
        "abstract": "Reinforcement learning (RL) has become a standard paradigm for refining large\nlanguage models (LLMs) beyond pre-training and instruction tuning. A prominent\nline of work is RL with verifiable rewards (RLVR), which leverages\nautomatically verifiable outcomes (e.g., correctness or executability) to\ngenerate reward signals. While efficient, this framework faces two key\nlimitations: First, its binary feedback is too sparse to capture the quality of\nthe reasoning process. Second, its coarse-grained rewards potentially lead to\nvanishing gradients. Inspired by observations from human learning, we introduce\na RL technique that integrates verifiable outcomes with the model's own\nconfidence estimates. This joint design enriches the reward signal, providing\nfiner-grained feedback and implicitly supervising the reasoning process.\nExperimental results demonstrate that our proposed method enhances RL\nperformance across multiple datasets and reduces token consumption during\ninference, while incurring negligible additional training cost. Moreover, it\ncan be used as a plug-in module to enhance other state-of-the-art RL methods.",
        "url": "http://arxiv.org/abs/2509.17730v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17730v1",
        "arxiv_id": "2509.17730v1",
        "authors": [
            "Bonan Zhang",
            "Zhongqi Chen",
            "Bowen Song",
            "Qinya Li",
            "Fan Wu",
            "Guihai Chen"
        ],
        "submitted": "2025-09-22 13:00:35",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on reinforcement learning for large language models, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context is more on model refinement and optimization rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Human vs. Agent in Task-Oriented Conversations",
        "abstract": "Task-oriented conversational systems are essential for efficiently addressing\ndiverse user needs, yet their development requires substantial amounts of\nhigh-quality conversational data that is challenging and costly to obtain.\nWhile large language models (LLMs) have demonstrated potential in generating\nsynthetic conversations, the extent to which these agent-generated interactions\ncan effectively substitute real human conversations remains unclear. This work\npresents the first systematic comparison between LLM-simulated users and human\nusers in personalized task-oriented conversations. We propose a comprehensive\nanalytical framework encompassing three key aspects (conversation strategy,\ninteraction style, and conversation evaluation) and ten distinct dimensions for\nevaluating user behaviors, and collect parallel conversational datasets from\nboth human users and LLM agent users across four representative scenarios under\nidentical conditions. Our analysis reveals significant behavioral differences\nbetween the two user types in problem-solving approaches, question broadness,\nuser engagement, context dependency, feedback polarity and promise, language\nstyle, and hallucination awareness. We found consistency in the agent users and\nhuman users across the depth-first or breadth-first dimensions, as well as the\nusefulness dimensions. These findings provide critical insights for advancing\nLLM-based user simulation. Our multi-dimensional taxonomy constructed a\ngeneralizable framework for analyzing user behavior patterns, offering insights\nfrom LLM agent users and human users. By this work, we provide perspectives on\nrethinking how to use user simulation in conversational systems in the future.",
        "url": "http://arxiv.org/abs/2509.17619v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17619v1",
        "arxiv_id": "2509.17619v1",
        "authors": [
            "Zhefan Wang",
            "Ning Geng",
            "Zhiqiang Guo",
            "Weizhi Ma",
            "Min Zhang"
        ],
        "submitted": "2025-09-22 11:30:39",
        "source": "arxiv",
        "comment": "SIGIR-AP 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'user behavior' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores task-oriented conversational systems and user simulation, which is somewhat related to information retrieval and search technologies. However, the focus on conversational systems and user behavior modeling is not a central match to the user's primary research interests in query understanding, ranking models, and user behavior modeling in the context of search technologies."
    },
    {
        "title": "AutiHero: Leveraging Generative AI in Social Narratives to Engage Parents in Story-Driven Behavioral Guidance for Autistic Children",
        "abstract": "Social narratives are known to help autistic children understand and navigate\nsocial situations through stories. To ensure effectiveness, however, the\nmaterials need to be customized to reflect each child's unique behavioral\ncontext, requiring considerable time and effort for parents to practice at\nhome. We present AutiHero, a generative AI-based social narrative system for\nbehavioral guidance, which supports parents to create personalized stories for\ntheir autistic children and read them together. AutiHero generates text and\nvisual illustrations that reflect their children's interests, target behaviors,\nand everyday contexts. In a two-week deployment study with 16 autistic\nchild-parent dyads, parents created 218 stories and read an average of 4.25\nstories per day, demonstrating a high level of engagement. AutiHero also\nprovided an effective, low-demanding means to guide children's social\nbehaviors, encouraging positive change. We discuss the implications of\ngenerative AI-infused tools to empower parents in guiding their children's\nbehaviors, fostering their social learning.",
        "url": "http://arxiv.org/abs/2509.17608v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17608v1",
        "arxiv_id": "2509.17608v1",
        "authors": [
            "Jungeun Lee",
            "Kyungah Lee",
            "Inseok Hwang",
            "SoHyun Park",
            "Young-Ho Kim"
        ],
        "submitted": "2025-09-22 11:23:10",
        "source": "arxiv",
        "comment": "22 pages except reference",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing, as it focuses on a generative AI system for creating personalized social narratives for autistic children. While it involves text generation, the context and application are unrelated to your areas of interest."
    },
    {
        "title": "Leveraging Audio-Visual Data to Reduce the Multilingual Gap in Self-Supervised Speech Models",
        "abstract": "Self-supervised learning (SSL) has made significant advances in speech\nrepresentation learning. Models like wav2vec 2.0 and HuBERT have achieved\nstate-of-the-art results in tasks such as speech recognition, particularly in\nmonolingual settings. However, multilingual SSL models tend to underperform\ntheir monolingual counterparts on each individual language, especially in\nmultilingual scenarios with few languages such as the bilingual setting. In\nthis work, we investigate a novel approach to reduce this performance gap by\nintroducing limited visual grounding into bilingual speech SSL models. Our\nresults show that visual grounding benefits both monolingual and bilingual\nmodels, with especially pronounced gains for the latter, reducing the\nmultilingual performance gap on zero-shot phonetic discrimination from 31.5%\nfor audio-only models to 8.04% with grounding.",
        "url": "http://arxiv.org/abs/2509.17523v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17523v1",
        "arxiv_id": "2509.17523v1",
        "authors": [
            "María Andrea Cruz Blandón",
            "Zakaria Aldeneh",
            "Jie Chi",
            "Maureen de Seyssel"
        ],
        "submitted": "2025-09-22 08:48:04",
        "source": "arxiv",
        "comment": "5 pages, 2 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper focuses on speech representation learning and self-supervised learning in the context of speech recognition, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "CorefInst: Leveraging LLMs for Multilingual Coreference Resolution",
        "abstract": "Coreference Resolution (CR) is a crucial yet challenging task in natural\nlanguage understanding, often constrained by task-specific architectures and\nencoder-based language models that demand extensive training and lack\nadaptability. This study introduces the first multilingual CR methodology which\nleverages decoder-only LLMs to handle both overt and zero mentions. The article\nexplores how to model the CR task for LLMs via five different instruction sets\nusing a controlled inference method. The approach is evaluated across three\nLLMs; Llama 3.1, Gemma 2, and Mistral 0.3. The results indicate that LLMs, when\ninstruction-tuned with a suitable instruction set, can surpass state-of-the-art\ntask-specific architectures. Specifically, our best model, a fully fine-tuned\nLlama 3.1 for multilingual CR, outperforms the leading multilingual CR model\n(i.e., Corpipe 24 single stage variant) by 2 pp on average across all languages\nin the CorefUD v1.2 dataset collection.",
        "url": "http://arxiv.org/abs/2509.17505v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17505v1",
        "arxiv_id": "2509.17505v1",
        "authors": [
            "Tuğba Pamay Arslan",
            "Emircan Erol",
            "Gülşen Eryiğit"
        ],
        "submitted": "2025-09-22 08:35:21",
        "source": "arxiv",
        "comment": "Accepted for publication in Transactions of the Association for\n  Computational Linguistics (TACL) (2025 August). Submission: March, 2025.\n  Revision: July, 2025. Acceptance: August, 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and deep semantic understanding, but it primarily focuses on coreference resolution, which is a specific task within NLP. While it leverages LLMs, a topic of interest in the user's background, the paper's focus on coreference resolution and instruction tuning is not directly aligned with the user's core research themes in Information Retrieval and Search technologies."
    },
    {
        "title": "Enhancing Cross-Lingual Transfer through Reversible Transliteration: A Huffman-Based Approach for Low-Resource Languages",
        "abstract": "As large language models (LLMs) are trained on increasingly diverse and\nextensive multilingual corpora, they demonstrate cross-lingual transfer\ncapabilities. However, these capabilities often fail to effectively extend to\nlow-resource languages, particularly those utilizing non-Latin scripts. While\ntransliterating low-resource languages into Latin script presents a natural\nsolution, there currently lacks a comprehensive framework for integrating\ntransliteration into LLMs training and deployment. Taking a pragmatic approach,\nthis paper innovatively combines character transliteration with Huffman coding\nto design a complete transliteration framework. Our proposed framework offers\nthe following advantages: 1) Compression: Reduces storage requirements for\nlow-resource language content, achieving up to 50% reduction in file size and\n50-80% reduction in token count. 2) Accuracy: Guarantees 100% lossless\nconversion from transliterated text back to the source language. 3) Efficiency:\nEliminates the need for vocabulary expansion for low-resource languages,\nimproving training and inference efficiency. 4) Scalability: The framework can\nbe extended to other low-resource languages. We validate the effectiveness of\nour framework across multiple downstream tasks, including text classification,\nmachine reading comprehension, and machine translation. Experimental results\ndemonstrate that our method significantly enhances the model's capability to\nprocess low-resource languages while maintaining performance on high-resource\nlanguages. Our data and code are publicly available at\nhttps://github.com/CMLI-NLP/HuffmanTranslit.",
        "url": "http://arxiv.org/abs/2509.17493v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17493v1",
        "arxiv_id": "2509.17493v1",
        "authors": [
            "Wenhao Zhuang",
            "Yuan Sun",
            "Xiaobing Zhao"
        ],
        "submitted": "2025-09-22 08:24:26",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on cross-lingual transfer and low-resource languages, which is somewhat related to information retrieval and NLP. However, the primary focus on transliteration and Huffman coding does not align with the user's core research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "PRINCIPLES: Synthetic Strategy Memory for Proactive Dialogue Agents",
        "abstract": "Dialogue agents based on large language models (LLMs) have shown promising\nperformance in proactive dialogue, which requires effective strategy planning.\nHowever, existing approaches to strategy planning for proactive dialogue face\nseveral limitations: limited strategy coverage, preference bias in planning,\nand reliance on costly additional training. To address these, we propose\nPRINCIPLES: a synthetic strategy memory for proactive dialogue agents.\nPRINCIPLES is derived through offline self-play simulations and serves as\nreusable knowledge that guides strategy planning during inference, eliminating\nthe need for additional training and data annotation. We evaluate PRINCIPLES in\nboth emotional support and persuasion domains, demonstrating consistent\nimprovements over strong baselines. Furthermore, PRINCIPLES maintains its\nrobustness across extended and more diverse evaluation settings. See our\nproject page at https://huggingface.co/spaces/kimnamssya/Principles.",
        "url": "http://arxiv.org/abs/2509.17459v1",
        "pdf_url": "http://arxiv.org/pdf/2509.17459v1",
        "arxiv_id": "2509.17459v1",
        "authors": [
            "Namyoung Kim",
            "Kai Tzu-iunn Ong",
            "Yeonjun Hwang",
            "Minseok Kang",
            "Iiseo Jihn",
            "Gayoung Kim",
            "Minju Kim",
            "Jinyoung Yeo"
        ],
        "submitted": "2025-09-22 07:53:59",
        "source": "arxiv",
        "comment": "Accepted to EMNLP 2025 Findings",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on proactive dialogue agents and strategy planning, which is not directly related to the user's core research themes in Information Retrieval and Search technologies. Although it involves large language models and offline self-play simulations, the context is more aligned with NLP and dialogue systems rather than query understanding, ranking models, or user behavior modeling."
    }
]