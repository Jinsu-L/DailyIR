# Daily Papers Report - 2025-10-09

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models

- **LLM Score**: 8
- **Keyword Score**: 6
- **Authors**: Yuntao Gui, James Cheng
- **URL**: <http://arxiv.org/abs/2510.07048v1>
- **Submitted**: 2025-10-08 14:16:20
- **Topic Keywords**: information retrieval, retrieval, search
- **Reason**: This paper presents a novel framework, Search-R3, that integrates reasoning and embedding generation in Large Language Models for retrieval tasks, aligning with your interests in Information Retrieval and deep semantic understanding. The approach exploits LLMs' chain-of-thought capabilities and demonstrates significant improvements over prior methods. While the focus is on LLMs and NLP, the relevance to IR and search technologies is clear.

#### Abstract
> Despite their remarkable natural language understanding capabilities, Large
Language Models (LLMs) have been underutilized for retrieval tasks. We present
Search-R3, a novel framework that addresses this limitation by adapting LLMs to
generate search embeddings as a direct output of their reasoning process. Our
approach exploits LLMs' chain-of-thought capabilities, allowing them to produce
more effective embeddings by reasoning step-by-step through complex semantic
analyses. We implement this through three complementary mechanisms. (1) a
supervised learning stage enables the model's ability to produce quality
embeddings, (2) a reinforcement learning (RL) methodology that optimizes
embedding generation alongside reasoning, and (3) a specialized RL environment
that efficiently handles evolving embedding representations without requiring
complete corpus re-encoding at each training iteration. Our extensive
evaluations on diverse benchmarks demonstrate that Search-R3 significantly
outperforms prior methods by unifying the reasoning and embedding generation
processes. This integrated post-training approach represents a substantial
advancement in handling complex knowledge-intensive tasks that require both
sophisticated reasoning and effective information retrieval. Project page:
https://github.com/ytgui/Search-R3

---

### 2. Customer-R1: Personalized Simulation of Human Behaviors via RL-based LLM Agent in Online Shopping

- **LLM Score**: 8
- **Keyword Score**: 4
- **Authors**: Ziyi Wang, Yuxuan Lu, Yimeng Zhang, Jing Huang, Dakuo Wang
- **URL**: <http://arxiv.org/abs/2510.07230v1>
- **Submitted**: 2025-10-08 17:00:25
- **Topic Keywords**: user behavior, shopping, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of user behavior modeling. The use of Reinforcement Learning (RL) and Large Language Models (LLMs) to simulate personalized user behavior in online shopping environments aligns with your focus on query understanding and ranking models. The paper's emphasis on real-time relevance optimization also resonates with your interests.

#### Abstract
> Simulating step-wise human behavior with Large Language Models (LLMs) has
become an emerging research direction, enabling applications in various
practical domains. While prior methods, including prompting, supervised
fine-tuning (SFT), and reinforcement learning (RL), have shown promise in
modeling step-wise behavior, they primarily learn a population-level policy
without conditioning on a user's persona, yielding generic rather than
personalized simulations. In this work, we pose a critical question: how can
LLM agents better simulate personalized user behavior? We introduce
Customer-R1, an RL-based method for personalized, step-wise user behavior
simulation in online shopping environments. Our policy is conditioned on an
explicit persona, and we optimize next-step rationale and action generation via
action correctness reward signals. Experiments on the OPeRA dataset emonstrate
that Customer-R1 not only significantly outperforms prompting and SFT-based
baselines in next-action prediction tasks, but also better matches users'
action distribution, indicating higher fidelity in personalized behavior
simulation.

---

### 3. Towards Reliable Retrieval in RAG Systems for Large Legal Datasets

- **LLM Score**: 7
- **Keyword Score**: 10
- **Authors**: Markus Reuter, Tobias Lingenberg, R≈´ta Liepi≈Üa, Francesca Lagioia, Marco Lippi, Giovanni Sartor, Andrea Passerini, Burcu Sayin
- **URL**: <http://arxiv.org/abs/2510.06999v1>
- **Submitted**: 2025-10-08 13:22:20
- **Comment**: Accepted for the 7th Natural Legal Language Processing Workshop (NLLP
  2025), co-located with EMNLP 2025
- **Topic Keywords**: information retrieval, retriever, rag, retrieval
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, specifically in the context of Retrieval-Augmented Generation (RAG) systems. While it focuses on the legal domain, the techniques and challenges discussed, such as Document-Level Retrieval Mismatch (DRM), are relevant to your interests in query understanding and ranking models. However, the paper's primary focus on the legal domain and the specific application of RAG systems limits its alignment with your broader research themes.

#### Abstract
> Retrieval-Augmented Generation (RAG) is a promising approach to mitigate
hallucinations in Large Language Models (LLMs) for legal applications, but its
reliability is critically dependent on the accuracy of the retrieval step. This
is particularly challenging in the legal domain, where large databases of
structurally similar documents often cause retrieval systems to fail. In this
paper, we address this challenge by first identifying and quantifying a
critical failure mode we term Document-Level Retrieval Mismatch (DRM), where
the retriever selects information from entirely incorrect source documents. To
mitigate DRM, we investigate a simple and computationally efficient technique
which we refer to as Summary-Augmented Chunking (SAC). This method enhances
each text chunk with a document-level synthetic summary, thereby injecting
crucial global context that would otherwise be lost during a standard chunking
process. Our experiments on a diverse set of legal information retrieval tasks
show that SAC greatly reduces DRM and, consequently, also improves text-level
retrieval precision and recall. Interestingly, we find that a generic
summarization strategy outperforms an approach that incorporates legal expert
domain knowledge to target specific legal elements. Our work provides evidence
that this practical, scalable, and easily integrable technique enhances the
reliability of RAG systems when applied to large-scale legal document datasets.

---

### 4. All Claims Are Equal, but Some Claims Are More Equal Than Others: Importance-Sensitive Factuality Evaluation of LLM Generations

- **LLM Score**: 6
- **Keyword Score**: 9
- **Authors**: Miriam Wanner, Leif Azzopardi, Paul Thomas, Soham Dan, Benjamin Van Durme, Nick Craswell
- **URL**: <http://arxiv.org/abs/2510.07083v1>
- **Submitted**: 2025-10-08 14:40:33
- **Topic Keywords**: query, queries, relevance
- **Reason**: This paper is somewhat related to your interests in Information Retrieval, particularly in the context of evaluating the factuality of large language model responses. However, it focuses more on Natural Language Processing and factuality evaluation, which, while related to your broader interests, is not a central match.

#### Abstract
> Existing methods for evaluating the factuality of large language model (LLM)
responses treat all claims as equally important. This results in misleading
evaluations when vital information is missing or incorrect as it receives the
same weight as peripheral details, raising the question: how can we reliably
detect such differences when there are errors in key information? Current
approaches that measure factuality tend to be insensitive to omitted or false
key information. To investigate this lack of sensitivity, we construct
VITALERRORS, a benchmark of 6,733 queries with minimally altered LLM responses
designed to omit or falsify key information. Using this dataset, we demonstrate
the insensitivities of existing evaluation metrics to key information errors.
To address this gap, we introduce VITAL, a set of metrics that provide greater
sensitivity in measuring the factuality of responses by incorporating the
relevance and importance of claims with respect to the query. Our analysis
demonstrates that VITAL metrics more reliably detect errors in key information
than previous methods. Our dataset, metrics, and analysis provide a foundation
for more accurate and robust assessment of LLM factuality.

---

### 5. LongRM: Revealing and Unlocking the Context Boundary of Reward Modeling

- **LLM Score**: 6
- **Keyword Score**: 5
- **Authors**: Zecheng Tang, Baibei Ji, Quantong Qiu, Haitian Wang, Xiaobo Liang, Juntao Li, Min Zhang
- **URL**: <http://arxiv.org/abs/2510.06915v1>
- **Submitted**: 2025-10-08 11:48:16
- **Topic Keywords**: pairwise, rag
- **Reason**: This paper is somewhat related to the user's interests in Information Retrieval, particularly in the context of query understanding and ranking models. However, the focus on reward modeling and long-context scenarios is not a central match for the user's primary research themes, which include query understanding, ranking models, and user behavior modeling.

#### Abstract
> Reward model (RM) plays a pivotal role in aligning large language model (LLM)
with human preferences. As real-world applications increasingly involve long
history trajectories, e.g., LLM agent, it becomes indispensable to evaluate
whether a model's responses are not only high-quality but also grounded in and
consistent with the provided context. Yet, current RMs remain confined to
short-context settings and primarily focus on response-level attributes (e.g.,
safety or helpfulness), while largely neglecting the critical dimension of long
context-response consistency. In this work, we introduce Long-RewardBench, a
benchmark specifically designed for long-context RM evaluation, featuring both
Pairwise Comparison and Best-of-N tasks. Our preliminary study reveals that
even state-of-the-art generative RMs exhibit significant fragility in
long-context scenarios, failing to maintain context-aware preference judgments.
Motivated by the analysis of failure patterns observed in model outputs, we
propose a general multi-stage training strategy that effectively scales
arbitrary models into robust Long-context RMs (LongRMs). Experiments show that
our approach not only substantially improves performance on long-context
evaluation but also preserves strong short-context capability. Notably, our 8B
LongRM outperforms much larger 70B-scale baselines and matches the performance
of the proprietary Gemini 2.5 Pro model.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Vibe Checker: Aligning Code Evaluation with Human Preference

- **LLM Score**: 6
- **Keyword Score**: 2
- **Authors**: Ming Zhong, Xiang Zhou, Ting-Yun Chang, Qingze Wang, Nan Xu, Xiance Si, Dan Garrette, Shyam Upadhyay, Jeremiah Liu, Jiawei Han, Benoit Schillings, Jiao Sun
- **URL**: <http://arxiv.org/abs/2510.07315v1>
- **Submitted**: 2025-10-08 17:59:19
- **Comment**: Preprint
- **Topic Keywords**: rag
- **Reason**: The paper explores code evaluation and instruction following, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on code generation and human preference in coding is not directly aligned with the user's core research themes, but it does involve natural language interactions and real-time relevance optimization, making it somewhat relevant.

#### Abstract
> Large Language Models (LLMs) have catalyzed vibe coding, where users leverage
LLMs to generate and iteratively refine code through natural language
interactions until it passes their vibe check. Vibe check is tied to real-world
human preference and goes beyond functionality: the solution should feel right,
read cleanly, preserve intent, and remain correct. However, current code
evaluation remains anchored to pass@k and captures only functional correctness,
overlooking the non-functional instructions that users routinely apply. In this
paper, we hypothesize that instruction following is the missing piece
underlying vibe check that represents human preference in coding besides
functional correctness. To quantify models' code instruction following
capabilities with measurable signals, we present VeriCode, a taxonomy of 30
verifiable code instructions together with corresponding deterministic
verifiers. We use the taxonomy to augment established evaluation suites,
resulting in Vibe Checker, a testbed to assess both code instruction following
and functional correctness. Upon evaluating 31 leading LLMs, we show that even
the strongest models struggle to comply with multiple instructions and exhibit
clear functional regression. Most importantly, a composite score of functional
correctness and instruction following correlates the best with human
preference, with the latter emerging as the primary differentiator on
real-world programming tasks. Our work identifies core factors of the vibe
check, providing a concrete path for benchmarking and developing models that
better align with user preferences in coding.

### 7. LAD-RAG: Layout-aware Dynamic RAG for Visually-Rich Document Understanding

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Zhivar Sourati, Zheng Wang, Marianne Menglin Liu, Yazhe Hu, Mengqing Guo, Sujeeth Bharadwaj, Kyu Han, Tao Sheng, Sujith Ravi, Morteza Dehghani, Dan Roth
- **URL**: <http://arxiv.org/abs/2510.07233v1>
- **Submitted**: 2025-10-08 17:02:04
- **Topic Keywords**: retriever, query, rag, retrieval
- **Reason**: This paper explores visually-rich document understanding, which is somewhat related to information retrieval and query understanding. However, it focuses on visually-rich documents and uses a novel framework to capture layout structure and cross-page dependencies, which is not directly aligned with the user's core research themes in e-commerce or real-time relevance optimization.

#### Abstract
> Question answering over visually rich documents (VRDs) requires reasoning not
only over isolated content but also over documents' structural organization and
cross-page dependencies. However, conventional retrieval-augmented generation
(RAG) methods encode content in isolated chunks during ingestion, losing
structural and cross-page dependencies, and retrieve a fixed number of pages at
inference, regardless of the specific demands of the question or context. This
often results in incomplete evidence retrieval and degraded answer quality for
multi-page reasoning tasks. To address these limitations, we propose LAD-RAG, a
novel Layout-Aware Dynamic RAG framework. During ingestion, LAD-RAG constructs
a symbolic document graph that captures layout structure and cross-page
dependencies, adding it alongside standard neural embeddings to yield a more
holistic representation of the document. During inference, an LLM agent
dynamically interacts with the neural and symbolic indices to adaptively
retrieve the necessary evidence based on the query. Experiments on
MMLongBench-Doc, LongDocURL, DUDE, and MP-DocVQA demonstrate that LAD-RAG
improves retrieval, achieving over 90% perfect recall on average without any
top-k tuning, and outperforming baseline retrievers by up to 20% in recall at
comparable noise levels, yielding higher QA accuracy with minimal latency.

### 8. Agent Bain vs. Agent McKinsey: A New Text-to-SQL Benchmark for the Business Domain

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Yue Li, Ran Tao, Derek Hommel, Yusuf Denizay D√∂nder, Sungyong Chang, David Mimno, Unso Eun Seo Jo
- **URL**: <http://arxiv.org/abs/2510.07309v2>
- **Submitted**: 2025-10-08 17:57:35
- **Comment**: 20 pages, 6 figures, under review for ACL ARR; typos corrected
- **Topic Keywords**: queries, retrieval, recommend
- **Reason**: The paper is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, but it focuses on a specific task (text-to-SQL) and domain (business) that is not the user's primary focus. While it involves query understanding and ranking models, the context is more aligned with recommender systems and data mining than the user's core research themes.

#### Abstract
> In the business domain, where data-driven decision making is crucial,
text-to-SQL is fundamental for easy natural language access to structured data.
While recent LLMs have achieved strong performance in code generation, existing
text-to-SQL benchmarks remain focused on factual retrieval of past records. We
introduce CORGI, a new benchmark specifically designed for real-world business
contexts. CORGI is composed of synthetic databases inspired by enterprises such
as Doordash, Airbnb, and Lululemon. It provides questions across four
increasingly complex categories of business queries: descriptive, explanatory,
predictive, and recommendational. This challenge calls for causal reasoning,
temporal forecasting, and strategic recommendation, reflecting multi-level and
multi-step agentic intelligence. We find that LLM performance drops on
high-level questions, struggling to make accurate predictions and offer
actionable plans. Based on execution success rate, the CORGI benchmark is about
21% more difficult than the BIRD benchmark. This highlights the gap between
popular LLMs and the need for real-world business intelligence. We release a
public dataset and evaluation framework, and a website for public submissions.

### 9. Comparing human and language models sentence processing difficulties on complex structures

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Samuel Joseph Amouyal, Aya Meltzer-Asscher, Jonathan Berant
- **URL**: <http://arxiv.org/abs/2510.07141v1>
- **Submitted**: 2025-10-08 15:42:49
- **Comment**: Data and code will be released soon
- **Topic Keywords**: ranking, rag, rank
- **Reason**: This paper explores the sentence comprehension abilities of large language models, comparing them to human performance. While it touches on aspects of natural language processing, it doesn't directly relate to information retrieval, query understanding, or ranking models, which are core areas of your research interests.

#### Abstract
> Large language models (LLMs) that fluently converse with humans are a reality
- but do LLMs experience human-like processing difficulties? We systematically
compare human and LLM sentence comprehension across seven challenging
linguistic structures. We collect sentence comprehension data from humans and
five families of state-of-the-art LLMs, varying in size and training procedure
in a unified experimental framework. Our results show LLMs overall struggle on
the target structures, but especially on garden path (GP) sentences. Indeed,
while the strongest models achieve near perfect accuracy on non-GP structures
(93.7% for GPT-5), they struggle on GP structures (46.8% for GPT-5).
Additionally, when ranking structures based on average performance, rank
correlation between humans and models increases with parameter count. For each
target structure, we also collect data for their matched baseline without the
difficult structure. Comparing performance on the target vs. baseline
sentences, the performance gap observed in humans holds for LLMs, with two
exceptions: for models that are too weak performance is uniformly low across
both sentence types, and for models that are too strong the performance is
uniformly high. Together, these reveal convergence and divergence in human and
LLM sentence comprehension, offering new insights into the similarity of humans
and LLMs.

### 10. Online Rubrics Elicitation from Pairwise Comparisons

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: MohammadHossein Rezaei, Robert Vacareanu, Zihao Wang, Clinton Wang, Yunzhong He, Afra Feyza Aky√ºrek
- **URL**: <http://arxiv.org/abs/2510.07284v1>
- **Submitted**: 2025-10-08 17:44:59
- **Topic Keywords**: pairwise
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Learning to Rank, as it discusses training Large Language Models (LLMs) with rubric-based rewards. However, the focus on rubric elicitation and its application to LLMs is not directly aligned with your core research themes in Information Retrieval and Search technologies.

#### Abstract
> Rubrics provide a flexible way to train LLMs on open-ended long-form answers
where verifiable rewards are not applicable and human preferences provide
coarse signals. Prior work shows that reinforcement learning with rubric-based
rewards leads to consistent gains in LLM post-training. Most existing
approaches rely on rubrics that remain static over the course of training. Such
static rubrics, however, are vulnerable to reward-hacking type behaviors and
fail to capture emergent desiderata that arise during training. We introduce
Online Rubrics Elicitation (OnlineRubrics), a method that dynamically curates
evaluation criteria in an online manner through pairwise comparisons of
responses from current and reference policies. This online process enables
continuous identification and mitigation of errors as training proceeds.
Empirically, this approach yields consistent improvements of up to 8% over
training exclusively with static rubrics across AlpacaEval, GPQA, ArenaHard as
well as the validation sets of expert questions and rubrics. We qualitatively
analyze the elicited criteria and identify prominent themes such as
transparency, practicality, organization, and reasoning.

### 11. A Multi-Agent Framework for Stateful Inference-Time Search

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Arshika Lalan, Rajat Ghosh, Aditya Kolsur, Debojyoti Dutta
- **URL**: <http://arxiv.org/abs/2510.07147v1>
- **Submitted**: 2025-10-08 15:48:41
- **Topic Keywords**: rag, search
- **Reason**: This paper proposes a multi-agent framework for stateful inference-time search, which is somewhat related to information retrieval and search technologies. However, the focus on automated unit test generation and code analysis is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling. The connection to deep semantic understanding and real-time relevance optimization is also not explicitly mentioned.

#### Abstract
> Recent work explores agentic inference-time techniques to perform structured,
multi-step reasoning. However, stateless inference often struggles on
multi-step tasks due to the absence of persistent state. Moreover,
task-specific fine-tuning or instruction-tuning often achieve surface-level
code generation but remain brittle on tasks requiring deeper reasoning and
long-horizon dependencies. To address these limitations, we propose stateful
multi-agent evolutionary search, a training-free framework that departs from
prior stateless approaches by combining (i) persistent inference-time state,
(ii) adversarial mutation, and (iii) evolutionary preservation. We demonstrate
its effectiveness in automated unit test generation through the generation of
edge cases. We generate robust edge cases using an evolutionary search process,
where specialized agents sequentially propose, mutate, and score candidates. A
controller maintains persistent state across generations, while evolutionary
preservation ensures diversity and exploration across all possible cases. This
yields a generalist agent capable of discovering robust, high-coverage edge
cases across unseen codebases. Experiments show our stateful multi-agent
inference framework achieves substantial gains in coverage over stateless
single-step baselines, evaluated on prevalent unit-testing benchmarks such as
HumanEval and TestGenEvalMini and using three diverse LLM families - Llama,
Gemma, and GPT. These results indicate that combining persistent inference-time
state with evolutionary search materially improves unit-test generation.

### 12. Benchmarking LLM Causal Reasoning with Scientifically Validated Relationships

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Donggyu Lee, Sungwon Park, Yerin Hwang, Hyoshin Kim, Hyunwoo Oh, Jungwon Kim, Meeyoung Cha, Sangyoon Park, Jihee Kim
- **URL**: <http://arxiv.org/abs/2510.07231v2>
- **Submitted**: 2025-10-08 17:00:49
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat relevant to your research interests in Information Retrieval and Natural Language Processing, as it deals with Large Language Models (LLMs) and their limitations in causal reasoning. However, the focus on causal reasoning and its applications in high-stakes domains, such as economics and finance, is not directly related to your primary areas of interest in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Causal reasoning is fundamental for Large Language Models (LLMs) to
understand genuine cause-and-effect relationships beyond pattern matching.
Existing benchmarks suffer from critical limitations such as reliance on
synthetic data and narrow domain coverage. We introduce a novel benchmark
constructed from casually identified relationships extracted from top-tier
economics and finance journals, drawing on rigorous methodologies including
instrumental variables, difference-in-differences, and regression discontinuity
designs. Our benchmark comprises 40,379 evaluation items covering five task
types across domains such as health, environment, technology, law, and culture.
Experimental results on eight state-of-the-art LLMs reveal substantial
limitations, with the best model achieving only 57.6\% accuracy. Moreover,
model scale does not consistently translate to superior performance, and even
advanced reasoning models struggle with fundamental causal relationship
identification. These findings underscore a critical gap between current LLM
capabilities and demands of reliable causal reasoning in high-stakes
applications.

### 13. Opt-ICL at LeWiDi-2025: Maximizing In-Context Signal from Rater Examples via Meta-Learning

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Taylor Sorensen, Yejin Choi
- **URL**: <http://arxiv.org/abs/2510.07105v1>
- **Submitted**: 2025-10-08 14:59:24
- **Comment**: NLPerspectives: The 4th Workshop on Perspectivist Approaches to
  Natural Language Processing at EMNLP 2025
- **Topic Keywords**: rag
- **Reason**: This paper focuses on natural language processing (NLP) and meta-learning, which is somewhat related to the user's interests in NLP and deep semantic understanding. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user. The paper's relevance is limited to the user's broader interests in NLP and related topics.

#### Abstract
> Many natural language processing (NLP) tasks involve subjectivity, ambiguity,
or legitimate disagreement between annotators. In this paper, we outline our
system for modeling human variation. Our system leverages language models'
(LLMs) in-context learning abilities, along with a two-step meta-learning
training procedure for 1) post-training on many datasets requiring in-context
learning and 2) specializing the model via in-context meta-learning to the
particular data distribution of interest. We also evaluate the performance of
our system submission to the Learning With Disagreements (LeWiDi) competition,
where it was the overall winner on both tasks. Additionally, we perform an
ablation study to measure the importance of each system component. We find that
including rater examples in-context is crucial for our system's performance,
dataset-specific fine-tuning is helpful on the larger datasets, post-training
on other in-context datasets is helpful on one of the competition datasets, and
that performance improves with model scale.

### 14. LeMAJ (Legal LLM-as-a-Judge): Bridging Legal Reasoning and LLM Evaluation

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Joseph Enguehard, Morgane Van Ermengem, Kate Atkinson, Sujeong Cha, Arijit Ghosh Chowdhury, Prashanth Kallur Ramaswamy, Jeremy Roghair, Hannah R Marlowe, Carina Suzana Negreanu, Kitty Boxall, Diana Mincu
- **URL**: <http://arxiv.org/abs/2510.07243v1>
- **Submitted**: 2025-10-08 17:10:47
- **Comment**: Published in Natural Legal Language Processing - EMNLP Workshop 2025
- **Topic Keywords**: search
- **Reason**: This paper is somewhat related to information retrieval, specifically in the context of legal question-answering and large language model evaluation. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's focus on legal domain and LLM evaluation is somewhat tangential to the user's primary research themes.

#### Abstract
> Evaluating large language model (LLM) outputs in the legal domain presents
unique challenges due to the complex and nuanced nature of legal analysis.
Current evaluation approaches either depend on reference data, which is costly
to produce, or use standardized assessment methods, both of which have
significant limitations for legal applications.
  Although LLM-as-a-Judge has emerged as a promising evaluation technique, its
reliability and effectiveness in legal contexts depend heavily on evaluation
processes unique to the legal industry and how trustworthy the evaluation
appears to the human legal expert. This is where existing evaluation methods
currently fail and exhibit considerable variability.
  This paper aims to close the gap: a) we break down lengthy responses into
'Legal Data Points' (LDPs), self-contained units of information, and introduce
a novel, reference-free evaluation methodology that reflects how lawyers
evaluate legal answers; b) we demonstrate that our method outperforms a variety
of baselines on both our proprietary dataset and an open-source dataset
(LegalBench); c) we show how our method correlates more closely with human
expert evaluations and helps improve inter-annotator agreement; and finally d)
we open source our Legal Data Points for a subset of LegalBench used in our
experiments, allowing the research community to replicate our results and
advance research in this vital area of LLM evaluation on legal
question-answering.

### 15. Mining the Mind: What 100M Beliefs Reveal About Frontier LLM Knowledge

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Shrestha Ghosh, Luca Giordano, Yujia Hu, Tuan-Phong Nguyen, Simon Razniewski
- **URL**: <http://arxiv.org/abs/2510.07024v2>
- **Submitted**: 2025-10-08 13:48:38
- **Topic Keywords**: search
- **Reason**: This paper explores the factual knowledge of Large Language Models (LLMs), which is somewhat related to the user's interests in Natural Language Processing (NLP) and deep semantic understanding. However, the focus on LLMs and their knowledge bases is not directly aligned with the user's primary research themes in Information Retrieval and Search technologies.

#### Abstract
> LLMs are remarkable artifacts that have revolutionized a range of NLP and AI
tasks. A significant contributor is their factual knowledge, which, to date,
remains poorly understood, and is usually analyzed from biased samples. In this
paper, we take a deep tour into the factual knowledge (or beliefs) of a
frontier LLM, based on GPTKB v1.5 (Hu et al., 2025a), a recursively elicited
set of 100 million beliefs of one of the strongest currently available frontier
LLMs, GPT-4.1. We find that the models' factual knowledge differs quite
significantly from established knowledge bases, and that its accuracy is
significantly lower than indicated by previous benchmarks. We also find that
inconsistency, ambiguity and hallucinations are major issues, shedding light on
future research opportunities concerning factual LLM knowledge.

### 16. RedTWIZ: Diverse LLM Red Teaming via Adaptive Attack Planning

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Artur Horal, Daniel Pina, Henrique Paz, Iago Paulo, Jo√£o Soares, Rafael Ferreira, Diogo Tavares, Diogo Gl√≥ria-Silva, Jo√£o Magalh√£es, David Semedo
- **URL**: <http://arxiv.org/abs/2510.06994v1>
- **Submitted**: 2025-10-08 13:18:42
- **Topic Keywords**: search
- **Reason**: The paper is somewhat related to the user's interests in Natural Language Processing (NLP) and Large Language Models (LLMs), but it does not directly align with the user's primary focus on Information Retrieval (IR) and query understanding. The paper's focus on robustness and adversarial attacks in LLMs is not a central match for the user's interests in search technologies and user behavior modeling.

#### Abstract
> This paper presents the vision, scientific contributions, and technical
details of RedTWIZ: an adaptive and diverse multi-turn red teaming framework,
to audit the robustness of Large Language Models (LLMs) in AI-assisted software
development. Our work is driven by three major research streams: (1) robust and
systematic assessment of LLM conversational jailbreaks; (2) a diverse
generative multi-turn attack suite, supporting compositional, realistic and
goal-oriented jailbreak conversational strategies; and (3) a hierarchical
attack planner, which adaptively plans, serializes, and triggers attacks
tailored to specific LLM's vulnerabilities. Together, these contributions form
a unified framework -- combining assessment, attack generation, and strategic
planning -- to comprehensively evaluate and expose weaknesses in LLMs'
robustness. Extensive evaluation is conducted to systematically assess and
analyze the performance of the overall system and each component. Experimental
results demonstrate that our multi-turn adversarial attack strategies can
successfully lead state-of-the-art LLMs to produce unsafe generations,
highlighting the pressing need for more research into enhancing LLM's
robustness.

### 17. Making Machines Sound Sarcastic: LLM-Enhanced and Retrieval-Guided Sarcastic Speech Synthesis

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Zhu Li, Yuqing Zhang, Xiyuan Gao, Shekhar Nayak, Matt Coler
- **URL**: <http://arxiv.org/abs/2510.07096v1>
- **Submitted**: 2025-10-08 14:53:48
- **Topic Keywords**: rag, retrieval augmented generation, retrieval, search
- **Reason**: This paper focuses on speech synthesis and sarcasm detection, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve deep semantic understanding, the context is speech synthesis rather than text-based information retrieval.

#### Abstract
> Sarcasm is a subtle form of non-literal language that poses significant
challenges for speech synthesis due to its reliance on nuanced semantic,
contextual, and prosodic cues. While existing speech synthesis research has
focused primarily on broad emotional categories, sarcasm remains largely
unexplored. In this paper, we propose a Large Language Model (LLM)-enhanced
Retrieval-Augmented framework for sarcasm-aware speech synthesis. Our approach
combines (1) semantic embeddings from a LoRA-fine-tuned LLaMA 3, which capture
pragmatic incongruity and discourse-level cues of sarcasm, and (2) prosodic
exemplars retrieved via a Retrieval Augmented Generation (RAG) module, which
provide expressive reference patterns of sarcastic delivery. Integrated within
a VITS backbone, this dual conditioning enables more natural and contextually
appropriate sarcastic speech. Experiments demonstrate that our method
outperforms baselines in both objective measures and subjective evaluations,
yielding improvements in speech naturalness, sarcastic expressivity, and
downstream sarcasm detection.

### 18. AudioMarathon: A Comprehensive Benchmark for Long-Context Audio Understanding and Efficiency in Audio LLMs

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Peize He, Zichen Wen, Yubo Wang, Yuxuan Wang, Xiaoqian Liu, Jiajie Huang, Zehui Lei, Zhuangcheng Gu, Xiangqi Jin, Jiabing Yang, Kai Li, Zhifei Liu, Weijia Li, Cunxiang Wang, Conghui He, Linfeng Zhang
- **URL**: <http://arxiv.org/abs/2510.07293v1>
- **Submitted**: 2025-10-08 17:50:16
- **Comment**: 26 pages, 23 figures, the code is available at
  \url{https://github.com/DabDans/AudioMarathon}
- **Topic Keywords**: rag, search
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. Although it involves Large Language Models (LLMs), the focus is on audio understanding and efficiency, which is outside your primary areas of interest.

#### Abstract
> Processing long-form audio is a major challenge for Large Audio Language
models (LALMs). These models struggle with the quadratic cost of attention
($O(N^2)$) and with modeling long-range temporal dependencies. Existing audio
benchmarks are built mostly from short clips and do not evaluate models in
realistic long context settings. To address this gap, we introduce
AudioMarathon, a benchmark designed to evaluate both understanding and
inference efficiency on long-form audio. AudioMarathon provides a diverse set
of tasks built upon three pillars: long-context audio inputs with durations
ranging from 90.0 to 300.0 seconds, which correspond to encoded sequences of
2,250 to 7,500 audio tokens, respectively, full domain coverage across speech,
sound, and music, and complex reasoning that requires multi-hop inference. We
evaluate state-of-the-art LALMs and observe clear performance drops as audio
length grows. We also study acceleration techniques and analyze the trade-offs
of token pruning and KV cache eviction. The results show large gaps across
current LALMs and highlight the need for better temporal reasoning and
memory-efficient architectures. We believe AudioMarathon will drive the audio
and multimodal research community to develop more advanced audio understanding
models capable of solving complex audio tasks.

### 19. When Benchmarks Age: Temporal Misalignment through Large Language Model Factuality Evaluation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Xunyi Jiang, Dingyi Chang, Julian McAuley, Xin Xu
- **URL**: <http://arxiv.org/abs/2510.07238v1>
- **Submitted**: 2025-10-08 17:06:07
- **Topic Keywords**: retrieval, search
- **Reason**: This paper focuses on the evaluation of large language models, which is a topic in Natural Language Processing (NLP), but it does not directly relate to Information Retrieval (IR), query understanding, ranking models, or user behavior modeling, which are the core areas of your research interests.

#### Abstract
> The rapid evolution of large language models (LLMs) and the real world has
outpaced the static nature of widely used evaluation benchmarks, raising
concerns about their reliability for evaluating LLM factuality. While
substantial works continue to rely on the popular but old benchmarks, their
temporal misalignment with real-world facts and modern LLMs, and their effects
on LLM factuality evaluation remain underexplored. Therefore, in this work, we
present a systematic investigation of this issue by examining five popular
factuality benchmarks and eight LLMs released across different years. An
up-to-date fact retrieval pipeline and three metrics are tailored to quantify
benchmark aging and its impact on LLM factuality evaluation. Experimental
results and analysis illustrate that a considerable portion of samples in the
widely used factuality benchmarks are outdated, leading to unreliable
assessments of LLM factuality. We hope our work can provide a testbed to assess
the reliability of a benchmark for LLM factuality evaluation and inspire more
research on the benchmark aging issue. Codes are available in
https://github.com/JiangXunyi/BenchAge.

### 20. NurseLLM: The First Specialized Language Model for Nursing

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Md Tawkat Islam Khondaker, Julia Harrington, Shady Shehata
- **URL**: <http://arxiv.org/abs/2510.07173v1>
- **Submitted**: 2025-10-08 16:15:06
- **Comment**: EMNLP 2025 Industry Track
- **Topic Keywords**: ctr, search
- **Reason**: This paper focuses on developing a language model for nursing, which is a specialized domain unrelated to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves language models, the application and context are distinct from the user's areas of focus.

#### Abstract
> Recent advancements in large language models (LLMs) have significantly
transformed medical systems. However, their potential within specialized
domains such as nursing remains largely underexplored. In this work, we
introduce NurseLLM, the first nursing-specialized LLM tailored for multiple
choice question-answering (MCQ) tasks. We develop a multi-stage data generation
pipeline to build the first large scale nursing MCQ dataset to train LLMs on a
broad spectrum of nursing topics. We further introduce multiple nursing
benchmarks to enable rigorous evaluation. Our extensive experiments demonstrate
that NurseLLM outperforms SoTA general-purpose and medical-specialized LLMs of
comparable size on different benchmarks, underscoring the importance of a
specialized LLM for the nursing domain. Finally, we explore the role of
reasoning and multi-agent collaboration systems in nursing, highlighting their
promise for future research and applications.

### 21. TRIM: Token-wise Attention-Derived Saliency for Data-Efficient Instruction Tuning

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Manish Nagaraj, Sakshi Choudhary, Utkarsh Saxena, Deepak Ravikumar, Kaushik Roy
- **URL**: <http://arxiv.org/abs/2510.07118v1>
- **Submitted**: 2025-10-08 15:11:04
- **Topic Keywords**: relevance
- **Reason**: This paper focuses on instruction tuning for large language models, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves attention-based mechanisms, the context is NLP and dataset optimization, rather than query understanding or ranking models.

#### Abstract
> Instruction tuning is essential for aligning large language models (LLMs) to
downstream tasks and commonly relies on large, diverse corpora. However, small,
high-quality subsets, known as coresets, can deliver comparable or superior
results, though curating them remains challenging. Existing methods often rely
on coarse, sample-level signals like gradients, an approach that is
computationally expensive and overlooks fine-grained features. To address this,
we introduce TRIM (Token Relevance via Interpretable Multi-layer Attention), a
forward-only, token-centric framework. Instead of using gradients, TRIM
operates by matching underlying representational patterns identified via
attention-based "fingerprints" from a handful of target samples. Such an
approach makes TRIM highly efficient and uniquely sensitive to the structural
features that define a task. Coresets selected by our method consistently
outperform state-of-the-art baselines by up to 9% on downstream tasks and even
surpass the performance of full-data fine-tuning in some settings. By avoiding
expensive backward passes, TRIM achieves this at a fraction of the
computational cost. These findings establish TRIM as a scalable and efficient
alternative for building high-quality instruction-tuning datasets.

### 22. VelLMes: A high-interaction AI-based deception framework

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Muris Sladiƒá, Veronica Valeros, Carlos Catania, Sebastian Garcia
- **URL**: <http://arxiv.org/abs/2510.06975v1>
- **Submitted**: 2025-10-08 13:00:23
- **Comment**: 9 pages. 9 figures. 1 table. This is a preprint of a paper that was
  presented at the Active Defense and Deception Workshop colocated with IEEE
  EuroS&P 2025 conference
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve Large Language Models, the focus is on deception and cybersecurity, which is not a central match to your research themes.

#### Abstract
> There are very few SotA deception systems based on Large Language Models. The
existing ones are limited only to simulating one type of service, mainly SSH
shells. These systems - but also the deception technologies not based on LLMs -
lack an extensive evaluation that includes human attackers. Generative AI has
recently become a valuable asset for cybersecurity researchers and
practitioners, and the field of cyber-deception is no exception. Researchers
have demonstrated how LLMs can be leveraged to create realistic-looking
honeytokens, fake users, and even simulated systems that can be used as
honeypots. This paper presents an AI-based deception framework called VelLMes,
which can simulate multiple protocols and services such as SSH Linux shell,
MySQL, POP3, and HTTP. All of these can be deployed and used as honeypots, thus
VelLMes offers a variety of choices for deception design based on the users'
needs. VelLMes is designed to be attacked by humans, so interactivity and
realism are key for its performance. We evaluate the generative capabilities
and the deception capabilities. Generative capabilities were evaluated using
unit tests for LLMs. The results of the unit tests show that, with careful
prompting, LLMs can produce realistic-looking responses, with some LLMs having
a 100% passing rate. In the case of the SSH Linux shell, we evaluated deception
capabilities with 89 human attackers. The results showed that about 30% of the
attackers thought that they were interacting with a real system when they were
assigned an LLM-based honeypot. Lastly, we deployed 10 instances of the SSH
Linux shell honeypot on the Internet to capture real-life attacks. Analysis of
these attacks showed us that LLM honeypots simulating Linux shells can perform
well against unstructured and unexpected attacks on the Internet, responding
correctly to most of the issued commands.

### 23. Ethical AI prompt recommendations in large language models using collaborative filtering

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jordan Nelson, Almas Baimagambetov, Konstantinos Avgerinakis, Nikolaos Polatidis
- **URL**: <http://arxiv.org/abs/2510.06924v1>
- **Submitted**: 2025-10-08 12:03:21
- **Comment**: This paper has been accepted to by the International Journal of
  Parallel, Emergent & Distributed Systems (Taylor and Francis) and has an
  assigned DOI. We have already chose to make this open access using CC BY. The
  article is not yet available online on the publisher's website. The DOI is:
  doi.org/10.1080/17445760.2025.2573086
- **Topic Keywords**: rag, recommend
- **Reason**: This paper focuses on large language models and collaborative filtering for ethical prompt recommendations, which is somewhat related to your interests in NLP and related topics. However, it does not directly align with your core research themes in Information Retrieval, query understanding, ranking models, and user behavior modeling.

#### Abstract
> As large language models (LLMs) shape AI development, ensuring ethical prompt
recommendations is crucial. LLMs offer innovation but risk bias, fairness
issues, and accountability concerns. Traditional oversight methods struggle
with scalability, necessitating dynamic solutions. This paper proposes using
collaborative filtering, a technique from recommendation systems, to enhance
ethical prompt selection. By leveraging user interactions, it promotes ethical
guidelines while reducing bias. Contributions include a synthetic dataset for
prompt recommendations and the application of collaborative filtering. The work
also tackles challenges in ethical AI, such as bias mitigation, transparency,
and preventing unethical prompt engineering.

### 24. Artificial Hippocampus Networks for Efficient Long-Context Modeling

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yunhao Fang, Weihao Yu, Shu Zhong, Qinghao Ye, Xuehan Xiong, Lai Wei
- **URL**: <http://arxiv.org/abs/2510.07318v1>
- **Submitted**: 2025-10-08 17:59:55
- **Comment**: Code: https://github.com/ByteDance-Seed/AHN
- **Topic Keywords**: rag
- **Reason**: This paper focuses on long-context modeling using artificial neural networks, which is not directly related to information retrieval, search technologies, or query understanding. While it involves deep learning architectures, the context is more aligned with NLP and sequence modeling, but lacks relevance to the user's core research themes.

#### Abstract
> Long-sequence modeling faces a fundamental trade-off between the efficiency
of compressive fixed-size memory in RNN-like models and the fidelity of
lossless growing memory in attention-based Transformers. Inspired by the
Multi-Store Model in cognitive science, we introduce a memory framework of
artificial neural networks. Our method maintains a sliding window of the
Transformer's KV cache as lossless short-term memory, while a learnable module
termed Artificial Hippocampus Network (AHN) recurrently compresses
out-of-window information into a fixed-size compact long-term memory. To
validate this framework, we instantiate AHNs using modern RNN-like
architectures, including Mamba2, DeltaNet, and Gated DeltaNet. Extensive
experiments on long-context benchmarks LV-Eval and InfiniteBench demonstrate
that AHN-augmented models consistently outperform sliding window baselines and
achieve performance comparable or even superior to full-attention models, while
substantially reducing computational and memory requirements. For instance,
augmenting the Qwen2.5-3B-Instruct with AHNs reduces inference FLOPs by 40.5%
and memory cache by 74.0%, while improving its average score on LV-Eval (128k
sequence length) from 4.41 to 5.88. Code is available at:
https://github.com/ByteDance-Seed/AHN.

### 25. Don't Adapt Small Language Models for Tools; Adapt Tool Schemas to the Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jonggeun Lee, Woojung Song, Jongwook Han, Haesung Pyun, Yohan Jo
- **URL**: <http://arxiv.org/abs/2510.07248v1>
- **Submitted**: 2025-10-08 17:16:07
- **Comment**: 15 pages, 4 figures
- **Topic Keywords**: rag
- **Reason**: This paper focuses on adapting tool schemas to small language models, which is not directly related to information retrieval, query understanding, ranking models, or user behavior modeling. While it touches on the topic of model adaptation, it is more relevant to the NLP domain and does not seem to address real-time relevance optimization or deep semantic understanding, which are key areas of interest for your research.

#### Abstract
> Small language models (SLMs) offer significant computational advantages for
tool-augmented AI systems, yet they struggle with tool-use tasks, particularly
in selecting appropriate tools and identifying correct parameters. A common
failure mode is schema misalignment: models hallucinate plausible but
non-existent tool names that reflect naming conventions internalized during
pretraining but absent from the provided tool schema. Rather than forcing
models to adapt to arbitrary schemas, we propose adapting schemas to align with
models' pretrained knowledge. We introduce PA-Tool (Pretraining-Aligned Tool
Schema Generation), a training-free method that leverages peakedness-a signal
from contamination detection indicating pretraining familiarity-to
automatically rename tool components. By generating multiple candidates and
selecting those with highest output concentration across samples, PA-Tool
identifies pretrain-aligned naming patterns. Experiments on MetaTool and
RoTBench show improvements of up to 17% points, with schema misalignment errors
reduced by 80%. PA-Tool enables small models to approach state-of-the-art
performance while maintaining computational efficiency for adaptation to new
tools without retraining. Our work demonstrates that schema-level interventions
can unlock the tool-use potential of resource-efficient models by adapting
schemas to models rather than models to schemas.

### 26. Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Leitian Tao, Ilia Kulikov, Swarnadeep Saha, Tianlu Wang, Jing Xu, Yixuan Li, Jason E Weston, Ping Yu
- **URL**: <http://arxiv.org/abs/2510.07242v2>
- **Submitted**: 2025-10-08 17:09:41
- **Comment**: 21 pages
- **Topic Keywords**: rag
- **Reason**: This paper focuses on reinforcement learning and reward models for post-training large language models, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves optimization and ranking, the context is NLP and not specifically related to the user's core research themes.

#### Abstract
> Post-training for reasoning of large language models (LLMs) increasingly
relies on verifiable rewards: deterministic checkers that provide 0-1
correctness signals. While reliable, such binary feedback is brittle--many
tasks admit partially correct or alternative answers that verifiers
under-credit, and the resulting all-or-nothing supervision limits learning.
Reward models offer richer, continuous feedback, which can serve as a
complementary supervisory signal to verifiers. We introduce HERO (Hybrid
Ensemble Reward Optimization), a reinforcement learning framework that
integrates verifier signals with reward-model scores in a structured way. HERO
employs stratified normalization to bound reward-model scores within
verifier-defined groups, preserving correctness while refining quality
distinctions, and variance-aware weighting to emphasize challenging prompts
where dense signals matter most. Across diverse mathematical reasoning
benchmarks, HERO consistently outperforms RM-only and verifier-only baselines,
with strong gains on both verifiable and hard-to-verify tasks. Our results show
that hybrid reward design retains the stability of verifiers while leveraging
the nuance of reward models to advance reasoning.

### 27. Sunflower: A New Approach To Expanding Coverage of African Languages in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Benjamin Akera, Evelyn Nafula Ouma, Gilbert Yiga, Patrick Walukagga, Phionah Natukunda, Trevor Saaka, Solomon Nsumba, Lilian Teddy Nabukeera, Joel Muhanguzi, Imran Sekalala, Nimpamya Janat Namara, Engineer Bainomugisha, Ernest Mwebaze, John Quinn
- **URL**: <http://arxiv.org/abs/2510.07203v1>
- **Submitted**: 2025-10-08 16:35:53
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests as it focuses on expanding language coverage in large language models for African languages, which is outside your primary focus on Information Retrieval, Search technologies, and Natural Language Processing, particularly in areas requiring deep semantic understanding and real-time relevance optimization.

#### Abstract
> There are more than 2000 living languages in Africa, most of which have been
bypassed by advances in language technology. Current leading LLMs exhibit
strong performance on a number of the most common languages (e.g. Swahili or
Yoruba), but prioritise support for the languages with the most speakers first,
resulting in piecemeal ability across disparate languages. We contend that a
regionally focussed approach is more efficient, and present a case study for
Uganda, a country with high linguistic diversity. We describe the development
of Sunflower 14B and 32B, a pair of models based on Qwen 3 with state of the
art comprehension in the majority of all Ugandan languages. These models are
open source and can be used to reduce language barriers in a number of
important practical applications.

### 28. ConCuR: Conciseness Makes State-of-the-Art Kernel Generation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Lingcheng Kong, Jiateng Wei, Hanzhang Shen, Huan Wang
- **URL**: <http://arxiv.org/abs/2510.07356v1>
- **Submitted**: 2025-10-08 15:41:15
- **Topic Keywords**: rag
- **Reason**: This paper appears to be focused on GPU kernel generation using Large Language Models (LLMs), which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves deep learning techniques, the specific application and domain are not aligned with the user's core research themes.

#### Abstract
> GPU kernel generation by LLMs has recently experienced rapid development,
leveraging test-time scaling and reinforcement learning techniques. However, a
key challenge for kernel generation is the scarcity of high-quality data, as
most high-quality kernels are proprietary and not open-source. This challenge
prevents us from leveraging supervised fine-tuning to align LLMs to the kernel
generation task. To address this challenge, we develop a pipeline that
generates and curates high-quality CUDA kernels with reasoning traces,
motivated by a critical observation that concise yet informative reasoning
traces result in robust generation of high-performance kernels. Using this
pipeline, we construct our dataset ConCuR and introduce our model KernelCoder,
which is the first model trained on a curated dataset consisting of PyTorch,
reasoning, and CUDA kernel pairs, to our knowledge. In the KernelBench setup,
our model achieves significant improvements over the existing top-performing
model, QwQ-32B, and outperforms all open-source models fine-tuned for kernel
generation, as well as frontier models such as DeepSeek-V3.1-Think and
Claude-4-sonnet. Finally, we show that the average reasoning length can serve
as a metric to assess the difficulty of kernel generation tasks. The
observations, metrics, and our data collection and curation pipeline can help
obtain better data in the kernel generation task in the future.

### 29. TALENT: Table VQA via Augmented Language-Enhanced Natural-text Transcription

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Guo Yutong, Wanying Wang, Yue Wu, Zichen Miao, Haoyu Wang
- **URL**: <http://arxiv.org/abs/2510.07098v1>
- **Submitted**: 2025-10-08 14:56:42
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Table VQA, leveraging vision-language models and large language models for reasoning. While it involves multimodal reasoning, it does not directly relate to information retrieval, query understanding, or ranking models, which are core areas of interest. The paper's emphasis on computer vision and OCR transcription makes it more relevant to the broader NLP domain, but not specifically to the user's research interests.

#### Abstract
> Table Visual Question Answering (Table VQA) is typically addressed by large
vision-language models (VLMs). While such models can answer directly from
images, they often miss fine-grained details unless scaled to very large sizes,
which are computationally prohibitive, especially for mobile deployment. A
lighter alternative is to have a small VLM perform OCR and then use a large
language model (LLM) to reason over structured outputs such as Markdown tables.
However, these representations are not naturally optimized for LLMs and still
introduce substantial errors. We propose TALENT (Table VQA via Augmented
Language-Enhanced Natural-text Transcription), a lightweight framework that
leverages dual representations of tables. TALENT prompts a small VLM to produce
both OCR text and natural language narration, then combines them with the
question for reasoning by an LLM. This reframes Table VQA as an LLM-centric
multimodal reasoning task, where the VLM serves as a perception-narration
module rather than a monolithic solver. Additionally, we construct ReTabVQA, a
more challenging Table VQA dataset requiring multi-step quantitative reasoning
over table images. Experiments show that TALENT enables a small VLM-LLM
combination to match or surpass a single large VLM at significantly lower
computational cost on both public datasets and ReTabVQA.

### 30. LuxInstruct: A Cross-Lingual Instruction Tuning Dataset For Luxembourgish

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Fred Philippy, Laura Bernardy, Siwen Guo, Jacques Klein, Tegawend√© F. Bissyand√©
- **URL**: <http://arxiv.org/abs/2510.07074v1>
- **Submitted**: 2025-10-08 14:35:59
- **Comment**: Paper under review; Dataset available at
  https://huggingface.co/datasets/fredxlpy/LuxInstruct
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, which are the core areas of your research interests. While it involves Natural Language Processing, it focuses on a specific task (instruction tuning) and a low-resource language (Luxembourgish), which doesn't align with your broader interests in e-commerce, deep semantic understanding, and real-time relevance optimization.

#### Abstract
> Instruction tuning has become a key technique for enhancing the performance
of large language models, enabling them to better follow human prompts.
However, low-resource languages such as Luxembourgish face severe limitations
due to the lack of high-quality instruction datasets. Traditional reliance on
machine translation often introduces semantic misalignment and cultural
inaccuracies. In this work, we address these challenges by creating a
cross-lingual instruction tuning dataset for Luxembourgish, without resorting
to machine-generated translations into it. Instead, by leveraging aligned data
from English, French, and German, we build a high-quality dataset that
preserves linguistic and cultural nuances. We provide evidence that
cross-lingual instruction tuning not only improves representational alignment
across languages but also the model's generative capabilities in Luxembourgish.
This highlights how cross-lingual data curation can avoid the common pitfalls
of machine-translated data and directly benefit low-resource language
development.

### 31. Does Local News Stay Local?: Online Content Shifts in Sinclair-Acquired Stations

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Miriam Wanner, Sophia Hager, Anjalie Field
- **URL**: <http://arxiv.org/abs/2510.07060v1>
- **Submitted**: 2025-10-08 14:27:00
- **Topic Keywords**: rag
- **Reason**: This paper appears to be focused on the impact of corporate acquisition on local news content, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on the topic of content, it is more focused on media studies and does not involve query understanding, ranking models, or user behavior modeling.

#### Abstract
> Local news stations are often considered to be reliable sources of
non-politicized information, particularly local concerns that residents care
about. Because these stations are trusted news sources, viewers are
particularly susceptible to the information they report. The Sinclair Broadcast
group is a broadcasting company that has acquired many local news stations in
the last decade. We investigate the effects of local news stations being
acquired by Sinclair: how does coverage change? We use computational methods to
investigate changes in internet content put out by local news stations before
and after being acquired by Sinclair and in comparison to national news
outlets. We find that there is clear evidence that local news stations report
more frequently on national news at the expense of local topics, and that their
coverage of polarizing national topics increases.

### 32. Pragyaan: Designing and Curating High-Quality Cultural Post-Training Datasets for Indian Languages

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Neel Prabhanjan Rachamalla, Aravind Konakalla, Gautam Rajeev, Ashish Kulkarni, Chandra Khatri, Shubham Agarwal
- **URL**: <http://arxiv.org/abs/2510.07000v1>
- **Submitted**: 2025-10-08 13:23:45
- **Comment**: EMNLP 2025
- **Topic Keywords**: rag
- **Reason**: This paper focuses on creating high-quality post-training datasets for Indian languages, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, it's more focused on dataset curation and language modeling, rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> The effectiveness of Large Language Models (LLMs) depends heavily on the
availability of high-quality post-training data, particularly
instruction-tuning and preference-based examples. Existing open-source
datasets, however, often lack multilingual coverage, cultural grounding, and
suffer from task diversity gaps that are especially pronounced for Indian
languages. We introduce a human-in-the-loop pipeline that combines translations
with synthetic expansion to produce reliable and diverse Indic post-training
data. Using this pipeline, we curate two datasets: Pragyaan-IT (22.5K) and
Pragyaan-Align (100K) across 10 Indian languages covering 13 broad and 56
sub-categories, leveraging 57 diverse datasets. Our dataset protocol
incorporates several often-overlooked dimensions and emphasize task diversity,
multi-turn dialogue, instruction fidelity, safety alignment, and preservation
of cultural nuance, providing a foundation for more inclusive and effective
multilingual LLMs.

### 33. Open ASR Leaderboard: Towards Reproducible and Transparent Multilingual and Long-Form Speech Recognition Evaluation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Vaibhav Srivastav, Steven Zheng, Eric Bezzam, Eustache Le Bihan, Nithin Koluguri, Piotr ≈ªelasko, Somshubra Majumdar, Adel Moumen, Sanchit Gandhi
- **URL**: <http://arxiv.org/abs/2510.06961v2>
- **Submitted**: 2025-10-08 12:44:51
- **Comment**: Submitted to ICASSP 2026; Leaderboard:
  https://huggingface.co/spaces/hf-audio/open_asr_leaderboard ; Code:
  https://github.com/huggingface/open_asr_leaderboard
- **Topic Keywords**: rag
- **Reason**: This paper focuses on speech recognition evaluation, which is not directly related to your core research themes in Information Retrieval and Search technologies. Although it involves some aspects of ranking models and efficiency, the context is specific to ASR and does not align with your primary interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> Despite rapid progress, ASR evaluation remains saturated with short-form
English, and efficiency is rarely reported. We present the Open ASR
Leaderboard, a fully reproducible benchmark and interactive leaderboard
comparing 60+ open-source and proprietary systems across 11 datasets, including
dedicated multilingual and long-form tracks. We standardize text normalization
and report both word error rate (WER) and inverse real-time factor (RTFx),
enabling fair accuracy-efficiency comparisons. For English transcription,
Conformer encoders paired with LLM decoders achieve the best average WER but
are slower, while CTC and TDT decoders deliver much better RTFx, making them
attractive for long-form and offline use. Whisper-derived encoders fine-tuned
for English improve accuracy but often trade off multilingual coverage. All
code and dataset loaders are open-sourced to support transparent, extensible
evaluation.

### 34. Where to Begin: Efficient Pretraining via Subnetwork Selection and Distillation

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Arjun Krishnakumar, Rhea Sanjay Sukthanker, Hannan Javed Mahadik, Gabriela Kadlecov√°, Vladyslav Moroshan, Timur Carstensen, Frank Hutter, Aaron Klein
- **URL**: <http://arxiv.org/abs/2510.07227v1>
- **Submitted**: 2025-10-08 16:57:46
- **Topic Keywords**: search
- **Reason**: This paper focuses on efficient pretraining of small language models, which is not directly related to information retrieval, query understanding, or ranking models. While it touches on NLP, the context is on model development rather than application in search technologies.

#### Abstract
> Small Language models (SLMs) offer an efficient and accessible alternative to
Large Language Models (LLMs), delivering strong performance while using far
fewer resources. We introduce a simple and effective framework for pretraining
SLMs that brings together three complementary ideas. First, we identify
structurally sparse sub-network initializations that consistently outperform
randomly initialized models of similar size under the same compute budget.
Second, we use evolutionary search to automatically discover high-quality
sub-network initializations, providing better starting points for pretraining.
Third, we apply knowledge distillation from larger teacher models to speed up
training and improve generalization. Together, these components make SLM
pretraining substantially more efficient: our best model, discovered using
evolutionary search and initialized with LLM weights, matches the validation
perplexity of a comparable Pythia SLM while requiring 9.2x fewer pretraining
tokens. We release all code and models at
https://github.com/whittle-org/whittle/, offering a practical and reproducible
path toward cost-efficient small language model development at scale.

### 35. More Data or Better Data? A Critical Analysis of Data Selection and Synthesis for Mathematical Reasoning

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yike Zhao, Simin Guo, Ziqing Yang, Shifan Han, Dahua Lin, Fei Tan
- **URL**: <http://arxiv.org/abs/2510.07169v1>
- **Submitted**: 2025-10-08 16:07:26
- **Comment**: 12 pages, 3 figures, submitted to EMNLP 2025 Industry Track
- **Topic Keywords**: search
- **Reason**: This paper focuses on data selection and synthesis for mathematical reasoning in Large Language Models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it touches on model enhancement, the context is specific to mathematical reasoning and does not align with your primary focus on real-time relevance optimization and deep semantic understanding.

#### Abstract
> The reasoning capabilities of Large Language Models (LLMs) play a critical
role in many downstream tasks, yet depend strongly on the quality of training
data. Despite various proposed data construction methods, their practical
utility in real-world pipelines remains underexplored. In this work, we conduct
a comprehensive analysis of open-source datasets and data synthesis techniques
for mathematical reasoning, evaluating them under a unified pipeline designed
to mirror training and deployment scenarios. We further distill effective data
selection strategies and identify practical methods suitable for industrial
applications. Our findings highlight that structuring data in more
interpretable formats, or distilling from stronger models often outweighs
simply scaling up data volume. This study provides actionable guidance for
integrating training data to enhance LLM capabilities, supporting both
cost-effective data curation and scalable model enhancement. We hope this work
will inspire further research on how to balance "more data" versus "better
data" for real-world reasoning tasks.

### 36. Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Rajvee Sheth, Samridhi Raj Sinha, Mahavir Patil, Himanshu Beniwal, Mayank Singh
- **URL**: <http://arxiv.org/abs/2510.07037v2>
- **Submitted**: 2025-10-08 14:04:14
- **Topic Keywords**: search
- **Reason**: This paper is primarily focused on Code-Switched NLP and large language models, which is outside the user's core research themes in Information Retrieval and Search technologies. While it touches on multilingual aspects, it does not directly relate to query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's interests.

#### Abstract
> Code-switching (CSW), the alternation of languages and scripts within a
single utterance, remains a fundamental challenge for multiling ual NLP, even
amidst the rapid advances of large language models (LLMs). Most LLMs still
struggle with mixed-language inputs, limited CSW datasets, and evaluation
biases, hindering deployment in multilingual societies. This survey provides
the first comprehensive analysis of CSW-aware LLM research, reviewing 308
studies spanning five research areas, 12 NLP tasks, 30+ datasets, and 80+
languages. We classify recent advances by architecture, training strategy, and
evaluation methodology, outlining how LLMs have reshaped CSW modeling and what
challenges persist. The paper concludes with a roadmap emphasizing the need for
inclusive datasets, fair evaluation, and linguistically grounded models to
achieve truly multilingual intelligence. A curated collection of all resources
is maintained at https://github.com/lingo-iitgn/awesome-code-mixing/.

---

