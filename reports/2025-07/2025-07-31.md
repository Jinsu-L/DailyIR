# Daily Papers Report - 2025-07-31

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Intent-Aware Neural Query Reformulation for Behavior-Aligned Product Search

- **LLM Score**: 8
- **Keyword Score**: 17
- **Authors**: Jayanth Yetukuri, Ishita Khan
- **URL**: <http://arxiv.org/abs/2507.22213v1>
- **Submitted**: 2025-07-29 20:20:07
- **Comment**: Accepted at SIGIR eCom'25.
  https://sigir-ecom.github.io/eCom25Papers/paper_23.pdf
- **Topic Keywords**: query, ranking, relevance, rag, retrieval, commerce, e-commerce, rank, search
- **Reason**: The paper focuses on intent-aware query reformulation in e-commerce search systems, which aligns with your interest in Information Retrieval and Search technologies. The use of neural networks and sequence mining techniques is also relevant to your background in Natural Language Processing and data mining. The paper's emphasis on understanding user intent and behavior modeling, such as click models, is particularly relevant to your research interests.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Intent-conditioned reformulation framework for e-commerce search pipelines
- **Aim**: Enhance retrieval relevance and downstream engagement metrics by aligning query rewriting with underlying user objectives
- **Rationale**: Bridging the gap between sparse user inputs and complex product discovery goals through intent-centric modeling
- **Ground**: Mining and analyzing large-scale buyer query logs to extract fine-grained intent signals from both explicit interactions and implicit behavioral cues
- **Experiment**: Evaluating the framework using novel metrics, including Rewrite Type Agreement Score, Rewrite Type Frequency-Weighted Recall, and Rewrite Type Frequency-Weighted Precision, and demonstrating its effectiveness using three models
- **Takeaway**: The proposed framework delivers precision-enhanced retrieval, a contextually adaptive, and behaviorally informed search experience, addressing multiple pain points in modern search pipelines

#### Abstract
> Understanding and modeling buyer intent is a foundational challenge in
optimizing search query reformulation within the dynamic landscape of
e-commerce search systems. This work introduces a robust data pipeline designed
to mine and analyze large-scale buyer query logs, with a focus on extracting
fine-grained intent signals from both explicit interactions and implicit
behavioral cues. Leveraging advanced sequence mining techniques and supervised
learning models, the pipeline systematically captures patterns indicative of
latent purchase intent, enabling the construction of a high-fidelity,
intent-rich dataset. The proposed framework facilitates the development of
adaptive query rewrite strategies by grounding reformulations in inferred user
intent rather than surface-level lexical signals. This alignment between query
rewriting and underlying user objectives enhances both retrieval relevance and
downstream engagement metrics. Empirical evaluations across multiple product
verticals demonstrate measurable gains in precision-oriented relevance metrics,
underscoring the efficacy of intent-aware reformulation. Our findings highlight
the value of intent-centric modeling in bridging the gap between sparse user
inputs and complex product discovery goals, and establish a scalable foundation
for future research in user-aligned neural retrieval and ranking systems.

---

### 2. NeedleChain: Measuring Intact Long-Context Reasoning Capability of Large Language Models

- **LLM Score**: 7
- **Keyword Score**: 3
- **Authors**: Hyeonseok Moon, Heuiseok Lim
- **URL**: <http://arxiv.org/abs/2507.22411v1>
- **Submitted**: 2025-07-30 06:29:50
- **Comment**: 13 pages
- **Topic Keywords**: query
- **Reason**: The paper's focus on evaluating the long-context understanding of Large Language Models aligns with your interest in query understanding and ranking models. The introduction of a novel benchmark, NeedleChain, and the proposed strategy to improve LC understanding capability of LLMs are relevant to your research themes. However, the paper's primary focus is on NLP and LLMs, which is not your core area of expertise in IR and search technologies.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Evaluating Long-Context Reasoning Capability of Large Language Models
- **Aim**: Introduce a novel benchmark, NeedleChain, to assess the long-context reasoning capability of LLMs and propose a strategy, ROPE Contraction, to improve their performance
- **Rationale**: Existing benchmarks may overestimate LLMs' long-context understanding capability due to inclusion of query-irrelevant information
- **Ground**: NeedleChain benchmark requires LLMs to fully grasp input to answer correctly, allowing for flexible context length and reasoning order
- **Experiment**: Experiments using state-of-the-art LLMs show struggles on NeedleChain benchmark, particularly with long token lengths and reverse reasoning
- **Takeaway**: LLMs face challenges in understanding long-context tasks, and structuring context to emphasize interrelations between information can improve performance; ROPE Contraction strategy can enhance long-context comprehension ability of LLMs

#### Abstract
> The Needle-in-a-Haystack (NIAH) benchmark is widely used to evaluate Large
Language Models' (LLMs) ability to understand long contexts (LC). It evaluates
the capability to identify query-relevant context within extensive
query-irrelevant passages. Although this method serves as a widely accepted
standard for evaluating long-context understanding, our findings suggest it may
overestimate the true LC capability of LLMs. We demonstrate that even
state-of-the-art models such as GPT-4o struggle to intactly incorporate given
contexts made up of solely query-relevant ten sentences. In response, we
introduce a novel benchmark, \textbf{NeedleChain}, where the context consists
entirely of query-relevant information, requiring the LLM to fully grasp the
input to answer correctly. Our benchmark allows for flexible context length and
reasoning order, offering a more comprehensive analysis of LLM performance.
Additionally, we propose an extremely simple yet compelling strategy to improve
LC understanding capability of LLM: ROPE Contraction. Our experiments with
various advanced LLMs reveal a notable disparity between their ability to
process large contexts and their capacity to fully understand them. Source code
and datasets are available at https://github.com/hyeonseokk/NeedleChain

---

### 3. A Comprehensive Taxonomy of Negation for NLP and Neural Retrievers

- **LLM Score**: 6
- **Keyword Score**: 13
- **Authors**: Roxana Petcu, Samarth Bhargav, Maarten de Rijke, Evangelos Kanoulas
- **URL**: <http://arxiv.org/abs/2507.22337v1>
- **Submitted**: 2025-07-30 02:44:20
- **Topic Keywords**: information retrieval, retriever, queries, rag, retrieval
- **Reason**: The paper explores negation in neural information retrieval, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on negation and its taxonomy is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Negation in Neural Information Retrieval and Language Models
- **Aim**: To propose a comprehensive taxonomy of negation and develop a classification mechanism to improve the performance of neural IR models on negation tasks
- **Rationale**: Proper treatment of negation is essential for retrieval models to provide accurate information to users, but handling negation is challenging due to ambiguity of negation scope and pragmatic inferences
- **Ground**: The authors generate two benchmark datasets covering all proposed negation types and propose a classification mechanism involving typed lambda calculus formalizations and categorization in four iterative steps
- **Experiment**: The authors evaluate the generated datasets and the classification mechanism using human annotation and various retrieval models, and fine-tune three models on different datasets
- **Takeaway**: The study contributes to the understanding of negation in natural language processing and provides a framework for evaluating and improving the performance of neural models on negation tasks

#### Abstract
> Understanding and solving complex reasoning tasks is vital for addressing the
information needs of a user. Although dense neural models learn contextualised
embeddings, they still underperform on queries containing negation. To
understand this phenomenon, we study negation in both traditional neural
information retrieval and LLM-based models. We (1) introduce a taxonomy of
negation that derives from philosophical, linguistic, and logical definitions;
(2) generate two benchmark datasets that can be used to evaluate the
performance of neural information retrieval models and to fine-tune models for
a more robust performance on negation; and (3) propose a logic-based
classification mechanism that can be used to analyze the performance of
retrieval models on existing datasets. Our taxonomy produces a balanced data
distribution over negation types, providing a better training setup that leads
to faster convergence on the NevIR dataset. Moreover, we propose a
classification schema that reveals the coverage of negation types in existing
datasets, offering insights into the factors that might affect the
generalization of fine-tuned models on negation.

---

### 4. CliCARE: Grounding Large Language Models in Clinical Guidelines for Decision Support over Longitudinal Cancer Electronic Health Records

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Dongchen Li, Jitao Liang, Wei Li, Xiaoyu Wang, Longbing Cao, Kun Yu
- **URL**: <http://arxiv.org/abs/2507.22533v1>
- **Submitted**: 2025-07-30 10:02:16
- **Topic Keywords**: rag, ctr, retrieval, recommend
- **Reason**: The paper proposes a framework for grounding large language models in clinical guidelines for decision support over longitudinal cancer electronic health records. While it touches on some aspects of information retrieval, such as processing unstructured data and generating a high-fidelity clinical summary, the focus is primarily on clinical decision support and oncology, which is not directly related to the user's core research themes in information retrieval and search technologies.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: CliCARE: A Framework for Grounding Large Language Models in Clinical Guidelines for Decision Support
- **Aim**: To develop a framework that addresses the challenges of processing extensive and multilingual patient records, clinical hallucination, and unreliable evaluation metrics in implementing Large Language Models (LLMs) for clinical decision support
- **Rationale**: The framework transforms unstructured, longitudinal Electronic Health Records (EHRs) into patient-specific Temporal Knowledge Graphs (TKGs) and grounds the decision support process by aligning real-world patient trajectories with a normative guideline knowledge graph
- **Ground**: CliCARE consists of three main components: EHR-to-TKGs transformation, event extraction, and pathway generation, and uses a BERT model to match patient trajectories with guideline paths
- **Experiment**: The framework is evaluated using two large-scale clinical datasets: CancerEHR and MIMIC-Cancer, and compared against various robust baseline methods, including standard retrieval-augmented generation (RAG) pipelines implemented with powerful open-source models
- **Takeaway**: CliCARE outperforms the baseline methods, demonstrating the effectiveness of the framework in clinical generation tasks, particularly on complex datasets, and highlighting the importance of considering context length and knowledge graph alignment in model performance

#### Abstract
> Large Language Models (LLMs) hold significant promise for improving clinical
decision support and reducing physician burnout by synthesizing complex,
longitudinal cancer Electronic Health Records (EHRs). However, their
implementation in this critical field faces three primary challenges: the
inability to effectively process the extensive length and multilingual nature
of patient records for accurate temporal analysis; a heightened risk of
clinical hallucination, as conventional grounding techniques such as
Retrieval-Augmented Generation (RAG) do not adequately incorporate
process-oriented clinical guidelines; and unreliable evaluation metrics that
hinder the validation of AI systems in oncology. To address these issues, we
propose CliCARE, a framework for Grounding Large Language Models in Clinical
Guidelines for Decision Support over Longitudinal Cancer Electronic Health
Records. The framework operates by transforming unstructured, longitudinal EHRs
into patient-specific Temporal Knowledge Graphs (TKGs) to capture long-range
dependencies, and then grounding the decision support process by aligning these
real-world patient trajectories with a normative guideline knowledge graph.
This approach provides oncologists with evidence-grounded decision support by
generating a high-fidelity clinical summary and an actionable recommendation.
We validated our framework using large-scale, longitudinal data from a private
Chinese cancer dataset and the public English MIMIC-IV dataset. In these
diverse settings, CliCARE significantly outperforms strong baselines, including
leading long-context LLMs and Knowledge Graph-enhanced RAG methods. The
clinical validity of our results is supported by a robust evaluation protocol,
which demonstrates a high correlation with assessments made by expert
oncologists.

---

### 5. SLM-SQL: An Exploration of Small Language Models for Text-to-SQL

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Lei Sheng, Shuai-Shuai Xu
- **URL**: <http://arxiv.org/abs/2507.22478v1>
- **Submitted**: 2025-07-30 08:29:07
- **Comment**: 16 pages, 2 figures, work in progress
- **Topic Keywords**: queries, rag
- **Reason**: The paper explores the application of small language models for text-to-SQL tasks, which is a specific problem in Natural Language Processing. While it touches on the topic of query understanding, it is not directly related to ranking models or user behavior modeling, which are core areas of interest in Information Retrieval. The paper's focus on text-to-SQL translation is also not directly applicable to e-commerce or real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: SLM-SQL: A Novel Approach for Text-to-SQL Tasks
- **Aim**: To develop a novel approach, SLM-SQL, that leverages small language models (SLMs) for text-to-SQL tasks, addressing the limitation of SLMs' logical reasoning capabilities
- **Rationale**: SLMs offer advantages in inference speed and edge deployment suitability, but require improvement in logical reasoning capabilities
- **Ground**: The authors construct two derived datasets, SynSQL-Think-916K and SynSQL-Merge-Think-310K, and apply supervised fine-tuning and reinforcement learning-based post-training to the SLM
- **Experiment**: The authors evaluate the effectiveness and generalization of the proposed SLM-SQL method on the BIRD development set and the Spider dataset, achieving significant performance gains
- **Takeaway**: The paper contributes to the development of text-to-SQL approaches, demonstrating the effectiveness of SLM-SQL and highlighting the importance of synthetic data for supervised fine-tuning

#### Abstract
> Large language models (LLMs) have demonstrated strong performance in
translating natural language questions into SQL queries (Text-to-SQL). In
contrast, small language models (SLMs) ranging from 0.5B to 1.5B parameters
currently underperform on Text-to-SQL tasks due to their limited logical
reasoning capabilities. However, SLMs offer inherent advantages in inference
speed and suitability for edge deployment. To explore their potential in
Text-to-SQL applications, we leverage recent advancements in post-training
techniques. Specifically, we used the open-source SynSQL-2.5M dataset to
construct two derived datasets: SynSQL-Think-916K for SQL generation and
SynSQL-Merge-Think-310K for SQL merge revision. We then applied supervised
fine-tuning and reinforcement learning-based post-training to the SLM, followed
by inference using a corrective self-consistency approach. Experimental results
validate the effectiveness and generalizability of our method, SLM-SQL. On the
BIRD development set, the five evaluated models achieved an average improvement
of 31.4 points. Notably, the 0.5B model reached 56.87\% execution accuracy
(EX), while the 1.5B model achieved 67.08\% EX. We will release our dataset,
model, and code to github: https://github.com/CycloneBoy/slm_sql.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Multi-modal Relational Item Representation Learning for Inferring Substitutable and Complementary Items

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Junting Wang, Chenghuan Guo, Jiao Yang, Yanhui Guo, Yan Gao, Hari Sundaram
- **URL**: <http://arxiv.org/abs/2507.22268v1>
- **Submitted**: 2025-07-29 22:38:39
- **Topic Keywords**: rag, user behavior, recommend
- **Reason**: The paper focuses on multi-modal relational item representation learning for inferring substitutable and complementary items, which is related to information retrieval and search technologies. However, the paper's primary focus is on recommender systems, which is not the user's primary area of interest. The paper's use of graph neural networks and multi-modal foundational models is also not directly related to the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> We introduce a novel self-supervised multi-modal relational item
representation learning framework designed to infer substitutable and
complementary items. Existing approaches primarily focus on modeling item-item
associations deduced from user behaviors using graph neural networks (GNNs) or
leveraging item content information. However, these methods often overlook
critical challenges, such as noisy user behavior data and data sparsity due to
the long-tailed distribution of these behaviors. In this paper, we propose
MMSC, a self-supervised multi-modal relational item representation learning
framework to address these challenges. Specifically, MMSC consists of three
main components: (1) a multi-modal item representation learning module that
leverages a multi-modal foundational model and learns from item metadata, (2) a
self-supervised behavior-based representation learning module that denoises and
learns from user behavior data, and (3) a hierarchical representation
aggregation mechanism that integrates item representations at both the semantic
and task levels. Additionally, we leverage LLMs to generate augmented training
data, further enhancing the denoising process during training. We conduct
extensive experiments on five real-world datasets, showing that MMSC
outperforms existing baselines by 26.1% for substitutable recommendation and
39.2% for complementary recommendation. In addition, we empirically show that
MMSC is effective in modeling cold-start items.

### 7. From Sufficiency to Reflection: Reinforcement-Guided Thinking Quality in Retrieval-Augmented Reasoning for LLMs

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Jie He, Victor Gutierrez Basulto, Jeff Z. Pan
- **URL**: <http://arxiv.org/abs/2507.22716v1>
- **Submitted**: 2025-07-30 14:29:44
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on reinforcement learning-based retrieval-augmented generation methods for large language models, which is related to query understanding and ranking models in Information Retrieval. However, the paper's primary focus is on improving the reasoning abilities of language models, which is not directly aligned with my research interests in user behavior modeling and click models.

#### Abstract
> Reinforcement learning-based retrieval-augmented generation (RAG) methods
enhance the reasoning abilities of large language models (LLMs). However, most
rely only on final-answer rewards, overlooking intermediate reasoning quality.
This paper analyzes existing RAG reasoning models and identifies three main
failure patterns: (1) information insufficiency, meaning the model fails to
retrieve adequate support; (2) faulty reasoning, where logical or content-level
flaws appear despite sufficient information; and (3) answer-reasoning
inconsistency, where a valid reasoning chain leads to a mismatched final
answer. We propose TIRESRAG-R1, a novel framework using a
think-retrieve-reflect process and a multi-dimensional reward system to improve
reasoning and stability. TIRESRAG-R1 introduces: (1) a sufficiency reward to
encourage thorough retrieval; (2) a reasoning quality reward to assess the
rationality and accuracy of the reasoning chain; and (3) a reflection reward to
detect and revise errors. It also employs a difficulty-aware reweighting
strategy and training sample filtering to boost performance on complex tasks.
Experiments on four multi-hop QA datasets show that TIRESRAG-R1 outperforms
prior RAG methods and generalizes well to single-hop tasks. The code and data
are available at: https://github.com/probe2/TIRESRAG-R1.

### 8. RecGPT Technical Report

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Chao Yi, Dian Chen, Gaoyang Guo, Jiakai Tang, Jian Wu, Jing Yu, Mao Zhang, Sunhao Dai, Wen Chen, Wenjun Yang, Yuning Jiang, Zhujin Gao, Bo Zheng, Chi Li, Dimin Wang, Dixuan Wang, Fan Li, Fan Zhang, Haibin Chen, Haozhuang Liu, Jialin Zhu, Jiamang Wang, Jiawei Wu, Jin Cui, Ju Huang, Kai Zhang, Kan Liu, Lang Tian, Liang Rao, Longbin Li, Lulu Zhao, Na He, Peiyang Wang, Qiqi Huang, Tao Luo, Wenbo Su, Xiaoxiao He, Xin Tong, Xu Chen, Xunke Xi, Yang Li, Yaxuan Wu, Yeqiu Yang, Yi Hu, Yinnan Song, Yuchen Li, Yujie Luo, Yujin Yuan, Yuliang Yan, Zhengyang Wang, Zhibo Xiao, Zhixin Ma, Zile Zhou, Ziqi Zhang
- **URL**: <http://arxiv.org/abs/2507.22879v2>
- **Submitted**: 2025-07-30 17:55:06
- **Topic Keywords**: retrieval, recommend
- **Reason**: The paper discusses recommender systems, which is a related topic to information retrieval, but it focuses on user intent modeling and large language models, which is not directly aligned with the user's primary interest in query understanding, ranking models, and user behavior modeling. While the paper's intent-centric approach is an interesting direction, it does not seem to address the user's core research themes.

#### Abstract
> Recommender systems are among the most impactful applications of artificial
intelligence, serving as critical infrastructure connecting users, merchants,
and platforms. However, most current industrial systems remain heavily reliant
on historical co-occurrence patterns and log-fitting objectives, i.e.,
optimizing for past user interactions without explicitly modeling user intent.
This log-fitting approach often leads to overfitting to narrow historical
preferences, failing to capture users' evolving and latent interests. As a
result, it reinforces filter bubbles and long-tail phenomena, ultimately
harming user experience and threatening the sustainability of the whole
recommendation ecosystem.
  To address these challenges, we rethink the overall design paradigm of
recommender systems and propose RecGPT, a next-generation framework that places
user intent at the center of the recommendation pipeline. By integrating large
language models (LLMs) into key stages of user interest mining, item retrieval,
and explanation generation, RecGPT transforms log-fitting recommendation into
an intent-centric process. To effectively align general-purpose LLMs to the
above domain-specific recommendation tasks at scale, RecGPT incorporates a
multi-stage training paradigm, which integrates reasoning-enhanced
pre-alignment and self-training evolution, guided by a Human-LLM cooperative
judge system. Currently, RecGPT has been fully deployed on the Taobao App.
Online experiments demonstrate that RecGPT achieves consistent performance
gains across stakeholders: users benefit from increased content diversity and
satisfaction, merchants and the platform gain greater exposure and conversions.
These comprehensive improvement results across all stakeholders validates that
LLM-driven, intent-centric design can foster a more sustainable and mutually
beneficial recommendation ecosystem.

### 9. Beyond Natural Language Plans: Structure-Aware Planning for Query-Focused Table Summarization

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Weijia Zhang, Songgaojun Deng, Evangelos Kanoulas
- **URL**: <http://arxiv.org/abs/2507.22829v1>
- **Submitted**: 2025-07-30 16:42:19
- **Comment**: 10 pages, 4 figures, and 5 tables
- **Topic Keywords**: query
- **Reason**: The paper explores query-focused table summarization, which is related to information retrieval and search technologies. However, the focus on structured representations and multi-agent systems is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Query-focused table summarization requires complex reasoning, often
approached through step-by-step natural language (NL) plans. However, NL plans
are inherently ambiguous and lack structure, limiting their conversion into
executable programs like SQL and hindering scalability, especially for
multi-table tasks. To address this, we propose a paradigm shift to structured
representations. We introduce a new structured plan, TaSoF, inspired by
formalism in traditional multi-agent systems, and a framework, SPaGe, that
formalizes the reasoning process in three phases: 1) Structured Planning to
generate TaSoF from a query, 2) Graph-based Execution to convert plan steps
into SQL and model dependencies via a directed cyclic graph for parallel
execution, and 3) Summary Generation to produce query-focused summaries. Our
method explicitly captures complex dependencies and improves reliability.
Experiments on three public benchmarks show that SPaGe consistently outperforms
prior models in both single- and multi-table settings, demonstrating the
advantages of structured representations for robust and scalable summarization.

### 10. Strategic Deflection: Defending LLMs from Logit Manipulation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Yassine Rachidy, Jihad Rbaiti, Youssef Hmamouche, Faissal Sehbaoui, Amal El Fallah Seghrouchni
- **URL**: <http://arxiv.org/abs/2507.22160v1>
- **Submitted**: 2025-07-29 18:46:56
- **Comment**: 20 pages
- **Topic Keywords**: queries
- **Reason**: The paper focuses on Large Language Models (LLMs) and their security against logit manipulation attacks, which is a specific topic in NLP. While it touches on the idea of 'semantically adjacent' responses, it does not directly relate to query understanding, ranking models, or user behavior modeling in the context of information retrieval, which are the user's primary research interests.

#### Abstract
> With the growing adoption of Large Language Models (LLMs) in critical areas,
ensuring their security against jailbreaking attacks is paramount. While
traditional defenses primarily rely on refusing malicious prompts, recent
logit-level attacks have demonstrated the ability to bypass these safeguards by
directly manipulating the token-selection process during generation. We
introduce Strategic Deflection (SDeflection), a defense that redefines the
LLM's response to such advanced attacks. Instead of outright refusal, the model
produces an answer that is semantically adjacent to the user's request yet
strips away the harmful intent, thereby neutralizing the attacker's harmful
intent. Our experiments demonstrate that SDeflection significantly lowers
Attack Success Rate (ASR) while maintaining model performance on benign
queries. This work presents a critical shift in defensive strategies, moving
from simple refusal to strategic content redirection to neutralize advanced
threats.

### 11. Resource-Efficient Adaptation of Large Language Models for Text Embeddings via Prompt Engineering and Contrastive Fine-tuning

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Benedikt Roth, Stephan Rappensperger, Tianming Qiu, Hamza Imamoviƒá, Julian W√∂rmann, Hao Shen
- **URL**: <http://arxiv.org/abs/2507.22729v1>
- **Submitted**: 2025-07-30 14:49:30
- **Topic Keywords**: retrieval
- **Reason**: The paper explores adaptation strategies for pre-trained language models to generate text embeddings, which is related to NLP and data mining. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core interests in Information Retrieval. The paper's focus on language models and text embeddings is somewhat relevant, but not a central match for the user's research themes.

#### Abstract
> Large Language Models (LLMs) have become a cornerstone in Natural Language
Processing (NLP), achieving impressive performance in text generation. Their
token-level representations capture rich, human-aligned semantics. However,
pooling these vectors into a text embedding discards crucial information.
Nevertheless, many non-generative downstream tasks, such as clustering,
classification, or retrieval, still depend on accurate and controllable
sentence- or document-level embeddings. We explore several adaptation
strategies for pre-trained, decoder-only LLMs: (i) various aggregation
techniques for token embeddings, (ii) task-specific prompt engineering, and
(iii) text-level augmentation via contrastive fine-tuning. Combining these
components yields state-of-the-art performance on the English clustering track
of the Massive Text Embedding Benchmark (MTEB). An analysis of the attention
map further shows that fine-tuning shifts focus from prompt tokens to
semantically relevant words, indicating more effective compression of meaning
into the final hidden state. Our experiments demonstrate that LLMs can be
effectively adapted as text embedding models through a combination of prompt
engineering and resource-efficient contrastive fine-tuning on synthetically
generated positive pairs.

### 12. Intent Recognition and Out-of-Scope Detection using LLMs in Multi-party Conversations

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Galo Castillo-L√≥pez, Ga√´l de Chalendar, Nasredine Semmar
- **URL**: <http://arxiv.org/abs/2507.22289v1>
- **Submitted**: 2025-07-29 23:48:41
- **Comment**: Accepted for publication at SIGDIAL 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on intent recognition and out-of-scope detection in task-oriented dialogue systems, which is related to query understanding and user behavior modeling in information retrieval. However, the paper's primary focus is on natural language processing and dialogue systems, rather than search technologies or ranking models, which are core areas of interest for the user.

#### Abstract
> Intent recognition is a fundamental component in task-oriented dialogue
systems (TODS). Determining user intents and detecting whether an intent is
Out-of-Scope (OOS) is crucial for TODS to provide reliable responses. However,
traditional TODS require large amount of annotated data. In this work we
propose a hybrid approach to combine BERT and LLMs in zero and few-shot
settings to recognize intents and detect OOS utterances. Our approach leverages
LLMs generalization power and BERT's computational efficiency in such
scenarios. We evaluate our method on multi-party conversation corpora and
observe that sharing information from BERT outputs to LLMs leads to system
performance improvement.

### 13. AUV-Fusion: Cross-Modal Adversarial Fusion of User Interactions and Visual Perturbations Against VARS

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Hai Ling, Tianchi Wang, Xiaohao Liu, Zhulin Tao, Lifang Yang, Xianglin Huang
- **URL**: <http://arxiv.org/abs/2507.22880v1>
- **Submitted**: 2025-07-30 17:55:09
- **Comment**: 14 pages,6 figures
- **Topic Keywords**: recommend
- **Reason**: The paper explores adversarial attacks on Visual-Aware Recommender Systems, which is related to information retrieval and search technologies. However, the focus on recommender systems and visual perturbations is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Modern Visual-Aware Recommender Systems (VARS) exploit the integration of
user interaction data and visual features to deliver personalized
recommendations with high precision. However, their robustness against
adversarial attacks remains largely underexplored, posing significant risks to
system reliability and security. Existing attack strategies suffer from notable
limitations: shilling attacks are costly and detectable, and visual-only
perturbations often fail to align with user preferences. To address these
challenges, we propose AUV-Fusion, a cross-modal adversarial attack framework
that adopts high-order user preference modeling and cross-modal adversary
generation. Specifically, we obtain robust user embeddings through multi-hop
user-item interactions and transform them via an MLP into semantically aligned
perturbations. These perturbations are injected onto the latent space of a
pre-trained VAE within the diffusion model. By synergistically integrating
genuine user interaction data with visually plausible perturbations, AUV-Fusion
eliminates the need for injecting fake user profiles and effectively mitigates
the challenge of insufficient user preference extraction inherent in
traditional visual-only attacks. Comprehensive evaluations on diverse VARS
architectures and real-world datasets demonstrate that AUV-Fusion significantly
enhances the exposure of target (cold-start) items compared to conventional
baseline methods. Moreover, AUV-Fusion maintains exceptional stealth under
rigorous scrutiny.

### 14. Reducing Hallucinations in Summarization via Reinforcement Learning with Entity Hallucination Index

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Praveenkumar Katwe, Rakesh Chandra, Balabantaray Kali, Prasad Vittala
- **URL**: <http://arxiv.org/abs/2507.22744v1>
- **Submitted**: 2025-07-30 15:00:00
- **Comment**: 8
- **Topic Keywords**: search
- **Reason**: The paper focuses on reducing hallucinations in abstractive summarization, which is a related topic to information retrieval. However, the specific context of summarization and the use of reinforcement learning with entity hallucination index do not directly align with the user's primary interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Reducing hallucinations in abstractive summarization remains a critical
challenge for deploying language models (LMs) in real-world settings. In this
work, we introduce a rewarddriven fine-tuning framework that explicitly
optimizes for Entity Hallucination Index (EHI), a metric designed to quantify
the presence, correctness, and grounding of named entities in generated
summaries. Given a corpus of meeting transcripts, we first generate baseline
summaries using a pre-trained LM and compute EHI scores via automatic entity
extraction and matching. We then apply reinforcement learning to fine-tune the
model parameters, using EHI as a reward signal to bias generation toward
entity-faithful outputs. Our approach does not rely on human-written factuality
annotations, enabling scalable fine-tuning. Experiments demonstrate consistent
improvements in EHI across datasets, with qualitative analysis revealing a
significant reduction in entity-level hallucinations without degradation in
fluency or informativeness. We release a reproducible Colab pipeline,
facilitating further research on hallucination-aware model fine-tuning using
lightweight, hallucintion metrics like EHI.

### 15. ControlMed: Adding Reasoning Control to Medical Language Model

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Sung-Min Lee, Siyoon Lee, Juyeon Kim, Kyungmin Roh
- **URL**: <http://arxiv.org/abs/2507.22545v1>
- **Submitted**: 2025-07-30 10:17:07
- **Comment**: 13 pages
- **Topic Keywords**: korea
- **Reason**: The paper introduces a medical language model that enables fine-grained control over the reasoning process, which is an interesting concept. However, it does not directly relate to information retrieval, search technologies, or query understanding, which are the user's primary research interests. The paper's focus on medical language models and clinical decision-making is somewhat relevant, but not a central match for the user's research themes.

#### Abstract
> Reasoning Large Language Models (LLMs) with enhanced accuracy and
explainability are increasingly being adopted in the medical domain, as the
life-critical nature of clinical decision-making demands reliable support.
Despite these advancements, existing reasoning LLMs often generate
unnecessarily lengthy reasoning processes, leading to significant computational
overhead and response latency. These limitations hinder their practical
deployment in real-world clinical environments. To address these challenges, we
introduce \textbf{ControlMed}, a medical language model that enables users to
actively control the length of the reasoning process at inference time through
fine-grained control markers. ControlMed is trained through a three-stage
pipeline: 1) pre-training on a large-scale synthetic medical instruction
dataset covering both \textit{direct} and \textit{reasoning responses}; 2)
supervised fine-tuning with multi-length reasoning data and explicit
length-control markers; and 3) reinforcement learning with model-based reward
signals to enhance factual accuracy and response quality. Experimental results
on a variety of English and Korean medical benchmarks demonstrate that our
model achieves similar or better performance compared to state-of-the-art
models. Furthermore, users can flexibly balance reasoning accuracy and
computational efficiency by controlling the reasoning length as needed. These
findings demonstrate that ControlMed is a practical and adaptable solution for
clinical question answering and medical information analysis.

### 16. Generative Recommendation with Semantic IDs: A Practitioner's Handbook

- **LLM Score**: 3
- **Keyword Score**: 2
- **Authors**: Clark Mingxuan Ju, Liam Collins, Leonardo Neves, Bhuvesh Kumar, Louis Yufeng Wang, Tong Zhao, Neil Shah
- **URL**: <http://arxiv.org/abs/2507.22224v1>
- **Submitted**: 2025-07-29 20:41:51
- **Topic Keywords**: recommend, search
- **Reason**: The paper focuses on generative recommendation with semantic IDs, which is not directly related to the user's primary research interests in Information Retrieval, query understanding, and ranking models. While the paper touches on semantic representations and discrete decoding, the context is different from the user's background in e-commerce and NLP. The paper's emphasis on recommender systems and open-source framework also diverges from the user's focus on information retrieval and real-time relevance optimization.

#### Abstract
> Generative recommendation (GR) has gained increasing attention for its
promising performance compared to traditional models. A key factor contributing
to the success of GR is the semantic ID (SID), which converts continuous
semantic representations (e.g., from large language models) into discrete ID
sequences. This enables GR models with SIDs to both incorporate semantic
information and learn collaborative filtering signals, while retaining the
benefits of discrete decoding. However, varied modeling techniques,
hyper-parameters, and experimental setups in existing literature make direct
comparisons between GR proposals challenging. Furthermore, the absence of an
open-source, unified framework hinders systematic benchmarking and extension,
slowing model iteration. To address this challenge, our work introduces and
open-sources a framework for Generative Recommendation with semantic ID, namely
GRID, specifically designed for modularity to facilitate easy component
swapping and accelerate idea iteration. Using GRID, we systematically
experiment with and ablate different components of GR models with SIDs on
public benchmarks. Our comprehensive experiments with GRID reveal that many
overlooked architectural components in GR models with SIDs substantially impact
performance. This offers both novel insights and validates the utility of an
open-source platform for robust benchmarking and GR research advancement. GRID
is open-sourced at https://github.com/snap-research/GRID.

### 17. The role of media memorability in facilitating startups' access to venture capital funding

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: L. Toschi, S. Torrisi, A. Fronzetti Colladon
- **URL**: <http://arxiv.org/abs/2507.22201v1>
- **Submitted**: 2025-07-29 19:58:41
- **Topic Keywords**: relevance, rag, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. The topic of venture capital funding and media memorability is outside the scope of your primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Media reputation plays an important role in attracting venture capital
investment. However, prior research has focused too narrowly on general media
exposure, limiting our understanding of how media truly influences funding
decisions. As informed decision-makers, venture capitalists respond to more
nuanced aspects of media content. We introduce the concept of media
memorability - the media's ability to imprint a startup's name in the memory of
relevant investors. Using data from 197 UK startups in the micro and
nanotechnology sector (funded between 1995 and 2004), we show that media
memorability significantly influences investment outcomes. Our findings suggest
that venture capitalists rely on detailed cues such as a startup's
distinctiveness and connectivity within news semantic networks. This
contributes to research on entrepreneurial finance and media legitimation. In
practice, startups should go beyond frequent media mentions to strengthen brand
memorability through more targeted, meaningful coverage highlighting their
uniqueness and relevance within the broader industry conversation.

### 18. PATENTWRITER: A Benchmarking Study for Patent Drafting with LLMs

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Homaira Huda Shomee, Suman Kalyan Maity, Sourav Medya
- **URL**: <http://arxiv.org/abs/2507.22387v1>
- **Submitted**: 2025-07-30 05:17:35
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper focuses on leveraging large language models for patent writing, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing, the scope is limited to patent drafting and does not align with the user's primary research interests.

#### Abstract
> Large language models (LLMs) have emerged as transformative approaches in
several important fields. This paper aims for a paradigm shift for patent
writing by leveraging LLMs to overcome the tedious patent-filing process. In
this work, we present PATENTWRITER, the first unified benchmarking framework
for evaluating LLMs in patent abstract generation. Given the first claim of a
patent, we evaluate six leading LLMs -- including GPT-4 and LLaMA-3 -- under a
consistent setup spanning zero-shot, few-shot, and chain-of-thought prompting
strategies to generate the abstract of the patent. Our benchmark PATENTWRITER
goes beyond surface-level evaluation: we systematically assess the output
quality using a comprehensive suite of metrics -- standard NLP measures (e.g.,
BLEU, ROUGE, BERTScore), robustness under three types of input perturbations,
and applicability in two downstream patent classification and retrieval tasks.
We also conduct stylistic analysis to assess length, readability, and tone.
Experimental results show that modern LLMs can generate high-fidelity and
stylistically appropriate patent abstracts, often surpassing domain-specific
baselines. Our code and dataset are open-sourced to support reproducibility and
future research.

### 19. C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Chengqian Ma, Wei Tao, Yiwen Guo
- **URL**: <http://arxiv.org/abs/2507.22968v1>
- **Submitted**: 2025-07-30 17:56:23
- **Topic Keywords**: queries, search
- **Reason**: This paper focuses on Spoken Dialogue Models, which is not directly related to Information Retrieval or Search technologies. While it mentions Large Language Models, the context is different from query understanding, ranking models, and user behavior modeling, which are core areas of interest.

#### Abstract
> Spoken Dialogue Models (SDMs) have recently attracted significant attention
for their ability to generate voice responses directly to users' spoken
queries. Despite their increasing popularity, there exists a gap in research
focused on comprehensively understanding their practical effectiveness in
comprehending and emulating human conversations. This is especially true
compared to text-based Large Language Models (LLMs), which benefit from
extensive benchmarking. Human voice interactions are inherently more complex
than text due to characteristics unique to spoken dialogue. Ambiguity poses one
challenge, stemming from semantic factors like polysemy, as well as
phonological aspects such as heterograph, heteronyms, and stress patterns.
Additionally, context-dependency, like omission, coreference, and multi-turn
interaction, adds further complexity to human conversational dynamics. To
illuminate the current state of SDM development and to address these
challenges, we present a benchmark dataset in this paper, which comprises 1,079
instances in English and Chinese. Accompanied by an LLM-based evaluation method
that closely aligns with human judgment, this dataset facilitates a
comprehensive exploration of the performance of SDMs in tackling these
practical challenges.

### 20. Traits Run Deep: Enhancing Personality Assessment via Psychology-Guided LLM Representations and Multimodal Apparent Behaviors

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Jia Li, Yichao He, Jiacheng Xu, Tianhao Luo, Zhenzhen Hu, Richang Hong, Meng Wang
- **URL**: <http://arxiv.org/abs/2507.22367v1>
- **Submitted**: 2025-07-30 04:12:14
- **Comment**: 8 pages, 3 figures, ACM MM 2025
- **Topic Keywords**: ranking, rank
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on personality assessment, psychology-guided LLM representations, and multimodal apparent behaviors, which are outside your areas of interest.

#### Abstract
> Accurate and reliable personality assessment plays a vital role in many
fields, such as emotional intelligence, mental health diagnostics, and
personalized education. Unlike fleeting emotions, personality traits are
stable, often subconsciously leaked through language, facial expressions, and
body behaviors, with asynchronous patterns across modalities. It was hard to
model personality semantics with traditional superficial features and seemed
impossible to achieve effective cross-modal understanding. To address these
challenges, we propose a novel personality assessment framework called
\textit{\textbf{Traits Run Deep}}. It employs
\textit{\textbf{psychology-informed prompts}} to elicit high-level
personality-relevant semantic representations. Besides, it devises a
\textit{\textbf{Text-Centric Trait Fusion Network}} that anchors rich text
semantics to align and integrate asynchronous signals from other modalities. To
be specific, such fusion module includes a Chunk-Wise Projector to decrease
dimensionality, a Cross-Modal Connector and a Text Feature Enhancer for
effective modality fusion and an ensemble regression head to improve
generalization in data-scarce situations. To our knowledge, we are the first to
apply personality-specific prompts to guide large language models (LLMs) in
extracting personality-aware semantics for improved representation quality.
Furthermore, extracting and fusing audio-visual apparent behavior features
further improves the accuracy. Experimental results on the AVI validation set
have demonstrated the effectiveness of the proposed components, i.e.,
approximately a 45\% reduction in mean squared error (MSE). Final evaluations
on the test set of the AVI Challenge 2025 confirm our method's superiority,
ranking first in the Personality Assessment track. The source code will be made
available at https://github.com/MSA-LMC/TraitsRunDeep.

### 21. IndoPref: A Multi-Domain Pairwise Preference Dataset for Indonesian

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Vanessa Rebecca Wiyono, David Anugraha, Ayu Purwarianti, Genta Indra Winata
- **URL**: <http://arxiv.org/abs/2507.22159v1>
- **Submitted**: 2025-07-29 18:46:25
- **Comment**: Preprint
- **Topic Keywords**: pairwise, search
- **Reason**: The paper focuses on a specific language, Indonesian, and a dataset for preference-based research, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. Although it mentions large language models, the primary focus is on evaluating the quality of generated text, rather than query understanding, ranking models, or real-time relevance optimization.

#### Abstract
> Over 200 million people speak Indonesian, yet the language remains
significantly underrepresented in preference-based research for large language
models (LLMs). Most existing multilingual datasets are derived from English
translations, often resulting in content that lacks cultural and linguistic
authenticity. To address this gap, we introduce IndoPref, the first fully
human-authored and multi-domain Indonesian preference dataset specifically
designed to evaluate the naturalness and quality of LLM-generated text. All
annotations are natively written in Indonesian and evaluated using
Krippendorff's alpha, demonstrating strong inter-annotator agreement.
Additionally, we benchmark the dataset across multiple LLMs and assess the
output quality of each model.

### 22. VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Ruifeng Yuan, Chenghao Xiao, Sicong Leng, Jianyu Wang, Long Li, Weiwen Xu, Hou Pong Chan, Deli Zhao, Tingyang Xu, Zhongyu Wei, Hao Zhang, Yu Rong
- **URL**: <http://arxiv.org/abs/2507.22607v2>
- **Submitted**: 2025-07-30 12:23:21
- **Comment**: 21 pages, 5 figures, 6 tables. Work in progress
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on multimodal reasoning and reinforcement learning, which is not directly related to the user's interests in Information Retrieval, Search technologies, and query understanding. While the paper mentions language models, it does not specifically address ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest for the user.

#### Abstract
> Reinforcement learning has proven its effectiveness in enhancing the
reasoning capabilities of large language models. Recent research efforts have
progressively extended this paradigm to multimodal reasoning tasks. Due to the
inherent complexity and diversity of multimodal tasks, especially in semantic
content and problem formulations, existing models often exhibit unstable
performance across various domains and difficulty levels. To address these
limitations, we propose VL-Cogito, an advanced multimodal reasoning model
trained via a novel multi-stage Progressive Curriculum Reinforcement Learning
(PCuRL) framework. PCuRL systematically guides the model through tasks of
gradually increasing difficulty, substantially improving its reasoning
abilities across diverse multimodal contexts. The framework introduces two key
innovations: (1) an online difficulty soft weighting mechanism, dynamically
adjusting training difficulty across successive RL training stages; and (2) a
dynamic length reward mechanism, which encourages the model to adaptively
regulate its reasoning path length according to task complexity, thus balancing
reasoning efficiency with correctness. Experimental evaluations demonstrate
that VL-Cogito consistently matches or surpasses existing reasoning-oriented
models across mainstream multimodal benchmarks spanning mathematics, science,
logic, and general understanding, validating the effectiveness of our approach.

### 23. BALSAM: A Platform for Benchmarking Arabic Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Rawan Al-Matham, Kareem Darwish, Raghad Al-Rasheed, Waad Alshammari, Muneera Alhoshan, Amal Almazrua, Asma Al Wazrah, Mais Alheraki, Firoj Alam, Preslav Nakov, Norah Alzahrani, Eman alBilali, Nizar Habash, Abdelrahman El-Sheikh, Muhammad Elmallah, Haonan Li, Hamdy Mubarak, Mohamed Anwar, Zaid Alyafeai, Ahmed Abdelali, Nora Altwairesh, Maram Hasanain, Abdulmohsen Al Thubaity, Shady Shehata, Bashar Alhafni, Injy Hamed, Go Inoue, Khalid Elmadani, Ossama Obeid, Fatima Haouari, Tamer Elsayed, Emad Alghamdi, Khalid Almubarak, Saied Alshahrani, Ola Aljarrah, Safa Alajlan, Areej Alshaqarawi, Maryam Alshihri, Sultana Alghurabi, Atikah Alzeghayer, Afrah Altamimi, Abdullah Alfaifi, Abdulrahman AlOsaimy
- **URL**: <http://arxiv.org/abs/2507.22603v1>
- **Submitted**: 2025-07-30 12:16:39
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on Arabic Large Language Models and benchmarking, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it touches on NLP tasks, the specific focus on Arabic and language models is not aligned with the user's primary research themes.

#### Abstract
> The impressive advancement of Large Language Models (LLMs) in English has not
been matched across all languages. In particular, LLM performance in Arabic
lags behind, due to data scarcity, linguistic diversity of Arabic and its
dialects, morphological complexity, etc. Progress is further hindered by the
quality of Arabic benchmarks, which typically rely on static, publicly
available data, lack comprehensive task coverage, or do not provide dedicated
platforms with blind test sets. This makes it challenging to measure actual
progress and to mitigate data contamination. Here, we aim to bridge these gaps.
In particular, we introduce BALSAM, a comprehensive, community-driven benchmark
aimed at advancing Arabic LLM development and evaluation. It includes 78 NLP
tasks from 14 broad categories, with 52K examples divided into 37K test and 15K
development, and a centralized, transparent platform for blind evaluation. We
envision BALSAM as a unifying platform that sets standards and promotes
collaborative research to advance Arabic LLM capabilities.

### 24. IFEvalCode: Controlled Code Generation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jian Yang, Wei Zhang, Shukai Liu, Linzheng Chai, Yingshui Tan, Jiaheng Liu, Ge Zhang, Wangchunshu Zhou, Guanglin Niu, Zhoujun Li, Binyuan Hui, Junyang Lin
- **URL**: <http://arxiv.org/abs/2507.22462v1>
- **Submitted**: 2025-07-30 08:08:48
- **Comment**: 10 pages
- **Topic Keywords**: queries
- **Reason**: The paper focuses on code generation and controlled code generation, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions language models, it does not explore query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user.

#### Abstract
> Code large language models (Code LLMs) have made significant progress in code
generation by translating natural language descriptions into functional code;
however, real-world applications often demand stricter adherence to detailed
requirements such as coding style, line count, and structural constraints,
beyond mere correctness. To address this, the paper introduces forward and
backward constraints generation to improve the instruction-following
capabilities of Code LLMs in controlled code generation, ensuring outputs align
more closely with human-defined guidelines. The authors further present
IFEvalCode, a multilingual benchmark comprising 1.6K test samples across seven
programming languages (Python, Java, JavaScript, TypeScript, Shell, C++, and
C#), with each sample featuring both Chinese and English queries. Unlike
existing benchmarks, IFEvalCode decouples evaluation into two metrics:
correctness (Corr.) and instruction-following (Instr.), enabling a more nuanced
assessment. Experiments on over 40 LLMs reveal that closed-source models
outperform open-source ones in controllable code generation and highlight a
significant gap between the models' ability to generate correct code versus
code that precisely follows instructions.

### 25. RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Dongyub Jude Lee, Zhenyi Ye, Pengcheng He
- **URL**: <http://arxiv.org/abs/2507.22219v1>
- **Submitted**: 2025-07-29 20:35:35
- **Topic Keywords**: rag, korea
- **Reason**: The paper focuses on machine translation, reinforcement learning, and teacher-model refinement, which are not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on machine translation and reinforcement learning is outside the user's primary focus.

#### Abstract
> Preference-learning methods for machine translation (MT)--such as Direct
Preference Optimization (DPO)--have achieved impressive gains but depend
heavily on large, carefully curated triplet datasets and often struggle to
generalize beyond their tuning domains. We propose Reinforcement Learning from
Teacher-Model Refinement (RLfR), a novel framework that removes reliance on
static triplets by leveraging continuous, high-quality feedback from an
external teacher model (GPT-4o). RLfR frames each translation step as a
micro-tutorial: the actor generates a hypothesis, the teacher refines it, and
the actor is rewarded based on how closely it aligns with the teacher's
refinement. Guided by two complementary signals--(i) negative edit distance,
promoting lexical and structural fidelity, and (ii) COMET score, ensuring
semantic adequacy--the actor progressively learns to emulate the teacher,
mirroring a human learning process through incremental, iterative improvement.
On the FLORES-200 benchmark (English to and from German, Spanish, Chinese,
Korean, and Japanese), RLfR consistently outperforms both MT-SFT and
preference-based baselines, significantly improving COMET (semantic adequacy)
and M-ETA (entity preservation) scores.

### 26. A Scalable Pipeline for Estimating Verb Frame Frequencies Using Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Adam M. Morgan, Adeen Flinker
- **URL**: <http://arxiv.org/abs/2507.22187v1>
- **Submitted**: 2025-07-29 19:30:11
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on estimating verb frame frequencies using large language models, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves natural language processing, the scope is limited to linguistic analysis and does not address query understanding, ranking models, or real-time relevance optimization, which are core areas of interest.

#### Abstract
> We present an automated pipeline for estimating Verb Frame Frequencies
(VFFs), the frequency with which a verb appears in particular syntactic frames.
VFFs provide a powerful window into syntax in both human and machine language
systems, but existing tools for calculating them are limited in scale,
accuracy, or accessibility. We use large language models (LLMs) to generate a
corpus of sentences containing 476 English verbs. Next, by instructing an LLM
to behave like an expert linguist, we had it analyze the syntactic structure of
the sentences in this corpus. This pipeline outperforms two widely used
syntactic parsers across multiple evaluation datasets. Furthermore, it requires
far fewer resources than manual parsing (the gold-standard), thereby enabling
rapid, scalable VFF estimation. Using the LLM parser, we produce a new VFF
database with broader verb coverage, finer-grained syntactic distinctions, and
explicit estimates of the relative frequencies of structural alternates
commonly studied in psycholinguistics. The pipeline is easily customizable and
extensible to new verbs, syntactic frames, and even other languages. We present
this work as a proof of concept for automated frame frequency estimation, and
release all code and data to support future research.

### 27. MASCA: LLM based-Multi Agents System for Credit Assessment

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Gautam Jajoo, Pranjal A Chitale, Saksham Agarwal
- **URL**: <http://arxiv.org/abs/2507.22758v1>
- **Submitted**: 2025-07-30 15:19:38
- **Comment**: Accepted at ACL REALM Workshop. Work in Progress
- **Topic Keywords**: rag
- **Reason**: The paper focuses on credit assessment using a multi-agent system with LLMs, which is not directly related to information retrieval, search technologies, or query understanding. While it uses some AI/ML techniques, the application domain is financial and not relevant to the user's primary research interests.

#### Abstract
> Recent advancements in financial problem-solving have leveraged LLMs and
agent-based systems, with a primary focus on trading and financial modeling.
However, credit assessment remains an underexplored challenge, traditionally
dependent on rule-based methods and statistical models. In this paper, we
introduce MASCA, an LLM-driven multi-agent system designed to enhance credit
evaluation by mirroring real-world decision-making processes. The framework
employs a layered architecture where specialized LLM-based agents
collaboratively tackle sub-tasks. Additionally, we integrate contrastive
learning for risk and reward assessment to optimize decision-making. We further
present a signaling game theory perspective on hierarchical multi-agent
systems, offering theoretical insights into their structure and interactions.
Our paper also includes a detailed bias analysis in credit assessment,
addressing fairness concerns. Experimental results demonstrate that MASCA
outperforms baseline approaches, highlighting the effectiveness of hierarchical
LLM-based multi-agent systems in financial applications, particularly in credit
scoring.

### 28. Next Tokens Denoising for Speech Synthesis

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yanqing Liu, Ruiqing Xue, Chong Zhang, Yufei Liu, Gang Wang, Bohan Li, Yao Qian, Lei He, Shujie Liu, Sheng Zhao
- **URL**: <http://arxiv.org/abs/2507.22746v1>
- **Submitted**: 2025-07-30 15:03:36
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests as it focuses on speech synthesis and text-to-speech models, which are outside the scope of information retrieval, search technologies, and natural language processing. The paper's abstract does not mention query understanding, ranking models, or user behavior modeling, which are key areas of interest for you.

#### Abstract
> While diffusion and autoregressive (AR) models have significantly advanced
generative modeling, they each present distinct limitations. AR models, which
rely on causal attention, cannot exploit future context and suffer from slow
generation speeds. Conversely, diffusion models struggle with key-value (KV)
caching. To overcome these challenges, we introduce Dragon-FM, a novel
text-to-speech (TTS) design that unifies AR and flow-matching. This model
processes 48 kHz audio codec tokens in chunks at a compact 12.5 tokens per
second rate. This design enables AR modeling across chunks, ensuring global
coherence, while parallel flow-matching within chunks facilitates fast
iterative denoising. Consequently, the proposed model can utilize KV-cache
across chunks and incorporate future context within each chunk. Furthermore, it
bridges continuous and discrete feature modeling, demonstrating that continuous
AR flow-matching can predict discrete tokens with finite scalar quantizers.
This efficient codec and fast chunk-autoregressive architecture also makes the
proposed model particularly effective for generating extended content.
Experiment for demos of our work} on podcast datasets demonstrate its
capability to efficiently generate high-quality zero-shot podcasts.

### 29. Listening to the Unspoken: Exploring 365 Aspects of Multimodal Interview Performance Assessment

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jia Li, Yang Wang, Wenhao Qian, Zhenzhen Hu, Richang Hong, Meng Wang
- **URL**: <http://arxiv.org/abs/2507.22676v1>
- **Submitted**: 2025-07-30 13:37:06
- **Comment**: 8 pages, 4 figures, ACM MM 2025.
  github:https://github.com/MSA-LMC/365Aspects
- **Topic Keywords**: rag
- **Reason**: The paper is not related to Information Retrieval or Search technologies, and does not involve query understanding, ranking models, or user behavior modeling. While it does involve multimodal data processing, the focus is on interview performance assessment, which is not a topic of interest in the user's research.

#### Abstract
> Interview performance assessment is essential for determining candidates'
suitability for professional positions. To ensure holistic and fair
evaluations, we propose a novel and comprehensive framework that explores
``365'' aspects of interview performance by integrating \textit{three}
modalities (video, audio, and text), \textit{six} responses per candidate, and
\textit{five} key evaluation dimensions. The framework employs
modality-specific feature extractors to encode heterogeneous data streams and
subsequently fused via a Shared Compression Multilayer Perceptron. This module
compresses multimodal embeddings into a unified latent space, facilitating
efficient feature interaction. To enhance prediction robustness, we incorporate
a two-level ensemble learning strategy: (1) independent regression heads
predict scores for each response, and (2) predictions are aggregated across
responses using a mean-pooling mechanism to produce final scores for the five
target dimensions. By listening to the unspoken, our approach captures both
explicit and implicit cues from multimodal data, enabling comprehensive and
unbiased assessments. Achieving a multi-dimensional average MSE of 0.1824, our
framework secured first place in the AVI Challenge 2025, demonstrating its
effectiveness and robustness in advancing automated and multimodal interview
performance assessment. The full implementation is available at
https://github.com/MSA-LMC/365Aspects.

### 30. Efficient Differentially Private Fine-Tuning of LLMs via Reinforcement Learning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Afshin Khadangi, Amir Sartipi, Igor Tchappi, Ramin Bahmani, Gilbert Fridgen
- **URL**: <http://arxiv.org/abs/2507.22565v1>
- **Submitted**: 2025-07-30 10:46:53
- **Topic Keywords**: rag
- **Reason**: This paper focuses on differentially private fine-tuning of large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on optimization techniques, the context is not relevant to the user's primary research interests.

#### Abstract
> The tension between data privacy and model utility has become the defining
bottleneck for the practical deployment of large language models (LLMs) trained
on sensitive corpora including healthcare. Differentially private stochastic
gradient descent (DP-SGD) guarantees formal privacy, yet it does so at a
pronounced cost: gradients are forcibly clipped and perturbed with noise,
degrading sample efficiency and final accuracy. Numerous variants have been
proposed to soften this trade-off, but they all share a handicap: their control
knobs are hard-coded, global, and oblivious to the evolving optimization
landscape. Consequently, practitioners are forced either to over-spend privacy
budget in pursuit of utility, or to accept mediocre models in order to stay
within privacy constraints. We present RLDP, the first framework to cast DP
optimization itself as a closed-loop control problem amenable to modern deep
reinforcement learning (RL). RLDP continuously senses rich statistics of the
learning dynamics and acts by selecting fine-grained per parameter
gradient-clipping thresholds as well as the magnitude of injected Gaussian
noise. A soft actor-critic (SAC) hyper-policy is trained online during language
model fine-tuning; it learns, from scratch, how to allocate the privacy budget
where it matters and when it matters. Across more than 1,600 ablation
experiments on GPT2-small, Llama-1B, Llama-3B, and Mistral-7B, RLDP delivers
perplexity reductions of 1.3-30.5% (mean 5.4%) and an average 5.6% downstream
utility gain. RLDP reaches each baseline's final utility after only 13-43% of
the gradient-update budget (mean speed-up 71%), all while honoring the same
($\epsilon$, $\delta$)-DP contract and exhibiting equal or lower susceptibility
to membership-inference and canary-extraction attacks.

### 31. Exploiting Synergistic Cognitive Biases to Bypass Safety in LLMs

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xikang Yang, Biyu Zhou, Xuehai Tang, Jizhong Han, Songlin Hu
- **URL**: <http://arxiv.org/abs/2507.22564v1>
- **Submitted**: 2025-07-30 10:40:53
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it touches on AI systems, it focuses on Large Language Models and cognitive biases, which is outside the scope of the user's primary research interests.

#### Abstract
> Large Language Models (LLMs) demonstrate impressive capabilities across a
wide range of tasks, yet their safety mechanisms remain susceptible to
adversarial attacks that exploit cognitive biases -- systematic deviations from
rational judgment. Unlike prior jailbreaking approaches focused on prompt
engineering or algorithmic manipulation, this work highlights the overlooked
power of multi-bias interactions in undermining LLM safeguards. We propose
CognitiveAttack, a novel red-teaming framework that systematically leverages
both individual and combined cognitive biases. By integrating supervised
fine-tuning and reinforcement learning, CognitiveAttack generates prompts that
embed optimized bias combinations, effectively bypassing safety protocols while
maintaining high attack success rates. Experimental results reveal significant
vulnerabilities across 30 diverse LLMs, particularly in open-source models.
CognitiveAttack achieves a substantially higher attack success rate compared to
the SOTA black-box method PAP (60.1% vs. 31.6%), exposing critical limitations
in current defense mechanisms. These findings highlight multi-bias interactions
as a powerful yet underexplored attack vector. This work introduces a novel
interdisciplinary perspective by bridging cognitive science and LLM safety,
paving the way for more robust and human-aligned AI systems.

### 32. Exploring Dynamic Parameters for Vietnamese Gender-Independent ASR

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sotheara Leang, √âric Castelli, Dominique Vaufreydaz, Sethserey Sam
- **URL**: <http://arxiv.org/abs/2507.22964v1>
- **Submitted**: 2025-07-30 08:25:55
- **Topic Keywords**: ctr
- **Reason**: This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on Automatic Speech Recognition (ASR) and acoustic signal processing, which is outside the user's primary research areas.

#### Abstract
> The dynamic characteristics of speech signal provides temporal information
and play an important role in enhancing Automatic Speech Recognition (ASR). In
this work, we characterized the acoustic transitions in a ratio plane of
Spectral Subband Centroid Frequencies (SSCFs) using polar parameters to capture
the dynamic characteristics of the speech and minimize spectral variation.
These dynamic parameters were combined with Mel-Frequency Cepstral Coefficients
(MFCCs) in Vietnamese ASR to capture more detailed spectral information. The
SSCF0 was used as a pseudo-feature for the fundamental frequency (F0) to
describe the tonal information robustly. The findings showed that the proposed
parameters significantly reduce word error rates and exhibit greater gender
independence than the baseline MFCCs.

### 33. Question Generation for Assessing Early Literacy Reading Comprehension

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xiaocheng Yang, Sumuk Shashidhar, Dilek Hakkani-Tur
- **URL**: <http://arxiv.org/abs/2507.22410v1>
- **Submitted**: 2025-07-30 06:27:02
- **Comment**: 2 pages, 1 figure, accepted by SLaTE 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on question generation for assessing early literacy reading comprehension, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on language models and question generation is not directly applicable to the user's areas of focus.

#### Abstract
> Assessment of reading comprehension through content-based interactions plays
an important role in the reading acquisition process. In this paper, we propose
a novel approach for generating comprehension questions geared to K-2 English
learners. Our method ensures complete coverage of the underlying material and
adaptation to the learner's specific proficiencies, and can generate a large
diversity of question types at various difficulty levels to ensure a thorough
evaluation. We evaluate the performance of various language models in this
framework using the FairytaleQA dataset as the source material. Eventually, the
proposed approach has the potential to become an important part of autonomous
AI-driven English instructors.

### 34. The Incomplete Bridge: How AI Research (Mis)Engages with Psychology

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Han Jiang, Pengda Wang, Xiaoyuan Yi, Xing Xie, Ziang Xiao
- **URL**: <http://arxiv.org/abs/2507.22847v1>
- **Submitted**: 2025-07-30 17:03:59
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on the interdisciplinary synergy between AI and psychology, analyzing papers and citations, and does not address query understanding, ranking models, user behavior modeling, or real-time relevance optimization.

#### Abstract
> Social sciences have accumulated a rich body of theories and methodologies
for investigating the human mind and behaviors, while offering valuable
insights into the design and understanding of Artificial Intelligence (AI)
systems. Focusing on psychology as a prominent case, this study explores the
interdisciplinary synergy between AI and the field by analyzing 1,006
LLM-related papers published in premier AI venues between 2023 and 2025, along
with the 2,544 psychology publications they cite. Through our analysis, we
identify key patterns of interdisciplinary integration, locate the psychology
domains most frequently referenced, and highlight areas that remain
underexplored. We further examine how psychology theories/frameworks are
operationalized and interpreted, identify common types of misapplication, and
offer guidance for more effective incorporation. Our work provides a
comprehensive map of interdisciplinary engagement between AI and psychology,
thereby facilitating deeper collaboration and advancing AI systems.

### 35. DBLPLink 2.0 -- An Entity Linker for the DBLP Scholarly Knowledge Graph

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Debayan Banerjee, Tilahun Abedissa Taffa, Ricardo Usbeck
- **URL**: <http://arxiv.org/abs/2507.22811v1>
- **Submitted**: 2025-07-30 16:29:47
- **Topic Keywords**: rank
- **Reason**: The paper focuses on entity linking and knowledge graph construction, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions using language models (LLMs), the application is not in the context of search or ranking models, and the paper does not explore user behavior modeling or real-time relevance optimization.

#### Abstract
> In this work we present an entity linker for DBLP's 2025 version of RDF-based
Knowledge Graph. Compared to the 2022 version, DBLP now considers publication
venues as a new entity type called dblp:Stream. In the earlier version of
DBLPLink, we trained KG-embeddings and re-rankers on a dataset to produce
entity linkings. In contrast, in this work, we develop a zero-shot entity
linker using LLMs using a novel method, where we re-rank candidate entities
based on the log-probabilities of the "yes" token output at the penultimate
layer of the LLM.

### 36. Opportunities and Challenges of LLMs in Education: An NLP Perspective

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Sowmya Vajjala, Bashar Alhafni, Stefano Bann√≤, Kaushal Kumar Maurya, Ekaterina Kochmar
- **URL**: <http://arxiv.org/abs/2507.22753v1>
- **Submitted**: 2025-07-30 15:12:12
- **Comment**: Pre-print
- **Topic Keywords**: search
- **Reason**: The paper focuses on the application of Large Language Models (LLMs) in education, from an NLP perspective, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and query understanding. While the paper touches on NLP, it does not address the user's specific areas of interest, such as ranking models, user behavior modeling, or deep semantic understanding.

#### Abstract
> Interest in the role of large language models (LLMs) in education is
increasing, considering the new opportunities they offer for teaching,
learning, and assessment. In this paper, we examine the impact of LLMs on
educational NLP in the context of two main application scenarios: {\em
assistance} and {\em assessment}, grounding them along the four dimensions --
reading, writing, speaking, and tutoring. We then present the new directions
enabled by LLMs, and the key challenges to address. We envision that this
holistic overview would be useful for NLP researchers and practitioners
interested in exploring the role of LLMs in developing language-focused and
NLP-enabled educational applications of the future.

### 37. Investigating Hallucination in Conversations for Low Resource Languages

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Amit Das, Md. Najib Hasan, Souvika Sarkar, Zheng Zhang, Fatemeh Jamshidi, Tathagata Bhattacharya, Nilanjana Raychawdhury, Dongji Feng, Vinija Jain, Aman Chadha
- **URL**: <http://arxiv.org/abs/2507.22720v1>
- **Submitted**: 2025-07-30 14:39:51
- **Topic Keywords**: search
- **Reason**: The paper focuses on investigating hallucination in conversations for low-resource languages, which is not directly related to the user's interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. Although it touches on Natural Language Processing, the specific topic and language models discussed are not relevant to the user's research areas.

#### Abstract
> Large Language Models (LLMs) have demonstrated remarkable proficiency in
generating text that closely resemble human writing. However, they often
generate factually incorrect statements, a problem typically referred to as
'hallucination'. Addressing hallucination is crucial for enhancing the
reliability and effectiveness of LLMs. While much research has focused on
hallucinations in English, our study extends this investigation to
conversational data in three languages: Hindi, Farsi, and Mandarin. We offer a
comprehensive analysis of a dataset to examine both factual and linguistic
errors in these languages for GPT-3.5, GPT-4o, Llama-3.1, Gemma-2.0,
DeepSeek-R1 and Qwen-3. We found that LLMs produce very few hallucinated
responses in Mandarin but generate a significantly higher number of
hallucinations in Hindi and Farsi.

### 38. Multilingual Political Views of Large Language Models: Identification and Steering

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Daniil Gurgurov, Katharina Trinley, Ivan Vykopal, Josef van Genabith, Simon Ostermann, Roberto Zamparelli
- **URL**: <http://arxiv.org/abs/2507.22623v1>
- **Submitted**: 2025-07-30 12:42:35
- **Comment**: pre-print
- **Topic Keywords**: search
- **Reason**: The paper focuses on the political biases of large language models, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it touches on the topic of language models, the study's scope and methodology are not aligned with the user's areas of interest, such as query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large language models (LLMs) are increasingly used in everyday tools and
applications, raising concerns about their potential influence on political
views. While prior research has shown that LLMs often exhibit measurable
political biases--frequently skewing toward liberal or progressive
positions--key gaps remain. Most existing studies evaluate only a narrow set of
models and languages, leaving open questions about the generalizability of
political biases across architectures, scales, and multilingual settings.
Moreover, few works examine whether these biases can be actively controlled.
  In this work, we address these gaps through a large-scale study of political
orientation in modern open-source instruction-tuned LLMs. We evaluate seven
models, including LLaMA-3.1, Qwen-3, and Aya-Expanse, across 14 languages using
the Political Compass Test with 11 semantically equivalent paraphrases per
statement to ensure robust measurement. Our results reveal that larger models
consistently shift toward libertarian-left positions, with significant
variations across languages and model families. To test the manipulability of
political stances, we utilize a simple center-of-mass activation intervention
technique and show that it reliably steers model responses toward alternative
ideological positions across multiple languages. Our code is publicly available
at https://github.com/d-gurgurov/Political-Ideologies-LLMs.

### 39. A Benchmark Dataset and Evaluation Framework for Vietnamese Large Language Models in Customer Support

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Long S. T. Nguyen, Truong P. Hua, Thanh M. Nguyen, Toan Q. Pham, Nam K. Ngo, An X. Nguyen, Nghi D. M. Pham, Nghia H. Nguyen, Tho T. Quan
- **URL**: <http://arxiv.org/abs/2507.22542v1>
- **Submitted**: 2025-07-30 10:14:31
- **Comment**: Under review at ICCCI 2025
- **Topic Keywords**: search
- **Reason**: The paper focuses on Vietnamese Large Language Models in customer support, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on question answering systems and customer support conversations does not align with the user's primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> With the rapid growth of Artificial Intelligence, Large Language Models
(LLMs) have become essential for Question Answering (QA) systems, improving
efficiency and reducing human workload in customer service. The emergence of
Vietnamese LLMs (ViLLMs) highlights lightweight open-source models as a
practical choice for their accuracy, efficiency, and privacy benefits. However,
domain-specific evaluations remain limited, and the absence of benchmark
datasets reflecting real customer interactions makes it difficult for
enterprises to select suitable models for support applications. To address this
gap, we introduce the Customer Support Conversations Dataset (CSConDa), a
curated benchmark of over 9,000 QA pairs drawn from real interactions with
human advisors at a large Vietnamese software company. Covering diverse topics
such as pricing, product availability, and technical troubleshooting, CSConDa
provides a representative basis for evaluating ViLLMs in practical scenarios.
We further present a comprehensive evaluation framework, benchmarking 11
lightweight open-source ViLLMs on CSConDa with both automatic metrics and
syntactic analysis to reveal model strengths, weaknesses, and linguistic
patterns. This study offers insights into model behavior, explains performance
differences, and identifies key areas for improvement, supporting the
development of next-generation ViLLMs. By establishing a robust benchmark and
systematic evaluation, our work enables informed model selection for customer
service QA and advances research on Vietnamese LLMs. The dataset is publicly
available at
https://huggingface.co/datasets/ura-hcmut/Vietnamese-Customer-Support-QA.

### 40. Sustainability Evaluation Metrics for Recommender Systems

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Alexander Felfernig, Damian Garber, Viet-Man Le, Sebastian Lubos, Thi Ngoc Trang Tran
- **URL**: <http://arxiv.org/abs/2507.22520v1>
- **Submitted**: 2025-07-30 09:46:56
- **Topic Keywords**: recommend
- **Reason**: The paper focuses on recommender systems, which is a related topic, but it does not address information retrieval, query understanding, ranking models, or user behavior modeling, which are the core areas of interest. The paper's focus on sustainability evaluation metrics is not directly relevant to the user's research themes.

#### Abstract
> Sustainability-oriented evaluation metrics can help to assess the quality of
recommender systems beyond wide-spread metrics such as accuracy, precision,
recall, and satisfaction. Following the United Nations`s sustainable
development goals (SDGs), such metrics can help to analyse the impact of
recommender systems on environmental, social, and economic aspects. We discuss
different basic sustainability evaluation metrics for recommender systems and
analyze their applications.

### 41. Falcon-H1: A Family of Hybrid-Head Language Models Redefining Efficiency and Performance

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jingwei Zuo, Maksim Velikanov, Ilyas Chahed, Younes Belkada, Dhia Eddine Rhayem, Guillaume Kunsch, Hakim Hacid, Hamza Yous, Brahim Farhat, Ibrahim Khadraoui, Mugariya Farooq, Giulia Campesan, Ruxandra Cojocaru, Yasser Djilali, Shi Hu, Iheb Chaabane, Puneesh Khanna, Mohamed El Amine Seddik, Ngoc Dung Huynh, Phuc Le Khac, Leen AlQadi, Billel Mokeddem, Mohamed Chami, Abdalgader Abubaker, Mikhail Lubinets, Kacper Piskorski, Slim Frikha
- **URL**: <http://arxiv.org/abs/2507.22448v1>
- **Submitted**: 2025-07-30 07:55:33
- **Comment**: Technical report of Falcon-H1 model series
- **Topic Keywords**: search
- **Reason**: The paper focuses on large language models and their architecture, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions performance and efficiency, the context is not relevant to the user's research interests in IR and NLP.

#### Abstract
> In this report, we introduce Falcon-H1, a new series of large language models
(LLMs) featuring hybrid architecture designs optimized for both high
performance and efficiency across diverse use cases. Unlike earlier Falcon
models built solely on Transformer or Mamba architectures, Falcon-H1 adopts a
parallel hybrid approach that combines Transformer-based attention with State
Space Models (SSMs), known for superior long-context memory and computational
efficiency. We systematically revisited model design, data strategy, and
training dynamics, challenging conventional practices in the field. Falcon-H1
is released in multiple configurations, including base and instruction-tuned
variants at 0.5B, 1.5B, 1.5B-deep, 3B, 7B, and 34B parameters. Quantized
instruction-tuned models are also available, totaling over 30 checkpoints on
Hugging Face Hub. Falcon-H1 models demonstrate state-of-the-art performance and
exceptional parameter and training efficiency. The flagship Falcon-H1-34B
matches or outperforms models up to 70B scale, such as Qwen3-32B, Qwen2.5-72B,
and Llama3.3-70B, while using fewer parameters and less data. Smaller models
show similar trends: the Falcon-H1-1.5B-Deep rivals current leading 7B-10B
models, and Falcon-H1-0.5B performs comparably to typical 7B models from 2024.
These models excel across reasoning, mathematics, multilingual tasks,
instruction following, and scientific knowledge. With support for up to 256K
context tokens and 18 languages, Falcon-H1 is suitable for a wide range of
applications. All models are released under a permissive open-source license,
underscoring our commitment to accessible and impactful AI research.

### 42. AI-generated stories favour stability over change: homogeneity and cultural stereotyping in narratives generated by gpt-4o-mini

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jill Walker Rettberg, Hermann Wigers
- **URL**: <http://arxiv.org/abs/2507.22445v1>
- **Submitted**: 2025-07-30 07:44:28
- **Comment**: This project has received funding from the European Union's Horizon
  2020 research and innovation programme under grant agreement number
  101142306. The project is also supported by the Center for Digital Narrative,
  which is funded by the Research Council of Norway through its Centres of
  Excellence scheme, project number 332643
- **Topic Keywords**: search
- **Reason**: The paper's focus on AI-generated stories and narrative structure is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on NLP research, its primary focus is on literary studies and narratology, making it only loosely relevant to the user's interests.

#### Abstract
> Can a language model trained largely on Anglo-American texts generate stories
that are culturally relevant to other nationalities? To find out, we generated
11,800 stories - 50 for each of 236 countries - by sending the prompt "Write a
1500 word potential {demonym} story" to OpenAI's model gpt-4o-mini. Although
the stories do include surface-level national symbols and themes, they
overwhelmingly conform to a single narrative plot structure across countries: a
protagonist lives in or returns home to a small town and resolves a minor
conflict by reconnecting with tradition and organising community events.
Real-world conflicts are sanitised, romance is almost absent, and narrative
tension is downplayed in favour of nostalgia and reconciliation. The result is
a narrative homogenisation: an AI-generated synthetic imaginary that
prioritises stability above change and tradition above growth. We argue that
the structural homogeneity of AI-generated narratives constitutes a distinct
form of AI bias, a narrative standardisation that should be acknowledged
alongside the more familiar representational bias. These findings are relevant
to literary studies, narratology, critical AI studies, NLP research, and
efforts to improve the cultural alignment of generative AI.

---

