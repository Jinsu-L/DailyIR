# Daily Papers Report - 2025-09-15

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Do Large Language Models Favor Recent Content? A Study on Recency Bias in LLM-Based Reranking

- **LLM Score**: 8
- **Keyword Score**: 25
- **Authors**: Hanpei Fang, Sijie Tao, Nuo Chen, Kai-Xin Chang, Tetsuya Sakai
- **URL**: <http://arxiv.org/abs/2509.11353v1>
- **Submitted**: 2025-09-14 17:11:07
- **Topic Keywords**: passage retrieval, ranking, rerank, listwise, pairwise, relevance, rag, retrieval, rank, trec
- **Reason**: This paper is highly relevant to your interests in Information Retrieval, particularly in the context of query understanding and ranking models. The study of recency bias in Large Language Models (LLMs) is a significant aspect of real-time relevance optimization, aligning with your focus on deep semantic understanding. Although the paper's primary focus is on recommender systems, the findings have implications for information retrieval pipelines.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Recency Bias in Large Language Models for Information Retrieval
- **Aim**: To investigate and quantify the extent of recency bias in LLMs used for passage reranking.
- **Rationale**: LLMs are increasingly used in information retrieval, but their susceptibility to recency bias, favoring more recent information, raises concerns about fairness and accuracy.
- **Ground**: The authors utilize the TREC Deep Learning passage retrieval collections (DL21 and DL22) and manipulate the publication dates of passages to assess LLM sensitivity to temporal cues.
- **Experiment**: Seven diverse LLMs (GPT-3.5-turbo, GPT-4o, GPT-4, LLaMA-3 8B/70B, and Qwen-2.5 7B/72B) are evaluated through ranking shifts, pairwise preference experiments, and the introduction of metrics like mAARS, YS(K), YSG(g), and Reversal Rate (RR).
- **Takeaway**: All LLMs exhibit recency bias, with larger models showing a reduced but not eliminated effect.  The bias manifests differently across the search results page and highlights the need for bias mitigation strategies in LLM-powered information retrieval systems.

#### Abstract
> Large language models (LLMs) are increasingly deployed in information
systems, including being used as second-stage rerankers in information
retrieval pipelines, yet their susceptibility to recency bias has received
little attention. We investigate whether LLMs implicitly favour newer documents
by prepending artificial publication dates to passages in the TREC Deep
Learning passage retrieval collections in 2021 (DL21) and 2022 (DL22). Across
seven models, GPT-3.5-turbo, GPT-4o, GPT-4, LLaMA-3 8B/70B, and Qwen-2.5
7B/72B, "fresh" passages are consistently promoted, shifting the Top-10's mean
publication year forward by up to 4.78 years and moving individual items by as
many as 95 ranks in our listwise reranking experiments. Although larger models
attenuate the effect, none eliminate it. We also observe that the preference of
LLMs between two passages with an identical relevance level can be reversed by
up to 25% on average after date injection in our pairwise preference
experiments. These findings provide quantitative evidence of a pervasive
recency bias in LLMs and highlight the importance of effective bias-mitigation
strategies.

---

### 2. FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval

- **LLM Score**: 8
- **Keyword Score**: 15
- **Authors**: Ying Li, Mengyu Wang, Miguel de Carvalho, Sotirios Sabanis, Tiejun Ma
- **URL**: <http://arxiv.org/abs/2509.12042v1>
- **Submitted**: 2025-09-15 15:25:26
- **Topic Keywords**: query, queries, rerank, rag, retrieval, rank, search
- **Reason**: This paper is highly relevant to Information Retrieval, particularly in the context of query understanding and ranking models. The focus on financial documents and the introduction of a tailored retrieval framework aligns with the user's interests in deep semantic understanding and real-time relevance optimization. However, the specific domain (financial documents) is somewhat narrow compared to the user's broader interests in e-commerce and general IR.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Financial Question Answering
- **Aim**: Develop a novel retrieval-first framework, FinGEAR, for answering financial questions (FinQA) using 10-K filings.
- **Rationale**: Address the unique challenges of FinQA, such as hierarchical structure, domain-specific language, and the need for precise evidence, through a multi-faceted approach.
- **Ground**: 10-K filings, a finance-specific lexicon (FLAM), dual hierarchical indices (Summary Tree and Question Tree), and a two-stage cross-encoder reranker.
- **Experiment**: Evaluated FinGEAR on the FinQA dataset using RAGAS framework metrics (precision, recall, F1 score, and relevancy) and compared it to five baseline models.
- **Takeaway**: FinGEAR outperformed baselines, achieving the highest recall and F1 score.  It demonstrates the effectiveness of a retrieval-first framework incorporating domain-specific knowledge, structural information, and semantic understanding for FinQA.

#### Abstract
> Financial disclosures such as 10-K filings present challenging retrieval
problems due to their length, regulatory section hierarchy, and domain-specific
language, which standard retrieval-augmented generation (RAG) models underuse.
We introduce FinGEAR (Financial Mapping-Guided Enhanced Answer Retrieval), a
retrieval framework tailored to financial documents. FinGEAR combines a finance
lexicon for Item-level guidance (FLAM), dual hierarchical indices for
within-Item search (Summary Tree and Question Tree), and a two-stage
cross-encoder reranker. This design aligns retrieval with disclosure structure
and terminology, enabling fine-grained, query-aware context selection.
Evaluated on full 10-Ks with queries aligned to the FinQA dataset, FinGEAR
delivers consistent gains in precision, recall, F1, and relevancy, improving F1
by up to 56.7% over flat RAG, 12.5% over graph-based RAGs, and 217.6% over
prior tree-based systems, while also increasing downstream answer accuracy with
a fixed reader. By jointly modeling section hierarchy and domain lexicon
signals, FinGEAR improves retrieval fidelity and provides a practical
foundation for high-stakes financial analysis.

---

### 3. !MSA at AraHealthQA 2025 Shared Task: Enhancing LLM Performance for Arabic Clinical Question Answering through Prompt Engineering and Ensemble Learning

- **LLM Score**: 8
- **Keyword Score**: 2
- **Authors**: Mohamed Tarek, Seif Ahmed, Mohamed Basem
- **URL**: <http://arxiv.org/abs/2509.11365v1>
- **Submitted**: 2025-09-14 17:39:58
- **Comment**: 8 Pages , ArabicNLP 2025 , Co-located with EMNLP 2025
- **Topic Keywords**: rag
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of query understanding and ranking models. The use of Large Language Models (LLMs) and prompt engineering for Arabic clinical question answering also aligns with your interests in NLP and deep semantic understanding. However, the focus on question answering and clinical contexts is somewhat specific and not directly related to your e-commerce background.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Arabic Clinical Question Answering
- **Aim**: Develop a high-performing system for answering medical questions in Arabic
- **Rationale**: Limited resources and challenges in handling Arabic language nuances necessitate innovative approaches for Arabic medical question answering.
- **Ground**: AraHealthQA-2025 shared task, Track 2 (MedArabiQ)
- **Experiment**: Utilized Gemini 2.5 Flash model with few-shot prompting and diverse strategies (Arabic Few-Shot, English Translation + Answer, Refinement + Answer) for both multiple-choice and open-ended question answering. Combined predictions via majority voting and incorporated post-processing techniques.
- **Takeaway**: Ensemble approach with diverse prompting strategies achieved 2nd place in both sub-tasks, demonstrating the effectiveness of combining different methods. Unified prompting for open-ended questions and post-processing techniques yielded high performance. Highlights challenges of limited training data and dialectal variations, suggesting future work in retrieval augmentation, model diversity, and human-in-the-loop validation.

#### Abstract
> We present our systems for Track 2 (General Arabic Health QA, MedArabiQ) of
the AraHealthQA-2025 shared task, where our methodology secured 2nd place in
both Sub-Task 1 (multiple-choice question answering) and Sub-Task 2 (open-ended
question answering) in Arabic clinical contexts. For Sub-Task 1, we leverage
the Gemini 2.5 Flash model with few-shot prompting, dataset preprocessing, and
an ensemble of three prompt configurations to improve classification accuracy
on standard, biased, and fill-in-the-blank questions. For Sub-Task 2, we employ
a unified prompt with the same model, incorporating role-playing as an Arabic
medical expert, few-shot examples, and post-processing to generate concise
responses across fill-in-the-blank, patient-doctor Q&A, GEC, and paraphrased
variants.

---

### 4. MillStone: How Open-Minded Are LLMs?

- **LLM Score**: 7
- **Keyword Score**: 7
- **Authors**: Harold Triedman, Vitaly Shmatikov
- **URL**: <http://arxiv.org/abs/2509.11967v1>
- **Submitted**: 2025-09-15 14:18:51
- **Comment**: 19 pages, 7 tables, 7 figures
- **Topic Keywords**: information retrieval, retrieval, web search, search
- **Reason**: This paper explores the use of Large Language Models (LLMs) in search and information retrieval, which aligns with your interests in IR and Search technologies. However, the focus is on the stances and opinions expressed by LLMs, rather than query understanding, ranking models, or user behavior modeling, which are your core research themes.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Open-mindedness of Large Language Models (LLMs) when exposed to arguments on controversial issues
- **Aim**: To evaluate the open-mindedness of nine leading LLMs by measuring their stance changes in response to arguments presented on 107 controversial issues.
- **Rationale**: Understanding how LLMs process arguments and form opinions is crucial as their outputs can influence public discourse and decision-making.
- **Ground**: The study utilizes the MILLSTONE benchmark, presenting each issue with various argument configurations (baseline, one-sided, clear and convincing, balanced). LLMs' stances are measured using regular expressions and an "open-mindedness score" is calculated based on stance changes.
- **Experiment**: Nine LLMs (Gemini 2.0 Flash, Claude 3.5 Haiku, Opus 4, Llama 3.1 7B, Llama 3.1 405B, GPT 4o, 4o mini, Grok 3, and 3 mini) were evaluated on 107 controversial issues sourced from Encyclopedia Britannica's ProCon website.
- **Takeaway**: LLMs demonstrate variable open-mindedness, with some models more susceptible to manipulation through carefully crafted arguments. Findings highlight the need for robust defenses against adversarial argumentation in LLM-based systems.

#### Abstract
> Large language models equipped with Web search, information retrieval tools,
and other agentic capabilities are beginning to supplant traditional search
engines. As users start to rely on LLMs for information on many topics,
including controversial and debatable issues, it is important to understand how
the stances and opinions expressed in LLM outputs are influenced by the
documents they use as their information sources.
  In this paper, we present MillStone, the first benchmark that aims to
systematically measure the effect of external arguments on the stances that
LLMs take on controversial issues (not all of them political). We apply
MillStone to nine leading LLMs and measure how ``open-minded'' they are to
arguments supporting opposite sides of these issues, whether different LLMs
agree with each other, which arguments LLMs find most persuasive, and whether
these arguments are the same for different LLMs.
  In general, we find that LLMs are open-minded on most issues. An
authoritative source of information can easily sway an LLM's stance,
highlighting the importance of source selection and the risk that LLM-based
information retrieval and search systems can be manipulated.

---

### 5. Unsupervised Candidate Ranking for Lexical Substitution via Holistic Sentence Semantics

- **LLM Score**: 6
- **Keyword Score**: 6
- **Authors**: Zhongyang Hu, Naijie Gu, Xiangzhi Tao, Tianhui Gu, Yibing Zhou
- **URL**: <http://arxiv.org/abs/2509.11513v1>
- **Submitted**: 2025-09-15 01:57:09
- **Topic Keywords**: ranking, rag, rank
- **Reason**: The paper explores ranking models for lexical substitution, which is somewhat related to the user's interests in ranking models and query understanding. However, the focus on lexical substitution and sentence semantics is not directly aligned with the user's primary research themes in information retrieval and search technologies.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Lexical Substitution Ranking
- **Aim**: Propose novel unsupervised methods for ranking candidate words in lexical substitution tasks.
- **Rationale**: Existing methods fail to capture the bidirectional influence of candidate words on both the target word and its surrounding context.
- **Ground**: Two methods are proposed: an attention-based approach and an Integrated Gradients approach.
- **Experiment**: Both methods are evaluated on LS07 and SWORDS datasets using the Generalized Average Precision (GAP) metric with various pre-trained language models.
- **Takeaway**: Contextual tokens provide complementary semantic cues that enhance substitution ranking accuracy. Integrated Gradients, while computationally expensive, offers interpretability benefits.

#### Abstract
> A key subtask in lexical substitution is ranking the given candidate words. A
common approach is to replace the target word with a candidate in the original
sentence and feed the modified sentence into a model to capture semantic
differences before and after substitution. However, effectively modeling the
bidirectional influence of candidate substitution on both the target word and
its context remains challenging. Existing methods often focus solely on
semantic changes at the target position or rely on parameter tuning over
multiple evaluation metrics, making it difficult to accurately characterize
semantic variation. To address this, we investigate two approaches: one based
on attention weights and another leveraging the more interpretable integrated
gradients method, both designed to measure the influence of context tokens on
the target token and to rank candidates by incorporating semantic similarity
between the original and substituted sentences. Experiments on the LS07 and
SWORDS datasets demonstrate that both approaches improve ranking performance.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Query-Focused Extractive Summarization for Sentiment Explanation

- **LLM Score**: 6
- **Keyword Score**: 5
- **Authors**: Ahmed Moubtahij, Sylvie Ratt√©, Yazid Attabi, Maxime Dumas
- **URL**: <http://arxiv.org/abs/2509.11989v1>
- **Submitted**: 2025-09-15 14:41:18
- **Topic Keywords**: query, rag
- **Reason**: This paper on Query-Focused Summarization for Sentiment Explanation is somewhat related to your interests in Information Retrieval, particularly in query understanding and ranking models. However, it focuses more on summarization and sentiment analysis, which, while related to your broader interests in NLP and data mining, does not directly align with your primary focus on query understanding and ranking models in the context of search technologies.

#### Abstract
> Constructive analysis of feedback from clients often requires determining the
cause of their sentiment from a substantial amount of text documents. To assist
and improve the productivity of such endeavors, we leverage the task of
Query-Focused Summarization (QFS). Models of this task are often impeded by the
linguistic dissonance between the query and the source documents. We propose
and substantiate a multi-bias framework to help bridge this gap at a
domain-agnostic, generic level; we then formulate specialized approaches for
the problem of sentiment explanation through sentiment-based biases and query
expansion. We achieve experimental results outperforming baseline models on a
real-world proprietary sentiment-aware QFS dataset.

### 7. AKCIT-FN at CheckThat! 2025: Switching Fine-Tuned SLMs and LLM Prompting for Multilingual Claim Normalization

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Fabrycio Leite Nakano Almada, Kauan Divino Pouso Mariano, Maykon Adriell Dutra, Victor Emanuel da Silva Monteiro, Juliana Resplande Sant'Anna Gomes, Arlindo Rodrigues Galv√£o Filho, Anderson da Silva Soares
- **URL**: <http://arxiv.org/abs/2509.11496v1>
- **Submitted**: 2025-09-15 01:19:49
- **Comment**: 15 pages, 2 figures
- **Topic Keywords**: ranking, rag, rank
- **Reason**: This paper is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, as it involves claim normalization and fact-checking pipelines. However, the focus on multilingual claim normalization and Large Language Model (LLM) prompting is not directly aligned with the user's primary research themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> Claim normalization, the transformation of informal social media posts into
concise, self-contained statements, is a crucial step in automated
fact-checking pipelines. This paper details our submission to the CLEF-2025
CheckThat! Task~2, which challenges systems to perform claim normalization
across twenty languages, divided into thirteen supervised (high-resource) and
seven zero-shot (no training data) tracks.
  Our approach, leveraging fine-tuned Small Language Models (SLMs) for
supervised languages and Large Language Model (LLM) prompting for zero-shot
scenarios, achieved podium positions (top three) in fifteen of the twenty
languages. Notably, this included second-place rankings in eight languages,
five of which were among the seven designated zero-shot languages, underscoring
the effectiveness of our LLM-based zero-shot strategy. For Portuguese, our
initial development language, our system achieved an average METEOR score of
0.5290, ranking third. All implementation artifacts, including inference,
training, evaluation scripts, and prompt configurations, are publicly available
at https://github.com/ju-resplande/checkthat2025_normalization.

### 8. A Dynamic Knowledge Update-Driven Model with Large Language Models for Fake News Detection

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Di Jin, Jun Yang, Xiaobao Wang, Junwei Zhang, Shuqi Li, Dongxiao He
- **URL**: <http://arxiv.org/abs/2509.11687v1>
- **Submitted**: 2025-09-15 08:38:08
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper focuses on fake news detection, which is somewhat related to information retrieval and NLP. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The use of large language models and knowledge graphs is relevant to IR and NLP, but the application is specific to fake news detection.

#### Abstract
> As the Internet and social media evolve rapidly, distinguishing credible news
from a vast amount of complex information poses a significant challenge. Due to
the suddenness and instability of news events, the authenticity labels of news
can potentially shift as events develop, making it crucial for fake news
detection to obtain the latest event updates. Existing methods employ
retrieval-augmented generation to fill knowledge gaps, but they suffer from
issues such as insufficient credibility of retrieved content and interference
from noisy information. We propose a dynamic knowledge update-driven model for
fake news detection (DYNAMO), which leverages knowledge graphs to achieve
continuous updating of new knowledge and integrates with large language models
to fulfill dual functions: news authenticity detection and verification of new
knowledge correctness, solving the two key problems of ensuring the
authenticity of new knowledge and deeply mining news semantics. Specifically,
we first construct a news-domain-specific knowledge graph. Then, we use Monte
Carlo Tree Search to decompose complex news and verify them step by step.
Finally, we extract and update new knowledge from verified real news texts and
reasoning paths. Experimental results demonstrate that DYNAMO achieves the best
performance on two real-world datasets.

### 9. Analyzing Information-Seeking Behaviors in a Hakka AI Chatbot: A Cognitive-Pragmatic Study

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Chu-Hsuan Lee, Chen-Chi Chang, Hung-Shin Lee, Yun-Hsiang Hsu, Ching-Yuan Chen
- **URL**: <http://arxiv.org/abs/2509.11591v1>
- **Submitted**: 2025-09-15 05:18:17
- **Comment**: Accepted to HICSS-59 (2026)
- **Topic Keywords**: rag, user behavior
- **Reason**: This paper is somewhat related to Information Retrieval, but its focus on AI-assisted language learning and cognitive development in low-resource language learners is not directly aligned with the user's core research themes. While it involves a generative AI chatbot, the study's emphasis on language preservation and educational practice is more closely related to NLP and data mining, but not specifically to query understanding, ranking models, or user behavior modeling.

#### Abstract
> With many endangered languages at risk of disappearing, efforts to preserve
them now rely more than ever on using technology alongside culturally informed
teaching strategies. This study examines user behaviors in TALKA, a generative
AI-powered chatbot designed for Hakka language engagement, by employing a
dual-layered analytical framework grounded in Bloom's Taxonomy of cognitive
processes and dialogue act categorization. We analyzed 7,077 user utterances,
each carefully annotated according to six cognitive levels and eleven dialogue
act types. These included a variety of functions, such as asking for
information, requesting translations, making cultural inquiries, and using
language creatively. Pragmatic classifications further highlight how different
types of dialogue acts--such as feedback, control commands, and social
greetings--align with specific cognitive intentions. The results suggest that
generative AI chatbots can support language learning in meaningful
ways--especially when they are designed with an understanding of how users
think and communicate. They may also help learners express themselves more
confidently and connect with their cultural identity. The TALKA case provides
empirical insights into how AI-mediated dialogue facilitates cognitive
development in low-resource language learners, as well as pragmatic negotiation
and socio-cultural affiliation. By focusing on AI-assisted language learning,
this study offers new insights into how technology can support language
preservation and educational practice.

### 10. HiChunk: Evaluating and Enhancing Retrieval-Augmented Generation with Hierarchical Chunking

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Wensheng Lu, Keyu Chen, Ruizhi Qiao, Xing Sun
- **URL**: <http://arxiv.org/abs/2509.11552v1>
- **Submitted**: 2025-09-15 03:32:50
- **Comment**: 17 pages, 5 figures, 6 tables
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of Retrieval-Augmented Generation and document chunking. However, it does not directly focus on query understanding, ranking models, or user behavior modeling, which are your core areas of interest.

#### Abstract
> Retrieval-Augmented Generation (RAG) enhances the response capabilities of
language models by integrating external knowledge sources. However, document
chunking as an important part of RAG system often lacks effective evaluation
tools. This paper first analyzes why existing RAG evaluation benchmarks are
inadequate for assessing document chunking quality, specifically due to
evidence sparsity. Based on this conclusion, we propose HiCBench, which
includes manually annotated multi-level document chunking points, synthesized
evidence-dense quetion answer(QA) pairs, and their corresponding evidence
sources. Additionally, we introduce the HiChunk framework, a multi-level
document structuring framework based on fine-tuned LLMs, combined with the
Auto-Merge retrieval algorithm to improve retrieval quality. Experiments
demonstrate that HiCBench effectively evaluates the impact of different
chunking methods across the entire RAG pipeline. Moreover, HiChunk achieves
better chunking quality within reasonable time consumption, thereby enhancing
the overall performance of RAG systems.

### 11. CEMTM: Contextual Embedding-based Multimodal Topic Modeling

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Amirhossein Abaskohi, Raymond Li, Chuyuan Li, Shafiq Joty, Giuseppe Carenini
- **URL**: <http://arxiv.org/abs/2509.11465v1>
- **Submitted**: 2025-09-14 23:07:46
- **Comment**: EMNLP 2025
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper explores multimodal topic modeling, which is somewhat related to information retrieval, particularly in areas that require deep semantic understanding. However, the focus on multimodal topic modeling and vision-language models is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is limited to the broader context of information retrieval and NLP.

#### Abstract
> We introduce CEMTM, a context-enhanced multimodal topic model designed to
infer coherent and interpretable topic structures from both short and long
documents containing text and images. CEMTM builds on fine-tuned large vision
language models (LVLMs) to obtain contextualized embeddings, and employs a
distributional attention mechanism to weight token-level contributions to topic
inference. A reconstruction objective aligns topic-based representations with
the document embedding, encouraging semantic consistency across modalities.
Unlike existing approaches, CEMTM can process multiple images per document
without repeated encoding and maintains interpretability through explicit
word-topic and document-topic distributions. Extensive experiments on six
multimodal benchmarks show that CEMTM consistently outperforms unimodal and
multimodal baselines, achieving a remarkable average LLM score of 2.61. Further
analysis shows its effectiveness in downstream few-shot retrieval and its
ability to capture visually grounded semantics in complex domains such as
scientific articles.

### 12. Understanding the Information Cocoon: A Multidimensional Assessment and Analysis of News Recommendation Systems

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Xin Wang, Xiaowen Huang, Jitao Sang
- **URL**: <http://arxiv.org/abs/2509.11139v1>
- **Submitted**: 2025-09-14 07:17:26
- **Topic Keywords**: click, recommend, search
- **Reason**: The paper explores news recommendation systems and their potential to create information cocoons, which is somewhat related to information retrieval and user behavior modeling. However, the focus is on recommender systems rather than search technologies, and the emphasis is on societal implications rather than deep semantic understanding or real-time relevance optimization.

#### Abstract
> Personalized news recommendation systems inadvertently create information
cocoons--homogeneous information bubbles that reinforce user biases and amplify
societal polarization. To address the lack of comprehensive assessment
frameworks in prior research, we propose a multidimensional analysis that
evaluates cocoons through dual perspectives: (1) Individual homogenization via
topic diversity (including the number of topic categories and category
information entropy) and click repetition; (2) Group polarization via network
density and community openness. Through multi-round experiments on real-world
datasets, we benchmark seven algorithms and reveal critical insights.
Furthermore, we design five lightweight mitigation strategies. This work
establishes the first unified metric framework for information cocoons and
delivers deployable solutions for ethical recommendation systems.

### 13. SPARK: Adaptive Low-Rank Knowledge Graph Modeling in Hybrid Geometric Spaces for Recommendation

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Binhao Wang, Yutian Xiao, Maolin Wang, Zhiqi Li, Tianshuo Wei, Ruocheng Guo, Xiangyu Zhao
- **URL**: <http://arxiv.org/abs/2509.11094v1>
- **Submitted**: 2025-09-14 05:12:46
- **Comment**: Accepted by CIKM' 25
- **Topic Keywords**: rag, recommend, rank
- **Reason**: The paper focuses on knowledge graph modeling and recommendation systems, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the emphasis on recommender systems and knowledge graph modeling is not a central match for your primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Knowledge Graphs (KGs) enhance recommender systems but face challenges from
inherent noise, sparsity, and Euclidean geometry's inadequacy for complex
relational structures, critically impairing representation learning, especially
for long-tail entities. Existing methods also often lack adaptive multi-source
signal fusion tailored to item popularity. This paper introduces SPARK, a novel
multi-stage framework systematically tackling these issues. SPARK first employs
Tucker low-rank decomposition to denoise KGs and generate robust entity
representations. Subsequently, an SVD-initialized hybrid geometric GNN
concurrently learns representations in Euclidean and Hyperbolic spaces; the
latter is strategically leveraged for its aptitude in modeling hierarchical
structures, effectively capturing semantic features of sparse, long-tail items.
A core contribution is an item popularity-aware adaptive fusion strategy that
dynamically weights signals from collaborative filtering, refined KG
embeddings, and diverse geometric spaces for precise modeling of both
mainstream and long-tail items. Finally, contrastive learning aligns these
multi-source representations. Extensive experiments demonstrate SPARK's
significant superiority over state-of-the-art methods, particularly in
improving long-tail item recommendation, offering a robust, principled approach
to knowledge-enhanced recommendation. Implementation code is available at
https://github.com/Applied-Machine-Learning-Lab/SPARK.

### 14. From Fuzzy Speech to Medical Insight: Benchmarking LLMs on Noisy Patient Narratives

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Eden Mama, Liel Sheri, Yehudit Aperstein, Alexander Apartsin
- **URL**: <http://arxiv.org/abs/2509.11803v1>
- **Submitted**: 2025-09-15 11:34:46
- **Comment**: 6 pages, 1 figure
- **Topic Keywords**: ctr, search
- **Reason**: This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and deep semantic understanding, but it does not directly align with their primary focus on Information Retrieval (IR) and Search technologies. The paper's focus on large language models and their ability to interpret patient-generated narratives is not directly applicable to the user's research interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> The widespread adoption of large language models (LLMs) in healthcare raises
critical questions about their ability to interpret patient-generated
narratives, which are often informal, ambiguous, and noisy. Existing benchmarks
typically rely on clean, structured clinical text, offering limited insight
into model performance under realistic conditions. In this work, we present a
novel synthetic dataset designed to simulate patient self-descriptions
characterized by varying levels of linguistic noise, fuzzy language, and
layperson terminology. Our dataset comprises clinically consistent scenarios
annotated with ground-truth diagnoses, spanning a spectrum of communication
clarity to reflect diverse real-world reporting styles. Using this benchmark,
we fine-tune and evaluate several state-of-the-art models (LLMs), including
BERT-based and encoder-decoder T5 models. To support reproducibility and future
research, we release the Noisy Diagnostic Benchmark (NDB), a structured dataset
of noisy, synthetic patient descriptions designed to stress-test and compare
the diagnostic capabilities of large language models (LLMs) under realistic
linguistic conditions. We made the benchmark available for the community:
https://github.com/lielsheri/PatientSignal

### 15. When Curiosity Signals Danger: Predicting Health Crises Through Online Medication Inquiries

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Dvora Goncharok, Arbel Shifman, Alexander Apartsin, Yehudit Aperstein
- **URL**: <http://arxiv.org/abs/2509.11802v1>
- **Submitted**: 2025-09-15 11:31:25
- **Comment**: 5 pages, 2 figures
- **Topic Keywords**: rag, search
- **Reason**: The paper explores the intersection of natural language processing and patient-generated data, which aligns with your NLP interests. However, the focus on health crises and medication inquiries is somewhat tangential to your core research themes in information retrieval and search technologies.

#### Abstract
> Online medical forums are a rich and underutilized source of insight into
patient concerns, especially regarding medication use. Some of the many
questions users pose may signal confusion, misuse, or even the early warning
signs of a developing health crisis. Detecting these critical questions that
may precede severe adverse events or life-threatening complications is vital
for timely intervention and improving patient safety. This study introduces a
novel annotated dataset of medication-related questions extracted from online
forums. Each entry is manually labelled for criticality based on clinical risk
factors. We benchmark the performance of six traditional machine learning
classifiers using TF-IDF textual representations, alongside three
state-of-the-art large language model (LLM)-based classification approaches
that leverage deep contextual understanding. Our results highlight the
potential of classical and modern methods to support real-time triage and alert
systems in digital health spaces. The curated dataset is made publicly
available to encourage further research at the intersection of
patient-generated data, natural language processing, and early warning systems
for critical health events. The dataset and benchmark are available at:
https://github.com/Dvora-coder/LLM-Medication-QA-Risk-Classifier-MediGuard.

### 16. User eXperience Perception Insights Dataset (UXPID): Synthetic User Feedback from Public Industrial Forums

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Mikhail Kulyabin, Jan Joosten, Choro Ulan uulu, Nuno Miguel Martins Pacheco, Fabian Ries, Filippos Petridis, Jan Bosch, Helena Holmstr√∂m Olsson
- **URL**: <http://arxiv.org/abs/2509.11777v1>
- **Submitted**: 2025-09-15 10:58:41
- **Topic Keywords**: rag, search
- **Reason**: The paper presents a dataset for user experience analysis in industrial forums, which is somewhat related to information retrieval and user behavior modeling. However, the focus is on data analysis and NLP techniques for extracting insights from user feedback, rather than query understanding, ranking models, or real-time relevance optimization.

#### Abstract
> Customer feedback in industrial forums reflect a rich but underexplored
source of insight into real-world product experience. These publicly shared
discussions offer an organic view of user expectations, frustrations, and
success stories shaped by the specific contexts of use. Yet, harnessing this
information for systematic analysis remains challenging due to the unstructured
and domain-specific nature of the content. The lack of structure and
specialized vocabulary makes it difficult for traditional data analysis
techniques to accurately interpret, categorize, and quantify the feedback,
thereby limiting its potential to inform product development and support
strategies. To address these challenges, this paper presents the User
eXperience Perception Insights Dataset (UXPID), a collection of 7130
artificially synthesized and anonymized user feedback branches extracted from a
public industrial automation forum. Each JavaScript object notation (JSON)
record contains multi-post comments related to specific hardware and software
products, enriched with metadata and contextual conversation data. Leveraging a
large language model (LLM), each branch is systematically analyzed and
annotated for UX insights, user expectations, severity and sentiment ratings,
and topic classifications. The UXPID dataset is designed to facilitate research
in user requirements, user experience (UX) analysis, and AI-driven feedback
processing, particularly where privacy and licensing restrictions limit access
to real-world data. UXPID supports the training and evaluation of
transformer-based models for tasks such as issue detection, sentiment analysis,
and requirements extraction in the context of technical forums.

### 17. Event2Vec: A Geometric Approach to Learning Composable Representations of Event Sequences

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Antonin Sulc
- **URL**: <http://arxiv.org/abs/2509.12188v1>
- **Submitted**: 2025-09-15 17:51:02
- **Comment**: 10 pages, 3 figures, Symmetry and Geometry in Neural Representations
  Workshop at NeuralIPS (Neurreps) 2025
- **Topic Keywords**: rag
- **Reason**: The paper introduces a novel framework for learning representations of event sequences, leveraging geometric and topological structures. While it touches on neural representations and embeddings, it does not directly relate to query understanding, ranking models, or user behavior modeling in information retrieval, which are core areas of your research interests.

#### Abstract
> The study of neural representations, both in biological and artificial
systems, is increasingly revealing the importance of geometric and topological
structures. Inspired by this, we introduce Event2Vec, a novel framework for
learning representations of discrete event sequences. Our model leverages a
simple, additive recurrent structure to learn composable, interpretable
embeddings. We provide a theoretical analysis demonstrating that, under
specific training objectives, our model's learned representations in a
Euclidean space converge to an ideal additive structure. This ensures that the
representation of a sequence is the vector sum of its constituent events, a
property we term the linear additive hypothesis. To address the limitations of
Euclidean geometry for hierarchical data, we also introduce a variant of our
model in hyperbolic space, which is naturally suited to embedding tree-like
structures with low distortion. We present experiments to validate our
hypothesis and demonstrate the benefits of each geometry, highlighting the
improved performance of the hyperbolic model on hierarchical event sequences.

### 18. Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Pu Jian, Junhong Wu, Wei Sun, Chen Wang, Shuo Ren, Jiajun Zhang
- **URL**: <http://arxiv.org/abs/2509.12132v1>
- **Submitted**: 2025-09-15 16:57:25
- **Comment**: EMNLP2025 Main
- **Topic Keywords**: rag
- **Reason**: The paper discusses enhancing visual reflection in vision-language models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on visual reflection and reinforcement learning is not directly aligned with the user's core research themes, limiting its relevance.

#### Abstract
> Recent advances in text-only "slow-thinking" reasoning have prompted efforts
to transfer this capability to vision-language models (VLMs), for training
visual reasoning models (\textbf{VRMs}). owever, such transfer faces critical
challenges: Effective "slow thinking" in VRMs requires \textbf{visual
reflection}, the ability to check the reasoning process based on visual
information. Through quantitative analysis, we observe that current VRMs
exhibit limited visual reflection, as their attention to visual information
diminishes rapidly with longer generated responses. To address this challenge,
we propose a new VRM \textbf{Reflection-V}, which enhances visual reflection
based on reasoning data construction for cold-start and reward design for
reinforcement learning (RL). Firstly, we construct vision-centered reasoning
data by leveraging an agent that interacts between VLMs and reasoning LLMs,
enabling cold-start learning of visual reflection patterns. Secondly, a visual
attention based reward model is employed during RL to encourage reasoning based
on visual information. Therefore, \textbf{Reflection-V} demonstrates
significant improvements across multiple visual reasoning benchmarks.
Furthermore, \textbf{Reflection-V} maintains a stronger and more consistent
reliance on visual information during visual reasoning, indicating effective
enhancement in visual reflection capabilities.

### 19. Is 'Hope' a person or an idea? A pilot benchmark for NER: comparing traditional NLP tools and large language models on ambiguous entities

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Payam Latifi
- **URL**: <http://arxiv.org/abs/2509.12098v1>
- **Submitted**: 2025-09-15 16:21:59
- **Comment**: 14 pages, 9 figures, 2 tables. This is a pilot study evaluating six
  NER systems -- three traditional tools (NLTK, spaCy, Stanza) and three LLMs
  (Gemini-1.5-flash, DeepSeek-V3, Qwen-3-4B) -- on a small, ambiguity-rich
  dataset of 119 tokens. The annotated dataset, prompts are provided in
  appendices for full reproducibility. All experiments were conducted on 14 May
  2025
- **Topic Keywords**: rag
- **Reason**: The paper is somewhat related to the user's interests in Natural Language Processing (NLP) and Named Entity Recognition (NER), but it does not directly align with the user's primary focus on Information Retrieval, especially in areas requiring deep semantic understanding and real-time relevance optimization. The paper's focus on comparing traditional NLP tools and large language models on ambiguous entities is also not directly related to the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> This pilot study presents a small-scale but carefully annotated benchmark of
Named Entity Recognition (NER) performance across six systems: three non-LLM
NLP tools (NLTK, spaCy, Stanza) and three general-purpose large language models
(LLMs: Gemini-1.5-flash, DeepSeek-V3, Qwen-3-4B). The dataset contains 119
tokens covering five entity types (PERSON, LOCATION, ORGANIZATION, DATE, TIME).
We evaluated each system's output against the manually annotated gold standard
dataset using F1-score. The results show that LLMs generally outperform
conventional tools in recognizing context-sensitive entities like person names,
with Gemini achieving the highest average F1-score. However, traditional
systems like Stanza demonstrate greater consistency in structured tags such as
LOCATION and DATE. We also observed variability among LLMs, particularly in
handling temporal expressions and multi-word organizations. Our findings
highlight that while LLMs offer improved contextual understanding, traditional
tools remain competitive in specific tasks, informing model selection.

### 20. ToolRM: Outcome Reward Models for Tool-Calling Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Mayank Agarwal, Ibrahim Abdelaziz, Kinjal Basu, Merve Unuvar, Luis A. Lastras, Yara Rizk, Pavan Kapanipathi
- **URL**: <http://arxiv.org/abs/2509.11963v1>
- **Submitted**: 2025-09-15 14:17:17
- **Topic Keywords**: rag
- **Reason**: The paper focuses on reward modeling for large language models interacting with external tools, which is somewhat related to information retrieval and search technologies. However, the primary focus on tool-calling and reward models for LLMs does not directly align with the user's core research themes in query understanding, ranking models, and user behavior modeling. While there is some overlap with NLP and data mining, the paper's relevance is not strong enough to warrant a higher score.

#### Abstract
> As large language models (LLMs) increasingly interact with external tools,
reward modeling for tool use has become a critical yet underexplored area.
Existing reward models, trained primarily on natural language outputs, struggle
to evaluate tool-based reasoning and execution. To quantify this gap, we
introduce FC-RewardBench, the first benchmark designed to systematically assess
reward models' performance in tool-calling scenarios. Our analysis shows that
current reward models often miss key signals of effective tool use,
highlighting the need for domain-specific modeling. To address this, we propose
a training framework for outcome-based reward models using data synthesized
from permissively licensed, open-weight LLMs. We train models ranging from 1.7B
to 14B parameters and evaluate them across seven out-of-domain benchmarks.
These models consistently outperform general-purpose baselines, achieving up to
25\% average improvement in downstream task performance and enabling
data-efficient fine-tuning through reward-guided filtering.

### 21. Bhaasha, Bhasa, Zaban: A Survey for Low-Resourced Languages in South Asia - Current Stage and Challenges

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Sampoorna Poria, Xiaolei Huang
- **URL**: <http://arxiv.org/abs/2509.11570v1>
- **Submitted**: 2025-09-15 04:31:22
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to the user's interests in Natural Language Processing (NLP), but it focuses on low-resourced languages in South Asia, which is not a central match for the user's research themes. While it touches on transformer-based models, it does not directly relate to query understanding, ranking models, or user behavior modeling in the context of information retrieval.

#### Abstract
> Rapid developments of large language models have revolutionized many NLP
tasks for English data. Unfortunately, the models and their evaluations for
low-resource languages are being overlooked, especially for languages in South
Asia. Although there are more than 650 languages in South Asia, many of them
either have very limited computational resources or are missing from existing
language models. Thus, a concrete question to be answered is: Can we assess the
current stage and challenges to inform our NLP community and facilitate model
developments for South Asian languages? In this survey, we have comprehensively
examined current efforts and challenges of NLP models for South Asian languages
by retrieving studies since 2020, with a focus on transformer-based models,
such as BERT, T5, & GPT. We present advances and gaps across 3 essential
aspects: data, models, & tasks, such as available data sources, fine-tuning
strategies, & domain applications. Our findings highlight substantial issues,
including missing data in critical domains (e.g., health), code-mixing, and
lack of standardized evaluation benchmarks. Our survey aims to raise awareness
within the NLP community for more targeted data curation, unify benchmarks
tailored to cultural and linguistic nuances of South Asia, and encourage an
equitable representation of South Asian languages. The complete list of
resources is available at: https://github.com/trust-nlp/LM4SouthAsia-Survey.

### 22. D$^2$HScore: Reasoning-Aware Hallucination Detection via Semantic Breadth and Depth Analysis in LLMs

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Yue Ding, Xiaofang Zhu, Tianze Xia, Junfei Wu, Xinlong Chen, Qiang Liu, Liang Wang
- **URL**: <http://arxiv.org/abs/2509.11569v1>
- **Submitted**: 2025-09-15 04:28:38
- **Comment**: under review
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and deep semantic understanding, but it primarily focuses on hallucination detection in large Language Models (LLMs), which is not a central theme in your research. While it touches on the idea of semantic analysis, it's more focused on the reliability of LLMs' outputs rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> Although large Language Models (LLMs) have achieved remarkable success, their
practical application is often hindered by the generation of non-factual
content, which is called "hallucination". Ensuring the reliability of LLMs'
outputs is a critical challenge, particularly in high-stakes domains such as
finance, security, and healthcare. In this work, we revisit hallucination
detection from the perspective of model architecture and generation dynamics.
Leveraging the multi-layer structure and autoregressive decoding process of
LLMs, we decompose hallucination signals into two complementary dimensions: the
semantic breadth of token representations within each layer, and the semantic
depth of core concepts as they evolve across layers. Based on this insight, we
propose \textbf{D$^2$HScore (Dispersion and Drift-based Hallucination Score)},
a training-free and label-free framework that jointly measures: (1)
\textbf{Intra-Layer Dispersion}, which quantifies the semantic diversity of
token representations within each layer; and (2) \textbf{Inter-Layer Drift},
which tracks the progressive transformation of key token representations across
layers. To ensure drift reflects the evolution of meaningful semantics rather
than noisy or redundant tokens, we guide token selection using attention
signals. By capturing both the horizontal and vertical dynamics of
representation during inference, D$^2$HScore provides an interpretable and
lightweight proxy for hallucination detection. Extensive experiments across
five open-source LLMs and five widely used benchmarks demonstrate that
D$^2$HScore consistently outperforms existing training-free baselines.

### 23. A Transformer-Based Cross-Platform Analysis of Public Discourse on the 15-Minute City Paradigm

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Gaurab Chhetri, Darrell Anderson, Boniphace Kutela, Subasish Das
- **URL**: <http://arxiv.org/abs/2509.11443v1>
- **Submitted**: 2025-09-14 21:36:24
- **Comment**: This is the author's preprint version of a paper accepted for
  presentation at the 24th International Conference on Machine Learning and
  Applications (ICMLA 2025), December 3-5, 2025, Florida, USA. The final
  published version will appear in the official IEEE proceedings. Conference
  site: https://www.icmla-conference.org/icmla25/
- **Topic Keywords**: ctr
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Information Retrieval (IR), particularly in the context of text classification and sentiment analysis. However, the focus on the 15-minute city paradigm and its application in urban planning discourse is not directly aligned with your core research themes. The use of transformer-based models and compressed models is relevant, but the specific domain and application are not central to your interests.

#### Abstract
> This study presents the first multi-platform sentiment analysis of public
opinion on the 15-minute city concept across Twitter, Reddit, and news media.
Using compressed transformer models and Llama-3-8B for annotation, we classify
sentiment across heterogeneous text domains. Our pipeline handles long-form and
short-form text, supports consistent annotation, and enables reproducible
evaluation. We benchmark five models (DistilRoBERTa, DistilBERT, MiniLM,
ELECTRA, TinyBERT) using stratified 5-fold cross-validation, reporting
F1-score, AUC, and training time. DistilRoBERTa achieved the highest F1
(0.8292), TinyBERT the best efficiency, and MiniLM the best cross-platform
consistency. Results show News data yields inflated performance due to class
imbalance, Reddit suffers from summarization loss, and Twitter offers moderate
challenge. Compressed models perform competitively, challenging assumptions
that larger models are necessary. We identify platform-specific trade-offs and
propose directions for scalable, real-world sentiment classification in urban
planning discourse.

### 24. Joint Effects of Argumentation Theory, Audio Modality and Data Enrichment on LLM-Based Fallacy Classification

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Hongxu Zhou, Hylke Westerdijk, Khondoker Ittehadul Islam
- **URL**: <http://arxiv.org/abs/2509.11127v1>
- **Submitted**: 2025-09-14 06:35:34
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and deep semantic understanding, but it focuses on fallacy classification and argumentation theory, which is not a central match to your primary focus on Information Retrieval and Search technologies. The paper's use of large language models and data enrichment is somewhat relevant, but the specific application and results do not align closely with your research themes.

#### Abstract
> This study investigates how context and emotional tone metadata influence
large language model (LLM) reasoning and performance in fallacy classification
tasks, particularly within political debate settings. Using data from U.S.
presidential debates, we classify six fallacy types through various prompting
strategies applied to the Qwen-3 (8B) model. We introduce two theoretically
grounded Chain-of-Thought frameworks: Pragma-Dialectics and the Periodic Table
of Arguments, and evaluate their effectiveness against a baseline prompt under
three input settings: text-only, text with context, and text with both context
and audio-based emotional tone metadata. Results suggest that while theoretical
prompting can improve interpretability and, in some cases, accuracy, the
addition of context and especially emotional tone metadata often leads to
lowered performance. Emotional tone metadata biases the model toward labeling
statements as \textit{Appeal to Emotion}, worsening logical reasoning. Overall,
basic prompts often outperformed enhanced ones, suggesting that attention
dilution from added inputs may worsen rather than improve fallacy
classification in LLMs.

### 25. Lost in Embeddings: Information Loss in Vision-Language Models

- **LLM Score**: 3
- **Keyword Score**: 2
- **Authors**: Wenyan Li, Raphael Tang, Chengzu Li, Caiqi Zhang, Ivan Vuliƒá, Anders S√∏gaard
- **URL**: <http://arxiv.org/abs/2509.11986v1>
- **Submitted**: 2025-09-15 14:38:06
- **Topic Keywords**: retrieval
- **Reason**: This paper explores information loss in vision-language models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on vision-language models and visual embeddings is not directly aligned with the user's primary research interests in IR and NLP. The paper's findings on information loss and model behavior may have some indirect implications for IR, but it is not a central match.

#### Abstract
> Vision--language models (VLMs) often process visual inputs through a
pretrained vision encoder, followed by a projection into the language model's
embedding space via a connector component. While crucial for modality fusion,
the potential information loss induced by this projection step and its direct
impact on model capabilities remain understudied. We introduce two
complementary approaches to examine and quantify this loss by analyzing the
latent representation space. First, we evaluate semantic information
preservation by analyzing changes in k-nearest neighbor relationships between
image representations, before and after projection. Second, we directly measure
information loss by reconstructing visual embeddings from the projected
representation, localizing loss at an image patch level. Experiments reveal
that connectors substantially distort the local geometry of visual
representations, with k-nearest neighbors diverging by 40--60\%
post-projection, correlating with degradation in retrieval performance. The
patch-level embedding reconstruction provides interpretable insights for model
behavior on visually grounded question-answering tasks, finding that areas of
high information loss reliably predict instances where models struggle.

### 26. Evalet: Evaluating Large Language Models by Fragmenting Outputs into Functions

- **LLM Score**: 3
- **Keyword Score**: 2
- **Authors**: Tae Soo Kim, Heechan Lee, Yoonjoo Lee, Joseph Seering, Juho Kim
- **URL**: <http://arxiv.org/abs/2509.11206v1>
- **Submitted**: 2025-09-14 10:24:13
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to the user's research interests in Natural Language Processing (NLP) and Large Language Models, but it does not directly align with the user's primary focus on Information Retrieval, query understanding, and ranking models. The paper's focus on evaluating LLMs and their outputs is tangentially related to the user's interests in deep semantic understanding and real-time relevance optimization, but it does not appear to be a central match.

#### Abstract
> Practitioners increasingly rely on Large Language Models (LLMs) to evaluate
generative AI outputs through "LLM-as-a-Judge" approaches. However, these
methods produce holistic scores that obscure which specific elements influenced
the assessments. We propose functional fragmentation, a method that dissects
each output into key fragments and interprets the rhetoric functions that each
fragment serves relative to evaluation criteria -- surfacing the elements of
interest and revealing how they fulfill or hinder user goals. We instantiate
this approach in Evalet, an interactive system that visualizes fragment-level
functions across many outputs to support inspection, rating, and comparison of
evaluations. A user study (N=10) found that, while practitioners struggled to
validate holistic scores, our approach helped them identify 48% more evaluation
misalignments. This helped them calibrate trust in LLM evaluations and rely on
them to find more actionable issues in model outputs. Our work shifts LLM
evaluation from quantitative scores toward qualitative, fine-grained analysis
of model behavior.

### 27. Membership Inference Attacks on Recommender System: A Survey

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Jiajie He, Yuechun Gu, Keke Chen, Xintong Chen
- **URL**: <http://arxiv.org/abs/2509.11080v1>
- **Submitted**: 2025-09-14 04:06:03
- **Topic Keywords**: user behavior, recommend, commerce, e-commerce, search, recsys
- **Reason**: This paper is primarily focused on recommender systems and membership inference attacks, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the topic is not directly aligned with your core research themes, such as query understanding, ranking models, and user behavior modeling.

#### Abstract
> Recommender systems (RecSys) have been widely applied to various
applications, including E-commerce, finance, healthcare, social media and have
become increasingly influential in shaping user behavior and decision-making,
highlighting their growing impact in various domains. However, recent studies
have shown that RecSys are vulnerable to membership inference attacks (MIAs),
which aim to infer whether user interaction record was used to train a target
model or not. MIAs on RecSys models can directly lead to a privacy breach. For
example, via identifying the fact that a purchase record that has been used to
train a RecSys associated with a specific user, an attacker can infer that
user's special quirks. In recent years, MIAs have been shown to be effective on
other ML tasks, e.g., classification models and natural language processing.
However, traditional MIAs are ill-suited for RecSys due to the unseen posterior
probability. Although MIAs on RecSys form a newly emerging and rapidly growing
research area, there has been no systematic survey on this topic yet. In this
article, we conduct the first comprehensive survey on RecSys MIAs. This survey
offers a comprehensive review of the latest advancements in RecSys MIAs,
exploring the design principles, challenges, attack and defense associated with
this emerging field. We provide a unified taxonomy that categorizes different
RecSys MIAs based on their characterizations and discuss their pros and cons.
Based on the limitations and gaps identified in this survey, we point out
several promising future research directions to inspire the researchers who
wish to follow this area. This survey not only serves as a reference for the
research community but also provides a clear description for researchers
outside this research domain.

### 28. MOOM: Maintenance, Organization and Optimization of Memory in Ultra-Long Role-Playing Dialogues

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Weishu Chen, Jinyi Tang, Zhouhui Hou, Shihao Han, Mingjie Zhan, Zhiyuan Huang, Delong Liu, Jiawei Guo, Zhicheng Zhao, Fei Su
- **URL**: <http://arxiv.org/abs/2509.11860v1>
- **Submitted**: 2025-09-15 12:35:14
- **Topic Keywords**: ltr, rag
- **Reason**: This paper focuses on memory extraction in human-robot role-playing scenarios, leveraging literary theory and a forgetting mechanism. While it involves NLP and deep semantic understanding, it is not directly related to information retrieval, search technologies, or user behavior modeling, which are the core areas of your research interests.

#### Abstract
> Memory extraction is crucial for maintaining coherent ultra-long dialogues in
human-robot role-playing scenarios. However, existing methods often exhibit
uncontrolled memory growth. To address this, we propose MOOM, the first
dual-branch memory plugin that leverages literary theory by modeling plot
development and character portrayal as core storytelling elements.
Specifically, one branch summarizes plot conflicts across multiple time scales,
while the other extracts the user's character profile. MOOM further integrates
a forgetting mechanism, inspired by the ``competition-inhibition'' memory
theory, to constrain memory capacity and mitigate uncontrolled growth.
Furthermore, we present ZH-4O, a Chinese ultra-long dialogue dataset
specifically designed for role-playing, featuring dialogues that average 600
turns and include manually annotated memory information. Experimental results
demonstrate that MOOM outperforms all state-of-the-art memory extraction
methods, requiring fewer large language model invocations while maintaining a
controllable memory capacity.

### 29. RAGs to Riches: RAG-like Few-shot Learning for Large Language Model Role-playing

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Timothy Rupprecht, Enfu Nan, Arash Akbari, Arman Akbari, Lei Lu, Priyanka Maan, Sean Duffy, Pu Zhao, Yumei He, David Kaeli, Yanzhi Wang
- **URL**: <http://arxiv.org/abs/2509.12168v1>
- **Submitted**: 2025-09-15 17:31:15
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper focuses on Large Language Model role-playing, using few-shot learning and a text retrieval approach. While it involves some aspects of Natural Language Processing, it does not directly relate to Information Retrieval, query understanding, ranking models, or user behavior modeling, which are core areas of interest.

#### Abstract
> Role-playing Large language models (LLMs) are increasingly deployed in
high-stakes domains such as healthcare, education, and governance, where
failures can directly impact user trust and well-being. A cost effective
paradigm for LLM role-playing is few-shot learning, but existing approaches
often cause models to break character in unexpected and potentially harmful
ways, especially when interacting with hostile users. Inspired by
Retrieval-Augmented Generation (RAG), we reformulate LLM role-playing into a
text retrieval problem and propose a new prompting framework called
RAGs-to-Riches, which leverages curated reference demonstrations to condition
LLM responses. We evaluate our framework with LLM-as-a-judge preference voting
and introduce two novel token-level ROUGE metrics: Intersection over Output
(IOO) to quantity how much an LLM improvises and Intersection over References
(IOR) to measure few-shot demonstrations utilization rate during the evaluation
tasks. When simulating interactions with a hostile user, our prompting strategy
incorporates in its responses during inference an average of 35% more tokens
from the reference demonstrations. As a result, across 453 role-playing
interactions, our models are consistently judged as being more authentic, and
remain in-character more often than zero-shot and in-context Learning (ICL)
methods. Our method presents a scalable strategy for building robust,
human-aligned LLM role-playing frameworks.

### 30. XplaiNLP at CheckThat! 2025: Multilingual Subjectivity Detection with Finetuned Transformers and Prompt-Based Inference with Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Ariana Sahitaj, Jiaao Li, Pia Wenzel Neves, Fedor Splitt, Premtim Sahitaj, Charlott Jakob, Veronika Solopova, Vera Schmitt
- **URL**: <http://arxiv.org/abs/2509.12130v1>
- **Submitted**: 2025-09-15 16:53:41
- **Topic Keywords**: ranking, rank
- **Reason**: This paper is primarily focused on multilingual subjectivity detection using NLP techniques, which is somewhat related to the user's interests in NLP. However, it does not align with the user's core research themes in Information Retrieval, query understanding, ranking models, or user behavior modeling.

#### Abstract
> This notebook reports the XplaiNLP submission to the CheckThat! 2025 shared
task on multilingual subjectivity detection. We evaluate two approaches: (1)
supervised fine-tuning of transformer encoders, EuroBERT, XLM-RoBERTa, and
German-BERT, on monolingual and machine-translated training data; and (2)
zero-shot prompting using two LLMs: o3-mini for Annotation (rule-based
labelling) and gpt-4.1-mini for DoubleDown (contrastive rewriting) and
Perspective (comparative reasoning). The Annotation Approach achieves 1st place
in the Italian monolingual subtask with an F_1 score of 0.8104, outperforming
the baseline of 0.6941. In the Romanian zero-shot setting, the fine-tuned
XLM-RoBERTa model obtains an F_1 score of 0.7917, ranking 3rd and exceeding the
baseline of 0.6461. The same model also performs reliably in the multilingual
task and improves over the baseline in Greek. For German, a German-BERT model
fine-tuned on translated training data from typologically related languages
yields competitive performance over the baseline. In contrast, performance in
the Ukrainian and Polish zero-shot settings falls slightly below the respective
baselines, reflecting the challenge of generalization in low-resource
cross-lingual scenarios.

### 31. SAQ: Pushing the Limits of Vector Quantization through Code Adjustment and Dimension Segmentation

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Hui Li, Shiyuan Deng, Xiao Yan, Xiangyu Zhi, James Cheng
- **URL**: <http://arxiv.org/abs/2509.12086v1>
- **Submitted**: 2025-09-15 16:14:05
- **Comment**: 13 pages, 12 figures, accepted by SIGMOD
- **Topic Keywords**: rag, recommend, search
- **Reason**: This paper focuses on Vector Quantization, a technique used in Approximate Nearest Neighbor Search, which is relevant to recommender systems. However, it does not directly relate to Information Retrieval, query understanding, or ranking models, which are core areas of your research interests.

#### Abstract
> Approximate Nearest Neighbor Search (ANNS) plays a critical role in
applications such as search engines, recommender systems, and RAG for LLMs.
Vector quantization (VQ), a crucial technique for ANNS, is commonly used to
reduce space overhead and accelerate distance computations. However, despite
significant research advances, state-of-the-art VQ methods still face
challenges in balancing encoding efficiency and quantization accuracy. To
address these limitations, we propose a novel VQ method called SAQ. To improve
accuracy, SAQ employs a new dimension segmentation technique to strategically
partition PCA-projected vectors into segments along their dimensions. By
prioritizing leading dimension segments with larger magnitudes, SAQ allocates
more bits to high-impact segments, optimizing the use of the available space
quota. An efficient dynamic programming algorithm is developed to optimize
dimension segmentation and bit allocation, ensuring minimal quantization error.
To speed up vector encoding, SAQ devises a code adjustment technique to first
quantize each dimension independently and then progressively refine quantized
vectors using a coordinate-descent-like approach to avoid exhaustive
enumeration. Extensive experiments demonstrate SAQ's superiority over classical
methods (e.g., PQ, PCA) and recent state-of-the-art approaches (e.g., LVQ,
Extended RabitQ). SAQ achieves up to 80% reduction in quantization error and
accelerates encoding speed by over 80x compared to Extended RabitQ.

### 32. An Incentive-Compatible Reward Sharing Mechanism for Mitigating Mirroring Attacks in Decentralized Data-Feed Systems

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Sina Aeeneh, Nikola Zlatanov, Jiangshan Yu
- **URL**: <http://arxiv.org/abs/2509.11294v1>
- **Submitted**: 2025-09-14 14:33:17
- **Topic Keywords**: rag, acl
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The topic of decentralized data-feed systems and mirroring attacks is unrelated to your areas of focus.

#### Abstract
> Decentralized data-feed systems enable blockchain-based smart contracts to
access off-chain information by aggregating values from multiple oracles. To
improve accuracy, these systems typically use an aggregation function, such as
majority voting, to consolidate the inputs they receive from oracles and make a
decision. Depending on the final decision and the values reported by the
oracles, the participating oracles are compensated through shared rewards.
However, such incentive mechanisms are vulnerable to mirroring attacks, where a
single user controls multiple oracles to bias the decision of the aggregation
function and maximize rewards. This paper analyzes the impact of mirroring
attacks on the reliability and dependability of majority voting-based data-feed
systems. We demonstrate how existing incentive mechanisms can unintentionally
encourage rational users to implement such attacks. To address this, we propose
a new incentive mechanism that discourages Sybil behavior. We prove that the
proposed mechanism leads to a Nash Equilibrium in which each user operates only
one oracle. Finally, we discuss the practical implementation of the proposed
incentive mechanism and provide numerical examples to demonstrate its
effectiveness.

### 33. Text2Mem: A Unified Memory Operation Language for Memory Operating System

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Felix Wang, Boyu Chen, Kerun Xu, Bo Tang, Feiyu Xiong, Zhiyu Li
- **URL**: <http://arxiv.org/abs/2509.11145v1>
- **Submitted**: 2025-09-14 07:30:09
- **Comment**: 11 pages, 3 figures
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper appears to be unrelated to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on memory operation languages and memory control in agents does not align with your areas of expertise.

#### Abstract
> Large language model agents increasingly depend on memory to sustain long
horizon interaction, but existing frameworks remain limited. Most expose only a
few basic primitives such as encode, retrieve, and delete, while higher order
operations like merge, promote, demote, split, lock, and expire are missing or
inconsistently supported. Moreover, there is no formal and executable
specification for memory commands, leaving scope and lifecycle rules implicit
and causing unpredictable behavior across systems. We introduce Text2Mem, a
unified memory operation language that provides a standardized pathway from
natural language to reliable execution. Text2Mem defines a compact yet
expressive operation set aligned with encoding, storage, and retrieval. Each
instruction is represented as a JSON based schema instance with required fields
and semantic invariants, which a parser transforms into typed operation objects
with normalized parameters. A validator ensures correctness before execution,
while adapters map typed objects either to a SQL prototype backend or to real
memory frameworks. Model based services such as embeddings or summarization are
integrated when required. All results are returned through a unified execution
contract. This design ensures safety, determinism, and portability across
heterogeneous backends. We also outline Text2Mem Bench, a planned benchmark
that separates schema generation from backend execution to enable systematic
evaluation. Together, these components establish the first standardized
foundation for memory control in agents.

### 34. AEFS: Adaptive Early Feature Selection for Deep Recommender Systems

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Fan Hu, Gaofeng Lu, Jun Chen, Chaonan Guo, Yuekui Yang, Xirong Li
- **URL**: <http://arxiv.org/abs/2509.12076v1>
- **Submitted**: 2025-09-15 16:04:24
- **Comment**: Accepted by TKDE
- **Topic Keywords**: rag, recommend
- **Reason**: This paper focuses on recommender systems, specifically feature selection and adaptive methods, which is somewhat related to the user's interests in Information Retrieval and Search technologies. However, the paper's emphasis on recommender systems and feature selection is not a central match for the user's core research themes.

#### Abstract
> Feature selection has emerged as a crucial technique in refining recommender
systems. Recent advancements leveraging Automated Machine Learning (AutoML) has
drawn significant attention, particularly in two main categories: early feature
selection and late feature selection, differentiated by whether the selection
occurs before or after the embedding layer. The early feature selection selects
a fixed subset of features and retrains the model, while the late feature
selection, known as adaptive feature selection, dynamically adjusts feature
choices for each data instance, recognizing the variability in feature
significance. Although adaptive feature selection has shown remarkable
improvements in performance, its main drawback lies in its post-embedding layer
feature selection. This process often becomes cumbersome and inefficient in
large-scale recommender systems with billions of ID-type features, leading to a
highly sparse and parameter-heavy embedding layer. To overcome this, we
introduce Adaptive Early Feature Selection (AEFS), a very simple method that
not only adaptively selects informative features for each instance, but also
significantly reduces the activated parameters of the embedding layer. AEFS
employs a dual-model architecture, encompassing an auxiliary model dedicated to
feature selection and a main model responsible for prediction. To ensure
effective alignment between these two models, we incorporate two collaborative
training loss constraints. Our extensive experiments on three benchmark
datasets validate the efficiency and effectiveness of our approach. Notably,
AEFS matches the performance of current state-of-theart Adaptive Late Feature
Selection methods while achieving a significant reduction of 37. 5% in the
activated parameters of the embedding layer. AEFS is open-source at
https://github. com/fly-dragon211/AEFS .

### 35. How to Evaluate Medical AI

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Ilia Kopanichuk, Petr Anokhin, Vladimir Shaposhnikov, Vladimir Makharev, Ekaterina Tsapieva, Iaroslav Bespalov, Dmitry V. Dylov, Ivan Oseledets
- **URL**: <http://arxiv.org/abs/2509.11941v1>
- **Submitted**: 2025-09-15 14:01:22
- **Comment**: 10 pages, 7 fugures
- **Topic Keywords**: relevance
- **Reason**: This paper is not directly related to your core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves AI and large language models, the focus is on medical diagnostic workflows and evaluation metrics, which is outside your primary areas of interest.

#### Abstract
> The integration of artificial intelligence (AI) into medical diagnostic
workflows requires robust and consistent evaluation methods to ensure
reliability, clinical relevance, and the inherent variability in expert
judgments. Traditional metrics like precision and recall often fail to account
for the inherent variability in expert judgments, leading to inconsistent
assessments of AI performance. Inter-rater agreement statistics like Cohen's
Kappa are more reliable but they lack interpretability. We introduce Relative
Precision and Recall of Algorithmic Diagnostics (RPAD and RRAD) - a new
evaluation metrics that compare AI outputs against multiple expert opinions
rather than a single reference. By normalizing performance against inter-expert
disagreement, these metrics provide a more stable and realistic measure of the
quality of predicted diagnosis. In addition to the comprehensive analysis of
diagnostic quality measures, our study contains a very important side result.
Our evaluation methodology allows us to avoid selecting diagnoses from a
limited list when evaluating a given case. Instead, both the models being
tested and the examiners verifying them arrive at a free-form diagnosis. In
this automated methodology for establishing the identity of free-form clinical
diagnoses, a remarkable 98% accuracy becomes attainable. We evaluate our
approach using 360 medical dialogues, comparing multiple large language models
(LLMs) against a panel of physicians. Large-scale study shows that
top-performing models, such as DeepSeek-V3, achieve consistency on par with or
exceeding expert consensus. Moreover, we demonstrate that expert judgments
exhibit significant variability - often greater than that between AI and
humans. This finding underscores the limitations of any absolute metrics and
supports the need to adopt relative metrics in medical AI.

### 36. MindVL: Towards Efficient and Effective Training of Multimodal Large Language Models on Ascend NPUs

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Feilong Chen, Yijiang Liu, Yi Huang, Hao Wang, Miren Tian, Ya-Qi Yu, Minghui Liao, Jihao Wu
- **URL**: <http://arxiv.org/abs/2509.11662v1>
- **Submitted**: 2025-09-15 08:00:31
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on multimodal large language models and their training on Ascend NPUs, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. While it involves natural language processing, the context is more aligned with NLP applications rather than IR or search technologies.

#### Abstract
> We propose MindVL, a multimodal large langauge model trained on Ascend NPUs.
Similar to Qwen2.5-VL, MindVL adopts native-resolution Vision Transformers,
which enables it to process images at their original variable resolutions. This
design avoids the degradation caused by fixed-resolution tiling while
preserving fine-grained details and global layouts, which is crucial for
visually dense content such as complex charts and diagrams. To ensure the
smooth training of MindVL on Ascend NPUs, we develop Mindspeed-MLLM, a
distributed multimodal training framework tailored for Ascend NPUs. To maintain
training accuracy, we implement equivalent replacements for certain operators.
MindVL undergoes a three-phase training process, namely the warm-up phase,
multitask training phase, and supervised instruction tuning phase, to gradually
enhance its capabilities. This process starts with basic visual and multimodal
pre-training, followed by large-scale multiask trainging and instruction
tuning. We also adopt multimodal data packaging and hybrid parallelism
techniques, which significantly improve end-to-end training speed. To further
boost model performance, we specifically introduce test-time resolution search
and model weight averaging. Notably, despite using about 1/10 of the training
data required by Qwen2.5-VL, MindVL achieves performance on par with Qwen2.5-VL
in evaluations of general multimodal understanding and document/table
comprehension. Beyond overall scores, MindVL also delivers leading performance
in OCR assessments.

### 37. MALLM: Multi-Agent Large Language Models Framework

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jonas Becker, Lars Benedikt Kaesberg, Niklas Bauer, Jan Philip Wahle, Terry Ruas, Bela Gipp
- **URL**: <http://arxiv.org/abs/2509.11656v1>
- **Submitted**: 2025-09-15 07:48:02
- **Comment**: Accepted at EMNLP 2025 (Demo)
- **Topic Keywords**: rag, search
- **Reason**: This paper appears to be focused on multi-agent debate and large language models, which is outside of your primary research interests in Information Retrieval and Search technologies. While it involves NLP, the context and application seem unrelated to your core themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> Multi-agent debate (MAD) has demonstrated the ability to augment collective
intelligence by scaling test-time compute and leveraging expertise. Current
frameworks for multi-agent debate are often designed towards tool use, lack
integrated evaluation, or provide limited configurability of agent personas,
response generators, discussion paradigms, and decision protocols. We introduce
MALLM (Multi-Agent Large Language Models), an open-source framework that
enables systematic analysis of MAD components. MALLM offers more than 144
unique configurations of MAD, including (1) agent personas (e.g., Expert,
Personality), (2) response generators (e.g., Critical, Reasoning), (3)
discussion paradigms (e.g., Memory, Relay), and (4) decision protocols (e.g.,
Voting, Consensus). MALLM uses simple configuration files to define a debate.
Furthermore, MALLM can load any textual Huggingface dataset (e.g., MMLU-Pro,
WinoGrande) and provides an evaluation pipeline for easy comparison of MAD
configurations. MALLM is tailored towards researchers and provides a window
into the heart of multi-agent debate, facilitating the understanding of its
components and their interplay.

### 38. Opal: An Operator Algebra View of RLHF

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Madhava Gaikwad
- **URL**: <http://arxiv.org/abs/2509.11298v1>
- **Submitted**: 2025-09-14 14:42:39
- **Comment**: 11 pages main
- **Topic Keywords**: pairwise
- **Reason**: This paper appears to be focused on reinforcement learning from human feedback (RLHF), which is not directly related to the user's core research themes in Information Retrieval and Search technologies. While it touches on the idea of optimizing objectives, it does not seem to involve query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's interests.

#### Abstract
> We present Opal, an operator view of reinforcement learning from human
feedback (RLHF). Objectives are expressed as ladders of two primitives on a
base utility: additive penalties and multiplicative pairwise weights. We
describe a simple reduction law with if-and-only-if conditions: such ladders
collapse to a normal form on pairwise margins when the reference is fixed,
penalties are additive, and weights are independent of intermediate margins.
When these assumptions do not hold (reference shift, non-additive gates,
score-dependent weights), small examples demonstrate non-reducibility.
  Building on this view, we introduce GKPO (Generalized Kernel Preference
Object), a canonical schema in which many RLHF methods can be represented and,
when reducible, mapped back from. GKPO provides a standard JSON serialization,
canonicalization and hashing rules, and explicit flags with finite witnesses
when assumptions fail.
  We illustrate these ideas with GKPO examples for DPO, RRHF, and ORPO, along
with cross-method conversions (where assumptions permit) and minimal stress
tests (SHIFT/GATE/SCORE) that highlight non-reducibility. A lightweight Python
reference library accompanies the schema, implementing canonical hashing and
adapters for DPO and RRHF.

### 39. AQUA: Attention via QUery mAgnitudes for Memory and Compute Efficient Inference in LLMs

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Santhosh G S, Saurav Prakash, Balaraman Ravindran
- **URL**: <http://arxiv.org/abs/2509.11155v1>
- **Submitted**: 2025-09-14 08:20:48
- **Topic Keywords**: query
- **Reason**: This paper focuses on optimizing Large Language Models (LLMs) for efficient inference, which is not directly related to Information Retrieval (IR) or Search technologies. While it does involve attention mechanisms, the context is not relevant to query understanding, ranking models, or user behavior modeling, which are core areas of interest.

#### Abstract
> The quadratic complexity of the attention mechanism remains a fundamental
barrier to scaling Large Language Models (LLMs) to longer contexts, creating a
critical bottleneck in both computation and memory. To address this, we
introduce AQUA (Attention via QUery mAgnitudes) a novel and versatile
approximation strategy that significantly reduces the cost of attention with a
graceful performance trade-off. Our method operates in two phases: an efficient
offline step where we compute a universal, language agnostic projection matrix
via SVD on a calibration dataset, and an online inference step where we project
query and key vectors and dynamically select a sparse subset of dimensions
based on the query's magnitude. We provide a formal theoretical analysis of
AQUA, establishing the break-even point at which it becomes more
computationally efficient than standard attention. Our empirical evaluations on
state-of-the-art models like Llama-3.1-8B demonstrate that a 25% reduction in
the attention dot-product computation can be achieved with a statistically
insignificant impact on performance across a wide range of benchmarks. We
further showcase the versatility of AQUA by demonstrating its ability to
synergistically accelerate existing token eviction methods like H2O and to
directly reduce KV-cache memory size. By offering a controllable knob to
balance efficiency and accuracy, AQUA provides a practical and powerful tool
for making large-scale LLM inference more accessible and sustainable.

### 40. Length-Aware Rotary Position Embedding for Text-Speech Alignment

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Hyeongju Kim, Juheon Lee, Jinhyeok Yang, Jacob Morton
- **URL**: <http://arxiv.org/abs/2509.11084v1>
- **Submitted**: 2025-09-14 04:25:13
- **Comment**: 5 pages, 3 figures, preprint
- **Topic Keywords**: query
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing, as it focuses on Text-to-Speech (TTS) systems and rotary position embedding for text-speech alignment.

#### Abstract
> Many recent text-to-speech (TTS) systems are built on transformer
architectures and employ cross-attention mechanisms for text-speech alignment.
Within these systems, rotary position embedding (RoPE) is commonly used to
encode positional information in text and speech representations. In this work,
we introduce length-aware RoPE (LARoPE), a simple yet effective extension of
RoPE that improves text-speech alignment. Unlike RoPE, which relies on absolute
indices, LARoPE computes relative distances between query and key positions
using length-normalized indices. Experimental results show that LARoPE
consistently outperforms RoPE, offering faster loss convergence, more accurate
text-speech alignment, and higher overall TTS quality. Furthermore, LARoPE
demonstrates greater resilience to variations in utterance duration and
maintains stable performance in extended speech generation up to 30 seconds,
whereas RoPE suffers from notable degradation. Notably, our method achieves a
state-of-the-art word error rate on a standard zero-shot TTS benchmark.

### 41. Text Adaptation to Plain Language and Easy Read via Automatic Post-Editing Cycles

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jes√∫s Calleja, David Ponce, Thierry Etchegoyhen
- **URL**: <http://arxiv.org/abs/2509.11991v1>
- **Submitted**: 2025-09-15 14:42:44
- **Topic Keywords**: rag
- **Reason**: This paper focuses on text adaptation and post-editing, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves Large Language Models, the context is more about readability and post-editing rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> We describe Vicomtech's participation in the CLEARS challenge on text
adaptation to Plain Language and Easy Read in Spanish. Our approach features
automatic post-editing of different types of initial Large Language Model
adaptations, where successive adaptations are generated iteratively until
readability and similarity metrics indicate that no further adaptation
refinement can be successfully performed. Taking the average of all official
metrics, our submissions achieved first and second place in Plain language and
Easy Read adaptation, respectively.

### 42. PledgeTracker: A System for Monitoring the Fulfilment of Pledges

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yulong Chen, Michael Sejr Schlichtkrull, Zhenyun Deng, David Corney, Nasim Asl, Joshua Salisbury, Andrew Dudfield, Andreas Vlachos
- **URL**: <http://arxiv.org/abs/2509.11804v1>
- **Submitted**: 2025-09-15 11:37:47
- **Comment**: EMNLP 2025 demo
- **Topic Keywords**: retrieval
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or Natural Language Processing, which are the core areas of your research interests. While it involves evidence retrieval and filtering, the context is specific to pledge verification and fact-checking, which is not aligned with your primary focus on e-commerce or deep semantic understanding in IR.

#### Abstract
> Political pledges reflect candidates' policy commitments, but tracking their
fulfilment requires reasoning over incremental evidence distributed across
multiple, dynamically updated sources. Existing methods simplify this task into
a document classification task, overlooking its dynamic, temporal and
multi-document nature. To address this issue, we introduce
\textsc{PledgeTracker}, a system that reformulates pledge verification into
structured event timeline construction. PledgeTracker consists of three core
components: (1) a multi-step evidence retrieval module; (2) a timeline
construction module and; (3) a fulfilment filtering module, allowing the
capture of the evolving nature of pledge fulfilment and producing interpretable
and structured timelines. We evaluate PledgeTracker in collaboration with
professional fact-checkers in real-world workflows, demonstrating its
effectiveness in retrieving relevant evidence and reducing human verification
effort.

### 43. CoachMe: Decoding Sport Elements with a Reference-Based Coaching Instruction Generation Model

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Wei-Hsin Yeh, Yu-An Su, Chih-Ning Chen, Yi-Hsueh Lin, Calvin Ku, Wen-Hsin Chiu, Min-Chun Hu, Lun-Wei Ku
- **URL**: <http://arxiv.org/abs/2509.11698v1>
- **Submitted**: 2025-09-15 09:01:39
- **Comment**: Published in Proceedings of the 63rd Annual Meeting of the
  Association for Computational Linguistics (Volume 1: Long Papers), ACL 2025.
  Official version: https://doi.org/10.18653/v1/2025.acl-long.1413
- **Topic Keywords**: rag
- **Reason**: This paper focuses on a coaching instruction generation model for sports, which is not directly related to Information Retrieval, Search technologies, or Natural Language Processing. Although it involves multimodal models and text generation, the domain-specific nature of the task and the lack of relevance to the user's core research themes result in a low score.

#### Abstract
> Motion instruction is a crucial task that helps athletes refine their
technique by analyzing movements and providing corrective guidance. Although
recent advances in multimodal models have improved motion understanding,
generating precise and sport-specific instruction remains challenging due to
the highly domain-specific nature of sports and the need for informative
guidance. We propose CoachMe, a reference-based model that analyzes the
differences between a learner's motion and a reference under temporal and
physical aspects. This approach enables both domain-knowledge learning and the
acquisition of a coach-like thinking process that identifies movement errors
effectively and provides feedback to explain how to improve. In this paper, we
illustrate how CoachMe adapts well to specific sports such as skating and
boxing by learning from general movements and then leveraging limited data.
Experiments show that CoachMe provides high-quality instructions instead of
directions merely in the tone of a coach but without critical information.
CoachMe outperforms GPT-4o by 31.6% in G-Eval on figure skating and by 58.3% on
boxing. Analysis further confirms that it elaborates on errors and their
corresponding improvement methods in the generated instructions. You can find
CoachMe here: https://motionxperts.github.io/

### 44. Securing AI Agents: Implementing Role-Based Access Control for Industrial Applications

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Aadil Gani Ganie
- **URL**: <http://arxiv.org/abs/2509.11431v1>
- **Submitted**: 2025-09-14 20:58:08
- **Topic Keywords**: rag
- **Reason**: This paper focuses on securing AI agents using Role-Based Access Control, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> The emergence of Large Language Models (LLMs) has significantly advanced
solutions across various domains, from political science to software
development. However, these models are constrained by their training data,
which is static and limited to information available up to a specific date.
Additionally, their generalized nature often necessitates fine-tuning --
whether for classification or instructional purposes -- to effectively perform
specific downstream tasks. AI agents, leveraging LLMs as their core, mitigate
some of these limitations by accessing external tools and real-time data,
enabling applications such as live weather reporting and data analysis. In
industrial settings, AI agents are transforming operations by enhancing
decision-making, predictive maintenance, and process optimization. For example,
in manufacturing, AI agents enable near-autonomous systems that boost
productivity and support real-time decision-making. Despite these advancements,
AI agents remain vulnerable to security threats, including prompt injection
attacks, which pose significant risks to their integrity and reliability. To
address these challenges, this paper proposes a framework for integrating
Role-Based Access Control (RBAC) into AI agents, providing a robust security
guardrail. This framework aims to support the effective and scalable deployment
of AI agents, with a focus on on-premises implementations.

### 45. Ko-PIQA: A Korean Physical Commonsense Reasoning Dataset with Cultural Context

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Dasol Choi, Jungwhan Kim, Guijin Son
- **URL**: <http://arxiv.org/abs/2509.11303v1>
- **Submitted**: 2025-09-14 14:47:04
- **Topic Keywords**: search, korea
- **Reason**: This paper focuses on creating a Korean physical commonsense reasoning dataset with cultural context, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language models, the primary goal is to create a culturally diverse dataset for commonsense reasoning, which is not a central match for your research focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Physical commonsense reasoning datasets like PIQA are predominantly
English-centric and lack cultural diversity. We introduce Ko-PIQA, a Korean
physical commonsense reasoning dataset that incorporates cultural context.
Starting from 3.01 million web-crawled questions, we employed a multi-stage
filtering approach using three language models to identify 11,553 PIQA-style
questions. Through GPT-4o refinement and human validation, we obtained 441
high-quality question-answer pairs. A key feature of Ko-PIQA is its cultural
grounding: 19.7\% of questions contain culturally specific elements like
traditional Korean foods (kimchi), clothing (hanbok), and specialized
appliances (kimchi refrigerators) that require culturally-aware reasoning
beyond direct translation. We evaluate seven language models on Ko-PIQA, with
the best model achieving 83.22\% accuracy while the weakest reaches only
59.86\%, demonstrating significant room for improvement. Models particularly
struggle with culturally specific scenarios, highlighting the importance of
culturally diverse datasets. Ko-PIQA serves as both a benchmark for Korean
language models and a foundation for more inclusive commonsense reasoning
research. The dataset and code will be publicly available.

### 46. The Prompt Engineering Report Distilled: Quick Start Guide for Life Sciences

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Valentin Romanov, Steven A Niederer
- **URL**: <http://arxiv.org/abs/2509.11295v1>
- **Submitted**: 2025-09-14 14:39:35
- **Topic Keywords**: recommend, search
- **Reason**: This paper focuses on prompt engineering for Large Language Models in the life sciences domain, which is unrelated to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on NLP, it's more about optimizing model inputs rather than deep semantic understanding or real-time relevance optimization.

#### Abstract
> Developing effective prompts demands significant cognitive investment to
generate reliable, high-quality responses from Large Language Models (LLMs). By
deploying case-specific prompt engineering techniques that streamline
frequently performed life sciences workflows, researchers could achieve
substantial efficiency gains that far exceed the initial time investment
required to master these techniques. The Prompt Report published in 2025
outlined 58 different text-based prompt engineering techniques, highlighting
the numerous ways prompts could be constructed. To provide actionable
guidelines and reduce the friction of navigating these various approaches, we
distil this report to focus on 6 core techniques: zero-shot, few-shot
approaches, thought generation, ensembling, self-criticism, and decomposition.
We breakdown the significance of each approach and ground it in use cases
relevant to life sciences, from literature summarization and data extraction to
editorial tasks. We provide detailed recommendations for how prompts should and
shouldn't be structured, addressing common pitfalls including multi-turn
conversation degradation, hallucinations, and distinctions between reasoning
and non-reasoning models. We examine context window limitations, agentic tools
like Claude Code, while analyzing the effectiveness of Deep Research tools
across OpenAI, Google, Anthropic and Perplexity platforms, discussing current
limitations. We demonstrate how prompt engineering can augment rather than
replace existing established individual practices around data processing and
document editing. Our aim is to provide actionable guidance on core prompt
engineering principles, and to facilitate the transition from opportunistic
prompting to an effective, low-friction systematic practice that contributes to
higher quality research.

### 47. Mitigating Hallucinations in Large Vision-Language Models by Self-Injecting Hallucinations

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yifan Lu, Ziqi Zhang, Chunfeng Yuan, Jun Gao, Congxuan Zhang, Xiaojuan Qi, Bing Li, Weiming Hu
- **URL**: <http://arxiv.org/abs/2509.11287v1>
- **Submitted**: 2025-09-14 14:26:53
- **Comment**: emnlp 2025 accepted
- **Topic Keywords**: rag
- **Reason**: This paper focuses on mitigating hallucinations in Vision-Language Models, which is not directly related to Information Retrieval or Search technologies. While it involves deep semantic understanding, the context is different from the user's primary research interests in IR and NLP.

#### Abstract
> Large Vision-Language Models (LVLMs) suffer from serious hallucination
problems, where the model-generated responses are inconsistent with the visual
inputs. Existing hallucination mitigation methods are mainly based on
preference alignment and require external human annotations or auxiliary models
for preference data collection, which increase costs and limit sustainable
improvement. To tackle these challenges, we propose Autonomous Preference
Alignment via Self-Injection (APASI), a novel and generalizable method that
mitigates hallucinations without external dependencies. APASI leverages the
target LVLM to self-inject hallucinations into a generated response, creating a
pair of responses with varying preference levels. During the self-injection
process, the dis-preferred response is generated based on three key
observations of hallucinations, ensuring it simulates real hallucination
patterns. This fidelity offers an accurate learning signal for hallucination
mitigation. Moreover, APASI incorporates an iterative alignment training
strategy combined with curriculum learning to periodically update the
preference data with increasing challenge, enabling stable and continuous
enhancement of the LVLM. Extensive experiments across six benchmarks show that
APASI not only effectively mitigates hallucinations for three baseline models
but also achieves comparable or even superior performance to alignment-based
methods with external dependency, thereby demonstrating its effectiveness and
generalization capability. The code is available at
https://github.com/davidluciolu/APASI.

### 48. DreamNav: A Trajectory-Based Imaginative Framework for Zero-Shot Vision-and-Language Navigation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yunheng Wang, Yuetong Fang, Taowen Wang, Yixiao Feng, Yawen Tan, Shuning Zhang, Peiran Liu, Yiding Ji, Renjing Xu
- **URL**: <http://arxiv.org/abs/2509.11197v1>
- **Submitted**: 2025-09-14 09:54:20
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Vision-and-Language Navigation, a topic outside of the user's primary research interests in Information Retrieval and Search technologies. While it involves some aspects of Natural Language Processing, the paper's primary contributions and applications are in robotics and embodied AI, which do not align with the user's research background.

#### Abstract
> Vision-and-Language Navigation in Continuous Environments (VLN-CE), which
links language instructions to perception and control in the real world, is a
core capability of embodied robots. Recently, large-scale pretrained foundation
models have been leveraged as shared priors for perception, reasoning, and
action, enabling zero-shot VLN without task-specific training. However,
existing zero-shot VLN methods depend on costly perception and passive scene
understanding, collapsing control to point-level choices. As a result, they are
expensive to deploy, misaligned in action semantics, and short-sighted in
planning. To address these issues, we present DreamNav that focuses on the
following three aspects: (1) for reducing sensory cost, our EgoView Corrector
aligns viewpoints and stabilizes egocentric perception; (2) instead of
point-level actions, our Trajectory Predictor favors global trajectory-level
planning to better align with instruction semantics; and (3) to enable
anticipatory and long-horizon planning, we propose an Imagination Predictor to
endow the agent with proactive thinking capability. On VLN-CE and real-world
tests, DreamNav sets a new zero-shot state-of-the-art (SOTA), outperforming the
strongest egocentric baseline with extra information by up to 7.49\% and
18.15\% in terms of SR and SPL metrics. To our knowledge, this is the first
zero-shot VLN method to unify trajectory-level planning and active imagination
while using only egocentric inputs.

### 49. When marine radar target detection meets pretrained large language models

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Qiying Hu, Linping Zhang, Xueqian Wang, Gang Li, Yu Liu, Xiao-Ping Zhang
- **URL**: <http://arxiv.org/abs/2509.12110v1>
- **Submitted**: 2025-09-15 16:38:13
- **Topic Keywords**: rag
- **Reason**: This paper appears to be unrelated to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topic of marine radar target detection and its application of large language models does not align with the user's focus on query understanding, ranking models, user behavior modeling, and deep semantic understanding in real-time relevance optimization.

#### Abstract
> Deep learning (DL) methods are widely used to extract high-dimensional
patterns from the sequence features of radar echo signals. However,
conventional DL algorithms face challenges such as redundant feature segments,
and constraints from restricted model sizes. To address these issues, we
propose a framework that integrates feature preprocessing with large language
models (LLMs). Our preprocessing module tokenizes radar sequence features,
applies a patch selection algorithm to filter out uninformative segments, and
projects the selected patches into embeddings compatible with the feature space
of pre-trained LLMs. Leveraging these refined embeddings, we incorporate a
pre-trained LLM, fine-tuning only the normalization layers to reduce training
burdens while enhancing performance. Experiments on measured datasets
demonstrate that the proposed method significantly outperforms the
state-of-the-art baselines on supervised learning tests.

### 50. Acoustic Overspecification in Electronic Dance Music Taxonomy

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Weilun Xu, Tianhao Dai, Oscar Goudet, Xiaoxuan Wang
- **URL**: <http://arxiv.org/abs/2509.11474v1>
- **Submitted**: 2025-09-14 23:38:45
- **Comment**: 5 pages, 3 figures, conference paper
- **Topic Keywords**: ctr
- **Reason**: This paper is not related to Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing, which are the primary areas of interest. The paper focuses on music taxonomy and acoustic analysis, which is outside the scope of the user's research interests.

#### Abstract
> Electronic Dance Music (EDM) classification typically relies on
industry-defined taxonomies with numerous subgenres, yet the acoustic basis for
these distinctions remains unclear. Current approaches use supervised learning
with prescribed genre labels, assuming their validity without systematic
evaluation. In this paper, we propose an unsupervised approach to discover the
natural acoustic structure of EDM independent of commercial labels. Our method
combines novel tempogram-based features capturing EDM's layered rhythmic
patterns with multi-criteria feature selection. To validate that our findings
reflect genuine acoustic structure rather than methodological artifacts, we
compare our results against state-of-the-art pre-trained audio embeddings (MERT
and CLAP). Both our feature space and embedding representations converge to
19-23 natural acoustic families compared to the prescribed 35, providing
consistent evidence of significant overspecification in current EDM taxonomy by
approximately one-third.

---

