# Daily Papers Report - 2025-09-18

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. MA-DPR: Manifold-aware Distance Metrics for Dense Passage Retrieval

- **LLM Score**: 8
- **Keyword Score**: 15
- **Authors**: Yifan Liu, Qianfeng Wen, Mark Zhao, Jiazhou Liang, Scott Sanner
- **URL**: <http://arxiv.org/abs/2509.13562v1>
- **Submitted**: 2025-09-16 22:02:56
- **Comment**: 19 pages, 8 figures
- **Topic Keywords**: passage retrieval, query, relevance, rag, ctr, retrieval
- **Reason**: This paper proposes a novel distance metric for Dense Passage Retrieval (DPR), addressing limitations of traditional metrics in capturing semantic similarity, particularly in out-of-distribution settings. The focus on improving DPR, a key area in Information Retrieval, aligns with your research interests. However, the specific application to DPR and dense embedding tasks is somewhat narrow compared to your broader interests in IR, NLP, and related topics.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Dense Passage Retrieval (DPR)
- **Aim**: Improve DPR performance, particularly in out-of-distribution (OOD) settings, by leveraging manifold-aware distance metrics.
- **Rationale**: Traditional distance metrics like Euclidean and cosine struggle to accurately represent semantic relationships in OOD scenarios where embeddings reside on non-linear manifolds.
- **Ground**: Passage embeddings are represented as nodes in a weighted undirected graph, where connections are based on nearest neighbor relationships.
- **Experiment**: MA-DPR is evaluated on various datasets (ANTIQUE, MS MARCO, NFCorpus, SciDocs) using different distance metrics (Euclidean, cosine, spectral) and embedding models. Performance is compared to baselines like Euclidean and cosine distance, PCA, KernelPCA, and NCA.
- **Takeaway**: MA-DPR significantly outperforms DPR baselines on OOD datasets, achieving up to 26% improvement in retrieval accuracy. It maintains comparable performance on in-distribution datasets and demonstrates generalizability across various embedding models. The choice of distance metric, cost function, and K significantly influences performance.

#### Abstract
> Dense Passage Retrieval (DPR) typically relies on Euclidean or cosine
distance to measure query-passage relevance in embedding space, which is
effective when embeddings lie on a linear manifold. However, our experiments
across DPR benchmarks suggest that embeddings often lie on lower-dimensional,
non-linear manifolds, especially in out-of-distribution (OOD) settings, where
cosine and Euclidean distance fail to capture semantic similarity. To address
this limitation, we propose a manifold-aware distance metric for DPR (MA-DPR)
that models the intrinsic manifold structure of passages using a nearest
neighbor graph and measures query-passage distance based on their shortest path
in this graph. We show that MA-DPR outperforms Euclidean and cosine distances
by up to 26% on OOD passage retrieval with comparable in-distribution
performance across various embedding models while incurring a minimal increase
in query inference time. Empirical evidence suggests that manifold-aware
distance allows DPR to leverage context from related neighboring passages,
making it effective even in the absence of direct semantic overlap. MADPR can
be applied to a wide range of dense embedding and retrieval tasks, offering
potential benefits across a wide spectrum of domains.

---

### 2. Modernizing Facebook Scoped Search: Keyword and Embedding Hybrid Retrieval with LLM Evaluation

- **LLM Score**: 8
- **Keyword Score**: 8
- **Authors**: Yongye Su, Zeya Zhang, Jane Kou, Cheng Ju, Shubhojeet Sarkar, Yamin Wang, Ji Liu, Shengbo Guo
- **URL**: <http://arxiv.org/abs/2509.13603v1>
- **Submitted**: 2025-09-17 00:22:08
- **Comment**: 5 Pages, work done as Yongye Su's internship project at Meta
- **Topic Keywords**: relevance, rag, retrieval, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of social network search and blending traditional keyword-based retrieval with embedding-based retrieval. The use of large language models for evaluation is also aligned with your interests in query understanding and ranking models. The focus on real-world social platforms is a nice extension of your e-commerce background.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Modernizing Facebook Group Scoped Search
- **Aim**: Enhance semantic relevance and search quality by combining keyword-based retrieval with embedding-based retrieval (EBR)
- **Rationale**: Keyword-only search struggles to capture complex relationships between queries and posts, leading to information gaps. EBR offers semantic understanding but faces challenges in computational overhead and explainability.
- **Ground**: Existing Facebook Group Scoped Search relies on keyword-based retrieval using Unicorn inverted index.
- **Experiment**: Proposed system uses parallel retrieval, dispatching queries to both keyword-based and EBR pathways. EBR employs a 12-layer SSR model for vector encoding and ANN search. An L2 ranking model, fine-tuned with MTML architecture, combines lexical and semantic features to score candidates. Effectiveness is evaluated using a novel LLM-based framework with Llama 3 to assess relevance within group contexts.
- **Takeaway**: Hybrid approach with EBR significantly improves search quality. Future work explores incorporating LLMs into ranking, adaptive retrieval strategies, and further system refinement.

#### Abstract
> Beyond general web-scale search, social network search uniquely enables users
to retrieve information and discover potential connections within their social
context. We introduce a framework of modernized Facebook Group Scoped Search by
blending traditional keyword-based retrieval with embedding-based retrieval
(EBR) to improve the search relevance and diversity of search results. Our
system integrates semantic retrieval into the existing keyword search pipeline,
enabling users to discover more contextually relevant group posts. To
rigorously assess the impact of this blended approach, we introduce a novel
evaluation framework that leverages large language models (LLMs) to perform
offline relevance assessments, providing scalable and consistent quality
benchmarks. Our results demonstrate that the blended retrieval system
significantly enhances user engagement and search quality, as validated by both
online metrics and LLM-based evaluation. This work offers practical insights
for deploying and evaluating advanced retrieval systems in large-scale,
real-world social platforms.

---

### 3. Improving Context Fidelity via Native Retrieval-Augmented Reasoning

- **LLM Score**: 8
- **Keyword Score**: 3
- **Authors**: Suyuchen Wang, Jinlin Wang, Xinyu Wang, Shiqi Li, Xiangru Tang, Sirui Hong, Xiao-Wen Chang, Chenglin Wu, Bang Liu
- **URL**: <http://arxiv.org/abs/2509.13683v1>
- **Submitted**: 2025-09-17 04:28:07
- **Comment**: Accepted as a main conference paper at EMNLP 2025
- **Topic Keywords**: retrieval, search
- **Reason**: This paper explores the intersection of query understanding and ranking models, specifically in the context of large language models (LLMs). The proposed CARE framework aims to improve context fidelity and answer generation performance, which is relevant to information retrieval and NLP. While the focus is on QA benchmarks, the underlying concepts and techniques are applicable to broader search technologies.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Contextual Fidelity in Large Language Models for Question Answering
- **Aim**: To develop a novel framework, CARE, that enhances the context fidelity of LLMs in question-answering (QA) tasks by integrating native retrieval directly into the reasoning process.
- **Rationale**: Existing solutions for addressing context hallucination in LLMs rely on external retrieval mechanisms or supervised fine-tuning with large datasets, which are resource-intensive and may not fully leverage the model's language understanding capabilities.
- **Ground**: The research leverages a two-phase training approach: supervised fine-tuning on a dataset of reasoning chains with golden in-context retrieval snippets, followed by reinforcement learning to refine the self-retrieval mechanism.
- **Experiment**: Extensive experiments on various QA benchmarks, including LongBench datasets and the CofCA benchmark, demonstrate CARE's superiority over existing methods.
- **Takeaway**: CARE significantly outperforms baseline models in multi-hop QA tasks and surpasses traditional online search methods in context fidelity. Its success stems from native integration of in-context evidence during reasoning, curriculum learning, and effective evidence retrieval.

#### Abstract
> Large language models (LLMs) often struggle with context fidelity, producing
inconsistent answers when responding to questions based on provided
information. Existing approaches either rely on expensive supervised
fine-tuning to generate evidence post-answer or train models to perform web
searches without necessarily improving utilization of the given context. We
propose CARE, a novel native retrieval-augmented reasoning framework that
teaches LLMs to explicitly integrate in-context evidence within their reasoning
process with the model's own retrieval capabilities. Our method requires
limited labeled evidence data while significantly enhancing both retrieval
accuracy and answer generation performance through strategically retrieved
in-context tokens in the reasoning chain. Extensive experiments on multiple
real-world and counterfactual QA benchmarks demonstrate that our approach
substantially outperforms supervised fine-tuning, traditional
retrieval-augmented generation methods, and external retrieval solutions. This
work represents a fundamental advancement in making LLMs more accurate,
reliable, and efficient for knowledge-intensive tasks.

---

### 4. Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval

- **LLM Score**: 7
- **Keyword Score**: 17
- **Authors**: Amanda Chan, James Jiayu Liu, He Kai, Onno P. Kampman
- **URL**: <http://arxiv.org/abs/2509.13626v1>
- **Submitted**: 2025-09-17 01:54:11
- **Comment**: 25 pages, 3 figures, submitted to NeurIPS 2025 GenAI4Health
- **Topic Keywords**: query, ranking, rerank, relevance, rag, retrieval, rank
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of query understanding and relevance optimization. Although it focuses on mental health retrieval and knowledge base augmentation, the proposed framework and evaluation metrics are relevant to your work in search technologies and ranking models. However, the specific domain and application area are not directly aligned with your core research themes.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Mental health support for students using Retrieval Augmented Generation (RAG) systems
- **Aim**: To improve the effectiveness of RAG systems in addressing mental health concerns by addressing the challenge of aligning knowledge bases with user needs.
- **Rationale**: Existing knowledge bases may not comprehensively cover mental health topics or understand nuanced user language, leading to inadequate support.
- **Ground**: Naturalistic user data from a mental health platform (mindline.sg) and a library of mental health resources.
- **Experiment**: A gap-informed corpus augmentation framework was developed and evaluated using four different RAG pipelines (Baseline, Hierarchical, Reranking, and Query Transformation) compared to a Non-Directed augmentation method.
- **Takeaway**: Gap-informed corpus augmentation significantly improves RAG performance in mental health, particularly with fewer resources.  Expert-written content is crucial for reliability and safety. Future work should focus on incorporating expert evaluation and standardized evaluation methods for RAG in clinical settings.

#### Abstract
> Access to reliable mental health information is vital for early help-seeking,
yet expanding knowledge bases is resource-intensive and often misaligned with
user needs. This results in poor performance of retrieval systems when
presented concerns are not covered or expressed in informal or contextualized
language. We present an AI-based gap-informed framework for corpus augmentation
that authentically identifies underrepresented topics (gaps) by overlaying
naturalistic user data such as forum posts in order to prioritize expansions
based on coverage and usefulness. In a case study, we compare Directed
(gap-informed augmentations) with Non-Directed augmentation (random additions),
evaluating the relevance and usefulness of retrieved information across four
retrieval-augmented generation (RAG) pipelines. Directed augmentation achieved
near-optimal performance with modest expansions--requiring only a 42% increase
for Query Transformation, 74% for Reranking and Hierarchical, and 318% for
Baseline--to reach ~95% of the performance of an exhaustive reference corpus.
In contrast, Non-Directed augmentation required substantially larger and thus
practically infeasible expansions to achieve comparable performance (232%,
318%, 403%, and 763%, respectively). These results show that strategically
targeted corpus growth can reduce content creation demands while sustaining
high retrieval and provision quality, offering a scalable approach for building
trusted health information repositories and supporting generative AI
applications in high-stakes domains.

---

### 5. Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG

- **LLM Score**: 6
- **Keyword Score**: 10
- **Authors**: Dayeon Ki, Marine Carpuat, Paul McNamee, Daniel Khashabi, Eugene Yang, Dawn Lawrie, Kevin Duh
- **URL**: <http://arxiv.org/abs/2509.13930v1>
- **Submitted**: 2025-09-17 12:58:18
- **Comment**: 33 pages, 20 figures
- **Topic Keywords**: queries, relevance, rag, retrieval
- **Reason**: This paper explores the impact of language preference on citation behavior in multilingual Retrieval-Augmented Generation (RAG) systems, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on language preference and citation behavior is not directly aligned with the user's primary research themes. The paper's findings on language models' behavior may have implications for user behavior modeling, but the connection is not immediately clear.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Language Biases in Multilingual Retrieval-Augmented Generation (mRAG) Systems
- **Aim**: To investigate potential language biases in mRAG systems by examining model internals and citation choices across different languages.
- **Rationale**: Understanding how mRAG systems process multilingual context and potential biases in citation behavior is crucial for ensuring fairness and accuracy in information retrieval.
- **Ground**: Eight languages and six open-weight mRAG models.
- **Experiment**: Controlled methodology examining model internals and citation choices while keeping document relevance constant.
- **Takeaway**: mRAG systems exhibit a preference for English sources, particularly for queries in lower-resource languages, raising concerns about potential biases in citation behavior and the need for mitigation strategies.

#### Abstract
> Multilingual Retrieval-Augmented Generation (mRAG) systems enable language
models to answer knowledge-intensive queries with citation-supported responses
across languages. While such systems have been proposed, an open questions is
whether the mixture of different document languages impacts generation and
citation in unintended ways. To investigate, we introduce a controlled
methodology using model internals to measure language preference while holding
other factors such as document relevance constant. Across eight languages and
six open-weight models, we find that models preferentially cite English sources
when queries are in English, with this bias amplified for lower-resource
languages and for documents positioned mid-context. Crucially, we find that
models sometimes trade-off document relevance for language preference,
indicating that citation choices are not always driven by informativeness
alone. Our findings shed light on how language models leverage multilingual
context and influence citation behavior.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Who Taught the Lie? Responsibility Attribution for Poisoned Knowledge in Retrieval-Augmented Generation

- **LLM Score**: 4
- **Keyword Score**: 11
- **Authors**: Baolei Zhang, Haoran Xin, Yuxi Chen, Zhuqing Liu, Biao Yi, Tong Li, Lihai Nie, Zheli Liu, Minghong Fang
- **URL**: <http://arxiv.org/abs/2509.13772v1>
- **Submitted**: 2025-09-17 07:38:54
- **Comment**: To appear in the IEEE Symposium on Security and Privacy, 2026
- **Topic Keywords**: ranking, relevance, rag, retrieval, rank
- **Reason**: This paper is somewhat related to information retrieval, but its focus on Retrieval-Augmented Generation (RAG) and responsibility attribution for poisoned knowledge is not directly aligned with the user's core research themes of query understanding, ranking models, and user behavior modeling. While it touches on semantic relevance, the context is specific to RAG systems and not a central match for the user's interests.

#### Abstract
> Retrieval-Augmented Generation (RAG) integrates external knowledge into large
language models to improve response quality. However, recent work has shown
that RAG systems are highly vulnerable to poisoning attacks, where malicious
texts are inserted into the knowledge database to influence model outputs.
While several defenses have been proposed, they are often circumvented by more
adaptive or sophisticated attacks.
  This paper presents RAGOrigin, a black-box responsibility attribution
framework designed to identify which texts in the knowledge database are
responsible for misleading or incorrect generations. Our method constructs a
focused attribution scope tailored to each misgeneration event and assigns a
responsibility score to each candidate text by evaluating its retrieval
ranking, semantic relevance, and influence on the generated response. The
system then isolates poisoned texts using an unsupervised clustering method. We
evaluate RAGOrigin across seven datasets and fifteen poisoning attacks,
including newly developed adaptive poisoning strategies and multi-attacker
scenarios. Our approach outperforms existing baselines in identifying poisoned
content and remains robust under dynamic and noisy conditions. These results
suggest that RAGOrigin provides a practical and effective solution for tracing
the origins of corrupted knowledge in RAG systems.

### 7. Enhancing Time Awareness in Generative Recommendation

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Sunkyung Lee, Seongmin Park, Jonghyo Kim, Mincheol Yoon, Jongwuk Lee
- **URL**: <http://arxiv.org/abs/2509.13957v1>
- **Submitted**: 2025-09-17 13:28:46
- **Comment**: EMNLP 2025 (Findings)
- **Topic Keywords**: ranking, recommend, rank
- **Reason**: The paper discusses a novel model for generative recommendation, focusing on temporal dynamics and user preferences. While it touches on aspects of information retrieval, such as ranking and user behavior modeling, its primary focus is on recommender systems, which is a secondary interest of yours. The paper's emphasis on deep semantic understanding and real-time relevance optimization is not a central theme.

#### Abstract
> Generative recommendation has emerged as a promising paradigm that formulates
the recommendations into a text-to-text generation task, harnessing the vast
knowledge of large language models. However, existing studies focus on
considering the sequential order of items and neglect to handle the temporal
dynamics across items, which can imply evolving user preferences. To address
this limitation, we propose a novel model, Generative Recommender Using Time
awareness (GRUT), effectively capturing hidden user preferences via various
temporal signals. We first introduce Time-aware Prompting, consisting of two
key contexts. The user-level temporal context models personalized temporal
patterns across timestamps and time intervals, while the item-level transition
context provides transition patterns across users. We also devise Trend-aware
Inference, a training-free method that enhances rankings by incorporating trend
information about items with generation likelihood. Extensive experiments
demonstrate that GRUT outperforms state-of-the-art models, with gains of up to
15.4% and 14.3% in Recall@5 and NDCG@5 across four benchmark datasets. The
source code is available at https://github.com/skleee/GRUT.

### 8. MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Zhipeng Bian, Jieming Zhu, Xuyang Xie, Quanyu Dai, Zhou Zhao, Zhenhua Dong
- **URL**: <http://arxiv.org/abs/2509.13773v1>
- **Submitted**: 2025-09-17 07:43:14
- **Comment**: Published in Proceedings of the 63rd Annual Meeting of the
  Association for Computational Linguistics (Volume 6: Industry Track), ACL
  2025. Official version: https://doi.org/10.18653/v1/2025.acl-industry.103
- **Topic Keywords**: rag, recommend
- **Reason**: The paper MIRA introduces a framework for task instruction recommendation on smartphones, leveraging multimodal large language models for contextually relevant suggestions. While it touches on aspects of query understanding and user behavior modeling, its primary focus is on AI service integration and instruction recommendation, which is somewhat related to information retrieval but not a central match for your research interests.

#### Abstract
> The rapid advancement of generative AI technologies is driving the
integration of diverse AI-powered services into smartphones, transforming how
users interact with their devices. To simplify access to predefined AI
services, this paper introduces MIRA, a pioneering framework for task
instruction recommendation that enables intuitive one-touch AI tasking on
smartphones. With MIRA, users can long-press on images or text objects to
receive contextually relevant instruction recommendations for executing AI
tasks. Our work introduces three key innovations: 1) A multimodal large
language model (MLLM)-based recommendation pipeline with structured reasoning
to extract key entities, infer user intent, and generate precise instructions;
2) A template-augmented reasoning mechanism that integrates high-level
reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based
constrained decoding strategy that restricts outputs to predefined instruction
candidates, ensuring coherent and intent-aligned suggestions. Through
evaluation using a real-world annotated datasets and a user study, MIRA has
demonstrated substantial improvements in the accuracy of instruction
recommendation. The encouraging results highlight MIRA's potential to
revolutionize the way users engage with AI services on their smartphones,
offering a more seamless and efficient experience.

### 9. Combining Evidence and Reasoning for Biomedical Fact-Checking

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Mariano Barone, Antonio Romano, Giuseppe Riccio, Marco Postiglione, Vincenzo Moscato
- **URL**: <http://arxiv.org/abs/2509.13879v1>
- **Submitted**: 2025-09-17 10:14:56
- **Comment**: Proceedings of the 48th International ACM SIGIR Conference on
  Research and Development in Information Retrieval, 2025
- **Topic Keywords**: retrieval
- **Reason**: The paper focuses on biomedical fact-checking, which is a specific application of information retrieval and natural language processing. While it involves query understanding and ranking models, the context is distinct from the user's primary research interests in e-commerce and deep semantic understanding. The paper's emphasis on scientific evidence retrieval and veracity prediction is somewhat related to the user's interests in user behavior modeling and click models, but the connection is not direct.

#### Abstract
> Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https: //github.com/PRAISELab-PicusLab/CER.

### 10. Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: John Mendon√ßa, Lining Zhang, Rahul Mallidi, Alon Lavie, Isabel Trancoso, Luis Fernando D'Haro, Jo√£o Sedoc
- **URL**: <http://arxiv.org/abs/2509.13569v1>
- **Submitted**: 2025-09-16 22:13:45
- **Comment**: DSTC12 Track 1 Overview Paper. https://chateval.org/dstc12
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, as it involves dialogue system evaluation and Large Language Models. However, the focus on dialogue systems and safety considerations is not directly aligned with the user's primary research themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> The rapid advancement of Large Language Models (LLMs) has intensified the
need for robust dialogue system evaluation, yet comprehensive assessment
remains challenging. Traditional metrics often prove insufficient, and safety
considerations are frequently narrowly defined or culturally biased. The DSTC12
Track 1, "Dialog System Evaluation: Dimensionality, Language, Culture and
Safety," is part of the ongoing effort to address these critical gaps. The
track comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic
Evaluation Metrics, and (2) Multilingual and Multicultural Safety Detection.
For Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved
the highest average Spearman's correlation (0.1681), indicating substantial
room for improvement. In Task 2, while participating teams significantly
outperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top
ROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126
ROC-AUC), highlighting critical needs in culturally-aware safety. This paper
describes the datasets and baselines provided to participants, as well as
submission evaluation results for each of the two proposed subtasks.

### 11. AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Xinxu Zhou, Jiaqi Bai, Zhenqi Sun, Fanxiang Zeng, Yue Liu
- **URL**: <http://arxiv.org/abs/2509.13677v1>
- **Submitted**: 2025-09-17 04:07:22
- **Topic Keywords**: personalization
- **Reason**: The paper focuses on Controlled Text Generation (CTG) in Natural Language Processing (NLP), which is somewhat related to the user's interests in NLP and deep semantic understanding. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user.

#### Abstract
> Although significant progress has been made in many tasks within the field of
Natural Language Processing (NLP), Controlled Text Generation (CTG) continues
to face numerous challenges, particularly in achieving fine-grained conditional
control over generation. Additionally, in real scenario and online
applications, cost considerations, scalability, domain knowledge learning and
more precise control are required, presenting more challenge for CTG. This
paper introduces a novel and scalable framework, AgentCTG, which aims to
enhance precise and complex control over the text generation by simulating the
control and regulation mechanisms in multi-agent workflows. We explore various
collaboration methods among different agents and introduce an auto-prompt
module to further enhance the generation effectiveness. AgentCTG achieves
state-of-the-art results on multiple public datasets. To validate its
effectiveness in practical applications, we propose a new challenging
Character-Driven Rewriting task, which aims to convert the original text into
new text that conform to specific character profiles and simultaneously
preserve the domain knowledge. When applied to online navigation with
role-playing, our approach significantly enhances the driving experience
through improved content delivery. By optimizing the generation of contextually
relevant text, we enable a more immersive interaction within online
communities, fostering greater personalization and user engagement.

### 12. Sequential Data Augmentation for Generative Recommendation

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Geon Lee, Bhuvesh Kumar, Clark Mingxuan Ju, Tong Zhao, Kijung Shin, Neil Shah, Liam Collins
- **URL**: <http://arxiv.org/abs/2509.13648v1>
- **Submitted**: 2025-09-17 02:53:25
- **Topic Keywords**: recommend
- **Reason**: The paper focuses on generative recommendation and data augmentation, which is somewhat related to information retrieval and search technologies. However, the emphasis on recommendation systems and data efficiency is not a central match to the user's primary research interests in IR and NLP, especially in areas requiring deep semantic understanding and real-time relevance optimization.

#### Abstract
> Generative recommendation plays a crucial role in personalized systems,
predicting users' future interactions from their historical behavior sequences.
A critical yet underexplored factor in training these models is data
augmentation, the process of constructing training data from user interaction
histories. By shaping the training distribution, data augmentation directly and
often substantially affects model generalization and performance. Nevertheless,
in much of the existing work, this process is simplified, applied
inconsistently, or treated as a minor design choice, without a systematic and
principled understanding of its effects.
  Motivated by our empirical finding that different augmentation strategies can
yield large performance disparities, we conduct an in-depth analysis of how
they reshape training distributions and influence alignment with future targets
and generalization to unseen inputs. To systematize this design space, we
propose GenPAS, a generalized and principled framework that models augmentation
as a stochastic sampling process over input-target pairs with three
bias-controlled steps: sequence sampling, target sampling, and input sampling.
This formulation unifies widely used strategies as special cases and enables
flexible control of the resulting training distribution. Our extensive
experiments on benchmark and industrial datasets demonstrate that GenPAS yields
superior accuracy, data efficiency, and parameter efficiency compared to
existing strategies, providing practical guidance for principled training data
construction in generative recommendation.

### 13. Apertus: Democratizing Open and Compliant LLMs for Global Language Environments

- **LLM Score**: 3
- **Keyword Score**: 2
- **Authors**: Alejandro Hern√°ndez-Cano, Alexander H√§gele, Allen Hao Huang, Angelika Romanou, Antoni-Joan Solergibert, Barna Pasztor, Bettina Messmer, Dhia Garbaya, Eduard Frank ƒéurech, Ido Hakimi, Juan Garc√≠a Giraldo, Mete Ismayilzada, Negar Foroutan, Skander Moalla, Tiancheng Chen, Vinko Sabolƒçec, Yixuan Xu, Michael Aerni, Badr AlKhamissi, Ines Altemir Marinas, Mohammad Hossein Amani, Matin Ansaripour, Ilia Badanin, Harold Benoit, Emanuela Boros, Nicholas Browning, Fabian B√∂sch, Maximilian B√∂ther, Niklas Canova, Camille Challier, Clement Charmillot, Jonathan Coles, Jan Deriu, Arnout Devos, Lukas Drescher, Daniil Dzenhaliou, Maud Ehrmann, Dongyang Fan, Simin Fan, Silin Gao, Miguel Gila, Mar√≠a Grandury, Diba Hashemi, Alexander Hoyle, Jiaming Jiang, Mark Klein, Andrei Kucharavy, Anastasiia Kucherenko, Frederike L√ºbeck, Roman Machacek, Theofilos Manitaras, Andreas Marfurt, Kyle Matoba, Simon Matrenok, Henrique Mendonc√ßa, Fawzi Roberto Mohamed, Syrielle Montariol, Luca Mouchel, Sven Najem-Meyer, Jingwei Ni, Gennaro Oliva, Matteo Pagliardini, Elia Palme, Andrei Panferov, L√©o Paoletti, Marco Passerini, Ivan Pavlov, Auguste Poiroux, Kaustubh Ponkshe, Nathan Ranchin, Javi Rando, Mathieu Sauser, Jakhongir Saydaliev, Muhammad Ali Sayfiddinov, Marian Schneider, Stefano Schuppli, Marco Scialanga, Andrei Semenov, Kumar Shridhar, Raghav Singhal, Anna Sotnikova, Alexander Sternfeld, Ayush Kumar Tarun, Paul Teiletche, Jannis Vamvas, Xiaozhe Yao, Hao Zhao Alexander Ilic, Ana Klimovic, Andreas Krause, Caglar Gulcehre, David Rosenthal, Elliott Ash, Florian Tram√®r, Joost VandeVondele, Livio Veraldi, Martin Rajman, Thomas Schulthess, Torsten Hoefler, Antoine Bosselut, Martin Jaggi, Imanol Schlag
- **URL**: <http://arxiv.org/abs/2509.14233v1>
- **Submitted**: 2025-09-17 17:59:21
- **Topic Keywords**: rag
- **Reason**: This paper is loosely relevant to your research interests in Natural Language Processing (NLP) and large language models, but it does not directly address your core focus on Information Retrieval (IR), query understanding, or ranking models. The paper's emphasis on open and compliant LLMs for global language environments is somewhat tangential to your interests in e-commerce and real-time relevance optimization.

#### Abstract
> We present Apertus, a fully open suite of large language models (LLMs)
designed to address two systemic shortcomings in today's open model ecosystem:
data compliance and multilingual representation. Unlike many prior models that
release weights without reproducible data pipelines or regard for content-owner
rights, Apertus models are pretrained exclusively on openly available data,
retroactively respecting robots.txt exclusions and filtering for
non-permissive, toxic, and personally identifiable content. To mitigate risks
of memorization, we adopt the Goldfish objective during pretraining, strongly
suppressing verbatim recall of data while retaining downstream task
performance. The Apertus models also expand multilingual coverage, training on
15T tokens from over 1800 languages, with ~40% of pretraining data allocated to
non-English content. Released at 8B and 70B scales, Apertus approaches
state-of-the-art results among fully open models on multilingual benchmarks,
rivalling or surpassing open-weight counterparts. Beyond model weights, we
release all scientific artifacts from our development cycle with a permissive
license, including data preparation scripts, checkpoints, evaluation suites,
and training code, enabling transparent audit and extension.

### 14. Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification

- **LLM Score**: 3
- **Keyword Score**: 2
- **Authors**: Mariano Barone, Antonio Romano, Giuseppe Riccio, Marco Postiglione, Vincenzo Moscato
- **URL**: <http://arxiv.org/abs/2509.13888v1>
- **Submitted**: 2025-09-17 10:31:09
- **Topic Keywords**: retrieval
- **Reason**: The paper focuses on combating biomedical misinformation through multi-modal claim detection and evidence-based verification. While it involves natural language processing and large language models, its primary focus is on biomedical fact-checking, which is somewhat related to the user's interests in information retrieval and NLP, but not directly aligned with their core research themes.

#### Abstract
> Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https://github.com/PRAISELab-PicusLab/CER

### 15. Measuring Gender Bias in Job Title Matching for Grammatical Gender Languages

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Laura Garc√≠a-Sardi√±a, Hermenegildo Fabregat, Daniel Deniz, Rabih Zbib
- **URL**: <http://arxiv.org/abs/2509.13803v1>
- **Submitted**: 2025-09-17 08:17:28
- **Topic Keywords**: ranking, relevance, rank
- **Reason**: This paper focuses on measuring gender bias in job title matching for grammatical gender languages, which is not directly related to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves ranking systems, it's more focused on bias detection rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> This work sets the ground for studying how explicit grammatical gender
assignment in job titles can affect the results of automatic job ranking
systems. We propose the usage of metrics for ranking comparison controlling for
gender to evaluate gender bias in job title ranking systems, in particular RBO
(Rank-Biased Overlap). We generate and share test sets for a job title matching
task in four grammatical gender languages, including occupations in masculine
and feminine form and annotated by gender and matching relevance. We use the
new test sets and the proposed methodology to evaluate the gender bias of
several out-of-the-box multilingual models to set as baselines, showing that
all of them exhibit varying degrees of gender bias.

### 16. GEM-Bench: A Benchmark for Ad-Injected Response Generation within Generative Engine Marketing

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Silan Hu, Shiqi Zhang, Yimin Shi, Xiaokui Xiao
- **URL**: <http://arxiv.org/abs/2509.14221v1>
- **Submitted**: 2025-09-17 17:53:43
- **Topic Keywords**: click, click-through rate, search
- **Reason**: This paper is not directly related to your core research themes in Information Retrieval and Search technologies, as it focuses on Generative Engine Marketing and ad-injected response generation. While it involves some aspects of user behavior modeling, it is primarily concerned with a specific application of AI, rather than the underlying IR and NLP concepts.

#### Abstract
> Generative Engine Marketing (GEM) is an emerging ecosystem for monetizing
generative engines, such as LLM-based chatbots, by seamlessly integrating
relevant advertisements into their responses. At the core of GEM lies the
generation and evaluation of ad-injected responses. However, existing
benchmarks are not specifically designed for this purpose, which limits future
research. To address this gap, we propose GEM-Bench, the first comprehensive
benchmark for ad-injected response generation in GEM. GEM-Bench includes three
curated datasets covering both chatbot and search scenarios, a metric ontology
that captures multiple dimensions of user satisfaction and engagement, and
several baseline solutions implemented within an extensible multi-agent
framework. Our preliminary results indicate that, while simple prompt-based
methods achieve reasonable engagement such as click-through rate, they often
reduce user satisfaction. In contrast, approaches that insert ads based on
pre-generated ad-free responses help mitigate this issue but introduce
additional overhead. These findings highlight the need for future research on
designing more effective and efficient solutions for generating ad-injected
responses in GEM.

### 17. Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Sami Ul Haq, Sheila Castilho, Yvette Graham
- **URL**: <http://arxiv.org/abs/2509.14023v1>
- **Submitted**: 2025-09-17 14:27:17
- **Comment**: Accepted at WMT2025 (ENNLP) for oral presented
- **Topic Keywords**: ranking, rank
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves machine translation, a related topic, the focus on audio-based evaluation and crowd-sourced judgments is not central to your areas of expertise.

#### Abstract
> Machine Translation (MT) has achieved remarkable performance, with growing
interest in speech translation and multimodal approaches. However, despite
these advancements, MT quality assessment remains largely text centric,
typically relying on human experts who read and compare texts. Since many
real-world MT applications (e.g Google Translate Voice Mode, iFLYTEK
Translator) involve translation being spoken rather printed or read, a more
natural way to assess translation quality would be through speech as opposed
text-only evaluations. This study compares text-only and audio-based
evaluations of 10 MT systems from the WMT General MT Shared Task, using
crowd-sourced judgments collected via Amazon Mechanical Turk. We additionally,
performed statistical significance testing and self-replication experiments to
test reliability and consistency of audio-based approach. Crowd-sourced
assessments based on audio yield rankings largely consistent with text only
evaluations but, in some cases, identify significant differences between
translation systems. We attribute this to speech richer, more natural modality
and propose incorporating speech-based assessments into future MT evaluation
frameworks.

### 18. DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Xiao Zheng
- **URL**: <http://arxiv.org/abs/2509.13702v1>
- **Submitted**: 2025-09-17 05:09:22
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper focuses on Large Language Models and hallucination suppression, which is not directly related to your primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves NLP, the specific topic and application are not aligned with your core themes.

#### Abstract
> Large Language Model (LLM) hallucination is a significant barrier to their
reliable deployment. Current methods like Retrieval-Augmented Generation (RAG)
are often reactive. We introduce **Dynamic Self-reinforcing Calibration for
Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that
intervenes during autoregressive decoding. Inspired by dual-process cognitive
theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a
Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During
inference, these proxies dynamically steer a large target model by injecting a
real-time steering vector, which is the difference between FAP and HDP logits,
at each decoding step. This plug-and-play approach requires no modification to
the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS
achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%
Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained
the highest FActScore of 46.50. These results validate DSCC-HS as a principled
and efficient solution for enhancing LLM factuality.

### 19. Enhancing Multi-Agent Debate System Performance via Confidence Expression

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Zijie Lin, Bryan Hooi
- **URL**: <http://arxiv.org/abs/2509.14034v1>
- **Submitted**: 2025-09-17 14:34:27
- **Comment**: EMNLP'25 Findings
- **Topic Keywords**: rag, search
- **Reason**: This paper is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves Large Language Models, the focus is on Multi-Agent Debate systems and confidence expression, which is not a central match to your research themes.

#### Abstract
> Generative Large Language Models (LLMs) have demonstrated remarkable
performance across a wide range of tasks. Recent research has introduced
Multi-Agent Debate (MAD) systems, which leverage multiple LLMs to simulate
human debate and thereby improve task performance. However, while some LLMs may
possess superior knowledge or reasoning capabilities for specific tasks, they
often struggle to clearly communicate this advantage during debates, in part
due to a lack of confidence expression. Moreover, inappropriate confidence
expression can cause agents in MAD systems to either stubbornly maintain
incorrect beliefs or converge prematurely on suboptimal answers, ultimately
reducing debate effectiveness and overall system performance. To address these
challenges, we propose incorporating confidence expression into MAD systems to
allow LLMs to explicitly communicate their confidence levels. To validate this
approach, we develop ConfMAD, a MAD framework that integrates confidence
expression throughout the debate process. Experimental results demonstrate the
effectiveness of our method, and we further analyze how confidence influences
debate dynamics, offering insights into the design of confidence-aware MAD
systems.

### 20. A Simple and Efficient Jailbreak Method Exploiting LLMs' Helpfulness

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Xuan Luo, Yue Wang, Zefeng He, Geng Tu, Jing Li, Ruifeng Xu
- **URL**: <http://arxiv.org/abs/2509.14297v1>
- **Submitted**: 2025-09-17 04:21:20
- **Topic Keywords**: queries
- **Reason**: This paper is not relevant to your research interests as it focuses on Large Language Models (LLMs) and safety alignment, which is outside your primary areas of interest in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on 'jailbreak methods' and 'safety protections' does not align with your research themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> Safety alignment aims to prevent Large Language Models (LLMs) from responding
to harmful queries. To strengthen safety protections, jailbreak methods are
developed to simulate malicious attacks and uncover vulnerabilities. In this
paper, we introduce HILL (Hiding Intention by Learning from LLMs), a novel
jailbreak approach that systematically transforms imperative harmful requests
into learning-style questions with only straightforward hypotheticality
indicators. Further, we introduce two new metrics to thoroughly evaluate the
utility of jailbreak methods. Experiments on the AdvBench dataset across a wide
range of models demonstrate HILL's strong effectiveness, generalizability, and
harmfulness. It achieves top attack success rates on the majority of models and
across malicious categories while maintaining high efficiency with concise
prompts. Results of various defense methods show the robustness of HILL, with
most defenses having mediocre effects or even increasing the attack success
rates. Moreover, the assessment on our constructed safe prompts reveals
inherent limitations of LLMs' safety mechanisms and flaws in defense methods.
This work exposes significant vulnerabilities of safety measures against
learning-style elicitation, highlighting a critical challenge of balancing
helpfulness and safety alignments.

### 21. Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Andrea Piergentili, Beatrice Savoldi, Matteo Negri, Luisa Bentivogli
- **URL**: <http://arxiv.org/abs/2509.13480v1>
- **Submitted**: 2025-09-16 19:25:13
- **Comment**: Accepted at CLiC-it 2025
- **Topic Keywords**: relevance
- **Reason**: This paper focuses on gender-neutral rewriting in Italian using large language models, which is a topic in Natural Language Processing (NLP). However, it does not align with the user's primary research interests in Information Retrieval (IR), query understanding, ranking models, and user behavior modeling.

#### Abstract
> Gender-neutral rewriting (GNR) aims to reformulate text to eliminate
unnecessary gender specifications while preserving meaning, a particularly
challenging task in grammatical-gender languages like Italian. In this work, we
conduct the first systematic evaluation of state-of-the-art large language
models (LLMs) for Italian GNR, introducing a two-dimensional framework that
measures both neutrality and semantic fidelity to the input. We compare
few-shot prompting across multiple LLMs, fine-tune selected models, and apply
targeted cleaning to boost task relevance. Our findings show that open-weight
LLMs outperform the only existing model dedicated to GNR in Italian, whereas
our fine-tuned models match or exceed the best open-weight LLM's performance at
a fraction of its size. Finally, we discuss the trade-off between optimizing
the training data for neutrality and meaning preservation.

### 22. Language models' activations linearly encode training-order recency

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Dmitrii Krasheninnikov, Richard E. Turner, David Krueger
- **URL**: <http://arxiv.org/abs/2509.14223v1>
- **Submitted**: 2025-09-17 17:54:22
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language models, the focus is on understanding how models encode training-order recency, which is not a central theme in your research.

#### Abstract
> We show that language models' activations linearly encode when information
was learned during training. Our setup involves creating a model with a known
training order by sequentially fine-tuning Llama-3.2-1B on six disjoint but
otherwise similar datasets about named entities. We find that the average
activations of test samples for the six training datasets encode the training
order: when projected into a 2D subspace, these centroids are arranged exactly
in the order of training and lie on a straight line. Further, we show that
linear probes can accurately (~90%) distinguish "early" vs. "late" entities,
generalizing to entities unseen during the probes' own training. The model can
also be fine-tuned to explicitly report an unseen entity's training stage (~80%
accuracy). Interestingly, this temporal signal does not seem attributable to
simple differences in activation magnitudes, losses, or model confidence. Our
paper demonstrates that models are capable of differentiating information by
its acquisition time, and carries significant implications for how they might
manage conflicting data and respond to knowledge modifications.

### 23. Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Kerui Huang, Shuhan Liu, Xing Hu, Tongtong Xu, Lingfeng Bao, Xin Xia
- **URL**: <http://arxiv.org/abs/2509.14093v1>
- **Submitted**: 2025-09-17 15:33:44
- **Topic Keywords**: rag
- **Reason**: This paper focuses on optimizing Chain-of-Thought reasoning in Large Language Models for software engineering tasks, which is not directly related to Information Retrieval or Search technologies. While it involves Natural Language Processing, the context and application are quite different from the user's core research interests.

#### Abstract
> Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by
prompting intermediate steps, improving accuracy and robustness in arithmetic,
logic, and commonsense tasks. However, this benefit comes with high
computational costs: longer outputs increase latency, memory usage, and
KV-cache demands. These issues are especially critical in software engineering
tasks where concise and deterministic outputs are required. To investigate
these trade-offs, we conduct an empirical study based on code generation
benchmarks. The results reveal that longer CoT does not always help. Excessive
reasoning often causes truncation, accuracy drops, and latency up to five times
higher, with failed outputs consistently longer than successful ones. These
findings challenge the assumption that longer reasoning is inherently better
and highlight the need for adaptive CoT control. Motivated by this, we propose
SEER (Self-Enhancing Efficient Reasoning), an adaptive framework that
compresses CoT while preserving accuracy. SEER combines Best-of-N sampling with
task-aware adaptive filtering, dynamically adjusting thresholds based on
pre-inference outputs to reduce verbosity and computational overhead. We then
evaluate SEER on three software engineering tasks and one math task. On
average, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation,
and eliminates most infinite loops. These results demonstrate SEER as a
practical method to make CoT-enhanced LLMs more efficient and robust, even
under resource constraints.

### 24. SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zekang Liu, Wei Feng, Fanhua Shang, Lianyu Hu, Jichao Feng, Liqing Gao
- **URL**: <http://arxiv.org/abs/2509.14036v1>
- **Submitted**: 2025-09-17 14:37:59
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests as it focuses on Sign Language Translation and Question-based Sign Language Translation, which is outside your primary areas of interest in Information Retrieval and Search technologies, and Natural Language Processing.

#### Abstract
> Sign Language Translation (SLT) bridges the communication gap between deaf
people and hearing people, where dialogue provides crucial contextual cues to
aid in translation. Building on this foundational concept, this paper proposes
Question-based Sign Language Translation (QB-SLT), a novel task that explores
the efficient integration of dialogue. Unlike gloss (sign language
transcription) annotations, dialogue naturally occurs in communication and is
easier to annotate. The key challenge lies in aligning multimodality features
while leveraging the context of the question to improve translation. To address
this issue, we propose a cross-modality Self-supervised Learning with Sigmoid
Self-attention Weighting (SSL-SSAW) fusion method for sign language
translation. Specifically, we employ contrastive learning to align
multimodality features in QB-SLT, then introduce a Sigmoid Self-attention
Weighting (SSAW) module for adaptive feature extraction from question and sign
language sequences. Additionally, we leverage available question text through
self-supervised learning to enhance representation and translation
capabilities. We evaluated our approach on newly constructed CSL-Daily-QA and
PHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,
easily accessible question assistance can achieve or even surpass the
performance of gloss assistance. Furthermore, visualization results demonstrate
the effectiveness of incorporating dialogue in improving translation quality.

### 25. You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Pawe≈Ç MƒÖka, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis
- **URL**: <http://arxiv.org/abs/2509.14031v1>
- **Submitted**: 2025-09-17 14:33:17
- **Comment**: EMNLP 2025 main conference
- **Topic Keywords**: rag
- **Reason**: This paper focuses on machine translation models, which is related to NLP, but it does not directly address information retrieval, query understanding, or ranking models, which are core areas of your research interests.

#### Abstract
> Achieving human-level translations requires leveraging context to ensure
coherence and handle complex phenomena like pronoun disambiguation. Sparsity of
contextually rich examples in the standard training data has been hypothesized
as the reason for the difficulty of context utilization. In this work, we
systematically validate this claim in both single- and multilingual settings by
constructing training datasets with a controlled proportions of contextually
relevant examples. We demonstrate a strong association between training data
sparsity and model performance confirming sparsity as a key bottleneck.
Importantly, we reveal that improvements in one contextual phenomenon do no
generalize to others. While we observe some cross-lingual transfer, it is not
significantly higher between languages within the same sub-family. Finally, we
propose and empirically evaluate two training strategies designed to leverage
the available data. These strategies improve context utilization, resulting in
accuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in
single- and multilingual settings respectively.

### 26. Early Stopping Chain-of-thoughts in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Minjia Mao, Bowen Yin, Yu Zhu, Xiao Fang
- **URL**: <http://arxiv.org/abs/2509.14004v1>
- **Submitted**: 2025-09-17 14:14:05
- **Topic Keywords**: rag
- **Reason**: This paper focuses on optimizing the inference process of large language models, which is not directly related to information retrieval or search technologies. While it involves natural language processing, the context is more geared towards efficient reasoning and inference, rather than query understanding or ranking models.

#### Abstract
> Reasoning large language models (LLMs) have demonstrated superior capacities
in solving complicated problems by generating long chain-of-thoughts (CoT), but
such a lengthy CoT incurs high inference costs. In this study, we introduce
ES-CoT, an inference-time method that shortens CoT generation by detecting
answer convergence and stopping early with minimal performance loss. At the end
of each reasoning step, we prompt the LLM to output its current final answer,
denoted as a step answer. We then track the run length of consecutive identical
step answers as a measure of answer convergence. Once the run length exhibits a
sharp increase and exceeds a minimum threshold, the generation is terminated.
We provide both empirical and theoretical support for this heuristic: step
answers steadily converge to the final answer, and large run-length jumps
reliably mark this convergence. Experiments on five reasoning datasets across
three LLMs show that ES-CoT reduces the number of inference tokens by about
41\% on average while maintaining accuracy comparable to standard CoT. Further,
ES-CoT integrates seamlessly with self-consistency prompting and remains robust
across hyperparameter choices, highlighting it as a practical and effective
approach for efficient reasoning.

### 27. Long-context Reference-based MT Quality Estimation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sami Ul Haq, Chinonso Cynthia Osuji, Sheila Castilho, Brian Davis
- **URL**: <http://arxiv.org/abs/2509.13980v1>
- **Submitted**: 2025-09-17 13:52:45
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Machine Translation Quality Estimation, which is not a core area of interest for you. While it involves some NLP aspects, it does not align with your primary focus on Information Retrieval, query understanding, ranking models, or user behavior modeling.

#### Abstract
> In this paper, we present our submission to the Tenth Conference on Machine
Translation (WMT25) Shared Task on Automated Translation Quality Evaluation.
  Our systems are built upon the COMET framework and trained to predict
segment-level Error Span Annotation (ESA) scores using augmented long-context
data.
  To construct long-context training data, we concatenate in-domain,
human-annotated sentences and compute a weighted average of their scores.
  We integrate multiple human judgment datasets (MQM, SQM, and DA) by
normalising their scales and train multilingual regression models to predict
quality scores from the source, hypothesis, and reference translations.
  Experimental results show that incorporating long-context information
improves correlations with human judgments compared to models trained only on
short segments.

### 28. THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Qikai Chang, Zhenrong Zhang, Pengfei Hu, Jiefeng Ma, Yicheng Pan, Jianshu Zhang, Jun Du, Quan Liu, Jianqing Gao
- **URL**: <http://arxiv.org/abs/2509.13761v1>
- **Submitted**: 2025-09-17 07:16:12
- **Comment**: 22 pages, 13 figures
- **Topic Keywords**: rag
- **Reason**: This paper focuses on mathematical reasoning and tool-integrated optimization via RL, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Large Language Models (LLMs) have made remarkable progress in mathematical
reasoning, but still continue to struggle with high-precision tasks like
numerical computation and formal symbolic manipulation. Integrating external
tools has emerged as a promising approach to bridge this gap. Despite recent
advances, existing methods struggle with three key challenges: constructing
tool-integrated reasoning data, performing fine-grained optimization, and
enhancing inference. To overcome these limitations, we propose THOR
(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,
a multi-agent actor-critic-based pipeline for constructing high-quality
datasets of tool-integrated reasoning paths, aligning with the policy and
generalizing well across diverse models. Second, to perform fine-grained
hierarchical optimization, we introduce an RL strategy that jointly optimizes
for both trajectory-level problem solving and step-level code generation. This
is motivated by our key insight that the success of an intermediate tool call
is a strong predictor of the final answer's correctness. Finally, THOR
incorporates a self-correction mechanism that leverages immediate tool feedback
to dynamically revise erroneous reasoning paths during inference. Our approach
demonstrates strong generalization across diverse models, performing
effectively in both reasoning and non-reasoning models. It further achieves
state-of-the-art performance for models of a similar scale on multiple
mathematical benchmarks, while also delivering consistent improvements on code
benchmarks. Our code will be publicly available at
https://github.com/JingMog/THOR.

### 29. Implementing a Logical Inference System for Japanese Comparatives

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yosuke Mikami, Daiki Matsuoka, Hitomi Yanaka
- **URL**: <http://arxiv.org/abs/2509.13734v1>
- **Submitted**: 2025-09-17 06:37:10
- **Comment**: In Proceedings of the 5th Workshop on Natural Logic Meets Machine
  Learning (NALOMA)
- **Topic Keywords**: rag
- **Reason**: This paper focuses on a specific task of Natural Language Inference involving comparatives in Japanese, using a logical inference system grounded in compositional semantics. While it touches on aspects of NLP, it does not directly relate to the user's core research themes in Information Retrieval, query understanding, ranking models, or user behavior modeling. The paper's focus on Japanese language and logical inference systems also limits its relevance to the user's broader interests in e-commerce and real-time relevance optimization.

#### Abstract
> Natural Language Inference (NLI) involving comparatives is challenging
because it requires understanding quantities and comparative relations
expressed by sentences. While some approaches leverage Large Language Models
(LLMs), we focus on logic-based approaches grounded in compositional semantics,
which are promising for robust handling of numerical and logical expressions.
Previous studies along these lines have proposed logical inference systems for
English comparatives. However, it has been pointed out that there are several
morphological and semantic differences between Japanese and English
comparatives. These differences make it difficult to apply such systems
directly to Japanese comparatives. To address this gap, this study proposes
ccg-jcomp, a logical inference system for Japanese comparatives based on
compositional semantics. We evaluate the proposed system on a Japanese NLI
dataset containing comparative expressions. We demonstrate the effectiveness of
our system by comparing its accuracy with that of existing LLMs.

### 30. Privacy-Aware In-Context Learning for Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Bishnu Bhusal, Manoj Acharya, Ramneet Kaur, Colin Samplawski, Anirban Roy, Adam D. Cobb, Rohit Chadha, Susmit Jha
- **URL**: <http://arxiv.org/abs/2509.13625v1>
- **Submitted**: 2025-09-17 01:50:32
- **Topic Keywords**: rag
- **Reason**: This paper focuses on privacy concerns in large language models, which is a topic in NLP, but it does not align with the user's primary research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large language models (LLMs) have significantly transformed natural language
understanding and generation, but they raise privacy concerns due to potential
exposure of sensitive information. Studies have highlighted the risk of
information leakage, where adversaries can extract sensitive information
embedded in the prompts. In this work, we introduce a novel private prediction
framework for generating high-quality synthetic text with strong privacy
guarantees. Our approach leverages the Differential Privacy (DP) framework to
ensure worst-case theoretical bounds on information leakage without requiring
any fine-tuning of the underlying models.The proposed method performs inference
on private records and aggregates the resulting per-token output distributions.
This enables the generation of longer and coherent synthetic text while
maintaining privacy guarantees. Additionally, we propose a simple blending
operation that combines private and public inference to further enhance
utility. Empirical evaluations demonstrate that our approach outperforms
previous state-of-the-art methods on in-context-learning (ICL) tasks, making it
a promising direction for privacy-preserving text generation while maintaining
high utility.

### 31. Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Nathalie Neptune, Josiane Mothe
- **URL**: <http://arxiv.org/abs/2509.13586v1>
- **Submitted**: 2025-09-16 23:00:16
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. Although it involves deep learning techniques, the application is in image analysis and change detection in satellite images, which is unrelated to your core research themes.

#### Abstract
> The Amazon rain forest is a vital ecosystem that plays a crucial role in
regulating the Earth's climate and providing habitat for countless species.
Deforestation in the Amazon is a major concern as it has a significant impact
on global carbon emissions and biodiversity. In this paper, we present a method
for detecting deforestation in the Amazon using image pairs from Earth
observation satellites. Our method leverages deep learning techniques to
compare the images of the same area at different dates and identify changes in
the forest cover. We also propose a visual semantic model that automatically
annotates the detected changes with relevant keywords. The candidate annotation
for images are extracted from scientific documents related to the Amazon
region. We evaluate our approach on a dataset of Amazon image pairs and
demonstrate its effectiveness in detecting deforestation and generating
relevant annotations. Our method provides a useful tool for monitoring and
studying the impact of deforestation in the Amazon. While we focus on
environment applications of our work by using images of deforestation in the
Amazon rain forest to demonstrate the effectiveness of our proposed approach,
it is generic enough to be applied to other domains.

### 32. Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Akhil Theerthala
- **URL**: <http://arxiv.org/abs/2509.14180v1>
- **Submitted**: 2025-09-17 17:12:38
- **Comment**: 24 pages, 11 figures. The paper presents a novel framework for
  generating a personal finance dataset. The resulting fine-tuned model and
  dataset are publicly available
- **Topic Keywords**: personalization
- **Reason**: This paper appears to be focused on developing a framework for personal finance LLMs, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves LLMs and NLP, the context and application are quite specific to personal finance and do not align with the user's broader interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Personalized financial advice requires consideration of user goals,
constraints, risk tolerance, and jurisdiction. Prior LLM work has focused on
support systems for investors and financial planners. Simultaneously, numerous
recent studies examine broader personal finance tasks, including budgeting,
debt management, retirement, and estate planning, through agentic pipelines
that incur high maintenance costs, yielding less than 25% of their expected
financial returns. In this study, we introduce a novel and reproducible
framework that integrates relevant financial context with behavioral finance
studies to construct supervision data for end-to-end advisors. Using this
framework, we create a 19k sample reasoning dataset and conduct a comprehensive
fine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test
split and a blind LLM-jury study, we demonstrate that through careful data
curation and behavioral integration, our 8B model achieves performance
comparable to significantly larger baselines (14-32B parameters) across factual
accuracy, fluency, and personalization metrics while incurring 80% lower costs
than the larger counterparts.

### 33. Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Hasan Abed Al Kader Hammoud, Mohammad Zbeeb, Bernard Ghanem
- **URL**: <http://arxiv.org/abs/2509.14008v1>
- **Submitted**: 2025-09-17 14:19:28
- **Comment**: Technical Report
- **Topic Keywords**: search
- **Reason**: This paper focuses on Arabic-centric instruction and translation models, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific domain and application are not aligned with the user's core themes.

#### Abstract
> We present Hala, a family of Arabic-centric instruction and translation
models built with our translate-and-tune pipeline. We first compress a strong
AR$\leftrightarrow$EN teacher to FP8 (yielding $\sim$2$\times$ higher
throughput with no quality loss) and use it to create high-fidelity bilingual
supervision. A lightweight language model LFM2-1.2B is then fine-tuned on this
data and used to translate high-quality English instruction sets into Arabic,
producing a million-scale corpus tailored to instruction following. We train
Hala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to
balance Arabic specialization with base-model strengths. On Arabic-centric
benchmarks, Hala achieves state-of-the-art results within both the "nano"
($\leq$2B) and "small" (7-9B) categories, outperforming their bases. We release
models, data, evaluation, and recipes to accelerate research in Arabic NLP.

### 34. Masked Diffusion Models as Energy Minimization

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Sitong Chen, Shen Nie, Jiacheng Sun, Zijin Feng, Zhenguo Li, Ji-Rong Wen, Chongxuan Li
- **URL**: <http://arxiv.org/abs/2509.13866v1>
- **Submitted**: 2025-09-17 09:57:31
- **Topic Keywords**: search
- **Reason**: This paper appears to be primarily focused on masked diffusion models in the context of energy minimization problems, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> We present a systematic theoretical framework that interprets masked
diffusion models (MDMs) as solutions to energy minimization problems in
discrete optimal transport. Specifically, we prove that three distinct energy
formulations--kinetic, conditional kinetic, and geodesic energy--are
mathematically equivalent under the structure of MDMs, and that MDMs minimize
all three when the mask schedule satisfies a closed-form optimality condition.
This unification not only clarifies the theoretical foundations of MDMs, but
also motivates practical improvements in sampling. By parameterizing
interpolation schedules via Beta distributions, we reduce the schedule design
space to a tractable 2D search, enabling efficient post-training tuning without
model modification. Experiments on synthetic and real-world benchmarks
demonstrate that our energy-inspired schedules outperform hand-crafted
baselines, particularly in low-step sampling settings.

### 35. Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Edward Phillips, Sean Wu, Soheila Molaei, Danielle Belgrave, Anshul Thakur, David Clifton
- **URL**: <http://arxiv.org/abs/2509.13813v1>
- **Submitted**: 2025-09-17 08:28:07
- **Topic Keywords**: rank
- **Reason**: This paper focuses on Large Language Models (LLMs) and hallucination detection, which is outside your primary research interests in Information Retrieval and Search technologies. While it involves Natural Language Processing, the specific application and methodology are not directly related to your core themes.

#### Abstract
> Large language models demonstrate impressive results across diverse tasks but
are still known to hallucinate, generating linguistically plausible but
incorrect answers to questions. Uncertainty quantification has been proposed as
a strategy for hallucination detection, but no existing black-box approach
provides estimates for both global and local uncertainty. The former attributes
uncertainty to a batch of responses, while the latter attributes uncertainty to
individual responses. Current local methods typically rely on white-box access
to internal model states, whilst black-box methods only provide global
uncertainty estimates. We introduce a geometric framework to address this,
based on archetypal analysis of batches of responses sampled with only
black-box model access. At the global level, we propose Geometric Volume, which
measures the convex hull volume of archetypes derived from response embeddings.
At the local level, we propose Geometric Suspicion, which ranks responses by
reliability and enables hallucination reduction through preferential response
selection. Unlike prior dispersion methods which yield only a single global
score, our approach provides semantic boundary points which have utility for
attributing reliability to individual responses. Experiments show that our
framework performs comparably to or better than prior methods on short form
question-answering datasets, and achieves superior results on medical datasets
where hallucinations carry particularly critical risks. We also provide
theoretical justification by proving a link between convex hull volume and
entropy.

### 36. CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Shang Qin, Jingheng Ye, Yinghui Li, Hai-Tao Zheng, Qi Li, Jinxiao Shan, Zhixing Li, Hong-Gee Kim
- **URL**: <http://arxiv.org/abs/2509.13672v1>
- **Submitted**: 2025-09-17 03:54:52
- **Topic Keywords**: search
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves language models and error correction, the focus is on grammatical error correction in Chinese literature, which is not a central theme in your research.

#### Abstract
> The growing demand for automated writing assistance in diverse academic
domains highlights the need for robust Chinese Grammatical Error Correction
(CGEC) systems that can adapt across disciplines. However, existing CGEC
research largely lacks dedicated benchmarks for multi-disciplinary academic
writing, overlooking continual learning (CL) as a promising solution to handle
domain-specific linguistic variation and prevent catastrophic forgetting. To
fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning
benchmark for Chinese Literature Grammatical Error Correction, designed to
evaluate adaptive CGEC across multiple academic fields. Our benchmark includes
10,000 human-annotated sentences spanning 10 disciplines, each exhibiting
distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating
grammatical error correction in a continual learning setting, simulating
sequential exposure to diverse academic disciplines to reflect real-world
editorial dynamics. We evaluate large language models under sequential tuning,
parameter-efficient adaptation, and four representative CL algorithms, using
both standard GEC metrics and continual learning metrics adapted to task-level
variation. Experimental results reveal that regularization-based methods
mitigate forgetting more effectively than replay-based or naive sequential
approaches. Our benchmark provides a rigorous foundation for future research in
adaptive grammatical error correction across diverse academic domains.

### 37. SteeringControl: Holistic Evaluation of Alignment Steering in LLMs

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Vincent Siu, Nicholas Crispino, David Park, Nathan W. Henry, Zhun Wang, Yang Liu, Dawn Song, Chenguang Wang
- **URL**: <http://arxiv.org/abs/2509.13450v1>
- **Submitted**: 2025-09-16 18:36:22
- **Topic Keywords**: search
- **Reason**: This paper focuses on representation steering in Large Language Models (LLMs), which is a topic in Natural Language Processing (NLP). While it touches on the concept of 'alignment' and 'steering', it doesn't directly relate to the user's core research interests in Information Retrieval (IR), query understanding, ranking models, or user behavior modeling.

#### Abstract
> We introduce SteeringControl, a benchmark for evaluating representation
steering methods across core alignment objectives--bias, harmful generation,
and hallucination--and their effects on secondary behaviors such as sycophancy
and commonsense morality. While prior alignment work often highlights
truthfulness or reasoning ability to demonstrate the side effects of
representation steering, we find there are many unexplored tradeoffs not yet
understood in a systematic way. We collect a dataset of safety-relevant primary
and secondary behaviors to evaluate steering effectiveness and behavioral
entanglement centered around five popular steering methods. To enable this, we
craft a modular steering framework based on unique components that serve as the
building blocks of many existing methods. Our results on Qwen-2.5-7B and
Llama-3.1-8B find that strong steering performance is dependent on the specific
combination of steering method, model, and targeted behavior, and that severe
concept entanglement can result from poor combinations of these three as well.
We release our code here:
https://github.com/wang-research-lab/SteeringControl.git.

### 38. CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset

- **LLM Score**: 0
- **Keyword Score**: 1
- **Authors**: Brian Yan, Injy Hamed, Shuichiro Shimizu, Vasista Lodagala, William Chen, Olga Iakovenko, Bashar Talafha, Amir Hussein, Alexander Polok, Kalvin Chang, Dominik Klement, Sara Althubaiti, Puyuan Peng, Matthew Wiesner, Thamar Solorio, Ahmed Ali, Sanjeev Khudanpur, Shinji Watanabe, Chih-Chen Chen, Zhen Wu, Karim Benharrak, Anuj Diwan, Samuele Cornell, Eunjung Yeo, Kwanghee Choi, Carlos Carvalho, Karen Rosero
- **URL**: <http://arxiv.org/abs/2509.14161v1>
- **Submitted**: 2025-09-17 16:45:22
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests as it focuses on speech recognition and translation systems, which is outside your primary areas of Information Retrieval and Natural Language Processing.

#### Abstract
> We present CS-FLEURS, a new dataset for developing and evaluating
code-switched speech recognition and translation systems beyond high-resourced
languages. CS-FLEURS consists of 4 test sets which cover in total 113 unique
code-switched language pairs across 52 languages: 1) a 14 X-English language
pair set with real voices reading synthetically generated code-switched
sentences, 2) a 16 X-English language pair set with generative text-to-speech
3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the
generative text-to-speech, and 4) a 45 X-English lower-resourced language pair
test set with concatenative text-to-speech. Besides the four test sets,
CS-FLEURS also provides a training set with 128 hours of generative
text-to-speech data across 16 X-English language pairs. Our hope is that
CS-FLEURS helps to broaden the scope of future code-switched speech research.
Dataset link: https://huggingface.co/datasets/byan/cs-fleurs.

### 39. Noise Supervised Contrastive Learning and Feature-Perturbed for Anomalous Sound Detection

- **LLM Score**: 0
- **Keyword Score**: 1
- **Authors**: Shun Huang, Zhihua Fang, Liang He
- **URL**: <http://arxiv.org/abs/2509.13853v2>
- **Submitted**: 2025-09-17 09:38:47
- **Comment**: Accepted ICASSP 2025
- **Topic Keywords**: www
- **Reason**: This paper focuses on anomalous sound detection using audio data, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Unsupervised anomalous sound detection aims to detect unknown anomalous
sounds by training a model using only normal audio data. Despite advancements
in self-supervised methods, the issue of frequent false alarms when handling
samples of the same type from different machines remains unresolved. This paper
introduces a novel training technique called one-stage supervised contrastive
learning (OS-SCL), which significantly addresses this problem by perturbing
features in the embedding space and employing a one-stage noisy supervised
contrastive learning approach. On the DCASE 2020 Challenge Task 2, it achieved
94.64\% AUC, 88.42\% pAUC, and 89.24\% mAUC using only Log-Mel features.
Additionally, a time-frequency feature named TFgram is proposed, which is
extracted from raw audio. This feature effectively captures critical
information for anomalous sound detection, ultimately achieving 95.71\% AUC,
90.23\% pAUC, and 91.23\% mAUC. The source code is available at:
\underline{www.github.com/huangswt/OS-SCL}.

---

