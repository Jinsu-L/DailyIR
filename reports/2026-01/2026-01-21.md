# Daily Papers Report - 2026-01-21

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Rerank Before You Reason: Analyzing Reranking Tradeoffs through Effective Token Cost in Deep Search Agents

- **LLM Score**: 8
- **Keyword Score**: 16
- **Authors**: Sahel Sharifymoghaddam, Jimmy Lin
- **URL**: <http://arxiv.org/abs/2601.14224v1>
- **Submitted**: 2026-01-20 18:38:35
- **Comment**: 10 pages, 7 figures
- **Topic Keywords**: queries, ranking, rerank, listwise, retrieval, rank, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, specifically in the area of ranking models and query understanding. The focus on reranking and its tradeoffs in deep search agents aligns with your interests in Learning to Rank and real-time relevance optimization. However, the paper's specific application in the BrowseComp-Plus benchmark and its emphasis on efficiency concerns slightly reduces its relevance to your broader interests in NLP and data mining.

#### Abstract
> Deep research agents rely on iterative retrieval and reasoning to answer complex queries, but scaling test-time computation raises significant efficiency concerns. We study how to allocate reasoning budget in deep search pipelines, focusing on the role of listwise reranking. Using the BrowseComp-Plus benchmark, we analyze tradeoffs between model scale, reasoning effort, reranking depth, and total token cost via a novel effective token cost (ETC) metric. Our results show that reranking consistently improves retrieval and end-to-end accuracy, and that moderate reranking often yields larger gains than increasing search-time reasoning, achieving comparable accuracy at substantially lower cost. All our code is available at https://github.com/texttron/BrowseComp-Plus.git

---

### 2. Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval

- **LLM Score**: 8
- **Keyword Score**: 11
- **Authors**: Joaqu√≠n Polonuer, Lucas Vittor, I√±aki Arango, Ayush Noori, David A. Clifton, Luciano Del Corro, Marinka Zitnik
- **URL**: <http://arxiv.org/abs/2601.13969v1>
- **Submitted**: 2026-01-20 13:46:37
- **Topic Keywords**: retriever, queries, rag, retrieval, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of query understanding and ranking models. The paper introduces a novel approach to knowledge graph exploration, which aligns with your focus on deep semantic understanding and real-time relevance optimization. While it doesn't specifically focus on e-commerce, the techniques and concepts presented can be applied to various domains.

#### Abstract
> Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.

---

### 3. ReSearch: A Multi-Stage Machine Learning Framework for Earth Science Data Discovery

- **LLM Score**: 7
- **Keyword Score**: 13
- **Authors**: Youran Sun, Yixin Wen, Haizhao Yang
- **URL**: <http://arxiv.org/abs/2601.14176v1>
- **Submitted**: 2026-01-20 17:27:12
- **Topic Keywords**: queries, ranking, rerank, retrieval, rank, search
- **Reason**: The paper introduces a multi-stage search framework, ReSearch, which addresses the challenge of bridging high-level scientific intent and heterogeneous metadata in Earth Science data discovery. While the focus is on Earth Science, the framework's use of intent interpretation, semantic embeddings, and large language model reranking aligns with your interests in query understanding, ranking models, and user behavior modeling. However, the specific domain and application are not directly related to your primary focus on e-commerce and information retrieval.

#### Abstract
> The rapid expansion of Earth Science data from satellite observations, reanalysis products, and numerical simulations has created a critical bottleneck in scientific discovery, namely identifying relevant datasets for a given research objective.
  Existing discovery systems are primarily retrieval-centric and struggle to bridge the gap between high-level scientific intent and heterogeneous metadata at scale.
  We introduce \textbf{ReSearch}, a multi-stage, reasoning-enhanced search framework that formulates Earth Science data discovery as an iterative process of intent interpretation, high-recall retrieval, and context-aware ranking.
  ReSearch integrates lexical search, semantic embeddings, abbreviation expansion, and large language model reranking within a unified architecture that explicitly separates recall and precision objectives.
  To enable realistic evaluation, we construct a literature-grounded benchmark by aligning natural language intent with datasets cited in peer-reviewed Earth Science studies.
  Experiments demonstrate that ReSearch consistently improves recall and ranking performance over baseline methods, particularly for task-based queries expressing abstract scientific goals.
  These results underscore the importance of intent-aware, multi-stage search as a foundational capability for reproducible and scalable Earth Science research.

---

### 4. Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores

- **LLM Score**: 7
- **Keyword Score**: 4
- **Authors**: Esma Balkƒ±r, Alice Pernthaller, Marco Basaldella, Jos√© Hern√°ndez-Orallo, Nigel Collier
- **URL**: <http://arxiv.org/abs/2601.13885v1>
- **Submitted**: 2026-01-20 11:59:13
- **Topic Keywords**: ranking, rank
- **Reason**: This paper presents a novel approach to adaptive testing for LLM evaluation, which is related to ranking models and query understanding in Information Retrieval. Although it focuses on LLM evaluation, it involves uncertainty-aware ranking and continuous scoring, which are relevant to the user's interests. However, the primary focus on LLM evaluation and generation tasks makes it somewhat less central to the user's core research themes.

#### Abstract
> Computerized Adaptive Testing (CAT) has proven effective for efficient LLM evaluation on multiple-choice benchmarks, but modern LLM evaluation increasingly relies on generation tasks where outputs are scored continuously rather than marked correct/incorrect. We present a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, we introduce an uncertainty aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. We validate our method on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics. Our method uses 2% of the items while improving ranking correlation by 0.12 œÑ over random sampling, with 95% accuracy on confident predictions.

---

### 5. Auditory Brain Passage Retrieval: Cross-Sensory EEG Training for Neural Information Retrieval

- **LLM Score**: 4
- **Keyword Score**: 15
- **Authors**: Niall McGuire, Yashar Moshfeghi
- **URL**: <http://arxiv.org/abs/2601.14001v1>
- **Submitted**: 2026-01-20 14:22:41
- **Comment**: Accepted At ECIR 2026
- **Topic Keywords**: information retrieval, passage retrieval, query, queries, retrieval, search
- **Reason**: This paper explores Brain Passage Retrieval using auditory EEG signals, which is somewhat related to information retrieval and neural information retrieval. However, the focus on auditory brain signals and cross-sensory training is not directly aligned with the user's core research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Query formulation from internal information needs remains fundamentally challenging across all Information Retrieval paradigms due to cognitive complexity and physical impairments. Brain Passage Retrieval (BPR) addresses this by directly mapping EEG signals to passage representations without intermediate text translation. However, existing BPR research exclusively uses visual stimuli, leaving critical questions unanswered: Can auditory EEG enable effective retrieval for voice-based interfaces and visually impaired users? Can training on combined EEG datasets from different sensory modalities improve performance despite severe data scarcity? We present the first systematic investigation of auditory EEG for BPR and evaluate cross-sensory training benefits. Using dual encoder architectures with four pooling strategies (CLS, mean, max, multi-vector), we conduct controlled experiments comparing auditory-only, visual-only, and combined training on the Alice (auditory) and Nieuwland (visual) datasets. Results demonstrate that auditory EEG consistently outperforms visual EEG, and cross-sensory training with CLS pooling achieves substantial improvements over individual training: 31% in MRR (0.474), 43% in Hit@1 (0.314), and 28% in Hit@10 (0.858). Critically, combined auditory EEG models surpass BM25 text baselines (MRR: 0.474 vs 0.428), establishing neural queries as competitive with traditional retrieval whilst enabling accessible interfaces. These findings validate auditory neural interfaces for IR tasks and demonstrate that cross-sensory training addresses data scarcity whilst outperforming single-modality approaches Code: https://github.com/NiallMcguire/Audio_BPR

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. NewsRECON: News article REtrieval for image CONtextualization

- **LLM Score**: 4
- **Keyword Score**: 12
- **Authors**: Jonathan Tonglet, Iryna Gurevych, Tinne Tuytelaars, Marie-Francine Moens
- **URL**: <http://arxiv.org/abs/2601.14121v1>
- **Submitted**: 2026-01-20 16:15:53
- **Comment**: Preprint under review. Code available at https://github.com/jtonglet/arxiv2025-newsrecon
- **Topic Keywords**: ranking, rerank, rag, retrieval, rank, search
- **Reason**: The paper is somewhat related to information retrieval, as it involves a method for retrieving news articles. However, the focus is on image contextualization and linking images to news articles, which is not directly related to query understanding, ranking models, or user behavior modeling. While it involves NLP and data mining, the application is specific to news article retrieval and not broadly applicable to the user's research interests.

#### Abstract
> Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available.

### 7. IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization

- **LLM Score**: 4
- **Keyword Score**: 11
- **Authors**: Heyang Zhou, JiaJia Chen, Xiaolu Chen, Jie Bao, Zhen Chen, Yong Liao
- **URL**: <http://arxiv.org/abs/2601.13938v1>
- **Submitted**: 2026-01-20 13:13:39
- **Comment**: 9 pages, 3 figures. Submitted to ACL 2026. Corresponding author: Zhen Chen
- **Topic Keywords**: information retrieval, query, queries, retrieval
- **Reason**: The paper discusses Generative Engine Optimization, which is related to information retrieval, but its focus on query synthesis and optimization for diverse queries is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling. While it touches on optimization challenges, it does not explicitly address the user's core research themes.

#### Abstract
> As Generative Engines revolutionize information retrieval by synthesizing direct answers from retrieved sources, ensuring source visibility becomes a significant challenge. Improving it through targeted content revisions is a practical strategy termed Generative Engine Optimization (GEO). However, optimizing a document for diverse queries presents a constrained optimization challenge where heterogeneous queries often impose conflicting and competing revision requirements under a limited content budget. To address this challenge, we propose IF-GEO, a "diverge-then-converge" framework comprising two phases: (i) mining distinct optimization preferences from representative latent queries; (ii) synthesizing a Global Revision Blueprint for guided editing by coordinating preferences via conflict-aware instruction fusion. To explicitly quantify IF-GEO's objective of cross-query stability, we introduce risk-aware stability metrics. Experiments on multi-query benchmarks demonstrate that IF-GEO achieves substantial performance gains while maintaining robustness across diverse retrieval scenarios.

### 8. More Than Efficiency: Embedding Compression Improves Domain Adaptation in Dense Retrieval

- **LLM Score**: 4
- **Keyword Score**: 11
- **Authors**: Chunsheng Zuo, Daniel Khashabi
- **URL**: <http://arxiv.org/abs/2601.13525v1>
- **Submitted**: 2026-01-20 02:21:03
- **Topic Keywords**: retriever, dense retrieval, query, retrieval
- **Reason**: This paper explores domain adaptation in dense retrieval, which is somewhat related to information retrieval and search technologies. However, the focus on embedding compression and its application to domain adaptation does not directly align with the user's primary interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Dense retrievers powered by pretrained embeddings are widely used for document retrieval but struggle in specialized domains due to the mismatches between the training and target domain distributions. Domain adaptation typically requires costly annotation and retraining of query-document pairs. In this work, we revisit an overlooked alternative: applying PCA to domain embeddings to derive lower-dimensional representations that preserve domain-relevant features while discarding non-discriminative components. Though traditionally used for efficiency, we demonstrate that this simple embedding compression can effectively improve retrieval performance. Evaluated across 9 retrievers and 14 MTEB datasets, PCA applied solely to query embeddings improves NDCG@10 in 75.4% of model-dataset pairs, offering a simple and lightweight method for domain adaptation.

### 9. HALT: Hallucination Assessment via Latent Testing

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Rohan Bhatnagar, Youran Sun, Chi Andrew Zhang, Yixin Wen, Haizhao Yang
- **URL**: <http://arxiv.org/abs/2601.14210v1>
- **Submitted**: 2026-01-20 18:16:10
- **Topic Keywords**: query, queries
- **Reason**: This paper focuses on assessing hallucinations in large language models, which is related to query understanding and deep semantic understanding in Information Retrieval. However, the primary focus on language models and hallucination assessment does not directly align with the user's core research themes in IR and search technologies, despite some tangential connections to query understanding and uncertainty modeling.

#### Abstract
> Hallucination in large language models (LLMs) can be understood as a failure of faithful readout: although internal representations may encode uncertainty about a query, decoding pressures still yield a fluent answer. We propose lightweight residual probes that read hallucination risk directly from intermediate hidden states of question tokens, motivated by the hypothesis that these layers retain epistemic signals that are attenuated in the final decoding stage. The probe is a small auxiliary network whose computation is orders of magnitude cheaper than token generation and can be evaluated fully in parallel with inference, enabling near-instantaneous hallucination risk estimation with effectively zero added latency in low-risk cases. We deploy the probe as an agentic critic for fast selective generation and routing, allowing LLMs to immediately answer confident queries while delegating uncertain ones to stronger verification pipelines. Across four QA benchmarks and multiple LLM families, the method achieves strong AUROC and AURAC, generalizes under dataset shift, and reveals interpretable structure in intermediate representations, positioning fast internal uncertainty readout as a principled foundation for reliable agentic AI.

### 10. XR: Cross-Modal Agents for Composed Image Retrieval

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Zhongyu Yang, Wei Pang, Yingfang Yuan
- **URL**: <http://arxiv.org/abs/2601.14245v1>
- **Submitted**: 2026-01-20 18:57:00
- **Comment**: Accepted by WWW 2026. Project: https://01yzzyu.github.io/xr.github.io/
- **Topic Keywords**: query, retrieval
- **Reason**: The paper 'XR: Cross-Modal Agents for Composed Image Retrieval' explores a novel approach to image retrieval, leveraging multimodal reasoning and multi-agent coordination. While it touches on aspects of query understanding and ranking models, its primary focus on image retrieval and cross-modal agents makes it somewhat related to your interests in Information Retrieval, but not a central match. The paper's emphasis on deep semantic understanding and real-time relevance optimization is also relevant, but not a primary focus of the work.

#### Abstract
> Retrieval is being redefined by agentic AI, demanding multimodal reasoning beyond conventional similarity-based paradigms. Composed Image Retrieval (CIR) exemplifies this shift as each query combines a reference image with textual modifications, requiring compositional understanding across modalities. While embedding-based CIR methods have achieved progress, they remain narrow in perspective, capturing limited cross-modal cues and lacking semantic reasoning. To address these limitations, we introduce XR, a training-free multi-agent framework that reframes retrieval as a progressively coordinated reasoning process. It orchestrates three specialized types of agents: imagination agents synthesize target representations through cross-modal generation, similarity agents perform coarse filtering via hybrid matching, and question agents verify factual consistency through targeted reasoning for fine filtering. Through progressive multi-agent coordination, XR iteratively refines retrieval to meet both semantic and visual query constraints, achieving up to a 38% gain over strong training-free and training-based baselines on FashionIQ, CIRR, and CIRCO, while ablations show each agent is essential. Code is available: https://01yzzyu.github.io/xr.github.io/.

### 11. Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Xinlei Yin, Xiulian Peng, Xiao Li, Zhiwei Xiong, Yan Lu
- **URL**: <http://arxiv.org/abs/2601.13719v1>
- **Submitted**: 2026-01-20 08:23:29
- **Topic Keywords**: rag, retrieval, search
- **Reason**: This paper explores long video understanding with a focus on audiovisual entity cohesion and agentic search, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on video understanding and multimodal reasoning, while interesting, does not directly align with the user's core research themes in IR and NLP. The paper's emphasis on structured, multimodal reasoning for comprehensive video understanding is an interesting application, but it does not directly contribute to the user's interests in query understanding, ranking models, or user behavior modeling.

#### Abstract
> Long video understanding presents significant challenges for vision-language models due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation, typically suffer from information fragmentation and a loss of global coherence. We present HAVEN, a unified framework for long-video understanding that enables coherent and comprehensive reasoning by integrating audiovisual entity cohesion and hierarchical video indexing with agentic search. First, we preserve semantic consistency by integrating entity-level representations across visual and auditory streams, while organizing content into a structured hierarchy spanning global summary, scene, segment, and entity levels. Then we employ an agentic search mechanism to enable dynamic retrieval and reasoning across these layers, facilitating coherent narrative reconstruction and fine-grained entity tracking. Extensive experiments demonstrate that our method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos.

### 12. A Systematic Analysis of Chunking Strategies for Reliable Question Answering

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Sofia Bennani, Charles Moslonka
- **URL**: <http://arxiv.org/abs/2601.14123v1>
- **Submitted**: 2026-01-20 16:19:58
- **Comment**: 3 pages, 2 figures, 1 table, pre-print
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper is somewhat related to Information Retrieval, specifically focusing on Retrieval-Augmented Generation systems and chunking strategies. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The connection to NLP is also present, but the paper's focus on question answering and chunking strategies is not a central match to the user's research themes.

#### Abstract
> We study how document chunking choices impact the reliability of Retrieval-Augmented Generation (RAG) systems in industry. While practice often relies on heuristics, our end-to-end evaluation on Natural Questions systematically varies chunking method (token, sentence, semantic, code), chunk size, overlap, and context length. We use a standard industrial setup: SPLADE retrieval and a Mistral-8B generator. We derive actionable lessons for cost-efficient deployment: (i) overlap provides no measurable benefit and increases indexing cost; (ii) sentence chunking is the most cost-effective method, matching semantic chunking up to ~5k tokens; (iii) a "context cliff" reduces quality beyond ~2.5k tokens; and (iv) optimal context depends on the goal (semantic quality peaks at small contexts; exact match at larger ones).

### 13. AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Yusheng Liao, Chuan Xuan, Yutong Cai, Lina Yang, Zhe Chen, Yanfeng Wang, Yu Wang
- **URL**: <http://arxiv.org/abs/2601.13918v1>
- **Submitted**: 2026-01-20 12:48:04
- **Comment**: 37 pages, 12 figures
- **Topic Keywords**: ctr, retrieval
- **Reason**: The paper explores the application of large language models in the medical domain, specifically in Electronic Health Records navigation. While it touches on summarization and decision-making tasks, it doesn't directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%.

### 14. Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Sasha Ronaghi, Prerit Choudhary, David H Rehkopf, Bryant Lin
- **URL**: <http://arxiv.org/abs/2601.13388v1>
- **Submitted**: 2026-01-19 20:53:09
- **Comment**: 7 pages, 5 figures
- **Topic Keywords**: ctr, retrieval
- **Reason**: This paper explores the application of large language models to extract structured insights from unstructured patient narratives, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on healthcare and risk prediction modeling is not directly aligned with the user's core research themes in e-commerce and real-time relevance optimization.

#### Abstract
> Social determinants of health (SDOH) play a critical role in Type 2 Diabetes (T2D) management but are often absent from electronic health records and risk prediction models. Most individual-level SDOH data is collected through structured screening tools, which lack the flexibility to capture the complexity of patient experiences and unique needs of a clinic's population. This study explores the use of large language models (LLMs) to extract structured SDOH information from unstructured patient life stories and evaluate the predictive value of both the extracted features and the narratives themselves for assessing diabetes control. We collected unstructured interviews from 65 T2D patients aged 65 and older, focused on their lived experiences, social context, and diabetes management. These narratives were analyzed using LLMs with retrieval-augmented generation to produce concise, actionable qualitative summaries for clinical interpretation and structured quantitative SDOH ratings for risk prediction modeling. The structured SDOH ratings were used independently and in combination with traditional laboratory biomarkers as inputs to linear and tree-based machine learning models (Ridge, Lasso, Random Forest, and XGBoost) to demonstrate how unstructured narrative data can be applied in conventional risk prediction workflows. Finally, we evaluated several LLMs on their ability to predict a patient's level of diabetes control (low, medium, high) directly from interview text with A1C values redacted. LLMs achieved 60% accuracy in predicting diabetes control levels from interview text. This work demonstrates how LLMs can translate unstructured SDOH-related data into structured insights, offering a scalable approach to augment clinical risk models and decision-making.

### 15. Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Samantha Sudhoff, Pranav Perumal, Zhaoqing Wu, Tunazzina Islam
- **URL**: <http://arxiv.org/abs/2601.13317v1>
- **Submitted**: 2026-01-19 19:00:56
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper explores the intersection of climate discourse and online platforms, using a thematic discovery framework to analyze paid and public climate messaging. While it touches on aspects of information retrieval, such as theme labeling and retrieval tasks, its primary focus is on climate communication and narrative analysis, which is somewhat related to the user's interests in IR and NLP.

#### Abstract
> Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.

### 16. Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Xiaolin Zhou, Zheng Luo, Yicheng Gao, Qixuan Chen, Xiyang Hu, Yue Zhao, Ruishan Liu
- **URL**: <http://arxiv.org/abs/2601.13649v1>
- **Submitted**: 2026-01-20 06:33:33
- **Topic Keywords**: pairwise
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Large Language Models (LLMs), but it focuses more on the fairness and bias aspects of LLMs rather than query understanding, ranking models, or user behavior modeling. While it touches on the performance disparities of LLMs across languages, it does not directly relate to your core areas of interest in Information Retrieval and Search technologies.

#### Abstract
> Recent advances in Large Language Models (LLMs) have incentivized the development of LLM-as-a-judge, an application of LLMs where they are used as judges to decide the quality of a certain piece of text given a certain context. However, previous studies have demonstrated that LLM-as-a-judge can be biased towards different aspects of the judged texts, which often do not align with human preference. One of the identified biases is language bias, which indicates that the decision of LLM-as-a-judge can differ based on the language of the judged texts. In this paper, we study two types of language bias in pairwise LLM-as-a-judge: (1) performance disparity between languages when the judge is prompted to compare options from the same language, and (2) bias towards options written in major languages when the judge is prompted to compare options of two different languages. We find that for same-language judging, there exist significant performance disparities across language families, with European languages consistently outperforming African languages, and this bias is more pronounced in culturally-related subjects. For inter-language judging, we observe that most models favor English answers, and that this preference is influenced more by answer language than question language. Finally, we investigate whether language bias is in fact caused by low-perplexity bias, a previously identified bias of LLM-as-a-judge, and we find that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity only.

### 17. Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: George Mihaila
- **URL**: <http://arxiv.org/abs/2601.14112v2>
- **Submitted**: 2026-01-20 16:06:34
- **Topic Keywords**: ctr
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Explainable AI (XAI), but it does not directly address your primary focus on Information Retrieval (IR), query understanding, or ranking models. The paper's emphasis on transformer attention patterns and model interpretability may be of interest, but it does not appear to be a central match for your research themes.

#### Abstract
> Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.

### 18. From Tags to Trees: Structuring Fine-Grained Knowledge for Controllable Data Selection in LLM Instruction Tuning

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Zihan Niu, Wenping Hu, Junmin Chen, Xiyue Wang, Tong Xu, Ruiming Tang
- **URL**: <http://arxiv.org/abs/2601.13995v1>
- **Submitted**: 2026-01-20 14:06:51
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to your interests in Information Retrieval, particularly in the context of Learning to Rank and user behavior modeling. However, the focus on Large Language Models (LLMs) and data selection for instruction tuning is not a central match to your primary research themes. The paper does involve some aspects of semantic understanding and relevance optimization, but it is not directly applicable to your areas of expertise.

#### Abstract
> Effective and controllable data selection is critical for LLM instruction tuning, especially with massive open-source datasets. Existing approaches primarily rely on instance-level quality scores, or diversity metrics based on embedding clusters or semantic tags. However, constrained by the flatness of embedding spaces or the coarseness of tags, these approaches overlook fine-grained knowledge and its intrinsic hierarchical dependencies, consequently hindering precise data valuation and knowledge-aligned sampling. To address this challenge, we propose Tree-aware Aligned Global Sampling (TAGS), a unified framework that leverages a knowledge tree built from fine-grained tags, thereby enabling joint control of global quality, diversity, and target alignment. Using an LLM-based tagger, we extract atomic knowledge concepts, which are organized into a global tree through bottom-up hierarchical clustering. By grounding data instances onto this tree, a tree-aware metric then quantifies data quality and diversity, facilitating effective sampling. Our controllable sampling strategy maximizes tree-level information gain and enforces leaf-level alignment via KL-divergence for specific domains. Extensive experiments demonstrate that TAGS significantly outperforms state-of-the-art baselines. Notably, it surpasses the full-dataset model by \textbf{+5.84\%} using only \textbf{5\%} of the data, while our aligned sampling strategy further boosts average performance by \textbf{+4.24\%}.

### 19. Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Dezhao Song, Guglielmo Bonifazi, Frank Schilder, Jonathan Richard Schwarz
- **URL**: <http://arxiv.org/abs/2601.13806v1>
- **Submitted**: 2026-01-20 10:06:34
- **Topic Keywords**: rag
- **Reason**: The paper explores the application of knowledge graphs to enhance legal reasoning in LLMs, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on legal reasoning and knowledge graphs is not a central match to the user's core research themes, which are more focused on general search technologies and user behavior modeling.

#### Abstract
> LLM post-training has primarily relied on large text corpora and human feedback, without capturing the structure of domain knowledge. This has caused models to struggle dealing with complex reasoning tasks, especially for high-stakes professional domains. In Law, reasoning requires deep understanding of the relations between various legal concepts, a key component missing in current LLM post-training. In this paper, we propose a knowledge graph (KG)-assisted approach for enhancing LLMs' reasoning capability in Legal that is generalizable to other high-stakes domains. We model key legal concepts by following the \textbf{IRAC} (Issue, Rule, Analysis and Conclusion) framework, and construct a KG with 12K legal cases. We then produce training data using our IRAC KG, and conduct both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) with three state-of-the-art (SOTA) LLMs (30B, 49B and 70B), varying architecture and base model family. Our post-trained models obtained better average performance on 4/5 diverse legal benchmarks (14 tasks) than baselines. In particular, our 70B DPO model achieved the best score on 4/6 reasoning tasks, among baselines and a 141B SOTA legal LLM, demonstrating the effectiveness of our KG for enhancing LLMs' legal reasoning capability.

### 20. DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Shengda Fan, Xuyan Ye, Yankai Lin
- **URL**: <http://arxiv.org/abs/2601.13761v2>
- **Submitted**: 2026-01-20 09:12:27
- **Topic Keywords**: rag
- **Reason**: This paper focuses on large language models and self-play frameworks, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary contribution is in the area of language model evolution, which is not a central match to the user's core research themes. The paper does involve deep semantic understanding, but the context is different from the user's focus on real-time relevance optimization in IR.

#### Abstract
> Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations. The code is available at https://github.com/RUCBM/DARC.

### 21. Towards robust long-context understanding of large language model via active recap learning

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Chenyu Hui
- **URL**: <http://arxiv.org/abs/2601.13734v1>
- **Submitted**: 2026-01-20 08:42:04
- **Comment**: 5 pages
- **Topic Keywords**: rag
- **Reason**: The paper focuses on enhancing large language models' understanding of long contexts, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on language models and memory augmentation does not directly align with the user's core research themes in IR and Search technologies. The connection to NLP is relevant, but the paper's scope is more narrow than the user's interests.

#### Abstract
> In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM

### 22. Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Fan Huang, Haewoon Kwak, Jisun An
- **URL**: <http://arxiv.org/abs/2601.13590v1>
- **Submitted**: 2026-01-20 04:43:55
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Large Language Models, but it does not directly align with your primary focus on Information Retrieval, query understanding, and ranking models. The paper's focus on LLMs' susceptibility to persuasion and belief stability is an interesting aspect, but it does not seem to have a direct connection to your work in search technologies and user behavior modeling.

#### Abstract
> Large Language Models (LLMs) are increasingly employed in various question-answering tasks. However, recent studies showcase that LLMs are susceptible to persuasion and could adopt counterfactual beliefs. We present a systematic evaluation of LLM susceptibility to persuasion under the Source--Message--Channel--Receiver (SMCR) communication framework. Across five mainstream Large Language Models (LLMs) and three domains (factual knowledge, medical QA, and social bias), we analyze how different persuasive strategies influence belief stability over multiple interaction turns. We further examine whether meta-cognition prompting (i.e., eliciting self-reported confidence) affects resistance to persuasion. Results show that smaller models exhibit extreme compliance, with over 80% of belief changes occurring at the first persuasive turn (average end turn of 1.1--1.4). Contrary to expectations, meta-cognition prompting increases vulnerability by accelerating belief erosion rather than enhancing robustness. Finally, we evaluate adversarial fine-tuning as a defense. While GPT-4o-mini achieves near-complete robustness (98.6%) and Mistral~7B improves substantially (35.7% $\rightarrow$ 79.3%), Llama models remain highly susceptible (<14%) even when fine-tuned on their own failure cases. Together, these findings highlight substantial model-dependent limits of current robustness interventions and offer guidance for developing more trustworthy LLMs.

### 23. AfroScope: A Framework for Studying the Linguistic Landscape of Africa

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Sang Yun Kwon, AbdelRahim Elmadany, Muhammad Abdul-Mageed
- **URL**: <http://arxiv.org/abs/2601.13346v1>
- **Submitted**: 2026-01-19 19:30:35
- **Topic Keywords**: rag
- **Reason**: The paper is somewhat related to the user's interests in Natural Language Processing (NLP) and data mining, but it focuses on language identification and linguistic landscape analysis, which is not directly aligned with the user's core research themes in Information Retrieval and Search technologies. While it does involve a dataset and models, the application and context are quite different from the user's areas of interest.

#### Abstract
> Language Identification (LID) is the task of determining the language of a given text and is a fundamental preprocessing step that affects the reliability of downstream NLP applications. While recent work has expanded LID coverage for African languages, existing approaches remain limited in (i) the number of supported languages and (ii) their ability to make fine-grained distinctions among closely related varieties. We introduce AfroScope, a unified framework for African LID that includes AfroScope-Data, a dataset covering 713 African languages, and AfroScope-Models, a suite of strong LID models with broad language coverage. To better distinguish highly confusable languages, we propose a hierarchical classification approach that leverages Mirror-Serengeti, a specialized embedding model targeting 29 closely related or geographically proximate languages. This approach improves macro F1 by 4.55 on this confusable subset compared to our best base model. Finally, we analyze cross linguistic transfer and domain effects, offering guidance for building robust African LID systems. We position African LID as an enabling technology for large scale measurement of Africas linguistic landscape in digital text and release AfroScope-Data and AfroScope-Models publicly.

### 24. XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Mohsinul Kabir, Tasnim Ahmed, Md Mezbaur Rahman, Shaoxiong Ji, Hassan Alhuzali, Sophia Ananiadou
- **URL**: <http://arxiv.org/abs/2601.14063v1>
- **Submitted**: 2026-01-20 15:21:18
- **Comment**: 30 Pages, 13 Figures
- **Topic Keywords**: search
- **Reason**: The paper focuses on cross-cultural reasoning in LLMs, which is related to query understanding and deep semantic understanding in IR. However, it does not directly address ranking models or user behavior modeling, and its primary focus is on NLP rather than IR. The paper's relevance to the user's research interests is somewhat limited.

#### Abstract
> Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. Our corpus integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Our findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, we find evidence that LLMs encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. We release our corpus and code to facilitate future research on cross-cultural NLP.

### 25. LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction

- **LLM Score**: 3
- **Keyword Score**: 2
- **Authors**: Yuxing Lu, J. Ben Tamo, Weichen Zhao, Nan Sun, Yishan Zhong, Wenqi Shi, Jinzhuo Wang, May D. Wang
- **URL**: <http://arxiv.org/abs/2601.13352v1>
- **Submitted**: 2026-01-19 19:41:39
- **Comment**: 17 pages, 5 figures, 6 tables
- **Topic Keywords**: rag
- **Reason**: This paper proposes a novel inference-only framework for large language models, enabling online learning through language. While it touches on sequence prediction and memory updates, it primarily focuses on improving the performance of language models, which is somewhat related to information retrieval and NLP, but not directly aligned with the user's core research themes.

#### Abstract
> Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.

### 26. Legal Retrieval for Public Defenders

- **LLM Score**: 2
- **Keyword Score**: 9
- **Authors**: Dominik Stammbach, Kylie Zhang, Patty Liu, Nimra Nadeem, Lucia Zheng, Peter Henderson
- **URL**: <http://arxiv.org/abs/2601.14348v1>
- **Submitted**: 2026-01-20 17:08:34
- **Topic Keywords**: query, queries, retrieval, search
- **Reason**: This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves retrieval tools, the focus is on legal retrieval for public defenders, which is a specific domain and does not align with the user's broader interests in e-commerce, query understanding, ranking models, or user behavior modeling.

#### Abstract
> AI tools are increasingly suggested as solutions to assist public agencies with heavy workloads. In public defense, where a constitutional right to counsel meets the complexities of law, overwhelming caseloads and constrained resources, practitioners face especially taxing conditions. Yet, there is little evidence of how AI could meaningfully support defenders' day-to-day work. In partnership with the New Jersey Office of the Public Defender, we develop the NJ BriefBank, a retrieval tool which surfaces relevant appellate briefs to streamline legal research and writing. We show that existing legal retrieval benchmarks fail to transfer to public defense search, however adding domain knowledge improves retrieval quality. This includes query expansion with legal reasoning, domain-specific data and curated synthetic examples. To facilitate further research, we provide a taxonomy of realistic defender search queries and release a manually annotated public defense retrieval dataset. Together, our work offers starting points towards building practical, reliable retrieval AI tools for public defense, and towards more realistic legal retrieval benchmarks.

### 27. HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Yuezhe Yang, Hao Wang, Yige Peng, Jinman Kim, Lei Bi
- **URL**: <http://arxiv.org/abs/2601.13919v1>
- **Submitted**: 2026-01-20 12:48:09
- **Comment**: Under Review
- **Topic Keywords**: rag, ctr, retrieval
- **Reason**: This paper focuses on medical AI, specifically clinical diagnosis, and uses a deep diagnosis framework to integrate EHR and X-Ray data. While it involves information retrieval and multimodal data integration, the context and application are quite different from the user's core research themes in Information Retrieval and Search technologies.

#### Abstract
> Automated clinical diagnosis remains a core challenge in medical AI, which usually requires models to integrate multi-modal data and reason across complex, case-specific contexts. Although recent methods have advanced medical report generation (MRG) and visual question answering (VQA) with medical vision-language models (VLMs), these methods, however, predominantly operate under a sample-isolated inference paradigm, as such processing cases independently without access to longitudinal electronic health records (EHRs) or structurally related patient examples. This paradigm limits reasoning to image-derived information alone, which ignores external complementary medical evidence for potentially more accurate diagnosis. To overcome this limitation, we propose \textbf{HyperWalker}, a \textit{Deep Diagnosis} framework that reformulates clinical reasoning via dynamic hypergraphs and test-time training. First, we construct a dynamic hypergraph, termed \textbf{iBrochure}, to model the structural heterogeneity of EHR data and implicit high-order associations among multimodal clinical information. Within this hypergraph, a reinforcement learning agent, \textbf{Walker}, navigates to and identifies optimal diagnostic paths. To ensure comprehensive coverage of diverse clinical characteristics in test samples, we incorporate a \textit{linger mechanism}, a multi-hop orthogonal retrieval strategy that iteratively selects clinically complementary neighborhood cases reflecting distinct clinical attributes. Experiments on MRG with MIMIC and medical VQA on EHRXQA demonstrate that HyperWalker achieves state-of-the-art performance. Code is available at: https://github.com/Bean-Young/HyperWalker

### 28. On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Weichuan Wang, Mingyang Liu, Linqi Song, Chen Ma
- **URL**: <http://arxiv.org/abs/2601.13729v1>
- **Submitted**: 2026-01-20 08:39:10
- **Comment**: 9 pages, 12 figures
- **Topic Keywords**: ranking, rank, search
- **Reason**: This paper is not relevant to your research interests as it focuses on machine translation and non-deterministic properties of language models, which is outside your primary areas of interest in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> In recent years, the non-deterministic properties of language models have garnered considerable attention and have shown a significant influence on real-world applications. However, such properties remain under-explored in machine translation (MT), a complex, non-deterministic NLP task. In this study, we systematically evaluate modern MT systems and identify temperature-constrained Non-Deterministic MT (ND-MT) as a distinct phenomenon. Additionally, we demonstrate that ND-MT exhibits significant potential in addressing the multi-modality issue that has long challenged MT research and provides higher-quality candidates than Deterministic MT (D-MT) under temperature constraints. However, ND-MT introduces new challenges in evaluating system performance. Specifically, the evaluation framework designed for D-MT fails to yield consistent evaluation results when applied to ND-MT. We further investigate this emerging challenge by evaluating five state-of-the-art ND-MT systems across three open datasets using both lexical-based and semantic-based metrics at varying sampling sizes. The results reveal a Buckets effect across these systems: the lowest-quality candidate generated by ND-MT consistently determines the overall system ranking across different sampling sizes for all reasonable metrics. Furthermore, we propose the ExpectoSample strategy to automatically assess the reliability of evaluation metrics for selecting robust ND-MT.

### 29. Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Zhaopeng Zhang, Pengcheng Sun, Lan Zhang, Chen Tang, Jiewei Lai, Yunhao Wang, Hui Jin
- **URL**: <http://arxiv.org/abs/2601.13630v1>
- **Submitted**: 2026-01-20 05:57:44
- **Topic Keywords**: query, retrieval
- **Reason**: This paper focuses on access control for large language models, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves LLMs and question answering, the primary focus is on security and permission control, rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> Large language models (LLMs) are increasingly deployed over knowledge bases for efficient knowledge retrieval and question answering. However, LLMs can inadvertently answer beyond a user's permission scope, leaking sensitive content, thus making it difficult to deploy knowledge-base QA under fine-grained access control requirements. In this work, we identify a geometric regularity in intermediate activations: for the same query, representations induced by different permission scopes cluster distinctly and are readily separable. Building on this separability, we propose Activation-space Anchored Access Control (AAAC), a training-free framework for multi-class permission control. AAAC constructs an anchor bank, with one permission anchor per class, from a small offline sample set and requires no fine-tuning. At inference time, a multi-anchor steering mechanism redirects each query's activations toward the anchor-defined authorized region associated with the current user, thereby suppressing over-privileged generations by design. Finally, extensive experiments across three LLM families demonstrate that AAAC reduces permission violation rates by up to 86.5% and prompt-based attack success rates by 90.7%, while improving response usability with minor inference overhead compared to baselines.

### 30. Pro-AI Bias in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Benaya Trabelsi, Jonathan Shaki, Sarit Kraus
- **URL**: <http://arxiv.org/abs/2601.13749v1>
- **Submitted**: 2026-01-20 09:03:57
- **Comment**: 13 pages, 6 figures. Code available at: https://github.com/benayat/Pro-AI-bias-in-LLMs
- **Topic Keywords**: queries, recommend
- **Reason**: This paper focuses on the bias in large language models, which is a topic in Natural Language Processing (NLP). However, it does not directly relate to Information Retrieval (IR), query understanding, ranking models, or user behavior modeling, which are the core areas of your research interests.

#### Abstract
> Large language models (LLMs) are increasingly employed for decision-support across multiple domains. We investigate whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, we find consistent evidence of pro-AI bias. First, we show that LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, we demonstrate that models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that ``Artificial Intelligence'' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.

### 31. OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Yulin Hu, Zimo Long, Jiahe Guo, Xingyu Sui, Xing Fu, Weixiang Zhao, Yanyan Zhao, Bing Qin
- **URL**: <http://arxiv.org/abs/2601.13722v1>
- **Submitted**: 2026-01-20 08:27:13
- **Topic Keywords**: relevance, personalization
- **Reason**: This paper focuses on conversational agents and personalization, which is somewhat related to information retrieval and search technologies. However, the topic is more aligned with natural language processing and recommender systems, and the paper's focus on over-personalization in dialogue systems does not directly relate to the user's core research themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. In fact, agents may overuse personal information, producing responses that feel forced, intrusive, or socially inappropriate to users. We refer to this issue as \emph{over-personalization}. In this work, we formalize over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduce \textbf{OP-Bench} a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using \textbf{OP-Bench}, we evaluate multiple large language models and memory-augmentation methods, and find that over-personalization is widespread when memory is introduced. Further analysis reveals that agents tend to retrieve and over-attend to user memories even when unnecessary. To address this issue, we propose \textbf{Self-ReCheck}, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. Our work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.

### 32. HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Zhiyuan Shi, Qibo Qiu, Feng Xue, Zhonglin Jiang, Li Yu, Jian Jiang, Xiaofei He, Wenxiao Wang
- **URL**: <http://arxiv.org/abs/2601.13684v1>
- **Submitted**: 2026-01-20 07:35:06
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper focuses on optimizing the performance of Large Language Models (LLMs) for long-context tasks, proposing a dynamic compression framework called HeteroCache. While it involves retrieval and caching strategies, the context is specific to LLM inference and does not directly relate to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information, principally because they overlook the attention drift phenomenon where token significance evolves dynamically. Although recent dynamic retrieval approaches attempt to address this issue, they typically suffer from coarse-grained caching strategies and incur high I/O overhead due to frequent data transfers. To overcome these limitations, we propose HeteroCache, a training-free dynamic compression framework. Our method is built on two key insights: attention heads exhibit diverse temporal heterogeneity, and there is significant spatial redundancy among heads within the same layer. Guided by these insights, HeteroCache categorizes heads based on stability and redundancy. Consequently, we apply a fine-grained weighting strategy that allocates larger cache budgets to heads with rapidly shifting attention to capture context changes, thereby addressing the inefficiency of coarse-grained strategies. Furthermore, we employ a hierarchical storage mechanism in which a subset of representative heads monitors attention shift, and trigger an asynchronous, on-demand retrieval of contexts from the CPU, effectively hiding I/O latency. Finally, experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to $3\times$ compared to the original model in the 224K context. Our code will be open-source.

### 33. DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Maojun Sun, Yifei Xie, Yue Wu, Ruijian Han, Binyan Jiang, Defeng Sun, Yancheng Yuan, Jian Huang
- **URL**: <http://arxiv.org/abs/2601.13591v1>
- **Submitted**: 2026-01-20 04:44:36
- **Topic Keywords**: query, search
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, which are core areas of your research interests. While it touches on deep learning and multimodal perception, its focus is on data science agents and evaluation, which is somewhat tangential to your primary areas of interest.

#### Abstract
> Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.

### 34. Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yuming Yang, Mingyoung Lai, Wanxu Zhao, Xiaoran Fan, Zhiheng Xi, Mingqi Wu, Chiyue Huang, Jun Zhao, Haijun Lv, Jian Tong, Yunhua Zhou, Yicheng Zou, Qipeng Guo, Tao Gui, Qi Zhang, Xuanjing Huang
- **URL**: <http://arxiv.org/abs/2601.14249v1>
- **Submitted**: 2026-01-20 18:58:10
- **Comment**: 26 pages. Project page: https://github.com/UmeanNever/RankSurprisalRatio
- **Topic Keywords**: rag, rank
- **Reason**: This paper focuses on assessing the suitability of reasoning trajectories for teaching students to reason better, using a metric called Rank-Surprisal Ratio (RSR). While it involves ranking and alignment, the context is in natural language processing and machine learning, which is somewhat related to your interests in Information Retrieval and NLP, but not directly aligned with your core research themes.

#### Abstract
> Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.

### 35. From Completion to Editing: Unlocking Context-Aware Code Infilling via Search-and-Replace Instruction Tuning

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jiajun Zhang, Zeyu Cui, Jiaxi Yang, Lei Zhang, Yuheng Jing, Zeyao Ma, Tianyi Bai, Zilei Wang, Qiang Liu, Liang Wang, Binyuan Hui, Junyang Lin
- **URL**: <http://arxiv.org/abs/2601.13384v1>
- **Submitted**: 2026-01-19 20:33:53
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your research interests as it focuses on code infilling and editing, which is outside your primary areas of interest in Information Retrieval, Search technologies, and Natural Language Processing. While it involves search and replacement, the context is programming code rather than text or user behavior.

#### Abstract
> The dominant Fill-in-the-Middle (FIM) paradigm for code completion is constrained by its rigid inability to correct contextual errors and reliance on unaligned, insecure Base models. While Chat LLMs offer safety and Agentic workflows provide flexibility, they suffer from performance degradation and prohibitive latency, respectively. To resolve this dilemma, we propose Search-and-Replace Infilling (SRI), a framework that internalizes the agentic verification-and-editing mechanism into a unified, single-pass inference process. By structurally grounding edits via an explicit search phase, SRI harmonizes completion tasks with the instruction-following priors of Chat LLMs, extending the paradigm from static infilling to dynamic context-aware editing. We synthesize a high-quality dataset, SRI-200K, and fine-tune the SRI-Coder series. Extensive evaluations demonstrate that with minimal data (20k samples), SRI-Coder enables Chat models to surpass the completion performance of their Base counterparts. Crucially, unlike FIM-style tuning, SRI preserves general coding competencies and maintains inference latency comparable to standard FIM. We empower the entire Qwen3-Coder series with SRI, encouraging the developer community to leverage this framework for advanced auto-completion and assisted development.

### 36. Guidelines for the Creation of an Annotated Corpus

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Bahdja Boudoua, Nadia Guiffant, Mathieu Roche, Maguelonne Teisseire, Annelise Tran
- **URL**: <http://arxiv.org/abs/2601.13353v1>
- **Submitted**: 2026-01-19 19:42:43
- **Comment**: 8 pages, 3 figures
- **Topic Keywords**: rag, search
- **Reason**: The paper appears to be focused on corpus annotation, which is a related but distinct area from Information Retrieval and Search technologies. While it may be useful for NLP tasks, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest.

#### Abstract
> This document, based on feedback from UMR TETIS members and the scientific literature, provides a generic methodology for creating annotation guidelines and annotated textual datasets (corpora). It covers methodological aspects, as well as storage, sharing, and valorization of the data. It includes definitions and examples to clearly illustrate each step of the process, thus providing a comprehensive framework to support the creation and use of corpora in various research contexts.

### 37. InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Matthew Y. R. Yang, Hao Bai, Ian Wu, Gene Yang, Amrith Setlur, Aviral Kumar
- **URL**: <http://arxiv.org/abs/2601.14209v1>
- **Submitted**: 2026-01-20 18:15:38
- **Topic Keywords**: rag
- **Reason**: This paper is primarily focused on improving the reasoning capabilities of large language models using reinforcement learning, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on deep semantic understanding, its application is in a different domain and doesn't align with the user's core research themes.

#### Abstract
> Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.

### 38. The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Renmiao Chen, Yida Lu, Shiyao Cui, Xuan Ouyang, Victor Shea-Jay Huang, Shumin Zhang, Chengwei Pan, Han Qiu, Minlie Huang
- **URL**: <http://arxiv.org/abs/2601.14127v1>
- **Submitted**: 2026-01-20 16:24:18
- **Comment**: *15 pages, 5 figures. Introduces MIR-SafetyBench (2,676 instances; 9 multi-image relations). Equal contribution; ‚Ä†Corresponding author. Code/data: https://github.com/thu-coai/MIR-SafetyBench
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests as it focuses on safety risks in multimodal large language models' multi-image reasoning, which is outside the scope of information retrieval, search technologies, and natural language processing. While it involves language models, the topic is more related to NLP safety and security rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.

### 39. Truth with a Twist: The Rhetoric of Persuasion in Professional vs. Community-Authored Fact-Checks

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Olesya Razuvayevskaya, Kalina Bontcheva
- **URL**: <http://arxiv.org/abs/2601.14105v1>
- **Submitted**: 2026-01-20 16:04:09
- **Comment**: In Proceedings of the ACM Web Conference 2026 (WWW 2026)
- **Topic Keywords**: rag
- **Reason**: This paper appears to be focused on fact-checking and persuasion techniques in community-authored vs. professionally-written content, which does not align with your primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on aspects of language and rhetoric, the context and application are distinct from your core areas of focus.

#### Abstract
> This study presents the first large-scale comparison of persuasion techniques present in crowd- versus professionally-written debunks. Using extensive datasets from Community Notes (CNs), EUvsDisinfo, and the Database of Known Fakes (DBKF), we quantify the prevalence and types of persuasion techniques across these fact-checking ecosystems. Contrary to prior hypothesis that community-produced debunks rely more heavily on subjective or persuasive wording, we find no evidence that CNs contain a higher average number of persuasion techniques than professional fact-checks. We additionally identify systematic rhetorical differences between CNs and professional debunking efforts, reflecting differences in institutional norms and topical coverage. Finally, we examine how the crowd evaluates persuasive language in CNs and show that, although notes with more persuasive elements receive slightly higher overall helpfulness ratings, crowd raters are effective at penalising the use of particular problematic rhetorical means

### 40. "The Whole Is Greater Than the Sum of Its Parts": A Compatibility-Aware Multi-Teacher CoT Distillation Framework

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jin Cui, Jiaqi Guo, Jiepeng Zhou, Ruixuan Yang, Jiayi Lu, Jiajun Xu, Jiangcheng Song, Boran Zhao, Pengju Ren
- **URL**: <http://arxiv.org/abs/2601.13992v1>
- **Submitted**: 2026-01-20 14:05:19
- **Comment**: 11pages, 9figures
- **Topic Keywords**: rag
- **Reason**: This paper focuses on improving the performance of Large Language Models (LLMs) through a novel distillation framework. While it touches on the concept of 'teacher-student incompatibility', it does not directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect "epiphany moments" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.

### 41. Towards Effective Negation Modeling in Joint Audio-Text Models for Music

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yannis Vasilakis, Rachel Bittner, Johan Pauwels
- **URL**: <http://arxiv.org/abs/2601.13931v1>
- **Submitted**: 2026-01-20 13:06:48
- **Comment**: Accepted at IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2026
- **Topic Keywords**: retrieval
- **Reason**: This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves text modeling, its focus on music retrieval and audio-text models is not aligned with the user's interests, and the paper's emphasis on negation modeling in music is not a central match for the user's research.

#### Abstract
> Joint audio-text models are widely used for music retrieval, yet they struggle with semantic phenomena such as negation. Negation is fundamental for distinguishing the absence (or presence) of musical elements (e.g., "with vocals" vs. "without vocals"), but current systems fail to represent this reliably. In this work, we investigate and mitigate this limitation by training CLAP models from scratch on the Million Song Dataset with LP-MusicCaps-MSD captions. We introduce negation through text augmentation and a dissimilarity-based contrastive loss, designed to explicitly separate original and negated captions in the joint embedding space. To evaluate progress, we propose two protocols that frame negation modeling as retrieval and binary classification tasks. Experiments demonstrate that both methods, individually and combined, improve negation handling while largely preserving retrieval performance.

### 42. FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Qian Chen, Jinlan Fu, Changsong Li, See-Kiong Ng, Xipeng Qiu
- **URL**: <http://arxiv.org/abs/2601.13836v1>
- **Submitted**: 2026-01-20 10:47:20
- **Comment**: https://openmoss.github.io/FutureOmni
- **Topic Keywords**: rag
- **Reason**: This paper focuses on multimodal large language models and future forecasting from audio-visual cues, which is outside the scope of information retrieval and search technologies. While it involves some aspects of multimodal perception, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest.

#### Abstract
> Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (https://github.com/OpenMOSS/FutureOmni) and datasets (https://huggingface.co/datasets/OpenMOSS-Team/FutureOmni).

### 43. OptiSQL: Executable SQL Generation from Optical Tokens

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sifan Li, Hongkai Chen, Yujun Cai, Liyang Chen, Qingwen Ye, Yiwei Wang
- **URL**: <http://arxiv.org/abs/2601.13695v2>
- **Submitted**: 2026-01-20 07:49:29
- **Topic Keywords**: rag
- **Reason**: This paper focuses on executable SQL generation from optical tokens, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves natural language processing, the context is specific to text-to-SQL settings and does not align with the user's interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.

### 44. Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yue Guo, Fanfu Wang, Jianwei Lv, Xincheng Shi, Yuchen Li, Youya Wang, Yunsheng Zeng, Yujing Liu, Yunhao Qiao, Gen Li, Junfeng Wang, Bo Yuan
- **URL**: <http://arxiv.org/abs/2601.13690v1>
- **Submitted**: 2026-01-20 07:43:57
- **Topic Keywords**: retrieval
- **Reason**: This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves a Large Language Model, the focus is on clinical diagnostic inquiry and reasoning, which is outside the user's primary areas of interest.

#### Abstract
> Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance.

### 45. Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Mehrab Beikzadeh, Chenglin Hong, Cory J Cascalheira, Callisto Boka, Majid Sarrafzadeh, Ian W Holloway
- **URL**: <http://arxiv.org/abs/2601.13558v1>
- **Submitted**: 2026-01-20 03:28:50
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing, as it focuses on text analysis for public health interventions and does not address query understanding, ranking models, or user behavior modeling.

#### Abstract
> Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to heterosexual men. Text data collected from social media and dating applications may provide new opportunities for personalized public health interventions by enabling automatic identification of risk and protective behaviors. In this study, we evaluated whether text from social media and dating apps can be used to predict sexual risk behaviors, alcohol use, and pre-exposure prophylaxis (PrEP) uptake among MSM. With participant consent, we collected textual data and trained machine learning models using features derived from ChatGPT embeddings, BERT embeddings, LIWC, and a dictionary-based risk term approach. The models achieved strong performance in predicting monthly binge drinking and having more than five sexual partners, with F1 scores of 0.78, and moderate performance in predicting PrEP use and heavy drinking, with F1 scores of 0.64 and 0.63. These findings demonstrate that social media and dating app text data can provide valuable insights into risk and protective behaviors and highlight the potential of large language model-based methods to support scalable and personalized public health interventions for MSM.

### 46. The Hidden Toll of Social Media News: Causal Effects on Psychosocial Wellbeing

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Olivia Pal, Agam Goyal, Eshwar Chandrasekharan, Koustuv Saha
- **URL**: <http://arxiv.org/abs/2601.13487v1>
- **Submitted**: 2026-01-20 00:46:51
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. The study focuses on the psychosocial effects of social media news consumption, which is outside your primary areas of interest.

#### Abstract
> News consumption on social media has become ubiquitous, yet how different forms of engagement shape psychosocial outcomes remains unclear. To address this gap, we leveraged a large-scale dataset of ~26M posts and ~45M comments on the BlueSky platform, and conducted a quasi-experimental study, matching 81,345 Treated users exposed to News feeds with 83,711 Control users using stratified propensity score analysis. We examined psychosocial wellbeing, in terms of affective, behavioral, and cognitive outcomes. Our findings reveal that news engagement produces systematic trade-offs: increased depression, stress, and anxiety, yet decreased loneliness and increased social interaction on the platform. Regression models reveal that News feed bookmarking is associated with greater psychosocial deterioration compared to commenting or quoting, with magnitude differences exceeding tenfold. These per-engagement effects accumulate with repeated exposure, showing significant psychosocial impacts. Our work extends theories of news effects beyond crisis-centric frameworks by demonstrating that routine consumption creates distinct psychological dynamics depending on engagement type, and bears implications for tools and interventions for mitigating the psychosocial costs of news consumption on social media.

### 47. PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Aditya Thole, Anmol Agrawal, Arnav Ramamoorthy, Dhruv Kumar
- **URL**: <http://arxiv.org/abs/2601.13453v1>
- **Submitted**: 2026-01-19 23:11:02
- **Topic Keywords**: rag
- **Reason**: This paper focuses on multimodal explanations for numerical physics problem solving, using visual explanations and large language models. While it touches on the idea of generating high-quality content, it is not directly related to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Explaining numerical physics problems often requires more than text-based solutions; clear visual reasoning can substantially improve conceptual understanding. While large language models (LLMs) demonstrate strong performance on many physics questions in textual form, their ability to generate long, high-quality visual explanations remains insufficiently explored. In this work, we introduce PhysicsSolutionAgent (PSA), an autonomous agent that generates physics-problem explanation videos of up to six minutes using Manim animations. To evaluate the generated videos, we design an assessment pipeline that performs automated checks across 15 quantitative parameters and incorporates feedback from a vision-language model (VLM) to iteratively improve video quality. We evaluate PSA on 32 videos spanning numerical and theoretical physics problems. Our results reveal systematic differences in video quality depending on problem difficulty and whether the task is numerical or theoretical. Using GPT-5-mini, PSA achieves a 100% video-completion rate with an average automated score of 3.8/5. However, qualitative analysis and human inspection uncover both minor and major issues, including visual layout inconsistencies and errors in how visual content is interpreted during feedback. These findings expose key limitations in reliable Manim code generation and highlight broader challenges in multimodal reasoning and evaluation for visual explanations of numerical physics problems. Our work underscores the need for improved visual understanding, verification, and evaluation frameworks in future multimodal educational systems

### 48. Arab Voices: Mapping Standard and Dialectal Arabic Speech Technology

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Peter Sullivan, AbdelRahim Elmadany, Alcides Alcoba Inciarte, Muhammad Abdul-Mageed
- **URL**: <http://arxiv.org/abs/2601.13319v1>
- **Submitted**: 2026-01-19 19:02:40
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Arabic speech technology and introduces a standardized framework for dialectal Arabic ASR, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Dialectal Arabic (DA) speech data vary widely in domain coverage, dialect labeling practices, and recording conditions, complicating cross-dataset comparison and model evaluation. To characterize this landscape, we conduct a computational analysis of linguistic ``dialectness'' alongside objective proxies of audio quality on the training splits of widely used DA corpora. We find substantial heterogeneity both in acoustic conditions and in the strength and consistency of dialectal signals across datasets, underscoring the need for standardized characterization beyond coarse labels. To reduce fragmentation and support reproducible evaluation, we introduce Arab Voices, a standardized framework for DA ASR. Arab Voices provides unified access to 31 datasets spanning 14 dialects, with harmonized metadata and evaluation utilities. We further benchmark a range of recent ASR systems, establishing strong baselines for modern DA ASR.

### 49. Toward Efficient Agents: Memory, Tool learning, and Planning

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Xiaofang Yang, Lijun Li, Heng Zhou, Tong Zhu, Xiaoye Qu, Yuchen Fan, Qianshan Wei, Rui Ye, Li Kang, Yiran Qin, Zhiqiang Kou, Daizong Liu, Qi Li, Ning Ding, Siheng Chen, Jing Shao
- **URL**: <http://arxiv.org/abs/2601.14192v1>
- **Submitted**: 2026-01-20 17:51:56
- **Comment**: 35 pages, 200 references
- **Topic Keywords**: search
- **Reason**: This paper focuses on agentic systems, memory, tool learning, and planning, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on efficiency and optimization, the context is different from the user's areas of focus.

#### Abstract
> Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.

### 50. Generalization and Completeness of Stochastic Local Search Algorithms

- **LLM Score**: 0
- **Keyword Score**: 1
- **Authors**: Daniel Loscos, Narciso Marti-Oliet, Ismael Rodriguez
- **URL**: <http://arxiv.org/abs/2601.14212v1>
- **Submitted**: 2026-01-20 18:17:45
- **Comment**: This paper was published in Swarm and Evolutionary Computation. The present version is the author's accepted manuscript
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on Stochastic Local Search algorithms and their Turing-completeness, which is unrelated to your areas of expertise.

#### Abstract
> We generalize Stochastic Local Search (SLS) heuristics into a unique formal model. This model has two key components: a common structure designed to be as large as possible and a parametric structure intended to be as small as possible. Each heuristic is obtained by instantiating the parametric part in a different way. Particular instances for Genetic Algorithms (GA), Ant Colony Optimization (ACO), and Particle Swarm Optimization (PSO) are presented. Then, we use our model to prove the Turing-completeness of SLS algorithms in general. The proof uses our framework to construct a GA able to simulate any Turing machine. This Turing-completeness implies that determining any non-trivial property concerning the relationship between the inputs and the computed outputs is undecidable for GA and, by extension, for the general set of SLS methods (although not necessarily for each particular method). Similar proofs are more informally presented for PSO and ACO.

---

