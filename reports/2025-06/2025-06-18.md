# Daily Papers Report - 2025-06-18

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Identifying economic narratives in large text corpora -- An integrated approach using Large Language Models

- **LLM Score**: 7
- **Keyword Score**: 4
- **Authors**: Tobias Schmidt, Kai-Robin Lange, Matthias Reccius, Henrik M√ºller, Michael Roos, Carsten Jentsch
- **URL**: <http://arxiv.org/abs/2506.15041v1>
- **Submitted**: 2025-06-18 01:00:59
- **Comment**: 53 pages, 5 figures
- **Topic Keywords**: ir, search
- **Reason**: The paper explores the application of Large Language Models (LLMs) in identifying economic narratives in large text corpora, which is relevant to my interest in Natural Language Processing (NLP) and Information Retrieval (IR). The paper's focus on semantic understanding and narrative extraction aligns with my research interests. However, the paper's scope is more focused on economic narratives and LLMs, which is not directly related to my primary focus on search and query understanding.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Extracting economic narratives from texts using natural language processing techniques
- **Aim**: Evaluate the benefits of Large Language Models (LLMs) in extracting economic narratives from newspaper articles about inflation
- **Rationale**: State-of-the-art models like BERT lack deeper semantic understanding to distinguish economic narratives from other tasks
- **Ground**: Analysis of a corpus of newspaper articles about inflation using GPT-4o and comparison with gold-standard narratives produced by expert annotators
- **Experiment**: Comparison of GPT-4o outputs with gold-standard narratives to evaluate the model's ability to extract valid economic narratives
- **Takeaway**: GPT-4o can extract valid economic narratives in a structured format, but falls short of expert-level performance when handling complex documents and narratives

#### Abstract
> As interest in economic narratives has grown in recent years, so has the number of pipelines dedicated to extracting such narratives from texts. Pipelines often employ a mix of state-of-the-art natural language processing techniques, such as BERT, to tackle this task. While effective on foundational linguistic operations essential for narrative extraction, such models lack the deeper semantic understanding required to distinguish extracting economic narratives from merely conducting classic tasks like Semantic Role Labeling. Instead of relying on complex model pipelines, we evaluate the benefits of Large Language Models (LLMs) by analyzing a corpus of Wall Street Journal and New York Times newspaper articles about inflation. We apply a rigorous narrative definition and compare GPT-4o outputs to gold-standard narratives produced by expert annotators. Our results suggests that GPT-4o is capable of extracting valid economic narratives in a structured format, but still falls short of expert-level performance when handling complex documents and narratives. Given the novelty of LLMs in economic research, we also provide guidance for future work in economics and the social sciences that employs LLMs to pursue similar objectives.

---

### 2. MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs

- **LLM Score**: 6
- **Keyword Score**: 16
- **Authors**: Yongqi Fan, Yating Wang, Guandong Wang, Jie Zhai, Jingping Liu, Qi Ye, Tong Ruan
- **URL**: <http://arxiv.org/abs/2506.15215v1>
- **Submitted**: 2025-06-18 07:49:13
- **Topic Keywords**: ir, ranking, listwise, pointwise, pairwise, rank
- **Reason**: The paper's focus on open-ended question answering and evaluation methods for large language models is relevant to my interests in Natural Language Processing and Information Retrieval. The proposed MinosEval method's distinction between factoid and non-factoid questions and its use of different evaluation strategies for each type of question is particularly interesting. However, the paper's primary focus on LLMs and open-ended QA evaluation is not directly related to my interests in search technologies, ranking models, and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Open-Ended Question Answering Evaluation
- **Aim**: To propose a novel evaluation method, MinosEval, for open-ended question answering tasks that distinguishes between factoid and non-factoid questions
- **Rationale**: Existing LLM-based evaluation approaches are limited in their ability to accurately evaluate open-ended QA tasks, and a more effective and interpretable method is needed
- **Ground**: MinosEval consists of a two-stage approach that detects question type and applies adaptive scoring strategies for factoid and non-factoid questions
- **Experiment**: Experiments on four datasets, including two self-built datasets, demonstrate that MinosEval outperforms existing LLM-based evaluation approaches
- **Takeaway**: MinosEval provides a more effective and interpretable evaluation method for open-ended QA tasks, achieving high performance and strong generalizability

#### Abstract
> Open-ended question answering (QA) is a key task for evaluating the capabilities of large language models (LLMs). Compared to closed-ended QA, it demands longer answer statements, more nuanced reasoning processes, and diverse expressions, making refined and interpretable automatic evaluation both crucial and challenging. Traditional metrics like ROUGE and BERTScore struggle to capture semantic similarities due to different patterns between model responses and reference answers. Current LLM-based evaluation approaches, such as pairwise or listwise comparisons of candidate answers, lack intuitive interpretability. While pointwise scoring of each response provides some descriptions, it fails to adapt across different question contents. Most notably, existing methods overlook the distinction between factoid and non-factoid questions. To address these challenges, we propose \textbf{MinosEval}, a novel evaluation method that first distinguishes open-ended questions and then ranks candidate answers using different evaluation strategies. For factoid questions, it applies an adaptive key-point scoring strategy, while for non-factoid questions, it uses an instance-aware listwise ranking strategy. Experiments on multiple open-ended QA datasets, including self-built ones with more candidate responses to complement community resources, show that MinosEval better aligns with human annotations and offers more interpretable results.

---

### 3. TopClustRAG at SIGIR 2025 LiveRAG Challenge

- **LLM Score**: 6
- **Keyword Score**: 13
- **Authors**: Juli Bakagianni, John Pavlopoulos, Aristidis Likas
- **URL**: <http://arxiv.org/abs/2506.15246v1>
- **Submitted**: 2025-06-18 08:24:27
- **Topic Keywords**: ir, rerank, relevance, rag, retrieval, rank
- **Reason**: The paper's focus on retrieval-augmented generation (RAG) and question answering over large-scale web corpora is relevant to the user's interests in Information Retrieval and Search technologies. The use of clustering and prompt aggregation is also related to the user's interest in ranking models and user behavior modeling. However, the paper's primary focus on question answering and large-scale web corpora is not directly related to the user's interest in e-commerce or recommender systems.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Retrieval-Augmented Generation (RAG) system for large-scale question answering over diverse web data
- **Aim**: To design a RAG system that can generate comprehensive and faithful answers to questions from web data
- **Rationale**: The system employs a hybrid retrieval strategy, K-Means clustering, and prompt aggregation to improve answer diversity, relevance, and faithfulness
- **Ground**: The system is grounded in the use of a large language model (LLM) and various evaluation metrics, including ROUGE-L, BERTScore F1, Correctness, and Faithfulness
- **Experiment**: The system is evaluated on the FineWeb Sample-10BT dataset and compared to three baselines, demonstrating its effectiveness in large-scale RAG systems
- **Takeaway**: The paper demonstrates the potential of clustering and prompt aggregation techniques to improve large language model grounding in RAG, and highlights the effectiveness of the TOPCLUSTRAG system

#### Abstract
> We present TopClustRAG, a retrieval-augmented generation (RAG) system developed for the LiveRAG Challenge, which evaluates end-to-end question answering over large-scale web corpora. Our system employs a hybrid retrieval strategy combining sparse and dense indices, followed by K-Means clustering to group semantically similar passages. Representative passages from each cluster are used to construct cluster-specific prompts for a large language model (LLM), generating intermediate answers that are filtered, reranked, and finally synthesized into a single, comprehensive response. This multi-stage pipeline enhances answer diversity, relevance, and faithfulness to retrieved evidence. Evaluated on the FineWeb Sample-10BT dataset, TopClustRAG ranked 2nd in faithfulness and 7th in correctness on the official leaderboard, demonstrating the effectiveness of clustering-based context filtering and prompt aggregation in large-scale RAG systems.

---

### 4. Lessons from Training Grounded LLMs with Verifiable Rewards

- **LLM Score**: 6
- **Keyword Score**: 9
- **Authors**: Shang Hong Sim, Tej Deep Pala, Vernon Toh, Hai Leong Chieu, Amir Zadeh, Chuan Li, Navonil Majumder, Soujanya Poria
- **URL**: <http://arxiv.org/abs/2506.15522v1>
- **Submitted**: 2025-06-18 14:58:13
- **Topic Keywords**: ir, queries, rag, retrieval
- **Reason**: The paper explores the application of reinforcement learning and internal reasoning to enhance grounding in large language models, which is related to query understanding and ranking models in Information Retrieval. While the focus is on language models and not directly on search technologies, the concepts and techniques discussed can be relevant to the broader field of IR. The paper's emphasis on verifiable rewards and outcome-driven RL also touches on the theme of real-time relevance optimization. However, the paper's primary focus on language models and generation tasks means it is not a direct match for the user's research interests.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Improving Trustworthiness and Groundedness of Large Language Models in Question-Answering Tasks
- **Aim**: To propose a two-stage reinforcement learning framework, Ground-GRPO, to improve the groundedness and trustworthiness of large language models in question-answering tasks
- **Rationale**: The importance of groundedness in language models, as excessively high answer ratios often correlate with lower refusal-grounding and citation quality
- **Ground**: The study evaluates the performance of Ground-GRPO on various models and datasets, showing significant improvements in handling unanswerable queries and generating well-cited responses
- **Experiment**: The authors introduce a comprehensive evaluation framework for assessing the trustworthiness of model responses, and analyze performance trends across different training data sizes for three question-answering datasets
- **Takeaway**: The key takeaways include the effectiveness of Ground-GRPO in improving trustworthiness and groundedness, the benefits of reasoning models, staged training, and distillation, and recommendations for improving the performance of Reasoning-Augmented Generation systems

#### Abstract
> Generating grounded and trustworthy responses remains a key challenge for large language models (LLMs). While retrieval-augmented generation (RAG) with citation-based grounding holds promise, instruction-tuned models frequently fail even in straightforward scenarios: missing explicitly stated answers, citing incorrectly, or refusing when evidence is available. In this work, we explore how reinforcement learning (RL) and internal reasoning can enhance grounding in LLMs. We use the GRPO (Group Relative Policy Optimization) method to train models using verifiable outcome-based rewards targeting answer correctness, citation sufficiency, and refusal quality, without requiring gold reasoning traces or expensive annotations. Through comprehensive experiments across ASQA, QAMPARI, ELI5, and ExpertQA we show that reasoning-augmented models significantly outperform instruction-only variants, especially in handling unanswerable queries and generating well-cited responses. A two-stage training setup, first optimizing answer and citation behavior and then refusal, further improves grounding by stabilizing the learning signal. Additionally, we revisit instruction tuning via GPT-4 distillation and find that combining it with GRPO enhances performance on long-form, generative QA tasks. Overall, our findings highlight the value of reasoning, stage-wise optimization, and outcome-driven RL for building more verifiable and reliable LLMs.

---

### 5. Context-Informed Grounding Supervision

- **LLM Score**: 6
- **Keyword Score**: 5
- **Authors**: Hyunji Lee, Seunghyun Yoon, Yunjae Won, Hanseok Oh, Geewook Kim, Trung Bui, Franck Dernoncourt, Elias Stengel-Eskin, Mohit Bansal, Minjoon Seo
- **URL**: <http://arxiv.org/abs/2506.15480v1>
- **Submitted**: 2025-06-18 14:13:56
- **Topic Keywords**: ir, rag
- **Reason**: The paper explores the concept of grounding in language models, which is related to query understanding and ranking models in Information Retrieval. The focus on post-training supervision and the use of external context is also relevant to user behavior modeling in search. However, the paper's primary focus on language models and generation tasks is not directly related to my interests in search and recommender systems. The connection to NLP and data mining is more tenuous, as the paper's scope is narrower than my broader interests in these areas.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Context-Informed Grounding Supervision (CINGS) for Large Language Models
- **Aim**: Improve the grounding ability of large language models (LLMs) in both text-only and multimodal settings
- **Rationale**: Reduce the model's reliance on prior knowledge and amplify the effect of external context
- **Ground**: CINGS outperforms standard instruction tuning on 11 information-seeking datasets in the text domain and reduces hallucinations across four benchmarks in the vision-language domain
- **Experiment**: Comparing CINGS to standard instruction tuning, AdaCAD, and CORG, using evaluation metrics such as D-F1, answer accuracy, and normalized answer scores
- **Takeaway**: CINGS is an effective approach for improving the grounding ability of LLMs, leading to more accurate and factually consistent responses

#### Abstract
> Large language models (LLMs) are often supplemented with external knowledge to provide information not encoded in their parameters or to reduce hallucination. In such cases, we expect the model to generate responses by grounding its response in the provided external context. However, prior work has shown that simply appending context at inference time does not ensure grounded generation. To address this, we propose Context-INformed Grounding Supervision (CINGS), a post-training supervision in which the model is trained with relevant context prepended to the response, while computing the loss only over the response tokens and masking out the context. Our experiments demonstrate that models trained with CINGS exhibit stronger grounding in both textual and visual domains compared to standard instruction-tuned models. In the text domain, CINGS outperforms other training methods across 11 information-seeking datasets and is complementary to inference-time grounding techniques. In the vision-language domain, replacing a vision-language model's LLM backbone with a CINGS-trained model reduces hallucinations across four benchmarks and maintains factual consistency throughout the generated response. This improved grounding comes without degradation in general downstream performance. Finally, we analyze the mechanism underlying the enhanced grounding in CINGS and find that it induces a shift in the model's prior knowledge and behavior, implicitly encouraging greater reliance on the external context.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 1. Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework

- **LLM Score**: 6
- **Keyword Score**: 4
- **Authors**: Laura Kopf, Nils Feldhus, Kirill Bykov, Philine Lou Bommer, Anna Hedstr√∂m, Marina M. -C. H√∂hne, Oliver Eberle
- **URL**: <http://arxiv.org/abs/2506.15538v1>
- **Reason**: The paper's focus on neural network feature description and polysemanticity is relevant to my interests in NLP and deep learning. However, it does not directly relate to my primary focus on search and query understanding. The paper's methodology and results are interesting, but the application to language models is not directly applicable to my research interests.

---

### 2. Targeted Lexical Injection: Unlocking Latent Cross-Lingual Alignment in Lugha-Llama via Early-Layer LoRA Fine-Tuning

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Stanley Ngugi
- **URL**: <http://arxiv.org/abs/2506.15415v1>
- **Reason**: The paper's focus on cross-lingual lexical alignment and fine-tuning of language models is relevant to Information Retrieval and Natural Language Processing, but it does not directly address query understanding, ranking models, or user behavior modeling. The paper's emphasis on low-resource languages and lexical alignment is not directly related to the user's background in e-commerce or interests in real-time relevance optimization.

---

### 3. Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form Generation

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Zongxia Li, Yapei Chang, Yuhang Zhou, Xiyang Wu, Zichao Liang, Yoo Yeon Sung, Jordan Lee Boyd-Graber
- **URL**: <http://arxiv.org/abs/2506.15068v1>
- **Reason**: The paper focuses on open-ended long-form generation and proposes a scoring model, PrefBERT, to evaluate and guide the training process. While it's related to Natural Language Processing (NLP), it's not directly related to Information Retrieval (IR) or Search technologies, which are the primary areas of interest. The paper's emphasis on semantic understanding and rewards is relevant, but the context is different from the user's focus on query understanding, ranking models, and user behavior modeling.

---

### 4. Multi-Interest Recommendation: A Survey

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Zihao Li, Qiang Chen, Lixin Zou, Aixin Sun, Chenliang Li
- **URL**: <http://arxiv.org/abs/2506.15284v1>
- **Reason**: The paper's title and abstract focus on recommendation systems, which is related to search technologies, but it does not specifically address query understanding, ranking models, or user behavior modeling, which are key areas of interest in your research. While the paper does mention extracting multiple interest representations from users' historical interactions, it does not delve into the deep semantic understanding and real-time relevance optimization that you are particularly interested in. The paper's focus is more on recommendation systems and their applications, rather than search technologies.

---

### 5. SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Chengye Wang, Yifei Shen, Zexi Kuang, Arman Cohan, Yilun Zhao
- **URL**: <http://arxiv.org/abs/2506.15569v1>
- **Reason**: The paper is related to Natural Language Processing (NLP) and multimodal scientific claim verification, which is a novel area that combines IR and NLP. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are the primary focus of your research interests. The paper's focus on foundation models and multimodal scientific literature tasks is not directly applicable to your e-commerce domain experience. While the paper touches on IR and NLP, it does not provide insights into query understanding, ranking models, or user behavior modeling, which are the core aspects of your research interests.

---

### 6. When and How Unlabeled Data Provably Improve In-Context Learning

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Yingcong Li, Xiangyu Chang, Muti Kara, Xiaofeng Liu, Amit Roy-Chowdhury, Samet Oymak
- **URL**: <http://arxiv.org/abs/2506.15329v1>
- **Reason**: The paper's focus on in-context learning and unlabeled data is somewhat relevant to my research interests in information retrieval and search technologies, particularly in the context of query understanding and ranking models. However, the paper's emphasis on theoretical study and polynomial expressions is not directly applicable to my interests. The connection to Expectation Maximization and iterative pseudo-labeling is also not directly relevant to my research. While the paper's results on semi-supervised learning may have some indirect implications for search technologies, the relevance is limited.

---

### 7. Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Jing Yang Lee, Kong-Aik Lee, Woon-Seng Gan
- **URL**: <http://arxiv.org/abs/2506.15131v1>
- **Reason**: The paper's focus on open-domain dialogue and modeling the one-to-many property in language models is somewhat relevant to my research interests in Information Retrieval and Search technologies. However, the paper's primary focus on dialogue generation and response diversity is not directly related to my interests in query understanding, ranking models, and user behavior modeling. The paper's use of large language models (LLMs) is also not directly applicable to my work in e-commerce or recommender systems. While the paper's techniques and metrics may be of interest to some researchers in NLP, they do not align with my specific research goals and interests.

---

### 8. Advancing Loss Functions in Recommender Systems: A Comparative Study with a R√©nyi Divergence-Based Solution

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Shengjia Zhang, Jiawei Chen, Changdong Li, Sheng Zhou, Qihao Shi, Yan Feng, Chun Chen, Can Wang
- **URL**: <http://arxiv.org/abs/2506.15120v1>
- **Reason**: The paper focuses on recommender systems and loss functions, which is relevant to your interest in search and ranking models. However, it does not directly address query understanding, user behavior modeling, or deep semantic understanding, which are key aspects of your research interests. The paper's emphasis on recommender systems, while related to search, is not a primary focus of your research. The use of R√©nyi divergence in the proposed loss function is an interesting aspect, but it is not directly applicable to your areas of interest.

---

### 9. AutoRule: Reasoning Chain-of-thought Extracted Rule-based Rewards Improve Preference Learning

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Tevin Wang, Chenyan Xiong
- **URL**: <http://arxiv.org/abs/2506.15651v1>
- **Reason**: The paper's focus on reinforcement learning from human feedback (RLHF) and preference learning is somewhat relevant to search technologies, particularly in the context of user behavior modeling. However, the paper's emphasis on rule-based rewards and language models is not directly related to query understanding, ranking models, or click models, which are key areas of interest in search technologies. The paper's connection to NLP is also limited to language models, which is a peripheral interest. Overall, the paper's relevance to the user's research interests is moderate.

---

### 10. WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Negar Foroutan, Angelika Romanou, Matin Ansaripour, Julian Martin Eisenschlos, Karl Aberer, R√©mi Lebret
- **URL**: <http://arxiv.org/abs/2506.15594v1>
- **Reason**: The paper introduces a new benchmark for question answering over tables and charts, which is related to information retrieval and multimodal processing. However, the focus is on document understanding and multimodal reasoning, rather than search technologies or ranking models, which are the primary areas of interest. Additionally, the paper does not explicitly discuss query understanding, user behavior modeling, or real-time relevance optimization, which are key aspects of search technologies.

---

### 11. Next-User Retrieval: Enhancing Cold-Start Recommendations via Generative Next-User Modeling

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Yu-Ting Lan, Yang Huo, Yi Shen, Xiao Yang, Zuotao Liu
- **URL**: <http://arxiv.org/abs/2506.15267v1>
- **Reason**: The paper's focus on recommendation systems and cold-start problems is relevant to your interests in Information Retrieval and Search technologies. However, the paper's emphasis on lookalike algorithms and generative next-user modeling is more specific to recommender systems, which is not your primary focus. The paper's use of transformer-based models and interaction signals is also relevant to your interests in Natural Language Processing and data mining. However, the paper's abstract does not explicitly mention query understanding, ranking models, or user behavior modeling, which are key areas of interest for you.

---

### 12. ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning in LLMs

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Feng He, Zijun Chen, Xinnian Liang, Tingting Ma, Yunqi Qiu, Shuangzhi Wu, Junchi Yan
- **URL**: <http://arxiv.org/abs/2506.15211v1>
- **Reason**: The paper's focus on Large Language Models (LLMs) and reasoning capabilities is relevant to my interest in Natural Language Processing (NLP). However, the paper's primary focus on logical reasoning, planning, and general reasoning in LLMs is not directly related to my interests in Information Retrieval (IR) and Search technologies. While the paper's concepts, such as prototypes and reasoning patterns, may have some indirect relevance to query understanding and ranking models, the connection is not strong enough to warrant a higher score.

---

### 13. CC-LEARN: Cohort-based Consistency Learning

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Xiao Ye, Shaswat Shrivastava, Zhaonan Li, Jacob Dineen, Shijie Lu, Avneet Ahuja, Ming Shen, Zhikun Xu, Ben Zhou
- **URL**: <http://arxiv.org/abs/2506.15662v1>
- **Reason**: The paper introduces a reinforcement learning framework for improving the reliability of large language models' reasoning, which is relevant to the field of Natural Language Processing. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are key areas of interest in Information Retrieval. The paper's focus on large language models and reasoning stability is more aligned with NLP and AI research, but not specifically with search technologies or e-commerce domain.

---

### 14. DiscRec: Disentangled Semantic-Collaborative Modeling for Generative Recommendation

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Chang Liu, Yimeng Bai, Xiaoyan Zhao, Yang Zhang, Fuli Feng, Wenge Rong
- **URL**: <http://arxiv.org/abs/2506.15576v1>
- **Reason**: The paper's focus on generative recommendation and disentangled semantic-collaborative modeling is relevant to your interests in search and recommendation systems. However, the paper's emphasis on item-level position embeddings and dual-branch module may be more applicable to recommender systems rather than search technologies. Additionally, the paper's abstract does not explicitly mention query understanding, ranking models, or user behavior modeling, which are key areas of interest for you.

---

### 15. video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Changli Tang, Yixuan Li, Yudong Yang, Jimin Zhuang, Guangzhi Sun, Wei Li, Zejun Ma, Chao Zhang
- **URL**: <http://arxiv.org/abs/2506.15220v1>
- **Reason**: The paper focuses on video captioning, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing, the primary application is in video understanding rather than search. The techniques and models presented may have some relevance to data mining, but the connection is indirect. The paper does not address ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest for the user.

---

### 16. Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Zhengyang Shan, Emily Ruth Diana, Jiawei Zhou
- **URL**: <http://arxiv.org/abs/2506.15568v1>
- **Reason**: The paper's focus on large language models and gender inclusivity is relevant to NLP, but it does not directly relate to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling, which are the primary areas of interest. The paper's scope is more focused on fairness and inclusivity in language models, which is a related but distinct area.

---

### 17. Research on Graph-Retrieval Augmented Generation Based on Historical Text Knowledge Graphs

- **LLM Score**: 2
- **Keyword Score**: 9
- **Authors**: Yang Fan, Zhang Qi, Xing Wenqian, Liu Chang, Liu Liu
- **URL**: <http://arxiv.org/abs/2506.15241v1>
- **Reason**: The paper's focus on graph-retrieval augmented generation and historical text knowledge graphs is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper does mention relation extraction and knowledge extraction, the context is historical text analysis and computational humanities, which is not a primary focus of the user's research. The paper's relevance to the user's interests is limited.

---

### 18. SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling

- **LLM Score**: 2
- **Keyword Score**: 8
- **Authors**: Md Imbesat Hassan Rizvi, Xiaodan Zhu, Iryna Gurevych
- **URL**: <http://arxiv.org/abs/2506.15498v1>
- **Reason**: The paper's focus on process supervision and reward modeling for Large Language Models (LLMs) is not directly related to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper does involve NLP and machine learning, the specific application and methodology are not aligned with your areas of interest.

---

### 19. AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Zhouhong Gu, Xiaoxuan Zhu, Yin Cai, Hao Shen, Xingzhou Chen, Qingyi Wang, Jialin Li, Xiaoran Shi, Haoran Guo, Wenxuan Huang, Hongwei Feng, Yanghua Xiao, Zheyu Ye, Yao Hu, Shaosheng Cao
- **URL**: <http://arxiv.org/abs/2506.15451v1>
- **Reason**: The paper is not directly related to Information Retrieval (IR) or Search technologies, as it focuses on multi-agent systems and large language models. While it mentions 'user queries', the context is different from query understanding and ranking models. The paper's topics, such as social simulation and complex task resolution, are not within the user's primary research interests. The only slight connection is the mention of 'queries', but it's not a strong enough link to warrant a higher score.

---

### 20. SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models' Knowledge of Indian Culture

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Arijit Maji, Raghvendra Kumar, Akash Ghosh, Anushka, Sriparna Saha
- **URL**: <http://arxiv.org/abs/2506.15355v1>
- **Reason**: The paper's focus on language models' comprehension of Indian culture is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper does involve language models, its scope is limited to evaluating their cultural understanding, which is not a primary focus of the user's research. The paper's relevance to the user's interests is low.

---

### 21. SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Anuradha Chopra, Abhinaba Roy, Dorien Herremans
- **URL**: <http://arxiv.org/abs/2506.15154v1>
- **Reason**: The paper is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves text generation and captioning, the focus is on music AI and music feature detection, which is not a primary area of interest. The paper's relevance is low, but it may have some tangential connections to the user's background in e-commerce and data mining.

---

### 22. CKD-EHR:Clinical Knowledge Distillation for Electronic Health Records

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Junke Wang, Hongshun Ling, Li Zhang, Longqian Zhang, Fang Wang, Yuan Gao, Zhi Li
- **URL**: <http://arxiv.org/abs/2506.15118v1>
- **Reason**: The paper's focus on Clinical Knowledge Distillation for Electronic Health Records is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper does involve language models and knowledge distillation, the context is medical and clinical, which is not a primary area of interest for the user. The paper's relevance to the user's research is limited, and the score is low.

---

### 23. GenRecal: Generation after Recalibration from Large to Small Vision-Language Models

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Byung-Kwan Lee, Ryo Hachiuma, Yong Man Ro, Yu-Chiang Frank Wang, Yueh-Hua Wu
- **URL**: <http://arxiv.org/abs/2506.15681v1>
- **Reason**: The paper focuses on vision-language models and distillation, which is not directly related to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions language models, the context is different from your primary focus on query understanding, ranking models, and user behavior modeling. The paper's relevance is low.

---

### 24. DiscoSG: Towards Discourse-Level Text Scene Graph Parsing through Iterative Graph Refinement

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Shaoqing Lin, Chong Teng, Fei Li, Donghong Ji, Lizhen Qu, Zhuang Li
- **URL**: <http://arxiv.org/abs/2506.15583v1>
- **Reason**: The paper's focus on Vision-Language Models and text scene graph parsing is not directly related to Information Retrieval, Search technologies, or Natural Language Processing, which are the primary areas of interest. While the paper does involve text processing and graph refinement, the context is specific to visual description generation and not relevant to query understanding, ranking models, or user behavior modeling.

---

### 25. Factorized RVQ-GAN For Disentangled Speech Tokenization

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Sameer Khurana, Dominik Klement, Antoine Laurent, Dominik Bobos, Juraj Novosad, Peter Gazdik, Ellen Zhang, Zili Huang, Amir Hussein, Ricard Marxer, Yoshiki Masuyama, Ryo Aihara, Chiori Hori, Francois G. Germain, Gordon Wichern, Jonathan Le Roux
- **URL**: <http://arxiv.org/abs/2506.15456v1>
- **Reason**: The paper's focus on speech tokenization and disentangled token sets is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions knowledge distillation objectives and encoder models, the context is specific to speech processing and does not align with the user's interests in query understanding, ranking models, and user behavior modeling.

---

### 26. Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Yining Hong, Rui Sun, Bingxuan Li, Xingcheng Yao, Maxine Wu, Alexander Chien, Da Yin, Ying Nian Wu, Zhecan James Wang, Kai-Wei Chang
- **URL**: <http://arxiv.org/abs/2506.15677v1>
- **Reason**: The paper's focus on embodied cognition and web-scale knowledge access is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. While the paper does mention web interfaces and knowledge access, the context is different and the techniques and concepts presented are not applicable to the user's areas of interest. The paper's relevance to Natural Language Processing and data mining is also limited, as it does not involve language processing or data mining techniques. The user's primary focus on search, especially in areas that require deep semantic understanding and real-time relevance optimization, is not addressed in this paper.

---

### 27. LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Gabrel J. Perin, Runjin Chen, Xuxi Chen, Nina S. T. Hirata, Zhangyang Wang, Junyuan Hong
- **URL**: <http://arxiv.org/abs/2506.15606v1>
- **Reason**: The paper's focus on Large Language Models (LLMs) and fine-tuning is not directly related to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on safety concerns, the methods and techniques proposed are not relevant to your areas of expertise.

---

### 28. RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Xinnuo Xu, Rachel Lawrence, Kshitij Dubey, Atharva Pandey, Risa Ueno, Fabian Falck, Aditya V. Nori, Rahul Sharma, Amit Sharma, Javier Gonzalez
- **URL**: <http://arxiv.org/abs/2506.15455v1>
- **Reason**: The paper focuses on Large Language Models and their ability to reason, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions symbolic representation, it is not in the context of search or ranking models. The paper's relevance to your research interests is limited, and it does not seem to address your primary focus on search, especially in areas that require deep semantic understanding and real-time relevance optimization.

---

### 29. COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Raghvendra Kumar, S. A. Mohammed Salman, Aryan Sahu, Tridib Nandi, Pragathi Y. P., Sriparna Saha, Jose G. Moreno
- **URL**: <http://arxiv.org/abs/2506.15372v1>
- **Reason**: The paper's focus on summarization and headline generation in Indian languages, as well as its multimodal and multilingual approach, do not directly align with your research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper does mention NLP and language models, the specific topics and applications are not relevant to your areas of focus.

---

### 30. Cohort Discovery: A Survey on LLM-Assisted Clinical Trial Recruitment

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Shrestha Ghosh, Moritz Schneider, Carina Reinicke, Carsten Eickhoff
- **URL**: <http://arxiv.org/abs/2506.15301v1>
- **Reason**: The paper's focus on LLMs and clinical trial recruitment is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on NLP, it is primarily concerned with applying LLMs to a specific domain (clinical trial recruitment) rather than exploring general NLP or IR concepts. The user's interests in query understanding, ranking models, and user behavior modeling are not addressed in this paper.

---

### 31. PhantomHunter: Detecting Unseen Privately-Tuned LLM-Generated Text via Family-Aware Learning

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yuhui Shi, Yehan Yang, Qiang Sheng, Hao Mi, Beizhe Hu, Chaoxi Xu, Juan Cao
- **URL**: <http://arxiv.org/abs/2506.15683v1>
- **Reason**: The paper focuses on detecting LLM-generated text, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves Natural Language Processing (NLP), the specific application is not relevant to the user's interests in search, ranking models, or user behavior modeling. The paper's focus on privately-tuned LLMs and family-aware learning is also not directly applicable to the user's research areas.

---

### 32. Dense SAE Latents Are Features, Not Bugs

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Xiaoqing Sun, Alessandro Stolfo, Joshua Engels, Ben Wu, Senthooran Rajamanoharan, Mrinmaya Sachan, Max Tegmark
- **URL**: <http://arxiv.org/abs/2506.15679v1>
- **Reason**: The paper's focus on sparse autoencoders and their latents does not seem to be directly related to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, data mining, or recommender systems. While the paper does involve language models, the topic is more focused on the internal workings of the models rather than their application to search or retrieval tasks.

---

### 33. Gender-Neutral Machine Translation Strategies in Practice

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Hillary Dawkins, Isar Nejadgholi, Chi-kiu Lo
- **URL**: <http://arxiv.org/abs/2506.15676v1>
- **Reason**: The paper's focus on machine translation strategies for gender neutrality is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on the topic of language processing, it is primarily concerned with machine translation and does not address query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user.

---

### 34. Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Tommaso Green, Martin Gubri, Haritz Puerto, Sangdoo Yun, Seong Joon Oh
- **URL**: <http://arxiv.org/abs/2506.15674v1>
- **Reason**: The paper's focus on privacy leakage in reasoning models is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. While the paper touches on the idea of 'thinking' and 'reasoning', it does not explore these concepts in the context of search or IR. The paper's relevance to NLP is also limited, as it primarily deals with privacy concerns rather than language understanding or processing. The user's background in e-commerce and interest in recommender systems are also not directly addressed in this paper.

---

### 35. The Compositional Architecture of Regret in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Xiangxiang Cui, Shu Yang, Tianjin Huang, Wanyu Lin, Lijie Hu, Di Wang
- **URL**: <http://arxiv.org/abs/2506.15617v1>
- **Reason**: The paper's focus on Large Language Models and regret expressions in their outputs is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on neural networks and information processing, the abstract does not mention ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest in your research. The paper's relevance to your interests is limited, and it does not appear to be a strong match.

---

### 36. From Model to Classroom: Evaluating Generated MCQs for Portuguese with Narrative and Difficulty Concerns

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Bernardo Leite, Henrique Lopes Cardoso, Pedro Pinto, Abel Ferreira, Lu√≠s Abreu, Isabel Rangel, Sandra Monteiro
- **URL**: <http://arxiv.org/abs/2506.15598v1>
- **Reason**: The paper's focus on MCQ generation and evaluation for Portuguese is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on AI-generated content, it does not explore query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user. The paper's relevance is limited to the user's background in e-commerce and NLP, but the specific application and language used are not directly applicable to the user's research goals.

---

### 37. PredGen: Accelerated Inference of Large Language Models through Input-Time Speculation for Real-Time Speech Interaction

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Shufan Li, Aditya Grover
- **URL**: <http://arxiv.org/abs/2506.15556v1>
- **Reason**: The paper's focus on large language models, real-time speech interaction, and latency reduction is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper does involve language models, the context is different and the techniques proposed are not applicable to the user's areas of interest.

---

### 38. Enhancing Hyperbole and Metaphor Detection with Their Bidirectional Dynamic Interaction and Emotion Knowledge

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Li Zheng, Sihang Wang, Hao Fei, Zuquan Peng, Fei Li, Jianming Fu, Chong Teng, Donghong Ji
- **URL**: <http://arxiv.org/abs/2506.15504v1>
- **Reason**: The paper focuses on hyperbole and metaphor detection in natural language processing, which is a related topic to NLP. However, it does not directly relate to information retrieval, search technologies, or query understanding, which are the primary areas of interest. The paper's emphasis on emotion analysis and domain mapping is also not directly applicable to the user's research interests.

---

### 39. Understanding GUI Agent Localization Biases through Logit Sharpness

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Xingjian Tao, Yiwei Wang, Yujun Cai, Zhicheng Yang, Jing Tang
- **URL**: <http://arxiv.org/abs/2506.15425v1>
- **Reason**: The paper's focus on GUI agent localization biases and multimodal large language models is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on the topic of model uncertainty and evaluation, it does not address query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user.

---

### 40. DeVisE: Behavioral Testing of Medical Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Camila Zurdo Tagliabue, Heloisa Oss Boll, Aykut Erdem, Erkut Erdem, Iacer Calixto
- **URL**: <http://arxiv.org/abs/2506.15339v1>
- **Reason**: The paper focuses on evaluating the clinical understanding of large language models in a medical context, using behavioral testing and counterfactual reasoning. While it touches on the topic of model behavior, it does not directly relate to query understanding, ranking models, or user behavior modeling in the context of search technologies, which are the primary areas of interest. The paper's focus on medical language models and clinical decision support also diverges from the e-commerce domain. Although it does mention fairness-aware evaluation, which is a related topic, the overall relevance to the user's research interests is limited.

---

### 41. Thunder-DeID: Accurate and Efficient De-identification Framework for Korean Court Judgments

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Sungen Hahm, Heejin Kim, Gyuseong Lee, Hyunji Park, Jaejin Lee
- **URL**: <http://arxiv.org/abs/2506.15266v1>
- **Reason**: The paper is not directly related to the user's research interests in Information Retrieval, Search technologies, Query understanding, Ranking models, User behavior modeling, Natural Language Processing, Data mining, or Recommender systems. The paper focuses on De-identification of court judgments, which is a specific domain and task, and does not involve the user's areas of interest. The paper's use of deep neural networks is also not directly relevant to the user's interests.

---

### 42. Lost in Variation? Evaluating NLI Performance in Basque and Spanish Geographical Variants

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jaione Bengoetxea, Itziar Gonzalez-Dios, Rodrigo Agerri
- **URL**: <http://arxiv.org/abs/2506.15239v1>
- **Reason**: The paper's focus on Natural Language Inference (NLI) and language varieties is not directly related to your research interests in Information Retrieval, Search technologies, and query understanding. While it touches on NLP, the specific topic of linguistic variation and NLI is not relevant to your primary focus on search and real-time relevance optimization.

---

### 43. A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Andrea Cadeddu, Alessandro Chessa, Vincenzo De Leo, Gianni Fenu, Enrico Motta, Francesco Osborne, Diego Reforgiato Recupero, Angelo Salatino, Luca Secchi
- **URL**: <http://arxiv.org/abs/2506.15208v1>
- **Reason**: The paper's focus on large language models and text classification is relevant to NLP, but it does not directly relate to Information Retrieval, Search technologies, or query understanding, which are the primary areas of interest. The paper's application to Sustainable Development Goals is also outside the e-commerce domain, which is a secondary area of interest. While the paper touches on some general NLP concepts, it does not explore ranking models, user behavior modeling, or real-time relevance optimization, which are key aspects of the user's research interests.

---

### 44. Emergence of Primacy and Recency Effect in Mamba: A Mechanistic Point of View

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Muhammad Cendekia Airlangga, Hilal AlQuabeh, Munachiso S Nwadike, Kentaro Inui
- **URL**: <http://arxiv.org/abs/2506.15156v1>
- **Reason**: The paper's focus on memory in state-space language models and the mechanisms that give rise to primacy and recency effects is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper does involve language models, the context and methodology are quite different from the user's areas of interest.

---

### 45. Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yaxin Fan, Peifeng Li, Qiaoming Zhu
- **URL**: <http://arxiv.org/abs/2506.15081v1>
- **Reason**: The paper's focus on dialogue discourse parsing and discourse-aware utterance clarification is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper does involve NLP, the specific area of dialogue discourse parsing is not a primary focus of the user's research. The paper's relevance is low due to the lack of connection to query understanding, ranking models, and user behavior modeling, which are key areas of interest for the user.

---

### 46. Learning-Time Encoding Shapes Unlearning in LLMs

- **Keyword Score**: 3
- **Authors**: Ruihan Wu, Konstantin Garov, Kamalika Chaudhuri
- **URL**: <http://arxiv.org/abs/2506.15076v1>

---

### 47. An accurate and revised version of optical character recognition-based speech synthesis using LabVIEW

- **Keyword Score**: 3
- **Authors**: Prateek Mehta, Anasuya Patil
- **URL**: <http://arxiv.org/abs/2506.15029v1>

---

### 48. Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability

- **Keyword Score**: 2
- **Authors**: Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe
- **URL**: <http://arxiv.org/abs/2506.15629v1>

---

### 49. Minding the Politeness Gap in Cross-cultural Communication

- **Keyword Score**: 2
- **Authors**: Yuka Machino, Matthias Hofer, Max Siegel, Joshua B. Tenenbaum, Robert D. Hawkins
- **URL**: <http://arxiv.org/abs/2506.15623v1>

---

### 50. Thunder-Tok: Minimizing Tokens per Word in Tokenizing Korean Texts for Generative Language Models

- **Keyword Score**: 2
- **Authors**: Gyeongje Cho, Yeonkyoun So, Chanwoo Park, Sangmin Lee, Sungmok Jung, Jaejin Lee
- **URL**: <http://arxiv.org/abs/2506.15138v1>

---

### 51. Identifying social isolation themes in NVDRS text narratives using topic modeling and text-classification methods

- **Keyword Score**: 2
- **Authors**: Drew Walker, Swati Rajwal, Sudeshna Das, Snigdha Peddireddy, Abeed Sarker
- **URL**: <http://arxiv.org/abs/2506.15030v1>

---

