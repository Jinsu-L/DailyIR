# Daily Papers Report - 2026-01-25

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. LLM-based Semantic Search for Conversational Queries in E-commerce

- **LLM Score**: 8
- **Keyword Score**: 11
- **Authors**: Emad Siddiqui, Venkatesh Terikuti, Xuan Lu
- **URL**: <http://arxiv.org/abs/2601.16492v1>
- **Submitted**: 2026-01-23 06:35:28
- **Topic Keywords**: semantic search, queries, retrieval, commerce, e-commerce, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of query understanding and ranking models. The use of LLMs for semantic search and the focus on conversational queries aligns with your interests in deep semantic understanding and real-time relevance optimization. Although the paper is focused on e-commerce, its relevance to IR and NLP makes it a useful contribution to your field of study.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: LLM‚ÄëDriven Conversational Semantic Search for E‚ÄëCommerce
- **Aim**: Create a lightweight, intent‚Äëaligned retrieval system that fuses dense embeddings with automatic structured‚Äëfilter extraction to handle single‚Äëturn conversational queries containing numeric and categorical constraints.
- **Rationale**: Conversational search dominates e‚Äëcommerce traffic but keyword engines miss intent and constraints, leading to high abandonment. Fine‚Äëtuning embeddings is hard due to scarce labeled data and difficulty embedding structured attributes. An LLM‚Äëdriven pipeline can generate realistic query‚Äëproduct pairs and extract constraints, enabling intent‚Äëaligned retrieval.
- **Ground**: Data: ~1.3M Amazon Cell Phones & Accessories items (ID, title, description, specs, price, rating, sub‚Äëcategory). Synthetic queries: Gemini Flash generates ~10 conversational queries per product; ChatGPT enriches with constraint annotations. Models: Flan‚ÄëT5‚Äësmall for constraint extraction (99.8‚Äì99.9% per‚Äëdimension accuracy), Sentence‚ÄëTransformer multi‚Äëqa‚ÄëMiniLM‚ÄëL6 fine‚Äëtuned with MultipleNegativesRankingLoss on synthetic pairs. Indexing: FAISS IVF‚ÄëFlat; three‚Äëstage retrieval: (1) query embedding + constraint extraction, (2) pre‚Äëfilter catalog by constraints, (3) dense ranking of remaining items.
- **Experiment**: Evaluated on Amazon ESCI (151 conversational queries, 0‚Äì8 constraints). Metrics: Precision@1=0.32, @5=0.20, @10=0.13; Recall@1=0.16, @5=0.44, @10=0.57. Baselines: pre‚Äëtrained transformer, structured filter only, NER baseline. Dense‚Äëplus‚Äëstructured‚Äëfilter pipeline outperformed all baselines in recall@10 and ranking quality for k‚â§5.
- **Takeaway**: Dense embeddings alone cannot capture numeric/categorical constraints; structured filtering is essential. Flan‚ÄëT5‚Äësmall excels at constraint extraction, far surpassing NER. FAISS pre‚Äëfiltering reduces search space, enabling sub‚Äëmillisecond retrieval at scale. LLM‚Äëdriven synthetic query generation yields diverse, constraint‚Äërich training data, improving robustness. The framework is lightweight, scalable to millions of products, and provides a practical solution for conversational e‚Äëcommerce search.

#### Abstract
> Conversational user queries are increasingly challenging traditional e-commerce platforms, whose search systems are typically optimized for keyword-based queries. We present an LLM-based semantic search framework that effectively captures user intent from conversational queries by combining domain-specific embeddings with structured filters. To address the challenge of limited labeled data, we generate synthetic data using LLMs to guide the fine-tuning of two models: an embedding model that positions semantically similar products close together in the representation space, and a generative model for converting natural language queries into structured constraints. By combining similarity-based retrieval with constraint-based filtering, our framework achieves strong precision and recall across various settings compared to baseline approaches on a real-world dataset.

---

### 2. DeepEra: A Deep Evidence Reranking Agent for Scientific Retrieval-Augmented Generated Question Answering

- **LLM Score**: 8
- **Keyword Score**: 11
- **Authors**: Haotian Chen, Qingqing Long, Siyu Pu, Xiao Luo, Wei Ju, Meng Xiao, Yuanchun Zhou, Jianghua Zhao, Xuezhi Wang
- **URL**: <http://arxiv.org/abs/2601.16478v1>
- **Submitted**: 2026-01-23 06:19:08
- **Topic Keywords**: ranking, rerank, rag, retrieval, rank
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of query understanding and ranking models. The proposed Deep Evidence Reranking Agent (DeepEra) addresses a critical challenge in scientific question answering, which aligns with your focus on deep semantic understanding and real-time relevance optimization. Although the paper is primarily focused on scientific retrieval, it explores reranking methods that are applicable to broader IR domains.

#### Abstract
> With the rapid growth of scientific literature, scientific question answering (SciQA) has become increasingly critical for exploring and utilizing scientific knowledge. Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating knowledge from external sources, thereby providing credible evidence for scientific question answering. But existing retrieval and reranking methods remain vulnerable to passages that are semantically similar but logically irrelevant, often reducing factual reliability and amplifying hallucinations.To address this challenge, we propose a Deep Evidence Reranking Agent (DeepEra) that integrates step-by-step reasoning, enabling more precise evaluation of candidate passages beyond surface-level semantics. To support systematic evaluation, we construct SciRAG-SSLI (Scientific RAG - Semantically Similar but Logically Irrelevant), a large-scale dataset comprising about 300K SciQA instances across 10 subjects, constructed from 10M scientific corpus. The dataset combines naturally retrieved contexts with systematically generated distractors to test logical robustness and factual grounding. Comprehensive evaluations confirm that our approach achieves superior retrieval performance compared to leading rerankers. To our knowledge, this work is the first to comprehensively study and empirically validate innegligible SSLI issues in two-stage RAG frameworks.

---

### 3. Navigating the Shift: A Comparative Analysis of Web Search and Generative AI Response Generation

- **LLM Score**: 8
- **Keyword Score**: 5
- **Authors**: Mahe Chen, Xiaoxuan Wang, Kaiwen Chen, Nick Koudas
- **URL**: <http://arxiv.org/abs/2601.16858v1>
- **Submitted**: 2026-01-23 16:06:18
- **Topic Keywords**: query, web search, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of query understanding and ranking models. The analysis of generative AI response generation and its comparison to traditional web search results aligns with your focus on deep semantic understanding and real-time relevance optimization. The paper also touches on the emerging field of Answer Engine Optimization (AEO), which may be of interest to you.

#### Abstract
> The rise of generative AI as a primary information source presents a paradigm shift from traditional web search. This paper presents a large-scale empirical study quantifying the fundamental differences between the results returned by Google Search and leading generative AI services. We analyze multiple dimensions, demonstrating that AI-generated answers and web search results diverge significantly in their consulted source domains, the typology of these domains (e.g., earned media vs. owned, social), query intent and the freshness of the information provided. We then investigate the role of LLM pre-training as a key factor shaping these differences, analyzing how this intrinsic knowledge base interacts with and influences real-time web search when enabled. Our findings reveal the distinct mechanics of these two information ecosystems, leading to critical observations on the emergent field of Answer Engine Optimization (AEO) and its contrast with traditional Search Engine Optimization (SEO).

---

### 4. Information Representation Fairness in Long-Document Embeddings: The Peculiar Interaction of Positional and Language Bias

- **LLM Score**: 7
- **Keyword Score**: 1
- **Authors**: Elias Schuhmacher, Andrianos Michail, Juri Opitz, Rico Sennrich, Simon Clematide
- **URL**: <http://arxiv.org/abs/2601.16934v1>
- **Submitted**: 2026-01-23 17:48:31
- **Topic Keywords**: search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the area of deep semantic understanding and real-time relevance optimization. The focus on positional and language biases in document embeddings is relevant to query understanding and ranking models, but it's not a central match to your primary research themes. The paper's emphasis on fairness and attention calibration is also somewhat related to your interests in NLP and data mining.

#### Abstract
> To be discoverable in an embedding-based search process, each part of a document should be reflected in its embedding representation. To quantify any potential reflection biases, we introduce a permutation-based evaluation framework. With this, we observe that state-of-the-art embedding models exhibit systematic positional and language biases when documents are longer and consist of multiple segments. Specifically, early segments and segments in higher-resource languages like English are over-represented, while later segments and segments in lower-resource languages are marginalized. In our further analysis, we find that the positional bias stems from front-loaded attention distributions in pooling-token embeddings, where early tokens receive more attention. To mitigate this issue, we introduce an inference-time attention calibration method that redistributes attention more evenly across document positions, increasing discoverabiltiy of later segments. Our evaluation framework and attention calibration is available at https://github.com/impresso/fair-sentence-transformers

---

### 5. From Atom to Community: Structured and Evolving Agent Memory for User Behavior Modeling

- **LLM Score**: 6
- **Keyword Score**: 5
- **Authors**: Yuxin Liao, Le Wu, Min Hou, Yu Wang, Han Wu, Meng Wang
- **URL**: <http://arxiv.org/abs/2601.16872v1>
- **Submitted**: 2026-01-23 16:24:57
- **Topic Keywords**: user behavior, click, recommend
- **Reason**: This paper presents a novel framework for user behavior modeling, STEAM, which decomposes preferences into atomic memory units and organizes similar memories across users into communities. While it is related to query understanding and user behavior modeling, it does not directly address ranking models or click models, which are core areas of interest. However, the paper's focus on deep semantic understanding and real-time relevance optimization makes it somewhat relevant to your research interests.

#### Abstract
> User behavior modeling lies at the heart of personalized applications like recommender systems. With LLM-based agents, user preference representation has evolved from latent embeddings to semantic memory. While existing memory mechanisms show promise in textual dialogues, modeling non-textual behaviors remains challenging, as preferences must be inferred from implicit signals like clicks without ground truth supervision. Current approaches rely on a single unstructured summary, updated through simple overwriting. However, this is suboptimal: users exhibit multi-faceted interests that get conflated, preferences evolve yet naive overwriting causes forgetting, and sparse individual interactions necessitate collaborative signals. We present STEAM (\textit{\textbf{ST}ructured and \textbf{E}volving \textbf{A}gent \textbf{M}emory}), a novel framework that reimagines how agent memory is organized and updated. STEAM decomposes preferences into atomic memory units, each capturing a distinct interest dimension with explicit links to observed behaviors. To exploit collaborative patterns, STEAM organizes similar memories across users into communities and generates prototype memories for signal propagation. The framework further incorporates adaptive evolution mechanisms, including consolidation for refining memories and formation for capturing emerging interests. Experiments on three real-world datasets demonstrate that STEAM substantially outperforms state-of-the-art baselines in recommendation accuracy, simulation fidelity, and diversity.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. SearchLLM: Detecting LLM Paraphrased Text by Measuring the Similarity with Regeneration of the Candidate Source via Search Engine

- **LLM Score**: 6
- **Keyword Score**: 3
- **Authors**: Hoang-Quoc Nguyen-Son, Minh-Son Dao, Koji Zettsu
- **URL**: <http://arxiv.org/abs/2601.16512v1>
- **Submitted**: 2026-01-23 07:18:30
- **Comment**: EACL 2026 camera ready (Main Track)
- **Topic Keywords**: rag, search
- **Reason**: The paper explores a novel approach to detecting LLM-paraphrased text, leveraging search engine capabilities. While it touches on information retrieval aspects, its primary focus is on NLP and text analysis, which aligns with your interests in query understanding and deep semantic understanding. However, the specific application domain and focus on LLMs and paraphrasing attacks are somewhat tangential to your core research themes in IR and search technologies.

#### Abstract
> With the advent of large language models (LLMs), it has become common practice for users to draft text and utilize LLMs to enhance its quality through paraphrasing. However, this process can sometimes result in the loss or distortion of the original intended meaning. Due to the human-like quality of LLM-generated text, traditional detection methods often fail, particularly when text is paraphrased to closely mimic original content. In response to these challenges, we propose a novel approach named SearchLLM, designed to identify LLM-paraphrased text by leveraging search engine capabilities to locate potential original text sources. By analyzing similarities between the input and regenerated versions of candidate sources, SearchLLM effectively distinguishes LLM-paraphrased content. SearchLLM is designed as a proxy layer, allowing seamless integration with existing detectors to enhance their performance. Experimental results across various LLMs demonstrate that SearchLLM consistently enhances the accuracy of recent detectors in detecting LLM-paraphrased text that closely mimics original content. Furthermore, SearchLLM also helps the detectors prevent paraphrasing attacks.

### 7. Graph-Anchored Knowledge Indexing for Retrieval-Augmented Generation

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Zhenghao Liu, Mingyan Wu, Xinze Li, Yukun Yan, Shuo Wang, Cheng Yang, Minghe Yu, Zheni Zeng, Maosong Sun
- **URL**: <http://arxiv.org/abs/2601.16462v1>
- **Submitted**: 2026-01-23 05:41:05
- **Topic Keywords**: queries, rag, retrieval
- **Reason**: This paper focuses on Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs), which is somewhat related to your interests in Information Retrieval and Search technologies. However, the primary focus on knowledge indexing and graph structures is not directly aligned with your core research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Retrieval-Augmented Generation (RAG) has emerged as a dominant paradigm for mitigating hallucinations in Large Language Models (LLMs) by incorporating external knowledge. Nevertheless, effectively integrating and interpreting key evidence scattered across noisy documents remains a critical challenge for existing RAG systems. In this paper, we propose GraphAnchor, a novel Graph-Anchored Knowledge Indexing approach that reconceptualizes graph structures from static knowledge representations into active, evolving knowledge indices. GraphAnchor incrementally updates a graph during iterative retrieval to anchor salient entities and relations, yielding a structured index that guides the LLM in evaluating knowledge sufficiency and formulating subsequent subqueries. The final answer is generated by jointly leveraging all retrieved documents and the final evolved graph. Experiments on four multi-hop question answering benchmarks demonstrate the effectiveness of GraphAnchor, and reveal that GraphAnchor modulates the LLM's attention to more effectively associate key information distributed in retrieved documents. All code and data are available at https://github.com/NEUIR/GraphAnchor.

### 8. PI2I: A Personalized Item-Based Collaborative Filtering Retrieval Framework

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Shaoqing Wang, Yingcai Ma, Kairui Fu, Ziyang Wang, Dunxian Huang, Yuliang Yan, Jian Wu
- **URL**: <http://arxiv.org/abs/2601.16815v1>
- **Submitted**: 2026-01-23 15:10:39
- **Comment**: Published on WWW'26: In Proceedings of the ACM Web Conference 2026
- **Topic Keywords**: retrieval, recommend, personalization, search
- **Reason**: The paper focuses on a personalized item-based collaborative filtering framework, which is somewhat related to the user's interests in Information Retrieval and recommender systems. However, the emphasis on collaborative filtering and item-to-item interactions is not a central match for the user's primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Efficiently selecting relevant content from vast candidate pools is a critical challenge in modern recommender systems. Traditional methods, such as item-to-item collaborative filtering (CF) and two-tower models, often fall short in capturing the complex user-item interactions due to uniform truncation strategies and overdue user-item crossing. To address these limitations, we propose Personalized Item-to-Item (PI2I), a novel two-stage retrieval framework that enhances the personalization capabilities of CF. In the first Indexer Building Stage (IBS), we optimize the retrieval pool by relaxing truncation thresholds to maximize Hit Rate, thereby temporarily retaining more items users might be interested in. In the second Personalized Retrieval Stage (PRS), we introduce an interactive scoring model to overcome the limitations of inner product calculations, allowing for richer modeling of intricate user-item interactions. Additionally, we construct negative samples based on the trigger-target (item-to-item) relationship, ensuring consistency between offline training and online inference. Offline experiments on large-scale real-world datasets demonstrate that PI2I outperforms traditional CF methods and rivals Two-Tower models. Deployed in the "Guess You Like" section on Taobao, PI2I achieved a 1.05% increase in online transaction rates. In addition, we have released a large-scale recommendation dataset collected from Taobao, containing 130 million real-world user interactions used in the experiments of this paper. The dataset is publicly available at https://huggingface.co/datasets/PI2I/PI2I, which could serve as a valuable benchmark for the research community.

### 9. LLM-powered Real-time Patent Citation Recommendation for Financial Technologies

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Tianang Deng, Yu Deng, Tianchen Gao, Yonghong Hu, Rui Pan
- **URL**: <http://arxiv.org/abs/2601.16775v1>
- **Submitted**: 2026-01-23 14:21:30
- **Topic Keywords**: retrieval, recommend, rank, search
- **Reason**: The paper is somewhat related to information retrieval, specifically patent citation recommendation, but it does not align with the user's core research themes of query understanding, ranking models, and user behavior modeling. While it involves deep semantic understanding and real-time relevance optimization, the focus is on patent retrieval rather than general search technologies.

#### Abstract
> Rapid financial innovation has been accompanied by a sharp increase in patenting activity, making timely and comprehensive prior-art discovery more difficult. This problem is especially evident in financial technologies, where innovations develop quickly, patent collections grow continuously, and citation recommendation systems must be updated as new applications arrive. Existing patent retrieval and citation recommendation methods typically rely on static indexes or periodic retraining, which limits their ability to operate effectively in such dynamic settings. In this study, we propose a real-time patent citation recommendation framework designed for large and fast-changing financial patent corpora. Using a dataset of 428,843 financial patents granted by the China National Intellectual Property Administration (CNIPA) between 2000 and 2024, we build a three-stage recommendation pipeline. The pipeline uses large language model (LLM) embeddings to represent the semantic content of patent abstracts, applies efficient approximate nearest-neighbor search to construct a manageable candidate set, and ranks candidates by semantic similarity to produce top-k citation recommendations. In addition to improving recommendation accuracy, the proposed framework directly addresses the dynamic nature of patent systems. By using an incremental indexing strategy based on hierarchical navigable small-world (HNSW) graphs, newly issued patents can be added without rebuilding the entire index. A rolling day-by-day update experiment shows that incremental updating improves recall while substantially reducing computational cost compared with rebuild-based indexing. The proposed method also consistently outperforms traditional text-based baselines and alternative nearest-neighbor retrieval approaches.

### 10. MRAG: Benchmarking Retrieval-Augmented Generation for Bio-medicine

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Wei Zhu
- **URL**: <http://arxiv.org/abs/2601.16503v1>
- **Submitted**: 2026-01-23 07:07:13
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper MRAG is somewhat related to the user's research interests in Information Retrieval, specifically in the context of Retrieval-Augmented Generation. However, the focus on the medical domain and the use of Wikipedia and Pubmed as a corpus limits its relevance to the user's interests in e-commerce and general information retrieval. The paper's emphasis on NLP and deep semantic understanding is a partial match, but the specific application to bio-medicine and clinical QA systems is not a central theme in the user's research.

#### Abstract
> While Retrieval-Augmented Generation (RAG) has been swiftly adopted in scientific and clinical QA systems, a comprehensive evaluation benchmark in the medical domain is lacking. To address this gap, we introduce the Medical Retrieval-Augmented Generation (MRAG) benchmark, covering various tasks in English and Chinese languages, and building a corpus with Wikipedia and Pubmed. Additionally, we develop the MRAG-Toolkit, facilitating systematic exploration of different RAG components. Our experiments reveal that: (a) RAG enhances LLM reliability across MRAG tasks. (b) the performance of RAG systems is influenced by retrieval approaches, model sizes, and prompting strategies. (c) While RAG improves usefulness and reasoning quality, LLM responses may become slightly less readable for long-form questions. We will release the MRAG-Bench's dataset and toolkit with CCBY-4.0 license upon acceptance, to facilitate applications from both academia and industry.

### 11. How Does Personalized Memory Shape LLM Behavior? Benchmarking Rational Preference Utilization in Personalized Assistants

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Xueyang Feng, Weinan Gan, Xu Chen, Quanyu Dai, Yong Liu
- **URL**: <http://arxiv.org/abs/2601.16621v1>
- **Submitted**: 2026-01-23 10:19:48
- **Topic Keywords**: rag, personalization
- **Reason**: This paper explores the impact of personalized memory on large language models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on pragmatic reasoning and user experience in personalized assistants is more aligned with NLP and recommender systems, but not directly related to the user's core research themes in IR and search technologies.

#### Abstract
> Large language model (LLM)-powered assistants have recently integrated memory mechanisms that record user preferences, leading to more personalized and user-aligned responses. However, irrelevant personalized memories are often introduced into the context, interfering with the LLM's intent understanding. To comprehensively investigate the dual effects of personalization, we develop RPEval, a benchmark comprising a personalized intent reasoning dataset and a multi-granularity evaluation protocol. RPEval reveals the widespread phenomenon of irrational personalization in existing LLMs and, through error pattern analysis, illustrates its negative impact on user experience. Finally, we introduce RP-Reasoner, which treats memory utilization as a pragmatic reasoning process, enabling the selective integration of personalized information. Experimental results demonstrate that our method significantly outperforms carefully designed baselines on RPEval, and resolves 80% of the bad cases observed in a large-scale commercial personalized assistant, highlighting the potential of pragmatic reasoning to mitigate irrational personalization. Our benchmark is publicly available at https://github.com/XueyangFeng/RPEval.

### 12. Teaching and Evaluating LLMs to Reason About Polymer Design Related Tasks

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Dikshya Mohanty, Mohammad Saqib Hasan, Syed Mostofa Monsur, Size Zheng, Benjamin Hsiao, Niranjan Balasubramanian
- **URL**: <http://arxiv.org/abs/2601.16312v1>
- **Submitted**: 2026-01-22 20:39:18
- **Topic Keywords**: rag, search
- **Reason**: The paper is somewhat related to the user's interests in Natural Language Processing (NLP) and Learning to Rank, as it involves training and evaluating language models. However, the focus on polymer design and related tasks is not directly aligned with the user's core research themes in Information Retrieval and Search technologies. The paper's use of knowledge-augmented reasoning distillation method and benchmark dataset may be of interest, but it is not a central match for the user's research interests.

#### Abstract
> Research in AI4Science has shown promise in many science applications, including polymer design. However, current LLMs prove ineffective on this problem space because: (i) most models lack polymer-specific knowledge (ii) existing aligned models lack coverage of knowledge and capabilities relevant to polymer design. Addressing this, we introduce PolyBench, a large scale training and test benchmark dataset of more than 125K polymer design related tasks, leveraging a knowledge base of 13M+ data points obtained from experimental and synthetic sources to ensure broad coverage of polymers and their properties. For effective alignment using PolyBench, we introduce a knowledge-augmented reasoning distillation method that augments this dataset with structured CoT. Furthermore, tasks in PolyBench are organized from simple to complex analytical reasoning problems, enabling generalization tests and diagnostic probes across the problem space. Experiments show that small language models (SLMs), of 7B to 14B parameters, trained on PolyBench data outperform similar sized models, and even closed source frontier LLMs on PolyBench test dataset while demonstrating gains on other polymer benchmarks as well.

### 13. LLM-Based Adversarial Persuasion Attacks on Fact-Checking Systems

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Jo√£o A. Leite, Olesya Razuvayevskaya, Kalina Bontcheva, Carolina Scarton
- **URL**: <http://arxiv.org/abs/2601.16890v1>
- **Submitted**: 2026-01-23 16:57:16
- **Topic Keywords**: retrieval
- **Reason**: This paper explores adversarial attacks on fact-checking systems using persuasion techniques, which is somewhat related to information retrieval and NLP. However, the focus on adversarial attacks and persuasion techniques is not directly aligned with the user's core research themes of query understanding, ranking models, and user behavior modeling. The paper's relevance to the user's interests is limited, but it may be of interest due to its connection to NLP and deep semantic understanding.

#### Abstract
> Automated fact-checking (AFC) systems are susceptible to adversarial attacks, enabling false claims to evade detection. Existing adversarial frameworks typically rely on injecting noise or altering semantics, yet no existing framework exploits the adversarial potential of persuasion techniques, which are widely used in disinformation campaigns to manipulate audiences. In this paper, we introduce a novel class of persuasive adversarial attacks on AFCs by employing a generative LLM to rephrase claims using persuasion techniques. Considering 15 techniques grouped into 6 categories, we study the effects of persuasion on both claim verification and evidence retrieval using a decoupled evaluation strategy. Experiments on the FEVER and FEVEROUS benchmarks show that persuasion attacks can substantially degrade both verification performance and evidence retrieval. Our analysis identifies persuasion techniques as a potent class of adversarial attacks, highlighting the need for more robust AFC systems.

### 14. Select or Project? Evaluating Lower-dimensional Vectors for LLM Training Data Explanations

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Lukas Hinterleitner, Loris Schoenegger, Benjamin Roth
- **URL**: <http://arxiv.org/abs/2601.16651v1>
- **Submitted**: 2026-01-23 11:15:20
- **Comment**: 8 pages
- **Topic Keywords**: retrieval
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, specifically in the context of large language models and instance-based explanation. However, the focus on model component selection and gradient projection for explanation purposes is not directly aligned with your primary interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Gradient-based methods for instance-based explanation for large language models (LLMs) are hindered by the immense dimensionality of model gradients. In practice, influence estimation is restricted to a subset of model parameters to make computation tractable, but this subset is often chosen ad hoc and rarely justified by systematic evaluation. This paper investigates if it is better to create low-dimensional representations by selecting a small, architecturally informed subset of model components or by projecting the full gradients into a lower-dimensional space. Using a novel benchmark, we show that a greedily selected subset of components captures the information about training data influence needed for a retrieval task more effectively than either the full gradient or random projection. We further find that this approach is more computationally efficient than random projection, demonstrating that targeted component selection is a practical strategy for making instance-based explanations of large models more computationally feasible.

### 15. Clarify or Answer: Reinforcement Learning for Agentic VQA with Context Under-specification

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Zongwan Cao, Bingbing Wen, Lucy Lu Wang
- **URL**: <http://arxiv.org/abs/2601.16400v1>
- **Submitted**: 2026-01-23 02:12:33
- **Topic Keywords**: rag
- **Reason**: The paper explores reinforcement learning for agentic VQA with context under-specification, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on visual question answering and reinforcement learning for clarification question generation is not directly aligned with the user's core research themes in IR and NLP.

#### Abstract
> Real-world visual question answering (VQA) is often context-dependent: an image-question pair may be under-specified, such that the correct answer depends on external information that is not observable in the image. In such cases, directly answering can lead to confident but incorrect predictions. We propose CoA(Clarify-or-Answer), an ask-or-answer agent that separately models the decision to ask or answer, and what to ask if needed. CoA first determines whether clarification is necessary; if so, it asks a single focused question and then incorporates the response to produce the final answer. We introduce CONTEXTCLARIFY with a set of ambiguous VQA questions and the contrast set that is non-ambiguous. We further introduce GRPO-CR (Clarification Reasoning), a reinforcement learning approach that optimizes clarification question generation with multiple reward signals encouraging well-formed, focused, non-trivial questions that resolve ambiguity. Across three VLLMs and three datasets, CoA achieves consistent improvements at both the module and system levels, improving end-to-end VQA accuracy by an average of +15.3 points (83%) over prompting-based baselines

### 16. White-Box Sensitivity Auditing with Steering Vectors

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Hannah Cyberey, Yangfeng Ji, David Evans
- **URL**: <http://arxiv.org/abs/2601.16398v1>
- **Submitted**: 2026-01-23 02:03:20
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it involves large language models and bias audits. However, the focus on auditing and sensitivity analysis is not directly aligned with your primary interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Algorithmic audits are essential tools for examining systems for properties required by regulators or desired by operators. Current audits of large language models (LLMs) primarily rely on black-box evaluations that assess model behavior only through input-output testing. These methods are limited to tests constructed in the input space, often generated by heuristics. In addition, many socially relevant model properties (e.g., gender bias) are abstract and difficult to measure through text-based inputs alone. To address these limitations, we propose a white-box sensitivity auditing framework for LLMs that leverages activation steering to conduct more rigorous assessments through model internals. Our auditing method conducts internal sensitivity tests by manipulating key concepts relevant to the model's intended function for the task. We demonstrate its application to bias audits in four simulated high-stakes LLM decision tasks. Our method consistently reveals substantial dependence on protected attributes in model predictions, even in settings where standard black-box evaluations suggest little or no bias. Our code is openly available at https://github.com/hannahxchen/llm-steering-audit

### 17. Where is the multimodal goal post? On the Ability of Foundation Models to Recognize Contextually Important Moments

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Aditya K Surikuchi, Raquel Fern√°ndez, Sandro Pezzelle
- **URL**: <http://arxiv.org/abs/2601.16333v1>
- **Submitted**: 2026-01-22 21:40:08
- **Topic Keywords**: rag
- **Reason**: This paper explores the ability of foundation models to recognize contextually important moments in multimodal events, such as football games. While it touches on aspects of multimodal data and model performance, it doesn't directly relate to information retrieval, query understanding, or ranking models, which are core areas of your research interests.

#### Abstract
> Foundation models are used for many real-world applications involving language generation from temporally-ordered multimodal events. In this work, we study the ability of models to identify the most important sub-events in a video, which is a fundamental prerequisite for narrating or summarizing multimodal events. Specifically, we focus on football games and evaluate models on their ability to distinguish between important and non-important sub-events in a game. To this end, we construct a new dataset by leveraging human preferences for importance implicit in football game highlight reels, without any additional annotation costs. Using our dataset, which we will publicly release to the community, we compare several state-of-the-art multimodal models and show that they are not far from chance level performance. Analyses of models beyond standard evaluation metrics reveal their tendency to rely on a single dominant modality and their ineffectiveness in synthesizing necessary information from multiple sources. Our findings underline the importance of modular architectures that can handle sample-level heterogeneity in multimodal data and the need for complementary training procedures that can maximize cross-modal synergy.

### 18. Machine-Assisted Grading of Nationwide School-Leaving Essay Exams with LLMs and Statistical NLP

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Andres Karjus, Kais Allkivi, Silvia Maine, Katarin Leppik, Krister Kruusmaa, Merilin Aruvee
- **URL**: <http://arxiv.org/abs/2601.16314v1>
- **Submitted**: 2026-01-22 20:44:39
- **Topic Keywords**: ctr
- **Reason**: The paper explores the application of Large Language Models (LLMs) and Statistical NLP in automated essay grading, which is somewhat related to your interests in NLP and IR. However, the focus on educational assessment and grading is not directly aligned with your primary research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large language models (LLMs) enable rapid and consistent automated evaluation of open-ended exam responses, including dimensions of content and argumentation that have traditionally required human judgment. This is particularly important in cases where a large amount of exams need to be graded in a limited time frame, such as nation-wide graduation exams in various countries. Here, we examine the applicability of automated scoring on two large datasets of trial exam essays of two full national cohorts from Estonia. We operationalize the official curriculum-based rubric and compare LLM and statistical natural language processing (NLP) based assessments with human panel scores. The results show that automated scoring can achieve performance comparable to that of human raters and tends to fall within the human scoring range. We also evaluate bias, prompt injection risks, and LLMs as essay writers. These findings demonstrate that a principled, rubric-driven, human-in-the-loop scoring pipeline is viable for high-stakes writing assessment, particularly relevant for digitally advanced societies like Estonia, which is about to adapt a fully electronic examination system. Furthermore, the system produces fine-grained subscore profiles that can be used to generate systematic, personalized feedback for instruction and exam preparation. The study provides evidence that LLM-assisted assessment can be implemented at a national scale, even in a small-language context, while maintaining human oversight and compliance with emerging educational and regulatory standards.

### 19. Better as Generators Than Classifiers: Leveraging LLMs and Synthetic Data for Low-Resource Multilingual Classification

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Branislav Pecher, Jan Cegin, Robert Belanec, Ivan Srba, Jakub Simko, Maria Bielikova
- **URL**: <http://arxiv.org/abs/2601.16278v1>
- **Submitted**: 2026-01-22 19:19:13
- **Comment**: Accepted to the Findings of EACL 2026
- **Topic Keywords**: rag
- **Reason**: This paper focuses on leveraging Large Language Models (LLMs) for synthetic data generation in low-resource multilingual classification. While it touches on the capabilities of LLMs, it doesn't directly address query understanding, ranking models, or user behavior modeling in information retrieval, which are core areas of your research interests.

#### Abstract
> Large Language Models (LLMs) have demonstrated remarkable multilingual capabilities, making them promising tools in both high- and low-resource languages. One particularly valuable use case is generating synthetic samples that can be used to train smaller models in low-resource scenarios where human-labelled data is scarce. In this work, we investigate whether these synthetic data generation capabilities can serve as a form of distillation, producing smaller models that perform on par with or even better than massive LLMs across languages and tasks. To this end, we use a state-of-the-art multilingual LLM to generate synthetic datasets covering 11 languages and 4 classification tasks. These datasets are then used to train smaller models via fine-tuning or instruction tuning, or as synthetic in-context examples for compact LLMs. Our experiments show that even small amounts of synthetic data enable smaller models to outperform the large generator itself, particularly in low-resource languages. Overall, the results suggest that LLMs are best utilised as generators (teachers) rather than classifiers, producing data that empowers smaller and more efficient multilingual models.

### 20. PRISM: Purified Representation and Integrated Semantic Modeling for Generative Sequential Recommendation

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Dengzhao Fang, Jingtong Gao, Yu Li, Xiangyu Zhao, Yi Chang
- **URL**: <http://arxiv.org/abs/2601.16556v1>
- **Submitted**: 2026-01-23 08:50:16
- **Topic Keywords**: ranking, retrieval, recommend, rank
- **Reason**: The paper focuses on Generative Sequential Recommendation, which is not a core area of interest in Information Retrieval. While it touches upon semantic understanding, the primary focus is on recommender systems, which is a secondary interest. The paper's relevance to query understanding, ranking models, and user behavior modeling is limited.

#### Abstract
> Generative Sequential Recommendation (GSR) has emerged as a promising paradigm, reframing recommendation as an autoregressive sequence generation task over discrete Semantic IDs (SIDs), typically derived via codebook-based quantization. Despite its great potential in unifying retrieval and ranking, existing GSR frameworks still face two critical limitations: (1) impure and unstable semantic tokenization, where quantization methods struggle with interaction noise and codebook collapse, resulting in SIDs with ambiguous discrimination; and (2) lossy and weakly structured generation, where reliance solely on coarse-grained discrete tokens inevitably introduces information loss and neglects items' hierarchical logic. To address these issues, we propose a novel generative recommendation framework, PRISM, with Purified Representation and Integrated Semantic Modeling. Specifically, to ensure high-quality tokenization, we design a Purified Semantic Quantizer that constructs a robust codebook via adaptive collaborative denoising and hierarchical semantic anchoring mechanisms. To compensate for information loss during quantization, we further propose an Integrated Semantic Recommender, which incorporates a dynamic semantic integration mechanism to integrate fine-grained semantics and enforces logical validity through a semantic structure alignment objective. PRISM consistently outperforms state-of-the-art baselines across four real-world datasets, demonstrating substantial performance gains, particularly in high-sparsity scenarios.

### 21. Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Bernes Lorier Atabonfack, Ahmed Tahiru Issah, Mohammed Hardi Abdul Baaki, Clemence Ingabire, Tolulope Olusuyi, Maruf Adewole, Udunna C. Anazodo, Timothy X Brown
- **URL**: <http://arxiv.org/abs/2601.16967v1>
- **Submitted**: 2026-01-23 18:39:55
- **Comment**: Accepted at the MIRASOL Workshop at MICCAI 2025. To appear in Lecture Notes in Computer Science (LNCS)
- **Topic Keywords**: ltr, search
- **Reason**: This paper is not relevant to your research interests as it focuses on medical equipment sustainability and AI-powered diagnostic platforms, which do not align with your core areas of interest in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.

### 22. Better Generalizing to Unseen Concepts: An Evaluation Framework and An LLM-Based Auto-Labeled Pipeline for Biomedical Concept Recognition

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Shanshan Liu, Noriki Nishida, Fei Cheng, Narumi Tokunaga, Rumana Ferdous Munne, Yuki Yamagata, Kouji Kozaki, Takehito Utsuro, Yuji Matsumoto
- **URL**: <http://arxiv.org/abs/2601.16711v1>
- **Submitted**: 2026-01-23 12:59:06
- **Comment**: Accepted to EACL 2026 (Main)
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on biomedical concept recognition, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves LLMs, the context is specific to biomedical domain and does not align with the user's interests in query understanding, ranking models, or user behavior modeling.

#### Abstract
> Generalization to unseen concepts is a central challenge due to the scarcity of human annotations in Mention-agnostic Biomedical Concept Recognition (MA-BCR). This work makes two key contributions to systematically address this issue. First, we propose an evaluation framework built on hierarchical concept indices and novel metrics to measure generalization. Second, we explore LLM-based Auto-Labeled Data (ALD) as a scalable resource, creating a task-specific pipeline for its generation. Our research unequivocally shows that while LLM-generated ALD cannot fully substitute for manual annotations, it is a valuable resource for improving generalization, successfully providing models with the broader coverage and structural knowledge needed to approach recognizing unseen concepts. Code and datasets are available at https://github.com/bio-ie-tool/hi-ald.

### 23. Persona Jailbreaking in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jivnesh Sandhan, Fei Cheng, Tushar Sandhan, Yugo Murawaki
- **URL**: <http://arxiv.org/abs/2601.16466v1>
- **Submitted**: 2026-01-23 05:51:35
- **Comment**: Accepted at EACL26 (Findings)
- **Topic Keywords**: queries
- **Reason**: This paper focuses on Large Language Models and persona manipulation, which is not directly related to the user's core research themes in Information Retrieval and Search technologies. While it touches on user behavior modeling, the context is specific to conversational AI and does not align with the user's primary interests in query understanding, ranking models, and real-time relevance optimization.

#### Abstract
> Large Language Models (LLMs) are increasingly deployed in domains such as education, mental health and customer support, where stable and consistent personas are critical for reliability. Yet, existing studies focus on narrative or role-playing tasks and overlook how adversarial conversational history alone can reshape induced personas. Black-box persona manipulation remains unexplored, raising concerns for robustness in realistic interactions. In response, we introduce the task of persona editing, which adversarially steers LLM traits through user-side inputs under a black-box, inference-only setting. To this end, we propose PHISH (Persona Hijacking via Implicit Steering in History), the first framework to expose a new vulnerability in LLM safety that embeds semantically loaded cues into user queries to gradually induce reverse personas. We also define a metric to quantify attack success. Across 3 benchmarks and 8 LLMs, PHISH predictably shifts personas, triggers collateral changes in correlated traits, and exhibits stronger effects in multi-turn settings. In high-risk domains mental health, tutoring, and customer support, PHISH reliably manipulates personas, validated by both human and LLM-as-Judge evaluations. Importantly, PHISH causes only a small reduction in reasoning benchmark performance, leaving overall utility largely intact while still enabling significant persona manipulation. While current guardrails offer partial protection, they remain brittle under sustained attack. Our findings expose new vulnerabilities in personas and highlight the need for context-resilient persona in LLMs. Our codebase and dataset is available at: https://github.com/Jivnesh/PHISH

### 24. A Longitudinal, Multinational, and Multilingual Corpus of News Coverage of the Russo-Ukrainian War

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Dikshya Mohanty, Taisiia Sabadyn, Jelwin Rodrigues, Chenlu Wang, Abhishek Kalugade, Ritwik Banerjee
- **URL**: <http://arxiv.org/abs/2601.16309v1>
- **Submitted**: 2026-01-22 20:37:42
- **Topic Keywords**: rag, search
- **Reason**: This paper appears to be focused on building a news corpus for studying wartime discourse and information warfare, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve NLP tasks like stance detection and sentiment analysis, the context and application are quite different from your typical research areas.

#### Abstract
> We introduce DNIPRO, a novel longitudinal corpus of 246K news articles documenting the Russo-Ukrainian war from Feb 2022 to Aug 2024, spanning eleven media outlets across five nation states (Russia, Ukraine, U.S., U.K., and China) and three languages (English, Russian, and Mandarin Chinese). This multilingual resource features consistent and comprehensive metadata, and multiple types of annotation with rigorous human evaluations for downstream tasks relevant to systematic transnational analyses of contentious wartime discourse. DNIPRO's distinctive value lies in its inclusion of competing geopolitical perspectives, making it uniquely suited for studying narrative divergence, media framing, and information warfare. To demonstrate its utility, we include use case experiments using stance detection, sentiment analysis, topical framing, and contradiction analysis of major conflict events within the larger war. Our explorations reveal how outlets construct competing realities, with coverage exhibiting polarized interpretations that reflect geopolitical interests. Beyond supporting computational journalism research, DNIPRO provides a foundational resource for understanding how conflicting narratives emerge and evolve across global information ecosystems.

### 25. Trapped in the past? Disentangling fluid and crystallized intelligence of large language models using chess

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Leonard S. Pleiss, Maximilian Schiffer, Robert K. von Weizs√§cker
- **URL**: <http://arxiv.org/abs/2601.16823v1>
- **Submitted**: 2026-01-23 15:23:08
- **Topic Keywords**: rag
- **Reason**: This paper appears to be primarily focused on evaluating the reasoning abilities of Large Language Models (LLMs) using chess as a controlled testbed. While it touches on aspects of model performance and generalization, it does not directly relate to the user's core research themes in Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling, making it only loosely relevant to their interests.

#### Abstract
> Large Language Models (LLMs) exhibit remarkable capabilities, yet it remains unclear to what extent these reflect sophisticated recall (crystallized intelligence) or reasoning ability (fluid intelligence). We introduce chess as a controlled testbed for disentangling these faculties. Leveraging the game's structure and scalable engine evaluations, we construct a taxonomy of positions varying in training corpus proximity--ranging from common states solvable by memorization to novel ones requiring first-principles reasoning. We systematically evaluate multiple GPT generations under varying reasoning intensities. Our analysis reveals a clear gradient: performance consistently degrades as fluid intelligence demands increase. Notably, in out-of-distribution tasks, performance collapses to random levels. While newer models improve, progress slows significantly for tasks outside the training distribution. Furthermore, while reasoning-augmented inference improves performance, its marginal benefit per token decreases with distributional proximity. These results suggest current architectures remain limited in systematic generalization, highlighting the need for mechanisms beyond scale to achieve robust fluid intelligence.

### 26. EMemBench: Interactive Benchmarking of Episodic Memory for VLM Agents

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xinze Li, Ziyue Zhu, Siyuan Liu, Yubo Ma, Yuhang Zang, Yixin Cao, Aixin Sun
- **URL**: <http://arxiv.org/abs/2601.16690v1>
- **Submitted**: 2026-01-23 12:09:59
- **Comment**: 25 pages
- **Topic Keywords**: rag
- **Reason**: This paper appears to be focused on evaluating the long-term memory of agents in virtual environments, using a benchmark called EMemBench. While it involves natural language processing and visual understanding, its primary focus is on episodic memory and its application to virtual agents, which is not directly related to information retrieval, search technologies, or user behavior modeling.

#### Abstract
> We introduce EMemBench, a programmatic benchmark for evaluating long-term memory of agents through interactive games. Rather than using a fixed set of questions, EMemBench generates questions from each agent's own trajectory, covering both text and visual game environments. Each template computes verifiable ground truth from underlying game signals, with controlled answerability and balanced coverage over memory skills: single/multi-hop recall, induction, temporal, spatial, logical, and adversarial. We evaluate memory agents with strong LMs/VLMs as backbones, using in-context prompting as baselines. Across 15 text games and multiple visual seeds, results are far from saturated: induction and spatial reasoning are persistent bottlenecks, especially in visual setting. Persistent memory yields clear gains for open backbones on text games, but improvements are less consistent for VLM agents, suggesting that visually grounded episodic memory remains an open challenge. A human study further confirms the difficulty of EMemBench.

### 27. PROST-LLM: Progressively Enhancing the Speech-to-Speech Translation Capability in LLMs

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jing Xu, Jiaqi Wang, Daxin Tan, Xiao Chen
- **URL**: <http://arxiv.org/abs/2601.16618v1>
- **Submitted**: 2026-01-23 10:16:13
- **Comment**: Accepted by ICASSP 2026
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests as it focuses on Speech-to-Speech Translation in Large Language Models, which is outside your core areas of Information Retrieval, Search technologies, and Natural Language Processing. Although it involves fine-tuning and optimization, the context is not aligned with your primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Although Large Language Models (LLMs) excel in many tasks, their application to Speech-to-Speech Translation (S2ST) is underexplored and hindered by data scarcity. To bridge this gap, we propose PROST-LLM (PROgressive Speech-to-speech Translation) to enhance the S2ST capabilities in LLMs progressively. First, we fine-tune the LLMs with the CVSS corpus, employing designed tri-task learning and chain of modality methods to boost the initial performance. Then, leveraging the fine-tuned model, we generate preference pairs through self-sampling and back-translation without human evaluation. Finally, these preference pairs are used for preference optimization to enhance the model's S2ST capability further. Extensive experiments confirm the effectiveness of our proposed PROST-LLM in improving the S2ST capability of LLMs.

### 28. Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xianya Fang, Feiyang Ren, Xiang Chen, Yu Tian, Zhen Bi, Haiyang Yu, Sheng-Jun Huang
- **URL**: <http://arxiv.org/abs/2601.16527v1>
- **Submitted**: 2026-01-23 07:58:38
- **Topic Keywords**: rag
- **Reason**: This paper focuses on mitigating hallucinations in multimodal LLMs, which is a topic in NLP. However, it does not directly relate to information retrieval, query understanding, ranking models, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.

### 29. Endless Terminals: Scaling RL Environments for Terminal Agents

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Kanishk Gandhi, Shivam Garg, Noah D. Goodman, Dimitris Papailiopoulos
- **URL**: <http://arxiv.org/abs/2601.16443v1>
- **Submitted**: 2026-01-23 04:39:55
- **Topic Keywords**: retrieval
- **Reason**: This paper focuses on reinforcement learning environments for terminal agents, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on scalability and model performance, the context and techniques used are not relevant to the user's core themes.

#### Abstract
> Environments are the bottleneck for self-improving agents. Current terminal benchmarks were built for evaluation, not training; reinforcement learning requires a scalable pipeline, not just a dataset. We introduce Endless Terminals, a fully autonomous pipeline that procedurally generates terminal-use tasks without human annotation. The pipeline has four stages: generating diverse task descriptions, building and validating containerized environments, producing completion tests, and filtering for solvability. From this pipeline we obtain 3255 tasks spanning file operations, log management, data processing, scripting, and database operations. We train agents using vanilla PPO with binary episode level rewards and a minimal interaction loop: no retrieval, multi-agent coordination, or specialized tools. Despite this simplicity, models trained on Endless Terminals show substantial gains: on our held-out dev set, Llama-3.2-3B improves from 4.0% to 18.2%, Qwen2.5-7B from 10.7% to 53.3%, and Qwen3-8B-openthinker-sft from 42.6% to 59.0%. These improvements transfer to human-curated benchmarks: models trained on Endless Terminals show substantial gains on held out human curated benchmarks: on TerminalBench 2.0, Llama-3.2-3B improves from 0.0% to 2.2%, Qwen2.5-7B from 2.2% to 3.4%, and Qwen3-8B-openthinker-sft from 1.1% to 6.7%, in each case outperforming alternative approaches including models with more complex agentic scaffolds. These results demonstrate that simple RL succeeds when environments scale.

### 30. Cite-While-You-Generate: Training-Free Evidence Attribution for Multimodal Clinical Summarization

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Qianqi Yan, Huy Nguyen, Sumana Srivatsa, Hari Bandi, Xin Eric Wang, Krishnaram Kenthapadi
- **URL**: <http://arxiv.org/abs/2601.16397v1>
- **Submitted**: 2026-01-23 02:01:43
- **Topic Keywords**: rag
- **Reason**: This paper focuses on clinical summarization, multimodal attribution, and transparency in AI systems, which are not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP and attention mechanisms, the context and application are quite different from the user's areas of focus.

#### Abstract
> Trustworthy clinical summarization requires not only fluent generation but also transparency about where each statement comes from. We propose a training-free framework for generation-time source attribution that leverages decoder attentions to directly cite supporting text spans or images, overcoming the limitations of post-hoc or retraining-based methods. We introduce two strategies for multimodal attribution: a raw image mode, which directly uses image patch attentions, and a caption-as-span mode, which substitutes images with generated captions to enable purely text-based alignment. Evaluations on two representative domains: clinician-patient dialogues (CliConSummation) and radiology reports (MIMIC-CXR), show that our approach consistently outperforms embedding-based and self-attribution baselines, improving both text-level and multimodal attribution accuracy (e.g., +15% F1 over embedding baselines). Caption-based attribution achieves competitive performance with raw-image attention while being more lightweight and practical. These findings highlight attention-guided attribution as a promising step toward interpretable and deployable clinical summarization systems.

### 31. Cross-Lingual Activation Steering for Multilingual Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Rhitabrat Pokharel, Ameeta Agrawal, Tanay Nagar
- **URL**: <http://arxiv.org/abs/2601.16390v1>
- **Submitted**: 2026-01-23 01:41:17
- **Comment**: Under review
- **Topic Keywords**: rag
- **Reason**: This paper focuses on multilingual language models and proposes a method to improve performance across languages. While it touches on the idea of 'latent capacity' in existing models, it doesn't directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Large language models exhibit strong multilingual capabilities, yet significant performance gaps persist between dominant and non-dominant languages. Prior work attributes this gap to imbalances between shared and language-specific neurons in multilingual representations. We propose Cross-Lingual Activation Steering (CLAS), a training-free inference-time intervention that selectively modulates neuron activations. We evaluate CLAS on classification and generation benchmarks, achieving average improvements of 2.3% (Acc.) and 3.4% (F1) respectively, while maintaining high-resource language performance. We discover that effective transfer operates through functional divergence rather than strict alignment; performance gains correlate with increased language cluster separation. Our results demonstrate that targeted activation steering can unlock latent multilingual capacity in existing models without modification to model weights.

### 32. Explaining Group Recommendations via Counterfactuals

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Maria Stratigi, Nikos Bikakis
- **URL**: <http://arxiv.org/abs/2601.16882v1>
- **Submitted**: 2026-01-23 16:42:05
- **Topic Keywords**: recommend
- **Reason**: This paper is primarily focused on recommender systems, specifically group recommendations, and proposes a framework for counterfactual explanations. While it touches on optimization and efficiency, it does not directly relate to information retrieval, query understanding, or ranking models, which are core areas of interest. The paper's focus on recommender systems and group recommendations makes it somewhat tangential to the user's primary research themes.

#### Abstract
> Group recommender systems help users make collective choices but often lack transparency, leaving group members uncertain about why items are suggested. Existing explanation methods focus on individuals, offering limited support for groups where multiple preferences interact. In this paper, we propose a framework for group counterfactual explanations, which reveal how removing specific past interactions would change a group recommendation. We formalize this concept, introduce utility and fairness measures tailored to groups, and design heuristic algorithms, such as Pareto-based filtering and grow-and-prune strategies, for efficient explanation discovery. Experiments on MovieLens and Amazon datasets show clear trade-offs: low-cost methods produce larger, less fair explanations, while other approaches yield concise and balanced results at higher cost. Furthermore, the Pareto-filtering heuristic demonstrates significant efficiency improvements in sparse settings.

### 33. SoS: Analysis of Surface over Semantics in Multilingual Text-To-Image Generation

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Carolin Holtermann, Florian Schneider, Anne Lauscher
- **URL**: <http://arxiv.org/abs/2601.16803v1>
- **Submitted**: 2026-01-23 14:55:11
- **Topic Keywords**: search
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it touches on the analysis of language and cultural identities, its focus on text-to-image generation and visual depictions does not align with your primary areas of interest.

#### Abstract
> Text-to-image (T2I) models are increasingly employed by users worldwide. However, prior research has pointed to the high sensitivity of T2I towards particular input languages - when faced with languages other than English (i.e., different surface forms of the same prompt), T2I models often produce culturally stereotypical depictions, prioritizing the surface over the prompt's semantics. Yet a comprehensive analysis of this behavior, which we dub Surface-over-Semantics (SoS), is missing. We present the first analysis of T2I models' SoS tendencies. To this end, we create a set of prompts covering 171 cultural identities, translated into 14 languages, and use it to prompt seven T2I models. To quantify SoS tendencies across models, languages, and cultures, we introduce a novel measure and analyze how the tendencies we identify manifest visually. We show that all but one model exhibit strong surface-level tendency in at least two languages, with this effect intensifying across the layers of T2I text encoders. Moreover, these surface tendencies frequently correlate with stereotypical visual depictions.

### 34. EvoConfig: Self-Evolving Multi-Agent Systems for Efficient Autonomous Environment Configuration

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Xinshuai Guo, Jiayi Kuang, Linyue Pan, Yinghui Li, Yangning Li, Hai-Tao Zheng, Ying Shen, Di Yin, Xing Sun
- **URL**: <http://arxiv.org/abs/2601.16489v1>
- **Submitted**: 2026-01-23 06:33:01
- **Topic Keywords**: recommend
- **Reason**: This paper appears to be unrelated to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves multi-agent systems and optimization, the focus is on environment configuration for software engineering tasks, which doesn't align with your primary areas of interest.

#### Abstract
> A reliable executable environment is the foundation for ensuring that large language models solve software engineering tasks. Due to the complex and tedious construction process, large-scale configuration is relatively inefficient. However, most methods always overlook fine-grained analysis of the actions performed by the agent, making it difficult to handle complex errors and resulting in configuration failures. To address this bottleneck, we propose EvoConfig, an efficient environment configuration framework that optimizes multi-agent collaboration to build correct runtime environments. EvoConfig features an expert diagnosis module for fine-grained post-execution analysis, and a self-evolving mechanism that lets expert agents self-feedback and dynamically adjust error-fixing priorities in real time. Empirically, EvoConfig matches the previous state-of-the-art Repo2Run on Repo2Run's 420 repositories, while delivering clear gains on harder cases: on the more challenging Envbench, EvoConfig achieves a 78.1% success rate, outperforming Repo2Run by 7.1%. Beyond end-to-end success, EvoConfig also demonstrates stronger debugging competence, achieving higher accuracy in error identification and producing more effective repair recommendations than existing methods.

### 35. Segregation Before Polarization: How Recommendation Strategies Shape Echo Chamber Pathways

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Junning Zhao, Kazutoshi Sasahara, Yu Chen
- **URL**: <http://arxiv.org/abs/2601.16457v1>
- **Submitted**: 2026-01-23 05:28:49
- **Comment**: 13 pages, 5 figures for main text; 7 pages, 6 figures for supplementary materials
- **Topic Keywords**: recommend
- **Reason**: This paper is primarily focused on the impact of recommendation strategies on social media echo chambers, which is somewhat related to information retrieval and search technologies. However, the paper's focus on social media and recommendation systems is not directly aligned with the user's core research themes in information retrieval, search technologies, and natural language processing.

#### Abstract
> Social media platforms facilitate echo chambers through feedback loops between user preferences and recommendation algorithms. While algorithmic homogeneity is well-documented, the distinct evolutionary pathways driven by content-based versus link-based recommendations remain unclear. Using an extended dynamic Bounded Confidence Model (BCM), we show that content-based algorithms--unlike their link-based counterparts--steer social networks toward a segregation-before-polarization (SbP) pathway. Along this trajectory, structural segregation precedes opinion divergence, accelerating individual isolation while delaying but ultimately intensifying collective polarization. Furthermore, we reveal a paradox in information sharing: Reposting increases the number of connections in the network, yet it simultaneously reinforces echo chambers because it amplifies small, latent opinion differences that would otherwise remain inconsequential. These findings suggest that mitigating polarization requires stage-dependent algorithmic interventions, shifting from content-centric to structure-centric strategies as networks evolve.

### 36. Exploring the Effects of Alignment on Numerical Bias in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Ayako Sato, Hwichan Kim, Zhousi Chen, Masato Mita, Mamoru Komachi
- **URL**: <http://arxiv.org/abs/2601.16444v1>
- **Submitted**: 2026-01-23 04:45:35
- **Comment**: Accepted at AIBSD 2026 (Workshop at AAAI 2026)
- **Topic Keywords**: search
- **Reason**: This paper focuses on the effects of alignment on numerical bias in Large Language Models, which is a topic in NLP. However, it does not directly relate to the user's core research themes in Information Retrieval, query understanding, ranking models, or user behavior modeling, making it only loosely relevant.

#### Abstract
> ``LLM-as-a-judge,'' which utilizes large language models (LLMs) as evaluators, has proven effective in many evaluation tasks. However, evaluator LLMs exhibit numerical bias, a phenomenon where certain evaluation scores are generated disproportionately often, leading reduced evaluation performance. This study investigates the cause of this bias. Given that most evaluator LLMs are aligned through instruction tuning and preference tuning, and that prior research suggests alignment reduces output diversity, we hypothesize that numerical bias arises from alignment. To test this, we compare outputs from pre- and post-alignment LLMs, and observe that alignment indeed increases numerical bias. We also explore mitigation strategies for post-alignment LLMs, including temperature scaling, distribution calibration, and score range adjustment. Among these, score range adjustment is most effective in reducing bias and improving performance, though still heuristic. Our findings highlight the need for further work on optimal score range selection and more robust mitigation strategies.

### 37. Regional Bias in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: M P V S Gopinadh, Kappara Lakshmi Sindhu, Soma Sekhar Pandu Ranga Raju P, Yesaswini Swarna
- **URL**: <http://arxiv.org/abs/2601.16349v1>
- **Submitted**: 2026-01-22 22:22:23
- **Comment**: 8 pages, 1 figure. Presented at the Second International Conference on Advanced Computing, Machine Learning, Robotics and Internet Technologies (AMRIT 2024)
- **Topic Keywords**: search
- **Reason**: This paper focuses on regional bias in large language models, which is outside your primary research interests in Information Retrieval and Search technologies. Although it touches on AI fairness and global representation, it doesn't directly relate to your core areas of query understanding, ranking models, or user behavior modeling.

#### Abstract
> This study investigates regional bias in large language models (LLMs), an emerging concern in AI fairness and global representation. We evaluate ten prominent LLMs: GPT-3.5, GPT-4o, Gemini 1.5 Flash, Gemini 1.0 Pro, Claude 3 Opus, Claude 3.5 Sonnet, Llama 3, Gemma 7B, Mistral 7B, and Vicuna-13B using a dataset of 100 carefully designed prompts that probe forced-choice decisions between regions under contextually neutral scenarios. We introduce FAZE, a prompt-based evaluation framework that measures regional bias on a 10-point scale, where higher scores indicate a stronger tendency to favor specific regions. Experimental results reveal substantial variation in bias levels across models, with GPT-3.5 exhibiting the highest bias score (9.5) and Claude 3.5 Sonnet scoring the lowest (2.5). These findings indicate that regional bias can meaningfully undermine the reliability, fairness, and inclusivity of LLM outputs in real-world, cross-cultural applications. This work contributes to AI fairness research by highlighting the importance of inclusive evaluation frameworks and systematic approaches for identifying and mitigating geographic biases in language models.

### 38. PolyAgent: Large Language Model Agent for Polymer Design

- **LLM Score**: 0
- **Keyword Score**: 1
- **Authors**: Vani Nigam, Achuth Chandrasekhar, Amir Barati Farimani
- **URL**: <http://arxiv.org/abs/2601.16376v1>
- **Submitted**: 2026-01-23 00:17:52
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on polymer design using Large Language Model Agent, which is outside your areas of expertise.

#### Abstract
> On-demand Polymer discovery is essential for various industries, ranging from biomedical to reinforcement materials. Experiments with polymers have a long trial-and-error process, leading to long procedures and extensive resources. For these processes, machine learning has accelerated scientific discovery at the property prediction and latent space search fronts. However, laboratory researchers cannot readily access codes and these models to extract individual structures and properties due to infrastructure limitations. We present a closed-loop polymer structure-property predictor integrated in a terminal for early-stage polymer discovery. The framework is powered by LLM reasoning to provide users with property prediction, property-guided polymer structure generation, and structure modification capabilities. The SMILES sequences are guided by the synthetic accessibility score and the synthetic complexity score (SC Score) to ensure that polymer generation is as close as possible to synthetically accessible monomer-level structures. This framework addresses the challenge of generating novel polymer structures for laboratory researchers, thereby providing computational insights into polymer research.

---

