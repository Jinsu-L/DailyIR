# Daily Papers Report - 2025-10-05

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Revisiting Query Variants: The Advantage of Retrieval Over Generation of Query Variants for Effective QPP

- **LLM Score**: 8
- **Keyword Score**: 16
- **Authors**: Fangzheng Tian, Debasis Ganguly, Craig Macdonald
- **URL**: <http://arxiv.org/abs/2510.02512v1>
- **Submitted**: 2025-10-02 19:36:58
- **Comment**: 11 pages, 4 figures
- **Topic Keywords**: query, queries, ranking, rag, retrieval, rank, trec
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The focus on query variants and retrieval-based methods aligns with your expertise in Learning to Rank and user behavior modeling. The application of the proposed method to neural ranking models like MonoT5 further supports its relevance.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Query Performance Prediction (QPP) in Neural Ranking Models
- **Aim**: To improve QPP accuracy by leveraging retrieved Query Variants (QVs) from training datasets instead of generating them.
- **Rationale**: Traditional QPP methods generate QVs, which can suffer from hallucinations and information drift. Directly retrieving QVs from training data enhances recall and improves accuracy.
- **Ground**: Training datasets like MS MARCO containing Query Variant (QV) pairs.
- **Experiment**: Experiments conducted on TREC DL'19 and DL'20 datasets using MonoT5 model.  Performance evaluated using AP@100 metric.
- **Takeaway**: Directly retrieving QVs from training data significantly outperforms generated-QV-based approaches.  Optimal performance achieved with small number of QVs (k=1) and dataset-specific lambda values.  Future work suggests integrating QV retrieval with LLM-based QV generation.

#### Abstract
> Leveraging query variants (QVs), i.e., queries with potentially similar
information needs to the target query, has been shown to improve the
effectiveness of query performance prediction (QPP) approaches. Existing
QV-based QPP methods generate QVs facilitated by either query expansion or
non-contextual embeddings, which may introduce topical drifts and
hallucinations. In this paper, we propose a method that retrieves QVs from a
training set (e.g., MS MARCO) for a given target query of QPP. To achieve a
high recall in retrieving queries with the most similar information needs as
the target query from a training set, we extend the directly retrieved QVs
(1-hop QVs) by a second retrieval using their denoted relevant documents (which
yields 2-hop QVs). Our experiments, conducted on TREC DL'19 and DL'20, show
that the QPP methods with QVs retrieved by our method outperform the
best-performing existing generated-QV-based QPP approaches by as much as around
20\%, on neural ranking models like MonoT5.

---

### 2. Grounding Large Language Models in Clinical Evidence: A Retrieval-Augmented Generation System for Querying UK NICE Clinical Guidelines

- **LLM Score**: 8
- **Keyword Score**: 11
- **Authors**: Matthew Lewis, Samuel Thio, Richard JB Dobson, Spiros Denaxas
- **URL**: <http://arxiv.org/abs/2510.02967v1>
- **Submitted**: 2025-10-03 12:57:13
- **Topic Keywords**: query, queries, rag, retrieval, rank
- **Reason**: This paper is highly relevant to Information Retrieval, particularly in the context of query understanding and ranking models, as it presents a Retrieval-Augmented Generation system for querying clinical guidelines. The system's performance evaluation, including Mean Reciprocal Rank and Recall metrics, is also of interest. However, the focus on healthcare and clinical guidelines is somewhat outside the user's primary domain of e-commerce, which slightly reduces the score.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Retrieval-Augmented Generation (RAG) for Clinical Decision Support
- **Aim**: To develop a cost-effective RAG system for answering clinical queries using UK NICE guidelines.
- **Rationale**: Clinical decision support systems can benefit from integrating medical guidelines, and RAG offers a promising approach to efficiently retrieve and utilize this information.
- **Ground**: UK's National Institute for Health and Care Excellence (NICE) clinical guidelines.
- **Experiment**: A hybrid retrieval architecture combining Okapi BM25 and dense embedding models (Voyage-3-Large, Qwen3-Embedding-0.6B) was implemented. A Weighted Reciprocal Rank Fusion (WRRF) method integrated rankings, and a cross-encoder model (Voyage Reranker-2) reranked documents. Retrieved information was incorporated into prompts for LLMs (GPT-4.1, O4-Mini, Claude Sonnet 4). The system was evaluated on a dataset of 10,195 text chunks and 70 question-answer pairs.
- **Takeaway**: The RAG system achieved high retrieval and generation performance, demonstrating the potential of applying generative AI in healthcare for cost-effective and accurate clinical decision support. However, human oversight is crucial due to potential LLM inaccuracies, and future research should address limitations such as synthetic data, multi-source queries, and privacy concerns.

#### Abstract
> This paper presents the development and evaluation of a Retrieval-Augmented
Generation (RAG) system for querying the United Kingdom's National Institute
for Health and Care Excellence (NICE) clinical guidelines using Large Language
Models (LLMs). The extensive length and volume of these guidelines can impede
their utilisation within a time-constrained healthcare system, a challenge this
project addresses through the creation of a system capable of providing users
with precisely matched information in response to natural language queries. The
system's retrieval architecture, composed of a hybrid embedding mechanism, was
evaluated against a database of 10,195 text chunks derived from three hundred
guidelines. It demonstrates high performance, with a Mean Reciprocal Rank (MRR)
of 0.814, a Recall of 81% at the first chunk and of 99.1% within the top ten
retrieved chunks, when evaluated on 7901 queries.
  The most significant impact of the RAG system was observed during the
generation phase. When evaluated on a manually curated dataset of seventy
question-answer pairs, RAG-enhanced models showed substantial gains in
performance. Faithfulness, the measure of whether an answer is supported by the
source text, was increased by 64.7 percentage points to 99.5% for the
RAG-enhanced O4-Mini model and significantly outperformed the medical-focused
Meditron3-8B LLM, which scored 43%. This, combined with a perfect Context
Precision score of 1 for all RAG-enhanced models, confirms the system's ability
to prevent information fabrication by grounding its answers in relevant source
material. This study thus establishes RAG as an effective, reliable, and
scalable approach for applying generative AI in healthcare, enabling
cost-effective access to medical guidelines.

---

### 3. Finding Diamonds in Conversation Haystacks: A Benchmark for Conversational Data Retrieval

- **LLM Score**: 8
- **Keyword Score**: 8
- **Authors**: Yohan Lee, Yongwoo Song, Sangyeop Kim
- **URL**: <http://arxiv.org/abs/2510.02938v1>
- **Submitted**: 2025-10-03 12:29:44
- **Comment**: Accepted by EMNLP 2025 Industry Track
- **Topic Keywords**: query, queries, retrieval
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in conversational data retrieval, which requires deep semantic understanding and real-time relevance optimization. The focus on conversational data retrieval and the evaluation of embedding models aligns with your interests in query understanding and ranking models. However, the e-commerce domain focus is somewhat narrower than your broader interests in IR and NLP.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Conversational Data Retrieval
- **Aim**: To introduce a comprehensive benchmark, CDR, for evaluating systems designed to retrieve conversation data for product insights.
- **Rationale**: There is a significant disparity between the capabilities of document and conversational data retrieval systems.
- **Ground**: The CDR benchmark comprises 1,600 queries spanning five analytical tasks and 9,100 conversations.
- **Experiment**: An evaluation of 16 common embedding models against the CDR benchmark revealed that even the highest-performing models achieved an NDCG@10 score of only approximately 0.51.
- **Takeaway**: The paper highlights specific challenges in conversational data retrieval, including implicit state recognition, turn dynamics, and contextual references. It also provides practical query templates and in-depth error analysis.

#### Abstract
> We present the Conversational Data Retrieval (CDR) benchmark, the first
comprehensive test set for evaluating systems that retrieve conversation data
for product insights. With 1.6k queries across five analytical tasks and 9.1k
conversations, our benchmark provides a reliable standard for measuring
conversational data retrieval performance. Our evaluation of 16 popular
embedding models shows that even the best models reach only around NDCG@10 of
0.51, revealing a substantial gap between document and conversational data
retrieval capabilities. Our work identifies unique challenges in conversational
data retrieval (implicit state recognition, turn dynamics, contextual
references) while providing practical query templates and detailed error
analysis across different task categories. The benchmark dataset and code are
available at https://github.com/l-yohai/CDR-Benchmark.

---

### 4. Less LLM, More Documents: Searching for Improved RAG

- **LLM Score**: 8
- **Keyword Score**: 8
- **Authors**: Jingjie Ning, Yibo Kong, Yunfan Long, Jamie Callan
- **URL**: <http://arxiv.org/abs/2510.02657v1>
- **Submitted**: 2025-10-03 01:26:13
- **Comment**: 16 pages. Submitted to ECIR 2026
- **Topic Keywords**: retriever, rag, retrieval, search
- **Reason**: This paper is highly relevant to Information Retrieval, specifically in the context of Retrieval-Augmented Generation (RAG), which is a query understanding and ranking model. The focus on corpus scaling as an alternative to increasing model size aligns with the user's interest in real-time relevance optimization and deep semantic understanding. However, the e-commerce domain is not explicitly mentioned, which is why the score is not a perfect 10.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Retrieval Augmented Generation (RAG) Systems
- **Aim**: Investigate the impact of scaling the retrieval corpus on RAG performance, particularly for smaller language models (LLMs).
- **Rationale**: Challenge the prevailing trend of solely scaling LLM size by proposing that expanding the retrieval corpus can be a more efficient and practical approach, especially for smaller LLMs.
- **Ground**: Three benchmark datasets: NQ, TriviaQA, and WebQ.
- **Experiment**: Full-factorial experimental design, systematically varying both corpus size (using ClueWeb22-A shards) and LLM size (Qwen3 models from 0.6B to 14B parameters).
- **Takeaway**: Scaling the retrieval corpus consistently improves RAG performance, particularly for smaller LLMs. Performance gains saturate after a 5-6x increase in corpus size. Mid-sized generators paired with larger corpora can achieve comparable or better performance than very large models.

#### Abstract
> Retrieval-Augmented Generation (RAG) couples document retrieval with large
language models (LLMs). While scaling generators improves accuracy, it also
raises cost and limits deployability. We explore an orthogonal axis: enlarging
the retriever's corpus to reduce reliance on large LLMs. Experimental results
show that corpus scaling consistently strengthens RAG and can often serve as a
substitute for increasing model size, though with diminishing returns at larger
scales. Small- and mid-sized generators paired with larger corpora often rival
much larger models with smaller corpora; mid-sized models tend to gain the
most, while tiny and large models benefit less. Our analysis shows that
improvements arise primarily from increased coverage of answer-bearing
passages, while utilization efficiency remains largely unchanged. These
findings establish a principled corpus-generator trade-off: investing in larger
corpora offers an effective path to stronger RAG, often comparable to enlarging
the LLM itself.

---

### 5. Hierarchical Semantic Retrieval with Cobweb

- **LLM Score**: 8
- **Keyword Score**: 7
- **Authors**: Anant Gupta, Karthik Singaravadivelan, Zekun Wang
- **URL**: <http://arxiv.org/abs/2510.02539v1>
- **Submitted**: 2025-10-02 20:14:52
- **Comment**: 20 pages, 7 tables, 4 figures
- **Topic Keywords**: relevance, retrieval, rank, search
- **Reason**: This paper explores hierarchical semantic retrieval, which aligns with your interest in query understanding and ranking models. The use of a hierarchy-aware framework and prototype tree for ranking documents is particularly relevant to your focus on deep semantic understanding and real-time relevance optimization in information retrieval.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Hierarchical Semantic Retrieval
- **Aim**: To develop a novel framework, Cobweb, that leverages prototype-based reasoning for improved hierarchical semantic retrieval.
- **Rationale**: Traditional flat vector-space matching lacks the nuance to capture complex document relationships. Cobweb's prototype tree structure allows for multi-granular relevance signals, enabling a more sophisticated understanding of document semantics.
- **Ground**: Sentence embeddings are organized into a prototype tree, where internal nodes represent concepts and leaf nodes correspond to documents.
- **Experiment**: Cobweb is evaluated on MS MARCO and QQP datasets using both encoder (BERT/T5) and decoder (GPT-2) representations.  Performance is compared to baseline dot product search and variations of Cobweb are explored.
- **Takeaway**: Cobweb achieves comparable or superior performance to dot product search, particularly with weaker embeddings. Its hierarchical structure and multi-step aggregation mitigate data anisotropy, leading to improved retrieval effectiveness and interpretability.

#### Abstract
> Neural document retrieval often treats a corpus as a flat cloud of vectors
scored at a single granularity, leaving corpus structure underused and
explanations opaque. We use Cobweb--a hierarchy-aware framework--to organize
sentence embeddings into a prototype tree and rank documents via coarse-to-fine
traversal. Internal nodes act as concept prototypes, providing multi-granular
relevance signals and a transparent rationale through retrieval paths. We
instantiate two inference approaches: a generalized best-first search and a
lightweight path-sum ranker. We evaluate our approaches on MS MARCO and QQP
with encoder (e.g., BERT/T5) and decoder (GPT-2) representations. Our results
show that our retrieval approaches match the dot product search on strong
encoder embeddings while remaining robust when kNN degrades: with GPT-2
vectors, dot product performance collapses whereas our approaches still
retrieve relevant results. Overall, our experiments suggest that Cobweb
provides competitive effectiveness, improved robustness to embedding quality,
scalability, and interpretable retrieval via hierarchical prototypes.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Uncertainty as Feature Gaps: Epistemic Uncertainty Quantification of LLMs in Contextual Question-Answering

- **LLM Score**: 8
- **Keyword Score**: 1
- **Authors**: Yavuz Bakman, Sungmin Kang, Zhiqi Huang, Duygu Nur Yaldiz, Catarina G. Bel√©m, Chenyang Zhu, Anoop Kumar, Alfy Samuel, Salman Avestimehr, Daben Liu, Sai Praneeth Karimireddy
- **URL**: <http://arxiv.org/abs/2510.02671v1>
- **Submitted**: 2025-10-03 02:09:25
- **Topic Keywords**: search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of query understanding and ranking models. The focus on uncertainty quantification in contextual question-answering aligns with your interest in deep semantic understanding and real-time relevance optimization. However, the specific application to Large Language Models (LLMs) is a more specialized area, which prevents it from being a perfect match.

#### Abstract
> Uncertainty Quantification (UQ) research has primarily focused on closed-book
factual question answering (QA), while contextual QA remains unexplored,
despite its importance in real-world applications. In this work, we focus on UQ
for the contextual QA task and propose a theoretically grounded approach to
quantify epistemic uncertainty. We begin by introducing a task-agnostic,
token-level uncertainty measure defined as the cross-entropy between the
predictive distribution of the given model and the unknown true distribution.
By decomposing this measure, we isolate the epistemic component and approximate
the true distribution by a perfectly prompted, idealized model. We then derive
an upper bound for epistemic uncertainty and show that it can be interpreted as
semantic feature gaps in the given model's hidden representations relative to
the ideal model. We further apply this generic framework to the contextual QA
task and hypothesize that three features approximate this gap: context-reliance
(using the provided context rather than parametric knowledge), context
comprehension (extracting relevant information from context), and honesty
(avoiding intentional lies). Using a top-down interpretability approach, we
extract these features by using only a small number of labeled samples and
ensemble them to form a robust uncertainty score. Experiments on multiple QA
benchmarks in both in-distribution and out-of-distribution settings show that
our method substantially outperforms state-of-the-art unsupervised
(sampling-free and sampling-based) and supervised UQ methods, achieving up to a
13-point PRR improvement while incurring a negligible inference overhead.

### 7. Knowledge-Graph Based RAG System Evaluation Framework

- **LLM Score**: 7
- **Keyword Score**: 10
- **Authors**: Sicheng Dong, Vahid Zolfaghari, Nenad Petrovic, Alois Knoll
- **URL**: <http://arxiv.org/abs/2510.02549v1>
- **Submitted**: 2025-10-02 20:36:21
- **Topic Keywords**: relevance, rag, retrieval augmented generation, retrieval, search
- **Reason**: The paper discusses Retrieval Augmented Generation (RAG) systems, which is related to query understanding and ranking models in Information Retrieval. Although it's not directly focused on e-commerce, it explores the evaluation of RAG systems using knowledge graphs, which is relevant to deep semantic understanding and real-time relevance optimization. However, it's not a central match to the user's core research themes.

#### Abstract
> Large language models (LLMs) has become a significant research focus and is
utilized in various fields, such as text generation and dialog systems. One of
the most essential applications of LLM is Retrieval Augmented Generation (RAG),
which greatly enhances generated content's reliability and relevance. However,
evaluating RAG systems remains a challenging task. Traditional evaluation
metrics struggle to effectively capture the key features of modern
LLM-generated content that often exhibits high fluency and naturalness.
Inspired by the RAGAS tool, a well-known RAG evaluation framework, we extended
this framework into a KG-based evaluation paradigm, enabling multi-hop
reasoning and semantic community clustering to derive more comprehensive
scoring metrics. By incorporating these comprehensive evaluation criteria, we
gain a deeper understanding of RAG systems and a more nuanced perspective on
their performance. To validate the effectiveness of our approach, we compare
its performance with RAGAS scores and construct a human-annotated subset to
assess the correlation between human judgments and automated metrics. In
addition, we conduct targeted experiments to demonstrate that our KG-based
evaluation method is more sensitive to subtle semantic differences in generated
outputs. Finally, we discuss the key challenges in evaluating RAG systems and
highlight potential directions for future research.

### 8. A Simple but Effective Elaborative Query Reformulation Approach for Natural Language Recommendation

- **LLM Score**: 6
- **Keyword Score**: 12
- **Authors**: Qianfeng Wen, Yifan Liu, Justin Cui, Joshua Zhang, Anton Korikov, George-Kirollos Saad, Scott Sanner
- **URL**: <http://arxiv.org/abs/2510.02656v1>
- **Submitted**: 2025-10-03 01:21:55
- **Comment**: 11 pages, 5 figures
- **Topic Keywords**: dense retrieval, query, queries, retrieval, recommend
- **Reason**: The paper explores query reformulation in Natural Language Recommendation, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the focus on recommender systems and dense retrieval methods is not a central match to your primary research themes, although it does touch on query understanding and real-time relevance optimization.

#### Abstract
> Natural Language (NL) recommender systems aim to retrieve relevant items from
free-form user queries and item descriptions. Existing systems often rely on
dense retrieval (DR), which struggles to interpret challenging queries that
express broad (e.g., "cities for youth friendly activities") or indirect (e.g.,
"cities for a high school graduation trip") user intents. While query
reformulation (QR) has been widely adopted to improve such systems, existing QR
methods tend to focus only on expanding the range of query subtopics (breadth)
or elaborating on the potential meaning of a query (depth), but not both. In
this paper, we propose EQR (Elaborative Subtopic Query Reformulation), a large
language model-based QR method that combines both breadth and depth by
generating potential query subtopics with information-rich elaborations. We
also introduce three new natural language recommendation benchmarks in travel,
hotel, and restaurant domains to establish evaluation of NL recommendation with
challenging queries. Experiments show EQR substantially outperforms
state-of-the-art QR methods in various evaluation metrics, highlighting that a
simple yet effective QR approach can significantly improve NL recommender
systems for queries with broad and indirect user intents.

### 9. StepChain GraphRAG: Reasoning Over Knowledge Graphs for Multi-Hop Question Answering

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Tengjun Ni, Xin Yuan, Shenghong Li, Kai Wu, Ren Ping Liu, Wei Ni, Wenjie Zhang
- **URL**: <http://arxiv.org/abs/2510.02827v1>
- **Submitted**: 2025-10-03 09:06:37
- **Topic Keywords**: query, rag, retrieval, search
- **Reason**: The paper focuses on multi-hop question answering and knowledge graph reasoning, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on question answering and knowledge graphs does not directly align with the user's core research themes, and the relevance to user's interests is limited.

#### Abstract
> Recent progress in retrieval-augmented generation (RAG) has led to more
accurate and interpretable multi-hop question answering (QA). Yet, challenges
persist in integrating iterative reasoning steps with external knowledge
retrieval. To address this, we introduce StepChain GraphRAG, a framework that
unites question decomposition with a Breadth-First Search (BFS) Reasoning Flow
for enhanced multi-hop QA. Our approach first builds a global index over the
corpus; at inference time, only retrieved passages are parsed on-the-fly into a
knowledge graph, and the complex query is split into sub-questions. For each
sub-question, a BFS-based traversal dynamically expands along relevant edges,
assembling explicit evidence chains without overwhelming the language model
with superfluous context. Experiments on MuSiQue, 2WikiMultiHopQA, and HotpotQA
show that StepChain GraphRAG achieves state-of-the-art Exact Match and F1
scores. StepChain GraphRAG lifts average EM by 2.57% and F1 by 2.13% over the
SOTA method, achieving the largest gain on HotpotQA (+4.70% EM, +3.44% F1).
StepChain GraphRAG also fosters enhanced explainability by preserving the
chain-of-thought across intermediate retrieval steps. We conclude by discussing
how future work can mitigate the computational overhead and address potential
hallucinations from large language models to refine efficiency and reliability
in multi-hop QA.

### 10. FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Imene Kerboua, Sahar Omidi Shayegan, Megh Thakkar, Xing Han L√π, L√©o Boisvert, Massimo Caccia, J√©r√©my Espinas, Alexandre Aussem, V√©ronique Eglin, Alexandre Lacoste
- **URL**: <http://arxiv.org/abs/2510.03204v1>
- **Submitted**: 2025-10-03 17:41:30
- **Topic Keywords**: retriever, rag, retrieval
- **Reason**: The paper discusses web agents and large language models, but its focus on pruning irrelevant content and improving efficiency in web agents doesn't directly align with your core research themes in Information Retrieval and Search technologies. While it touches on relevant topics like query understanding and real-time relevance optimization, the context is more specific to web agents and security, which is not a central match to your interests.

#### Abstract
> Web agents powered by large language models (LLMs) must process lengthy web
page observations to complete user goals; these pages often exceed tens of
thousands of tokens. This saturates context limits and increases computational
cost processing; moreover, processing full pages exposes agents to security
risks such as prompt injection. Existing pruning strategies either discard
relevant content or retain irrelevant context, leading to suboptimal action
prediction. We introduce FocusAgent, a simple yet effective approach that
leverages a lightweight LLM retriever to extract the most relevant lines from
accessibility tree (AxTree) observations, guided by task goals. By pruning
noisy and irrelevant content, FocusAgent enables efficient reasoning while
reducing vulnerability to injection attacks. Experiments on WorkArena and
WebArena benchmarks show that FocusAgent matches the performance of strong
baselines, while reducing observation size by over 50%. Furthermore, a variant
of FocusAgent significantly reduces the success rate of prompt-injection
attacks, including banner and pop-up attacks, while maintaining task success
performance in attack-free settings. Our results highlight that targeted
LLM-based retrieval is a practical and robust strategy for building web agents
that are efficient, effective, and secure.

### 11. AgenticRAG: Tool-Augmented Foundation Models for Zero-Shot Explainable Recommender Systems

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Bo Ma, Hang Li, ZeHua Hu, XiaoFan Gui, LuYao Liu, Simon Liu
- **URL**: <http://arxiv.org/abs/2510.02668v1>
- **Submitted**: 2025-10-03 01:52:37
- **Topic Keywords**: rag, ctr, retrieval, recommend
- **Reason**: The paper introduces a novel framework for recommender systems, leveraging foundation models and retrieval-augmented generation. While it touches on explainability and transparency, the primary focus is on recommender systems rather than information retrieval. The paper's emphasis on tool-augmented foundation models and zero-shot explainable recommendations is somewhat related to query understanding and ranking models, but it does not directly align with the user's core research themes in IR and search technologies.

#### Abstract
> Foundation models have revolutionized artificial intelligence, yet their
application in recommender systems remains limited by reasoning opacity and
knowledge constraints. This paper introduces AgenticRAG, a novel framework that
combines tool-augmented foundation models with retrieval-augmented generation
for zero-shot explainable recommendations. Our approach integrates external
tool invocation, knowledge retrieval, and chain-of-thought reasoning to create
autonomous recommendation agents capable of transparent decision-making without
task-specific training. Experimental results on three real-world datasets
demonstrate that AgenticRAG achieves consistent improvements over
state-of-the-art baselines, with NDCG@10 improvements of 0.4\% on Amazon
Electronics, 0.8\% on MovieLens-1M, and 1.6\% on Yelp datasets. The framework
exhibits superior explainability while maintaining computational efficiency
comparable to traditional methods.

### 12. Model-Based Ranking of Source Languages for Zero-Shot Cross-Lingual Transfer

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Abteen Ebrahimi, Adam Wiemerslage, Katharina von der Wense
- **URL**: <http://arxiv.org/abs/2510.03202v1>
- **Submitted**: 2025-10-03 17:39:44
- **Comment**: Accepted to EMNLP 2025 (Main)
- **Topic Keywords**: ranking, rag, rank
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it involves ranking models and cross-lingual transfer. However, the focus on source language ranking for zero-shot cross-lingual transfer is not directly aligned with your primary interests in query understanding, ranking models, and user behavior modeling. While the paper does leverage multilingual models, it is more focused on NLP applications rather than search technologies.

#### Abstract
> We present NN-Rank, an algorithm for ranking source languages for
cross-lingual transfer, which leverages hidden representations from
multilingual models and unlabeled target-language data. We experiment with two
pretrained multilingual models and two tasks: part-of-speech tagging (POS) and
named entity recognition (NER). We consider 51 source languages and evaluate on
56 and 72 target languages for POS and NER, respectively. When using in-domain
data, NN-Rank beats state-of-the-art baselines that leverage lexical and
linguistic features, with average improvements of up to 35.56 NDCG for POS and
18.14 NDCG for NER. As prior approaches can fall back to language-level
features if target language data is not available, we show that NN-Rank remains
competitive using only the Bible, an out-of-domain corpus available for a large
number of languages. Ablations on the amount of unlabeled target data show
that, for subsets consisting of as few as 25 examples, NN-Rank produces
high-quality rankings which achieve 92.8% of the NDCG achieved using all
available target data for ranking.

### 13. EditLens: Quantifying the Extent of AI Editing in Text

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Katherine Thai, Bradley Emi, Elyas Masrour, Mohit Iyyer
- **URL**: <http://arxiv.org/abs/2510.03154v1>
- **Submitted**: 2025-10-03 16:27:48
- **Topic Keywords**: queries, rag, search
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Information Retrieval (IR), particularly in the context of query understanding and text analysis. However, it focuses on text editing and authorship attribution, which is not a central match to your primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> A significant proportion of queries to large language models ask them to edit
user-provided text, rather than generate new text from scratch. While previous
work focuses on detecting fully AI-generated text, we demonstrate that
AI-edited text is distinguishable from human-written and AI-generated text.
First, we propose using lightweight similarity metrics to quantify the
magnitude of AI editing present in a text given the original human-written text
and validate these metrics with human annotators. Using these similarity
metrics as intermediate supervision, we then train EditLens, a regression model
that predicts the amount of AI editing present within a text. Our model
achieves state-of-the-art performance on both binary (F1=94.7%) and ternary
(F1=90.4%) classification tasks in distinguishing human, AI, and mixed writing.
Not only do we show that AI-edited text can be detected, but also that the
degree of change made by AI to human writing can be detected, which has
implications for authorship attribution, education, and policy. Finally, as a
case study, we use our model to analyze the effects of AI-edits applied by
Grammarly, a popular writing assistance tool. To encourage further research, we
commit to publicly releasing our models and dataset.

### 14. Evaluating Large Language Models for IUCN Red List Species Information

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Shinya Uryu
- **URL**: <http://arxiv.org/abs/2510.02830v1>
- **Submitted**: 2025-10-03 09:09:35
- **Comment**: 20 pages, 7 figures
- **Topic Keywords**: information retrieval, retrieval, recommend
- **Reason**: The paper discusses the application of Large Language Models (LLMs) in conservation, specifically their reliability for species evaluation. While it touches on information retrieval, the focus is on the limitations and biases of LLMs in conservation reasoning, which is somewhat related to the user's interests in query understanding and ranking models, but not a central match.

#### Abstract
> Large Language Models (LLMs) are rapidly being adopted in conservation to
address the biodiversity crisis, yet their reliability for species evaluation
is uncertain. This study systematically validates five leading models on 21,955
species across four core IUCN Red List assessment components: taxonomy,
conservation status, distribution, and threats. A critical paradox was
revealed: models excelled at taxonomic classification (94.9%) but consistently
failed at conservation reasoning (27.2% for status assessment). This
knowledge-reasoning gap, evident across all models, suggests inherent
architectural constraints, not just data limitations. Furthermore, models
exhibited systematic biases favoring charismatic vertebrates, potentially
amplifying existing conservation inequities. These findings delineate clear
boundaries for responsible LLM deployment: they are powerful tools for
information retrieval but require human oversight for judgment-based decisions.
A hybrid approach is recommended, where LLMs augment expert capacity while
human experts retain sole authority over risk assessment and policy.

### 15. AutoMaAS: Self-Evolving Multi-Agent Architecture Search for Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Bo Ma, Hang Li, ZeHua Hu, XiaoFan Gui, LuYao Liu, Simon Liu
- **URL**: <http://arxiv.org/abs/2510.02669v1>
- **Submitted**: 2025-10-03 01:57:07
- **Topic Keywords**: query, rag, search
- **Reason**: While the paper discusses the application of large language models, it primarily focuses on multi-agent architecture search, which is somewhat related to my interests in Information Retrieval and Search technologies. However, the paper's emphasis on large language models and multi-agent systems is not directly aligned with my core research themes, which include query understanding, ranking models, and user behavior modeling.

#### Abstract
> Multi-agent systems powered by large language models have demonstrated
remarkable capabilities across diverse domains, yet existing automated design
approaches seek monolithic solutions that fail to adapt resource allocation
based on query complexity and domain requirements. This paper introduces
AutoMaAS, a self-evolving multi-agent architecture search framework that
leverages neural architecture search principles to automatically discover
optimal agent configurations through dynamic operator lifecycle management and
automated machine learning techniques. Our approach incorporates four key
innovations: (1) automatic operator generation, fusion, and elimination based
on performance-cost analysis, (2) dynamic cost-aware optimization with
real-time parameter adjustment, (3) online feedback integration for continuous
architecture refinement, and (4) enhanced interpretability through decision
tracing mechanisms. Extensive experiments across six benchmarks demonstrate
that AutoMaAS achieves 1.0-7.1\% performance improvement while reducing
inference costs by 3-5\% compared to state-of-the-art methods. The framework
shows superior transferability across datasets and LLM backbones, establishing
a new paradigm for automated multi-agent system design in the era of large
language models.

### 16. SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys?

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Zhaojun Sun, Xuzhou Zhu, Xuanhe Zhou, Xin Tong, Shuo Wang, Jie Fu, Guoliang Li, Zhiyuan Liu, Fan Wu
- **URL**: <http://arxiv.org/abs/2510.03120v1>
- **Submitted**: 2025-10-03 15:49:09
- **Topic Keywords**: rag, search
- **Reason**: This paper is somewhat relevant to your research interests in Information Retrieval, particularly in the area of query understanding and ranking models. However, it focuses on survey writing and evaluation, which is not a central match to your primary focus on real-time relevance optimization and deep semantic understanding. The paper's use of LLMs is also tangentially related to your interests in Learning to Rank and user behavior modeling.

#### Abstract
> Academic survey writing, which distills vast literature into a coherent and
insightful narrative, remains a labor-intensive and intellectually demanding
task. While recent approaches, such as general DeepResearch agents and
survey-specialized methods, can generate surveys automatically (a.k.a.
LLM4Survey), their outputs often fall short of human standards and there lacks
a rigorous, reader-aligned benchmark for thoroughly revealing their
deficiencies. To fill the gap, we propose a fine-grained, quiz-driven
evaluation framework SurveyBench, featuring (1) typical survey topics source
from recent 11,343 arXiv papers and corresponding 4,947 high-quality surveys;
(2) a multifaceted metric hierarchy that assesses the outline quality (e.g.,
coverage breadth, logical coherence), content quality (e.g., synthesis
granularity, clarity of insights), and non-textual richness; and (3) a
dual-mode evaluation protocol that includes content-based and quiz-based
answerability tests, explicitly aligned with readers' informational needs.
Results show SurveyBench effectively challenges existing LLM4Survey approaches
(e.g., on average 21% lower than human in content-based evaluation).

### 17. SoT: Structured-of-Thought Prompting Guides Multilingual Reasoning in Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Rui Qi, Zhibo Man, Yufeng Chen, Fengran Mo, Jinan Xu, Kaiyu Huang
- **URL**: <http://arxiv.org/abs/2510.02648v1>
- **Submitted**: 2025-10-03 01:02:14
- **Comment**: EMNLP 2025 (findings)
- **Topic Keywords**: query
- **Reason**: The paper explores a method for improving multilingual reasoning in Large Language Models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on language models and multilingual reasoning does not directly align with the user's primary research themes. The paper's relevance is somewhat enhanced by its mention of structured representations and reasoning pathways, which may be of interest in the broader context of NLP and data mining.

#### Abstract
> Recent developments have enabled Large Language Models (LLMs) to engage in
complex reasoning tasks through deep thinking. However, the capacity of
reasoning has not been successfully transferred to non-high-resource languages
due to resource constraints, which struggles with multilingual reasoning tasks.
To this end, we propose Structured-of-Thought (SoT), a training-free method
that improves the performance on multilingual reasoning through a multi-step
transformation: Language Thinking Transformation and Structured Knowledge
Transformation. The SoT method converts language-specific semantic information
into language-agnostic structured representations, enabling the models to
understand the query in different languages more sophisticated. Besides, SoT
effectively guides LLMs toward more concentrated reasoning to maintain
consistent underlying reasoning pathways when handling cross-lingual variations
in expression. Experimental results demonstrate that SoT outperforms several
strong baselines on multiple multilingual reasoning benchmarks when adapting to
various backbones of LLMs. It can also be integrated with other training-free
strategies for further improvements. Our code is available at
https://github.com/Cherry-qwq/SoT.

### 18. Self-Anchor: Large Language Model Reasoning via Step-by-step Attention Alignment

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Hongxiang Zhang, Yuan Tian, Tianyi Zhang
- **URL**: <http://arxiv.org/abs/2510.03223v1>
- **Submitted**: 2025-10-03 17:56:33
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Large Language Models, but it does not directly address query understanding, ranking models, or user behavior modeling in the context of Information Retrieval. The focus on Large Language Model reasoning and attention alignment is an interesting aspect, but it does not seem to be a central match with your primary research themes.

#### Abstract
> To solve complex reasoning tasks for Large Language Models (LLMs),
prompting-based methods offer a lightweight alternative to fine-tuning and
reinforcement learning. However, as reasoning chains extend, critical
intermediate steps and the original prompt will be buried in the context,
receiving insufficient attention and leading to errors. In this paper, we
propose Self-Anchor, a novel pipeline that leverages the inherent structure of
reasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories
into structured plans and automatically aligns the model's attention to the
most relevant inference steps, allowing the model to maintain focus throughout
generation. Our experiment shows that Self-Anchor outperforms SOTA prompting
methods across six benchmarks. Notably, Self-Anchor significantly reduces the
performance gap between ``non-reasoning'' models and specialized reasoning
models, with the potential to enable most LLMs to tackle complex reasoning
tasks without retraining.

### 19. XTRA: Cross-Lingual Topic Modeling with Topic and Representation Alignments

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Tien Phat Nguyen, Vu Minh Ngo, Tung Nguyen, Linh Van Ngo, Duc Anh Nguyen, Sang Dinh, Trung Le
- **URL**: <http://arxiv.org/abs/2510.02788v1>
- **Submitted**: 2025-10-03 07:46:23
- **Comment**: 2025 EMNLP Findings
- **Topic Keywords**: rag
- **Reason**: The paper focuses on cross-lingual topic modeling, which is somewhat related to information retrieval and natural language processing. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's emphasis on topic coherence and alignment is relevant to deep semantic understanding, but the context is more focused on text analysis rather than search technologies.

#### Abstract
> Cross-lingual topic modeling aims to uncover shared semantic themes across
languages. Several methods have been proposed to address this problem,
leveraging both traditional and neural approaches. While previous methods have
achieved some improvements in topic diversity, they often struggle to ensure
high topic coherence and consistent alignment across languages. We propose XTRA
(Cross-Lingual Topic Modeling with Topic and Representation Alignments), a
novel framework that unifies Bag-of-Words modeling with multilingual
embeddings. XTRA introduces two core components: (1) representation alignment,
aligning document-topic distributions via contrastive learning in a shared
semantic space; and (2) topic alignment, projecting topic-word distributions
into the same space to enforce crosslingual consistency. This dual mechanism
enables XTRA to learn topics that are interpretable (coherent and diverse) and
well-aligned across languages. Experiments on multilingual corpora confirm that
XTRA significantly outperforms strong baselines in topic coherence, diversity,
and alignment quality. Code and reproducible scripts are available at https:
//github.com/tienphat140205/XTRA.

### 20. On the Role of Temperature Sampling in Test-Time Scaling

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Yuheng Wu, Azalia Mirhoseini, Thierry Tambe
- **URL**: <http://arxiv.org/abs/2510.02611v1>
- **Submitted**: 2025-10-02 23:09:56
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and deep semantic understanding, but it focuses on test-time scaling and temperature sampling in large language models, which is not a central match for the user's core research themes in Information Retrieval and Search technologies.

#### Abstract
> Large language models (LLMs) can improve reasoning at inference time through
test-time scaling (TTS), where multiple reasoning traces are generated and the
best one is selected. Prior work shows that increasing the number of samples K
steadily improves accuracy. In this paper, we demonstrate that this trend does
not hold indefinitely: at large K, further scaling yields no gains, and certain
hard questions remain unsolved regardless of the number of traces.
Interestingly, we find that different sampling temperatures solve different
subsets of problems, implying that single-temperature scaling explores only
part of a model's potential. We therefore propose scaling along the temperature
dimension, which enlarges the reasoning boundary of LLMs. Averaged over Qwen3
(0.6B, 1.7B, 4B, 8B) and five representative reasoning benchmarks (AIME
2024/2025, MATH500, LiveCodeBench, Hi-ToM), temperature scaling yields an
additional 7.3 points over single-temperature TTS. Temperature scaling also
enables base models to reach performance comparable to reinforcement learning
(RL)-trained counterparts, without additional post-training. We further provide
a comprehensive analysis of this phenomenon and design a multi-temperature
voting method that reduces the overhead of temperature scaling. Overall, our
findings suggest that TTS is more powerful than previously thought, and that
temperature scaling offers a simple and effective way to unlock the latent
potential of base models.

### 21. Reward Models are Metrics in a Trench Coat

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Sebastian Gehrmann
- **URL**: <http://arxiv.org/abs/2510.03231v1>
- **Submitted**: 2025-10-03 17:59:44
- **Topic Keywords**: search
- **Reason**: This paper discusses the intersection of reward models and evaluation metrics in the context of reinforcement learning and large language models. While it touches on relevant topics, it does not directly address the user's core research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. The paper's focus on reinforcement learning and post-training of large language models makes it somewhat related but not a central match for the user's research interests.

#### Abstract
> The emergence of reinforcement learning in post-training of large language
models has sparked significant interest in reward models. Reward models assess
the quality of sampled model outputs to generate training signals. This task is
also performed by evaluation metrics that monitor the performance of an AI
model. We find that the two research areas are mostly separate, leading to
redundant terminology and repeated pitfalls. Common challenges include
susceptibility to spurious correlations, impact on downstream reward hacking,
methods to improve data quality, and approaches to meta-evaluation. Our
position paper argues that a closer collaboration between the fields can help
overcome these issues. To that end, we show how metrics outperform reward
models on specific tasks and provide an extensive survey of the two areas.
Grounded in this survey, we point to multiple research topics in which closer
alignment can improve reward models and metrics in areas such as preference
elicitation methods, avoidance of spurious correlations and reward hacking, and
calibration-aware meta-evaluation.

### 22. Unraveling Syntax: How Language Models Learn Context-Free Grammars

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Laura Ying Schulz, Daniel Mitropolsky, Tomaso Poggio
- **URL**: <http://arxiv.org/abs/2510.02524v1>
- **Submitted**: 2025-10-02 19:52:19
- **Comment**: Equal contribution by LYS and DM
- **Topic Keywords**: search
- **Reason**: This paper explores the learning dynamics of language models on probabilistic context-free grammars, which is related to deep semantic understanding in NLP. However, the focus is on syntax acquisition rather than query understanding or ranking models, making it somewhat relevant but not a central match for your research interests.

#### Abstract
> We introduce a new framework for understanding how language models acquire
syntax. While large models achieve impressive results, little is known about
their learning dynamics. Our approach starts with the observation that most
domains of interest, such as natural language syntax, coding languages,
arithmetic problems, are captured by probabilistic context-free grammars
(PCFGs). We study the learning dynamics of small models trained on synthetic
languages generated from PCFGs, enabling precise control over grammar
complexity, recursion depth, and subgrammar structure. We prove several
general, recursive formulae for the training loss and Kullback-Leibler
divergence over the subgrammar structure of a PCFG. Empirically, we find that
unlike children, who first master simple substructures before progressing to
more complex constructions, transformers reduce loss across all subgrammars in
parallel. We further show that subgrammar pretraining can improve the final
loss for smaller models, and that pretrained models develop internal
representations more aligned with the grammar's substructure. Finally, we
demonstrate that models struggle with deeper recursive structures (a limitation
even of large language models), revealing fundamental challenges in how neural
networks represent hierarchical syntax. Overall, our work initiates the study
of the learning dynamics of transformers on PCFGs as a versatile testbed for
probing learning in language models, opening a research direction with many
open questions.

### 23. How to Train Your Advisor: Steering Black-Box LLMs with Advisor Models

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Parth Asawa, Alan Zhu, Matei Zaharia, Alexandros G. Dimakis, Joseph E. Gonzalez
- **URL**: <http://arxiv.org/abs/2510.02453v1>
- **Submitted**: 2025-10-02 18:02:39
- **Topic Keywords**: personalization
- **Reason**: This paper introduces Advisor Models, which can be seen as a form of query understanding and ranking model, but its primary focus is on black-box LLMs and dynamic optimization. While it touches on personalization and environment-adaptable AI, it doesn't directly relate to information retrieval or search technologies. The paper's relevance to your interests is somewhat related, but not a central match.

#### Abstract
> Foundation models are increasingly deployed as black-box services, where
model weights cannot be modified and customization is limited to prompting.
While static prompt optimization has shown promise, it produces a single fixed
prompt that fails to adapt to different inputs, users, or environments. We
introduce Advisor Models, lightweight parametric policies trained with
reinforcement learning to reactively issue natural language steering
instructions in-context to black-box models. The advisor is a second small
model that sits between the input and the model, shaping behavior on a
per-instance basis using reward signals from the environment. Across multiple
domains involving reasoning and personalization, we show that Advisor Models
outperform static prompt optimizers, discovering environment dynamics and
improving downstream task performance. We also demonstrate the generalizability
of advisors by transferring them across black-box models, as well as the
framework's ability to achieve specialization while retaining robustness to
out-of-distribution inputs. Viewed more broadly, Advisor Models provide a
learnable interface to black-box systems where the advisor acts as a
parametric, environment-specific memory. We argue that dynamic optimization of
black-box models via Advisor Models is a promising direction for enabling
personalization and environment-adaptable AI with frontier-level capabilities.

### 24. CHORD: Customizing Hybrid-precision On-device Model for Sequential Recommendation with Device-cloud Collaboration

- **LLM Score**: 2
- **Keyword Score**: 11
- **Authors**: Tianqi Liu, Kairui Fu, Shengyu Zhang, Wenyan Fan, Zhaocheng Du, Jieming Zhu, Fan Wu, Fei Wu
- **URL**: <http://arxiv.org/abs/2510.03038v1>
- **Submitted**: 2025-10-03 14:20:45
- **Comment**: accepted by ACM MM'25
- **Topic Keywords**: ranking, rerank, rag, recommend, personalization, rank
- **Reason**: This paper focuses on sequential recommendation and model deployment on devices, which is somewhat related to information retrieval, but it primarily deals with recommender systems and model compression, not directly aligning with the user's core research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> With the advancement of mobile device capabilities, deploying reranking
models directly on devices has become feasible, enabling real-time contextual
recommendations. When migrating models from cloud to devices, resource
heterogeneity inevitably necessitates model compression. Recent quantization
methods show promise for efficient deployment, yet they overlook
device-specific user interests, resulting in compromised recommendation
accuracy. While on-device finetuning captures personalized user preference, it
imposes additional computational burden through local retraining. To address
these challenges, we propose a framework for \underline{\textbf{C}}ustomizing
\underline{\textbf{H}}ybrid-precision \underline{\textbf{O}}n-device model for
sequential \underline{\textbf{R}}ecommendation with
\underline{\textbf{D}}evice-cloud collaboration (\textbf{CHORD}), leveraging
channel-wise mixed-precision quantization to simultaneously achieve
personalization and resource-adaptive deployment. CHORD distributes randomly
initialized models across heterogeneous devices and identifies user-specific
critical parameters through auxiliary hypernetwork modules on the cloud. Our
parameter sensitivity analysis operates across multiple granularities (layer,
filter, and element levels), enabling precise mapping from user profiles to
quantization strategy. Through on-device mixed-precision quantization, CHORD
delivers dynamic model adaptation and accelerated inference without
backpropagation, eliminating costly retraining cycles. We minimize
communication overhead by encoding quantization strategies using only 2 bits
per channel instead of 32-bit weights. Experiments on three real-world datasets
with two popular backbones (SASRec and Caser) demonstrate the accuracy,
efficiency, and adaptivity of CHORD.

### 25. Geolog-IA: Conversational System for Academic Theses

- **LLM Score**: 2
- **Keyword Score**: 10
- **Authors**: Micaela Fuel Pozo, Andrea Guatumillo Saltos, Yese√±a Tipan Llumiquinga, Kelly Lascano Aguirre, Marilyn Castillo Jara, Christian Mejia-Escobar
- **URL**: <http://arxiv.org/abs/2510.02653v1>
- **Submitted**: 2025-10-03 01:11:47
- **Comment**: 17 pages, in Spanish language
- **Topic Keywords**: information retrieval, rag, retrieval augmented generation, retrieval, search
- **Reason**: This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves conversational systems and language models, its focus on geology theses and education makes it an off-topic application.

#### Abstract
> This study presents the development of Geolog-IA, a novel conversational
system based on artificial intelligence that responds naturally to questions
about geology theses from the Central University of Ecuador. Our proposal uses
the Llama 3.1 and Gemini 2.5 language models, which are complemented by a
Retrieval Augmented Generation (RAG) architecture and an SQLite database. This
strategy allows us to overcome problems such as hallucinations and outdated
knowledge. The evaluation of Geolog-IA's performance with the BLEU metric
reaches an average of 0.87, indicating high consistency and accuracy in the
responses generated. The system offers an intuitive, web-based interface that
facilitates interaction and information retrieval for directors, teachers,
students, and administrative staff at the institution. This tool can be a key
support in education, training, and research and establishes a basis for future
applications in other disciplines.

### 26. Cache-to-Cache: Direct Semantic Communication Between Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Tianyu Fu, Zihan Min, Hanling Zhang, Jichao Yan, Guohao Dai, Wanli Ouyang, Yu Wang
- **URL**: <http://arxiv.org/abs/2510.03215v1>
- **Submitted**: 2025-10-03 17:52:32
- **Topic Keywords**: rag, acl
- **Reason**: This paper focuses on direct semantic communication between Large Language Models, using a neural network to project and fuse their knowledge caches. While it involves NLP and deep semantic understanding, it is primarily concerned with improving the performance of LLMs, which is not a core area of your research interests in Information Retrieval and Search technologies.

#### Abstract
> Multi-LLM systems harness the complementary strengths of diverse Large
Language Models, achieving performance and efficiency gains unattainable by a
single model. In existing designs, LLMs communicate through text, forcing
internal representations to be transformed into output token sequences. This
process both loses rich semantic information and incurs token-by-token
generation latency. Motivated by these limitations, we ask: Can LLMs
communicate beyond text? Oracle experiments show that enriching the KV-Cache
semantics can improve response quality without increasing cache size,
supporting KV-Cache as an effective medium for inter-model communication. Thus,
we propose Cache-to-Cache (C2C), a new paradigm for direct semantic
communication between LLMs. C2C uses a neural network to project and fuse the
source model's KV-cache with that of the target model to enable direct semantic
transfer. A learnable gating mechanism selects the target layers that benefit
from cache communication. Compared with text communication, C2C utilizes the
deep, specialized semantics from both models, while avoiding explicit
intermediate text generation. Experiments show that C2C achieves 8.5-10.5%
higher average accuracy than individual models. It further outperforms the text
communication paradigm by approximately 3.0-5.0%, while delivering an average
2.0x speedup in latency. Our code is available at
https://github.com/thu-nics/C2C.

### 27. Constraint Satisfaction Approaches to Wordle: Novel Heuristics and Cross-Lexicon Validation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jahidul Arafat, Fariha Tasmin, Sanjaya Poudel, Kamrujjaman, Eftakhar Ahmed Arnob, Ahsan Habib Tareq
- **URL**: <http://arxiv.org/abs/2510.02855v1>
- **Submitted**: 2025-10-03 09:44:14
- **Comment**: 35 pages, 14 figures, 10 tables. Open-source implementation with 91%
  test coverage available at
  https://github.com/jahidul-arafat/constraint_satisfaction_wordle_arxiv_preprint
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on constraint satisfaction problem (CSP) solving for the Wordle game, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. While it involves some form of problem-solving and optimization, the context and techniques used are quite different from those in IR and Search.

#### Abstract
> Wordle presents an algorithmically rich testbed for constraint satisfaction
problem (CSP) solving. While existing solvers rely on information-theoretic
entropy maximization or frequency-based heuristics without formal constraint
treatment, we present the first comprehensive CSP formulation of Wordle with
novel constraint-aware solving strategies. We introduce CSP-Aware Entropy,
computing information gain after constraint propagation rather than on raw
candidate sets, and a Probabilistic CSP framework integrating Bayesian
word-frequency priors with logical constraints. Through evaluation on 2,315
English words, CSP-Aware Entropy achieves 3.54 average guesses with 99.9%
success rate, a statistically significant 1.7% improvement over Forward
Checking (t=-4.82, p<0.001, Cohen's d=0.07) with 46% faster runtime (12.9ms
versus 23.7ms per guess). Under 10% noise, CSP-aware approaches maintain 5.3
percentage point advantages (29.0% versus 23.7%, p=0.041), while Probabilistic
CSP achieves 100% success across all noise levels (0-20%) through constraint
recovery mechanisms. Cross-lexicon validation on 500 Spanish words demonstrates
88% success with zero language-specific tuning, validating that core CSP
principles transfer across languages despite an 11.2 percentage point gap from
linguistic differences (p<0.001, Fisher's exact test). Our open-source
implementation with 34 unit tests achieving 91% code coverage provides
reproducible infrastructure for CSP research. The combination of formal CSP
treatment, constraint-aware heuristics, probabilistic-logical integration,
robustness analysis, and cross-lexicon validation establishes new performance
benchmarks demonstrating that principled constraint satisfaction techniques
outperform classical information-theoretic and learning-based approaches for
structured puzzle-solving domains.

### 28. A Computational Framework for Interpretable Text-Based Personality Assessment from Social Media

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Matej Gjurkoviƒá
- **URL**: <http://arxiv.org/abs/2510.02811v1>
- **Submitted**: 2025-10-03 08:36:36
- **Comment**: Phd thesis
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on personality assessment from social media, which is not directly related to the user's core research themes in Information Retrieval and Search technologies. Although it involves Natural Language Processing, the application domain and methodology are quite different from the user's interests.

#### Abstract
> Personality refers to individual differences in behavior, thinking, and
feeling. With the growing availability of digital footprints, especially from
social media, automated methods for personality assessment have become
increasingly important. Natural language processing (NLP) enables the analysis
of unstructured text data to identify personality indicators. However, two main
challenges remain central to this thesis: the scarcity of large,
personality-labeled datasets and the disconnect between personality psychology
and NLP, which restricts model validity and interpretability. To address these
challenges, this thesis presents two datasets -- MBTI9k and PANDORA --
collected from Reddit, a platform known for user anonymity and diverse
discussions. The PANDORA dataset contains 17 million comments from over 10,000
users and integrates the MBTI and Big Five personality models with demographic
information, overcoming limitations in data size, quality, and label coverage.
Experiments on these datasets show that demographic variables influence model
validity. In response, the SIMPA (Statement-to-Item Matching Personality
Assessment) framework was developed - a computational framework for
interpretable personality assessment that matches user-generated statements
with validated questionnaire items. By using machine learning and semantic
similarity, SIMPA delivers personality assessments comparable to human
evaluations while maintaining high interpretability and efficiency. Although
focused on personality assessment, SIMPA's versatility extends beyond this
domain. Its model-agnostic design, layered cue detection, and scalability make
it suitable for various research and practical applications involving complex
label taxonomies and variable cue associations with target concepts.

### 29. Self-Improvement in Multimodal Large Language Models: A Survey

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Shijian Deng, Kai Wang, Tianyu Yang, Harsh Singh, Yapeng Tian
- **URL**: <http://arxiv.org/abs/2510.02665v1>
- **Submitted**: 2025-10-03 01:48:26
- **Comment**: EMNLP 2025
- **Topic Keywords**: rag, search
- **Reason**: This paper is not directly related to your core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it touches on Large Language Models, the focus is on self-improvement and multimodal aspects, which do not align with your primary interests.

#### Abstract
> Recent advancements in self-improvement for Large Language Models (LLMs) have
efficiently enhanced model capabilities without significantly increasing costs,
particularly in terms of human effort. While this area is still relatively
young, its extension to the multimodal domain holds immense potential for
leveraging diverse data sources and developing more general self-improving
models. This survey is the first to provide a comprehensive overview of
self-improvement in Multimodal LLMs (MLLMs). We provide a structured overview
of the current literature and discuss methods from three perspectives: 1) data
collection, 2) data organization, and 3) model optimization, to facilitate the
further development of self-improvement in MLLMs. We also include commonly used
evaluations and downstream applications. Finally, we conclude by outlining open
challenges and future research directions.

### 30. HyperAdaLoRA: Accelerating LoRA Rank Allocation During Training via Hypernetworks without Sacrificing Performance

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Hao Zhang, Zhenjia Li, Runfeng Bao, Yifan Gao, Xi Xiao, Bo Huang, Yuhang Wu, Tianyang Wang, Hao Xu
- **URL**: <http://arxiv.org/abs/2510.02630v1>
- **Submitted**: 2025-10-03 00:15:59
- **Comment**: 13 pages
- **Topic Keywords**: rag, rank
- **Reason**: This paper focuses on a parameter-efficient fine-tuning approach for large language models, specifically addressing the issue of slow convergence speed and high computational overhead in LoRA. While it involves optimization techniques, it does not directly relate to information retrieval, query understanding, ranking models, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Parameter-Efficient Fine-Tuning (PEFT), especially Low-Rank Adaptation
(LoRA), has emerged as a promising approach to fine-tuning large language
models(LLMs) while reducing computational and memory overhead. However, LoRA
assumes a uniform rank \textit{r} for each incremental matrix, not accounting
for the varying significance of weight matrices across different modules and
layers. AdaLoRA leverages Singular Value Decomposition (SVD) to parameterize
updates and employs pruning of singular values to introduce dynamic rank
allocation, thereby enhancing adaptability. However, during the training
process, it often encounters issues of slow convergence speed and high
computational overhead. To address this issue, we propose HyperAdaLoRA, a novel
framework that accelerates the convergence of AdaLoRA by leveraging a
hypernetwork. Instead of directly optimizing the components of Singular Value
Decomposition $(P, \Lambda, Q)$, HyperAdaLoRA employs a hypernetwork based on
attention mechanisms to dynamically generate these parameters. By pruning the
outputs of the hypernetwork that generates the singular values, dynamic rank
allocation is achieved. Comprehensive experiments on various datasets and
models demonstrate that our method achieves faster convergence without
sacrificing performance. Additionally, further extension experiments on other
LoRA-based approaches validate the broad applicability of our method.

### 31. How Confident are Video Models? Empowering Video Models to Express their Uncertainty

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Zhiting Mei, Ola Shorinwa, Anirudha Majumdar
- **URL**: <http://arxiv.org/abs/2510.02571v1>
- **Submitted**: 2025-10-02 21:20:41
- **Topic Keywords**: rag, rank
- **Reason**: This paper focuses on uncertainty quantification in video models, which is a topic in the broader field of machine learning and deep learning. While it touches on the concept of uncertainty, it does not directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Generative video models demonstrate impressive text-to-video capabilities,
spurring widespread adoption in many real-world applications. However, like
large language models (LLMs), video generation models tend to hallucinate,
producing plausible videos even when they are factually wrong. Although
uncertainty quantification (UQ) of LLMs has been extensively studied in prior
work, no UQ method for video models exists, raising critical safety concerns.
To our knowledge, this paper represents the first work towards quantifying the
uncertainty of video models. We present a framework for uncertainty
quantification of generative video models, consisting of: (i) a metric for
evaluating the calibration of video models based on robust rank correlation
estimation with no stringent modeling assumptions; (ii) a black-box UQ method
for video models (termed S-QUBED), which leverages latent modeling to
rigorously decompose predictive uncertainty into its aleatoric and epistemic
components; and (iii) a UQ dataset to facilitate benchmarking calibration in
video models. By conditioning the generation task in the latent space, we
disentangle uncertainty arising due to vague task specifications from that
arising from lack of knowledge. Through extensive experiments on benchmark
video datasets, we demonstrate that S-QUBED computes calibrated total
uncertainty estimates that are negatively correlated with the task accuracy and
effectively computes the aleatoric and epistemic constituents.

### 32. Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Guanhua Huang, Tingqiang Xu, Mingze Wang, Qi Yi, Xue Gong, Siheng Li, Ruibin Xiong, Kejiao Li, Yuhao Jiang, Bo Zhou
- **URL**: <http://arxiv.org/abs/2510.03222v1>
- **Submitted**: 2025-10-03 17:56:13
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves reinforcement learning and large language models, its focus on exploration in RLVR and the concept of 'reasoning sparks' does not align with the user's primary research interests in IR and NLP.

#### Abstract
> Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large
Language Models in complex reasoning, yet its scalability is often hindered by
a training bottleneck where performance plateaus as policy entropy collapses,
signaling a loss of exploration. Previous methods typically address this by
maintaining high policy entropy, yet the precise mechanisms that govern
meaningful exploration have remained underexplored. Our analysis suggests that
an unselective focus on entropy risks amplifying irrelevant tokens and
destabilizing training. This paper investigates the exploration dynamics within
RLVR and identifies a key issue: the gradual elimination of valuable
low-probability exploratory tokens, which we term \textbf{\textit{reasoning
sparks}}. We find that while abundant in pre-trained models, these sparks are
systematically extinguished during RLVR due to over-penalization, leading to a
degeneracy in exploration. To address this, we introduce Low-probability
Regularization (Lp-Reg). Its core mechanism regularizes the policy towards a
heuristic proxy distribution. This proxy is constructed by filtering out
presumed noise tokens and re-normalizing the distribution over the remaining
candidates. The result is a less-noisy proxy where the probability of
\textit{reasoning sparks} is amplified, which then serves as a soft
regularization target to shield these valuable tokens from elimination via KL
divergence. Experiments show that Lp-Reg enables stable on-policy training for
around 1,000 steps, a regime where baseline entropy-control methods collapse.
This sustained exploration leads to state-of-the-art performance, achieving a
$60.17\%$ average accuracy on five math benchmarks, an improvement of $2.66\%$
over prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.

### 33. Coevolutionary Continuous Discrete Diffusion: Make Your Diffusion Language Model a Latent Reasoner

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Cai Zhou, Chenxiao Yang, Yi Hu, Chenyu Wang, Chubin Zhang, Muhan Zhang, Lester Mackey, Tommi Jaakkola, Stephen Bates, Dinghuai Zhang
- **URL**: <http://arxiv.org/abs/2510.03206v1>
- **Submitted**: 2025-10-03 17:44:41
- **Comment**: 27 pages
- **Topic Keywords**: rag
- **Reason**: This paper focuses on improving diffusion language models, which is a topic in Natural Language Processing (NLP). However, it does not appear to be directly related to Information Retrieval (IR), query understanding, ranking models, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Diffusion language models, especially masked discrete diffusion models, have
achieved great success recently. While there are some theoretical and primary
empirical results showing the advantages of latent reasoning with looped
transformers or continuous chain-of-thoughts, continuous diffusion models
typically underperform their discrete counterparts. In this paper, we argue
that diffusion language models do not necessarily need to be in the discrete
space. In particular, we prove that continuous diffusion models have stronger
expressivity than discrete diffusions and looped transformers. We attribute the
contradiction between the theoretical expressiveness and empirical performance
to their practical trainability: while continuous diffusion provides
intermediate supervision that looped transformers lack, they introduce
additional difficulty decoding tokens into the discrete token space from the
continuous representation space. We therefore propose Coevolutionary Continuous
Discrete Diffusion (CCDD), which defines a joint multimodal diffusion process
on the union of a continuous representation space and a discrete token space,
leveraging a single model to simultaneously denoise in the joint space. By
combining two modalities, CCDD is expressive with rich semantics in the latent
space, as well as good trainability and sample quality with the help of
explicit discrete tokens. We also propose effective architectures and advanced
training/sampling techniques for CCDD, which reveals strong empirical
performance in extensive language modeling experiments on real-world tasks.

### 34. Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yilun Hao, Yongchao Chen, Chuchu Fan, Yang Zhang
- **URL**: <http://arxiv.org/abs/2510.03182v1>
- **Submitted**: 2025-10-03 16:57:01
- **Comment**: 30 pages, 5 figures, 5 tables
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves a Vision Language Model (VLM), the focus is on formal visual planning and planning domain definition language, which is not a central match to your core research themes.

#### Abstract
> Vision Language Models (VLMs) show strong potential for visual planning but
struggle with precise spatial and long-horizon reasoning. In contrast, Planning
Domain Definition Language (PDDL) planners excel at long-horizon formal
planning, but cannot interpret visual inputs. Recent works combine these
complementary advantages by enabling VLMs to turn visual planning problems into
PDDL files for formal planning. However, while VLMs can generate PDDL problem
files satisfactorily, they struggle to accurately generate the PDDL domain
files, which describe all the planning rules. As a result, prior methods rely
on human experts to predefine domain files or on constant environment access
for refinement. We propose VLMFP, a Dual-VLM-guided framework that can
autonomously generate both PDDL problem and domain files for formal visual
planning. VLMFP introduces two VLMs to ensure reliable PDDL file generation: A
SimVLM that simulates action consequences based on input rule descriptions, and
a GenVLM that generates and iteratively refines PDDL files by comparing the
PDDL and SimVLM execution results. VLMFP unleashes multiple levels of
generalizability: The same generated PDDL domain file works for all the
different instances under the same problem, and VLMs generalize to different
problems with varied appearances and rules. We evaluate VLMFP with 6 grid-world
domains and test its generalization to unseen instances, appearance, and game
rules. On average, SimVLM accurately describes 95.5%, 82.6% of scenarios,
simulates 85.5%, 87.8% of action sequence, and judges 82.4%, 85.6% goal
reaching for seen and unseen appearances, respectively. With the guidance of
SimVLM, VLMFP can generate PDDL files to reach 70.0%, 54.1% valid plans for
unseen instances in seen and unseen appearances, respectively. Project page:
https://sites.google.com/view/vlmfp.

### 35. Listening or Reading? Evaluating Speech Awareness in Chain-of-Thought Speech-to-Text Translation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jacobo Romero-D√≠az, Gerard I. G√°llego, Oriol Pareras, Federico Costa, Javier Hernando, Cristina Espa√±a-Bonet
- **URL**: <http://arxiv.org/abs/2510.03115v1>
- **Submitted**: 2025-10-03 15:42:38
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Speech-to-Text Translation and Chain-of-Thought prompting, which is not directly related to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves text processing, the context is specific to speech translation and does not align with your interests in query understanding, ranking models, or user behavior modeling.

#### Abstract
> Speech-to-Text Translation (S2TT) systems built from Automatic Speech
Recognition (ASR) and Text-to-Text Translation (T2TT) modules face two major
limitations: error propagation and the inability to exploit prosodic or other
acoustic cues. Chain-of-Thought (CoT) prompting has recently been introduced,
with the expectation that jointly accessing speech and transcription will
overcome these issues. Analyzing CoT through attribution methods, robustness
evaluations with corrupted transcripts, and prosody-awareness, we find that it
largely mirrors cascaded behavior, relying mainly on transcripts while barely
leveraging speech. Simple training interventions, such as adding Direct S2TT
data or noisy transcript injection, enhance robustness and increase speech
attribution. These findings challenge the assumed advantages of CoT and
highlight the need for architectures that explicitly integrate acoustic
information into translation.

### 36. Self-Reflective Generation at Test Time

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jian Mu, Qixin Zhang, Zhiyong Wang, Menglin Yang, Shuang Qiu, Chengwei Qin, Zhongxiang Dai, Yao Shu
- **URL**: <http://arxiv.org/abs/2510.02919v1>
- **Submitted**: 2025-10-03 11:46:04
- **Comment**: 24 pages, 8 figures
- **Topic Keywords**: rag
- **Reason**: This paper focuses on self-reflective generation in large language models, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves deep semantic understanding, the context is not aligned with the user's primary research interests in IR and search technologies.

#### Abstract
> Large language models (LLMs) increasingly solve complex reasoning tasks via
long chain-of-thought, but their forward-only autoregressive generation process
is fragile; early token errors can cascade, which creates a clear need for
self-reflection mechanisms. However, existing self-reflection either performs
revisions over full drafts or learns self-correction via expensive training,
both fundamentally reactive and inefficient. To address this, we propose
Self-Reflective Generation at Test Time (SRGen), a lightweight test-time
framework that reflects before generating at uncertain points. During token
generation, SRGen utilizes dynamic entropy thresholding to identify
high-uncertainty tokens. For each identified token, it trains a specific
corrective vector, which fully exploits the already generated context for a
self-reflective generation to correct the token probability distribution. By
retrospectively analyzing the partial output, this self-reflection enables more
trustworthy decisions, thereby significantly reducing the probability of errors
at highly uncertain points. Evaluated on challenging mathematical reasoning
benchmarks and a diverse set of LLMs, SRGen can consistently strengthen model
reasoning: improvements in single-pass quality also translate into stronger
self-consistency voting. Especially, on AIME2024 with
DeepSeek-R1-Distill-Qwen-7B, SRGen yields absolute improvements of +12.0% on
Pass@1 and +13.3% on Cons@5. Moreover, our findings position SRGen as a
plug-and-play method that integrates reflection into the generation process for
reliable LLM reasoning, achieving consistent gains with bounded overhead and
broad composability with other training-time (e.g., RLHF) and test-time (e.g.,
SLOT) techniques.

### 37. PGMEL: Policy Gradient-based Generative Adversarial Network for Multimodal Entity Linking

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: KM Pooja, Cheng Long, Aixin Sun
- **URL**: <http://arxiv.org/abs/2510.02726v1>
- **Submitted**: 2025-10-03 05:09:47
- **Topic Keywords**: rag
- **Reason**: This paper focuses on multimodal entity linking using a generative adversarial network, which is not directly related to information retrieval, query understanding, or ranking models. While it involves learning representations, it's more focused on entity linking and knowledge graphs, which doesn't align with the user's primary research interests.

#### Abstract
> The task of entity linking, which involves associating mentions with their
respective entities in a knowledge graph, has received significant attention
due to its numerous potential applications. Recently, various multimodal entity
linking (MEL) techniques have been proposed, targeted to learn comprehensive
embeddings by leveraging both text and vision modalities. The selection of
high-quality negative samples can potentially play a crucial role in
metric/representation learning. However, to the best of our knowledge, this
possibility remains unexplored in existing literature within the framework of
MEL. To fill this gap, we address the multimodal entity linking problem in a
generative adversarial setting where the generator is responsible for
generating high-quality negative samples, and the discriminator is assigned the
responsibility for the metric learning tasks. Since the generator is involved
in generating samples, which is a discrete process, we optimize it using policy
gradient techniques and propose a policy gradient-based generative adversarial
network for multimodal entity linking (PGMEL). Experimental results based on
Wiki-MEL, Richpedia-MEL and WikiDiverse datasets demonstrate that PGMEL learns
meaningful representation by selecting challenging negative samples and
outperforms state-of-the-art methods.

### 38. Beyond Imitation: Recovering Dense Rewards from Demonstrations

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jiangnan Li, Thuy-Trang Vu, Ehsan Abbasnejad, Gholamreza Haffari
- **URL**: <http://arxiv.org/abs/2510.02493v1>
- **Submitted**: 2025-10-02 18:58:26
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Recovering Dense Rewards from Demonstrations using Inverse Reinforcement Learning, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. While it touches on reinforcement learning, it's more aligned with control and decision-making, and doesn't seem to leverage deep semantic understanding or real-time relevance optimization.

#### Abstract
> Conventionally, supervised fine-tuning (SFT) is treated as a simple imitation
learning process that only trains a policy to imitate expert behavior on
demonstration datasets. In this work, we challenge this view by establishing a
fundamental equivalence between SFT and Inverse Reinforcement Learning. We
prove that the SFT objective is a special case of Inverse Q-Learning, which
implies that the SFT process does not just learn a policy, but also an
implicit, dense, token-level reward model that explains the expert
demonstrations. We then show how to recover this dense reward signal directly
from the SFT model by formulating a baseline-relative reward function. The
availability of such a dense reward model offers numerous benefits, providing
granular credit assignment for each token generated. We demonstrate one key
application by using these recovered rewards to further improve the policy with
reinforcement learning. Our method, Dense-Path REINFORCE, consistently
outperforms the original SFT models on instruction-following benchmarks. This
work reframes SFT not merely as policy imitation but as a powerful reward
learning mechanism, opening new possibilities for leveraging expert
demonstrations.

### 39. Litespark Technical Report: High-Throughput, Energy-Efficient LLM Training Framework

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Nii Osae Osae Dade, Moinul Hossain Rahat
- **URL**: <http://arxiv.org/abs/2510.02483v1>
- **Submitted**: 2025-10-02 18:42:07
- **Comment**: 14 pages
- **Topic Keywords**: ctr
- **Reason**: This paper focuses on optimizing Large Language Model (LLM) training, which is not directly related to Information Retrieval or Search technologies. While it involves transformer architectures, the primary goal is energy efficiency and training speed, rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> Training Large Language Models (LLMs) is plagued by long training times and
massive energy consumption, with modern models requiring months of computation
and gigawatt-hours of electricity. In light of these challenges,we introduce
Litespark, a novel pre-training framework that addresses these inefficiencies
through targeted optimizations to transformer attention and MLP layers. Our
approach combines architectural improvements with algorithmic enhancements to
maximize Model FLOPs Utilization (MFU) while maintaining compatibility with
standard transformer implementations. Comprehensive benchmarking on 3B and 30B
parameter Llama models using the SlimPajama-627B dataset demonstrates
substantial performance gains: 2x-6x training throughput improvement and
$55\%-83$% energy consumption reduction across multi-node H200 GPU clusters.
These optimizations are model- and hardware-agnostic, enabling broad
applicability across transformer architectures and extending to post-training
phases including supervised fine-tuning and direct preference optimization.

### 40. OpenZL: A Graph-Based Model for Compression

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yann Collet, Nick Terrell, W. Felix Handte, Danielle Rozenblit, Victor Zhang, Kevin Zhang, Yaelle Goldschlag, Jennifer Lee, Daniel Riegel, Stan Angelov, Nadav Rotem
- **URL**: <http://arxiv.org/abs/2510.03203v1>
- **Submitted**: 2025-10-03 17:40:29
- **Topic Keywords**: search
- **Reason**: This paper is primarily focused on data compression, which is not a central theme in your research interests. While it does involve a graph-based model, the context is not related to information retrieval, search technologies, or natural language processing.

#### Abstract
> Research in general-purpose lossless compression over the last decade has
largely found improvements in compression ratio that come at great cost to
resource utilization and processing throughput. However, most production
workloads require high throughput and low resource utilization, so most
research systems have seen little adoption. Instead, real world improvements in
compression are increasingly often realized by building application-specific
compressors which can exploit knowledge about the structure and semantics of
the data being compressed. These systems easily outperform even the best
generic compressors, but application-specific compression schemes are not
without drawbacks. They are inherently limited in applicability and are
difficult to maintain and deploy.
  We show that these challenges can be overcome with a new way of thinking
about compression. We propose the ``graph model'' of compression, a new
theoretical framework for representing compression as a directed acyclic graph
of modular codecs. This motivates OpenZL, an implementation of this model that
compresses data into a self-describing wire format, any configuration of which
can be decompressed by a universal decoder. OpenZL's design enables rapid
development of tailored compressors with minimal code, its universal decoder
eliminates deployment lag, and its investment in a well-vetted standard
component library minimizes security risks. Experimental results demonstrate
that OpenZL achieves superior compression ratios and speeds compared to
state-of-the-art general-purpose compressors on a variety of real-world
datasets. Internal deployments at Meta have also shown consistent improvements
in size and/or speed, with development timelines reduced from months to days.
OpenZL thus represents an advance in practical, scalable, and maintainable data
compression for modern data-intensive applications.

### 41. Neural Correlates of Language Models Are Specific to Human Language

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: I√±igo Parra
- **URL**: <http://arxiv.org/abs/2510.03156v1>
- **Submitted**: 2025-10-03 16:28:31
- **Comment**: To be presented at NeurIPS 2025 Workshops
- **Topic Keywords**: search
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or your other core research themes. It explores the neural correlates of language models and their similarity to human brain states, which is a topic in Natural Language Processing, but not a central match for your interests.

#### Abstract
> Previous work has shown correlations between the hidden states of large
language models and fMRI brain responses, on language tasks. These correlations
have been taken as evidence of the representational similarity of these models
and brain states. This study tests whether these previous results are robust to
several possible concerns. Specifically this study shows: (i) that the previous
results are still found after dimensionality reduction, and thus are not
attributable to the curse of dimensionality; (ii) that previous results are
confirmed when using new measures of similarity; (iii) that correlations
between brain representations and those from models are specific to models
trained on human language; and (iv) that the results are dependent on the
presence of positional encoding in the models. These results confirm and
strengthen the results of previous research and contribute to the debate on the
biological plausibility and interpretability of state-of-the-art large language
models.

### 42. Hyperparameter Loss Surfaces Are Simple Near their Optima

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Nicholas Lourie, He He, Kyunghyun Cho
- **URL**: <http://arxiv.org/abs/2510.02721v1>
- **Submitted**: 2025-10-03 04:52:27
- **Comment**: Accepted to COLM 2025. 23 pages, 8 figures
- **Topic Keywords**: search
- **Reason**: This paper appears to be unrelated to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, and data mining. The paper focuses on understanding the hyperparameter loss surface in machine learning models, which is a topic more relevant to the broader field of machine learning and optimization.

#### Abstract
> Hyperparameters greatly impact models' capabilities; however, modern models
are too large for extensive search. Instead, researchers design recipes that
train well across scales based on their understanding of the hyperparameters.
Despite this importance, few tools exist for understanding the hyperparameter
loss surface. We discover novel structure in it and propose a new theory
yielding such tools. The loss surface is complex, but as you approach the
optimum simple structure emerges. It becomes characterized by a few basic
features, like its effective dimension and the best possible loss. To uncover
this asymptotic regime, we develop a novel technique based on random search.
Within this regime, the best scores from random search take on a new
distribution we discover. Its parameters are exactly the features defining the
loss surface in the asymptotic regime. From these features, we derive a new
asymptotic law for random search that can explain and extrapolate its
convergence. These new tools enable new analyses, such as confidence intervals
for the best possible performance or determining the effective number of
hyperparameters. We make these tools available at
https://github.com/nicholaslourie/opda .

### 43. SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D Gaussian Splatting

- **LLM Score**: 0
- **Keyword Score**: 3
- **Authors**: Sung-Yeon Park, Adam Lee, Juanwu Lu, Can Cui, Luyang Jiang, Rohit Gupta, Kyungtae Han, Ahmadreza Moradipari, Ziran Wang
- **URL**: <http://arxiv.org/abs/2510.02469v1>
- **Submitted**: 2025-10-02 18:22:03
- **Topic Keywords**: query
- **Reason**: This paper appears to be related to computer vision and driving scene manipulation, but it does not align with the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing.

#### Abstract
> Driving scene manipulation with sensor data is emerging as a promising
alternative to traditional virtual driving simulators. However, existing
frameworks struggle to generate realistic scenarios efficiently due to limited
editing capabilities. To address these challenges, we present SIMSplat, a
predictive driving scene editor with language-aligned Gaussian splatting. As a
language-controlled editor, SIMSplat enables intuitive manipulation using
natural language prompts. By aligning language with Gaussian-reconstructed
scenes, it further supports direct querying of road objects, allowing precise
and flexible editing. Our method provides detailed object-level editing,
including adding new objects and modifying the trajectories of both vehicles
and pedestrians, while also incorporating predictive path refinement through
multi-agent motion prediction to generate realistic interactions among all
agents in the scene. Experiments on the Waymo dataset demonstrate SIMSplat's
extensive editing capabilities and adaptability across a wide range of
scenarios. Project page: https://sungyeonparkk.github.io/simsplat/

---

