# Daily Papers Report - 2025-12-31

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Retrieval Augmented Question Answering: When Should LLMs Admit Ignorance?

- **LLM Score**: 8
- **Keyword Score**: 3
- **Authors**: Dingmin Wang, Ji Ma, Shankar Kumar
- **URL**: <http://arxiv.org/abs/2512.23836v1>
- **Submitted**: 2025-12-29 19:59:10
- **Topic Keywords**: retrieval, search
- **Reason**: This paper is highly relevant to Information Retrieval, specifically in the context of query understanding and ranking models. The use of Large Language Models (LLMs) for retrieval-augmented question answering aligns with your interests in deep semantic understanding and real-time relevance optimization. However, the focus on question answering and LLMs is slightly more NLP-oriented than your primary focus on IR.

#### Abstract
> The success of expanded context windows in Large Language Models (LLMs) has driven increased use of broader context in retrieval-augmented generation. We investigate the use of LLMs for retrieval augmented question answering. While longer contexts make it easier to incorporate targeted knowledge, they introduce more irrelevant information that hinders the model's generation process and degrades its performance. To address the issue, we design an adaptive prompting strategy which involves splitting the retrieved information into smaller chunks and sequentially prompting a LLM to answer the question using each chunk. Adjusting the chunk size allows a trade-off between incorporating relevant information and reducing irrelevant information. Experimental results on three open-domain question answering datasets demonstrate that the adaptive strategy matches the performance of standard prompting while using fewer tokens. Our analysis reveals that when encountering insufficient information, the LLM often generates incorrect answers instead of declining to respond, which constitutes a major source of error. This finding highlights the need for further research into enhancing LLMs' ability to effectively decline requests when faced with inadequate information.

---

### 2. Integrating Domain Knowledge for Financial QA: A Multi-Retriever RAG Approach with LLMs

- **LLM Score**: 6
- **Keyword Score**: 8
- **Authors**: Yukun Zhang, Stefan Elbl Droguett, Samyak Jain
- **URL**: <http://arxiv.org/abs/2512.23848v1>
- **Submitted**: 2025-12-29 20:24:15
- **Topic Keywords**: retriever, rag, retrieval, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of query understanding and ranking models. However, its focus on Question Answering (QA) and domain knowledge in finance is not a central match to your primary interests in e-commerce and real-time relevance optimization.

#### Abstract
> This research project addresses the errors of financial numerical reasoning Question Answering (QA) tasks due to the lack of domain knowledge in finance. Despite recent advances in Large Language Models (LLMs), financial numerical questions remain challenging because they require specific domain knowledge in finance and complex multi-step numeric reasoning. We implement a multi-retriever Retrieval Augmented Generators (RAG) system to retrieve both external domain knowledge and internal question contexts, and utilize the latest LLM to tackle these tasks. Through comprehensive ablation experiments and error analysis, we find that domain-specific training with the SecBERT encoder significantly contributes to our best neural symbolic model surpassing the FinQA paper's top model, which serves as our baseline. This suggests the potential superior performance of domain-specific training. Furthermore, our best prompt-based LLM generator achieves the state-of-the-art (SOTA) performance with significant improvement (>7%), yet it is still below the human expert performance. This study highlights the trade-off between hallucinations loss and external knowledge gains in smaller models and few-shot examples. For larger models, the gains from external facts typically outweigh the hallucination loss. Finally, our findings confirm the enhanced numerical reasoning capabilities of the latest LLM, optimized for few-shot learning.

---

### 3. Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling

- **LLM Score**: 6
- **Keyword Score**: 7
- **Authors**: Chulun Zhou, Chunkang Zhang, Guoxin Yu, Fandong Meng, Jie Zhou, Wai Lam, Mo Yu
- **URL**: <http://arxiv.org/abs/2512.23959v1>
- **Submitted**: 2025-12-30 03:13:10
- **Comment**: 21 pages
- **Topic Keywords**: queries, rag, retrieval
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, particularly in the context of large language models and complex relational modeling. However, the focus on multi-step retrieval-augmented generation and hypergraph-based memory mechanisms is not directly aligned with your primary interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Multi-step retrieval-augmented generation (RAG) has become a widely adopted strategy for enhancing large language models (LLMs) on tasks that demand global comprehension and intensive reasoning. Many RAG systems incorporate a working memory module to consolidate retrieved information. However, existing memory designs function primarily as passive storage that accumulates isolated facts for the purpose of condensing the lengthy inputs and generating new sub-queries through deduction. This static nature overlooks the crucial high-order correlations among primitive facts, the compositions of which can often provide stronger guidance for subsequent steps. Therefore, their representational strength and impact on multi-step reasoning and knowledge evolution are limited, resulting in fragmented reasoning and weak global sense-making capacity in extended contexts. We introduce HGMem, a hypergraph-based memory mechanism that extends the concept of memory beyond simple storage into a dynamic, expressive structure for complex reasoning and global understanding. In our approach, memory is represented as a hypergraph whose hyperedges correspond to distinct memory units, enabling the progressive formation of higher-order interactions within memory. This mechanism connects facts and thoughts around the focal problem, evolving into an integrated and situated knowledge structure that provides strong propositions for deeper reasoning in subsequent steps. We evaluate HGMem on several challenging datasets designed for global sense-making. Extensive experiments and in-depth analyses show that our method consistently improves multi-step RAG and substantially outperforms strong baseline systems across diverse tasks.

---

### 4. World model inspired sarcasm reasoning with large language model agents

- **LLM Score**: 6
- **Keyword Score**: 2
- **Authors**: Keito Inoshita, Shinnosuke Mizuno
- **URL**: <http://arxiv.org/abs/2512.24329v1>
- **Submitted**: 2025-12-30 16:31:08
- **Topic Keywords**: rag
- **Reason**: The paper explores sarcasm understanding in NLP, which is related to query understanding and deep semantic understanding in IR. However, the focus on sarcasm detection and the use of large language models is somewhat tangential to the user's primary interests in IR and search technologies.

#### Abstract
> Sarcasm understanding is a challenging problem in natural language processing, as it requires capturing the discrepancy between the surface meaning of an utterance and the speaker's intentions as well as the surrounding social context. Although recent advances in deep learning and Large Language Models (LLMs) have substantially improved performance, most existing approaches still rely on black-box predictions of a single model, making it difficult to structurally explain the cognitive factors underlying sarcasm. Moreover, while sarcasm often emerges as a mismatch between semantic evaluation and normative expectations or intentions, frameworks that explicitly decompose and model these components remain limited. In this work, we reformulate sarcasm understanding as a world model inspired reasoning process and propose World Model inspired SArcasm Reasoning (WM-SAR), which decomposes literal meaning, context, normative expectation, and intention into specialized LLM-based agents. The discrepancy between literal evaluation and normative expectation is explicitly quantified as a deterministic inconsistency score, and together with an intention score, these signals are integrated by a lightweight Logistic Regression model to infer the final sarcasm probability. This design leverages the reasoning capability of LLMs while maintaining an interpretable numerical decision structure. Experiments on representative sarcasm detection benchmarks show that WM-SAR consistently outperforms existing deep learning and LLM-based methods. Ablation studies and case analyses further demonstrate that integrating semantic inconsistency and intention reasoning is essential for effective sarcasm detection, achieving both strong performance and high interpretability.

---

### 5. Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process

- **LLM Score**: 6
- **Keyword Score**: 2
- **Authors**: Zhenyu Zhang, Shujian Zhang, John Lambert, Wenxuan Zhou, Zhangyang Wang, Mingqing Chen, Andrew Hard, Rajiv Mathews, Lun Wang
- **URL**: <http://arxiv.org/abs/2512.23988v1>
- **Submitted**: 2025-12-30 05:09:11
- **Topic Keywords**: ctr
- **Reason**: This paper explores the internal mechanisms of large language models during the reasoning process, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on unsupervised discovery of reasoning behaviors in LLMs is not directly aligned with the user's primary research themes, but it does touch on related topics in NLP and deep semantic understanding.

#### Abstract
> Despite the growing reasoning capabilities of recent large language models (LLMs), their internal mechanisms during the reasoning process remain underexplored. Prior approaches often rely on human-defined concepts (e.g., overthinking, reflection) at the word level to analyze reasoning in a supervised manner. However, such methods are limited, as it is infeasible to capture the full spectrum of potential reasoning behaviors, many of which are difficult to define in token space. In this work, we propose an unsupervised framework (namely, RISE: Reasoning behavior Interpretability via Sparse auto-Encoder) for discovering reasoning vectors, which we define as directions in the activation space that encode distinct reasoning behaviors. By segmenting chain-of-thought traces into sentence-level 'steps' and training sparse auto-encoders (SAEs) on step-level activations, we uncover disentangled features corresponding to interpretable behaviors such as reflection and backtracking. Visualization and clustering analyses show that these behaviors occupy separable regions in the decoder column space. Moreover, targeted interventions on SAE-derived vectors can controllably amplify or suppress specific reasoning behaviors, altering inference trajectories without retraining. Beyond behavior-specific disentanglement, SAEs capture structural properties such as response length, revealing clusters of long versus short reasoning traces. More interestingly, SAEs enable the discovery of novel behaviors beyond human supervision. We demonstrate the ability to control response confidence by identifying confidence-related vectors in the SAE decoder space. These findings underscore the potential of unsupervised latent discovery for both interpreting and controllably steering reasoning in LLMs.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. On the Factual Consistency of Text-based Explainable Recommendation Models

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Ben Kabongo, Vincent Guigue
- **URL**: <http://arxiv.org/abs/2512.24366v1>
- **Submitted**: 2025-12-30 17:25:15
- **Comment**: 13 pages, 2 figures, 4 tables
- **Topic Keywords**: relevance, rag, recommend
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, but it focuses on explainable recommendation models rather than query understanding, ranking models, or user behavior modeling. While it involves LLMs and NLI-based approaches, the primary goal is to evaluate the factual consistency of generated explanations, which is not directly aligned with your core research themes.

#### Abstract
> Text-based explainable recommendation aims to generate natural-language explanations that justify item recommendations, to improve user trust and system transparency. Although recent advances leverage LLMs to produce fluent outputs, a critical question remains underexplored: are these explanations factually consistent with the available evidence? We introduce a comprehensive framework for evaluating the factual consistency of text-based explainable recommenders. We design a prompting-based pipeline that uses LLMs to extract atomic explanatory statements from reviews, thereby constructing a ground truth that isolates and focuses on their factual content. Applying this pipeline to five categories from the Amazon Reviews dataset, we create augmented benchmarks for fine-grained evaluation of explanation quality. We further propose statement-level alignment metrics that combine LLM- and NLI-based approaches to assess both factual consistency and relevance of generated explanations. Across extensive experiments on six state-of-the-art explainable recommendation models, we uncover a critical gap: while models achieve high semantic similarity scores (BERTScore F1: 0.81-0.90), all our factuality metrics reveal alarmingly low performance (LLM-based statement-level precision: 4.38%-32.88%). These findings underscore the need for factuality-aware evaluation in explainable recommendation and provide a foundation for developing more trustworthy explanation systems.

### 7. CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Jiaxin Hu, Tao Wang, Bingsan Yang, Hongrun Wang
- **URL**: <http://arxiv.org/abs/2512.24113v1>
- **Submitted**: 2025-12-30 09:50:50
- **Comment**: 9 pages, 6 figures
- **Topic Keywords**: queries, rag, recommend
- **Reason**: The paper explores a cognitive recommender agent that combines large language models and Soar architecture, which is somewhat related to information retrieval and NLP. However, the focus on recommendation systems and explainability is not a central match to the user's primary interest in information retrieval, especially in areas requiring deep semantic understanding and real-time relevance optimization.

#### Abstract
> Large Language Models (LLMs) have demonstrated a remarkable capacity in understanding user preferences for recommendation systems. However, they are constrained by several critical challenges, including their inherent "Black-Box" characteristics, susceptibility to knowledge hallucination, and limited online learning capacity. These factors compromise their trustworthiness and adaptability. Conversely, cognitive architectures such as Soar offer structured and interpretable reasoning processes, yet their knowledge acquisition is notoriously laborious. To address these complementary challenges, we propose a novel cognitive recommender agent called CogRec which synergizes the strengths of LLMs with the Soar cognitive architecture. CogRec leverages Soar as its core symbolic reasoning engine and leverages an LLM for knowledge initialization to populate its working memory with production rules. The agent operates on a Perception-Cognition-Action(PCA) cycle. Upon encountering an impasse, it dynamically queries the LLM to obtain a reasoned solution. This solution is subsequently transformed into a new symbolic production rule via Soar's chunking mechanism, thereby enabling robust online learning. This learning paradigm allows the agent to continuously evolve its knowledge base and furnish highly interpretable rationales for its recommendations. Extensive evaluations conducted on three public datasets demonstrate that CogRec demonstrates significant advantages in recommendation accuracy, explainability, and its efficacy in addressing the long-tail problem.

### 8. MedKGI: Iterative Differential Diagnosis with Medical Knowledge Graphs and Information-Guided Inquiring

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Qipeng Wang, Rui Sheng, Yafei Li, Huamin Qu, Yushi Sun, Min Zhu
- **URL**: <http://arxiv.org/abs/2512.24181v1>
- **Submitted**: 2025-12-30 12:31:53
- **Topic Keywords**: rag
- **Reason**: This paper explores the application of Large Language Models in clinical diagnosis, addressing challenges such as hallucinated content, redundant questions, and loss of coherence. While it involves information retrieval and query understanding, the focus on medical knowledge graphs and clinical practices is somewhat distant from the user's core research themes in e-commerce and general information retrieval. The paper's relevance to the user's interests in NLP and data mining is moderate, but the specific context and domain are not directly aligned.

#### Abstract
> Recent advancements in Large Language Models (LLMs) have demonstrated significant promise in clinical diagnosis. However, current models struggle to emulate the iterative, diagnostic hypothesis-driven reasoning of real clinical scenarios. Specifically, current LLMs suffer from three critical limitations: (1) generating hallucinated medical content due to weak grounding in verified knowledge, (2) asking redundant or inefficient questions rather than discriminative ones that hinder diagnostic progress, and (3) losing coherence over multi-turn dialogues, leading to contradictory or inconsistent conclusions. To address these challenges, we propose MedKGI, a diagnostic framework grounded in clinical practices. MedKGI integrates a medical knowledge graph (KG) to constrain reasoning to validated medical ontologies, selects questions based on information gain to maximize diagnostic efficiency, and adopts an OSCE-format structured state to maintain consistent evidence tracking across turns. Experiments on clinical benchmarks show that MedKGI outperforms strong LLM baselines in both diagnostic accuracy and inquiry efficiency, improving dialogue efficiency by 30% on average while maintaining state-of-the-art accuracy.

### 9. Adversarial Lens: Exploiting Attention Layers to Generate Adversarial Examples for Evaluation

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Kaustubh Dhole
- **URL**: <http://arxiv.org/abs/2512.23837v1>
- **Submitted**: 2025-12-29 19:59:52
- **Topic Keywords**: rag
- **Reason**: This paper explores the use of attention layers to generate adversarial examples, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on natural language processing and model interpretability is not a central match with the user's primary research interests in IR and search technologies. The paper's relevance is limited to the user's background in NLP and data mining.

#### Abstract
> Recent advances in mechanistic interpretability suggest that intermediate attention layers encode token-level hypotheses that are iteratively refined toward the final output. In this work, we exploit this property to generate adversarial examples directly from attention-layer token distributions. Unlike prompt-based or gradient-based attacks, our approach leverages model-internal token predictions, producing perturbations that are both plausible and internally consistent with the model's own generation process. We evaluate whether tokens extracted from intermediate layers can serve as effective adversarial perturbations for downstream evaluation tasks. We conduct experiments on argument quality assessment using the ArgQuality dataset, with LLaMA-3.1-Instruct-8B serving as both the generator and evaluator. Our results show that attention-based adversarial examples lead to measurable drops in evaluation performance while remaining semantically similar to the original inputs. However, we also observe that substitutions drawn from certain layers and token positions can introduce grammatical degradation, limiting their practical effectiveness. Overall, our findings highlight both the promise and current limitations of using intermediate-layer representations as a principled source of adversarial examples for stress-testing LLM-based evaluation pipelines.

### 10. MaRCA: Multi-Agent Reinforcement Learning for Dynamic Computation Allocation in Large-Scale Recommender Systems

- **LLM Score**: 3
- **Keyword Score**: 3
- **Authors**: Wan Jiang, Xinyi Zang, Yudong Zhao, Yusi Zou, Yunfei Lu, Junbo Tong, Yang Liu, Ming Li, Jiani Shi, Xin Yang
- **URL**: <http://arxiv.org/abs/2512.24325v1>
- **Submitted**: 2025-12-30 16:27:41
- **Comment**: 12 pages, 5 figures
- **Topic Keywords**: recommend, commerce, e-commerce
- **Reason**: This paper focuses on recommender systems and proposes a multi-agent reinforcement learning framework for efficient computation allocation. While it touches on large-scale systems and real-time optimization, it doesn't directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest for your research. The paper's emphasis on recommender systems and e-commerce applications makes it somewhat relevant but not a central match for your research.

#### Abstract
> Modern recommender systems face significant computational challenges due to growing model complexity and traffic scale, making efficient computation allocation critical for maximizing business revenue. Existing approaches typically simplify multi-stage computation resource allocation, neglecting inter-stage dependencies, thus limiting global optimality. In this paper, we propose MaRCA, a multi-agent reinforcement learning framework for end-to-end computation resource allocation in large-scale recommender systems. MaRCA models the stages of a recommender system as cooperative agents, using Centralized Training with Decentralized Execution (CTDE) to optimize revenue under computation resource constraints. We introduce an AutoBucket TestBench for accurate computation cost estimation, and a Model Predictive Control (MPC)-based Revenue-Cost Balancer to proactively forecast traffic loads and adjust the revenue-cost trade-off accordingly. Since its end-to-end deployment in the advertising pipeline of a leading global e-commerce platform in November 2024, MaRCA has consistently handled hundreds of billions of ad requests per day and has delivered a 16.67% revenue uplift using existing computation resources.

### 11. DermaVQA-DAS: Dermatology Assessment Schema (DAS) & Datasets for Closed-Ended Question Answering & Segmentation in Patient-Generated Dermatology Images

- **LLM Score**: 2
- **Keyword Score**: 9
- **Authors**: Wen-wai Yim, Yujuan Fu, Asma Ben Abacha, Meliha Yetisgen, Noel Codella, Roberto Andres Novoa, Josep Malvehy
- **URL**: <http://arxiv.org/abs/2512.24340v1>
- **Submitted**: 2025-12-30 16:48:20
- **Topic Keywords**: query, queries, rag, search
- **Reason**: The paper is primarily focused on dermatological image analysis and question answering, which is outside the user's core research themes in Information Retrieval and Search technologies. While it involves multimodal models and question answering, the context is medical and does not align with the user's interests in e-commerce or general search technologies.

#### Abstract
> Recent advances in dermatological image analysis have been driven by large-scale annotated datasets; however, most existing benchmarks focus on dermatoscopic images and lack patient-authored queries and clinical context, limiting their applicability to patient-centered care. To address this gap, we introduce DermaVQA-DAS, an extension of the DermaVQA dataset that supports two complementary tasks: closed-ended question answering (QA) and dermatological lesion segmentation. Central to this work is the Dermatology Assessment Schema (DAS), a novel expert-developed framework that systematically captures clinically meaningful dermatological features in a structured and standardized form. DAS comprises 36 high-level and 27 fine-grained assessment questions, with multiple-choice options in English and Chinese. Leveraging DAS, we provide expert-annotated datasets for both closed QA and segmentation and benchmark state-of-the-art multimodal models. For segmentation, we evaluate multiple prompting strategies and show that prompt design impacts performance: the default prompt achieves the best results under Mean-of-Max and Mean-of-Mean evaluation aggregation schemes, while an augmented prompt incorporating both patient query title and content yields the highest performance under majority-vote-based microscore evaluation, achieving a Jaccard index of 0.395 and a Dice score of 0.566 with BiomedParse. For closed-ended QA, overall performance is strong across models, with average accuracies ranging from 0.729 to 0.798; o3 achieves the best overall accuracy (0.798), closely followed by GPT-4.1 (0.796), while Gemini-1.5-Pro shows competitive performance within the Gemini family (0.783). We publicly release DermaVQA-DAS, the DAS schema, and evaluation protocols to support and accelerate future research in patient-centered dermatological vision-language modeling (https://osf.io/72rp3).

### 12. RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Pankayaraj Pathmanathan, Michael-Andrei Panaitescu-Liess, Cho-Yu Jason Chiang, Furong Huang
- **URL**: <http://arxiv.org/abs/2512.24268v1>
- **Submitted**: 2025-12-30 14:43:57
- **Comment**: Published at AAAI 2026 Workshop on New Frontiers in Information Retrieval [Oral]
- **Topic Keywords**: retriever, rag, retrieval
- **Reason**: This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it touches on retrieval-augmented generation, the focus is on corpus poisoning and defenses, which is not a central match for the user's interests.

#### Abstract
> Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to enhance large language models (LLMs) with external knowledge, reducing hallucinations and compensating for outdated information. However, recent studies have exposed a critical vulnerability in RAG pipelines corpus poisoning where adversaries inject malicious documents into the retrieval corpus to manipulate model outputs. In this work, we propose two complementary retrieval-stage defenses: RAGPart and RAGMask. Our defenses operate directly on the retriever, making them computationally lightweight and requiring no modification to the generation model. RAGPart leverages the inherent training dynamics of dense retrievers, exploiting document partitioning to mitigate the effect of poisoned points. In contrast, RAGMask identifies suspicious tokens based on significant similarity shifts under targeted token masking. Across two benchmarks, four poisoning strategies, and four state-of-the-art retrievers, our defenses consistently reduce attack success rates while preserving utility under benign conditions. We further introduce an interpretable attack to stress-test our defenses. Our findings highlight the potential and limitations of retrieval-stage defenses, providing practical insights for robust RAG deployments.

### 13. High-dimensional Regret Minimization

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Junyu Liao, Ashwin Lall, Mitsunori Ogihara, Raymond Wong
- **URL**: <http://arxiv.org/abs/2512.24078v1>
- **Submitted**: 2025-12-30 08:40:48
- **Topic Keywords**: query, queries, recommend
- **Reason**: This paper focuses on high-dimensional regret minimization in database applications, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves user interactions and preference learning, the context and techniques are more aligned with database systems and multi-criteria decision making, rather than query understanding, ranking models, or click models.

#### Abstract
> Multi-criteria decision making in large databases is very important in real world applications. Recently, an interactive query has been studied extensively in the database literature with the advantage of both the top-k query (with limited output size) and the skyline query (which does not require users to explicitly specify their preference function). This approach iteratively asks the user to select the one preferred within a set of options. Based on rounds of feedback, the query learns the implicit preference and returns the most favorable as a recommendation.
  However, many modern applications in areas like housing or financial product markets feature datasets with hundreds of attributes. Existing interactive algorithms either fail to scale or require excessive user interactions (often exceeding 1000 rounds). Motivated by this, we propose FHDR (Fast High-Dimensional Reduction), a novel framework that takes less than 0.01s with fewer than 30 rounds of interaction. It is considered a breakthrough in the field of interactive queries since most, if not all, existing studies are not scalable to high-dimensional datasets.
  Extensive experiments demonstrate that FHDR outperforms the best-known algorithms by at least an order of magnitude in execution time and up to several orders of magnitude in terms of the number of interactions required, establishing a new state of the art for scalable interactive regret minimization.

### 14. Beyond Hallucinations: A Composite Score for Measuring Reliability in Open-Source Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Rohit Kumar Salla, Manoj Saravanan, Shrikar Reddy Kota
- **URL**: <http://arxiv.org/abs/2512.24058v1>
- **Submitted**: 2025-12-30 08:07:28
- **Comment**: 5 pages, 4 tables, accepted at AAAI 2026
- **Topic Keywords**: ranking, rag, rank
- **Reason**: This paper focuses on evaluating the reliability of Large Language Models, which is a topic in Natural Language Processing. While it touches on the idea of uncertainty quantification, it does not directly relate to Information Retrieval, query understanding, ranking models, or user behavior modeling, which are the core areas of your research interests.

#### Abstract
> Large Language Models (LLMs) like LLaMA, Mistral, and Gemma are increasingly used in decision-critical domains such as healthcare, law, and finance, yet their reliability remains uncertain. They often make overconfident errors, degrade under input shifts, and lack clear uncertainty estimates. Existing evaluations are fragmented, addressing only isolated aspects. We introduce the Composite Reliability Score (CRS), a unified framework that integrates calibration, robustness, and uncertainty quantification into a single interpretable metric. Through experiments on ten leading open-source LLMs across five QA datasets, we assess performance under baselines, perturbations, and calibration methods. CRS delivers stable model rankings, uncovers hidden failure modes missed by single metrics, and highlights that the most dependable systems balance accuracy, robustness, and calibrated uncertainty.

### 15. LAILA: A Large Trait-Based Dataset for Arabic Automated Essay Scoring

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: May Bashendy, Walid Massoud, Sohaila Eltanbouly, Salam Albatarni, Marwan Sayed, Abrar Abir, Houda Bouamor, Tamer Elsayed
- **URL**: <http://arxiv.org/abs/2512.24235v1>
- **Submitted**: 2025-12-30 13:49:52
- **Topic Keywords**: relevance, search
- **Reason**: This paper is not relevant to your core research themes in Information Retrieval, Search technologies, or Natural Language Processing, as it focuses on Automated Essay Scoring for Arabic language, which is outside your primary areas of interest.

#### Abstract
> Automated Essay Scoring (AES) has gained increasing attention in recent years, yet research on Arabic AES remains limited due to the lack of publicly available datasets. To address this, we introduce LAILA, the largest publicly available Arabic AES dataset to date, comprising 7,859 essays annotated with holistic and trait-specific scores on seven dimensions: relevance, organization, vocabulary, style, development, mechanics, and grammar. We detail the dataset design, collection, and annotations, and provide benchmark results using state-of-the-art Arabic and English models in prompt-specific and cross-prompt settings. LAILA fills a critical need in Arabic AES research, supporting the development of robust scoring systems.

### 16. Deletion Considered Harmful

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Paul Englefield, Russell Beale
- **URL**: <http://arxiv.org/abs/2512.23907v1>
- **Submitted**: 2025-12-30 00:08:32
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The study focuses on the practice of deletion in managing digital resources, which is not directly related to query understanding, ranking models, or user behavior modeling.

#### Abstract
> In a world of information overload, understanding how we can most effectively manage information is crucial to success. We set out to understand how people view deletion, the removal of material no longer needed: does it help by reducing clutter and improving the signal to noise ratio, or does the effort required to decide to delete something make it not worthwhile? How does deletion relate to other strategies like filing; do people who spend extensive time in filing also prune their materials too? We studied the behaviour of 51 knowledge workers though a series of questionnaires and interviews to evaluate a range of tactics they used aimed at organizing, filing, and retrieving digital resources. Our study reveals that deletion is consistently under-adopted compared to other tactics such as Filing, Coverage, Ontology, and Timeliness. Moreover, the empirical data indicate that deletion is actually detrimental to retrieval success and satisfaction. In this paper, we examine the practice of deletion, review the related literature, and present detailed statistical results and clustering outcomes that underscore its adverse effects.

### 17. Time-Aware Adaptive Side Information Fusion for Sequential Recommendation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jie Luo, Wenyu Zhang, Xinming Zhang, Yuan Fang
- **URL**: <http://arxiv.org/abs/2512.24246v1>
- **Submitted**: 2025-12-30 14:15:06
- **Comment**: 10 pages. Accepted by WSDM'26
- **Topic Keywords**: rag, recommend
- **Reason**: This paper focuses on sequential recommendation and side information fusion, which is somewhat related to information retrieval, but it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's emphasis on recommender systems and sequential recommendation is not a primary focus of the user's research. The work is more aligned with data mining and NLP, but it does not demonstrate a deep semantic understanding or real-time relevance optimization, which are key aspects of the user's research interests.

#### Abstract
> Incorporating item-side information, such as category and brand, into sequential recommendation is a well-established and effective approach for improving performance. However, despite significant advancements, current models are generally limited by three key challenges: they often overlook the fine-grained temporal dynamics inherent in timestamps, exhibit vulnerability to noise in user interaction sequences, and rely on computationally expensive fusion architectures. To systematically address these challenges, we propose the Time-Aware Adaptive Side Information Fusion (TASIF) framework. TASIF integrates three synergistic components: (1) a simple, plug-and-play time span partitioning mechanism to capture global temporal patterns; (2) an adaptive frequency filter that leverages a learnable gate to denoise feature sequences adaptively, thereby providing higher-quality inputs for subsequent fusion modules; and (3) an efficient adaptive side information fusion layer, this layer employs a "guide-not-mix" architecture, where attributes guide the attention mechanism without being mixed into the content-representing item embeddings, ensuring deep interaction while ensuring computational efficiency. Extensive experiments on four public datasets demonstrate that TASIF significantly outperforms state-of-the-art baselines while maintaining excellent efficiency in training. Our source code is available at https://github.com/jluo00/TASIF.

### 18. Training a Huggingface Model on AWS Sagemaker (Without Tears)

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Liling Tan
- **URL**: <http://arxiv.org/abs/2512.24098v1>
- **Submitted**: 2025-12-30 09:14:17
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on training Huggingface models on AWS SageMaker, which is not directly related to Information Retrieval, Search technologies, or your other primary research interests. While it involves NLP, the context is more about model training and cloud computing rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> The development of Large Language Models (LLMs) has primarily been driven by resource-rich research groups and industry partners. Due to the lack of on-premise computing resources required for increasingly complex models, many researchers are turning to cloud services like AWS SageMaker to train Hugging Face models. However, the steep learning curve of cloud platforms often presents a barrier for researchers accustomed to local environments. Existing documentation frequently leaves knowledge gaps, forcing users to seek fragmented information across the web. This demo paper aims to democratize cloud adoption by centralizing the essential information required for researchers to successfully train their first Hugging Face model on AWS SageMaker from scratch.

### 19. HY-MT1.5 Technical Report

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Mao Zheng, Zheng Li, Tao Chen, Mingyang Song, Di Wang
- **URL**: <http://arxiv.org/abs/2512.24092v1>
- **Submitted**: 2025-12-30 09:06:37
- **Topic Keywords**: ltr
- **Reason**: This paper focuses on machine translation models, which is a related but distinct area from information retrieval and search technologies. While it involves natural language processing, the primary focus on translation and parameter efficiency does not align with the user's core research themes.

#### Abstract
> In this report, we introduce our latest translation models, HY-MT1.5-1.8B and HY-MT1.5-7B, a new family of machine translation models developed through a holistic training framework tailored for high-performance translation. Our methodology orchestrates a multi-stage pipeline that integrates general and MT-oriented pre-training, supervised fine-tuning, on-policy distillation, and reinforcement learning. HY-MT1.5-1.8B, the 1.8B-parameter model demonstrates remarkable parameter efficiency, comprehensively outperforming significantly larger open-source baselines (e.g., Tower-Plus-72B, Qwen3-32B) and mainstream commercial APIs (e.g., Microsoft Translator, Doubao Translator) in standard Chinese-foreign and English-foreign tasks. It achieves approximately 90% of the performance of ultra-large proprietary models such as Gemini-3.0-Pro, while marginally trailing Gemini-3.0-Pro on WMT25 and Mandarin-minority language benchmarks, it maintains a substantial lead over other competing models. Furthermore, HY-MT1.5-7B establishes a new state-of-the-art for its size class, achieving 95% of Gemini-3.0-Pro's performance on Flores-200 and surpassing it on the challenging WMT25 and Mandarin-minority language test sets. Beyond standard translation, the HY-MT1.5 series supports advanced constraints, including terminology intervention, context-aware translation, and format preservation. Extensive empirical evaluations confirm that both models offer highly competitive, robust solutions for general and specialized translation tasks within their respective parameter scales.

### 20. Training Report of TeleChat3-MoE

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xinzhang Liu, Chao Wang, Zhihao Yang, Zhuo Jiang, Xuncheng Zhao, Haoran Wang, Lei Li, Dongdong He, Luobin Liu, Kaizhe Yuan, Han Gao, Zihan Wang, Yitong Yao, Sishi Xiong, Wenmin Deng, Haowei He, Kaidong Yu, Yu Zhao, Ruiyu Fang, Yuhao Jiang, Yingyan Li, Xiaohui Hu, Xi Yu, Jingqi Li, Yanwei Liu, Qingli Li, Xinyu Shi, Junhao Niu, Chengnuo Huang, Yao Xiao, Ruiwen Wang, Fengkai Li, Luwen Pu, Kaipeng Jia, Fubei Yao, Yuyao Huang, Xuewei He, Zhuoru Jiang, Ruiting Song, Rui Xue, Qiyi Xie, Jie Zhang, Zilu Huang, Zhaoxi Zhang, Zhilong Lu, Yanhan Zhang, Yin Zhang, Yanlei Xue, Zhu Yuan, Teng Su, Xin Jiang, Shuangyong Song, Yongxiang Li, Xuelong Li
- **URL**: <http://arxiv.org/abs/2512.24157v1>
- **Submitted**: 2025-12-30 11:42:14
- **Topic Keywords**: rag
- **Reason**: This paper focuses on the training infrastructure for large language models, specifically the TeleChat3-MoE model. While it involves significant computational resources and optimization techniques, it does not appear to be directly related to information retrieval, search technologies, or query understanding, which are core areas of your research interests.

#### Abstract
> TeleChat3-MoE is the latest series of TeleChat large language models, featuring a Mixture-of-Experts (MoE) architecture with parameter counts ranging from 105 billion to over one trillion,trained end-to-end on Ascend NPU cluster. This technical report mainly presents the underlying training infrastructure that enables reliable and efficient scaling to frontier model sizes. We detail systematic methodologies for operator-level and end-to-end numerical accuracy verification, ensuring consistency across hardware platforms and distributed parallelism strategies. Furthermore, we introduce a suite of performance optimizations, including interleaved pipeline scheduling, attention-aware data scheduling for long-sequence training,hierarchical and overlapped communication for expert parallelism, and DVM-based operator fusion. A systematic parallelization framework, leveraging analytical estimation and integer linear programming, is also proposed to optimize multi-dimensional parallelism configurations. Additionally, we present methodological approaches to cluster-level optimizations, addressing host- and device-bound bottlenecks during large-scale training tasks. These infrastructure advancements yield significant throughput improvements and near-linear scaling on clusters comprising thousands of devices, providing a robust foundation for large-scale language model development on hardware ecosystems.

### 21. OptRot: Mitigating Weight Outliers via Data-Free Rotations for Post-Training Quantization

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Advait Gadhikar, Riccardo Grazzi, James Hensman
- **URL**: <http://arxiv.org/abs/2512.24124v1>
- **Submitted**: 2025-12-30 10:13:50
- **Comment**: 25 pages, 10 figures
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests as it focuses on post-training quantization of Large Language Model weights and activations, which is a topic outside of information retrieval, search technologies, and natural language processing.

#### Abstract
> The presence of outliers in Large Language Models (LLMs) weights and activations makes them difficult to quantize. Recent work has leveraged rotations to mitigate these outliers. In this work, we propose methods that learn fusible rotations by minimizing principled and cheap proxy objectives to the weight quantization error. We primarily focus on GPTQ as the quantization method. Our main method is OptRot, which reduces weight outliers simply by minimizing the element-wise fourth power of the rotated weights. We show that OptRot outperforms both Hadamard rotations and more expensive, data-dependent methods like SpinQuant and OSTQuant for weight quantization. It also improves activation quantization in the W4A8 setting. We also propose a data-dependent method, OptRot$^{+}$, that further improves performance by incorporating information on the activation covariance. In the W4A4 setting, we see that both OptRot and OptRot$^{+}$ perform worse, highlighting a trade-off between weight and activation quantization.

### 22. AHA: Aligning Large Audio-Language Models for Reasoning Hallucinations via Counterfactual Hard Negatives

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yanxi Chen, Wenhui Zhu, Xiwen Chen, Zhipeng Wang, Xin Li, Peijie Qiu, Hao Wang, Xuanzhao Dong, Yujian Xiong, Anderson Schneider, Yuriy Nevmyvaka, Yalin Wang
- **URL**: <http://arxiv.org/abs/2512.24052v1>
- **Submitted**: 2025-12-30 07:52:17
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Large Audio-Language Models and their hallucinations, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve NLP, the context is audio-language models and not query understanding, ranking models, or user behavior modeling.

#### Abstract
> Although Large Audio-Language Models (LALMs) deliver state-of-the-art (SOTA) performance, they frequently suffer from hallucinations, e.g. generating text not grounded in the audio input. We analyze these grounding failures and identify a distinct taxonomy: Event Omission, False Event Identity, Temporal Relation Error, and Quantitative Temporal Error. To address this, we introduce the AHA (Audio Hallucination Alignment) framework. By leveraging counterfactual hard negative mining, our pipeline constructs a high-quality preference dataset that forces models to distinguish strict acoustic evidence from linguistically plausible fabrications. Additionally, we establish AHA-Eval, a diagnostic benchmark designed to rigorously test these fine-grained temporal reasoning capabilities. We apply this data to align Qwen2.5-Omni. The resulting model, Qwen-Audio-AHA, achieves a 13.7% improvement on AHA-Eval. Crucially, this benefit generalizes beyond our diagnostic set. Our model shows substantial gains on public benchmarks, including 1.3% on MMAU-Test and 1.6% on MMAR, outperforming latest SOTA methods.

### 23. Efficient Context Scaling with LongCat ZigZag Attention

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Chen Zhang, Yang Bai, Jiahuan Li, Anchun Gui, Keheng Wang, Feifan Liu, Guanyu Wu, Yuwei Jiang, Defei Bu, Li Wei, Haihang Jing, Hongyin Tang, Xin Chen, Xiangzhou Huang, Fengcun Li, Rongxiang Weng, Yulei Qian, Yifan Lu, Yerui Sun, Jingang Wang, Yuchen Xie, Xunliang Cai
- **URL**: <http://arxiv.org/abs/2512.23966v1>
- **Submitted**: 2025-12-30 03:39:04
- **Comment**: 10 pages, 3 figures, 3 tables
- **Topic Keywords**: retrieval
- **Reason**: This paper focuses on attention mechanisms in deep learning, specifically proposing a sparse attention scheme. While attention is a fundamental concept in NLP, the paper's primary focus on efficiency and scalability in long-context scenarios does not directly align with your interests in Information Retrieval, query understanding, ranking models, and user behavior modeling.

#### Abstract
> We introduce LongCat ZigZag Attention (LoZA), which is a sparse attention scheme designed to transform any existing full-attention models into sparse versions with rather limited compute budget. In long-context scenarios, LoZA can achieve significant speed-ups both for prefill-intensive (e.g., retrieval-augmented generation) and decode-intensive (e.g., tool-integrated reasoning) cases. Specifically, by applying LoZA to LongCat-Flash during mid-training, we serve LongCat-Flash-Exp as a long-context foundation model that can swiftly process up to 1 million tokens, enabling efficient long-term reasoning and long-horizon agentic capabilities.

### 24. An Comparative Analysis about KYC on a Recommendation System Toward Agentic Recommendation System

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Junjie H. Xu
- **URL**: <http://arxiv.org/abs/2512.23961v1>
- **Submitted**: 2025-12-30 03:25:49
- **Comment**: 5 pages, 1 figure
- **Topic Keywords**: recommend, search
- **Reason**: This paper appears to be focused on recommender systems, specifically agentic recommendation systems, and their application in the financial domain. While it touches on the concept of user behavior modeling, it does not align with the user's primary research interests in Information Retrieval, particularly query understanding, ranking models, and real-time relevance optimization. The paper's focus on the financial domain also diverges from the user's background in e-commerce.

#### Abstract
> This research presents a cutting-edge recommendation system utilizing agentic AI for KYC (Know Your Customer in the financial domain), and its evaluation across five distinct content verticals: Advertising (Ad), News, Gossip, Sharing (User-Generated Content), and Technology (Tech). The study compares the performance of four experimental groups, grouping by the intense usage of KYC, benchmarking them against the Normalized Discounted Cumulative Gain (nDCG) metric at truncation levels of $k=1$, $k=3$, and $k=5$. By synthesizing experimental data with theoretical frameworks and industry benchmarks from platforms such as Baidu and Xiaohongshu, this research provides insight by showing experimental results for engineering a large-scale agentic recommendation system.

### 25. Probing the Limits of Compressive Memory: A Study of Infini-Attention in Small-Scale Pretraining

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ruizhe Huang, Kexuan Zhang, Yihao Fang, Baifeng Yu
- **URL**: <http://arxiv.org/abs/2512.23862v1>
- **Submitted**: 2025-12-29 21:02:14
- **Topic Keywords**: retrieval
- **Reason**: This paper focuses on small-scale pretraining for Small Language Models (SLMs) and explores the use of Infini-attention for long-context extrapolation. While it touches on retrieval accuracy, the primary focus is on improving language models, which is somewhat related to information retrieval but not directly aligned with the user's core research themes.

#### Abstract
> This study investigates small-scale pretraining for Small Language Models (SLMs) to enable efficient use of limited data and compute, improve accessibility in low-resource settings and reduce costs. To enhance long-context extrapolation in compact models, we focus on Infini-attention, which builds a compressed memory from past segments while preserving local attention. In our work, we conduct an empirical study using 300M-parameter LLaMA models pretrained with Infini-attention. The model demonstrates training stability and outperforms the baseline in long-context retrieval. We identify the balance factor as a key part of the model performance, and we found that retrieval accuracy drops with repeated memory compressions over long sequences. Even so, Infini-attention still effectively compensates for the SLM's limited parameters. Particularly, despite performance degradation at a 16,384-token context, the Infini-attention model achieves up to 31% higher accuracy than the baseline. Our findings suggest that achieving robust long-context capability in SLMs benefits from architectural memory like Infini-attention.

### 26. Trellis: Learning to Compress Key-Value Memory in Attention Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Mahdi Karami, Ali Behrouz, Praneeth Kacham, Vahab Mirrokni
- **URL**: <http://arxiv.org/abs/2512.23852v1>
- **Submitted**: 2025-12-29 20:32:10
- **Comment**: In Second Conference on Language Modeling (COLM) (2025)
- **Topic Keywords**: rag
- **Reason**: This paper focuses on optimizing the attention mechanism in Transformers, which is a topic related to Information Retrieval, but it does not directly address query understanding, ranking models, or user behavior modeling. The paper's emphasis on memory compression and online gradient descent is more aligned with NLP and deep learning techniques, but it does not seem to be a central match for your research interests.

#### Abstract
> Transformers, while powerful, suffer from quadratic computational complexity and the ever-growing Key-Value (KV) cache of the attention mechanism. This paper introduces Trellis, a novel Transformer architecture with bounded memory that learns how to compress its key-value memory dynamically at test time. Trellis replaces the standard KV cache with a fixed-size memory and train a two-pass recurrent compression mechanism to store new keys and values into memory. To achieve this, it leverages an online gradient descent procedure with a forget gate, enabling the compressed memory to be updated recursively while learning to retain important contextual information from incoming tokens at test time. Extensive experiments on language modeling, common-sense reasoning, recall-intensive tasks, and time series show that the proposed architecture outperforms strong baselines. Notably, its performance gains increase as the sequence length grows, highlighting its potential for long-context applications.

### 27. Automated Analysis of Sustainability Reports: Using Large Language Models for the Extraction and Prediction of EU Taxonomy-Compliant KPIs

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jonathan Schmoll, Adam Jatowt
- **URL**: <http://arxiv.org/abs/2512.24289v1>
- **Submitted**: 2025-12-30 15:28:03
- **Topic Keywords**: search
- **Reason**: This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves Large Language Models, the focus is on their application in a specific domain (sustainability reports) and task (extraction and prediction of KPIs), which is not aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> The manual, resource-intensive process of complying with the EU Taxonomy presents a significant challenge for companies. While Large Language Models (LLMs) offer a path to automation, research is hindered by a lack of public benchmark datasets. To address this gap, we introduce a novel, structured dataset from 190 corporate reports, containing ground-truth economic activities and quantitative Key Performance Indicators (KPIs). We use this dataset to conduct the first systematic evaluation of LLMs on the core compliance workflow. Our results reveal a clear performance gap between qualitative and quantitative tasks. LLMs show moderate success in the qualitative task of identifying economic activities, with a multi-step agentic framework modestly enhancing precision. Conversely, the models comprehensively fail at the quantitative task of predicting financial KPIs in a zero-shot setting. We also discover a paradox, where concise metadata often yields superior performance to full, unstructured reports, and find that model confidence scores are poorly calibrated. We conclude that while LLMs are not ready for full automation, they can serve as powerful assistive tools for human experts. Our dataset provides a public benchmark for future research.

### 28. Disentangling Learning from Judgment: Representation Learning for Open Response Analytics

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Conrad Borchers, Manit Patel, Seiyon M. Lee, Anthony F. Botelho
- **URL**: <http://arxiv.org/abs/2512.23941v1>
- **Submitted**: 2025-12-30 02:06:28
- **Comment**: Short research paper accepted at Learning Analytics and Knowledge (LAK '26)
- **Topic Keywords**: search
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves text embeddings and representation learning, its focus on open-ended responses and educational analytics is not a central match for your areas of expertise.

#### Abstract
> Open-ended responses are central to learning, yet automated scoring often conflates what students wrote with how teachers grade. We present an analytics-first framework that separates content signals from rater tendencies, making judgments visible and auditable via analytics. Using de-identified ASSISTments mathematics responses, we model teacher histories as dynamic priors and derive text representations from sentence embeddings, incorporating centering and residualization to mitigate prompt and teacher confounds. Temporally-validated linear models quantify the contributions of each signal, and a projection surfaces model disagreements for qualitative inspection. Results show that teacher priors heavily influence grade predictions; the strongest results arise when priors are combined with content embeddings (AUC~0.815), while content-only models remain above chance but substantially weaker (AUC~0.626). Adjusting for rater effects sharpens the residual content representation, retaining more informative embedding dimensions and revealing cases where semantic evidence supports understanding as opposed to surface-level differences in how students respond. The contribution presents a practical pipeline that transforms embeddings from mere features into learning analytics for reflection, enabling teachers and researchers to examine where grading practices align (or conflict) with evidence of student reasoning and learning.

---

