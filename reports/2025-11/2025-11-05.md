# Daily Papers Report - 2025-11-05

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Beyond Single Embeddings: Capturing Diverse Targets with Multi-Query Retrieval

- **LLM Score**: 8
- **Keyword Score**: 8
- **Authors**: Hung-Ting Chen, Xiang Liu, Shauli Ravfogel, Eunsol Choi
- **URL**: <http://arxiv.org/abs/2511.02770v1>
- **Submitted**: 2025-11-04 17:57:20
- **Topic Keywords**: retriever, query, retrieval
- **Reason**: This paper is highly relevant to Information Retrieval, specifically addressing the limitations of single query embeddings and proposing a new architecture, AMER, that generates multiple query vectors. The focus on capturing diverse targets and improving performance on multi-answer retrieval datasets aligns with your interests in query understanding and ranking models.

#### Abstract
> Most text retrievers generate \emph{one} query vector to retrieve relevant
documents. Yet, the conditional distribution of relevant documents for the
query may be multimodal, e.g., representing different interpretations of the
query. We first quantify the limitations of existing retrievers. All retrievers
we evaluate struggle more as the distance between target document embeddings
grows. To address this limitation, we develop a new retriever architecture,
\emph{A}utoregressive \emph{M}ulti-\emph{E}mbedding \emph{R}etriever (AMER).
Our model autoregressively generates multiple query vectors, and all the
predicted query vectors are used to retrieve documents from the corpus. We show
that on the synthetic vectorized data, the proposed method could capture
multiple target distributions perfectly, showing 4x better performance than
single embedding model. We also fine-tune our model on real-world multi-answer
retrieval datasets and evaluate in-domain. AMER presents 4 and 21\% relative
gains over single-embedding baselines on two datasets we evaluate on.
Furthermore, we consistently observe larger gains on the subset of dataset
where the embeddings of the target documents are less similar to each other. We
demonstrate the potential of using a multi-query vector retriever and open up a
new direction for future work.

---

### 2. Let Multimodal Embedders Learn When to Augment Query via Adaptive Query Augmentation

- **LLM Score**: 8
- **Keyword Score**: 8
- **Authors**: Wongyu Kim, Hochang Lee, Sanghak Lee, Yoonsung Kim, Jaehyun Park
- **URL**: <http://arxiv.org/abs/2511.02358v1>
- **Submitted**: 2025-11-04 08:24:41
- **Comment**: Accepted to MMGenSR Workshop (CIKM 2025)
- **Topic Keywords**: query, queries, rag
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The proposed adaptive query augmentation approach leverages Large Language Model (LLM) capabilities, which is a key area of interest for you. The paper's focus on multimodal environments and real-time relevance optimization also aligns with your research goals.

#### Abstract
> Query augmentation makes queries more meaningful by appending further
information to the queries to find relevant documents. Current studies have
proposed Large Language Model (LLM)-based embedders, which learn representation
for embedding and generation for query augmentation in a multi-task manner by
leveraging the generative capabilities of LLM. During inference, these jointly
trained embedders have conducted query augmentation followed by embedding,
showing effective results. However, augmenting every query leads to substantial
embedding latency and query augmentation can be detrimental to performance for
some queries. Also, previous methods have not been explored in multimodal
environments. To tackle these problems, we propose M-Solomon, a universal
multimodal embedder that can adaptively determine when to augment queries. Our
approach first divides the queries of the training datasets into two groups at
the dataset level. One includes queries that require augmentation and the other
includes queries that do not. Then, we introduces a synthesis process that
generates appropriate augmentations for queries that require them by leveraging
a powerful Multimodal LLM (MLLM). Next, we present adaptive query augmentation.
Through this step, M-Solomon can conduct query augmentation only when necessary
by learning to generate synthetic augmentations with the prefix /augment for
queries that demand them and to generate the simple string /embed for others.
Experimental results showed that M-Solomon not only surpassed the baseline
without augmentation by a large margin but also outperformed the baseline that
always used augmentation, providing much faster embedding latency.

---

### 3. MemSearcher: Training LLMs to Reason, Search and Manage Memory via End-to-End Reinforcement Learning

- **LLM Score**: 8
- **Keyword Score**: 3
- **Authors**: Qianhao Yuan, Jie Lou, Zichao Li, Jiawei Chen, Yaojie Lu, Hongyu Lin, Le Sun, Debing Zhang, Xianpei Han
- **URL**: <http://arxiv.org/abs/2511.02805v1>
- **Submitted**: 2025-11-04 18:27:39
- **Comment**: Project page: https://github.com/icip-cas/MemSearcher
- **Topic Keywords**: rag, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The proposed MemSearcher agent workflow and multi-context GRPO framework demonstrate a deep semantic understanding and real-time relevance optimization, aligning with your core research themes.

#### Abstract
> Typical search agents concatenate the entire interaction history into the LLM
context, preserving information integrity but producing long, noisy contexts,
resulting in high computation and memory costs. In contrast, using only the
current turn avoids this overhead but discards essential information. This
trade-off limits the scalability of search agents. To address this challenge,
we propose MemSearcher, an agent workflow that iteratively maintains a compact
memory and combines the current turn with it. At each turn, MemSearcher fuses
the user's question with the memory to generate reasoning traces, perform
search actions, and update memory to retain only information essential for
solving the task. This design stabilizes context length across multi-turn
interactions, improving efficiency without sacrificing accuracy. To optimize
this workflow, we introduce multi-context GRPO, an end-to-end RL framework that
jointly optimize reasoning, search strategies, and memory management of
MemSearcher Agents. Specifically, multi-context GRPO samples groups of
trajectories under different contexts and propagates trajectory-level
advantages across all conversations within them. Trained on the same dataset as
Search-R1, MemSearcher achieves significant improvements over strong baselines
on seven public benchmarks: +11% on Qwen2.5-3B-Instruct and +12% on
Qwen2.5-7B-Instruct relative average gains. Notably, the 3B-based MemSearcher
even outperforms 7B-based baselines, demonstrating that striking a balance
between information integrity and efficiency yields both higher accuracy and
lower computational overhead. The code and models will be publicly available at
https://github.com/icip-cas/MemSearcher

---

### 4. Personalized Decision Modeling: Utility Optimization or Textualized-Symbolic Reasoning

- **LLM Score**: 7
- **Keyword Score**: 2
- **Authors**: Yibo Zhao, Yang Zhao, Hongru Du, Hao Frank Yang
- **URL**: <http://arxiv.org/abs/2511.02194v1>
- **Submitted**: 2025-11-04 02:19:09
- **Topic Keywords**: rag
- **Reason**: The paper explores human-centric decision-making models, leveraging Large Language Models (LLMs) for textual-reasoning capabilities. While it focuses on utility optimization and symbolic reasoning, it shares some overlap with query understanding and ranking models in the context of information retrieval. However, the primary focus on decision-making models and symbolic reasoning limits its direct alignment with core research themes in IR and search technologies.

#### Abstract
> Decision-making models for individuals, particularly in high-stakes scenarios
like vaccine uptake, often diverge from population optimal predictions. This
gap arises from the uniqueness of the individual decision-making process,
shaped by numerical attributes (e.g., cost, time) and linguistic influences
(e.g., personal preferences and constraints). Developing upon Utility Theory
and leveraging the textual-reasoning capabilities of Large Language Models
(LLMs), this paper proposes an Adaptive Textual-symbolic Human-centric
Reasoning framework (ATHENA) to address the optimal information integration.
ATHENA uniquely integrates two stages: First, it discovers robust, group-level
symbolic utility functions via LLM-augmented symbolic discovery; Second, it
implements individual-level semantic adaptation, creating personalized semantic
templates guided by the optimal utility to model personalized choices.
Validated on real-world travel mode and vaccine choice tasks, ATHENA
consistently outperforms utility-based, machine learning, and other LLM-based
models, lifting F1 score by at least 6.5% over the strongest cutting-edge
models. Further, ablation studies confirm that both stages of ATHENA are
critical and complementary, as removing either clearly degrades overall
predictive performance. By organically integrating symbolic utility modeling
and semantic adaptation, ATHENA provides a new scheme for modeling
human-centric decisions. The project page can be found at
https://yibozh.github.io/Athena.

---

### 5. InteracSPARQL: An Interactive System for SPARQL Query Refinement Using Natural Language Explanations

- **LLM Score**: 6
- **Keyword Score**: 8
- **Authors**: Xiangru Jian, Zhengyuan Dong, M. Tamer √ñzsu
- **URL**: <http://arxiv.org/abs/2511.02002v1>
- **Submitted**: 2025-11-03 19:15:51
- **Comment**: Working paper
- **Topic Keywords**: query, queries, rag
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it involves query refinement and natural language explanations. However, it focuses on SPARQL query refinement in the semantic web domain, which is not a central match to your primary focus on e-commerce and real-time relevance optimization.

#### Abstract
> In recent years, querying semantic web data using SPARQL has remained
challenging, especially for non-expert users, due to the language's complex
syntax and the prerequisite of understanding intricate data structures. To
address these challenges, we propose InteracSPARQL, an interactive SPARQL query
generation and refinement system that leverages natural language explanations
(NLEs) to enhance user comprehension and facilitate iterative query refinement.
InteracSPARQL integrates LLMs with a rule-based approach to first produce
structured explanations directly from SPARQL abstract syntax trees (ASTs),
followed by LLM-based linguistic refinements. Users can interactively refine
queries through direct feedback or LLM-driven self-refinement, enabling the
correction of ambiguous or incorrect query components in real time. We evaluate
InteracSPARQL on standard benchmarks, demonstrating significant improvements in
query accuracy, explanation clarity, and overall user satisfaction compared to
baseline approaches. Our experiments further highlight the effectiveness of
combining rule-based methods with LLM-driven refinements to create more
accessible and robust SPARQL interfaces.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. LLM Probing with Contrastive Eigenproblems: Improving Understanding and Applicability of CCS

- **LLM Score**: 6
- **Keyword Score**: 1
- **Authors**: Stefan F. Schouten, Peter Bloem
- **URL**: <http://arxiv.org/abs/2511.02089v1>
- **Submitted**: 2025-11-03 22:00:37
- **Comment**: Accepted to the Mechanistic Interpretability Workshop at NeurIPS 2025
- **Topic Keywords**: search
- **Reason**: This paper explores the Contrast-Consistent Search (CCS) method, which is related to query understanding and ranking models in Information Retrieval. However, the focus on probing large language models and their internal activations is more aligned with NLP, and the paper's contribution is primarily in the area of model interpretability rather than search technologies or user behavior modeling.

#### Abstract
> Contrast-Consistent Search (CCS) is an unsupervised probing method able to
test whether large language models represent binary features, such as sentence
truth, in their internal activations. While CCS has shown promise, its two-term
objective has been only partially understood. In this work, we revisit CCS with
the aim of clarifying its mechanisms and extending its applicability. We argue
that what should be optimized for, is relative contrast consistency. Building
on this insight, we reformulate CCS as an eigenproblem, yielding closed-form
solutions with interpretable eigenvalues and natural extensions to multiple
variables. We evaluate these approaches across a range of datasets, finding
that they recover similar performance to CCS, while avoiding problems around
sensitivity to random initialization. Our results suggest that relativizing
contrast consistency not only improves our understanding of CCS but also opens
pathways for broader probing and mechanistic interpretability methods.

### 7. Average Precision at Cutoff k under Random Rankings: Expectation and Variance

- **LLM Score**: 4
- **Keyword Score**: 15
- **Authors**: Tetiana Manzhos, Tetiana Ianevych, Olga Melnyk
- **URL**: <http://arxiv.org/abs/2511.02571v1>
- **Submitted**: 2025-11-04 13:45:16
- **Comment**: 17 pages, 2 tables, 2 figures
- **Topic Keywords**: information retrieval, ranking, relevance, rag, retrieval, recommend, rank
- **Reason**: The paper discusses evaluation metrics for ranking algorithms, specifically Average Precision at cutoff k, which is relevant to Information Retrieval. However, the focus is on recommender systems and the derivation of expectation and variance, which is somewhat related to user behavior modeling and click models but not directly aligned with your core research themes.

#### Abstract
> Recommender systems and information retrieval platforms rely on ranking
algorithms to present the most relevant items to users, thereby improving
engagement and satisfaction. Assessing the quality of these rankings requires
reliable evaluation metrics. Among them, Mean Average Precision at cutoff k
(MAP@k) is widely used, as it accounts for both the relevance of items and
their positions in the list.
  In this paper, the expectation and variance of Average Precision at k (AP@k)
are derived since they can be used as biselines for MAP@k. Here, we covered two
widely used evaluation models: offline and online. The expectation establishes
the baseline, indicating the level of MAP@k that can be achieved by pure
chance. The variance complements this baseline by quantifying the extent of
random fluctuations, enabling a more reliable interpretation of observed
scores.

### 8. Relational Deep Dive: Error-Aware Queries Over Unstructured Data

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Daren Chao, Kaiwen Chen, Naiqing Guan, Nick Koudas
- **URL**: <http://arxiv.org/abs/2511.02711v1>
- **Submitted**: 2025-11-04 16:30:55
- **Topic Keywords**: query, queries, rag
- **Reason**: The paper 'Relational Deep Dive: Error-Aware Queries Over Unstructured Data' is somewhat related to your research interests in Information Retrieval and Natural Language Processing, particularly in the context of query understanding and data extraction. However, the focus on structured data and relational schema discovery is not directly aligned with your primary interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> Unstructured data is pervasive, but analytical queries demand structured
representations, creating a significant extraction challenge. Existing methods
like RAG lack schema awareness and struggle with cross-document alignment,
leading to high error rates. We propose ReDD (Relational Deep Dive), a
framework that dynamically discovers query-specific schemas, populates
relational tables, and ensures error-aware extraction with provable guarantees.
ReDD features a two-stage pipeline: (1) Iterative Schema Discovery (ISD)
identifies minimal, joinable schemas tailored to each query, and (2) Tabular
Data Population (TDP) extracts and corrects data using lightweight classifiers
trained on LLM hidden states. A main contribution of ReDD is SCAPE, a
statistically calibrated method for error detection with coverage guarantees,
and SCAPE-HYB, a hybrid approach that optimizes the trade-off between accuracy
and human correction costs. Experiments across diverse datasets demonstrate
ReDD's effectiveness, reducing data extraction errors from up to 30% to below
1% while maintaining high schema completeness (100% recall) and precision.
ReDD's modular design enables fine-grained control over accuracy-cost
trade-offs, making it a robust solution for high-stakes analytical queries over
unstructured corpora.

### 9. Demo: Statistically Significant Results On Biases and Errors of LLMs Do Not Guarantee Generalizable Results

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Jonathan Liu, Haoling Qiu, Jonathan Lasko, Damianos Karakos, Mahsa Yarmohammadi, Mark Dredze
- **URL**: <http://arxiv.org/abs/2511.02246v1>
- **Submitted**: 2025-11-04 04:20:33
- **Topic Keywords**: queries, rag, recommend, search, neurips
- **Reason**: This paper is somewhat related to your interests in Information Retrieval and Natural Language Processing, particularly in the context of Large Language Models (LLMs). However, the focus on LLM evaluation and biases in medical contexts is not directly aligned with your core research themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> Recent research has shown that hallucinations, omissions, and biases are
prevalent in everyday use-cases of LLMs. However, chatbots used in medical
contexts must provide consistent advice in situations where non-medical factors
are involved, such as when demographic information is present. In order to
understand the conditions under which medical chatbots fail to perform as
expected, we develop an infrastructure that 1) automatically generates queries
to probe LLMs and 2) evaluates answers to these queries using multiple
LLM-as-a-judge setups and prompts. For 1), our prompt creation pipeline samples
the space of patient demographics, histories, disorders, and writing styles to
create realistic questions that we subsequently use to prompt LLMs. In 2), our
evaluation pipeline provides hallucination and omission detection using
LLM-as-a-judge as well as agentic workflows, in addition to LLM-as-a-judge
treatment category detectors. As a baseline study, we perform two case studies
on inter-LLM agreement and the impact of varying the answering and evaluation
LLMs. We find that LLM annotators exhibit low agreement scores (average Cohen's
Kappa $\kappa=0.118$), and only specific (answering, evaluation) LLM pairs
yield statistically significant differences across writing styles, genders, and
races. We recommend that studies using LLM evaluation use multiple LLMs as
evaluators in order to avoid arriving at statistically significant but
non-generalizable results, particularly in the absence of ground-truth data. We
also suggest publishing inter-LLM agreement metrics for transparency. Our code
and dataset are available here:
https://github.com/BBN-E/medic-neurips-2025-demo.

### 10. Training Proactive and Personalized LLM Agents

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Weiwei Sun, Xuhui Zhou, Weihua Du, Xingyao Wang, Sean Welleck, Graham Neubig, Maarten Sap, Yiming Yang
- **URL**: <http://arxiv.org/abs/2511.02208v1>
- **Submitted**: 2025-11-04 02:59:36
- **Topic Keywords**: rag, personalization, search
- **Reason**: This paper explores the development of proactive and personalized LLM agents, focusing on optimizing productivity, proactivity, and personalization. While it touches on user behavior modeling, its primary focus is on multi-objective reinforcement learning and user-centered interaction, which is somewhat related to your interests in IR and NLP. However, the lack of direct connection to query understanding, ranking models, or click models limits its relevance.

#### Abstract
> While existing work focuses primarily on task success, we argue that
effective real-world agents require optimizing three dimensions: productivity
(task completion), proactivity (asking essential questions), and
personalization (adapting to diverse user preferences). We introduce UserVille,
an interactive environment with LLM-based user simulators enabling diverse,
configurable user preferences. Leveraging UserVille, we introduce PPP, a
multi-objective reinforcement learning approach that jointly optimizes all
three dimensions: Productivity, Proactivity, and Personalization. Experiments
on software engineering and deep research tasks show that agents trained with
PPP achieve substantial improvements over strong baselines such as GPT-5 (+21.6
on average), demonstrating the ability to ask strategic clarifying questions,
adapt to unseen user preferences, and improve task success through better
interaction. This work demonstrates that explicitly optimizing for
user-centered interaction is critical for building practical and effective AI
agents.

### 11. InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Ziheng Geng, Jiachen Liu, Ran Cao, Lu Cheng, Dan M. Frangopol, Minghui Cheng
- **URL**: <http://arxiv.org/abs/2511.02119v1>
- **Submitted**: 2025-11-03 23:19:27
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper explores the application of large language models in simulating individual behavior in purchasing flood insurance, which is somewhat related to information retrieval and user behavior modeling. However, the focus is on behavioral modeling and policy analysis, rather than query understanding, ranking models, or real-time relevance optimization, making it only loosely relevant to your core research themes.

#### Abstract
> Flood insurance is an effective strategy for individuals to mitigate
disaster-related losses. However, participation rates among at-risk populations
in the United States remain strikingly low. This gap underscores the need to
understand and model the behavioral mechanisms underlying insurance decisions.
Large language models (LLMs) have recently exhibited human-like intelligence
across wide-ranging tasks, offering promising tools for simulating human
decision-making. This study constructs a benchmark dataset to capture insurance
purchase probabilities across factors. Using this dataset, the capacity of LLMs
is evaluated: while LLMs exhibit a qualitative understanding of factors, they
fall short in estimating quantitative probabilities. To address this
limitation, InsurAgent, an LLM-empowered agent comprising five modules
including perception, retrieval, reasoning, action, and memory, is proposed.
The retrieval module leverages retrieval-augmented generation (RAG) to ground
decisions in empirical survey data, achieving accurate estimation of marginal
and bivariate probabilities. The reasoning module leverages LLM common sense to
extrapolate beyond survey data, capturing contextual information that is
intractable for traditional models. The memory module supports the simulation
of temporal decision evolutions, illustrated through a roller coaster life
trajectory. Overall, InsurAgent provides a valuable tool for behavioral
modeling and policy analysis.

### 12. Solving cold start in news recommendations: a RippleNet-based system for large scale media outlet

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Karol Radziszewski, Micha≈Ç Szpunar, Piotr Ociepka, Mateusz Buczy≈Ñski
- **URL**: <http://arxiv.org/abs/2511.02052v1>
- **Submitted**: 2025-11-03 20:38:37
- **Topic Keywords**: rag, recommend
- **Reason**: The paper is somewhat related to the user's interests in Information Retrieval and recommender systems, but it focuses on news recommendations and the cold-start problem, which is not a central match for the user's primary focus on query understanding, ranking models, and user behavior modeling. The use of RippleNet and Amazon SageMaker is also not directly related to the user's areas of expertise.

#### Abstract
> We present a scalable recommender system implementation based on RippleNet,
tailored for the media domain with a production deployment in Onet.pl, one of
Poland's largest online media platforms. Our solution addresses the cold-start
problem for newly published content by integrating content-based item
embeddings into the knowledge propagation mechanism of RippleNet, enabling
effective scoring of previously unseen items. The system architecture leverages
Amazon SageMaker for distributed training and inference, and Apache Airflow for
orchestrating data pipelines and model retraining workflows. To ensure
high-quality training data, we constructed a comprehensive golden dataset
consisting of user and item features and a separate interaction table, all
enabling flexible extensions and integration of new signals.

### 13. Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Amanda Bertsch, Adithya Pratapa, Teruko Mitamura, Graham Neubig, Matthew R. Gormley
- **URL**: <http://arxiv.org/abs/2511.02817v1>
- **Submitted**: 2025-11-04 18:42:12
- **Comment**: Preprint
- **Topic Keywords**: retrieval
- **Reason**: The paper Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities is somewhat related to the user's interests in Information Retrieval, particularly in the context of deep semantic understanding and real-time relevance optimization. However, the focus on long-context reasoning and aggregation capabilities in natural language processing is not a central match for the user's primary research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> As model context lengths continue to grow, concerns about whether models
effectively use the full context length have persisted. While several carefully
designed long-context evaluations have recently been released, these
evaluations tend to rely on retrieval from one or more sections of the context,
which allows nearly all of the context tokens to be disregarded as noise. This
represents only one type of task that might be performed with long context. We
introduce Oolong, a benchmark of long-context reasoning tasks that require
analyzing individual chunks of text on an atomic level, and then aggregating
these analyses to answer distributional questions. Oolong is separated into two
task sets: Oolong-synth, a set of naturalistic synthetic tasks, where we can
easily ablate components of the reasoning problem; and Oolong-real, a
downstream setting which requires reasoning over real-world conversational
data. Oolong requires models to reason over large quantities of examples, to
perform both classification and counting in-context, and to reason over
temporal and user relations. Even frontier models struggle on Oolong, with
GPT-5, Claude-Sonnet-4, and Gemini-2.5-Pro all achieving less than 50% accuracy
on both splits at 128K. We release the data and evaluation harness for Oolong
to enable further development of models that can reason over large quantities
of text.

### 14. UniChange: Unifying Change Detection with Multimodal Large Language Model

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Xu Zhang, Danyang Li, Xiaohang Dong, Tianhao Wu, Hualong Yu, Jianye Wang, Qicheng Li, Xiang Li
- **URL**: <http://arxiv.org/abs/2511.02607v1>
- **Submitted**: 2025-11-04 14:31:06
- **Topic Keywords**: rag
- **Reason**: The paper UniChange: Unifying Change Detection with Multimodal Large Language Model appears to be related to Natural Language Processing (NLP) and multimodal models, but it does not directly align with the user's primary focus on Information Retrieval (IR), query understanding, ranking models, and user behavior modeling. While it involves deep semantic understanding, the context is land cover dynamics and change detection, which is not a central match for the user's research interests.

#### Abstract
> Change detection (CD) is a fundamental task for monitoring and analyzing land
cover dynamics. While recent high performance models and high quality datasets
have significantly advanced the field, a critical limitation persists. Current
models typically acquire limited knowledge from single-type annotated data and
cannot concurrently leverage diverse binary change detection (BCD) and semantic
change detection (SCD) datasets. This constraint leads to poor generalization
and limited versatility. The recent advancements in Multimodal Large Language
Models (MLLMs) introduce new possibilities for a unified CD framework. We
leverage the language priors and unification capabilities of MLLMs to develop
UniChange, the first MLLM-based unified change detection model. UniChange
integrates generative language abilities with specialized CD functionalities.
Our model successfully unifies both BCD and SCD tasks through the introduction
of three special tokens: [T1], [T2], and [CHANGE]. Furthermore, UniChange
utilizes text prompts to guide the identification of change categories,
eliminating the reliance on predefined classification heads. This design allows
UniChange to effectively acquire knowledge from multi-source datasets, even
when their class definitions conflict. Experiments on four public benchmarks
(WHU-CD, S2Looking, LEVIR-CD+, and SECOND) demonstrate SOTA performance,
achieving IoU scores of 90.41, 53.04, 78.87, and 57.62, respectively,
surpassing all previous methods. The code is available at
https://github.com/Erxucomeon/UniChange.

### 15. Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents to Deliberation

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Zhiwei Zhang, Xiaomin Li, Yudi Lin, Hui Liu, Ramraj Chandradevan, Linlin Wu, Minhua Lin, Fali Wang, Xianfeng Tang, Qi He, Suhang Wang
- **URL**: <http://arxiv.org/abs/2511.02303v1>
- **Submitted**: 2025-11-04 06:37:31
- **Topic Keywords**: rag
- **Reason**: This paper explores the application of multi-agent Large Language Models (LLMs) for complex reasoning tasks. While it touches on aspects of query understanding and deep semantic understanding, its primary focus is on multi-agent reasoning and collaboration, which is somewhat related to your interests in Information Retrieval and NLP. However, the paper's emphasis on multi-agent frameworks and deliberation mechanisms does not directly align with your core research themes.

#### Abstract
> Large Language Models (LLMs) trained with reinforcement learning and
verifiable rewards have achieved strong results on complex reasoning tasks.
Recent work extends this paradigm to a multi-agent setting, where a
meta-thinking agent proposes plans and monitors progress while a reasoning
agent executes subtasks through sequential conversational turns. Despite
promising performance, we identify a critical limitation: lazy agent behavior,
in which one agent dominates while the other contributes little, undermining
collaboration and collapsing the setup to an ineffective single agent. In this
paper, we first provide a theoretical analysis showing why lazy behavior
naturally arises in multi-agent reasoning. We then introduce a stable and
efficient method for measuring causal influence, helping mitigate this issue.
Finally, as collaboration intensifies, the reasoning agent risks getting lost
in multi-turn interactions and trapped by previous noisy responses. To counter
this, we propose a verifiable reward mechanism that encourages deliberation by
allowing the reasoning agent to discard noisy outputs, consolidate
instructions, and restart its reasoning process when necessary. Extensive
experiments demonstrate that our framework alleviates lazy agent behavior and
unlocks the full potential of multi-agent framework for complex reasoning
tasks.

### 16. Rethinking LLM Human Simulation: When a Graph is What You Need

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Joseph Suh, Suhong Moon, Serina Chang
- **URL**: <http://arxiv.org/abs/2511.02135v1>
- **Submitted**: 2025-11-03 23:54:24
- **Comment**: Code: https://github.com/schang-lab/gems
- **Topic Keywords**: rag
- **Reason**: This paper explores the use of graph neural networks for human simulation, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on human simulation and decision-making tasks is not directly aligned with the user's primary research interests in IR, search technologies, and NLP. The paper's emphasis on graph-based modeling and efficiency is also not a central match for the user's interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> Large language models (LLMs) are increasingly used to simulate humans, with
applications ranging from survey prediction to decision-making. However, are
LLMs strictly necessary, or can smaller, domain-grounded models suffice? We
identify a large class of simulation problems in which individuals make choices
among discrete options, where a graph neural network (GNN) can match or surpass
strong LLM baselines despite being three orders of magnitude smaller. We
introduce Graph-basEd Models for human Simulation (GEMS), which casts discrete
choice simulation tasks as a link prediction problem on graphs, leveraging
relational knowledge while incorporating language representations only when
needed. Evaluations across three key settings on three simulation datasets show
that GEMS achieves comparable or better accuracy than LLMs, with far greater
efficiency, interpretability, and transparency, highlighting the promise of
graph-based modeling as a lightweight alternative to LLMs for human simulation.
Our code is available at https://github.com/schang-lab/gems.

### 17. Regularization Through Reasoning: Systematic Improvements in Language Model Classification via Explanation-Enhanced Fine-Tuning

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Vivswan Shah, Randy Cogill, Hanwei Yue, Gopinath Chennupati, Rinat Khaziev
- **URL**: <http://arxiv.org/abs/2511.02044v1>
- **Submitted**: 2025-11-03 20:25:42
- **Topic Keywords**: rag
- **Reason**: This paper explores the impact of explanations on fine-tuning language models for classification tasks. While it touches on aspects of query understanding and ranking models, the primary focus is on NLP and classification accuracy, which is somewhat related to your research interests in IR and search technologies.

#### Abstract
> Fine-tuning LLMs for classification typically maps inputs directly to labels.
We ask whether attaching brief explanations to each label during fine-tuning
yields better models. We evaluate conversational response quality along three
axes: naturalness, comprehensiveness, and on-topic adherence, each rated on
5-point scales. Using ensemble-generated data from multiple LLMs, we fine-tune
a 7B-parameter model and test across six diverse conversational datasets.
Across 18 dataset, task settings, label-plus-explanation training outperforms
label-only baselines.
  A central and unexpected result concerns random tokens. We replace
human-written explanations with text that is syntactically incoherent yet
vocabulary-aligned with the originals (e.g., shuffled or bag-of-words
variants). Despite lacking semantics, these pseudo-explanations still improve
accuracy over label-only training and often narrow much of the gap to true
explanations. The effect persists across datasets and training seeds,
indicating that gains arise less from meaning than from structure: the extra
token budget encourages richer intermediate computation and acts as a
regularizer that reduces over-confident shortcuts.
  Internal analyses support this view: explanation-augmented models exhibit
higher activation entropy in intermediate layers alongside sharper predictive
mass at the output layer, consistent with increased deliberation before
decision. Overall, explanation-augmented fine-tuning, whether with genuine
rationales or carefully constructed random token sequences, improves accuracy
and reliability for LLM classification while clarifying how token-level
scaffolding shapes computation during inference.

### 18. Enhancing Multimodal Recommendations with Vision-Language Models and Information-Aware Fusion

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Hai-Dang Kieu, Min Xu, Thanh Trung Huynh, Dung D. Le
- **URL**: <http://arxiv.org/abs/2511.02113v1>
- **Submitted**: 2025-11-03 23:01:27
- **Topic Keywords**: recommend
- **Reason**: The paper focuses on multimodal recommendations, which is related to information retrieval and search technologies. However, the emphasis is on vision-language models and fusion, which is somewhat tangential to the user's core research themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> Recent advances in multimodal recommendation (MMR) have shown that
incorporating rich content sources such as images and text can lead to
significant gains representation quality. However, existing methods often rely
on coarse visual features and uncontrolled fusion, leading to redundant or
misaligned representations. As a result, visual encoders often fail to capture
salient, item-relevant semantics, limiting their contribution in multimodal
fusion. From an information-theoretic perspective, effective fusion should
balance the unique, shared, and redundant information across modalities,
preserving complementary cues while avoiding correlation bias. This paper
presents VLIF, a vision-language and information-theoretic fusion framework
that enhances multimodal recommendation through two key components. (i) A
VLM-based visual enrichment module generates fine-grained, title-guided
descriptions to transform product images into semantically aligned
representations. (ii) An information-aware fusion module, inspired by Partial
Information Decomposition (PID), disentangles redundant and synergistic signals
across modalities for controlled integration. Experiments on three Amazon
datasets demonstrate that VLIF consistently outperforms recent multimodal
baselines and substantially strengthens the contribution of visual features.

### 19. Complete asymptotic type-token relationship for growing complex systems with inverse power-law count rankings

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Pablo Rosillo-Rodes, Laurent H√©bert-Dufresne, Peter Sheridan Dodds
- **URL**: <http://arxiv.org/abs/2511.02069v1>
- **Submitted**: 2025-11-03 21:07:33
- **Comment**: 5 pages, 2 figures
- **Topic Keywords**: ranking, rank
- **Reason**: This paper appears to be primarily focused on mathematical modeling of complex systems and their growth dynamics, specifically exploring the asymptotic type-token relationship. While it touches on power-law relationships, which are related to Zipf's law, it does not directly relate to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing.

#### Abstract
> The growth dynamics of complex systems often exhibit statistical regularities
involving power-law relationships. For real finite complex systems formed by
countable tokens (animals, words) as instances of distinct types (species,
dictionary entries), an inverse power-law scaling $S \sim r^{-\alpha}$ between
type count $S$ and type rank $r$, widely known as Zipf's law, is widely
observed to varying degrees of fidelity. A secondary, summary relationship is
Heaps' law, which states that the number of types scales sublinearly with the
total number of observed tokens present in a growing system. Here, we propose
an idealized model of a growing system that (1) deterministically produces
arbitrary inverse power-law count rankings for types, and (2) allows us to
determine the exact asymptotics of the type-token relationship. Our argument
improves upon and remedies earlier work. We obtain a unified asymptotic
expression for all values of $\alpha$, which corrects the special cases of
$\alpha = 1$ and $\alpha \gg 1$. Our approach relies solely on the form of
count rankings, avoids unnecessary approximations, and does not involve any
stochastic mechanisms or sampling processes. We thereby demonstrate that a
general type-token relationship arises solely as a consequence of Zipf's law.

### 20. Optimal Singular Damage: Efficient LLM Inference in Low Storage Regimes

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Mohammadsajad Alipour, Mohammad Mohammadi Amiri
- **URL**: <http://arxiv.org/abs/2511.02681v1>
- **Submitted**: 2025-11-04 16:05:25
- **Topic Keywords**: rag, rank
- **Reason**: This paper focuses on efficient storage of pre-trained language models, which is not directly related to information retrieval, search technologies, or query understanding. While it involves deep learning and model optimization, the context is more aligned with NLP and model storage efficiency rather than real-time relevance optimization or user behavior modeling.

#### Abstract
> Large language models (LLMs) are increasingly prevalent across diverse
applications. However, their enormous size limits storage and processing
capabilities to a few well-resourced stakeholders. As a result, most
applications rely on pre-trained LLMs, fine-tuned for specific tasks. However,
even storing the fine-tuned versions of these models remains a significant
challenge due to the wide range of tasks they address. Recently, studies show
that fine-tuning these models primarily affects a small fraction of parameters,
highlighting the need for more efficient storage of fine-tuned models. This
paper focuses on efficient storage of parameter updates in pre-trained models
after fine-tuning. To address this challenge, we leverage the observation that
fine-tuning updates are both low-rank and sparse, which can be utilized for
storage efficiency. However, using only low-rank approximation or
sparsification may discard critical singular components that enhance model
expressivity. We first observe that given the same memory budget, sparsified
low-rank approximations with larger ranks outperform standard low-rank
approximations with smaller ranks. Building on this, we propose our method,
optimal singular damage, that selectively sparsifies low-rank approximated
updates by leveraging the interleaved importance of singular vectors, ensuring
that the most impactful components are retained. We demonstrate through
extensive experiments that our proposed methods lead to significant storage
efficiency and superior accuracy within the same memory budget compared to
employing the low-rank approximation or sparsification individually.

### 21. The Analysis of Lexical Errors in Machine Translation from English into Romanian

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Angela Stamatie
- **URL**: <http://arxiv.org/abs/2511.02587v1>
- **Submitted**: 2025-11-04 14:07:21
- **Comment**: Doctoral thesis
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your research interests as it focuses on machine translation error analysis, which is outside the scope of information retrieval, search technologies, and natural language processing. Although it involves NLP, the specific context and goals of the research do not align with your core themes.

#### Abstract
> The research explores error analysis in the performance of translating by
Machine Translation from English into Romanian, and it focuses on lexical
errors found in texts which include official information, provided by the World
Health Organization (WHO), the Gavi Organization, by the patient information
leaflet (the information about the active ingredients of the vaccines or the
medication, the indications, the dosage instructions, the storage instructions,
the side effects and warning, etc.). All of these texts are related to Covid-19
and have been translated by Google Translate, a multilingual Machine
Translation that was created by Google. In the last decades, Google has
actively worked to develop a more accurate and fluent automatic translation
system. This research, specifically focused on improving Google Translate, aims
to enhance the overall quality of Machine Translation by achieving better
lexical selection and by reducing errors. The investigation involves a
comprehensive analysis of 230 texts that have been translated from English into
Romanian.

### 22. DetectiumFire: A Comprehensive Multi-modal Dataset Bridging Vision and Language for Fire Understanding

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Zixuan Liu, Siavash H. Khajavi, Guangkai Jiang
- **URL**: <http://arxiv.org/abs/2511.02495v1>
- **Submitted**: 2025-11-04 11:33:11
- **Comment**: Advances in Neural Information Processing Systems 2025 (NeurIPS
  2025), Poster, https://neurips.cc/virtual/2025/loc/san-diego/poster/121400
- **Topic Keywords**: rag, search
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or user behavior modeling, which are core areas of your research interests. While it involves multi-modal models and vision-language reasoning, the focus is on computer vision and fire understanding, which is not a primary area of your research.

#### Abstract
> Recent advances in multi-modal models have demonstrated strong performance in
tasks such as image generation and reasoning. However, applying these models to
the fire domain remains challenging due to the lack of publicly available
datasets with high-quality fire domain annotations. To address this gap, we
introduce DetectiumFire, a large-scale, multi-modal dataset comprising of 22.5k
high-resolution fire-related images and 2.5k real-world fire-related videos
covering a wide range of fire types, environments, and risk levels. The data
are annotated with both traditional computer vision labels (e.g., bounding
boxes) and detailed textual prompts describing the scene, enabling applications
such as synthetic data generation and fire risk reasoning. DetectiumFire offers
clear advantages over existing benchmarks in scale, diversity, and data
quality, significantly reducing redundancy and enhancing coverage of real-world
scenarios. We validate the utility of DetectiumFire across multiple tasks,
including object detection, diffusion-based image generation, and
vision-language reasoning. Our results highlight the potential of this dataset
to advance fire-related research and support the development of intelligent
safety systems. We release DetectiumFire to promote broader exploration of fire
understanding in the AI community. The dataset is available at
https://kaggle.com/datasets/38b79c344bdfc55d1eed3d22fbaa9c31fad45e27edbbe9e3c529d6e5c4f93890

### 23. LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yudong Li, Zhongliang Yang, Kejiang Chen, Wenxuan Wang, Tianxin Zhang, Sifang Wan, Kecheng Wang, Haitian Li, Xu Wang, Lefan Cheng, Youdan Yang, Baocheng Chen, Ziyu Liu, Yufei Sun, Liyan Wu, Wenya Wen, Xingchi Gu, Peiru Yang
- **URL**: <http://arxiv.org/abs/2511.02366v1>
- **Submitted**: 2025-11-04 08:44:09
- **Topic Keywords**: relevance
- **Reason**: This paper appears to be focused on AI safety benchmarking for LLMs in the Chinese context, which is not directly related to the user's core research themes in Information Retrieval and Search technologies, particularly query understanding, ranking models, and user behavior modeling.

#### Abstract
> In this work, we propose LiveSecBench, a dynamic and continuously updated
safety benchmark specifically for Chinese-language LLM application scenarios.
LiveSecBench evaluates models across six critical dimensions (Legality, Ethics,
Factuality, Privacy, Adversarial Robustness, and Reasoning Safety) rooted in
the Chinese legal and social frameworks. This benchmark maintains relevance
through a dynamic update schedule that incorporates new threat vectors, such as
the planned inclusion of Text-to-Image Generation Safety and Agentic Safety in
the next update. For now, LiveSecBench (v251030) has evaluated 18 LLMs,
providing a landscape of AI safety in the context of Chinese language. The
leaderboard is publicly accessible at https://livesecbench.intokentech.cn/.

### 24. PragExTra: A Multilingual Corpus of Pragmatic Explicitation in Translation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Doreen Osmelak, Koel Dutta Chowdhury, Uliana Sentsova, Cristina Espa√±a-Bonet, Josef van Genabith
- **URL**: <http://arxiv.org/abs/2511.02721v1>
- **Submitted**: 2025-11-04 16:44:57
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to your core research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves multilingualism and machine translation, the focus is on translation theory and corpus development, which is not a central match to your research themes.

#### Abstract
> Translators often enrich texts with background details that make implicit
cultural meanings explicit for new audiences. This phenomenon, known as
pragmatic explicitation, has been widely discussed in translation theory but
rarely modeled computationally. We introduce PragExTra, the first multilingual
corpus and detection framework for pragmatic explicitation. The corpus covers
eight language pairs from TED-Multi and Europarl and includes additions such as
entity descriptions, measurement conversions, and translator remarks. We
identify candidate explicitation cases through null alignments and refined
using active learning with human annotation. Our results show that entity and
system-level explicitations are most frequent, and that active learning
improves classifier accuracy by 7-8 percentage points, achieving up to 0.88
accuracy and 0.82 F1 across languages. PragExTra establishes pragmatic
explicitation as a measurable, cross-linguistic phenomenon and takes a step
towards building culturally aware machine translation. Keywords: translation,
multilingualism, explicitation

### 25. CGES: Confidence-Guided Early Stopping for Efficient and Accurate Self-Consistency

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ehsan Aghazadeh, Ahmad Ghasemi, Hedyeh Beyhaghi, Hossein Pishro-Nik
- **URL**: <http://arxiv.org/abs/2511.02603v1>
- **Submitted**: 2025-11-04 14:25:54
- **Comment**: Efficient Reasoning @ NeurIPS2025
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to Information Retrieval or Search technologies. It focuses on improving the efficiency and accuracy of large language models, which is a topic in Natural Language Processing, but not a central match to your research interests.

#### Abstract
> Large language models (LLMs) are often queried multiple times at test time,
with predictions aggregated by majority vote. While effective, this
self-consistency strategy (arXiv:2203.11171) requires a fixed number of calls
and can fail when the correct answer is rare. We introduce Confidence-Guided
Early Stopping (CGES), a Bayesian framework that forms posteriors over
candidate answers using scalar confidence signals derived from token
probabilities or reward models. CGES adaptively halts sampling once the
posterior mass of a candidate exceeds a threshold. We provide theoretical
guarantees for both perfectly calibrated confidences and realistic noisy
confidence signals. Across five reasoning benchmarks, CGES reduces the average
number of model calls by about 69 percent (for example, from 16.0 to 4.9) while
matching the accuracy of self-consistency within 0.06 percentage points.

### 26. Next Token Knowledge Tracing: Exploiting Pretrained LLM Representations to Decode Student Behaviour

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Max Norris, Kobi Gal, Sahan Bulathwela
- **URL**: <http://arxiv.org/abs/2511.02599v1>
- **Submitted**: 2025-11-04 14:20:56
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Knowledge Tracing in educational settings, using Large Language Models to predict student responses. While it involves natural language processing and sequence modeling, it is not directly related to information retrieval, search technologies, or e-commerce, which are the primary areas of interest.

#### Abstract
> Modelling student knowledge is a key challenge when leveraging AI in
education, with major implications for personalised learning. The Knowledge
Tracing (KT) task aims to predict how students will respond to educational
questions in learning environments, based on their prior interactions. Existing
KT models typically use response correctness along with metadata like skill
tags and timestamps, often overlooking the question text, which is an important
source of pedagogical insight. This omission poses a lost opportunity while
limiting predictive performance. We propose Next Token Knowledge Tracing
(NTKT), a novel approach that reframes KT as a next-token prediction task using
pretrained Large Language Models (LLMs). NTKT represents both student histories
and question content as sequences of text, allowing LLMs to learn patterns in
both behaviour and language. Our series of experiments significantly improves
performance over state-of-the-art neural KT models and generalises much better
to cold-start questions and users. These findings highlight the importance of
question content in KT and demonstrate the benefits of leveraging pretrained
representations of LLMs to model student learning more effectively.

### 27. CoCoVa: Chain of Continuous Vision-Language Thought for Latent Space Reasoning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jizheng Ma, Xiaofei Zhou, Yanlong Song, Han Yan
- **URL**: <http://arxiv.org/abs/2511.02360v1>
- **Submitted**: 2025-11-04 08:28:46
- **Topic Keywords**: rag
- **Reason**: This paper focuses on bridging the gap between discrete language processing and continuous visual understanding, proposing a novel framework for vision-language models. While it explores cross-modal reasoning, it doesn't directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> In human cognition, there exist numerous thought processes that are tacit and
beyond verbal expression, enabling us to understand and interact with the world
in multiple ways. However, contemporary Vision-Language Models (VLMs) remain
constrained to reasoning within the discrete and rigid space of linguistic
tokens, thereby bottlenecking the rich, high-dimensional nature of visual
perception. To bridge this gap, we propose CoCoVa (Chain of Continuous
Vision-Language Thought), a novel framework for vision-language model that
leverages continuous cross-modal reasoning for diverse vision-language tasks.
The core of CoCoVa is an iterative reasoning cycle, where a novel Latent
Q-Former (LQ-Former) acts as a dynamic reasoning engine, iteratively refining a
chain of latent thought vectors through cross-modal fusion. To focus this
process, a token selection mechanism dynamically identifies salient visual
regions, mimicking attentional focus. To ensure these latent thoughts remain
grounded, we train the model with a multi-task objective that combines
contrastive learning and diffusion-based reconstruction, enforcing alignment
between latent representations and both visual and textual modalities.
Evaluations show CoCoVa improves accuracy and token efficiency over strong
baselines. With a 1.5B backbone, it competes with or surpasses larger 7B-9B
models on almost all benchmarks. When scaled to 7B LLM backbones, it remains
competitive with state-of-the-art models. Qualitative analysis validates that
learned latent space captures interpretable and structured reasoning patterns,
highlighting the potential of CoCoVa to bridge the representational gap between
discrete language processing and the continuous nature of visual understanding.

### 28. An Evaluation of Interleaved Instruction Tuning on Semantic Reasoning Performance in an Audio MLLM

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jiawei Liu, Enis Berk √áoban, Zarina Schevchenko, Hao Tang, Zhigang Zhu, Michael I Mandel, Johanna Devaney
- **URL**: <http://arxiv.org/abs/2511.02234v1>
- **Submitted**: 2025-11-04 03:54:55
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Multi-modal Large Language Models (MLLMs) and their ability to integrate audio and text information, which is not directly related to the user's primary research interests in Information Retrieval, query understanding, and ranking models. While it touches on semantic reasoning, it is in the context of audio-based tasks, which is not a central match for the user's interests. The paper's focus on MLLMs and audio-based tasks makes it only loosely relevant to the user's research.

#### Abstract
> Standard training for Multi-modal Large Language Models (MLLMs) involves
concatenating non-textual information, like vision or audio, with a text
prompt. This approach may not encourage deep integration of modalities,
limiting the model's ability to leverage the core language model's reasoning
capabilities. This work examined the impact of interleaved instruction tuning
in an audio MLLM, where audio tokens are interleaved within the prompt. Using
the Listen, Think, and Understand (LTU) model as a testbed, we conduct an
experiment using the Synonym and Hypernym Audio Reasoning Dataset (SHARD), our
newly created reasoning benchmark for audio-based semantic reasoning focusing
on synonym and hypernym recognition. Our findings show that while even
zero-shot interleaved prompting improves performance on our reasoning tasks, a
small amount of fine-tuning using interleaved training prompts improves the
results further, however, at the expense of the MLLM's audio labeling ability.

### 29. LTD-Bench: Evaluating Large Language Models by Letting Them Draw

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Liuhao Lin, Ke Li, Zihan Xu, Yuchen Shi, Yulei Qin, Yan Zhang, Xing Sun, Rongrong Ji
- **URL**: <http://arxiv.org/abs/2511.02347v1>
- **Submitted**: 2025-11-04 08:11:23
- **Comment**: Accepted by NeurIPS 2025
- **Topic Keywords**: search
- **Reason**: This paper focuses on evaluating large language models through drawing and spatial reasoning tasks, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on model capabilities, it does not address query understanding, ranking models, or user behavior modeling, making it somewhat off-topic for your research.

#### Abstract
> Current evaluation paradigms for large language models (LLMs) represent a
critical blind spot in AI research--relying on opaque numerical metrics that
conceal fundamental limitations in spatial reasoning while providing no
intuitive understanding of model capabilities. This deficiency creates a
dangerous disconnect between reported performance and practical abilities,
particularly for applications requiring physical world understanding. We
introduce LTD-Bench, a breakthrough benchmark that transforms LLM evaluation
from abstract scores to directly observable visual outputs by requiring models
to generate drawings through dot matrices or executable code. This approach
makes spatial reasoning limitations immediately apparent even to non-experts,
bridging the fundamental gap between statistical performance and intuitive
assessment. LTD-Bench implements a comprehensive methodology with complementary
generation tasks (testing spatial imagination) and recognition tasks (assessing
spatial perception) across three progressively challenging difficulty levels,
methodically evaluating both directions of the critical language-spatial
mapping. Our extensive experiments with state-of-the-art models expose an
alarming capability gap: even LLMs achieving impressive results on traditional
benchmarks demonstrate profound deficiencies in establishing bidirectional
mappings between language and spatial concept--a fundamental limitation that
undermines their potential as genuine world models. Furthermore, LTD-Bench's
visual outputs enable powerful diagnostic analysis, offering a potential
approach to investigate model similarity.

### 30. Deep Value Benchmark: Measuring Whether Models Generalize Deep values or Shallow Preferences

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Joshua Ashkinaze, Hua Shen, Sai Avula, Eric Gilbert, Ceren Budak
- **URL**: <http://arxiv.org/abs/2511.02109v1>
- **Submitted**: 2025-11-03 22:49:54
- **Comment**: NeurIPS 2025 (Spotlight)
- **Topic Keywords**: rag
- **Reason**: LLM scoring failed.

#### Abstract
> We introduce the Deep Value Benchmark (DVB), an evaluation framework that
directly tests whether large language models (LLMs) learn fundamental human
values or merely surface-level preferences. This distinction is critical for AI
alignment: Systems that capture deeper values are likely to generalize human
intentions robustly, while those that capture only superficial patterns in
preference data risk producing misaligned behavior. The DVB uses a novel
experimental design with controlled confounding between deep values (e.g.,
moral principles) and shallow features (e.g., superficial attributes). In the
training phase, we expose LLMs to human preference data with deliberately
correlated deep and shallow features -- for instance, where a user consistently
prefers (non-maleficence, formal language) options over (justice, informal
language) alternatives. The testing phase then breaks these correlations,
presenting choices between (justice, formal language) and (non-maleficence,
informal language) options. This design allows us to precisely measure a
model's Deep Value Generalization Rate (DVGR) -- the probability of
generalizing based on the underlying value rather than the shallow feature.
Across 9 different models, the average DVGR is just 0.30. All models generalize
deep values less than chance. Larger models have a (slightly) lower DVGR than
smaller models. We are releasing our dataset, which was subject to three
separate human validation experiments. DVB provides an interpretable measure of
a core feature of alignment.

### 31. Library and Culture: A Scientometric Analysis and Visualization of Research Trends

- **LLM Score**: 0
- **Keyword Score**: 1
- **Authors**: Auwalu Abdullahi Umar, Muneer Ahmad, Dr M Sadik Batcha
- **URL**: <http://arxiv.org/abs/2511.02296v1>
- **Submitted**: 2025-11-04 06:19:25
- **Comment**: 8 pages, 3 figures, Research Article
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, data mining, or recommender systems. The paper focuses on a scientometric analysis of library and culture research trends, which is outside your primary areas of interest.

#### Abstract
> The significance of libraries in preserving and maintaining history and
traditional culture cannot be overlooked. It is from this purpose that
libraries are to envisage in their programmes cultural activities which must be
collected, documented and preserved for posterity. The usefulness of preserved
information lies in the fact that the generation to come will be able to
establish their identity. This will also assist them with a foundation to build
from. This study focus on the growth and development of Library and Culture
research in forms of publications reflected in Web of Science database, during
the span of 2010-2019. A total 890 publications were found and the highest 124
(13.93%) publications published in 2019.The analysis maps comprehensively the
parameters of total output, growth of output, authorship, institution wise and
country-level collaboration patterns, major contributors (individuals, top
publication sources, institutions, and countries). It exposed that the most
prolific author is Lo P secured first place by contributing 4 (0.45%)
publications, followed by Bressan V 3 (0.34%) publications in Library and
Culture literature. Journal of Academic Librarianship produced the highest
number of records 29 (3.26%) followed by Australian Library Journal having
contributed 21 (2.36%).It is identified the domination of Wuhan University;
School Information Management had contributed 6 (0.67%) of total research
output. Authors from USA published the highest number of publications with a
total of 244 (27.42%), followed by UK and Australia with 118 (13.26%) and 76
(8.54%) publications were produced respectively.

### 32. Research Output on Alopecia Areata Disease: A Scientometric Analysis of Publications from 2010 to 2019

- **LLM Score**: 0
- **Keyword Score**: 1
- **Authors**: Muneer Ahmad, M Sadik Batcha
- **URL**: <http://arxiv.org/abs/2511.02275v1>
- **Submitted**: 2025-11-04 05:26:46
- **Comment**: 16 pages, 3 figures, Research Paper
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, data mining, or related topics. The paper is a scientometric analysis of publications on a specific disease, which is unrelated to your areas of focus.

#### Abstract
> The present study is undertaken to find out the publication trends on
Alopecia Areata Disease during 2010-2019 from the global perspective. The study
mainly focus on distribution of research output, top journals for publications,
most prolific authors, authorship pattern, and citations pattern on Alopecia
Areata Disease. The results indicate that highest growth rate of publications
occurred during the year 2019. Columbia University topped the scene among all
institutes. The maximum publications were more than four authored publications.
Christiano AM and Clynes R were found to be the most prolific authors. It is
also found that most of the prolific authors (by number of publications) do
appear in highly cited publications list. Alopecia Areata Disease researchers
mostly preferred using article publications to communicate their findings.

### 33. KGBridge: Knowledge-Guided Prompt Learning for Non-overlapping Cross-Domain Recommendation

- **LLM Score**: 0
- **Keyword Score**: 1
- **Authors**: Yuhan Wang, Qing Xie, Zhifeng Bao, Mengzi Tang, Lin Li, Yongjian Liu
- **URL**: <http://arxiv.org/abs/2511.02181v1>
- **Submitted**: 2025-11-04 01:50:01
- **Comment**: 13 pages, 4 figures
- **Topic Keywords**: recommend
- **Reason**: LLM scoring failed.

#### Abstract
> Knowledge Graphs (KGs), as structured knowledge bases that organize
relational information across diverse domains, provide a unified semantic
foundation for cross-domain recommendation (CDR). By integrating symbolic
knowledge with user-item interactions, KGs enrich semantic representations,
support reasoning, and enhance model interpretability. Despite this potential,
existing KG-based methods still face major challenges in CDR, particularly
under non-overlapping user scenarios. These challenges arise from: (C1)
sensitivity to KG sparsity and popularity bias, (C2) dependence on overlapping
users for domain alignment and (C3) lack of explicit disentanglement between
transferable and domain-specific knowledge, which limit effective and stable
knowledge transfer. To this end, we propose KGBridge, a knowledge-guided prompt
learning framework for cross-domain sequential recommendation under
non-overlapping user scenarios. KGBridge comprises two core components: a
KG-enhanced Prompt Encoder, which models relation-level semantics as soft
prompts to provide structured and dynamic priors for user sequence modeling
(addressing C1), and a Two-stage Training Paradigm, which combines cross-domain
pretraining and privacy-preserving fine-tuning to enable knowledge transfer
without user overlap (addressing C2). By combining relation-aware semantic
control with correspondence-driven disentanglement, KGBridge explicitly
separates and balances domain-shared and domain-specific semantics, thereby
maintaining complementarity and stabilizing adaptation during fine-tuning
(addressing C3). Extensive experiments on benchmark datasets demonstrate that
KGBridge consistently outperforms state-of-the-art baselines and remains robust
under varying KG sparsity, highlighting its effectiveness in mitigating
structural imbalance and semantic entanglement in KG-enhanced cross-domain
recommendation.

---

