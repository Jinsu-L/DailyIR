[
    {
        "title": "Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning",
        "abstract": "We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen's $d = 3.30$ ($p < 10^{-116}$), enabling 85.0--95.6\\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B's Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\\text{MW}} = 1.16 \\times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.",
        "url": "http://arxiv.org/abs/2601.00791v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00791v1",
        "arxiv_id": "2601.00791v1",
        "authors": [
            "Valentin Noël"
        ],
        "submitted": "2026-01-02 18:49:37",
        "source": "arxiv",
        "comment": "58 pages, 19 figures, Under Review"
    },
    {
        "title": "Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries",
        "abstract": "Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-provincial evaluation of adapting BCCRTron, a domain-adapted transformer model developed at the British Columbia Cancer Registry, alongside GatorTron, a biomedical transformer model, for cancer surveillance in Canada. Our training dataset consisted of approximately 104,000 and 22,000 de-identified pathology reports from the Newfoundland & Labrador Cancer Registry (NLCR) for Tier 1 (cancer vs. non-cancer) and Tier 2 (reportable vs. non-reportable) tasks, respectively. Both models were fine-tuned using complementary synoptic and diagnosis focused report section input pipelines. Across NLCR test sets, the adapted models maintained high performance, demonstrating transformers pretrained in one jurisdiction can be localized to another with modest fine-tuning. To improve sensitivity, we combined the two models using a conservative OR-ensemble achieving a Tier 1 recall of 0.99 and reduced missed cancers to 24, compared with 48 and 54 for the standalone models. For Tier 2, the ensemble achieved 0.99 recall and reduced missed reportable cancers to 33, compared with 54 and 46 for the individual models. These findings demonstrate that an ensemble combining complementary text representations substantially reduce missed cancers and improve error coverage in cancer-registry NLP. We implement a privacy-preserving workflow in which only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model for cancer pathology and registry workflows.",
        "url": "http://arxiv.org/abs/2601.00787v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00787v1",
        "arxiv_id": "2601.00787v1",
        "authors": [
            "Jonathan Simkin",
            "Lovedeep Gondara",
            "Zeeshan Rizvi",
            "Gregory Doyle",
            "Jeff Dowden",
            "Dan Bond",
            "Desmond Martin",
            "Raymond Ng"
        ],
        "submitted": "2026-01-02 18:46:19",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Memory Bank Compression for Continual Adaptation of Large Language Models",
        "abstract": "Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at https://github.com/Thomkat/MBC.",
        "url": "http://arxiv.org/abs/2601.00756v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00756v1",
        "arxiv_id": "2601.00756v1",
        "authors": [
            "Thomas Katraouras",
            "Dimitrios Rafailidis"
        ],
        "submitted": "2026-01-02 17:22:34",
        "source": "arxiv",
        "comment": "Accepted to the 41st ACM/SIGAPP Symposium on Applied Computing (SAC '26)"
    },
    {
        "title": "Exploring the Performance of Large Language Models on Subjective Span Identification Tasks",
        "abstract": "Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.",
        "url": "http://arxiv.org/abs/2601.00736v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00736v1",
        "arxiv_id": "2601.00736v1",
        "authors": [
            "Alphaeus Dmonte",
            "Roland Oruche",
            "Tharindu Ranasinghe",
            "Marcos Zampieri",
            "Prasad Calyam"
        ],
        "submitted": "2026-01-02 16:30:14",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications",
        "abstract": "Ticket troubleshooting refers to the process of analyzing and resolving problems that are reported through a ticketing system. In large organizations offering a wide range of services, this task is highly complex due to the diversity of submitted tickets and the need for specialized domain knowledge. In particular, troubleshooting in telecommunications (telecom) is a very time-consuming task as it requires experts to interpret ticket content, consult documentation, and search historical records to identify appropriate resolutions. This human-intensive approach not only delays issue resolution but also hinders overall operational efficiency. To enhance the effectiveness and efficiency of ticket troubleshooting in telecom, we propose TeleDoCTR, a novel telecom-related, domain-specific, and contextual troubleshooting system tailored for end-to-end ticket resolution in telecom. TeleDoCTR integrates both domain-specific ranking and generative models to automate key steps of the troubleshooting workflow which are: routing tickets to the appropriate expert team responsible for resolving the ticket (classification task), retrieving contextually and semantically similar historical tickets (retrieval task), and generating a detailed fault analysis report outlining the issue, root cause, and potential solutions (generation task). We evaluate TeleDoCTR on a real-world dataset from a telecom infrastructure and demonstrate that it achieves superior performance over existing state-of-the-art methods, significantly enhancing the accuracy and efficiency of the troubleshooting process.",
        "url": "http://arxiv.org/abs/2601.00691v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00691v1",
        "arxiv_id": "2601.00691v1",
        "authors": [
            "Mohamed Trabelsi",
            "Huseyin Uzunalioglu"
        ],
        "submitted": "2026-01-02 13:55:07",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Sigmoid Head for Quality Estimation under Language Ambiguity",
        "abstract": "Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high probabilities simultaneuously and (2) LMs' training data is single, one-hot encoded references, indicating that there is only one correct option at each output step. We propose training a module for Quality Estimation on top of pre-trained LMs to address these limitations. The module, called Sigmoid Head, is an extra unembedding head with sigmoid activation to tackle the first limitation. To tackle the second limitation, during the negative sampling process to train the Sigmoid Head, we use a heuristic to avoid selecting potentially alternative correct tokens. Our Sigmoid Head is computationally efficient during training and inference. The probability from Sigmoid Head is notably better quality signal compared to the original softmax head. As the Sigmoid Head does not rely on human-annotated quality data, it is more robust to out-of-domain settings compared to supervised QE.",
        "url": "http://arxiv.org/abs/2601.00680v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00680v1",
        "arxiv_id": "2601.00680v1",
        "authors": [
            "Tu Anh Dinh",
            "Jan Niehues"
        ],
        "submitted": "2026-01-02 13:12:28",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Fast-weight Product Key Memory",
        "abstract": "Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, \"fast-weight\" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.",
        "url": "http://arxiv.org/abs/2601.00671v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00671v1",
        "arxiv_id": "2601.00671v1",
        "authors": [
            "Tianyu Zhao",
            "Llion Jones"
        ],
        "submitted": "2026-01-02 12:37:53",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations",
        "abstract": "Large Protein Language Models have shown strong potential for generative protein design, yet they frequently produce structural hallucinations, generating sequences with high linguistic likelihood that fold into thermodynamically unstable conformations. Existing alignment approaches such as Direct Preference Optimization are limited in this setting, as they model preferences as binary labels and ignore the continuous structure of the physical energy landscape. We propose Physio-DPO, a physics informed alignment framework that grounds protein language models in thermodynamic stability. Physio-DPO introduces a magnitude aware objective that scales optimization updates according to the energy gap between native structures and physics perturbed hard negatives. Experiments show that Physio-DPO consistently outperforms strong baselines including SFT, PPO, and standard DPO, reducing self consistency RMSD to 1.28 Å and increasing foldability to 92.8%. Qualitative analysis further demonstrates that Physio-DPO effectively mitigates structural hallucinations by recovering biophysical interactions such as hydrophobic core packing and hydrogen bond networks.",
        "url": "http://arxiv.org/abs/2601.00647v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00647v1",
        "arxiv_id": "2601.00647v1",
        "authors": [
            "QiWei Meng"
        ],
        "submitted": "2026-01-02 11:16:52",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs",
        "abstract": "Large language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model-agnostic framework that provides explicit probabilistic guarantees for reducing hallucinations in this setting.\n  We formalize the notion of a specific task, defined by a fixed input and a deterministic correctness criterion, and show that issuing the same prompt in independent context windows yields an exponential reduction in the probability that all model outputs are incorrect. To identify a correct answer among repeated runs, we incorporate an LLM-as-a-judge and prove that the probability that the judged pipeline fails decays at a rate determined by the judge's true- and false-positive probabilities. When the judge is imperfect, we strengthen it through majority vote over independent judge calls, obtaining ensemble-level error rates that decrease exponentially in the number of votes. This yields an explicit bound on the probability that the pipeline selects a hallucinated answer.\n  Experiments on controlled extraction tasks with synthetic noisy judges match these predictions exactly: pipeline failure decreases exponentially with the number of repetitions, and hallucination-selection decreases exponentially with the number of judges in the ensemble. Together, these results provide a lightweight, modular, and theoretically grounded method for driving hallucination probabilities arbitrarily low in fixed-input LLM workflows-without modifying model weights, decoding strategies, or prompt engineering.",
        "url": "http://arxiv.org/abs/2601.00641v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00641v1",
        "arxiv_id": "2601.00641v1",
        "authors": [
            "Nils Rautenberg",
            "Sven Schippkus"
        ],
        "submitted": "2026-01-02 10:52:33",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence",
        "abstract": "Traditional customer support systems, such as Interactive Voice Response (IVR), rely on rigid scripts and lack the flexibility required for handling complex, policy-driven tasks. While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge. Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. In this work, we introduce JourneyBench, a benchmark designed to assess policy-aware agents in customer support. JourneyBench leverages graph representations to generate diverse, realistic support scenarios and proposes the User Journey Coverage Score, a novel metric to measure policy adherence. We evaluate multiple state-of-the-art LLMs using two agent designs: a Static-Prompt Agent (SPA) and a Dynamic-Prompt Agent (DPA) that explicitly models policy control. Across 703 conversations in three domains, we show that DPA significantly boosts policy adherence, even allowing smaller models like GPT-4o-mini to outperform more capable ones like GPT-4o. Our findings demonstrate the importance of structured orchestration and establish JourneyBench as a critical resource to advance AI-driven customer support beyond IVR-era limitations.",
        "url": "http://arxiv.org/abs/2601.00596v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00596v1",
        "arxiv_id": "2601.00596v1",
        "authors": [
            "Sumanth Balaji",
            "Piyush Mishra",
            "Aashraya Sachdeva",
            "Suraj Agrawal"
        ],
        "submitted": "2026-01-02 07:21:23",
        "source": "arxiv",
        "comment": "17 pages, 3 figures, preprint"
    },
    {
        "title": "CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns",
        "abstract": "Large language models (LLMs) are increasingly deployed in cost-sensitive and on-device scenarios, and safety guardrails have advanced mainly in English. However, real-world Chinese malicious queries typically conceal intent via homophones, pinyin, symbol-based splitting, and other Chinese-specific patterns. These Chinese-specific adversarial patterns create the safety evaluation gap that is not well captured by existing benchmarks focused on English. This gap is particularly concerning for lightweight models, which may be more vulnerable to such specific adversarial perturbations. To bridge this gap, we introduce the Chinese-Specific Safety Benchmark (CSSBench) that emphasizes these adversarial patterns and evaluates the safety of lightweight LLMs in Chinese. Our benchmark covers six domains that are common in real Chinese scenarios, including illegal activities and compliance, privacy leakage, health and medical misinformation, fraud and hate, adult content, and public and political safety, and organizes queries into multiple task types. We evaluate a set of popular lightweight LLMs and measure over-refusal behavior to assess safety-induced performance degradation. Our results show that the Chinese-specific adversarial pattern is a critical challenge for lightweight LLMs. This benchmark offers a comprehensive evaluation of LLM safety in Chinese, assisting robust deployments in practice.",
        "url": "http://arxiv.org/abs/2601.00588v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00588v1",
        "arxiv_id": "2601.00588v1",
        "authors": [
            "Zhenhong Zhou",
            "Shilinlu Yan",
            "Chuanpu Liu",
            "Qiankun Li",
            "Kun Wang",
            "Zhigang Zeng"
        ],
        "submitted": "2026-01-02 06:21:41",
        "source": "arxiv",
        "comment": "18 pages"
    },
    {
        "title": "InfoSynth: Information-Guided Benchmark Synthesis for LLMs",
        "abstract": "Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/",
        "url": "http://arxiv.org/abs/2601.00575v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00575v1",
        "arxiv_id": "2601.00575v1",
        "authors": [
            "Ishir Garg",
            "Neel Kolhe",
            "Xuandong Zhao",
            "Dawn Song"
        ],
        "submitted": "2026-01-02 05:26:27",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Improving Scientific Document Retrieval with Academic Concept Index",
        "abstract": "Adapting general-domain retrievers to scientific domains is challenging due to the scarcity of large-scale domain-specific relevance annotations and the substantial mismatch in vocabulary and information needs. Recent approaches address these issues through two independent directions that leverage large language models (LLMs): (1) generating synthetic queries for fine-tuning, and (2) generating auxiliary contexts to support relevance matching. However, both directions overlook the diverse academic concepts embedded within scientific documents, often producing redundant or conceptually narrow queries and contexts. To address this limitation, we introduce an academic concept index, which extracts key concepts from papers and organizes them guided by an academic taxonomy. This structured index serves as a foundation for improving both directions. First, we enhance the synthetic query generation with concept coverage-based generation (CCQGen), which adaptively conditions LLMs on uncovered concepts to generate complementary queries with broader concept coverage. Second, we strengthen the context augmentation with concept-focused auxiliary contexts (CCExpand), which leverages a set of document snippets that serve as concise responses to the concept-aware CCQGen queries. Extensive experiments show that incorporating the academic concept index into both query generation and context augmentation leads to higher-quality queries, better conceptual alignment, and improved retrieval performance.",
        "url": "http://arxiv.org/abs/2601.00567v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00567v1",
        "arxiv_id": "2601.00567v1",
        "authors": [
            "Jeyun Lee",
            "Junhyoung Lee",
            "Wonbin Kweon",
            "Bowen Jin",
            "Yu Zhang",
            "Susik Yoon",
            "Dongha Lee",
            "Hwanjo Yu",
            "Jiawei Han",
            "Seongku Kang"
        ],
        "submitted": "2026-01-02 04:47:49",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR",
        "abstract": "Large-scale multilingual ASR (mASR) models such as Whisper achieve strong performance but incur high computational and latency costs, limiting their deployment on resource-constrained edge devices. In this study, we propose a lightweight and language-agnostic multilingual ASR system based on a CTC architecture with domain adaptation. Specifically, we introduce a Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model, enabling end-to-end decoding via LID-posterior-driven LoRA routing. The hierarchical design consists of a multilingual shared LoRA for learning language-invariant acoustic representations and language-specific LoRA experts for modeling language-dependent characteristics. The proposed routing mechanism removes the need for prior language identity information or explicit language labels during inference, achieving true language-agnostic decoding. Experiments on MSR-86K and the MLC-SLM 2025 Challenge datasets demonstrate that HLoRA achieves competitive performance with state-of-the-art two-stage inference methods using only single-pass decoding, significantly improving decoding efficiency for low-resource mASR applications.",
        "url": "http://arxiv.org/abs/2601.00557v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00557v1",
        "arxiv_id": "2601.00557v1",
        "authors": [
            "Yuang Zheng",
            "Yuxiang Mei",
            "Dongxing Xu",
            "Jie Chen",
            "Yanhua Long"
        ],
        "submitted": "2026-01-02 04:08:39",
        "source": "arxiv",
        "comment": "5 pages, submitted to IEEE Signal Processing Letters"
    },
    {
        "title": "ECR: Manifold-Guided Semantic Cues for Compact Language Models",
        "abstract": "Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.\n  To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.\n  In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.",
        "url": "http://arxiv.org/abs/2601.00543v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00543v1",
        "arxiv_id": "2601.00543v1",
        "authors": [
            "Chung-Wei Victor Yuan"
        ],
        "submitted": "2026-01-02 03:16:24",
        "source": "arxiv",
        "comment": "Preprint 13pages, 6 figures"
    },
    {
        "title": "Retrieval--Reasoning Processes for Multi-hop Question Answering: A Four-Axis Design Framework and Empirical Trends",
        "abstract": "Multi-hop question answering (QA) requires systems to iteratively retrieve evidence and reason across multiple hops. While recent RAG and agentic methods report strong results, the underlying retrieval--reasoning \\emph{process} is often left implicit, making procedural choices hard to compare across model families. This survey takes the execution procedure as the unit of analysis and introduces a four-axis framework covering (A) overall execution plan, (B) index structure, (C) next-step control (strategies and triggers), and (D) stop/continue criteria. Using this schema, we map representative multi-hop QA systems and synthesize reported ablations and tendencies on standard benchmarks (e.g., HotpotQA, 2WikiMultiHopQA, MuSiQue), highlighting recurring trade-offs among effectiveness, efficiency, and evidence faithfulness. We conclude with open challenges for retrieval--reasoning agents, including structure-aware planning, transferable control policies, and robust stopping under distribution shift.",
        "url": "http://arxiv.org/abs/2601.00536v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00536v1",
        "arxiv_id": "2601.00536v1",
        "authors": [
            "Yuelyu Ji",
            "Zhuochun Li",
            "Rui Meng",
            "Daqing He"
        ],
        "submitted": "2026-01-02 02:38:01",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "The Illusion of Insight in Reasoning Models",
        "abstract": "Do reasoning models have \"Aha!\" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.",
        "url": "http://arxiv.org/abs/2601.00514v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00514v1",
        "arxiv_id": "2601.00514v1",
        "authors": [
            "Liv G. d'Aliberti",
            "Manoel Horta Ribeiro"
        ],
        "submitted": "2026-01-02 00:12:13",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "A Chain-of-Thought Approach to Semantic Query Categorization in e-Commerce Taxonomies",
        "abstract": "Search in e-Commerce is powered at the core by a structured representation of the inventory, often formulated as a category taxonomy. An important capability in e-Commerce with hierarchical taxonomies is to select a set of relevant leaf categories that are semantically aligned with a given user query. In this scope, we address a fundamental problem of search query categorization in real-world e-Commerce taxonomies. A correct categorization of a query not only provides a way to zoom into the correct inventory space, but opens the door to multiple intent understanding capabilities for a query. A practical and accurate solution to this problem has many applications in e-commerce, including constraining retrieved items and improving the relevance of the search results. For this task, we explore a novel Chain-of-Thought (CoT) paradigm that combines simple tree-search with LLM semantic scoring. Assessing its classification performance on human-judged query-category pairs, relevance tests, and LLM-based reference methods, we find that the CoT approach performs better than a benchmark that uses embedding-based query category predictions. We show how the CoT approach can detect problems within a hierarchical taxonomy. Finally, we also propose LLM-based approaches for query-categorization of the same spirit, but which scale better at the range of millions of queries.",
        "url": "http://arxiv.org/abs/2601.00510v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00510v1",
        "arxiv_id": "2601.00510v1",
        "authors": [
            "Jetlir Duraj",
            "Ishita Khan",
            "Kilian Merkelbach",
            "Mehran Elyasi"
        ],
        "submitted": "2026-01-01 23:36:13",
        "source": "arxiv",
        "comment": "9 pages, accepted at SIGIR eCom 2025"
    },
    {
        "title": "Rule-Based Approaches to Atomic Sentence Extraction",
        "abstract": "Natural language often combines multiple ideas into complex sentences. Atomic sentence extraction, the task of decomposing complex sentences into simpler sentences that each express a single idea, improves performance in information retrieval, question answering, and automated reasoning systems. Previous work has formalized the \"split-and-rephrase\" task and established evaluation metrics, and machine learning approaches using large language models have improved extraction accuracy. However, these methods lack interpretability and provide limited insight into which linguistic structures cause extraction failures. Although some studies have explored dependency-based extraction of subject-verb-object triples and clauses, no principled analysis has examined which specific clause structures and dependencies lead to extraction difficulties. This study addresses this gap by analyzing how complex sentence structures, including relative clauses, adverbial clauses, coordination patterns, and passive constructions, affect the performance of rule-based atomic sentence extraction. Using the WikiSplit dataset, we implemented dependency-based extraction rules in spaCy, generated 100 gold=standard atomic sentence sets, and evaluated performance using ROUGE and BERTScore. The system achieved ROUGE-1 F1 = 0.6714, ROUGE-2 F1 = 0.478, ROUGE-L F1 = 0.650, and BERTScore F1 = 0.5898, indicating moderate-to-high lexical, structural, and semantic alignment. Challenging structures included relative clauses, appositions, coordinated predicates, adverbial clauses, and passive constructions. Overall, rule-based extraction is reasonably accurate but sensitive to syntactic complexity.",
        "url": "http://arxiv.org/abs/2601.00506v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00506v1",
        "arxiv_id": "2601.00506v1",
        "authors": [
            "Lineesha Kamana",
            "Akshita Ananda Subramanian",
            "Mehuli Ghosh",
            "Suman Saha"
        ],
        "submitted": "2026-01-01 23:19:51",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Noise-Aware Named Entity Recognition for Historical VET Documents",
        "abstract": "This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.",
        "url": "http://arxiv.org/abs/2601.00488v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00488v1",
        "arxiv_id": "2601.00488v1",
        "authors": [
            "Alexander M. Esser",
            "Jens Dörpinghaus"
        ],
        "submitted": "2026-01-01 21:43:35",
        "source": "arxiv",
        "comment": "This is an extended, non-peer-reviewed version of the paper presented at VISAPP 2026"
    },
    {
        "title": "Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations",
        "abstract": "Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.",
        "url": "http://arxiv.org/abs/2601.00454v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00454v1",
        "arxiv_id": "2601.00454v1",
        "authors": [
            "Hyunjun Kim"
        ],
        "submitted": "2026-01-01 19:42:08",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games",
        "abstract": "Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.",
        "url": "http://arxiv.org/abs/2601.00448v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00448v1",
        "arxiv_id": "2601.00448v1",
        "authors": [
            "Dimitris Vartziotis"
        ],
        "submitted": "2026-01-01 19:15:17",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment",
        "abstract": "In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - DistilBERT, MiniLM, and ALBERT - across three distinct domains: customer sentiment classification, news topic classification, and toxicity and hate speech detection. Utilizing datasets from IMDB, AG News, and the Measuring Hate Speech corpus, we evaluated performance using accuracy-based metrics including accuracy, precision, recall, and F1-score, as well as efficiency metrics such as model size, inference time, throughput, and memory usage. Key findings reveal that no single model dominates all performance dimensions. ALBERT achieves the highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates the most consistent accuracy across tasks while maintaining competitive efficiency. All results reflect controlled fine-tuning under fixed enterprise-oriented constraints rather than exhaustive hyperparameter optimization. These results highlight trade-offs between accuracy and efficiency, recommending MiniLM for latency-sensitive enterprise applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments.",
        "url": "http://arxiv.org/abs/2601.00444v1",
        "pdf_url": "https://arxiv.org/pdf/2601.00444v1",
        "arxiv_id": "2601.00444v1",
        "authors": [
            "Muhammad Shahmeer Khan"
        ],
        "submitted": "2026-01-01 19:05:25",
        "source": "arxiv",
        "comment": "11 pages, 6 figures. Code and reproducibility resources available on GitHub"
    }
]