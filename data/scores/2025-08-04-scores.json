[
    {
        "title": "FinCPRG: A Bidirectional Generation Pipeline for Hierarchical Queries and Rich Relevance in Financial Chinese Passage Retrieval",
        "abstract": "In recent years, large language models (LLMs) have demonstrated significant\npotential in constructing passage retrieval datasets. However, existing methods\nstill face limitations in expressing cross-doc query needs and controlling\nannotation quality. To address these issues, this paper proposes a\nbidirectional generation pipeline, which aims to generate 3-level hierarchical\nqueries for both intra-doc and cross-doc scenarios and mine additional\nrelevance labels on top of direct mapping annotation. The pipeline introduces\ntwo query generation methods: bottom-up from single-doc text and top-down from\nmulti-doc titles. The bottom-up method uses LLMs to disassemble and generate\nstructured queries at both sentence-level and passage-level simultaneously from\nintra-doc passages. The top-down approach incorporates three key financial\nelements--industry, topic, and time--to divide report titles into clusters and\nprompts LLMs to generate topic-level queries from each cluster. For relevance\nannotation, our pipeline not only relies on direct mapping annotation from the\ngeneration relationship but also implements an indirect positives mining method\nto enrich the relevant query-passage pairs. Using this pipeline, we constructed\na Financial Passage Retrieval Generated dataset (FinCPRG) from almost 1.3k\nChinese financial research reports, which includes hierarchical queries and\nrich relevance labels. Through evaluations of mined relevance labels,\nbenchmarking and training experiments, we assessed the quality of FinCPRG and\nvalidated its effectiveness as a passage retrieval dataset for both training\nand benchmarking.",
        "url": "http://arxiv.org/abs/2508.02222v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02222v1",
        "arxiv_id": "2508.02222v1",
        "authors": [
            "Xuan Xu",
            "Beilin Chu",
            "Qinhong Lin",
            "Yixiao Zhong",
            "Fufang Wen",
            "Jiaqi Liu",
            "Binjie Fei",
            "Yu Li",
            "Zhongliang Yang",
            "Linna Zhou"
        ],
        "submitted": "2025-08-04 09:12:45",
        "source": "arxiv",
        "comment": null,
        "score": 15,
        "keyword_reasons": [
            "Found 'passage retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper proposes a bidirectional generation pipeline for hierarchical queries and rich relevance in financial Chinese passage retrieval, which is related to information retrieval and query understanding. Although it focuses on a specific domain (finance) and language (Chinese), the techniques and methods discussed can be applicable to other domains and languages. The paper's emphasis on hierarchical queries and relevance labels aligns with the user's interest in ranking models and user behavior modeling."
    },
    {
        "title": "Decomposed Reasoning with Reinforcement Learning for Relevance Assessment in UGC Platforms",
        "abstract": "Retrieval-augmented generation (RAG) plays a critical role in user-generated\ncontent (UGC) platforms, but its effectiveness depends heavily on accurate\nrelevance assessment of query-document pairs. Despite recent advances in\napplying large language models (LLMs) to relevance modeling, UGC platforms\npresent unique challenges: 1) ambiguous user intent due to sparse user feedback\nin RAG scenarios, and 2) substantial noise introduced by informal and\nunstructured language. To address these issues, we propose the Reinforced\nReasoning Model for Relevance Assessment (R3A), which introduces a decomposed\nreasoning framework over queries and candidate documents before scoring. R3A\nfirst leverages auxiliary high-ranked documents within the platform to infer\nlatent query intent. It then performs verbatim fragment extraction to justify\nrelevance decisions, thereby reducing errors caused by noisy UGC. Based on a\nreinforcement learning framework, R3A is optimized to mitigate distortions\narising from ambiguous queries and unstructured content. Experimental results\nshow that R3A significantly outperforms existing baseline methods in terms of\nrelevance accuracy, across both offline benchmarks and online experiments.",
        "url": "http://arxiv.org/abs/2508.02506v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02506v1",
        "arxiv_id": "2508.02506v1",
        "authors": [
            "Xiaowei Yuan",
            "Lei Jin",
            "Haoxin Zhang",
            "Yan Gao",
            "Yi Wu",
            "Yao Hu",
            "Ziyang Huang",
            "Jun Zhao",
            "Kang Liu"
        ],
        "submitted": "2025-08-04 15:14:09",
        "source": "arxiv",
        "comment": null,
        "score": 14,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "The paper focuses on relevance assessment in user-generated content platforms, which aligns with your interest in Information Retrieval and Search technologies. The use of reinforcement learning and decomposed reasoning framework is also relevant to your interest in ranking models and query understanding. However, the paper's focus on user-generated content platforms and unstructured language may not be directly applicable to your e-commerce domain background."
    },
    {
        "title": "Simple Methods Defend RAG Systems Well Against Real-World Attacks",
        "abstract": "Ensuring safety and in-domain responses for Retrieval-Augmented Generation\n(RAG) systems is paramount in safety-critical applications, yet remains a\nsignificant challenge. To address this, we evaluate four methodologies for\nOut-Of-Domain (OOD) query detection: GPT-4o, regression-based, Principal\nComponent Analysis (PCA)-based, and Neural Collapse (NC), to ensure the RAG\nsystem only responds to queries confined to the system's knowledge base.\nSpecifically, our evaluation explores two novel dimensionality reduction and\nfeature separation strategies: \\textit{PCA}, where top components are selected\nusing explained variance or OOD separability, and an adaptation of\n\\textit{Neural Collapse Feature Separation}. We validate our approach on\nstandard datasets (StackExchange and MSMARCO) and real-world applications\n(Substance Use and COVID-19), including tests against LLM-simulated and actual\nattacks on a COVID-19 vaccine chatbot. Through human and LLM-based evaluations\nof response correctness and relevance, we confirm that an external OOD detector\nis crucial for maintaining response relevance.",
        "url": "http://arxiv.org/abs/2508.02296v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02296v1",
        "arxiv_id": "2508.02296v1",
        "authors": [
            "Ilias Triantafyllopoulos",
            "Renyi Qu",
            "Salvatore Giorgi",
            "Brenda Curtis",
            "Lyle H. Ungar",
            "Jo√£o Sedoc"
        ],
        "submitted": "2025-08-04 11:04:54",
        "source": "arxiv",
        "comment": null,
        "score": 13,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on Retrieval-Augmented Generation (RAG) systems and Out-Of-Domain (OOD) query detection, which is not directly related to my research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. Although the paper mentions relevance and response correctness, it does not address the specific topics I am interested in, such as query understanding, ranking models, and real-time relevance optimization."
    },
    {
        "title": "Quantum-RAG and PunGPT2: Advancing Low-Resource Language Generation and Retrieval for the Punjabi Language",
        "abstract": "Despite the rapid advancement of large language models (LLMs), low-resource\nlanguages remain largely excluded from the NLP landscape. We present PunGPT2,\nthe first fully open-source suite of Punjabi large language models, trained\nfrom scratch on a 35GB domain-diverse corpus encompassing literature, religious\ntexts, news, and social discourse. Unlike prior multilingual approaches,\nPunGPT2 captures rich syntactic and morphological features unique to Punjabi\nthrough a tokenizer optimised with byte pair encoding and linguistically\naligned pretraining objectives. To improve factual grounding and domain recall,\nwe introduce Pun-RAG, a retrieval-augmented generation framework combining\nPunGPT2 with a dense FAISS retriever over a curated Punjabi knowledge base. We\nfurther develop Pun-Instruct, a parameter-efficient, instruction-tuned variant\nusing QLoRA, enabling robust zero-shot and instruction-following performance\nwith significantly reduced compute needs.\n  As a key innovation, we propose Quantum-RAG, a novel hybrid retrieval system\nthat fuses sparse (BM25) and dense methods with quantum-inspired semantic\nmatching. By encoding queries using amplitude-based embeddings and retrieving\nvia quantum kernel similarity, Quantum-RAG achieves improved contextual\nrelevance with minimal memory overhead marking the first practical integration\nof quantum representations in low-resource language generation. Our models\nsignificantly outperform strong multilingual baselines (mBERT, mT5, MuRIL) in\nperplexity, factuality, and fluency. This work provides a scalable,\nreproducible blueprint for extending LLM capabilities to underrepresented\nlanguages and pioneers quantum-aware retrieval in low-resource NLP",
        "url": "http://arxiv.org/abs/2508.01918v1",
        "pdf_url": "http://arxiv.org/pdf/2508.01918v1",
        "arxiv_id": "2508.01918v1",
        "authors": [
            "Jaskaranjeet Singh",
            "Rakesh Thakur"
        ],
        "submitted": "2025-08-03 21:03:22",
        "source": "arxiv",
        "comment": null,
        "score": 13,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. Although it mentions retrieval-augmented generation and quantum-inspired semantic matching, the focus is on low-resource language generation and retrieval for the Punjabi language, which is not a primary area of interest for the user."
    },
    {
        "title": "Learning Partially-Decorrelated Common Spaces for Ad-hoc Video Search",
        "abstract": "Ad-hoc Video Search (AVS) involves using a textual query to search for\nmultiple relevant videos in a large collection of unlabeled short videos. The\nmain challenge of AVS is the visual diversity of relevant videos. A simple\nquery such as \"Find shots of a man and a woman dancing together indoors\" can\nspan a multitude of environments, from brightly lit halls and shadowy bars to\ndance scenes in black-and-white animations. It is therefore essential to\nretrieve relevant videos as comprehensively as possible. Current solutions for\nthe AVS task primarily fuse multiple features into one or more common spaces,\nyet overlook the need for diverse spaces. To fully exploit the expressive\ncapability of individual features, we propose LPD, short for Learning Partially\nDecorrelated common spaces. LPD incorporates two key innovations:\nfeature-specific common space construction and the de-correlation loss.\nSpecifically, LPD learns a separate common space for each video and text\nfeature, and employs de-correlation loss to diversify the ordering of negative\nsamples across different spaces. To enhance the consistency of multi-space\nconvergence, we designed an entropy-based fair multi-space triplet ranking\nloss. Extensive experiments on the TRECVID AVS benchmarks (2016-2023) justify\nthe effectiveness of LPD. Moreover, diversity visualizations of LPD's spaces\nhighlight its ability to enhance result diversity.",
        "url": "http://arxiv.org/abs/2508.02340v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02340v1",
        "arxiv_id": "2508.02340v1",
        "authors": [
            "Fan Hu",
            "Zijie Xin",
            "Xirong Li"
        ],
        "submitted": "2025-08-04 12:21:16",
        "source": "arxiv",
        "comment": "Accepted by ACMMM2025",
        "score": 10,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)",
            "Found 'trec' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Ad-hoc Video Search, which is not directly related to the user's primary interest in Information Retrieval and Search technologies. While it touches on query understanding and ranking models, the context is different and the techniques proposed are specific to video search. The user's background in e-commerce and interest in NLP and data mining are not explicitly addressed in this paper."
    },
    {
        "title": "AGENTICT$^2$S:Robust Text-to-SPARQL via Agentic Collaborative Reasoning over Heterogeneous Knowledge Graphs for the Circular Economy",
        "abstract": "Question answering over heterogeneous knowledge graphs (KGQA) involves\nreasoning across diverse schemas, incomplete alignments, and distributed data\nsources. Existing text-to-SPARQL approaches rely on large-scale domain-specific\nfine-tuning or operate within single-graph settings, limiting their\ngeneralizability in low-resource domains and their ability to handle queries\nspanning multiple graphs. These challenges are particularly relevant in domains\nsuch as the circular economy, where information about classifications,\nprocesses, and emissions is distributed across independently curated knowledge\ngraphs (KGs). We present AgenticT$^2$S, a modular framework that decomposes\nKGQA into subtasks managed by specialized agents responsible for retrieval,\nquery generation, and verification. A scheduler assigns subgoals to different\ngraphs using weak-to-strong alignment strategies. A two-stage verifier detects\nstructurally invalid and semantically underspecified queries through symbolic\nvalidation and counterfactual consistency checks. Experiments on real-world\ncircular economy KGs demonstrate that AgenticT$^2$S improves execution accuracy\nby 17.3% and triple level F$_1$ by 25.4% over the best baseline, while reducing\nthe average prompt length by 46.4%. These results demonstrate the benefits of\nagent-based schema-aware reasoning for scalable KGQA and support\ndecision-making in sustainability domains through robust cross-graph reasoning.",
        "url": "http://arxiv.org/abs/2508.01815v1",
        "pdf_url": "http://arxiv.org/pdf/2508.01815v1",
        "arxiv_id": "2508.01815v1",
        "authors": [
            "Yang Zhao",
            "Chengxiao Dai",
            "Wei Zhuo",
            "Tan Chuan Fu",
            "Yue Xiu",
            "Dusit Niyato",
            "Jonathan Z. Low",
            "Eugene Ho Hong Zhuang",
            "Daren Zong Loong Tan"
        ],
        "submitted": "2025-08-03 15:58:54",
        "source": "arxiv",
        "comment": null,
        "score": 10,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a framework for question answering over heterogeneous knowledge graphs, which is a topic in Natural Language Processing (NLP) and data mining. However, the focus on knowledge graphs and SPARQL queries is not directly related to my primary interest in Information Retrieval (IR) and search technologies, particularly query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Contextually Aware E-Commerce Product Question Answering using RAG",
        "abstract": "E-commerce product pages contain a mix of structured specifications,\nunstructured reviews, and contextual elements like personalized offers or\nregional variants. Although informative, this volume can lead to cognitive\noverload, making it difficult for users to quickly and accurately find the\ninformation they need. Existing Product Question Answering (PQA) systems often\nfail to utilize rich user context and diverse product information effectively.\nWe propose a scalable, end-to-end framework for e-commerce PQA using Retrieval\nAugmented Generation (RAG) that deeply integrates contextual understanding. Our\nsystem leverages conversational history, user profiles, and product attributes\nto deliver relevant and personalized answers. It adeptly handles objective,\nsubjective, and multi-intent queries across heterogeneous sources, while also\nidentifying information gaps in the catalog to support ongoing content\nimprovement. We also introduce novel metrics to measure the framework's\nperformance which are broadly applicable for RAG system evaluations.",
        "url": "http://arxiv.org/abs/2508.01990v1",
        "pdf_url": "http://arxiv.org/pdf/2508.01990v1",
        "arxiv_id": "2508.01990v1",
        "authors": [
            "Praveen Tangarajan",
            "Anand A. Rajasekar",
            "Manish Rathi",
            "Vinay Rao Dandin",
            "Ozan Ersoy"
        ],
        "submitted": "2025-08-04 02:14:07",
        "source": "arxiv",
        "comment": "6 pages, 1 figure, 5 tables. Preprint under review",
        "score": 9,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "The paper is highly relevant to your interests in Information Retrieval, particularly in the context of e-commerce product question answering. The use of Retrieval Augmented Generation (RAG) and contextual understanding aligns with your focus on query understanding and ranking models. While the paper's primary focus is on e-commerce, its exploration of user behavior modeling and real-time relevance optimization resonates with your broader interests in IR and NLP."
    },
    {
        "title": "Hubness Reduction with Dual Bank Sinkhorn Normalization for Cross-Modal Retrieval",
        "abstract": "The past decade has witnessed rapid advancements in cross-modal retrieval,\nwith significant progress made in accurately measuring the similarity between\ncross-modal pairs. However, the persistent hubness problem, a phenomenon where\na small number of targets frequently appear as nearest neighbors to numerous\nqueries, continues to hinder the precision of similarity measurements. Despite\nseveral proposed methods to reduce hubness, their underlying mechanisms remain\npoorly understood. To bridge this gap, we analyze the widely-adopted Inverted\nSoftmax approach and demonstrate its effectiveness in balancing target\nprobabilities during retrieval. Building on these insights, we propose a\nprobability-balancing framework for more effective hubness reduction. We\ncontend that balancing target probabilities alone is inadequate and, therefore,\nextend the framework to balance both query and target probabilities by\nintroducing Sinkhorn Normalization (SN). Notably, we extend SN to scenarios\nwhere the true query distribution is unknown, showing that current methods,\nwhich rely solely on a query bank to estimate target hubness, produce\nsuboptimal results due to a significant distributional gap between the query\nbank and targets. To mitigate this issue, we introduce Dual Bank Sinkhorn\nNormalization (DBSN), incorporating a corresponding target bank alongside the\nquery bank to narrow this distributional gap. Our comprehensive evaluation\nacross various cross-modal retrieval tasks, including image-text retrieval,\nvideo-text retrieval, and audio-text retrieval, demonstrates consistent\nperformance improvements, validating the effectiveness of both SN and DBSN. All\ncodes are publicly available at https://github.com/ppanzx/DBSN.",
        "url": "http://arxiv.org/abs/2508.02538v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02538v1",
        "arxiv_id": "2508.02538v1",
        "authors": [
            "Zhengxin Pan",
            "Haishuai Wang",
            "Fangyu Wu",
            "Peng Zhang",
            "Jiajun Bu"
        ],
        "submitted": "2025-08-04 15:45:48",
        "source": "arxiv",
        "comment": "ACMMM 2025",
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on cross-modal retrieval, which is not directly related to the user's primary research interests in Information Retrieval and Search technologies. While the paper mentions hubness reduction and normalization techniques, these concepts are not specifically related to query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user."
    },
    {
        "title": "Agentic Personalized Fashion Recommendation in the Age of Generative AI: Challenges, Opportunities, and Evaluation",
        "abstract": "Fashion recommender systems (FaRS) face distinct challenges due to rapid\ntrend shifts, nuanced user preferences, intricate item-item compatibility, and\nthe complex interplay among consumers, brands, and influencers. Traditional\nrecommendation approaches, largely static and retrieval-focused, struggle to\neffectively capture these dynamic elements, leading to decreased user\nsatisfaction and elevated return rates. This paper synthesizes both academic\nand industrial viewpoints to map the distinctive output space and stakeholder\necosystem of modern FaRS, identifying the complex interplay among users,\nbrands, platforms, and influencers, and highlighting the unique data and\nmodeling challenges that arise.\n  We outline a research agenda for industrial FaRS, centered on five\nrepresentative scenarios spanning static queries, outfit composition, and\nmulti-turn dialogue, and argue that mixed-modality refinement-the ability to\ncombine image-based references (anchors) with nuanced textual constraints-is a\nparticularly critical task for real-world deployment. To this end, we propose\nan Agentic Mixed-Modality Refinement (AMMR) pipeline, which fuses multimodal\nencoders with agentic LLM planners and dynamic retrieval, bridging the gap\nbetween expressive user intent and fast-changing fashion inventories. Our work\nshows that moving beyond static retrieval toward adaptive, generative, and\nstakeholder-aware systems is essential to satisfy the evolving expectations of\nfashion consumers and brands.",
        "url": "http://arxiv.org/abs/2508.02342v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02342v1",
        "arxiv_id": "2508.02342v1",
        "authors": [
            "Yashar Deldjoo",
            "Nima Rafiee",
            "Mahdyar Ravanbakhsh"
        ],
        "submitted": "2025-08-04 12:22:25",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on fashion recommender systems, which is outside the user's primary research interest in Information Retrieval and Search technologies. While it mentions some relevant concepts like query understanding and ranking models, the application domain is not directly related to the user's expertise. The paper's emphasis on mixed-modality refinement and agentic LLM planners is also not a central match for the user's interests."
    },
    {
        "title": "SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension",
        "abstract": "Retrieval-augmented generation (RAG) over long documents typically involves\nsplitting the text into smaller chunks, which serve as the basic units for\nretrieval. However, due to dependencies across the original document,\ncontextual information is often essential for accurately interpreting each\nchunk. To address this, prior work has explored encoding longer context windows\nto produce embeddings for longer chunks. Despite these efforts, gains in\nretrieval and downstream tasks remain limited. This is because (1) longer\nchunks strain the capacity of embedding models due to the increased amount of\ninformation they must encode, and (2) many real-world applications still\nrequire returning localized evidence due to constraints on model or human\nbandwidth.\n  We propose an alternative approach to this challenge by representing short\nchunks in a way that is conditioned on a broader context window to enhance\nretrieval performance -- i.e., situating a chunk's meaning within its context.\nWe further show that existing embedding models are not well-equipped to encode\nsuch situated context effectively, and thus introduce a new training paradigm\nand develop the situated embedding models (SitEmb). To evaluate our method, we\ncurate a book-plot retrieval dataset specifically designed to assess situated\nretrieval capabilities. On this benchmark, our SitEmb-v1 model based on BGE-M3\nsubstantially outperforms state-of-the-art embedding models, including several\nwith up to 7-8B parameters, with only 1B parameters. Our 8B SitEmb-v1.5 model\nfurther improves performance by over 10% and shows strong results across\ndifferent languages and several downstream applications.",
        "url": "http://arxiv.org/abs/2508.01959v1",
        "pdf_url": "http://arxiv.org/pdf/2508.01959v1",
        "arxiv_id": "2508.01959v1",
        "authors": [
            "Junjie Wu",
            "Jiangnan Li",
            "Yuqing Li",
            "Lemao Liu",
            "Liyan Xu",
            "Jiwei Li",
            "Dit-Yan Yeung",
            "Jie Zhou",
            "Mo Yu"
        ],
        "submitted": "2025-08-03 23:59:31",
        "source": "arxiv",
        "comment": "Our trained models can be downloaded from:\n  https://huggingface.co/SituatedEmbedding",
        "score": 7,
        "keyword_reasons": [
            "Found 'dense retrieval' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper proposes a new approach to contextualized dense retrieval, which is relevant to information retrieval and search technologies. However, the focus on long story comprehension and book-plot retrieval is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's emphasis on situated embeddings and contextualized retrieval is somewhat related to the user's interests in deep semantic understanding and real-time relevance optimization, but it does not seem to be a central match."
    },
    {
        "title": "Dynamic Forgetting and Spatio-Temporal Periodic Interest Modeling for Local-Life Service Recommendation",
        "abstract": "In the context of the booming digital economy, recommendation systems, as a\nkey link connecting users and numerous services, face challenges in modeling\nuser behavior sequences on local-life service platforms, including the sparsity\nof long sequences and strong spatio-temporal dependence. Such challenges can be\naddressed by drawing an analogy to the forgetting process in human memory. This\nis because users' responses to recommended content follow the recency effect\nand the cyclicality of memory. By exploring this, this paper introduces the\nforgetting curve and proposes Spatio-Temporal periodic Interest Modeling (STIM)\nwith long sequences for local-life service recommendation. STIM integrates\nthree key components: a dynamic masking module based on the forgetting curve,\nwhich is used to extract both recent spatiotemporal features and periodic\nspatiotemporal features; a query-based mixture of experts (MoE) approach that\ncan adaptively activate expert networks under different dynamic masks, enabling\nthe collaborative modeling of time, location, and items; and a hierarchical\nmulti-interest network unit, which captures multi-interest representations by\nmodeling the hierarchical interactions between the shallow and deep semantics\nof users' recent behaviors. By introducing the STIM method, we conducted online\nA/B tests and achieved a 1.54\\% improvement in gross transaction volume (GTV).\nIn addition, extended offline experiments also showed improvements. STIM has\nbeen deployed in a large-scale local-life service recommendation system,\nserving hundreds of millions of daily active users in core application\nscenarios.",
        "url": "http://arxiv.org/abs/2508.02451v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02451v1",
        "arxiv_id": "2508.02451v1",
        "authors": [
            "Zhaoyu Hu",
            "Hao Guo",
            "Yuan Tian",
            "Erpeng Xue",
            "Jianyang Wang",
            "Xianyang Qi",
            "Hongxiang Lin",
            "Lei Wang",
            "Sheng Chen"
        ],
        "submitted": "2025-08-04 14:16:49",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'user behavior' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on recommender systems, specifically local-life service recommendation, which is not directly related to the user's primary research interests in Information Retrieval and Search technologies. Although it mentions query-based mixture of experts, the approach is not specifically related to query understanding, ranking models, or user behavior modeling in the context of IR."
    },
    {
        "title": "Why Generate When You Can Transform? Unleashing Generative Attention for Dynamic Recommendation",
        "abstract": "Sequential Recommendation (SR) focuses on personalizing user experiences by\npredicting future preferences based on historical interactions. Transformer\nmodels, with their attention mechanisms, have become the dominant architecture\nin SR tasks due to their ability to capture dependencies in user behavior\nsequences. However, traditional attention mechanisms, where attention weights\nare computed through query-key transformations, are inherently linear and\ndeterministic. This fixed approach limits their ability to account for the\ndynamic and non-linear nature of user preferences, leading to challenges in\ncapturing evolving interests and subtle behavioral patterns. Given that\ngenerative models excel at capturing non-linearity and probabilistic\nvariability, we argue that generating attention distributions offers a more\nflexible and expressive alternative compared to traditional attention\nmechanisms. To support this claim, we present a theoretical proof demonstrating\nthat generative attention mechanisms offer greater expressiveness and\nstochasticity than traditional deterministic approaches. Building upon this\ntheoretical foundation, we introduce two generative attention models for SR,\neach grounded in the principles of Variational Autoencoders (VAE) and Diffusion\nModels (DMs), respectively. These models are designed specifically to generate\nadaptive attention distributions that better align with variable user\npreferences. Extensive experiments on real-world datasets show our models\nsignificantly outperform state-of-the-art in both accuracy and diversity.",
        "url": "http://arxiv.org/abs/2508.02050v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02050v1",
        "arxiv_id": "2508.02050v1",
        "authors": [
            "Yuli Liu",
            "Wenjun Kong",
            "Cheng Luo",
            "Weizhi Ma"
        ],
        "submitted": "2025-08-04 04:33:26",
        "source": "arxiv",
        "comment": "Accepted at ACMMM 2025",
        "score": 6,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'user behavior' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores a novel approach to attention mechanisms in sequential recommendation, leveraging generative models to capture non-linear user behavior. While it touches on attention and ranking, the focus is on recommendation rather than information retrieval, and the connection to query understanding and ranking models is not explicitly made. The paper's relevance to the user's interests is somewhat limited, but the innovative application of generative models to attention mechanisms is an interesting area of research."
    },
    {
        "title": "Evaluating Position Bias in Large Language Model Recommendations",
        "abstract": "Large Language Models (LLMs) are being increasingly explored as\ngeneral-purpose tools for recommendation tasks, enabling zero-shot and\ninstruction-following capabilities without the need for task-specific training.\nWhile the research community is enthusiastically embracing LLMs, there are\nimportant caveats to directly adapting them for recommendation tasks. In this\npaper, we show that LLM-based recommendation models suffer from position bias,\nwhere the order of candidate items in a prompt can disproportionately influence\nthe recommendations produced by LLMs. First, we analyse the position bias of\nLLM-based recommendations on real-world datasets, where results uncover\nsystemic biases of LLMs with high sensitivity to input orders. Furthermore, we\nintroduce a new prompting strategy to mitigate the position bias of LLM\nrecommendation models called Ranking via Iterative SElection (RISE). We compare\nour proposed method against various baselines on key benchmark datasets.\nExperiment results show that our method reduces sensitivity to input ordering\nand improves stability without requiring model fine-tuning or post-processing.",
        "url": "http://arxiv.org/abs/2508.02020v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02020v1",
        "arxiv_id": "2508.02020v1",
        "authors": [
            "Ethan Bito",
            "Yongli Ren",
            "Estrid He"
        ],
        "submitted": "2025-08-04 03:30:26",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 5,
        "llm_reason": "The paper explores the position bias in Large Language Model recommendations, which is somewhat related to my interests in Information Retrieval and Search technologies. However, the focus on recommender systems and language models is not directly aligned with my primary focus on query understanding, ranking models, and user behavior modeling in the context of e-commerce and information retrieval."
    },
    {
        "title": "Sparse-dLLM: Accelerating Diffusion LLMs with Dynamic Cache Eviction",
        "abstract": "Diffusion Large Language Models (dLLMs) enable breakthroughs in reasoning and\nparallel decoding but suffer from prohibitive quadratic computational\ncomplexity and memory overhead during inference. Current caching techniques\naccelerate decoding by storing full-layer states, yet impose substantial memory\nusage that limit long-context applications. Our analysis of attention patterns\nin dLLMs reveals persistent cross-layer sparsity, with pivotal tokens remaining\nsalient across decoding steps and low-relevance tokens staying unimportant,\nmotivating selective cache eviction. We propose Sparse-dLLM, the first\ntraining-free framework integrating dynamic cache eviction with sparse\nattention via delayed bidirectional sparse caching. By leveraging the stability\nof token saliency over steps, it retains critical tokens and dynamically evicts\nunimportant prefix/suffix entries using an attention-guided strategy. Extensive\nexperiments on LLaDA and Dream series demonstrate Sparse-dLLM achieves up to\n10$\\times$ higher throughput than vanilla dLLMs, with comparable performance\nand similar peak memory costs, outperforming previous methods in efficiency and\neffectiveness.",
        "url": "http://arxiv.org/abs/2508.02558v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02558v1",
        "arxiv_id": "2508.02558v1",
        "authors": [
            "Yuerong Song",
            "Xiaoran Liu",
            "Ruixiao Li",
            "Zhigeng Liu",
            "Zengfeng Huang",
            "Qipeng Guo",
            "Ziwei He",
            "Xipeng Qiu"
        ],
        "submitted": "2025-08-04 16:14:03",
        "source": "arxiv",
        "comment": "11 pages, 6 figures",
        "score": 5,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on accelerating Diffusion Large Language Models (dLLMs) with dynamic cache eviction, which is not directly related to Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling. Although it mentions attention patterns, it does not explore query understanding or ranking models, and the context is language models rather than search or retrieval."
    },
    {
        "title": "TreeRanker: Fast and Model-agnostic Ranking System for Code Suggestions in IDEs",
        "abstract": "Token-level code completion is one of the most critical features in modern\nIntegrated Development Environments (IDEs). It assists developers by suggesting\nrelevant identifiers and APIs during coding. While completions are typically\nderived from static analysis, their usefulness depends heavily on how they are\nranked, as correct predictions buried deep in the list are rarely seen by\nusers. Most current systems rely on hand-crafted heuristics or lightweight\nmachine learning models trained on user logs, which can be further improved to\ncapture context information and generalize across projects and coding styles.\nIn this work, we propose a new scoring approach to ranking static completions\nusing language models in a lightweight and model-agnostic way. Our method\norganizes all valid completions into a prefix tree and performs a single greedy\ndecoding pass to collect token-level scores across the tree. This enables a\nprecise token-aware ranking without needing beam search, prompt engineering, or\nmodel adaptations. The approach is fast, architecture-agnostic, and compatible\nwith already deployed models for code completion. These findings highlight a\npractical and effective pathway for integrating language models into already\nexisting tools within IDEs, and ultimately providing smarter and more\nresponsive developer assistance.",
        "url": "http://arxiv.org/abs/2508.02455v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02455v1",
        "arxiv_id": "2508.02455v1",
        "authors": [
            "Daniele Cipollone",
            "Egor Bogomolov",
            "Arie van Deursen",
            "Maliheh Izadi"
        ],
        "submitted": "2025-08-04 14:20:39",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on code completion and ranking in IDEs, which is a specific application of information retrieval. While it uses language models, the primary goal is not query understanding or ranking models, but rather a practical solution for code completion. The paper's relevance to the user's research interests is somewhat limited, but it does touch on some related topics."
    },
    {
        "title": "Beyond Chunks and Graphs: Retrieval-Augmented Generation through Triplet-Driven Thinking",
        "abstract": "Retrieval-augmented generation (RAG) is critical for reducing hallucinations\nand incorporating external knowledge into Large Language Models (LLMs).\nHowever, advanced RAG systems face a trade-off between performance and\nefficiency. Multi-round RAG approaches achieve strong reasoning but incur\nexcessive LLM calls and token costs, while Graph RAG methods suffer from\ncomputationally expensive, error-prone graph construction and retrieval\nredundancy. To address these challenges, we propose T$^2$RAG, a novel framework\nthat operates on a simple, graph-free knowledge base of atomic triplets.\nT$^2$RAG leverages an LLM to decompose questions into searchable triplets with\nplaceholders, which it then iteratively resolves by retrieving evidence from\nthe triplet database. Empirical results show that T$^2$RAG significantly\noutperforms state-of-the-art multi-round and Graph RAG methods, achieving an\naverage performance gain of up to 11\\% across six datasets while reducing\nretrieval costs by up to 45\\%. Our code is available at\nhttps://github.com/rockcor/T2RAG",
        "url": "http://arxiv.org/abs/2508.02435v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02435v1",
        "arxiv_id": "2508.02435v1",
        "authors": [
            "Shengbo Gong",
            "Xianfeng Tang",
            "Carl Yang",
            "Wei jin"
        ],
        "submitted": "2025-08-04 13:50:44",
        "source": "arxiv",
        "comment": "19 pages",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a novel framework for retrieval-augmented generation, addressing challenges in efficiency and performance. While it's related to information retrieval and NLP, the focus is on a specific application and doesn't directly align with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "CompressKV: Semantic Retrieval Heads Know What Tokens are Not Important Before Generation",
        "abstract": "Recent advances in large language models (LLMs) have significantly boosted\nlong-context processing. However, the increasing key-value (KV) cache size\nposes critical challenges to memory and execution efficiency. Most KV cache\ncompression methods rely on heuristic token eviction using all attention heads\nin Grouped Query Attention (GQA)-based LLMs. This method ignores the different\nfunctionalities of attention heads, leading to the eviction of critical tokens\nand thus degrades the performance of LLMs.\n  To address the issue above, instead of using all the attention heads in\nGQA-based LLMs to determine important tokens as in the previous work, we first\nidentify the attention heads in each layer that are not only capable of\nretrieving the initial and final tokens of a prompt, but also capable of\nretrieving important tokens within the text and attending to their surrounding\nsemantic context. Afterwards, we exploit such heads to determine the important\ntokens and retain their corresponding KV cache pairs. Furthermore, we analyze\nthe cache eviction error of each layer individually and introduce a\nlayer-adaptive KV cache allocation strategy. Experimental results demonstrate\nthe proposed CompressKV consistently outperforms state-of-the-art approaches\nunder various memory budgets on LongBench and Needle-in-a-Haystack benchmarks.\nOur code is publicly available at: https://github.com/TUDa-HWAI/CompressKV.git.",
        "url": "http://arxiv.org/abs/2508.02401v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02401v1",
        "arxiv_id": "2508.02401v1",
        "authors": [
            "Xiaolin Lin",
            "Jingcun Wang",
            "Olga Kondrateva",
            "Yiyu Shi",
            "Bing Li",
            "Grace Li Zhang"
        ],
        "submitted": "2025-08-04 13:26:16",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on compressing key-value caches in large language models, which is a specific problem in NLP. While it mentions attention heads and retrieval, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval. The paper's relevance is somewhat tangential, but it may still be of interest to researchers exploring NLP and related topics."
    },
    {
        "title": "Graph Embedding in the Graph Fractional Fourier Transform Domain",
        "abstract": "Spectral graph embedding plays a critical role in graph representation\nlearning by generating low-dimensional vector representations from graph\nspectral information. However, the embedding space of traditional spectral\nembedding methods often exhibit limited expressiveness, failing to exhaustively\ncapture latent structural features across alternative transform domains. To\naddress this issue, we use the graph fractional Fourier transform to extend the\nexisting state-of-the-art generalized frequency filtering embedding (GEFFE)\ninto fractional domains, giving birth to the generalized fractional filtering\nembedding (GEFRFE), which enhances embedding informativeness via the graph\nfractional domain. The GEFRFE leverages graph fractional domain filtering and a\nnonlinear composition of eigenvector components derived from a fractionalized\ngraph Laplacian. To dynamically determine the fractional order, two parallel\nstrategies are introduced: search-based optimization and a ResNet18-based\nadaptive learning. Extensive experiments on six benchmark datasets demonstrate\nthat the GEFRFE captures richer structural features and significantly enhance\nclassification performance. Notably, the proposed method retains computational\ncomplexity comparable to GEFFE approaches.",
        "url": "http://arxiv.org/abs/2508.02383v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02383v1",
        "arxiv_id": "2508.02383v1",
        "authors": [
            "Changjie Sheng",
            "Zhichao Zhang",
            "Wei Yao"
        ],
        "submitted": "2025-08-04 13:09:47",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on graph embedding and spectral graph representation learning, which is not directly related to the user's interests in Information Retrieval, Search technologies, and Natural Language Processing. While it mentions filtering and embedding, the context is graph-based and does not involve query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "CellForge: Agentic Design of Virtual Cell Models",
        "abstract": "Virtual cell modeling represents an emerging frontier at the intersection of\nartificial intelligence and biology, aiming to predict quantities such as\nresponses to diverse perturbations quantitatively. However, autonomously\nbuilding computational models for virtual cells is challenging due to the\ncomplexity of biological systems, the heterogeneity of data modalities, and the\nneed for domain-specific expertise across multiple disciplines. Here, we\nintroduce CellForge, an agentic system that leverages a multi-agent framework\nthat transforms presented biological datasets and research objectives directly\ninto optimized computational models for virtual cells. More specifically, given\nonly raw single-cell multi-omics data and task descriptions as input, CellForge\noutputs both an optimized model architecture and executable code for training\nvirtual cell models and inference. The framework integrates three core modules:\nTask Analysis for presented dataset characterization and relevant literature\nretrieval, Method Design, where specialized agents collaboratively develop\noptimized modeling strategies, and Experiment Execution for automated\ngeneration of code. The agents in the Design module are separated into experts\nwith differing perspectives and a central moderator, and have to\ncollaboratively exchange solutions until they achieve a reasonable consensus.\nWe demonstrate CellForge's capabilities in single-cell perturbation prediction,\nusing six diverse datasets that encompass gene knockouts, drug treatments, and\ncytokine stimulations across multiple modalities. CellForge consistently\noutperforms task-specific state-of-the-art methods. Overall, CellForge\ndemonstrates how iterative interaction between LLM agents with differing\nperspectives provides better solutions than directly addressing a modeling\nchallenge. Our code is publicly available at\nhttps://github.com/gersteinlab/CellForge.",
        "url": "http://arxiv.org/abs/2508.02276v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02276v1",
        "arxiv_id": "2508.02276v1",
        "authors": [
            "Xiangru Tang",
            "Zhuoyun Yu",
            "Jiapeng Chen",
            "Yan Cui",
            "Daniel Shao",
            "Weixu Wang",
            "Fang Wu",
            "Yuchen Zhuang",
            "Wenqi Shi",
            "Zhi Huang",
            "Arman Cohan",
            "Xihong Lin",
            "Fabian Theis",
            "Smita Krishnaswamy",
            "Mark Gerstein"
        ],
        "submitted": "2025-08-04 10:43:31",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on virtual cell modeling, artificial intelligence, and biology, which are not directly related to your areas of interest."
    },
    {
        "title": "From Generation to Consumption: Personalized List Value Estimation for Re-ranking",
        "abstract": "Re-ranking is critical in recommender systems for optimizing the order of\nrecommendation lists, thus improving user satisfaction and platform revenue.\nMost existing methods follow a generator-evaluator paradigm, where the\nevaluator estimates the overall value of each candidate list. However, they\noften ignore the fact that users may exit before consuming the full list,\nleading to a mismatch between estimated generation value and actual consumption\nvalue. To bridge this gap, we propose CAVE, a personalized Consumption-Aware\nlist Value Estimation framework. CAVE formulates the list value as the\nexpectation over sub-list values, weighted by user-specific exit probabilities\nat each position. The exit probability is decomposed into an interest-driven\ncomponent and a stochastic component, the latter modeled via a Weibull\ndistribution to capture random external factors such as fatigue. By jointly\nmodeling sub-list values and user exit behavior, CAVE yields a more faithful\nestimate of actual list consumption value. We further contribute three\nlarge-scale real-world list-wise benchmarks from the Kuaishou platform, varying\nin size and user activity patterns. Extensive experiments on these benchmarks,\ntwo Amazon datasets, and online A/B testing on Kuaishou show that CAVE\nconsistently outperforms strong baselines, highlighting the benefit of\nexplicitly modeling user exits in re-ranking.",
        "url": "http://arxiv.org/abs/2508.02242v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02242v1",
        "arxiv_id": "2508.02242v1",
        "authors": [
            "Kaike Zhang",
            "Xiaobei Wang",
            "Xiaoyu Liu",
            "Shuchang Liu",
            "Hailan Yang",
            "Xiang Li",
            "Fei Sun",
            "Qi Cao"
        ],
        "submitted": "2025-08-04 09:43:21",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on recommender systems, specifically re-ranking, which is somewhat related to information retrieval. However, the emphasis on user behavior modeling and exit probabilities is more relevant to user behavior modeling and click models, which are part of my research interests. The paper's scope is narrower than my interests, but it does touch on some relevant topics."
    },
    {
        "title": "Hidden in the Noise: Unveiling Backdoors in Audio LLMs Alignment through Latent Acoustic Pattern Triggers",
        "abstract": "As Audio Large Language Models (ALLMs) emerge as powerful tools for speech\nprocessing, their safety implications demand urgent attention. While\nconsiderable research has explored textual and vision safety, audio's distinct\ncharacteristics present significant challenges. This paper first investigates:\nIs ALLM vulnerable to backdoor attacks exploiting acoustic triggers? In\nresponse to this issue, we introduce Hidden in the Noise (HIN), a novel\nbackdoor attack framework designed to exploit subtle, audio-specific features.\nHIN applies acoustic modifications to raw audio waveforms, such as alterations\nto temporal dynamics and strategic injection of spectrally tailored noise.\nThese changes introduce consistent patterns that an ALLM's acoustic feature\nencoder captures, embedding robust triggers within the audio stream. To\nevaluate ALLM robustness against audio-feature-based triggers, we develop the\nAudioSafe benchmark, assessing nine distinct risk types. Extensive experiments\non AudioSafe and three established safety datasets reveal critical\nvulnerabilities in existing ALLMs: (I) audio features like environment noise\nand speech rate variations achieve over 90% average attack success rate. (II)\nALLMs exhibit significant sensitivity differences across acoustic features,\nparticularly showing minimal response to volume as a trigger, and (III)\npoisoned sample inclusion causes only marginal loss curve fluctuations,\nhighlighting the attack's stealth.",
        "url": "http://arxiv.org/abs/2508.02175v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02175v1",
        "arxiv_id": "2508.02175v1",
        "authors": [
            "Liang Lin",
            "Miao Yu",
            "Kaiwen Luo",
            "Yibo Zhang",
            "Lilan Peng",
            "Dexian Wang",
            "Xuehai Tang",
            "Yuanhe Zhang",
            "Xikang Yang",
            "Zhenhong Zhou",
            "Kun Wang",
            "Yang Liu"
        ],
        "submitted": "2025-08-04 08:15:16",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or Natural Language Processing. The focus is on audio-based attacks on Large Language Models, which is a topic outside of the user's primary research interests."
    },
    {
        "title": "CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search",
        "abstract": "Approximate nearest-neighbor search (ANNS) algorithms have become\nincreasingly critical for recent AI applications, particularly in\nretrieval-augmented generation (RAG) and agent-based LLM applications. In this\npaper, we present CRINN, a new paradigm for ANNS algorithms. CRINN treats ANNS\noptimization as a reinforcement learning problem where execution speed serves\nas the reward signal. This approach enables the automatic generation of\nprogressively faster ANNS implementations while maintaining accuracy\nconstraints. Our experimental evaluation demonstrates CRINN's effectiveness\nacross six widely-used NNS benchmark datasets. When compared against\nstate-of-the-art open-source ANNS algorithms, CRINN achieves best performance\non three of them (GIST-960-Euclidean, MNIST-784-Euclidean, and\nGloVe-25-angular), and tied for first place on two of them (SIFT-128-Euclidean\nand GloVe-25-angular). The implications of CRINN's success reach well beyond\nANNS optimization: It validates that LLMs augmented with reinforcement learning\ncan function as an effective tool for automating sophisticated algorithmic\noptimizations that demand specialized knowledge and labor-intensive manual\nrefinement.Code can be found at https://github.com/deepreinforce-ai/CRINN",
        "url": "http://arxiv.org/abs/2508.02091v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02091v1",
        "arxiv_id": "2508.02091v1",
        "authors": [
            "Xiaoya Li",
            "Xiaofei Sun",
            "Albert Wang",
            "Chris Shum",
            "Jiwei Li"
        ],
        "submitted": "2025-08-04 05:57:46",
        "source": "arxiv",
        "comment": "Preprint Version",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on approximate nearest-neighbor search, which is not directly related to information retrieval, query understanding, or ranking models. While it mentions reinforcement learning, which is a related topic, the application is not in the context of search or retrieval, and the paper does not seem to address user behavior modeling or deep semantic understanding."
    },
    {
        "title": "Controllable and Stealthy Shilling Attacks via Dispersive Latent Diffusion",
        "abstract": "Recommender systems (RSs) are now fundamental to various online platforms,\nbut their dependence on user-contributed data leaves them vulnerable to\nshilling attacks that can manipulate item rankings by injecting fake users.\nAlthough widely studied, most existing attack models fail to meet two critical\nobjectives simultaneously: achieving strong adversarial promotion of target\nitems while maintaining realistic behavior to evade detection. As a result, the\ntrue severity of shilling threats that manage to reconcile the two objectives\nremains underappreciated. To expose this overlooked vulnerability, we present\nDLDA, a diffusion-based attack framework that can generate highly effective yet\nindistinguishable fake users by enabling fine-grained control over target\npromotion. Specifically, DLDA operates in a pre-aligned collaborative embedding\nspace, where it employs a conditional latent diffusion process to iteratively\nsynthesize fake user profiles with precise target item control. To evade\ndetection, DLDA introduces a dispersive regularization mechanism that promotes\nvariability and realism in generated behavioral patterns. Extensive experiments\non three real-world datasets and five popular RS models demonstrate that,\ncompared to prior attacks, DLDA consistently achieves stronger item promotion\nwhile remaining harder to detect. These results highlight that modern RSs are\nmore vulnerable than previously recognized, underscoring the urgent need for\nmore robust defenses.",
        "url": "http://arxiv.org/abs/2508.01987v1",
        "pdf_url": "http://arxiv.org/pdf/2508.01987v1",
        "arxiv_id": "2508.01987v1",
        "authors": [
            "Shutong Qiao",
            "Wei Yuan",
            "Junliang Yu",
            "Tong Chen",
            "Quoc Viet Hung Nguyen",
            "Hongzhi Yin"
        ],
        "submitted": "2025-08-04 01:54:32",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on shilling attacks in recommender systems, which is a topic related to information retrieval, but it does not address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's emphasis on generating fake users and promoting target items is not directly relevant to my research themes."
    },
    {
        "title": "MLP Memory: Language Modeling with Retriever-pretrained External Memory",
        "abstract": "While modern decoder-only LLMs achieve superior performance across various\ndomains, hallucinations have risen to be a common problem in their generated\ntext, hindering their application in knowledge-intensive tasks.\nRetriever-augmented generation (RAG) offers a solution, but the non-parametric\nnature of the retriever hinders its deep interaction with LLM. In this work, we\npropose to decouple memorization from the LLM decoder using a pretrained,\ndifferentiable external memory. The external memory is an MLP pretrained by\nimitating the behavior of a retriever on the entire pretraining dataset. Our\nresulting architecture, which comprises a transformer decoder and an external\nMLP memory pretrained on language modeling and retriever imitation\nrespectively, demonstrates strong perplexity and performance on downstream\ntasks. Experiments show our architecture exhibits steeper power-law scaling\nwith model size, achieving 17.5% and 24.1% improvement on WikiText-103 and Web\ndatasets compared to decoder-only models while benefiting from added training\nwithout overfitting. We demonstrate superior performance on three hallucination\nbenchmarks and nine memory-intensive tasks. Additionally, our approach delivers\n$80\\times$ speedup over $k$NN-LM (500M tokens) and $1.3\\times$ faster inference\nthan decoder-only models. Unlike $k$NN-LM, which impairs reasoning, our MLP\nmemory improves StrategyQA performance. We will open-source our code and models\nin the future.",
        "url": "http://arxiv.org/abs/2508.01832v1",
        "pdf_url": "http://arxiv.org/pdf/2508.01832v1",
        "arxiv_id": "2508.01832v1",
        "authors": [
            "Rubin Wei",
            "Jiaqi Cao",
            "Jiarui Wang",
            "Jushi Kai",
            "Qipeng Guo",
            "Bowen Zhou",
            "Zhouhan Lin"
        ],
        "submitted": "2025-08-03 16:40:53",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a novel architecture for language modeling, leveraging a retriever-pretrained external memory to improve performance on downstream tasks. While it touches on some aspects of query understanding and ranking models, the focus is primarily on language modeling and memory-intensive tasks, which is somewhat related to the user's interests in Information Retrieval and Search technologies."
    },
    {
        "title": "Contextual Graph Transformer: A Small Language Model for Enhanced Engineering Document Information Extraction",
        "abstract": "Standard transformer-based language models, while powerful for general text,\noften struggle with the fine-grained syntax and entity relationships in complex\ntechnical, engineering documents. To address this, we propose the Contextual\nGraph Transformer (CGT), a hybrid neural architecture that combines Graph\nNeural Networks (GNNs) and Transformers for domain-specific question answering.\nCGT constructs a dynamic graph over input tokens using sequential, skip-gram,\nand semantic similarity edges, which is processed by GATv2Conv layers for local\nstructure learning. These enriched embeddings are then passed to a Transformer\nencoder to capture global dependencies. Unlike generic large models, technical\ndomains often require specialized language models with stronger\ncontextualization and structure awareness. CGT offers a parameter-efficient\nsolution for such use cases. Integrated into a Retrieval-Augmented Generation\n(RAG) pipeline, CGT outperforms baselines like GPT-2 and BERT, achieving 24.7%\nhigher accuracy than GPT-2 with 62.4% fewer parameters. This gain stems from\nCGTs ability to jointly model structural token interactions and long-range\nsemantic coherence. The model is trained from scratch using a two-phase\napproach: pretraining on general text followed by fine-tuning on\ndomain-specific manuals. This highlights CGTs adaptability to technical\nlanguage, enabling better grounding, entity tracking, and retrieval-augmented\nresponses in real-world applications.",
        "url": "http://arxiv.org/abs/2508.02532v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02532v1",
        "arxiv_id": "2508.02532v1",
        "authors": [
            "Karan Reddy",
            "Mayukha Pal"
        ],
        "submitted": "2025-08-04 15:41:35",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a novel neural architecture, Contextual Graph Transformer (CGT), for domain-specific question answering in technical documents. While it's related to Natural Language Processing (NLP) and Information Retrieval (IR), the focus is on language models for engineering documents, which is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Six Guidelines for Trustworthy, Ethical and Responsible Automation Design",
        "abstract": "Calibrated trust in automated systems (Lee and See 2004) is critical for\ntheir safe and seamless integration into society. Users should only rely on a\nsystem recommendation when it is actually correct and reject it when it is\nfactually wrong. One requirement to achieve this goal is an accurate\ntrustworthiness assessment, ensuring that the user's perception of the system's\ntrustworthiness aligns with its actual trustworthiness, allowing users to make\ninformed decisions about the extent to which they can rely on the system\n(Schlicker et al. 2022). We propose six design guidelines to help designers\noptimize for accurate trustworthiness assessments, thus fostering ethical and\nresponsible human-automation interactions. The proposed guidelines are derived\nfrom existing literature in various fields, such as human-computer interaction,\ncognitive psychology, automation research, user-experience design, and ethics.\nWe are incorporating key principles from the field of pragmatics, specifically\nthe cultivation of common ground (H. H. Clark 1996) and Gricean communication\nmaxims (Grice 1975). These principles are essential for the design of automated\nsystems because the user's perception of the system's trustworthiness is shaped\nby both environmental contexts, such as organizational culture or societal\nnorms, and by situational context, including the specific circumstances or\nscenarios in which the interaction occurs (Hoff and Bashir 2015). Our proposed\nguidelines provide actionable insights for designers to create automated\nsystems that make relevant trustworthiness cues available. This would ideally\nfoster calibrated trust and more satisfactory, productive, and safe\ninteractions between humans and automated systems. Furthermore, the proposed\nheuristics might work as a tool for evaluating to what extent existing systems\nenable users to accurately assess a system's trustworthiness.",
        "url": "http://arxiv.org/abs/2508.02371v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02371v1",
        "arxiv_id": "2508.02371v1",
        "authors": [
            "Matou≈° Jel√≠nek",
            "Nadine Schlicker",
            "Ewart de Visser"
        ],
        "submitted": "2025-08-04 13:01:09",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on trustworthiness assessment and design guidelines for human-automation interactions, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on user behavior and interaction, the context is more focused on human-computer interaction and ethics rather than search and retrieval."
    },
    {
        "title": "Pointer: Linear-Complexity Long-Range Modeling without Pre-training",
        "abstract": "We introduce Pointer, a novel architecture that achieves linear $O(NK)$\ncomplexity for long-range sequence modeling while maintaining superior\nperformance without requiring pre-training. Unlike standard attention\nmechanisms that compute $O(N^2)$ pairwise interactions, our approach uses\nlayer-wise pointer chaining where each layer's pointer selection depends on\nprevious layer's pointer positions, creating explicit long-distance connections\nthrough pointer chains. We demonstrate that this architecture achieves\n$2$--$10\\times$ speedup on long sequences compared to standard transformers,\nmaintains $>95\\%$ accuracy on copy tasks at distances up to 2048 tokens, and\nlearns interpretable pointer patterns that reveal structured dependency\nmodeling. Our experiments on efficiency benchmarks, long-range dependency\ntasks, and interpretability analysis show that Pointer offers a compelling\nalternative to attention mechanisms for scenarios requiring efficient\nlong-range modeling without pre-training dependencies.",
        "url": "http://arxiv.org/abs/2508.02631v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02631v1",
        "arxiv_id": "2508.02631v1",
        "authors": [
            "Zixi Li"
        ],
        "submitted": "2025-08-04 17:19:56",
        "source": "arxiv",
        "comment": "Submitted to Nordic AI Meet 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper introduces a novel architecture for long-range sequence modeling, which is not directly related to information retrieval or search technologies. While it mentions attention mechanisms, it does not focus on query understanding, ranking models, or user behavior modeling. The paper's emphasis on efficiency and interpretability is interesting, but it does not align with the user's primary research interests in IR and NLP."
    },
    {
        "title": "OptiHive: Ensemble Selection for LLM-Based Optimization via Statistical Modeling",
        "abstract": "LLM-based solvers have emerged as a promising means of automating problem\nmodeling and solving. However, they remain unreliable and often depend on\niterative repair loops that result in significant latency. We introduce\nOptiHive, an LLM-based framework that produces high-quality solvers for\noptimization problems from natural-language descriptions without iterative\nself-correction. OptiHive uses a single batched LLM query to generate diverse\ncomponents (solvers, problem instances, and validation tests) and filters out\nerroneous components to ensure fully interpretable outputs. Taking into account\nthe imperfection of the generated components, we employ a statistical model to\ninfer their true performance, enabling principled uncertainty quantification\nand solver selection. On tasks ranging from traditional optimization problems\nto challenging variants of the Multi-Depot Vehicle Routing Problem, OptiHive\nsignificantly outperforms baselines, increasing the optimality rate from 5\\% to\n92\\% on the most complex problems.",
        "url": "http://arxiv.org/abs/2508.02503v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02503v1",
        "arxiv_id": "2508.02503v1",
        "authors": [
            "Maxime Bouscary",
            "Saurabh Amin"
        ],
        "submitted": "2025-08-04 15:11:51",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on LLM-based optimization and solver selection, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions natural-language descriptions, the primary application is in optimization problems, which is outside the user's core research themes."
    },
    {
        "title": "Monsoon Uprising in Bangladesh: How Facebook Shaped Collective Identity",
        "abstract": "This study investigates how Facebook shaped collective identity during the\nJuly 2024 pro-democracy uprising in Bangladesh, known as the Monsoon Uprising.\nDuring government repression, protesters turned to Facebook as a central space\nfor resistance, where multimodal expressions, images, memes, videos, hashtags,\nand satirical posts played an important role in unifying participants. Using a\nqualitative approach, this research analyzes visual rhetoric, verbal discourse,\nand digital irony to reveal how shared symbols, protest art, and slogans built\na sense of solidarity. Key elements included the symbolic use of red, the\nironic metaphorical use of the term \"Razakar\", and the widespread sharing of\nvisuals representing courage, injustice, and resistance. The findings show that\nthe combination of visual and verbal strategies on Facebook not only mobilized\npublic sentiment, but also built a strong collective identity that challenged\nauthoritarian narratives. This study tries to demonstrate how online platforms\ncan serve as powerful tools for identity construction and political\nmobilization in the digital age.",
        "url": "http://arxiv.org/abs/2508.02498v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02498v1",
        "arxiv_id": "2508.02498v1",
        "authors": [
            "Md Tasin Abir",
            "Arpita Chowdhury",
            "Ashfia Rahman"
        ],
        "submitted": "2025-08-04 15:07:38",
        "source": "arxiv",
        "comment": "10 pages, 9 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on social media, collective identity, and political mobilization, which are outside your primary areas of interest."
    },
    {
        "title": "AI-Based Measurement of Innovation: Mapping Expert Insight into Large Language Model Applications",
        "abstract": "Measuring innovation often relies on context-specific proxies and on expert\nevaluation. Hence, empirical innovation research is often limited to settings\nwhere such data is available. We investigate how large language models (LLMs)\ncan be leveraged to overcome the constraints of manual expert evaluations and\nassist researchers in measuring innovation. We design an LLM framework that\nreliably approximates domain experts' assessment of innovation from\nunstructured text data. We demonstrate the performance and broad applicability\nof this framework through two studies in different contexts: (1) the\ninnovativeness of software application updates and (2) the originality of\nuser-generated feedback and improvement ideas in product reviews. We compared\nthe performance (F1-score) and reliability (consistency rate) of our LLM\nframework against alternative measures used in prior innovation studies, and to\nstate-of-the-art machine learning- and deep learning-based models. The LLM\nframework achieved higher F1-scores than the other approaches, and its results\nare highly consistent (i.e., results do not change across runs). This article\nequips R&D personnel in firms, as well as researchers, reviewers, and editors,\nwith the knowledge and tools to effectively use LLMs for measuring innovation\nand evaluating the performance of LLM-based innovation measures. In doing so,\nwe discuss, the impact of important design decisions-including model selection,\nprompt engineering, training data size, training data distribution, and\nparameter settings-on performance and reliability. Given the challenges\ninherent in using human expert evaluation and existing text-based measures, our\nframework has important implications for harnessing LLMs as reliable,\nincreasingly accessible, and broadly applicable research tools for measuring\ninnovation.",
        "url": "http://arxiv.org/abs/2508.02430v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02430v1",
        "arxiv_id": "2508.02430v1",
        "authors": [
            "Robin Nowak",
            "Patrick Figge",
            "Carolin Haeussler"
        ],
        "submitted": "2025-08-04 13:49:30",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on using large language models to measure innovation, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on NLP and machine learning, the context and application are quite different from the user's primary research interests."
    },
    {
        "title": "Dynaword: From One-shot to Continuously Developed Datasets",
        "abstract": "Large-scale datasets are foundational for research and development in natural\nlanguage processing. However, current approaches face three key challenges: (1)\nreliance on ambiguously licensed sources restricting use, sharing, and\nderivative works; (2) static dataset releases that prevent community\ncontributions and diminish longevity; and (3) quality assurance processes\nrestricted to publishing teams rather than leveraging community expertise.\n  To address these limitations, we introduce two contributions: the Dynaword\napproach and Danish Dynaword. The Dynaword approach is a framework for creating\nlarge-scale, open datasets that can be continuously updated through community\ncollaboration. Danish Dynaword is a concrete implementation that validates this\napproach and demonstrates its potential. Danish Dynaword contains over four\ntimes as many tokens as comparable releases, is exclusively openly licensed,\nand has received multiple contributions across industry and research. The\nrepository includes light-weight tests to ensure data formatting, quality, and\ndocumentation, establishing a sustainable framework for ongoing community\ncontributions and dataset evolution.",
        "url": "http://arxiv.org/abs/2508.02271v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02271v1",
        "arxiv_id": "2508.02271v1",
        "authors": [
            "Kenneth Enevoldsen",
            "Kristian N√∏rgaard Jensen",
            "Jan Kostkan",
            "Bal√°zs Szab√≥",
            "M√°rton Kardos",
            "Kirten Vad",
            "Andrea Blasi N√∫√±ez",
            "Gianluca Barmina",
            "Jacob Nielsen",
            "Rasmus Larsen",
            "Peter Vahlstrup",
            "Per M√∏ldrup Dalum",
            "Desmond Elliott",
            "Lukas Galke",
            "Peter Schneider-Kamp",
            "Kristoffer Nielbo"
        ],
        "submitted": "2025-08-04 10:30:42",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on dataset creation and open licensing, which is outside the scope of the user's research interests."
    },
    {
        "title": "Trainable Dynamic Mask Sparse Attention",
        "abstract": "In large language models, the demand for modeling long contexts is constantly\nincreasing, but the quadratic complexity of the standard self-attention\nmechanism often becomes a bottleneck. Although existing sparse attention\nmechanisms have improved efficiency, they may still encounter issues such as\nstatic patterns or information loss. We introduce a trainable dynamic mask\nsparse attention mechanism, Dynamic Mask Attention, which effectively utilizes\ncontent-aware and position-aware sparsity. DMA achieves this through two key\ninnovations: First, it dynamically generates content-aware sparse masks from\nvalue representations, enabling the model to identify and focus on critical\ninformation adaptively. Second, it implements position-aware sparse attention\ncomputation that effectively skips unnecessary calculation regions. This\ndual-sparsity design allows the model to significantly reduce the computational\ncomplexity of important information while retaining complete information,\nachieving an excellent balance between information fidelity and computational\nefficiency. We have verified the performance of DMA through comprehensive\nexperiments. Comparative studies show that DMA outperforms multi-head\nattention, sliding window attention, multi-head latent attention, and native\nsparse attention in terms of perplexity under Chinchilla Scaling Law settings.\nMoreover, in challenging multi-query associative recall tasks, DMA also\ndemonstrates superior performance and efficiency compared to these methods.\nCrucially, in the evaluation of a 1.7B parameter model, DMA significantly\noutperforms multi-head attention in both standard benchmark performance and the\nchallenging needle-in-a-haystack task. These experimental results highlight its\ncapability to balance model efficiency and long-context modeling ability\neffectively.",
        "url": "http://arxiv.org/abs/2508.02124v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02124v1",
        "arxiv_id": "2508.02124v1",
        "authors": [
            "Jingze Shi",
            "Yifan Wu",
            "Bingheng Wu",
            "Yiran Peng",
            "Liangdong Wang",
            "Guang Liu",
            "Yuyu Luo"
        ],
        "submitted": "2025-08-04 07:05:15",
        "source": "arxiv",
        "comment": "8 figures, 4 tables",
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper introduces a trainable dynamic mask sparse attention mechanism, which is a novel approach to improve the efficiency of self-attention mechanisms in large language models. While it is related to information retrieval and NLP, the focus is on improving the efficiency of language models rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user."
    },
    {
        "title": "A Decentralized Framework for Ethical Authorship Validation in Academic Publishing: Leveraging Self-Sovereign Identity and Blockchain Technology",
        "abstract": "Academic publishing, integral to knowledge dissemination and scientific\nadvancement, increasingly faces threats from unethical practices such as\nunconsented authorship, gift authorship, author ambiguity, and undisclosed\nconflicts of interest. While existing infrastructures like ORCID effectively\ndisambiguate researcher identities, they fall short in enforcing explicit\nauthorship consent, accurately verifying contributor roles, and robustly\ndetecting conflicts of interest during peer review. To address these\nshortcomings, this paper introduces a decentralized framework leveraging\nSelf-Sovereign Identity (SSI) and blockchain technology. The proposed model\nuses Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs) to\nsecurely verify author identities and contributions, reducing ambiguity and\nensuring accurate attribution. A blockchain-based trust registry records\nauthorship consent and peer-review activity immutably. Privacy-preserving\ncryptographic techniques, especially Zero-Knowledge Proofs (ZKPs), support\nconflict-of-interest detection without revealing sensitive data. Verified\nauthorship metadata and consent records are embedded in publications,\nincreasing transparency. A stakeholder survey of researchers, editors, and\nreviewers suggests the framework improves ethical compliance and confidence in\nscholarly communication. This work represents a step toward a more transparent,\naccountable, and trustworthy academic publishing ecosystem.",
        "url": "http://arxiv.org/abs/2508.01913v1",
        "pdf_url": "http://arxiv.org/pdf/2508.01913v1",
        "arxiv_id": "2508.01913v1",
        "authors": [
            "Kamal Al-Sabahi",
            "Yousuf Khamis Al Mabsali"
        ],
        "submitted": "2025-08-03 20:26:19",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, data mining, or recommender systems. The paper focuses on a specific problem in academic publishing, using blockchain technology and Self-Sovereign Identity, which is outside your primary research areas."
    },
    {
        "title": "Counterfactual Reciprocal Recommender Systems for User-to-User Matching",
        "abstract": "Reciprocal recommender systems (RRS) in dating, gaming, and talent platforms\nrequire mutual acceptance for a match. Logged data, however, over-represents\npopular profiles due to past exposure policies, creating feedback loops that\nskew learning and fairness. We introduce Counterfactual Reciprocal Recommender\nSystems (CFRR), a causal framework to mitigate this bias. CFRR uses inverse\npropensity scored, self-normalized objectives. Experiments show CFRR improves\nNDCG@10 by up to 3.5% (e.g., from 0.459 to 0.475 on DBLP, from 0.299 to 0.307\non Synthetic), increases long-tail user coverage by up to 51% (from 0.504 to\n0.763 on Synthetic), and reduces Gini exposure inequality by up to 24% (from\n0.708 to 0.535 on Synthetic). CFRR offers a promising approach for more\naccurate and fair user-to-user matching.",
        "url": "http://arxiv.org/abs/2508.01867v1",
        "pdf_url": "http://arxiv.org/pdf/2508.01867v1",
        "arxiv_id": "2508.01867v1",
        "authors": [
            "Kazuki Kawamura",
            "Takuma Udagawa",
            "Kei Tateno"
        ],
        "submitted": "2025-08-03 17:45:04",
        "source": "arxiv",
        "comment": "9 pages, 2 figures. Accepted for publication at the Workshop on\n  Two-sided Marketplace Optimization (TSMO '25), held in conjunction with the\n  31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2025),\n  Toronto, Canada",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on reciprocal recommender systems, which is not directly related to information retrieval, query understanding, or ranking models. While it touches on fairness and bias in learning, the context is specific to user-to-user matching in dating, gaming, and talent platforms, which is not a core area of interest for the user."
    },
    {
        "title": "CharBench: Evaluating the Role of Tokenization in Character-Level Tasks",
        "abstract": "Tasks that require character-level reasoning, such as counting or locating\ncharacters within words, remain challenging for contemporary language models. A\ncommon conjecture is that language models' reliance on subword units, rather\nthan characters, contributes to their struggles with character-level tasks, yet\nrecent studies offer conflicting conclusions about the role of tokenization,\nleaving its impact unclear. To address this gap, we introduce CharBench, a\ncomprehensive benchmark of character-level tasks that is two orders of\nmagnitude larger than existing alternatives. We evaluate a diverse range of\nleading open-weight and proprietary models on CharBench and find that it\npresents a significant challenge to modern LLMs, with an average accuracy of\n43.6% and 32.3% on some tasks. We present an in-depth analysis of how intrinsic\nproperties of words and their segmentations into tokens correspond to model\nperformance. For counting tasks, we find that tokenization properties are\nweakly correlated with correctness, while the length of the queried word and\nthe actual character count play a more significant part. In contrast, for tasks\nrequiring intra-word positional understanding, performance is negatively\ncorrelated with the length of the token containing the queried character,\nsuggesting that longer tokens obscure character position information for LLMs.\nWe encourage future work to build on the benchmark and evaluation methodology\nintroduced here as tools for improving model performance on such tasks.",
        "url": "http://arxiv.org/abs/2508.02591v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02591v1",
        "arxiv_id": "2508.02591v1",
        "authors": [
            "Omri Uzan",
            "Yuval Pinter"
        ],
        "submitted": "2025-08-04 16:46:15",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on character-level tasks and tokenization, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on language models and their performance on specific tasks is also not aligned with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Parameter-Efficient Routed Fine-Tuning: Mixture-of-Experts Demands Mixture of Adaptation Modules",
        "abstract": "Mixture-of-Experts (MoE) benefits from a dynamic routing mechanism among\ntheir specialized experts, which existing Parameter- Efficient Fine-Tuning\n(PEFT) strategies fail to leverage. This motivates us to investigate whether\nadaptation modules themselves should incorporate routing mechanisms to align\nwith MoE's multi-expert architecture. We analyze dynamics of core components\nwhen applying PEFT to MoE language models and examine how different routing\nstrategies affect adaptation effectiveness. Extensive experiments adapting\nOLMoE-1B-7B and Mixtral-8x7B on various commonsense and math reasoning tasks\nvalidate the performance and efficiency of our routed approach. We identify the\noptimal configurations for different scenarios and provide empirical analyses\nwith practical insights to facilitate better PEFT and MoE applications.",
        "url": "http://arxiv.org/abs/2508.02587v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02587v1",
        "arxiv_id": "2508.02587v1",
        "authors": [
            "Yilun Liu",
            "Yunpu Ma",
            "Yuetian Lu",
            "Shuo Chen",
            "Zifeng Ding",
            "Volker Tresp"
        ],
        "submitted": "2025-08-04 16:43:09",
        "source": "arxiv",
        "comment": "This paper is a preprint under review. arXiv admin note: text overlap\n  with arXiv:2411.08212",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on Mixture-of-Experts (MoE) and Parameter-Efficient Fine-Tuning (PEFT) strategies, which is not directly related to Information Retrieval (IR) or Search technologies. Although it mentions language models, the context is not about query understanding, ranking models, or user behavior modeling, which are core areas of interest in IR."
    },
    {
        "title": "MArgE: Meshing Argumentative Evidence from Multiple Large Language Models for Justifiable Claim Verification",
        "abstract": "Leveraging outputs from multiple large language models (LLMs) is emerging as\na method for harnessing their power across a wide range of tasks while\nmitigating their capacity for making errors, e.g., hallucinations. However,\ncurrent approaches to combining insights from multiple LLMs often involve\nunstructured interactions (e.g., free debate), resulting in model generations\nthat are not faithfully justifiable. In this work, we introduce MArgE, a novel\nframework to provide formal structure to the evidence from each LLM, in the\nform of a tree of extracted arguments, for the task of claim verification. We\nuse a variant of Argumentative LLMs (ArgLLMs), i.e. LLMs driven by frameworks\nand semantics from the field of computational argumentation, to construct\nstructured argument trees for given claims. This process creates an inspectable\npathway from the initial arguments to the final claim verification decisions,\nproviding a faithful justification thereof. We show experimentally that MArgE\ncan significantly outperform single LLMs, including three open-source models\n(4B to 8B parameters), GPT-4o-mini and existing ArgLLMs, as well as prior\nmethods for unstructured multi-LLM debates. We thus demonstrate the advantages\nof incorporating formal, argumentative reasoning mechanisms when combining\nmultiple LLM outputs.",
        "url": "http://arxiv.org/abs/2508.02584v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02584v1",
        "arxiv_id": "2508.02584v1",
        "authors": [
            "Ming Pok Ng",
            "Junqi Jiang",
            "Gabriel Freedman",
            "Antonio Rago",
            "Francesca Toni"
        ],
        "submitted": "2025-08-04 16:40:02",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the combination of multiple large language models, which is related to query understanding and ranking models in Information Retrieval. However, the focus on argumentative evidence and claim verification is not directly aligned with the user's primary interests in search technologies and user behavior modeling."
    },
    {
        "title": "EHSAN: Leveraging ChatGPT in a Hybrid Framework for Arabic Aspect-Based Sentiment Analysis in Healthcare",
        "abstract": "Arabic-language patient feedback remains under-analysed because dialect\ndiversity and scarce aspect-level sentiment labels hinder automated assessment.\nTo address this gap, we introduce EHSAN, a data-centric hybrid pipeline that\nmerges ChatGPT pseudo-labelling with targeted human review to build the first\nexplainable Arabic aspect-based sentiment dataset for healthcare. Each sentence\nis annotated with an aspect and sentiment label (positive, negative, or\nneutral), forming a pioneering Arabic dataset aligned with healthcare themes,\nwith ChatGPT-generated rationales provided for each label to enhance\ntransparency. To evaluate the impact of annotation quality on model\nperformance, we created three versions of the training data: a fully supervised\nset with all labels reviewed by humans, a semi-supervised set with 50% human\nreview, and an unsupervised set with only machine-generated labels. We\nfine-tuned two transformer models on these datasets for both aspect and\nsentiment classification. Experimental results show that our Arabic-specific\nmodel achieved high accuracy even with minimal human supervision, reflecting\nonly a minor performance drop when using ChatGPT-only labels. Reducing the\nnumber of aspect classes notably improved classification metrics across the\nboard. These findings demonstrate an effective, scalable approach to Arabic\naspect-based sentiment analysis (SA) in healthcare, combining large language\nmodel annotation with human expertise to produce a robust and explainable\ndataset. Future directions include generalisation across hospitals, prompt\nrefinement, and interpretable data-driven modelling.",
        "url": "http://arxiv.org/abs/2508.02574v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02574v1",
        "arxiv_id": "2508.02574v1",
        "authors": [
            "Eman Alamoudi",
            "Ellis Solaiman"
        ],
        "submitted": "2025-08-04 16:28:58",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Arabic aspect-based sentiment analysis in healthcare, leveraging ChatGPT for pseudo-labelling and human review. While it involves natural language processing and data mining, it is not directly related to information retrieval, search technologies, or query understanding, which are the user's primary research interests."
    },
    {
        "title": "Automated SNOMED CT Concept Annotation in Clinical Text Using Bi-GRU Neural Networks",
        "abstract": "Automated annotation of clinical text with standardized medical concepts is\ncritical for enabling structured data extraction and decision support. SNOMED\nCT provides a rich ontology for labeling clinical entities, but manual\nannotation is labor-intensive and impractical at scale. This study introduces a\nneural sequence labeling approach for SNOMED CT concept recognition using a\nBidirectional GRU model. Leveraging a subset of MIMIC-IV, we preprocess text\nwith domain-adapted SpaCy and SciBERT-based tokenization, segmenting sentences\ninto overlapping 19-token chunks enriched with contextual, syntactic, and\nmorphological features. The Bi-GRU model assigns IOB tags to identify concept\nspans and achieves strong performance with a 90 percent F1-score on the\nvalidation set. These results surpass traditional rule-based systems and match\nor exceed existing neural models. Qualitative analysis shows effective handling\nof ambiguous terms and misspellings. Our findings highlight that lightweight\nRNN-based architectures can deliver high-quality clinical concept annotation\nwith significantly lower computational cost than transformer-based models,\nmaking them well-suited for real-world deployment.",
        "url": "http://arxiv.org/abs/2508.02556v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02556v1",
        "arxiv_id": "2508.02556v1",
        "authors": [
            "Ali Noori",
            "Pratik Devkota",
            "Somya Mohanty",
            "Prashanti Manda"
        ],
        "submitted": "2025-08-04 16:08:49",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on automated annotation of clinical text using SNOMED CT concepts, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves neural networks, the application is in the medical domain, which is not a primary focus of your research interests."
    },
    {
        "title": "What's in the News? Towards Identification of Bias by Commission, Omission, and Source Selection (COSS)",
        "abstract": "In a world overwhelmed with news, determining which information comes from\nreliable sources or how neutral is the reported information in the news\narticles poses a challenge to news readers. In this paper, we propose a\nmethodology for automatically identifying bias by commission, omission, and\nsource selection (COSS) as a joint three-fold objective, as opposed to the\nprevious work separately addressing these types of bias. In a pipeline concept,\nwe describe the goals and tasks of its steps toward bias identification and\nprovide an example of a visualization that leverages the extracted features and\npatterns of text reuse.",
        "url": "http://arxiv.org/abs/2508.02540v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02540v1",
        "arxiv_id": "2508.02540v1",
        "authors": [
            "Anastasia Zhukova",
            "Terry Ruas",
            "Felix Hamborg",
            "Karsten Donnay",
            "Bela Gipp"
        ],
        "submitted": "2025-08-04 15:47:17",
        "source": "arxiv",
        "comment": "published in the Proceedings of the 2023 ACM/IEEE Joint Conference on\n  Digital Libraries",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on identifying bias in news articles, which is not directly related to Information Retrieval, Search technologies, or query understanding. Although it touches on text analysis and feature extraction, the primary goal is not to improve search or ranking models, making it only loosely relevant to the user's research interests."
    },
    {
        "title": "PoeTone: A Framework for Constrained Generation of Structured Chinese Songci with LLMs",
        "abstract": "This paper presents a systematic investigation into the constrained\ngeneration capabilities of large language models (LLMs) in producing Songci, a\nclassical Chinese poetry form characterized by strict structural, tonal, and\nrhyme constraints defined by Cipai templates. We first develop a comprehensive,\nmulti-faceted evaluation framework that includes: (i) a formal conformity\nscore, (ii) automated quality assessment using LLMs, (iii) human evaluation,\nand (iv) classification-based probing tasks. Using this framework, we evaluate\nthe generative performance of 18 LLMs, including 3 proprietary models and 15\nopen-source models across four families, under five prompting strategies:\nzero-shot, one-shot, completion-based, instruction-tuned, and chain-of-thought.\nFinally, we propose a Generate-Critic architecture in which the evaluation\nframework functions as an automated critic. Leveraging the critic's feedback as\na reward signal, we fine-tune three lightweight open-source LLMs via supervised\nfine-tuning (SFT), resulting in improvements of up to 5.88% in formal\nconformity. Our findings offer new insights into the generative strengths and\nlimitations of LLMs in producing culturally significant and formally\nconstrained literary texts.",
        "url": "http://arxiv.org/abs/2508.02515v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02515v1",
        "arxiv_id": "2508.02515v1",
        "authors": [
            "Zhan Qu",
            "Shuzhou Yuan",
            "Michael F√§rber"
        ],
        "submitted": "2025-08-04 15:19:22",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the application of large language models (LLMs) in generating structured Chinese Songci poetry, which is not directly related to information retrieval, search technologies, or query understanding. While it explores the capabilities of LLMs, the paper's primary concern is the cultural significance and formal constraints of literary texts, which is outside the scope of the user's research interests."
    },
    {
        "title": "AIAP: A No-Code Workflow Builder for Non-Experts with Natural Language and Multi-Agent Collaboration",
        "abstract": "While many tools are available for designing AI, non-experts still face\nchallenges in clearly expressing their intent and managing system complexity.\nWe introduce AIAP, a no-code platform that integrates natural language input\nwith visual workflows. AIAP leverages a coordinated multi-agent system to\ndecompose ambiguous user instructions into modular, actionable steps, hidden\nfrom users behind a unified interface. A user study involving 32 participants\nshowed that AIAP's AI-generated suggestions, modular workflows, and automatic\nidentification of data, actions, and context significantly improved\nparticipants' ability to develop services intuitively. These findings highlight\nthat natural language-based visual programming significantly reduces barriers\nand enhances user experience in AI service design.",
        "url": "http://arxiv.org/abs/2508.02470v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02470v1",
        "arxiv_id": "2508.02470v1",
        "authors": [
            "Hyunjn An",
            "Yongwon Kim",
            "Wonduk Seo",
            "Joonil Park",
            "Daye Kang",
            "Changhoon Oh",
            "Dokyun Kim",
            "Seunghyun Lee"
        ],
        "submitted": "2025-08-04 14:36:31",
        "source": "arxiv",
        "comment": "14 pages, 6 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on AIAP, a no-code platform for designing AI services, which is not directly related to Information Retrieval, Search technologies, or Natural Language Processing. The abstract does not mention query understanding, ranking models, or user behavior modeling, and the paper's scope is limited to AI service design, making it irrelevant to the user's research interests."
    },
    {
        "title": "LatentPrompt: Optimizing Promts in Latent Space",
        "abstract": "Recent advances have shown that optimizing prompts for Large Language Models\n(LLMs) can significantly improve task performance, yet many optimization\ntechniques rely on heuristics or manual exploration. We present LatentPrompt, a\nmodel-agnostic framework for prompt optimization that leverages latent semantic\nspace to automatically generate, evaluate, and refine candidate prompts without\nrequiring hand-crafted rules. Beginning with a set of seed prompts, our method\nembeds them in a continuous latent space and systematically explores this space\nto identify prompts that maximize task-specific performance. In a\nproof-of-concept study on the Financial PhraseBank sentiment classification\nbenchmark, LatentPrompt increased classification accuracy by approximately 3\npercent after a single optimization cycle. The framework is broadly applicable,\nrequiring only black-box access to an LLM and an automatic evaluation metric,\nmaking it suitable for diverse domains and tasks.",
        "url": "http://arxiv.org/abs/2508.02452v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02452v1",
        "arxiv_id": "2508.02452v1",
        "authors": [
            "Mateusz Bystro≈Ñski",
            "Grzegorz Piotrowski",
            "Nitesh V. Chawla",
            "Tomasz Kajdanowicz"
        ],
        "submitted": "2025-08-04 14:17:29",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a framework for optimizing prompts for Large Language Models, which is related to query understanding and ranking models. However, the focus is on optimizing prompts rather than understanding user behavior or click models, which are key aspects of my research interests. The paper's relevance to information retrieval is limited, and it does not directly address real-time relevance optimization or deep semantic understanding."
    },
    {
        "title": "Modality Bias in LVLMs: Analyzing and Mitigating Object Hallucination via Attention Lens",
        "abstract": "Large vision-language models (LVLMs) have demonstrated remarkable multimodal\ncomprehension and reasoning capabilities, but they still suffer from severe\nobject hallucination. Previous studies primarily attribute the flaw to\nlinguistic prior caused by the scale mismatch between visual encoders and large\nlanguage models (LLMs) in LVLMs. Specifically, as current LVLMs are built upon\nLLMs, they tend to over-rely on textual prompts and internal knowledge of LLMs,\ngenerating descriptions inconsistent with visual cues. However, through an\nin-depth investigation of the hallucinated mechanisms, we empirically reveal a\npreviously overlooked phenomenon: LVLMs may ignore not only visual information\nbut also textual modality during hallucination, a behavior termed as modality\nbias, which indicates that LVLMs struggle to simultaneously attend to both\nvisual and textual modalities, leading to fragmented understanding of\nuser-provided instructions. Based on this observation, we propose a simple yet\neffective training-free method to mitigate object hallucination. Concretely, we\nintervene and adjust the attention weights of textual and visual tokens,\nbalancing cross-modal compatibility for better alignment with user intentions.\nFurthermore, we adopt a contrastive decoding strategy to reduce the LVLM's\noverreliance on its parametric knowledge, synergistically enhancing our\nattention manipulation. Extensive experiments confirm the widespread presence\nof modality bias in LVLMs. Notably, our method effectively mitigates\nhallucination across multiple open-source LVLMs and benchmarks, highlighting\nits generalizability and efficacy.",
        "url": "http://arxiv.org/abs/2508.02419v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02419v1",
        "arxiv_id": "2508.02419v1",
        "authors": [
            "Haohan Zheng",
            "Zhenguo Zhang"
        ],
        "submitted": "2025-08-04 13:40:59",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on Large Vision-Language Models (LVLMs) and object hallucination, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on attention mechanisms, it is primarily concerned with multimodal comprehension and reasoning in the context of LVLMs, which is outside the scope of the user's research interests."
    },
    {
        "title": "Understanding and Mitigating Political Stance Cross-topic Generalization in Large Language Models",
        "abstract": "Fine-tuning Large Language Models on a political topic will significantly\nmanipulate their political stance on various issues and unintentionally affect\ntheir stance on unrelated topics. While previous studies have proposed this\nissue, there is still a lack of understanding regarding the internal\nrepresentations of these stances and the mechanisms that lead to unintended\ncross-topic generalization. In this paper, we systematically explore the\ninternal mechanisms underlying this phenomenon from a neuron-level perspective\nand how to mitigate the cross-topic generalization of political fine-tuning.\nFirstly, we propose Political Neuron Localization through Activation\nContrasting (PNLAC) to identify two distinct types of political neurons:\ngeneral political neurons, which govern stance across multiple political\ntopics, and topic-specific neurons} that affect the model's political stance on\nindividual topics. We find the existence of these political neuron types across\nfour models and datasets through activation patching experiments. Leveraging\nthese insights, we introduce InhibitFT, an inhibition-based fine-tuning method,\neffectively mitigating the cross-topic stance generalization. Experimental\nresults demonstrate the robustness of identified neuron types across various\nmodels and datasets, and show that InhibitFT significantly reduces the\ncross-topic stance generalization by 20% on average, while preserving\ntopic-specific performance. Moreover, we demonstrate that selectively\ninhibiting only 5% of neurons is sufficient to effectively mitigate the\ncross-topic stance generalization.",
        "url": "http://arxiv.org/abs/2508.02360v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02360v1",
        "arxiv_id": "2508.02360v1",
        "authors": [
            "Jiayi Zhang",
            "Shu Yang",
            "Junchao Wu",
            "Derek F. Wong",
            "Di Wang"
        ],
        "submitted": "2025-08-04 12:49:10",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on understanding and mitigating cross-topic generalization in large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on neural networks and fine-tuning, the context is specific to natural language processing and political stance analysis, making it less relevant to the user's research interests."
    },
    {
        "title": "CAMERA: Multi-Matrix Joint Compression for MoE Models via Micro-Expert Redundancy Analysis",
        "abstract": "Large Language Models (LLMs) with Mixture-of-Experts (MoE) architectures are\ndistinguished by their strong performance scaling with increasing parameters\nacross a wide range of tasks, yet they also suffer from substantial\ncomputational and storage overheads. Notably, the performance gains of MoE\nmodels do not scale proportionally with the growth in expert parameters. While\nprior works attempt to reduce parameters via expert-level pruning, merging, or\ndecomposition, they still suffer from challenges in both performance and\ncomputational efficiency. In this paper, we address these challenges by\nintroducing micro-expert as a finer-grained compression unit that spans across\nmatrices. We first establish a more fundamental perspective, viewing MoE layers\nas mixtures of micro-experts, and present CAMERA, a lightweight and\ntraining-free framework for identifying micro-expert redundancy. Our analysis\nuncovers significant variance in micro-expert contributions during decoding.\nBased on this insight, we further propose CAMERA-P, a structured micro-expert\npruning framework, and CAMERA-Q, a mixed-precision quantization idea designed\nfor micro-experts. Extensive experiments on nine downstream tasks show that\nCAMERA-P consistently outperforms strong baselines under pruning ratios ranging\nfrom 20% to 60%. Furthermore, CAMERA-Q achieves superior results under\naggressive 2-bit quantization, surpassing existing matrix- and channel-level\nideas. Notably, our method enables complete micro-expert analysis of\nQwen2-57B-A14B in less than 5 minutes on a single NVIDIA A100-40GB GPU.",
        "url": "http://arxiv.org/abs/2508.02322v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02322v1",
        "arxiv_id": "2508.02322v1",
        "authors": [
            "Yuzhuang Xu",
            "Xu Han",
            "Yuanchi Zhang",
            "Yixuan Wang",
            "Yijun Liu",
            "Shiyu Ji",
            "Qingfu Zhu",
            "Wanxiang Che"
        ],
        "submitted": "2025-08-04 11:42:48",
        "source": "arxiv",
        "comment": "16 pages, 9 figures, 7 tables",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on compressing Mixture-of-Experts (MoE) models, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions large language models, the context is not relevant to the user's interests in IR, NLP, or data mining."
    },
    {
        "title": "CAPO: Towards Enhancing LLM Reasoning through Verifiable Generative Credit Assignment",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has improved the\nreasoning abilities of Large Language Models (LLMs) by using rule-based binary\nfeedback, helping to mitigate reward hacking. However, current RLVR methods\ntypically treat whole responses as single actions, assigning the same reward to\nevery token. This coarse-grained feedback hampers precise credit assignment,\nmaking it hard for models to identify which reasoning steps lead to success or\nfailure, and often results in suboptimal policies and inefficient learning.\nMethods like PPO provide credit assignment through value estimation, but often\nyield inaccurate and unverifiable signals due to limited sampling. On the other\nhand, methods using Process Reward Models can provide step-by-step judgments\nfor each reasoning step, but they require high-quality process supervision\nlabels and are time-consuming when applied in online reinforcement learning\n(RL). To overcome these limitations, we introduce a simple but efficient method\nCredit Assignment Policy Optimization (CAPO). Given a reasoning response\nrollout from the policy model, CAPO directly leverages an off-the-shelf,\ngeneral-purpose LLM as a Generative Process Reward Model (LLM-as-GenPRM) to\ngenerate all step-wise critique by one pass, thereby providing verifiable\ntoken-level rewards to refine the tokens that were originally assigned\nidentical rule-based rewards. This enables more fine-grained credit assignment\nin an effective way. Furthermore, to enhance the accuracy and robustness of\nCAPO, we employ voting mechanisms that scale with the number of generated\ncritiques. Extensive experiments using different backbones like Llama and Qwen\nmodels and in different sizes show that CAPO consistently outperforms\nsupervised learning-based and RL-based fine-tuning methods across six\nchallenging mathematical benchmarks and three out-of-domain benchmarks.",
        "url": "http://arxiv.org/abs/2508.02298v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02298v1",
        "arxiv_id": "2508.02298v1",
        "authors": [
            "Guofu Xie",
            "Yunsheng Shi",
            "Hongtao Tian",
            "Ting Yao",
            "Xiao Zhang"
        ],
        "submitted": "2025-08-04 11:06:08",
        "source": "arxiv",
        "comment": "Work in progress",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on reinforcement learning and credit assignment for large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing, the context is different from the user's primary research interests."
    },
    {
        "title": "SHAMI-MT: A Syrian Arabic Dialect to Modern Standard Arabic Bidirectional Machine Translation System",
        "abstract": "The rich linguistic landscape of the Arab world is characterized by a\nsignificant gap between Modern Standard Arabic (MSA), the language of formal\ncommunication, and the diverse regional dialects used in everyday life. This\ndiglossia presents a formidable challenge for natural language processing,\nparticularly machine translation. This paper introduces \\textbf{SHAMI-MT}, a\nbidirectional machine translation system specifically engineered to bridge the\ncommunication gap between MSA and the Syrian dialect. We present two\nspecialized models, one for MSA-to-Shami and another for Shami-to-MSA\ntranslation, both built upon the state-of-the-art AraT5v2-base-1024\narchitecture. The models were fine-tuned on the comprehensive Nabra dataset and\nrigorously evaluated on unseen data from the MADAR corpus. Our MSA-to-Shami\nmodel achieved an outstanding average quality score of \\textbf{4.01 out of 5.0}\nwhen judged by OPENAI model GPT-4.1, demonstrating its ability to produce\ntranslations that are not only accurate but also dialectally authentic. This\nwork provides a crucial, high-fidelity tool for a previously underserved\nlanguage pair, advancing the field of dialectal Arabic translation and offering\nsignificant applications in content localization, cultural heritage, and\nintercultural communication.",
        "url": "http://arxiv.org/abs/2508.02268v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02268v1",
        "arxiv_id": "2508.02268v1",
        "authors": [
            "Serry Sibaee",
            "Omer Nacar",
            "Yasser Al-Habashi",
            "Adel Ammar",
            "Wadii Boulila"
        ],
        "submitted": "2025-08-04 10:21:11",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on machine translation between Modern Standard Arabic and the Syrian dialect, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves NLP, the specific application and scope are not aligned with the user's core research themes."
    },
    {
        "title": "I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking",
        "abstract": "Multimodal entity linking plays a crucial role in a wide range of\napplications. Recent advances in large language model-based methods have become\nthe dominant paradigm for this task, effectively leveraging both textual and\nvisual modalities to enhance performance. Despite their success, these methods\nstill face two challenges, including unnecessary incorporation of image data in\ncertain scenarios and the reliance only on a one-time extraction of visual\nfeatures, which can undermine their effectiveness and accuracy. To address\nthese challenges, we propose a novel LLM-based framework for the multimodal\nentity linking task, called Intra- and Inter-modal Collaborative Reflections.\nThis framework prioritizes leveraging text information to address the task.\nWhen text alone is insufficient to link the correct entity through intra- and\ninter-modality evaluations, it employs a multi-round iterative strategy that\nintegrates key visual clues from various aspects of the image to support\nreasoning and enhance matching accuracy. Extensive experiments on three widely\nused public datasets demonstrate that our framework consistently outperforms\ncurrent state-of-the-art methods in the task, achieving improvements of 3.2%,\n5.1%, and 1.6%, respectively. Our code is available at\nhttps://github.com/ziyan-xiaoyu/I2CR/.",
        "url": "http://arxiv.org/abs/2508.02243v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02243v1",
        "arxiv_id": "2508.02243v1",
        "authors": [
            "Ziyan Liu",
            "Junwen Li",
            "Kaiwen Li",
            "Tong Ruan",
            "Chao Wang",
            "Xinyan He",
            "Zongyu Wang",
            "Xuezhi Cao",
            "Jingping Liu"
        ],
        "submitted": "2025-08-04 09:43:54",
        "source": "arxiv",
        "comment": "10 pages, 6 figures, accepted by ACMMM 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on multimodal entity linking, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and query understanding. Although it mentions the use of large language models, the context is different from the user's focus on ranking models and user behavior modeling."
    },
    {
        "title": "LeanK: Learnable K Cache Channel Pruning for Efficient Decoding",
        "abstract": "Large language models (LLMs) enable long-context tasks but face efficiency\nchallenges due to the growing key-value (KV) cache. We propose LeanK, a\nlearning-based method that prunes unimportant key (K) cache channels by\nleveraging static channel sparsity. With a novel two-stage training process,\nLeanK learns channel-wise static mask that could satisfy specific sparsity\nratio and hardware alignment requirement. LeanK reduces GPU memory and\naccelerates decoding without sacrificing accuracy. Experiments demonstrate up\nto 70% K cache and 16%-18% V cache memory reduction. Custom decoding kernel\nenables 1.3x speedup for attention computation. We also provide insights into\nmodel channels and attention heads during long-context inference by analyzing\nthe learned importance distribution. Our code is available at\nhttps://aka.ms/LeanK.",
        "url": "http://arxiv.org/abs/2508.02215v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02215v1",
        "arxiv_id": "2508.02215v1",
        "authors": [
            "Yike Zhang",
            "Zhiyuan He",
            "Huiqiang Jiang",
            "Chengruidong Zhang",
            "Yuqing Yang",
            "Jianyong Wang",
            "Lili Qiu"
        ],
        "submitted": "2025-08-04 09:08:43",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on pruning key-value cache channels for efficient decoding in large language models, which is a topic in Natural Language Processing, but not directly related to the user's core research themes."
    }
]