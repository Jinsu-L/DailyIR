# Daily Papers Report - 2025-08-24

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. OPERA: A Reinforcement Learning--Enhanced Orchestrated Planner-Executor Architecture for Reasoning-Oriented Multi-Hop Retrieval

- **LLM Score**: 6
- **Keyword Score**: 13
- **Authors**: Yu Liu, Yanbing Liu, Fangfang Yuan, Cong Cao, Youbang Sun, Kun Peng, WeiZhuo Chen, Jianjun Li, Zhiyuan Ma
- **URL**: <http://arxiv.org/abs/2508.16438v1>
- **Submitted**: 2025-08-22 14:50:26
- **Topic Keywords**: retriever, query, queries, rag, retrieval
- **Reason**: The paper introduces a novel framework for reasoning-oriented multi-hop retrieval, which is related to information retrieval and query understanding. While it does not specifically focus on ranking models or user behavior modeling, it explores the intersection of retrieval and reasoning, which is relevant to the user's interests in deep semantic understanding and real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Reasoning-driven retrieval framework for complex multi-hop reasoning tasks
- **Aim**: Introduce OPERA, a novel framework that integrates reasoning into each component for multi-hop reasoning tasks
- **Rationale**: Existing methods lack effective integration of reasoning, leading to suboptimal performance
- **Ground**: OPERA consists of Goal Planning Module (GPM) and Reason-Execute Module (REM), with MAPGRPO training algorithm
- **Experiment**: Evaluate OPERA on HotpotQA, 2WikiMultiHopQA, Musique, NQ, and MultiHopRAG datasets, with ablation studies and error analysis
- **Takeaway**: OPERA advances state-of-the-art in multi-hop reasoning tasks with its novel framework and training algorithm, demonstrating strong empirical results and generalizability to out-of-domain tasks

#### Abstract
> Recent advances in large language models (LLMs) and dense retrievers have
driven significant progress in retrieval-augmented generation (RAG). However,
existing approaches face significant challenges in complex reasoning-oriented
multi-hop retrieval tasks: 1) Ineffective reasoning-oriented planning: Prior
methods struggle to generate robust multi-step plans for complex queries, as
rule-based decomposers perform poorly on out-of-template questions. 2)
Suboptimal reasoning-driven retrieval: Related methods employ limited query
reformulation, leading to iterative retrieval loops that often fail to locate
golden documents. 3) Insufficient reasoning-guided filtering: Prevailing
methods lack the fine-grained reasoning to effectively filter salient
information from noisy results, hindering utilization of retrieved knowledge.
Fundamentally, these limitations all stem from the weak coupling between
retrieval and reasoning in current RAG architectures. We introduce the
Orchestrated Planner-Executor Reasoning Architecture (OPERA), a novel
reasoning-driven retrieval framework. OPERA's Goal Planning Module (GPM)
decomposes questions into sub-goals, which are executed by a Reason-Execute
Module (REM) with specialized components for precise reasoning and effective
retrieval. To train OPERA, we propose Multi-Agents Progressive Group Relative
Policy Optimization (MAPGRPO), a novel variant of GRPO. Experiments on complex
multi-hop benchmarks show OPERA's superior performance, validating both the
MAPGRPO method and OPERA's design. Code is available at
https://github.com/Ameame1/OPERA.

---

### 2. Similarity-Based Supervised User Session Segmentation Method for Behavior Logs

- **LLM Score**: 6
- **Keyword Score**: 3
- **Authors**: Yongzhi Jin, Kazushi Okamoto, Kei Harada, Atsushi Shibata, Koki Karube
- **URL**: <http://arxiv.org/abs/2508.16106v1>
- **Submitted**: 2025-08-22 05:47:42
- **Comment**: Submitted to Journal of Advanced Computational Intelligence and
  Intelligent Informatics
- **Topic Keywords**: user action, recommend
- **Reason**: The paper proposes a supervised session segmentation method for behavior logs, which is related to user behavior modeling and recommender systems. However, it does not directly address query understanding, ranking models, or deep semantic understanding, which are core aspects of your research interests.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Supervised User Session Segmentation for Information Recommendation Systems
- **Aim**: Capture dynamic user behaviors by identifying session boundaries in user interaction sequences
- **Rationale**: Existing approaches rely solely on heuristic time thresholds or narrow window sizes, and do not incorporate item-level information
- **Ground**: Item embeddings, point-wise feature extraction, and supervised classification models
- **Experiment**: Evaluation on a manually annotated dataset from real user browsing histories, with comparison to existing baselines
- **Takeaway**: The proposed method outperforms existing approaches and provides a more comprehensive approach to session segmentation by incorporating item-level information and leveraging machine learning models

#### Abstract
> In information recommendation, a session refers to a sequence of user actions
within a specific time frame. Session-based recommender systems aim to capture
short-term preferences and generate relevant recommendations. However, user
interests may shift even within a session, making appropriate segmentation
essential for modeling dynamic behaviors. In this study, we propose a
supervised session segmentation method based on similarity features derived
from action embeddings and attributes. We compute the similarity scores between
items within a fixed-size window around each candidate segmentation point,
using four types of features: item co-occurrence embeddings, text embeddings of
titles and brands, and price. These features are used to train supervised
classifiers (LightGBM, XGBoost, CatBoost, support vector machine, and logistic
regression) to predict the session boundaries. We construct a manually
annotated dataset from real user browsing histories and evaluate the
segmentation performance using F1-score, area under the precision-recall curve
(PR-AUC), and area under the receiver operating characteristic curve. The
LightGBM model achieves the best performance, with an F1-score of 0.806 and a
PR-AUC of 0.831. These results demonstrate the effectiveness of the proposed
method for session segmentation and its potential to capture dynamic user
behaviors.

---

### 3. Retrieval Enhanced Feedback via In-context Neural Error-book

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Jongyeop Hyun, Bumsoo Kim
- **URL**: <http://arxiv.org/abs/2508.16313v1>
- **Submitted**: 2025-08-22 11:50:04
- **Comment**: Accepted at EMNLP 2025 main conference
- **Topic Keywords**: queries, rag, retrieval, search
- **Reason**: The paper proposes a framework for learning from errors in Large Language Models, which is related to query understanding and ranking models in Information Retrieval. However, the focus is on multimodal reasoning and error analysis, which is not directly aligned with the user's primary interests in search technologies and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Enhancing Multimodal Reasoning in Large Language Models (LLMs) using the REFINE Framework
- **Aim**: To develop a novel teacher-student approach that provides structured feedback to improve multimodal reasoning in LLMs
- **Rationale**: Existing methods lack a systematic approach to analyzing and mitigating errors, particularly in Multimodal LLMs
- **Ground**: The REFINE framework consists of three stages: Structured Feedback Generation, Feedback Filtering, and Neural Error-book Construction
- **Experiment**: The authors evaluate the effectiveness of their feedback mechanisms using three multimodal reasoning benchmarks and report significant improvements in accuracy compared to baseline methods
- **Takeaway**: The REFINE framework provides a novel approach to enhancing multimodal reasoning in LLMs by providing structured feedback that is task-specific, efficient, and scalable

#### Abstract
> Recent advancements in Large Language Models (LLMs) have significantly
improved reasoning capabilities, with in-context learning (ICL) emerging as a
key technique for adaptation without retraining. While previous works have
focused on leveraging correct examples, recent research highlights the
importance of learning from errors to enhance performance. However, existing
methods lack a structured framework for analyzing and mitigating errors,
particularly in Multimodal Large Language Models (MLLMs), where integrating
visual and textual inputs adds complexity. To address this issue, we propose
REFINE: Retrieval-Enhanced Feedback via In-context Neural Error-book, a
teacher-student framework that systematically structures errors and provides
targeted feedback. REFINE introduces three systematic queries to construct
structured feedback -- Feed-Target, Feed-Check, and Feed-Path -- to enhance
multimodal reasoning by prioritizing relevant visual information, diagnosing
critical failure points, and formulating corrective actions. Unlike prior
approaches that rely on redundant retrievals, REFINE optimizes structured
feedback retrieval, improving inference efficiency, token usage, and
scalability. Our results demonstrate substantial speedup, reduced computational
costs, and successful generalization, highlighting REFINE's potential for
enhancing multimodal reasoning.

---

### 4. ORCA: Mitigating Over-Reliance for Multi-Task Dwell Time Prediction with Causal Decoupling

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Huishi Luo, Fuzhen Zhuang, Yongchun Zhu, Yiqing Wu, Bo Kang, Ruobing Xie, Feng Xia, Deqing Wang, Jin Dong
- **URL**: <http://arxiv.org/abs/2508.16573v1>
- **Submitted**: 2025-08-22 17:56:01
- **Comment**: Accepted as a short paper at CIKM 2025
- **Topic Keywords**: rag, click, ctr, recommend
- **Reason**: The paper focuses on dwell time prediction in recommender systems, which is somewhat related to my interests in Information Retrieval and Search technologies. However, the paper's primary focus is on recommender systems and dwell time prediction, which is not a central match for my research themes. The paper's use of causal-decoupling and counterfactual intervention is interesting, but it does not directly relate to my interests in query understanding, ranking models, and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Mitigating Over-Reliance on Click-Through Rate in Multi-Task Learning Recommender Systems
- **Aim**: To develop a novel method to mitigate the over-reliance of dwell time prediction on click-through rate in multi-task learning recommender systems
- **Rationale**: Multi-task learning models tend to collapse dwell time predictions to the shortest and longest bins, under-predicting moderate durations, due to task imbalance, optimization bias, and spurious correlations from causal entanglement
- **Ground**: Recent advancements in recommender systems, targeted display advertising, and data mining, including modeling sequential dependence, reweighting clicks, attribute-aware counterfactual augmentation, and debiasing post-click conversion rate estimation
- **Experiment**: Evaluating ORCA on three datasets, comparing it to various single-task and multi-task models, with an average 10.6% uplift in dwell time metrics without harming click-through rate
- **Takeaway**: ORCA is a novel, model-agnostic, and easy-to-deploy method that mitigates the negative transfer effect in multi-task learning for recommender systems, restoring beneficial dwell time semantic capacity without compromising click-through rate performance

#### Abstract
> Dwell time (DT) is a critical post-click metric for evaluating user
preference in recommender systems, complementing the traditional click-through
rate (CTR). Although multi-task learning is widely adopted to jointly optimize
DT and CTR, we observe that multi-task models systematically collapse their DT
predictions to the shortest and longest bins, under-predicting the moderate
durations. We attribute this moderate-duration bin under-representation to
over-reliance on the CTR-DT spurious correlation, and propose ORCA to address
it with causal-decoupling. Specifically, ORCA explicitly models and subtracts
CTR's negative transfer while preserving its positive transfer. We further
introduce (i) feature-level counterfactual intervention, and (ii) a
task-interaction module with instance inverse-weighting, weakening CTR-mediated
effect and restoring direct DT semantics. ORCA is model-agnostic and easy to
deploy. Experiments show an average 10.6% lift in DT metrics without harming
CTR. Code is available at
https://github.com/Chrissie-Law/ORCA-Mitigating-Over-Reliance-for-Multi-Task-Dwell-Time-Prediction-with-Causal-Decoupling.

---

### 5. Spacetime-GR: A Spacetime-Aware Generative Model for Large Scale Online POI Recommendation

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Haitao Lin, Zhen Yang, Jiawei Xue, Ziji Zhang, Luzhu Wang, Yikun Gu, Yao Xu, Xin Li
- **URL**: <http://arxiv.org/abs/2508.16126v1>
- **Submitted**: 2025-08-22 06:37:57
- **Topic Keywords**: ranking, user action, recommend, rank
- **Reason**: The paper proposes a spacetime-aware generative model for POI recommendation, which is somewhat related to information retrieval and search technologies. However, the focus on POI recommendation and geographic-aware indexing strategy is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Spacetime-GR: A Spacetime-Aware Generative Model for Large-Scale Online Point-of-Interest Recommendation
- **Aim**: To develop a model that addresses the challenges of modeling a large vocabulary of POIs, learning spatiotemporal sensitivity, and encoding sufficient POI information
- **Rationale**: The proposed model, Spacetime-GR, incorporates flexible spatiotemporal information encoding methods, including a geographic-aware hierarchical POI indexing strategy, a novel spatiotemporal encoding module, and LLM-encoded multimodal POI embeddings
- **Ground**: The model is trained using a two-stage paradigm: pre-training and fine-tuning, and evaluated on both public benchmark datasets and large-scale industrial datasets
- **Experiment**: The authors conduct an ablation study to analyze the impact of the alignment stage on the model's joint recall and ranking ability, and investigate the influence of input sequence length on the model's performance
- **Takeaway**: Spacetime-GR demonstrates superior performance in terms of POI recommendation accuracy and ranking quality, and its ability to incorporate spatiotemporal information and geographic-aware hierarchical POI indexing makes it a promising approach for large-scale online POI recommendation

#### Abstract
> Building upon the strong sequence modeling capability, Generative
Recommendation (GR) has gradually assumed a dominant position in the
application of recommendation tasks (e.g., video and product recommendation).
However, the application of Generative Recommendation in Point-of-Interest
(POI) recommendation, where user preferences are significantly affected by
spatiotemporal variations, remains a challenging open problem. In this paper,
we propose Spacetime-GR, the first spacetime-aware generative model for
large-scale online POI recommendation. It extends the strong sequence modeling
ability of generative models by incorporating flexible spatiotemporal
information encoding. Specifically, we first introduce a geographic-aware
hierarchical POI indexing strategy to address the challenge of large vocabulary
modeling. Subsequently, a novel spatiotemporal encoding module is introduced to
seamlessly incorporate spatiotemporal context into user action sequences,
thereby enhancing the model's sensitivity to spatiotemporal variations.
Furthermore, we incorporate multimodal POI embeddings to enrich the semantic
understanding of each POI. Finally, to facilitate practical deployment, we
develop a set of post-training adaptation strategies after sufficient
pre-training on action sequences. These strategies enable Spacetime-GR to
generate outputs in multiple formats (i.e., embeddings, ranking scores and POI
candidates) and support a wide range of downstream application scenarios (i.e.,
ranking and end-to-end recommendation). We evaluate the proposed model on both
public benchmark datasets and large-scale industrial datasets, demonstrating
its superior performance over existing methods in terms of POI recommendation
accuracy and ranking quality. Furthermore, the model is the first generative
model deployed in online POI recommendation services that scale to hundreds of
millions of POIs and users.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Text Takes Over: A Study of Modality Bias in Multimodal Intent Detection

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Ankan Mullick, Saransh Sharma, Abhik Jana, Pawan Goyal
- **URL**: <http://arxiv.org/abs/2508.16122v1>
- **Submitted**: 2025-08-22 06:29:29
- **Comment**: EMNLP 2025 Main Conference Full Paper
- **Topic Keywords**: relevance, trec
- **Reason**: The paper focuses on multimodal intent detection, which is not directly related to the user's primary interest in Information Retrieval and Search technologies. While it touches on the topic of bias in datasets, the specific context of multimodal intent detection and the use of Large Language Models are not directly applicable to the user's research areas.

#### Abstract
> The rise of multimodal data, integrating text, audio, and visuals, has
created new opportunities for studying multimodal tasks such as intent
detection. This work investigates the effectiveness of Large Language Models
(LLMs) and non-LLMs, including text-only and multi-modal models, in the
multimodal intent detection task. Our study reveals that Mistral-7B, a
text-only LLM, outperforms most competitive multimodal models by approximately
9% on MIntRec-1 and 4% on MIntRec2.0 datasets. This performance advantage comes
from a strong textual bias in these datasets, where over 90% of the samples
require textual input, either alone or in combination with other modalities,
for correct classification. We confirm the modality bias of these datasets via
human evaluation, too. Next, we propose a framework to debias the datasets, and
upon debiasing, more than 70% of the samples in MIntRec-1 and more than 50% in
MIntRec2.0 get removed, resulting in significant performance degradation across
all models, with smaller multimodal fusion models being the most affected with
an accuracy drop of over 50 - 60%. Further, we analyze the context-specific
relevance of different modalities through empirical analysis. Our findings
highlight the challenges posed by modality bias in multimodal intent datasets
and emphasize the need for unbiased datasets to evaluate multimodal models
effectively.

### 7. ParamBench: A Graduate-Level Benchmark for Evaluating LLM Understanding on Indic Subjects

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Kaushal Sharma, Vivek Patel, Ayush Maheshwari, Aditya Maheshwari
- **URL**: <http://arxiv.org/abs/2508.16185v1>
- **Submitted**: 2025-08-22 07:59:37
- **Topic Keywords**: queries
- **Reason**: The paper focuses on evaluating large language models' understanding on graduate-level questions in the Indian context, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on topics like question understanding and ranking models, the primary focus is on evaluating language models' comprehension rather than developing new IR or NLP techniques.

#### Abstract
> Large language models (LLMs) have been widely evaluated on tasks such as
comprehension, question answering, summarization, code generation, etc.
However, their performance on graduate-level, culturally grounded questions in
the Indian context remains largely unexplored. Existing Indian benchmarks
emphasise basic fact-orientated queries that offer limited assessment of a
deeper disciplinary understanding tailored to the Indian setting. In this
paper, we present ParamBench, consisting of around 11.5K questions in Hindi
language comprising questionnaires from 16 diverse subjects. These questions
are primarily derived from nation-wide graduate level entrance examination
covering topics such as history, music, instruments, yoga, literature,
philosophy, law, etc., specifically for the Indian context. Additionally, we
assess the ability of LLMs to handle diverse question formats-such as
list-based matching, assertion-reason pairs, and sequence ordering-alongside
conventional multiple-choice questions. We evaluated the performance of more
than 17 open source LLMs on this benchmark, observing that Llama 3.3 70B
attains the highest overall accuracy of 48%. Furthermore, subject-wise analysis
indicates that even for the best performing LLMs, performance remains weak on
topics such as music, classical instruments, politics and archaeology,
underscoring persistent challenges in culturally grounded reasoning.

### 8. EGRA:Toward Enhanced Behavior Graphs and Representation Alignment for Multimodal Recommendation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Xiaoxiong Zhang, Xin Zhou, Zhiwei Zeng, Yongjie Wang, Dusit Niyato, Zhiqi Shen
- **URL**: <http://arxiv.org/abs/2508.16170v1>
- **Submitted**: 2025-08-22 07:47:54
- **Topic Keywords**: rag, recommend
- **Reason**: The paper focuses on Multimodal Recommendation, which is not directly related to Information Retrieval or Search technologies. While it mentions behavior graphs and representation alignment, the context is different from query understanding, ranking models, and user behavior modeling. The paper's relevance is somewhat limited, but it may still be of interest to those working on recommender systems.

#### Abstract
> MultiModal Recommendation (MMR) systems have emerged as a promising solution
for improving recommendation quality by leveraging rich item-side modality
information, prompting a surge of diverse methods. Despite these advances,
existing methods still face two critical limitations. First, they use raw
modality features to construct item-item links for enriching the behavior
graph, while giving limited attention to balancing collaborative and
modality-aware semantics or mitigating modality noise in the process. Second,
they use a uniform alignment weight across all entities and also maintain a
fixed alignment strength throughout training, limiting the effectiveness of
modality-behavior alignment. To address these challenges, we propose EGRA.
First, instead of relying on raw modality features, it alleviates sparsity by
incorporating into the behavior graph an item-item graph built from
representations generated by a pretrained MMR model. This enables the graph to
capture both collaborative patterns and modality aware similarities with
enhanced robustness against modality noise. Moreover, it introduces a novel
bi-level dynamic alignment weighting mechanism to improve modality-behavior
representation alignment, which dynamically assigns alignment strength across
entities according to their alignment degree, while gradually increasing the
overall alignment intensity throughout training. Extensive experiments on five
datasets show that EGRA significantly outperforms recent methods, confirming
its effectiveness.

### 9. OpenWHO: A Document-Level Parallel Corpus for Health Translation in Low-Resource Languages

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Rapha√´l Merx, Hanna Suominen, Trevor Cohn, Ekaterina Vylomova
- **URL**: <http://arxiv.org/abs/2508.16048v1>
- **Submitted**: 2025-08-22 02:53:56
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on machine translation in the health domain, which is related to information retrieval, but the scope is limited to translation and does not directly address query understanding, ranking models, or user behavior modeling. The paper's emphasis on low-resource languages and large language models is also not directly relevant to the user's interests in e-commerce and real-time relevance optimization.

#### Abstract
> In machine translation (MT), health is a high-stakes domain characterised by
widespread deployment and domain-specific vocabulary. However, there is a lack
of MT evaluation datasets for low-resource languages in this domain. To address
this gap, we introduce OpenWHO, a document-level parallel corpus of 2,978
documents and 26,824 sentences from the World Health Organization's e-learning
platform. Sourced from expert-authored, professionally translated materials
shielded from web-crawling, OpenWHO spans a diverse range of over 20 languages,
of which nine are low-resource. Leveraging this new resource, we evaluate
modern large language models (LLMs) against traditional MT models. Our findings
reveal that LLMs consistently outperform traditional MT models, with Gemini 2.5
Flash achieving a +4.79 ChrF point improvement over NLLB-54B on our
low-resource test set. Further, we investigate how LLM context utilisation
affects accuracy, finding that the benefits of document-level translation are
most pronounced in specialised domains like health. We release the OpenWHO
corpus to encourage further research into low-resource MT in the health domain.

### 10. LLM-as-classifier: Semi-Supervised, Iterative Framework for Hierarchical Text Classification using Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Doohee You, Andy Parisi, Zach Vander Velden, Lara Dantas Inojosa
- **URL**: <http://arxiv.org/abs/2508.16478v1>
- **Submitted**: 2025-08-22 15:47:17
- **Comment**: 20 pages excluding reference list, 2 figures
- **Topic Keywords**: rag
- **Reason**: The paper focuses on leveraging Large Language Models for hierarchical text classification, which is a relevant topic in Natural Language Processing. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core aspects of Information Retrieval. The paper's emphasis on practical applications and industry challenges is somewhat related to the e-commerce domain, but the connection is loose.

#### Abstract
> The advent of Large Language Models (LLMs) has provided unprecedented
capabilities for analyzing unstructured text data. However, deploying these
models as reliable, robust, and scalable classifiers in production environments
presents significant methodological challenges. Standard fine-tuning approaches
can be resource-intensive and often struggle with the dynamic nature of
real-world data distributions, which is common in the industry. In this paper,
we propose a comprehensive, semi-supervised framework that leverages the zero-
and few-shot capabilities of LLMs for building hierarchical text classifiers as
a framework for a solution to these industry-wide challenges. Our methodology
emphasizes an iterative, human-in-the-loop process that begins with domain
knowledge elicitation and progresses through prompt refinement, hierarchical
expansion, and multi-faceted validation. We introduce techniques for assessing
and mitigating sequence-based biases and outline a protocol for continuous
monitoring and adaptation. This framework is designed to bridge the gap between
the raw power of LLMs and the practical need for accurate, interpretable, and
maintainable classification systems in industry applications.

### 11. M3TQA: Massively Multilingual Multitask Table Question Answering

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Daixin Shu, Jian Yang, Zhenhe Wu, Xianjie Wu, Xianfu Cheng, Xiangyuan Guan, Yanghai Wang, Pengfei Wu, Tingyang Yang, Hualei Zhu, Wei Zhang, Ge Zhang, Jiaheng Liu, Zhoujun Li
- **URL**: <http://arxiv.org/abs/2508.16265v1>
- **Submitted**: 2025-08-22 09:57:40
- **Topic Keywords**: search
- **Reason**: The paper focuses on multilingual table question answering, which is not directly related to my primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on topics like query understanding and ranking models, the context is different and not as relevant to my core research themes.

#### Abstract
> Tabular data is a fundamental component of real-world information systems,
yet most research in table understanding remains confined to English, leaving
multilingual comprehension significantly underexplored. Existing multilingual
table benchmarks suffer from geolinguistic imbalance - overrepresenting certain
languages and lacking sufficient scale for rigorous cross-lingual analysis. To
address these limitations, we introduce a comprehensive framework for massively
multilingual multitask table question answering, featuring m3TQA-Instruct, a
large-scale benchmark spanning 97 languages across diverse language families,
including underrepresented and low-resource languages. We construct m3TQA by
curating 50 real-world tables in Chinese and English, then applying a robust
six-step LLM-based translation pipeline powered by DeepSeek and GPT-4o,
achieving high translation fidelity with a median BLEU score of 60.19 as
validated through back-translation. The benchmark includes 2,916 professionally
annotated question-answering pairs across four tasks designed to evaluate
nuanced table reasoning capabilities. Experiments on state-of-the-art LLMs
reveal critical insights into cross-lingual generalization, demonstrating that
synthetically generated, unannotated QA data can significantly boost
performance, particularly for low-resource languages. M3T-Bench establishes a
new standard for multilingual table understanding, providing both a challenging
evaluation platform and a scalable methodology for future research.

### 12. Modeling User Preferences as Distributions for Optimal Transport-based Cross-domain Recommendation under Non-overlapping Settings

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Ziyin Xiao, Toyotaro Suzumura
- **URL**: <http://arxiv.org/abs/2508.16210v1>
- **Submitted**: 2025-08-22 08:32:13
- **Topic Keywords**: recommend
- **Reason**: The paper focuses on Cross-Domain Recommender systems, which is a related topic to Information Retrieval. However, the emphasis on user preferences and Gaussian mixtures is not directly aligned with my interests in query understanding, ranking models, and user behavior modeling. The paper's abstract does not mention search technologies or real-time relevance optimization, which are key aspects of my research.

#### Abstract
> Cross-Domain Recommender (CDR) systems aim to transfer knowledge from dense
to sparse domains, alleviating data sparsity and cold-start issues in
single-domain recommendation. While many methods assume overlapping users or
items to connect domains, this is often unrealistic in real-world settings.
Thus, non-overlapping CDR systems, which require no shared users or items, are
needed.
  However, non-overlapping CDR is challenging due to: (1) the absence of
overlap preventing direct bridges between domains, and (2) large distributional
discrepancies degrading transfer performance. Moreover, most recommenders
represent user preferences as discrete vectors, failing to capture their
fine-grained, multi-faceted nature.
  We propose DUP-OT (Distributional User Preferences with Optimal Transport), a
framework for non-overlapping CDR. DUP-OT has three stages: (1) Shared
Preprocessing, where review-based embeddings and an autoencoder encode users
and items from both domains; (2) User GMM Weight Learning, which models user
preferences as Gaussian mixtures with learned weights; and (3) Cross-domain
Rating Prediction, where optimal transport aligns Gaussian components across
domains, enabling preference transfer from source to target.
  Experiments on Amazon review datasets show that DUP-OT effectively mitigates
domain discrepancy and outperforms state-of-the-art baselines under the
non-overlapping CDR setting.

### 13. Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 8
- **Authors**: Guangyu Yang, Jinghong Chen, Jingbiao Mei, Weizhe Lin, Bill Byrne
- **URL**: <http://arxiv.org/abs/2508.16406v1>
- **Submitted**: 2025-08-22 14:13:16
- **Topic Keywords**: query, queries, retrieval
- **Reason**: The paper focuses on defense mechanisms for Large Language Models against jailbreak attacks, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions retrieval-augmented generation, the context is different from traditional IR and NLP applications.

#### Abstract
> Large Language Models (LLMs) remain vulnerable to jailbreak attacks, which
attempt to elicit harmful responses from LLMs. The evolving nature and
diversity of these attacks pose many challenges for defense systems, including
(1) adaptation to counter emerging attack strategies without costly retraining,
and (2) control of the trade-off between safety and utility. To address these
challenges, we propose Retrieval-Augmented Defense (RAD), a novel framework for
jailbreak detection that incorporates a database of known attack examples into
Retrieval-Augmented Generation, which is used to infer the underlying,
malicious user query and jailbreak strategy used to attack the system. RAD
enables training-free updates for newly discovered jailbreak strategies and
provides a mechanism to balance safety and utility. Experiments on StrongREJECT
show that RAD substantially reduces the effectiveness of strong jailbreak
attacks such as PAP and PAIR while maintaining low rejection rates for benign
queries. We propose a novel evaluation scheme and show that RAD achieves a
robust safety-utility trade-off across a range of operating points in a
controllable manner.

### 14. MCPVerse: An Expansive, Real-World Benchmark for Agentic Tool Use

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Fei Lei, Yibo Yang, Wenxiu Sun, Dahua Lin
- **URL**: <http://arxiv.org/abs/2508.16260v1>
- **Submitted**: 2025-08-22 09:47:53
- **Topic Keywords**: rag, acl
- **Reason**: The paper focuses on evaluating Large Language Models' ability to use external tools, which is not directly related to Information Retrieval, Search technologies, or query understanding. Although it mentions real-time relevance optimization, the context is different from the user's primary research interests.

#### Abstract
> Large Language Models (LLMs) are evolving from text generators into reasoning
agents. This transition makes their ability to use external tools a critical
capability. However, evaluating this skill presents a significant challenge.
Existing benchmarks are often limited by their reliance on synthetic tools and
severely constrained action spaces. To address these limitations, we introduce
MCPVerse, an expansive, real-world benchmark for evaluating agentic tool use.
MCPVerse integrates more than 550 real-world, executable tools to create an
unprecedented action space exceeding 140k tokens, and employs outcome-based
evaluation with real-time ground truth for time-sensitive tasks. We benchmarked
the state-of-the-art LLMs across three modes (Oracle, Standard, and Max-Scale),
revealing that while most models suffer performance degradation when confronted
with larger tool sets, the agentic models, such as Claude-4-Sonnet, can
effectively leverage expanded exploration spaces to improve accuracy. This
finding not only exposes the limitations of state-of-the-art models in complex,
real-world scenarios but also establishes MCPVerse as a critical benchmark for
measuring and advancing agentic tool use capabilities.

### 15. LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Alisa Vinogradova, Vlad Vinogradov, Dmitrii Radkevich, Ilya Yasny, Dmitry Kobyzev, Ivan Izmailov, Katsiaryna Yanchanka, Andrey Doronichev
- **URL**: <http://arxiv.org/abs/2508.16571v1>
- **Submitted**: 2025-08-22 17:50:00
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on a specific domain (drug asset due diligence) and uses Large Language Models (LLMs) for competitor discovery, which is not directly related to your areas of interest.

#### Abstract
> In this paper, we describe and benchmark a competitor-discovery component
used within an agentic AI system for fast drug asset due diligence. A
competitor-discovery AI agent, given an indication, retrieves all drugs
comprising the competitive landscape of that indication and extracts canonical
attributes for these drugs. The competitor definition is investor-specific, and
data is paywalled/licensed, fragmented across registries, ontology-mismatched
by indication, alias-heavy for drug names, multimodal, and rapidly changing.
Although considered the best tool for this problem, the current LLM-based AI
systems aren't capable of reliably retrieving all competing drug names, and
there is no accepted public benchmark for this task. To address the lack of
evaluation, we use LLM-based agents to transform five years of multi-modal,
unstructured diligence memos from a private biotech VC fund into a structured
evaluation corpus mapping indications to competitor drugs with normalized
attributes. We also introduce a competitor validating LLM-as-a-judge agent that
filters out false positives from the list of predicted competitors to maximize
precision and suppress hallucinations. On this benchmark, our
competitor-discovery agent achieves 83% recall, exceeding OpenAI Deep Research
(65%) and Perplexity Labs (60%). The system is deployed in production with
enterprise users; in a case study with a biotech VC investment fund, analyst
turnaround time dropped from 2.5 days to $\sim$3 hours ($\sim$20x) for the
competitive analysis.

### 16. A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Lin Li, Chunyang Li, Yu Yin, Xiaohui Tao, Jianwei Zhang
- **URL**: <http://arxiv.org/abs/2508.16516v1>
- **Submitted**: 2025-08-22 16:39:53
- **Topic Keywords**: rag, recommend
- **Reason**: The paper focuses on graph-based collaborative filtering and quantization methods, which is not directly related to information retrieval, search technologies, or query understanding. While it does involve neural networks, the application is in recommender systems, which is a secondary interest. The paper's emphasis on graph structure and node-aware dynamic quantization is not aligned with the user's primary research themes.

#### Abstract
> In the realm of collaborative filtering recommendation systems, Graph Neural
Networks (GNNs) have demonstrated remarkable performance but face significant
challenges in deployment on resource-constrained edge devices due to their high
embedding parameter requirements and computational costs. Using common
quantization method directly on node embeddings may overlooks their graph based
structure, causing error accumulation during message passing and degrading the
quality of quantized embeddings.To address this, we propose Graph based
Node-Aware Dynamic Quantization training for collaborative filtering (GNAQ), a
novel quantization approach that leverages graph structural information to
enhance the balance between efficiency and accuracy of GNNs for Top-K
recommendation. GNAQ introduces a node-aware dynamic quantization strategy that
adapts quantization scales to individual node embeddings by incorporating graph
interaction relationships. Specifically, it initializes quantization intervals
based on node-wise feature distributions and dynamically refines them through
message passing in GNN layers. This approach mitigates information loss caused
by fixed quantization scales and captures hierarchical semantic features in
user-item interaction graphs. Additionally, GNAQ employs graph relation-aware
gradient estimation to replace traditional straight-through estimators,
ensuring more accurate gradient propagation during training. Extensive
experiments on four real-world datasets demonstrate that GNAQ outperforms
state-of-the-art quantization methods, including BiGeaR and N2UQ, by achieving
average improvement in 27.8\% Recall@10 and 17.6\% NDCG@10 under 2-bit
quantization. In particular, GNAQ is capable of maintaining the performance of
full-precision models while reducing their model sizes by 8 to 12 times; in
addition, the training time is twice as fast compared to quantization baseline
methods.

### 17. AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Zihan Wang, Jiaze Chen, Zhicheng Liu, Markus Mak, Yidi Du, Geonsik Moon, Luoqi Xu, Aaron Tua, Kunshuo Peng, Jiayi Lu, Mingfei Xia, Boqian Zou, Chenyang Ran, Guang Tian, Shoutai Zhu, Yeheng Duan, Zhenghui Kang, Zhenxing Lin, Shangshu Li, Qiang Luo, Qingshen Long, Zhiyong Chen, Yihan Xiao, Yurong Wu, Daoguang Zan, Yuyi Fu, Mingxuan Wang, Ming Ding
- **URL**: <http://arxiv.org/abs/2508.16402v1>
- **Submitted**: 2025-08-22 14:04:55
- **Comment**: 15 pages
- **Topic Keywords**: rag, search
- **Reason**: The paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, and Natural Language Processing. The topic of competitive programming and Large Language Models is not directly related to the user's areas of focus.

#### Abstract
> Competitive programming has emerged as a critical benchmark for evaluating
the reasoning and coding capabilities of Large Language Models (LLMs). Despite
impressive progress on existing benchmarks, we argue that current evaluations
overstate model proficiency, masking a substantial gap between LLMs and elite
human programmers. This gap arises from two key limitations: insufficient
difficulty and scope of benchmark problems, and evaluation bias from
low-quality test cases. To address these shortcomings, we present AetherCode, a
new benchmark that draws problems from premier programming competitions such as
IOI and ICPC, offering broader coverage and higher difficulty. AetherCode
further incorporates comprehensive, expert-validated test suites built through
a hybrid of automated generation and human curation, ensuring rigorous and
reliable assessment. By combining challenging problem design with robust
evaluation, AetherCode provides a more faithful measure of LLM capabilities and
sets a new standard for future research in code reasoning.

### 18. AgentFly: Fine-tuning LLM Agents without Fine-tuning LLMs

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Huichi Zhou, Yihang Chen, Siyuan Guo, Xue Yan, Kin Hei Lee, Zihan Wang, Ka Yiu Lee, Guchun Zhang, Kun Shao, Linyi Yang, Jun Wang
- **URL**: <http://arxiv.org/abs/2508.16153v1>
- **Submitted**: 2025-08-22 07:25:30
- **Topic Keywords**: retrieval, search
- **Reason**: The paper focuses on developing a novel learning paradigm for adaptive Large Language Model (LLM) agents, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions reinforcement learning and memory-based online learning, these concepts are not typically used in IR and Search. The paper's focus on LLM agents and machine learning is more relevant to NLP and data mining, but it does not align with the user's specific interests in ranking models, user behavior modeling, or real-time relevance optimization.

#### Abstract
> In this paper, we introduce a novel learning paradigm for adaptive Large
Language Model (LLM) agents that eliminates the need for fine-tuning the
underlying LLMs. Existing approaches are often either rigid, relying on static,
handcrafted reflection workflows, or computationally intensive, requiring
gradient updates of LLM model parameters. In contrast, our method enables
low-cost continual adaptation via memory-based online reinforcement learning.
We formalise this as a Memory-augmented Markov Decision Process (M-MDP),
equipped with a neural case-selection policy to guide action decisions. Past
experiences are stored in an episodic memory, either differentiable or
non-parametric. The policy is continually updated based on environmental
feedback through a memory rewriting mechanism, whereas policy improvement is
achieved through efficient memory reading (retrieval). We instantiate our agent
model in the deep research setting, namely AgentFly, which attains top-1 on
GAIA validation ($87.88\%$ Pass@$3$) and $79.40\%$ on the test set. It reaches
$66.6\%$ F1 and $80.4\%$ PM on the DeepResearcher dataset, outperforming the
state-of-the-art training-based method, while case-based memory adds $4.7\%$ to
$9.6\%$ absolute points on out-of-distribution tasks. Our approach offers a
scalable and efficient pathway for developing generalist LLM agents capable of
continuous, real-time learning without gradient updates, advancing machine
learning towards open-ended skill acquisition and deep research scenarios. The
code is available at https://github.com/Agent-on-the-Fly/AgentFly.

### 19. Extending FKG.in: Towards a Food Claim Traceability Network

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Saransh Kumar Gupta, Rizwan Gulzar Mir, Lipika Dey, Partha Pratim Das, Anirban Sen, Ramesh Jain
- **URL**: <http://arxiv.org/abs/2508.16117v1>
- **Submitted**: 2025-08-22 06:18:51
- **Comment**: 10 pages, 3 figures, 1 table, 45 references, ACM International
  Conference on Multimedia 2025 - Multi-modal Food Computing Workshop
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topic of food claim traceability network is outside the scope of your expertise and does not involve query understanding, ranking models, or user behavior modeling.

#### Abstract
> The global food landscape is rife with scientific, cultural, and commercial
claims about what foods are, what they do, what they should not do, or should
not do. These range from rigorously studied health benefits (probiotics improve
gut health) and misrepresentations (soaked almonds make one smarter) to vague
promises (superfoods boost immunity) and culturally rooted beliefs (cold foods
cause coughs). Despite their widespread influence, the infrastructure for
tracing, verifying, and contextualizing these claims remains fragmented and
underdeveloped. In this paper, we propose a Food Claim-Traceability Network
(FCN) as an extension of FKG.in, a knowledge graph of Indian food that we have
been incrementally building. We also present the ontology design and the
semi-automated knowledge curation workflow that we used to develop a proof of
concept of FKG.in-FCN using Reddit data and Large Language Models. FCN
integrates curated data inputs, structured schemas, and provenance-aware
pipelines for food-related claim extraction and validation. While directly
linked to the Indian food knowledge graph as an application, our methodology
remains application-agnostic and adaptable to other geographic, culinary, or
regulatory settings. By modeling food claims and their traceability in a
structured, verifiable, and explainable way, we aim to contribute to more
transparent and accountable food knowledge ecosystems, supporting researchers,
policymakers, and most importantly, everyday consumers in navigating a world
saturated with dietary assertions.

### 20. Less Redundancy: Boosting Practicality of Vision Language Model in Walking Assistants

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Chongyang Li, Yuan Zhiqiang, Jiapei Zhang, Ying Deng, Hanbo Bi, Zexi Jia, Xiaoyue Duan, Peixiang Luo, Jinchao Zhang
- **URL**: <http://arxiv.org/abs/2508.16070v1>
- **Submitted**: 2025-08-22 03:56:30
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on Visual Language Models for walking assistance systems, which is not related to Information Retrieval, Search technologies, or Natural Language Processing. The concepts of query understanding, ranking models, and user behavior modeling are not addressed in this paper.

#### Abstract
> Approximately 283 million people worldwide live with visual impairments,
motivating increasing research into leveraging Visual Language Models (VLMs) to
develop effective walking assistance systems for blind and low vision
individuals. However, existing VLMs in walking assistant task often have
outputs that contain considerable redundancy and extraneous details, adversely
affecting users' ability to accurately assess their surroundings. Moreover,
these models typically lack the capability to proactively assess environmental
risks and adaptively trigger reminders based on the appropriate scene, leading
to excessive temporal redundancy. To mitigate output and temporal redundancy,
we propose WalkVLM-LR, a walking assistance model with less redundancy. To
reduce output redundancy, we introduce four human-preference-based custom
reward functions within the GRPO-based reasoning framework to optimize the
output in terms of conciseness, fluency, keyword density, and accuracy, thereby
producing more informative and streamlined outputs. To minimize temporal
redundancy, we incorporate an environment awareness discriminator, which shares
the visual encoder with the VLMs to reduce redundant computations and enhance
discriminative efficiency, to make WalkVLM-LR assess scene risk levels and
minimize unnecessary reminders. Experimental results demonstrate that our
method achieves state-of-the-art performance across all evaluation metrics
compared with other models, particularly in output conciseness and less
temporal redundancy.

### 21. Sparse but Wrong: Incorrect L0 Leads to Incorrect Features in Sparse Autoencoders

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: David Chanin, Adri√† Garriga-Alonso
- **URL**: <http://arxiv.org/abs/2508.16560v1>
- **Submitted**: 2025-08-22 17:26:33
- **Topic Keywords**: rag
- **Reason**: The paper focuses on sparse autoencoders and their training hyperparameters, which is not directly related to information retrieval, search technologies, or query understanding. The topic is more relevant to natural language processing and deep learning, but the specific context and methodology are not aligned with the user's research interests.

#### Abstract
> Sparse Autoencoders (SAEs) extract features from LLM internal activations,
meant to correspond to single concepts. A core SAE training hyperparameter is
L0: how many features should fire per token on average. Existing work compares
SAE algorithms using sparsity--reconstruction tradeoff plots, implying L0 is a
free parameter with no single correct value. In this work we study the effect
of L0 on BatchTopK SAEs, and show that if L0 is not set precisely, the SAE
fails to learn the underlying features of the LLM. If L0 is too low, the SAE
will mix correlated features to improve reconstruction. If L0 is too high, the
SAE finds degenerate solutions that also mix features. Further, we demonstrate
a method to determine the correct L0 value for an SAE on a given training
distribution, which finds the true L0 in toy models and coincides with peak
sparse probing performance in LLMs. We find that most commonly used SAEs have
an L0 that is too low. Our work shows that, to train SAEs with correct
features, practitioners must set L0 correctly.

### 22. FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Parker Seegmiller, Kartik Mehta, Soumya Saha, Chenyang Tao, Shereen Oraby, Arpit Gupta, Tagyoung Chung, Mohit Bansal, Nanyun Peng
- **URL**: <http://arxiv.org/abs/2508.16514v1>
- **Submitted**: 2025-08-22 16:37:40
- **Comment**: To appear at EMNLP 2025
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on improving Large Language Model (LLM) math reasoning using synthetic data, which is outside your primary research areas. While it mentions some data synthesis strategies, the paper's scope and methodology are not aligned with your interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Recent works improving LLM math reasoning with synthetic data have used
unique setups, making comparison of data synthesis strategies impractical. This
leaves many unanswered questions about the roles of different factors in the
synthetic data pipeline, such as the impact of filtering low-quality problems.
To address this gap, we introduce FLAMES, a Framework for LLM Assessment of
Math rEasoning Data Synthesis, and perform a systematic study of 10 existing
data synthesis strategies and multiple other factors impacting the performance
of synthetic math reasoning data. Our FLAMES experiments provide several
valuable insights about the optimal balance of difficulty and diversity of
synthetic data. First, data agents designed to increase problem complexity lead
to best improvements on most math metrics. Second, with a fixed data generation
budget, keeping higher problem coverage is more important than keeping only
problems with reliable solutions. Third, GSM8K- and MATH-based synthetic data
can lead to improvements on competition-level benchmarks, showcasing
easy-to-hard generalization. Leveraging insights from our FLAMES experiments,
we design two novel data synthesis strategies for improving out-of-domain
generalization and robustness. Further, we develop the FLAMES dataset, an
effective blend of our novel and existing data synthesis strategies,
outperforming public datasets on OlympiadBench (+15.7), CollegeMath (+4.5),
GSMPlus (+6.5), and MATH (+3.1). Fine-tuning Qwen2.5-Math-7B on the FLAMES
dataset achieves 81.4% on MATH, surpassing larger Llama3 405B, GPT-4o and
Claude 3.5 Sonnet.

### 23. What makes an entity salient in discourse?

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Amir Zeldes, Jessica Lin
- **URL**: <http://arxiv.org/abs/2508.16464v1>
- **Submitted**: 2025-08-22 15:30:40
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it touches on linguistic cues and inferences, the focus is on discourse analysis and entity salience, which is outside the scope of the user's primary research interests.

#### Abstract
> Entities in discourse vary broadly in salience: main participants, objects
and locations are noticeable and memorable, while tangential ones are less
important and quickly forgotten, raising questions about how humans signal and
infer relative salience. Using a graded operationalization of salience based on
summary-worthiness in multiple summaries of a discourse, this paper explores
data from 24 spoken and written genres of English to extract a multifactorial
complex of overt and implicit linguistic cues, such as recurring subjecthood or
definiteness, discourse relations and hierarchy across utterances, as well as
pragmatic functional inferences based on genre and communicative intent.
Tackling the question 'how is the degree of salience expressed for each and
every entity mentioned?' our results show that while previous approaches to
salience all correlate with our salience scores to some extent, no single
generalization is without exceptions, and the phenomenon cuts across all levels
of linguistic representation.

### 24. LLMSymGuard: A Symbolic Safety Guardrail Framework Leveraging Interpretable Jailbreak Concepts

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Darpan Aswal, C√©line Hudelot
- **URL**: <http://arxiv.org/abs/2508.16325v1>
- **Submitted**: 2025-08-22 12:13:38
- **Topic Keywords**: rag
- **Reason**: The paper focuses on the safety of Large Language Models and introduces a framework to identify interpretable concepts within LLM internals associated with different jailbreak themes. While it mentions advances in mechanistic interpretability of LLMs, it does not directly relate to query understanding, ranking models, or user behavior modeling in the context of Information Retrieval and Search technologies, which are the user's primary research interests.

#### Abstract
> Large Language Models have found success in a variety of applications;
however, their safety remains a matter of concern due to the existence of
various types of jailbreaking methods. Despite significant efforts, alignment
and safety fine-tuning only provide a certain degree of robustness against
jailbreak attacks that covertly mislead LLMs towards the generation of harmful
content. This leaves them prone to a number of vulnerabilities, ranging from
targeted misuse to accidental profiling of users. This work introduces
\textbf{LLMSymGuard}, a novel framework that leverages Sparse Autoencoders
(SAEs) to identify interpretable concepts within LLM internals associated with
different jailbreak themes. By extracting semantically meaningful internal
representations, LLMSymGuard enables building symbolic, logical safety
guardrails -- offering transparent and robust defenses without sacrificing
model capabilities or requiring further fine-tuning. Leveraging advances in
mechanistic interpretability of LLMs, our approach demonstrates that LLMs learn
human-interpretable concepts from jailbreaks, and provides a foundation for
designing more interpretable and logical safeguard measures against attackers.
Code will be released upon publication.

### 25. From Confidence to Collapse in LLM Factual Robustness

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Alina Fastowski, Bardh Prenkaj, Gjergji Kasneci
- **URL**: <http://arxiv.org/abs/2508.16267v1>
- **Submitted**: 2025-08-22 09:59:23
- **Topic Keywords**: retrieval
- **Reason**: The paper focuses on the robustness of factual knowledge in Large Language Models (LLMs) for tasks like question answering and reasoning, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on the concept of uncertainty, it does not explore ranking models, user behavior modeling, or real-time relevance optimization, making it only loosely relevant to the user's research interests.

#### Abstract
> Ensuring the robustness of factual knowledge in LLMs is critical for reliable
applications in tasks such as question answering and reasoning. However,
existing evaluation methods predominantly focus on performance-based metrics,
often investigating from the perspective of prompt perturbations, which
captures only the externally triggered side of knowledge robustness. To bridge
this gap, we introduce a principled approach to measure factual robustness from
the perspective of the generation process by analyzing token distribution
entropy in combination with temperature scaling sensitivity. These two factors
build the Factual Robustness Score (FRS), a novel metric which quantifies the
stability of a fact against perturbations in decoding conditions, given its
initial uncertainty. To validate our approach, we conduct extensive experiments
on 5 LLMs across 3 closed-book QA datasets (SQuAD, TriviaQA, and HotpotQA). We
show that factual robustness varies significantly -- smaller models report an
FRS of $0.76$, larger ones $0.93$ -- with accuracy degrading by ~$60\%$ under
increased uncertainty. These insights demonstrate how entropy and temperature
scaling impact factual accuracy, and lay a foundation for developing more
robust knowledge retention and retrieval in future models.

### 26. Hierarchical Vision-Language Reasoning for Multimodal Multiple-Choice Question Answering

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ao Zhou, Zebo Gu, Tenghao Sun, Jiawen Chen, Mingsheng Tu, Zifeng Cheng, Yafeng Yin, Zhiwei Jiang, Qing Gu
- **URL**: <http://arxiv.org/abs/2508.16148v1>
- **Submitted**: 2025-08-22 07:17:16
- **Comment**: This paper has been accepted by ACM MM 2025
- **Topic Keywords**: retrieval
- **Reason**: The paper focuses on multimodal understanding in Visual Question Answering, which is not directly related to Information Retrieval, Search technologies, or query understanding. Although it mentions multimodal hierarchical reasoning, the context is not applicable to the user's research interests in IR and NLP.

#### Abstract
> Multimodal Large Language Models (MLLMs) have demonstrated remarkable
multimodal understanding capabilities in Visual Question Answering (VQA) tasks
by integrating visual and textual features. However, under the challenging
ten-choice question evaluation paradigm, existing methods still exhibit
significant limitations when processing PDF documents with complex layouts and
lengthy content. Notably, current mainstream models suffer from a strong bias
toward English training data, resulting in suboptimal performance for Japanese
and other language scenarios. To address these challenges, this paper proposes
a novel Japanese PDF document understanding framework that combines multimodal
hierarchical reasoning mechanisms with Colqwen-optimized retrieval methods,
while innovatively introducing a semantic verification strategy through
sub-question decomposition. Experimental results demonstrate that our framework
not only significantly enhances the model's deep semantic parsing capability
for complex documents, but also exhibits superior robustness in practical
application scenarios.

### 27. Integrating Time Series into LLMs via Multi-layer Steerable Embedding Fusion for Enhanced Forecasting

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zhuomin Chen, Dan Li, Jiahui Zhou, Shunyu Wu, Haozheng Ye, Jian Lou, See-Kiong Ng
- **URL**: <http://arxiv.org/abs/2508.16059v1>
- **Submitted**: 2025-08-22 03:22:10
- **Comment**: To be published in CIKM 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on integrating time series data into large language models for forecasting, which is not directly related to information retrieval, search technologies, or query understanding. While it involves embedding fusion, the context is different from the user's research interests in IR and NLP.

#### Abstract
> Time series (TS) data are ubiquitous across various application areas,
rendering time series forecasting (TSF) a fundamental task. With the astounding
advances in large language models (LLMs), a variety of methods have been
developed to adapt LLMs for time series forecasting. Despite unlocking the
potential of LLMs in comprehending TS data, existing methods are inherently
constrained by their shallow integration of TS information, wherein LLMs
typically access TS representations at shallow layers, primarily at the input
layer. This causes the influence of TS representations to progressively fade in
deeper layers and eventually leads to ineffective adaptation between textual
embeddings and TS representations. In this paper, we propose the Multi-layer
Steerable Embedding Fusion (MSEF), a novel framework that enables LLMs to
directly access time series patterns at all depths, thereby mitigating the
progressive loss of TS information in deeper layers. Specifically, MSEF
leverages off-the-shelf time series foundation models to extract semantically
rich embeddings, which are fused with intermediate text representations across
LLM layers via layer-specific steering vectors. These steering vectors are
designed to continuously optimize the alignment between time series and textual
modalities and facilitate a layer-specific adaptation mechanism that ensures
efficient few-shot learning capabilities. Experimental results on seven
benchmarks demonstrate significant performance improvements by MSEF compared
with baselines, with an average reduction of 31.8% in terms of MSE. The code is
available at https://github.com/One1sAll/MSEF.

### 28. Generative Foundation Model for Structured and Unstructured Electronic Health Records

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sonish Sivarajkumar, Hang Zhang, Yuelyu Ji, Maneesh Bilalpur, Xizhi Wu, Chenyu Li, Min Gu Kwak, Shyam Visweswaran, Yanshan Wang
- **URL**: <http://arxiv.org/abs/2508.16054v1>
- **Submitted**: 2025-08-22 03:05:09
- **Topic Keywords**: ctr
- **Reason**: The paper focuses on developing a foundation model for structured and unstructured electronic health records, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing and multimodal fusion, the application is specific to the healthcare domain and does not align with the user's broader research interests.

#### Abstract
> Electronic health records (EHRs) are rich clinical data sources but complex
repositories of patient data, spanning structured elements (demographics,
vitals, lab results, codes), unstructured clinical notes and other modalities
of data. Harnessing this heterogeneity is critical for improving patient
outcomes. Recent advances in large language models (LLMs) have enabled
foundation models that can learn from multiple data modalities and support
clinical tasks. However, most current approaches simply serialize numeric EHR
data into text, which risks losing temporal and quantitative detail. We
introduce Generative Deep Patient (GDP), a multimodal foundation model that
natively encodes structured EHR time-series via a CNN-Transformer encoder and
fuses it with unstructured EHRs through cross-modal attention into a
LLaMA-based decoder. GDP is trained in two stages: (1) generative pretraining,
where it learns to produce clinical narratives from raw patient timelines while
also performing masked feature prediction (MFP) and next time-step prediction
(NTP) to capture temporal dynamics; and (2) multi-task fine-tuning for
clinically meaningful predictions (e.g., heart failure, type 2 diabetes, 30-day
readmission). In clinical prediction, GDP demonstrated superior performance on
MIMIC-IV: heart failure AUROC = 0.923, type 2 diabetes AUROC = 0.817, and
30-day readmission AUROC = 0.627. For narrative generation, GDP achieved
ROUGE-L = 0.135 and BERTScore-F1 = 0.545. In a blinded human evaluation,
GDP-Instruct scored highest on faithfulness, fluency, and overall clinical
utility, suggesting reduced hospital documentation workload without sacrificing
accuracy. Our results demonstrate that a single multimodal foundation model can
both predict clinically actionable events and generate high-quality clinical
narratives. Furthermore, GDP's flexible architecture can be extended to
additional modalities.

### 29. Political Ideology Shifts in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Pietro Bernardelle, Stefano Civelli, Leon Fr√∂hling, Riccardo Lunardi, Kevin Roitero, Gianluca Demartini
- **URL**: <http://arxiv.org/abs/2508.16013v1>
- **Submitted**: 2025-08-22 00:16:38
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The focus on large language models and political ideology shifts is outside your primary areas of interest, and the paper does not address topics like e-commerce, recommender systems, or deep semantic understanding.

#### Abstract
> Large language models (LLMs) are increasingly deployed in politically
sensitive settings, raising concerns about their potential to encode, amplify,
or be steered toward specific ideologies. We investigate how adopting synthetic
personas influences ideological expression in LLMs across seven models (7B-70B+
parameters) from multiple families, using the Political Compass Test as a
standardized probe. Our analysis reveals four consistent patterns: (i) larger
models display broader and more polarized implicit ideological coverage; (ii)
susceptibility to explicit ideological cues grows with scale; (iii) models
respond more strongly to right-authoritarian than to left-libertarian priming;
and (iv) thematic content in persona descriptions induces systematic and
predictable ideological shifts, which amplify with size. These findings
indicate that both scale and persona content shape LLM political behavior. As
such systems enter decision-making, educational, and policy contexts, their
latent ideological malleability demands attention to safeguard fairness,
transparency, and safety.

### 30. Dancing with Deer: A Constructional Perspective on MWEs in the Era of LLMs

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Claire Bonial, Julia Bonn, Harish Tayyar Madabushi
- **URL**: <http://arxiv.org/abs/2508.15977v1>
- **Submitted**: 2025-08-21 21:42:50
- **Comment**: Chapter in Phraseology and Multiword Expressions, Language Science
  Press (to appear)
- **Topic Keywords**: rag
- **Reason**: The paper focuses on constructional grammar and multiword expressions, which is unrelated to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's abstract does not mention query understanding, ranking models, or user behavior modeling, and its topics are not relevant to the user's background in e-commerce or real-time relevance optimization.

#### Abstract
> In this chapter, we argue for the benefits of understanding multiword
expressions from the perspective of usage-based, construction grammar
approaches. We begin with a historical overview of how construction grammar was
developed in order to account for idiomatic expressions using the same
grammatical machinery as the non-idiomatic structures of language. We cover a
comprehensive description of constructions, which are pairings of meaning with
form of any size (morpheme, word, phrase), as well as how constructional
approaches treat the acquisition and generalization of constructions. We
describe a successful case study leveraging constructional templates for
representing multiword expressions in English PropBank. Because constructions
can be at any level or unit of form, we then illustrate the benefit of a
constructional representation of multi-meaningful morphosyntactic unit
constructions in Arapaho, a highly polysynthetic and agglutinating language. We
include a second case study leveraging constructional templates for
representing these multi-morphemic expressions in Uniform Meaning
Representation. Finally, we demonstrate the similarities and differences
between a usage-based explanation of a speaker learning a novel multiword
expression, such as "dancing with deer," and that of a large language model. We
present experiments showing that both models and speakers can generalize the
meaning of novel multiword expressions based on a single exposure of usage.
However, only speakers can reason over the combination of two such expressions,
as this requires comparison of the novel forms to a speaker's lifetime of
stored constructional exemplars, which are rich with cross-modal details.

### 31. ASIC-Agent: An Autonomous Multi-Agent System for ASIC Design with Benchmark Evaluation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ahmed Allam, Youssef Mansour, Mohamed Shalan
- **URL**: <http://arxiv.org/abs/2508.15940v1>
- **Submitted**: 2025-08-21 20:21:34
- **Comment**: 2025 IEEE International Conference on LLM-Aided Design (ICLAD)
- **Topic Keywords**: rag
- **Reason**: The paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on ASIC design and multi-agent systems, which is outside your primary areas of interest.

#### Abstract
> Large Language Models (LLMs) have demonstrated remarkable capabilities in
Register Transfer Level (RTL) design, enabling high-quality code generation
from natural language descriptions. However, LLMs alone face significant
limitations in real-world hardware design workflows, including the inability to
execute code, lack of debugging capabilities, and absence of long-term memory.
To address these challenges, we present ASIC-Agent, an autonomous system
designed specifically for digital ASIC design tasks. ASIC-Agent enhances base
LLMs with a multi-agent architecture incorporating specialized sub-agents for
RTL generation, verification, OpenLane hardening, and Caravel chip integration,
all operating within a comprehensive sandbox environment with access to
essential hardware design tools. The system leverages a vector database
containing documentation, API references, error knowledge, and curated insights
from the open-source silicon community. To evaluate ASIC-Agent's performance,
we introduce ASIC-Agent-Bench, the first benchmark specifically designed to
assess agentic systems in hardware design tasks. We evaluate ASIC-Agent with
various base LLMs, providing quantitative comparisons and qualitative insights
into agent behavior across different design scenarios. Our results demonstrate
that ASIC-Agent, when powered by Claude 4 Sonnet, successfully automates a
broad range of ASIC design tasks spanning varying levels of complexity, showing
the potential of significantly accelerating the ASIC design workflow.

### 32. HAMSA: Hijacking Aligned Compact Models via Stealthy Automation

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Alexey Krylov, Iskander Vagizov, Dmitrii Korzh, Maryam Douiba, Azidine Guezzaz, Vladimir Kokh, Sergey D. Erokhin, Elena V. Tutubalina, Oleg Y. Rogov
- **URL**: <http://arxiv.org/abs/2508.16484v1>
- **Submitted**: 2025-08-22 15:57:57
- **Comment**: 9 pages, 1 figure; article under review
- **Topic Keywords**: search
- **Reason**: This paper focuses on a specific topic in NLP, namely, adversarial attacks on large language models, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and query understanding. The paper's abstract does not mention any relevance to ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest for the user.

#### Abstract
> Large Language Models (LLMs), especially their compact efficiency-oriented
variants, remain susceptible to jailbreak attacks that can elicit harmful
outputs despite extensive alignment efforts. Existing adversarial prompt
generation techniques often rely on manual engineering or rudimentary
obfuscation, producing low-quality or incoherent text that is easily flagged by
perplexity-based filters. We present an automated red-teaming framework that
evolves semantically meaningful and stealthy jailbreak prompts for aligned
compact LLMs. The approach employs a multi-stage evolutionary search, where
candidate prompts are iteratively refined using a population-based strategy
augmented with temperature-controlled variability to balance exploration and
coherence preservation. This enables the systematic discovery of prompts
capable of bypassing alignment safeguards while maintaining natural language
fluency. We evaluate our method on benchmarks in English (In-The-Wild Jailbreak
Prompts on LLMs), and a newly curated Arabic one derived from In-The-Wild
Jailbreak Prompts on LLMs and annotated by native Arabic linguists, enabling
multilingual assessment.

### 33. PediatricsMQA: a Multi-modal Pediatrics Question Answering Benchmark

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Adil Bahaj, Mounir Ghogho
- **URL**: <http://arxiv.org/abs/2508.16439v1>
- **Submitted**: 2025-08-22 14:50:55
- **Topic Keywords**: search
- **Reason**: This paper focuses on a specific domain (pediatrics) and a particular application (question answering) that is not directly related to my research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it mentions large language models, which is a related topic, the paper's primary focus is on medical informatics and decision support, which is not a central match for my interests.

#### Abstract
> Large language models (LLMs) and vision-augmented LLMs (VLMs) have
significantly advanced medical informatics, diagnostics, and decision support.
However, these models exhibit systematic biases, particularly age bias,
compromising their reliability and equity. This is evident in their poorer
performance on pediatric-focused text and visual question-answering tasks. This
bias reflects a broader imbalance in medical research, where pediatric studies
receive less funding and representation despite the significant disease burden
in children. To address these issues, a new comprehensive multi-modal pediatric
question-answering benchmark, PediatricsMQA, has been introduced. It consists
of 3,417 text-based multiple-choice questions (MCQs) covering 131 pediatric
topics across seven developmental stages (prenatal to adolescent) and 2,067
vision-based MCQs using 634 pediatric images from 67 imaging modalities and 256
anatomical regions. The dataset was developed using a hybrid manual-automatic
pipeline, incorporating peer-reviewed pediatric literature, validated question
banks, existing benchmarks, and existing QA resources. Evaluating
state-of-the-art open models, we find dramatic performance drops in younger
cohorts, highlighting the need for age-aware methods to ensure equitable AI
support in pediatric care.

### 34. Attribute Filtering in Approximate Nearest Neighbor Search: An In-depth Experimental Study

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Mocheng Li, Xiao Yan, Baotong Lu, Yue Zhang, James Cheng, Chenhao Ma
- **URL**: <http://arxiv.org/abs/2508.16263v1>
- **Submitted**: 2025-08-22 09:54:57
- **Comment**: 15 pages, 15 figures, Accepted at SIGMOD 2026
- **Topic Keywords**: search
- **Reason**: The paper focuses on Attribute Filtering in Approximate Nearest Neighbor Search, which is not directly related to Information Retrieval, query understanding, ranking models, or user behavior modeling. While it involves indexing methods and filtering strategies, the context is different from the user's research interests in IR and NLP.

#### Abstract
> With the growing integration of structured and unstructured data, new methods
have emerged for performing similarity searches on vectors while honoring
structured attribute constraints, i.e., a process known as Filtering
Approximate Nearest Neighbor (Filtering ANN) search. Since many of these
algorithms have only appeared in recent years and are designed to work with a
variety of base indexing methods and filtering strategies, there is a pressing
need for a unified analysis that identifies their core techniques and enables
meaningful comparisons.
  In this work, we present a unified Filtering ANN search interface that
encompasses the latest algorithms and evaluate them extensively from multiple
perspectives. First, we propose a comprehensive taxonomy of existing Filtering
ANN algorithms based on attribute types and filtering strategies. Next, we
analyze their key components, i.e., index structures, pruning strategies, and
entry point selection, to elucidate design differences and tradeoffs. We then
conduct a broad experimental evaluation on 10 algorithms and 12 methods across
4 datasets (each with up to 10 million items), incorporating both synthetic and
real attributes and covering selectivity levels from 0.1% to 100%. Finally, an
in-depth component analysis reveals the influence of pruning, entry point
selection, and edge filtering costs on overall performance. Based on our
findings, we summarize the strengths and limitations of each approach, provide
practical guidelines for selecting appropriate methods, and suggest promising
directions for future research. Our code is available at:
https://github.com/lmccccc/FANNBench.

### 35. ComicScene154: A Scene Dataset for Comic Analysis

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Sandro Paval, Ivan P. Yamshchikov, Pascal Mei√üner
- **URL**: <http://arxiv.org/abs/2508.16190v1>
- **Submitted**: 2025-08-22 08:11:58
- **Topic Keywords**: search
- **Reason**: The paper focuses on a specific domain (comics) and dataset creation, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions Natural Language Processing, the scope is limited to multimodal narrative understanding and comic analysis, which is not a primary focus of the user's research interests.

#### Abstract
> Comics offer a compelling yet under-explored domain for computational
narrative analysis, combining text and imagery in ways distinct from purely
textual or audiovisual media. We introduce ComicScene154, a manually annotated
dataset of scene-level narrative arcs derived from public-domain comic books
spanning diverse genres. By conceptualizing comics as an abstraction for
narrative-driven, multimodal data, we highlight their potential to inform
broader research on multi-modal storytelling. To demonstrate the utility of
ComicScene154, we present a baseline scene segmentation pipeline, providing an
initial benchmark that future studies can build upon. Our results indicate that
ComicScene154 constitutes a valuable resource for advancing computational
methods in multimodal narrative understanding and expanding the scope of comic
analysis within the Natural Language Processing community.

### 36. From Indirect Object Identification to Syllogisms: Exploring Binary Mechanisms in Transformer Circuits

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Karim Saraipour, Shichang Zhang
- **URL**: <http://arxiv.org/abs/2508.16109v1>
- **Submitted**: 2025-08-22 05:54:11
- **Topic Keywords**: search
- **Reason**: The paper focuses on mechanistic interpretability of transformer-based language models, exploring binary mechanisms in transformer circuits. While it touches on attention heads, which are relevant to ranking models, the paper's primary focus is on linguistic tasks and logical reasoning, which is not directly related to information retrieval, search technologies, or user behavior modeling.

#### Abstract
> Transformer-based language models (LMs) can perform a wide range of tasks,
and mechanistic interpretability (MI) aims to reverse engineer the components
responsible for task completion to understand their behavior. Previous MI
research has focused on linguistic tasks such as Indirect Object Identification
(IOI). In this paper, we investigate the ability of GPT-2 small to handle
binary truth values by analyzing its behavior with syllogistic prompts, e.g.,
"Statement A is true. Statement B matches statement A. Statement B is", which
requires more complex logical reasoning compared to IOI. Through our analysis
of several syllogism tasks of varying difficulty, we identify multiple circuits
that mechanistically explain GPT-2's logical-reasoning capabilities and uncover
binary mechanisms that facilitate task completion, including the ability to
produce a negated token not present in the input prompt through negative heads.
Our evaluation using a faithfulness metric shows that a circuit comprising five
attention heads achieves over 90% of the original model's performance. By
relating our findings to IOI analysis, we provide new insights into the roles
of specific attention heads and MLPs in LMs. These insights contribute to a
broader understanding of model reasoning and support future research in
mechanistic interpretability.

### 37. CEQuest: Benchmarking Large Language Models for Construction Estimation

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yanzhao Wu, Lufan Wang, Rui Liu
- **URL**: <http://arxiv.org/abs/2508.16081v1>
- **Submitted**: 2025-08-22 04:14:20
- **Topic Keywords**: search
- **Reason**: The paper focuses on applying Large Language Models to construction estimation, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions LLMs, it does not address query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user.

#### Abstract
> Large Language Models (LLMs) have demonstrated remarkable capabilities across
a wide range of general-domain tasks. However, their effectiveness in
specialized fields, such as construction, remains underexplored. In this paper,
we introduce CEQuest, a novel benchmark dataset specifically designed to
evaluate the performance of LLMs in answering construction-related questions,
particularly in the areas of construction drawing interpretation and
estimation. We conduct comprehensive experiments using five state-of-the-art
LLMs, including Gemma 3, Phi4, LLaVA, Llama 3.3, and GPT-4.1, and evaluate
their performance in terms of accuracy, execution time, and model size. Our
experimental results demonstrate that current LLMs exhibit considerable room
for improvement, highlighting the importance of integrating domain-specific
knowledge into these models. To facilitate further research, we will
open-source the proposed CEQuest dataset, aiming to foster the development of
specialized large language models (LLMs) tailored to the construction domain.

### 38. Ethical Considerations of Large Language Models in Game Playing

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Qingquan Zhang, Yuchen Li, Bo Yuan, Julian Togelius, Georgios N. Yannakakis, Jialin Liu
- **URL**: <http://arxiv.org/abs/2508.16065v1>
- **Submitted**: 2025-08-22 03:32:35
- **Comment**: 19 pages
- **Topic Keywords**: search
- **Reason**: This paper focuses on the ethical implications of large language models in game playing, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on topics like language models and behavioral analysis, the context is game playing, which is not a primary area of interest for the user.

#### Abstract
> Large language models (LLMs) have demonstrated tremendous potential in game
playing, while little attention has been paid to their ethical implications in
those contexts. This work investigates and analyses the ethical considerations
of applying LLMs in game playing, using Werewolf, also known as Mafia, as a
case study. Gender bias, which affects game fairness and player experience, has
been observed from the behaviour of LLMs. Some roles, such as the Guard and
Werewolf, are more sensitive than others to gender information, presented as a
higher degree of behavioural change. We further examine scenarios in which
gender information is implicitly conveyed through names, revealing that LLMs
still exhibit discriminatory tendencies even in the absence of explicit gender
labels. This research showcases the importance of developing fair and ethical
LLMs. Beyond our research findings, we discuss the challenges and opportunities
that lie ahead in this field, emphasising the need for diving deeper into the
ethical implications of LLMs in gaming and other interactive domains.

### 39. Estimating the Effective Topics of Articles and journals Abstract Using LDA And K-Means Clustering Algorithm

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Shadikur Rahman, Umme Ayman Koana, Aras M. Ismael, Karmand Hussein Abdalla
- **URL**: <http://arxiv.org/abs/2508.16046v1>
- **Submitted**: 2025-08-22 02:51:33
- **Topic Keywords**: search
- **Reason**: The paper focuses on topic modeling and text clustering, which is not directly related to information retrieval, search technologies, or query understanding. Although it mentions keyphrase extraction, the context is not relevant to the user's interests in ranking models, user behavior modeling, or deep semantic understanding.

#### Abstract
> Analyzing journals and articles abstract text or documents using topic
modelling and text clustering has become a modern solution for the increasing
number of text documents. Topic modelling and text clustering are both
intensely involved tasks that can benefit one another. Text clustering and
topic modelling algorithms are used to maintain massive amounts of text
documents. In this study, we have used LDA, K-Means cluster and also lexical
database WordNet for keyphrases extraction in our text documents. K-Means
cluster and LDA algorithms achieve the most reliable performance for keyphrase
extraction in our text documents. This study will help the researcher to make a
search string based on journals and articles by avoiding misunderstandings.

---

