[
    {
        "title": "KiseKloset: Comprehensive System For Outfit Retrieval, Recommendation, And Try-On",
        "abstract": "The global fashion e-commerce industry has become integral to people's daily\nlives, leveraging technological advancements to offer personalized shopping\nexperiences, primarily through recommendation systems that enhance customer\nengagement through personalized suggestions. To improve customers' experience\nin online shopping, we propose a novel comprehensive KiseKloset system for\noutfit retrieval, recommendation, and try-on. We explore two approaches for\noutfit retrieval: similar item retrieval and text feedback-guided item\nretrieval. Notably, we introduce a novel transformer architecture designed to\nrecommend complementary items from diverse categories. Furthermore, we enhance\nthe overall performance of the search pipeline by integrating approximate\nalgorithms to optimize the search process. Additionally, addressing the crucial\nneeds of online shoppers, we employ a lightweight yet efficient virtual try-on\nframework capable of real-time operation, memory efficiency, and maintaining\nrealistic outputs compared to its predecessors. This virtual try-on module\nempowers users to visualize specific garments on themselves, enhancing the\ncustomers' experience and reducing costs associated with damaged items for\nretailers. We deployed our end-to-end system for online users to test and\nprovide feedback, enabling us to measure their satisfaction levels. The results\nof our user study revealed that 84% of participants found our comprehensive\nsystem highly useful, significantly improving their online shopping experience.",
        "url": "http://arxiv.org/abs/2506.23471v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23471v1",
        "arxiv_id": "2506.23471v1",
        "authors": [
            "Thanh-Tung Phan-Nguyen",
            "Khoi-Nguyen Nguyen-Ngoc",
            "Tam V. Nguyen",
            "Minh-Triet Tran",
            "Trung-Nghia Le"
        ],
        "submitted": "2025-06-30 02:25:39",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'shopping' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper proposes a comprehensive system for outfit retrieval, recommendation, and try-on, which is relevant to your interest in Information Retrieval and Search technologies, particularly in the e-commerce domain. The system's focus on personalized shopping experiences and real-time relevance optimization aligns with your research themes. However, the paper's primary focus on fashion e-commerce and outfit recommendation is not directly related to your core interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "NaviX: A Native Vector Index Design for Graph DBMSs With Robust Predicate-Agnostic Search Performance",
        "abstract": "There is an increasing demand for extending existing DBMSs with vector\nindices so that they become unified systems capable of supporting modern\npredictive applications, which require joint querying of vector embeddings\ntogether with the structured properties and connections of objects. We present\nNaviX, a native vector index for graph DBMSs (GDBMSs) that has two main design\ngoals. First, we aim to implement a disk-based vector index that leverages the\ncore storage and query-processing capabilities of the underlying GDBMS. To this\nend, NaviX is built on the Hierarchical Navigable Small-World (HNSW) graph,\nwhich itself is a graph-based structure. Second, we aim to support\npredicate-agnostic filtered vector search queries, in which the k nearest\nneighbors (kNNs) of a query vector vQ are searched only within an arbitrary\nsubset S of vectors defined by an ad-hoc selection sub-query QS. We adopt a\nprefiltering approach that evaluates QS first and passes the full description\nof subset S to the kNN search operator. We study how to design a prefiltering\nsearch algorithm that remains robust under varying selectivities and under\ndifferent correlations between subset S and query vector vQ. We propose an\nadaptive algorithm that uses the local selectivity of each vector in the HNSW\ngraph to choose an appropriate heuristic at every iteration of the kNN search.\nFinally, We demonstrate NaviX's robustness and efficiency through extensive\nexperiments against both existing prefiltering- and postfiltering-based\nbaselines.",
        "url": "http://arxiv.org/abs/2506.23397v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23397v1",
        "arxiv_id": "2506.23397v1",
        "authors": [
            "Gaurav Sehgal",
            "Semih Salihoglu"
        ],
        "submitted": "2025-06-29 21:16:07",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on designing a native vector index for graph DBMSs, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions search queries, the context is different from the user's interests in IR and NLP."
    },
    {
        "title": "On the Predictive Power of Representation Dispersion in Language Models",
        "abstract": "We show that a language model's ability to predict text is tightly linked to\nthe breadth of its embedding space: models that spread their contextual\nrepresentations more widely tend to achieve lower perplexity. Concretely, we\nfind that representation dispersion - the average pairwise cosine distance\namong hidden vectors - strongly and negatively correlates with perplexity\nacross diverse model families (LLaMA, Qwen, and others) and domains (Wikipedia,\nnews, scientific abstracts). Beyond illustrating this link, we show how\ndispersion can be leveraged for a range of practical tasks without requiring\nlabeled data. First, measuring dispersion on unlabeled text allows us to\npredict downstream accuracy in new domains, offering a data-efficient tool for\nmodel selection. Next, we find that identifying layers with higher dispersion\npinpoints the best representations for retrieval-based methods such as kNN-LM,\nbypassing exhaustive layer-by-layer searches. Finally, we integrate a simple\npush-away objective into training, which increases dispersion in both\nsingle-domain and cross-domain scenarios and directly improves perplexity in\neach.",
        "url": "http://arxiv.org/abs/2506.24106v1",
        "pdf_url": "http://arxiv.org/pdf/2506.24106v1",
        "arxiv_id": "2506.24106v1",
        "authors": [
            "Yanhong Li",
            "Ming Li",
            "Karen Livescu",
            "Jiawei Zhou"
        ],
        "submitted": "2025-06-30 17:53:50",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on the predictive power of representation dispersion in language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on the idea of using dispersion for model selection and retrieval-based methods, the connection to the user's research interests is loose and indirect."
    },
    {
        "title": "Emergent musical properties of a transformer under contrastive self-supervised learning",
        "abstract": "In music information retrieval (MIR), contrastive self-supervised learning\nfor general-purpose representation models is effective for global tasks such as\nautomatic tagging. However, for local tasks such as chord estimation, it is\nwidely assumed that contrastively trained general-purpose self-supervised\nmodels are inadequate and that more sophisticated SSL is necessary; e.g.,\nmasked modeling. Our paper challenges this assumption by revealing the\npotential of contrastive SSL paired with a transformer in local MIR tasks. We\nconsider a lightweight vision transformer with one-dimensional patches in the\ntime--frequency domain (ViT-1D) and train it with simple contrastive SSL\nthrough normalized temperature-scaled cross-entropy loss (NT-Xent). Although\nNT-Xent operates only over the class token, we observe that, potentially thanks\nto weight sharing, informative musical properties emerge in ViT-1D's sequence\ntokens. On global tasks, the temporal average of class and sequence tokens\noffers a performance increase compared to the class token alone, showing useful\nproperties in the sequence tokens. On local tasks, sequence tokens perform\nunexpectedly well, despite not being specifically trained for. Furthermore,\nhigh-level musical features such as onsets emerge from layer-wise attention\nmaps and self-similarity matrices show different layers capture different\nmusical dimensions. Our paper does not focus on improving performance but\nadvances the musical interpretation of transformers and sheds light on some\noverlooked abilities of contrastive SSL paired with transformers for sequence\nmodeling in MIR.",
        "url": "http://arxiv.org/abs/2506.23873v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23873v1",
        "arxiv_id": "2506.23873v1",
        "authors": [
            "Yuexuan Kong",
            "Gabriel Meseguer-Brocal",
            "Vincent Lostanlen",
            "Mathieu Lagrange",
            "Romain Hennequin"
        ],
        "submitted": "2025-06-30 14:04:59",
        "source": "arxiv",
        "comment": "Accepted at ISMIR 2025",
        "score": 7,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on music information retrieval and the application of transformers in music, which is outside the user's primary research areas."
    },
    {
        "title": "Leveraging the Potential of Prompt Engineering for Hate Speech Detection in Low-Resource Languages",
        "abstract": "The rapid expansion of social media leads to a marked increase in hate\nspeech, which threatens personal lives and results in numerous hate crimes.\nDetecting hate speech presents several challenges: diverse dialects, frequent\ncode-mixing, and the prevalence of misspelled words in user-generated content\non social media platforms. Recent progress in hate speech detection is\ntypically concentrated on high-resource languages. However, low-resource\nlanguages still face significant challenges due to the lack of large-scale,\nhigh-quality datasets. This paper investigates how we can overcome this\nlimitation via prompt engineering on large language models (LLMs) focusing on\nlow-resource Bengali language. We investigate six prompting strategies -\nzero-shot prompting, refusal suppression, flattering the classifier, multi-shot\nprompting, role prompting, and finally our innovative metaphor prompting to\ndetect hate speech effectively in low-resource languages. We pioneer the\nmetaphor prompting to circumvent the built-in safety mechanisms of LLMs that\nmarks a significant departure from existing jailbreaking methods. We\ninvestigate all six different prompting strategies on the Llama2-7B model and\ncompare the results extensively with three pre-trained word embeddings - GloVe,\nWord2Vec, and FastText for three different deep learning models - multilayer\nperceptron (MLP), convolutional neural network (CNN), and bidirectional gated\nrecurrent unit (BiGRU). To prove the effectiveness of our metaphor prompting in\nthe low-resource Bengali language, we also evaluate it in another low-resource\nlanguage - Hindi, and two high-resource languages - English and German. The\nperformance of all prompting techniques is evaluated using the F1 score, and\nenvironmental impact factor (IF), which measures CO$_2$ emissions, electricity\nusage, and computational time.",
        "url": "http://arxiv.org/abs/2506.23930v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23930v1",
        "arxiv_id": "2506.23930v1",
        "authors": [
            "Ruhina Tabasshum Prome",
            "Tarikul Islam Tamiti",
            "Anomadarshi Barua"
        ],
        "submitted": "2025-06-30 14:59:25",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topic of hate speech detection in low-resource languages is outside your primary focus on query understanding, ranking models, and user behavior modeling. Although the paper mentions large language models, it does not relate to your specific areas of interest."
    },
    {
        "title": "Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation",
        "abstract": "Context-aware embedding methods boost retrieval accuracy by conditioning on\ncorpus statistics (e.g., term co-occurrence and topical patterns) extracted\nfrom neighboring documents. However, this context-aware approach requires\naccess to the target corpus or requires domain-specific finetuning, posing\npractical barriers in privacy-sensitive or resource-constrained settings. We\npresent ZEST, a zero-shot contextual adaptation framework that replaces real\ncorpus access with a one-time offline synthesis of a compact proxy. Given only\na handful exemplar documents representative of the general target domain, we\nuse a multi-step hierarchical procedure to generate a synthetic context corpus\nof several hundred documents that aims to emulate key domain-specific\ndistributions. At inference, the frozen context-aware encoder uses this proxy\ncorpus -- without any finetuning or target corpus access -- to produce\ndomain-adapted embeddings. Across the MTEB benchmark, ZEST's zero-shot\nsynthetic context adaptation using only five example documents performs within\n0.5% of models leveraging full target corpus access -- demonstrating remarkable\nefficacy without any retraining. ZEST thus provides a practical method for\ndeploying high-performance, adaptable embeddings in constrained environments.",
        "url": "http://arxiv.org/abs/2506.23662v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23662v1",
        "arxiv_id": "2506.23662v1",
        "authors": [
            "Philip Lippmann",
            "Jie Yang"
        ],
        "submitted": "2025-06-30 09:38:50",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a method for generating synthetic context corpora, which is related to information retrieval and query understanding. However, the focus is on contextual embeddings rather than ranking models or user behavior modeling, which are key areas of interest for the user. While the method is applicable to various domains, the e-commerce background of the user is not directly relevant to this paper."
    },
    {
        "title": "Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent",
        "abstract": "Interactive recommendation is a typical information-seeking task that allows\nusers to interactively express their needs through natural language and obtain\npersonalized recommendations. Large language model-powered (LLM-powered) agents\nhave become a new paradigm in interactive recommendations, effectively\ncapturing users' real-time needs and enhancing personalized experiences.\nHowever, due to limited planning and generalization capabilities, existing\nformulations of LLM-powered interactive recommender agents struggle to\neffectively address diverse and complex user intents, such as intuitive,\nunrefined, or occasionally ambiguous requests. To tackle this challenge, we\npropose a novel thought-augmented interactive recommender agent system (TAIRA)\nthat addresses complex user intents through distilled thought patterns.\nSpecifically, TAIRA is designed as an LLM-powered multi-agent system featuring\na manager agent that orchestrates recommendation tasks by decomposing user\nneeds and planning subtasks, with its planning capacity strengthened through\nThought Pattern Distillation (TPD), a thought-augmentation method that extracts\nhigh-level thoughts from the agent's and human experts' experiences. Moreover,\nwe designed a set of user simulation schemes to generate personalized queries\nof different difficulties and evaluate the recommendations based on specific\ndatasets. Through comprehensive experiments conducted across multiple datasets,\nTAIRA exhibits significantly enhanced performance compared to existing methods.\nNotably, TAIRA shows a greater advantage on more challenging tasks while\ngeneralizing effectively on novel tasks, further validating its superiority in\nmanaging complex user intents within interactive recommendation systems. The\ncode is publicly available at:https://github.com/Alcein/TAIRA.",
        "url": "http://arxiv.org/abs/2506.23485v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23485v1",
        "arxiv_id": "2506.23485v1",
        "authors": [
            "Haocheng Yu",
            "Yaxiong Wu",
            "Hao Wang",
            "Wei Guo",
            "Yong Liu",
            "Yawen Li",
            "Yuyang Ye",
            "Junping Du",
            "Enhong Chen"
        ],
        "submitted": "2025-06-30 03:15:50",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper proposes a novel thought-augmented interactive recommender agent system (TAIRA) that addresses complex user intents through distilled thought patterns. While it's related to information retrieval and search technologies, the focus is on recommender systems, which is not the primary area of interest. The paper's emphasis on LLM-powered agents and thought pattern distillation is somewhat relevant to query understanding and ranking models, but it's not a central match."
    },
    {
        "title": "EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations",
        "abstract": "Recent advances in large language models and vision-language models have led\nto growing interest in explainable evaluation metrics for image captioning.\nHowever, these metrics generate explanations without standardized criteria, and\nthe overall quality of the generated explanations remains unverified. In this\npaper, we propose EXPERT, a reference-free evaluation metric that provides\nstructured explanations based on three fundamental criteria: fluency,\nrelevance, and descriptiveness. By constructing large-scale datasets of\nhigh-quality structured explanations, we develop a two-stage evaluation\ntemplate to effectively supervise a vision-language model for both scoring and\nexplanation generation. EXPERT achieves state-of-the-art results on benchmark\ndatasets while providing significantly higher-quality explanations than\nexisting metrics, as validated through comprehensive human evaluation. Our code\nand datasets are available at https://github.com/hjkim811/EXPERT.",
        "url": "http://arxiv.org/abs/2506.24016v1",
        "pdf_url": "http://arxiv.org/pdf/2506.24016v1",
        "arxiv_id": "2506.24016v1",
        "authors": [
            "Hyunjong Kim",
            "Sangyeop Kim",
            "Jongheon Jeong",
            "Yeongjae Cho",
            "Sungzoon Cho"
        ],
        "submitted": "2025-06-30 16:20:51",
        "source": "arxiv",
        "comment": "Accepted at ACL 2025 Findings",
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it touches on Natural Language Processing (NLP) and vision-language models, the focus is on image captioning evaluation metrics, which is a specific application in NLP rather than a broader topic in IR or NLP."
    },
    {
        "title": "Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning",
        "abstract": "Congenital heart disease (CHD) presents complex, lifelong challenges often\nunderrepresented in traditional clinical metrics. While unstructured narratives\noffer rich insights into patient and caregiver experiences, manual thematic\nanalysis (TA) remains labor-intensive and unscalable. We propose a fully\nautomated large language model (LLM) pipeline that performs end-to-end TA on\nclinical narratives, which eliminates the need for manual coding or full\ntranscript review. Our system employs a novel multi-agent framework, where\nspecialized LLM agents assume roles to enhance theme quality and alignment with\nhuman analysis. To further improve thematic relevance, we optionally integrate\nreinforcement learning from human feedback (RLHF). This supports scalable,\npatient-centered analysis of large qualitative datasets and allows LLMs to be\nfine-tuned for specific clinical contexts.",
        "url": "http://arxiv.org/abs/2506.23998v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23998v1",
        "arxiv_id": "2506.23998v1",
        "authors": [
            "Seungjun Yi",
            "Joakim Nguyen",
            "Huimin Xu",
            "Terence Lim",
            "Andrew Well",
            "Mia Markey",
            "Ying Ding"
        ],
        "submitted": "2025-06-30 16:02:28",
        "source": "arxiv",
        "comment": "Presented at ACL 2025 SRW",
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on automated thematic analysis in the medical domain, which is outside the user's primary focus areas."
    },
    {
        "title": "Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs",
        "abstract": "Multimodal Large Language Models (MLLMs) have achieved success across various\ndomains. However, their applicability tends to degrade when confronted with\ndifferent types of data inputs, especially for MLLMs that have been fine-tuned\nfor specific tasks. Despite its importance, the study of knowledge sharing\namong domain-specific MLLMs--such as those trained for mathematics or\ncode--remains largely underexplored. To address the fragmentation of knowledge\nacross domain-specialized MLLMs, we propose a unified parameter integration\nframework that enables modular composition of expert capabilities. Our method\nis grounded in a novel Compatibility-Aware Parameter Splicing (CAPS) strategy,\nwhich leverages both local functional attribution and global\ninformation-theoretic signals to guide selective parameter fusion. By extending\nthis mechanism to the low-rank adaptation layer granularity, we ensure\nefficient integration with minimal inference overhead. Furthermore, we\nintroduce a domain compatibility scoring mechanism that quantifies inter-expert\nalignment at the activation level and correlates with downstream task utility.\nThis principled fusion protocol allows the final model to synergize\nheterogeneous expertise while preserving structural modularity. Extensive\nevaluations across diverse multimodal benchmarks validate the effectiveness of\nour framework, offering a scalable path toward compositional, domain-adaptive\nMLLMs.",
        "url": "http://arxiv.org/abs/2506.23940v2",
        "pdf_url": "http://arxiv.org/pdf/2506.23940v2",
        "arxiv_id": "2506.23940v2",
        "authors": [
            "Yang Dai",
            "Jianxiang An",
            "Tianwei Lin",
            "Hongyang He",
            "Hongzhe Huang",
            "Wenqiao Zhang",
            "Zheqi Lv",
            "Siliang Tang",
            "Yueting Zhuang"
        ],
        "submitted": "2025-06-30 15:07:41",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on integrating domain knowledge in Multimodal Large Language Models (MLLMs), which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on the concept of knowledge sharing, the context is different from the user's primary research interests."
    },
    {
        "title": "AutoEvoEval: An Automated Framework for Evolving Close-Ended LLM Evaluation Data",
        "abstract": "Large language models (LLMs) have shown remarkable performance on various\ntasks, but existing evaluation benchmarks are often static and insufficient to\nfully assess their robustness and generalization in realistic scenarios. Prior\nwork using evolutionary or adversarial data augmentation has improved\nevaluation diversity but lacks systematic control over perturbation types and\nmulti-step complexity, limiting comprehensive robustness analysis. To address\nthese gaps, we propose AutoEvoEval, an evolution-based evaluation framework for\nclose-ended tasks such as multi-choice question answering. AutoEvoEval\nintroduces 22 interpretable atomic evolution operations and supports\nmulti-round compositions, enabling controlled generation of diverse,\nchallenging, and realistic test samples. We conduct extensive experiments\naddressing four research questions on a broad set of open- and closed-source\nLLMs. Our results show that atomic operations cause an average accuracy drop of\n7.283\\%, with structure-disrupting or misleading semantic edits causing the\nlargest declines. Model sensitivities vary significantly for the same\nperturbation, and combining multiple evolution steps amplifies adversarial\neffects by up to 52.932\\%. These findings suggest current benchmarks may\noverestimate true model generalization and emphasize the need for\nevolution-aware robustness evaluation. Code and resources are available at:\nhttps://github.com/SYSUSELab/AutoEvoEval.",
        "url": "http://arxiv.org/abs/2506.23735v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23735v1",
        "arxiv_id": "2506.23735v1",
        "authors": [
            "JiaRu Wu",
            "Mingwei Liu"
        ],
        "submitted": "2025-06-30 11:18:56",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes an evaluation framework for large language models, focusing on close-ended tasks and robustness analysis. While it touches on the topic of evaluation, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval and Search technologies."
    },
    {
        "title": "Towards an Automated Multimodal Approach for Video Summarization: Building a Bridge Between Text, Audio and Facial Cue-Based Summarization",
        "abstract": "The increasing volume of video content in educational, professional, and\nsocial domains necessitates effective summarization techniques that go beyond\ntraditional unimodal approaches. This paper proposes a behaviour-aware\nmultimodal video summarization framework that integrates textual, audio, and\nvisual cues to generate timestamp-aligned summaries. By extracting prosodic\nfeatures, textual cues and visual indicators, the framework identifies\nsemantically and emotionally important moments. A key contribution is the\nidentification of bonus words, which are terms emphasized across multiple\nmodalities and used to improve the semantic relevance and expressive clarity of\nthe summaries. The approach is evaluated against pseudo-ground truth (pGT)\nsummaries generated using LLM-based extractive method. Experimental results\ndemonstrate significant improvements over traditional extractive method, such\nas the Edmundson method, in both text and video-based evaluation metrics.\nText-based metrics show ROUGE-1 increasing from 0.4769 to 0.7929 and BERTScore\nfrom 0.9152 to 0.9536, while in video-based evaluation, our proposed framework\nimproves F1-Score by almost 23%. The findings underscore the potential of\nmultimodal integration in producing comprehensive and behaviourally informed\nvideo summaries.",
        "url": "http://arxiv.org/abs/2506.23714v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23714v1",
        "arxiv_id": "2506.23714v1",
        "authors": [
            "Md Moinul Islam",
            "Sofoklis Kakouros",
            "Janne Heikkil√§",
            "Mourad Oussalah"
        ],
        "submitted": "2025-06-30 10:41:33",
        "source": "arxiv",
        "comment": "Accepted to HHAI WS 2025: Workshops at the Fourth International\n  Conference on Hybrid Human-Artificial Intelligence (HHAI)",
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a multimodal video summarization framework that integrates textual, audio, and visual cues, which is somewhat related to information retrieval and search technologies. However, the focus on video summarization and multimodal integration is not directly aligned with the user's primary research interests in query understanding, ranking models, and user behavior modeling. The paper's relevance to the user's interests is limited, but it may still be of interest due to its connection to natural language processing and data mining."
    },
    {
        "title": "Act-With-Think: Chunk Auto-Regressive Modeling for Generative Recommendation",
        "abstract": "Generative recommendation (GR) typically encodes behavioral or semantic\naspects of item information into discrete tokens, leveraging the standard\nautoregressive (AR) generation paradigm to make predictions. However, existing\nmethods tend to overlook their intrinsic relationship, that is, the semantic\nusually provides some reasonable explainability \"$\\textbf{why}$\" for the\nbehavior \"$\\textbf{what}$\", which may constrain the full potential of GR. To\nthis end, we present Chunk AutoRegressive Modeling (CAR), a new generation\nparadigm following the decision pattern that users usually think semantic\naspects of items (e.g. brand) and then take actions on target items (e.g.\npurchase). Our CAR, for the $\\textit{first time}$, incorporates semantics\n(SIDs) and behavior (UID) into a single autoregressive transformer from an\n``act-with-think'' dual perspective via chunk-level autoregression.\nSpecifically, CAR packs SIDs and UID into a conceptual chunk for item unified\nrepresentation, allowing each decoding step to make a holistic prediction.\nExperiments show that our CAR significantly outperforms existing methods based\non traditional AR, improving Recall@5 by 7.93% to 22.30%. Furthermore, we\nverify the scaling effect between model performance and SIDs bit number,\ndemonstrating that CAR preliminary emulates a kind of slow-thinking style\nmechanism akin to the reasoning processes observed in large language models\n(LLMs).",
        "url": "http://arxiv.org/abs/2506.23643v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23643v1",
        "arxiv_id": "2506.23643v1",
        "authors": [
            "Yifan Wang",
            "Weinan Gan",
            "Longtao Xiao",
            "Jieming Zhu",
            "Heng Chang",
            "Haozhao Wang",
            "Rui Zhang",
            "Zhenhua Dong",
            "Ruiming Tang",
            "Ruixuan Li"
        ],
        "submitted": "2025-06-30 09:13:54",
        "source": "arxiv",
        "comment": "9 pages, 2 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a novel approach to generative recommendation, incorporating semantic and behavioral aspects into a single autoregressive transformer. While it touches on some aspects of user behavior modeling, the focus is primarily on the generation paradigm rather than query understanding, ranking models, or real-time relevance optimization, which are core areas of interest in Information Retrieval."
    },
    {
        "title": "Semantic-guided Diverse Decoding for Large Language Model",
        "abstract": "Diverse decoding of large language models is crucial for applications\nrequiring multiple semantically distinct responses, yet existing methods\nprimarily achieve lexical rather than semantic diversity. This limitation\nsignificantly constrains Best-of-N strategies, group-based reinforcement\nlearning, and data synthesis. While temperature sampling and diverse beam\nsearch modify token distributions or apply n-gram penalties, they fail to\nensure meaningful semantic differentiation. We introduce Semantic-guided\nDiverse Decoding (SemDiD), operating directly in embedding space that balances\nquality with diversity through three complementary mechanisms: orthogonal\ndirectional guidance, dynamic inter-group repulsion, and position-debiased\nprobability assessment. SemDiD harmonizes these competing objectives using\nadaptive gain functions and constraint optimization, ensuring both quality\nthresholds and maximal semantic differentiation. Experiments show SemDiD\nconsistently outperforms existing methods, improving Best-of-N coverage by\n1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15%\nwhile increasing accuracy by up to 2.1%.",
        "url": "http://arxiv.org/abs/2506.23601v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23601v1",
        "arxiv_id": "2506.23601v1",
        "authors": [
            "Weijie Shi",
            "Yue Cui",
            "Yaguang Wu",
            "Jingzhi Fang",
            "Shibo Zhang",
            "Mengze Li",
            "Sirui Han",
            "Jia Zhu",
            "Jiajie Xu",
            "Xiaofang Zhou"
        ],
        "submitted": "2025-06-30 08:06:49",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on diverse decoding for large language models, which is related to query understanding and ranking models in Information Retrieval. However, the paper's primary concern is semantic diversity in language generation, which is not directly aligned with the user's interests in search technologies and user behavior modeling."
    },
    {
        "title": "NEU-ESC: A Comprehensive Vietnamese dataset for Educational Sentiment analysis and topic Classification toward multitask learning",
        "abstract": "In the field of education, understanding students' opinions through their\ncomments is crucial, especially in the Vietnamese language, where resources\nremain limited. Existing educational datasets often lack domain relevance and\nstudent slang. To address these gaps, we introduce NEU-ESC, a new Vietnamese\ndataset for Educational Sentiment Classification and Topic Classification,\ncurated from university forums, which offers more samples, richer class\ndiversity, longer texts, and broader vocabulary. In addition, we explore\nmultitask learning using encoder-only language models (BERT), in which we\nshowed that it achieves performance up to 83.7% and 79.8% accuracy for\nsentiment and topic classification tasks. We also benchmark our dataset and\nmodel with other datasets and models, including Large Language Models, and\ndiscuss these benchmarks. The dataset is publicly available at:\nhttps://huggingface.co/datasets/hung20gg/NEU-ESC.",
        "url": "http://arxiv.org/abs/2506.23524v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23524v1",
        "arxiv_id": "2506.23524v1",
        "authors": [
            "Phan Quoc Hung Mai",
            "Quang Hung Nguyen",
            "Phuong Giang Duong",
            "Hong Hanh Nguyen",
            "Nguyen Tuan Long"
        ],
        "submitted": "2025-06-30 05:19:04",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on a specific domain (education) and language (Vietnamese), with a narrow scope on sentiment analysis and topic classification. While it uses a language model (BERT), the context is not related to information retrieval, search technologies, or query understanding, which are the user's primary research interests."
    },
    {
        "title": "Datasets for Fairness in Language Models: An In-Depth Survey",
        "abstract": "Fairness benchmarks play a central role in shaping how we evaluate language\nmodels, yet surprisingly little attention has been given to examining the\ndatasets that these benchmarks rely on. This survey addresses that gap by\npresenting a broad and careful review of the most widely used fairness datasets\nin current language model research, characterizing them along several key\ndimensions including their origin, scope, content, and intended use to help\nresearchers better appreciate the assumptions and limitations embedded in these\nresources. To support more meaningful comparisons and analyses, we introduce a\nunified evaluation framework that reveals consistent patterns of demographic\ndisparities across datasets and scoring methods. Applying this framework to\ntwenty four common benchmarks, we highlight the often overlooked biases that\ncan influence conclusions about model fairness and offer practical guidance for\nselecting, combining, and interpreting these datasets. We also point to\nopportunities for creating new fairness benchmarks that reflect more diverse\nsocial contexts and encourage more thoughtful use of these tools going forward.\nAll code, data, and detailed results are publicly available at\nhttps://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets\nto promote transparency and reproducibility across the research community.",
        "url": "http://arxiv.org/abs/2506.23411v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23411v1",
        "arxiv_id": "2506.23411v1",
        "authors": [
            "Jiale Zhang",
            "Zichong Wang",
            "Avash Palikhe",
            "Zhipeng Yin",
            "Wenbin Zhang"
        ],
        "submitted": "2025-06-29 22:11:58",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The focus on fairness in language models and datasets is outside your primary areas of interest, and the paper does not address topics like real-time relevance optimization or deep semantic understanding."
    },
    {
        "title": "Density, asymmetry and citation dynamics in scientific literature",
        "abstract": "Scientific behavior is often characterized by a tension between building upon\nestablished knowledge and introducing novel ideas. Here, we investigate whether\nthis tension is reflected in the relationship between the similarity of a\nscientific paper to previous research and its eventual citation rate. To\noperationalize similarity to previous research, we introduce two complementary\nmetrics to characterize the local geometry of a publication's semantic\nneighborhood: (1) \\emph{density} ($\\rho$), defined as the ratio between a fixed\nnumber of previously-published papers and the minimum distance enclosing those\npapers in a semantic embedding space, and (2) asymmetry ($\\alpha$), defined as\nthe average directional difference between a paper and its nearest neighbors.\nWe tested the predictive relationship between these two metrics and its\nsubsequent citation rate using a Bayesian hierarchical regression approach,\nsurveying $\\sim 53,000$ publications across nine academic disciplines and five\ndifferent document embeddings. While the individual effects of $\\rho$ on\ncitation count are small and variable, incorporating density-based predictors\nconsistently improves out-of-sample prediction when added to baseline models.\nThese results suggest that the density of a paper's surrounding scientific\nliterature may carry modest but informative signals about its eventual impact.\nMeanwhile, we find no evidence that publication asymmetry improves model\npredictions of citation rates. Our work provides a scalable framework for\nlinking document embeddings to scientometric outcomes and highlights new\nquestions regarding the role that semantic similarity plays in shaping the\ndynamics of scientific reward.",
        "url": "http://arxiv.org/abs/2506.23366v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23366v1",
        "arxiv_id": "2506.23366v1",
        "authors": [
            "Nathaniel Imel",
            "Zachary Hafen"
        ],
        "submitted": "2025-06-29 18:55:04",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on scientometrics, citation dynamics, and document embeddings, which are not central to your areas of interest."
    },
    {
        "title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning",
        "abstract": "Recent advances in reinforcement learning have shown that language models can\ndevelop sophisticated reasoning through training on tasks with verifiable\nrewards, but these approaches depend on human-curated problem-answer pairs and\ndomain-specific reward engineering. We introduce SPIRAL, a self-play framework\nwhere models learn by playing multi-turn, zero-sum games against continuously\nimproving versions of themselves, eliminating the need for human supervision.\nThrough self-play, SPIRAL generates an infinite curriculum of progressively\nchallenging problems as models must constantly adapt to stronger opponents. To\nenable this self-play training at scale, We implement a fully online,\nmulti-turn, multi-agent reinforcement learning system for LLMs and propose\nrole-conditioned advantage estimation (RAE) to stabilize multi-agent training.\nUsing SPIRAL, self-play on zero-sum games produces reasoning capabilities that\ntransfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%\nimprovement on math and 8.4% on general reasoning, outperforming SFT on 25,000\nexpert game trajectories. Analysis reveals that this transfer occurs through\nthree cognitive patterns: systematic decomposition, expected value calculation,\nand case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple\nNegotiation) further enhances performance as each game develops distinct\nreasoning strengths. Applying SPIRAL to a strong reasoning model\n(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These\nresults demonstrate that zero-sum games naturally develop transferable\nreasoning capabilities, highlighting a promising direction for autonomous\nreasoning development.",
        "url": "http://arxiv.org/abs/2506.24119v2",
        "pdf_url": "http://arxiv.org/pdf/2506.24119v2",
        "arxiv_id": "2506.24119v2",
        "authors": [
            "Bo Liu",
            "Leon Guertler",
            "Simon Yu",
            "Zichen Liu",
            "Penghui Qi",
            "Daniel Balcells",
            "Mickel Liu",
            "Cheston Tan",
            "Weiyan Shi",
            "Min Lin",
            "Wee Sun Lee",
            "Natasha Jaques"
        ],
        "submitted": "2025-06-30 17:58:13",
        "source": "arxiv",
        "comment": "Work in Progress",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on reinforcement learning and multi-agent systems, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions language models, the context is different from the user's interests in NLP and IR. The paper's emphasis on zero-sum games and self-play training is not relevant to the user's research themes."
    },
    {
        "title": "TaP: A Taxonomy-Guided Framework for Automated and Scalable Preference Data Generation",
        "abstract": "Conducting supervised fine-tuning and preference fine-tuning on large\nlanguage models (LLMs) requires high-quality datasets to improve their ability\nto follow instructions and align with human preferences and values. However,\nconstructing such datasets is resource-intensive, and most available datasets\nfor supervised and preference fine-tuning are in English. To address these\nchallenges, we propose the \\underline{\\textbf{Ta}}xonomy-Guided\n\\underline{\\textbf{P}}reference Data Generation (TaP) framework, which\nfacilitates automated and scalable construction of preference datasets across\nvarious languages. TaP is grounded in a structured taxonomy that allows\nfine-grained control over dataset composition, thereby ensuring both diversity\nand comprehensive coverage. We employ TaP-generated datasets to perform\nsupervised and preference fine-tuning on various LLMs. Experimental results\ndemonstrate that LLMs trained on TaP-generated datasets outperform those\ntrained on existing open-source datasets. Remarkably, LLMs trained on\nTaP-generated datasets surpass the performance of those trained on an\nopen-source dataset that is 180 times larger.",
        "url": "http://arxiv.org/abs/2506.23979v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23979v1",
        "arxiv_id": "2506.23979v1",
        "authors": [
            "Renren Jin",
            "Tianhao Shen",
            "Xinwei Wu",
            "Dan Shi",
            "Haoran Sun",
            "Wuwei Huang",
            "Quandong Wang",
            "Wei Liu",
            "Jian Luan",
            "Bin Wang",
            "Deyi Xiong"
        ],
        "submitted": "2025-06-30 15:45:28",
        "source": "arxiv",
        "comment": "33 pages, 15 tables, 11 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on preference data generation and fine-tuning of large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on NLP, the topic is more specific to language models and dataset construction, which is not a central match for your research interests."
    },
    {
        "title": "Unveiling Decision-Making in LLMs for Text Classification : Extraction of influential and interpretable concepts with Sparse Autoencoders",
        "abstract": "Sparse Autoencoders (SAEs) have been successfully used to probe Large\nLanguage Models (LLMs) and extract interpretable concepts from their internal\nrepresentations. These concepts are linear combinations of neuron activations\nthat correspond to human-interpretable features. In this paper, we investigate\nthe effectiveness of SAE-based explainability approaches for sentence\nclassification, a domain where such methods have not been extensively explored.\nWe present a novel SAE-based architecture tailored for text classification,\nleveraging a specialized classifier head and incorporating an activation rate\nsparsity loss. We benchmark this architecture against established methods such\nas ConceptShap, Independent Component Analysis, and other SAE-based concept\nextraction techniques. Our evaluation covers two classification benchmarks and\nfour fine-tuned LLMs from the Pythia family. We further enrich our analysis\nwith two novel metrics for measuring the precision of concept-based\nexplanations, using an external sentence encoder. Our empirical results show\nthat our architecture improves both the causality and interpretability of the\nextracted features.",
        "url": "http://arxiv.org/abs/2506.23951v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23951v1",
        "arxiv_id": "2506.23951v1",
        "authors": [
            "Mathis Le Bail",
            "J√©r√©mie Dentan",
            "Davide Buscaldi",
            "Sonia Vanier"
        ],
        "submitted": "2025-06-30 15:18:50",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of Sparse Autoencoders to extract interpretable concepts from Large Language Models for text classification, which is a topic in Natural Language Processing. While it touches on the idea of extracting features, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval."
    },
    {
        "title": "Garbage In, Reasoning Out? Why Benchmark Scores are Unreliable and What to Do About It",
        "abstract": "We conduct a systematic audit of three widely used reasoning benchmarks,\nSocialIQa, FauxPas-EAI, and ToMi, and uncover pervasive flaws in both benchmark\nitems and evaluation methodology. Using five LLMs (GPT-{3, 3.5, 4, o1}, and\nLLaMA 3.1) as diagnostic tools, we identify structural, semantic, and pragmatic\nissues in benchmark design (e.g., duplicated items, ambiguous wording, and\nimplausible answers), as well as scoring procedures that prioritize output form\nover reasoning process. Through systematic human annotation and re-evaluation\non cleaned benchmark subsets, we find that model scores often improve not due\nto due to erratic surface wording variations and not to improved reasoning.\nInfact, further analyses show that model performance is highly sensitive to\nminor input variations such as context availability and phrasing, revealing\nthat high scores may reflect alignment with format-specific cues rather than\nconsistent inference based on the input. These findings challenge the validity\nof current benchmark-based claims about reasoning in LLMs, and highlight the\nneed for evaluation protocols that assess reasoning as a process of drawing\ninference from available information, rather than as static output selection.\nWe release audited data and evaluation tools to support more interpretable and\ndiagnostic assessments of model reasoning.",
        "url": "http://arxiv.org/abs/2506.23864v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23864v1",
        "arxiv_id": "2506.23864v1",
        "authors": [
            "Seyed Mahed Mousavi",
            "Edoardo Cecchinato",
            "Lucia Hornikova",
            "Giuseppe Riccardi"
        ],
        "submitted": "2025-06-30 13:57:28",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper's focus on benchmarking and evaluation methodology in natural language processing (NLP) is not directly related to the user's interests in information retrieval, query understanding, ranking models, and user behavior modeling. While the paper touches on topics like language models and reasoning, the context is not relevant to the user's primary research areas."
    },
    {
        "title": "Towards the \"Digital Me\": A vision of authentic Conversational Agents powered by personal Human Digital Twins",
        "abstract": "Human Digital Twins (HDTs) have traditionally been conceptualized as\ndata-driven models designed to support decision-making across various domains.\nHowever, recent advancements in conversational AI open new possibilities for\nHDTs to function as authentic, interactive digital counterparts of individuals.\nThis paper introduces a novel HDT system architecture that integrates large\nlanguage models with dynamically updated personal data, enabling it to mirror\nan individual's conversational style, memories, and behaviors. To achieve this,\nour approach implements context-aware memory retrieval, neural\nplasticity-inspired consolidation, and adaptive learning mechanisms, creating a\nmore natural and evolving digital persona. The resulting system does not only\nreplicate an individual's unique conversational style depending on who they are\nspeaking with, but also enriches responses with dynamically captured personal\nexperiences, opinions, and memories. While this marks a significant step toward\ndeveloping authentic virtual counterparts, it also raises critical ethical\nconcerns regarding privacy, accountability, and the long-term implications of\npersistent digital identities. This study contributes to the field of HDTs by\ndescribing our novel system architecture, demonstrating its capabilities, and\ndiscussing future directions and emerging challenges to ensure the responsible\nand ethical development of HDTs.",
        "url": "http://arxiv.org/abs/2506.23826v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23826v1",
        "arxiv_id": "2506.23826v1",
        "authors": [
            "Llu√≠s C. Coll",
            "Martin W. Lauer-Schmaltz",
            "Philip Cash",
            "John P. Hansen",
            "Anja Maier"
        ],
        "submitted": "2025-06-30 13:18:31",
        "source": "arxiv",
        "comment": "24 pages, 9 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it touches on conversational AI, the focus is on Human Digital Twins and their applications, which is outside the scope of the user's primary research interests."
    },
    {
        "title": "Evaluating the Simulation of Human Personality-Driven Susceptibility to Misinformation with LLMs",
        "abstract": "Large language models (LLMs) make it possible to generate synthetic\nbehavioural data at scale, offering an ethical and low-cost alternative to\nhuman experiments. Whether such data can faithfully capture psychological\ndifferences driven by personality traits, however, remains an open question. We\nevaluate the capacity of LLM agents, conditioned on Big-Five profiles, to\nreproduce personality-based variation in susceptibility to misinformation,\nfocusing on news discernment, the ability to judge true headlines as true and\nfalse headlines as false. Leveraging published datasets in which human\nparticipants with known personality profiles rated headline accuracy, we create\nmatching LLM agents and compare their responses to the original human patterns.\nCertain trait-misinformation associations, notably those involving\nAgreeableness and Conscientiousness, are reliably replicated, whereas others\ndiverge, revealing systematic biases in how LLMs internalize and express\npersonality. The results underscore both the promise and the limits of\npersonality-aligned LLMs for behavioral simulation, and offer new insight into\nmodeling cognitive diversity in artificial agents.",
        "url": "http://arxiv.org/abs/2506.23610v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23610v1",
        "arxiv_id": "2506.23610v1",
        "authors": [
            "Manuel Pratelli",
            "Marinella Petrocchi"
        ],
        "submitted": "2025-06-30 08:16:07",
        "source": "arxiv",
        "comment": "pre-print version - paper actually under submission",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper evaluates the simulation of human personality-driven susceptibility to misinformation using Large Language Models (LLMs), which is a topic in Natural Language Processing (NLP). Although it's not directly related to Information Retrieval (IR) or Search technologies, it touches on the theme of understanding human behavior, which is a related topic. However, the focus on personality-driven susceptibility to misinformation is not directly aligned with the user's primary research interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Hierarchical Memory Organization for Wikipedia Generation",
        "abstract": "Generating Wikipedia articles autonomously is a challenging task requiring\nthe integration of accurate, comprehensive, and well-structured information\nfrom diverse sources. This paper introduces the Memory Organization-based\nGeneration (MOG) framework, a novel approach to address these challenges by\nleveraging a hierarchical memory architecture. MOG extracts fine-grained memory\nunits from web documents, recursively organizes them into a Wikipedia-style\nhierarchical structure, and uses this structure to guide the generation\nprocess. This ensures alignment between memory and the article outline,\nimproving both informativeness and verifiability while minimizing\nhallucinations. Additionally, a citation module is implemented to enhance\ntraceability by linking every generated sentence to specific memory units.\nEvaluations on our newly created WikiStart dataset demonstrate that MOG\noutperforms baseline methods in producing informative and reliable articles,\nmaking it particularly robust in real-world scenarios.",
        "url": "http://arxiv.org/abs/2506.23393v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23393v1",
        "arxiv_id": "2506.23393v1",
        "authors": [
            "Eugene J. Yu",
            "Dawei Zhu",
            "Yifan Song",
            "Xiangyu Wong",
            "Jiebin Zhang",
            "Wenxuan Shi",
            "Xiaoguang Li",
            "Qun Liu",
            "Sujian Li"
        ],
        "submitted": "2025-06-29 20:22:49",
        "source": "arxiv",
        "comment": "ACL 2025 Main Conference",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on generating Wikipedia articles using a hierarchical memory architecture, which is not directly related to information retrieval, search technologies, or query understanding. While it involves processing and organizing information, the context is different from the user's primary research interests."
    },
    {
        "title": "You Sound a Little Tense: L2 Tailored Clear TTS Using Durational Vowel Properties",
        "abstract": "We present the first text-to-speech (TTS) system tailored to second language\n(L2) speakers. We use duration differences between American English tense\n(longer) and lax (shorter) vowels to create a \"clarity mode\" for Matcha-TTS.\nOur perception studies showed that French-L1, English-L2 listeners had fewer\n(at least 9.15%) transcription errors when using our clarity mode, and found it\nmore encouraging and respectful than overall slowed down speech. Remarkably,\nlisteners were not aware of these effects: despite the decreased word error\nrate in clarity mode, listeners still believed that slowing all target words\nwas the most intelligible, suggesting that actual intelligibility does not\ncorrelate with perceived intelligibility. Additionally, we found that\nWhisper-ASR did not use the same cues as L2 speakers to differentiate difficult\nvowels and is not sufficient to assess the intelligibility of TTS systems for\nthese individuals.",
        "url": "http://arxiv.org/abs/2506.23367v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23367v1",
        "arxiv_id": "2506.23367v1",
        "authors": [
            "Paige Tutt√∂s√≠",
            "H. Henny Yeung",
            "Yue Wang",
            "Jean-Julien Aucouturier",
            "Angelica Lim"
        ],
        "submitted": "2025-06-29 18:55:05",
        "source": "arxiv",
        "comment": "Accepted to ISCA Speech Synthesis Workshop, 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The topic of text-to-speech systems for second language speakers is outside your primary focus on information retrieval and real-time relevance optimization."
    },
    {
        "title": "Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective",
        "abstract": "The progress of Large Language Models (LLMs) like ChatGPT raises the question\nof how they can be integrated into education. One hope is that they can support\nmathematics learning, including word-problem solving. Since LLMs can handle\ntextual input with ease, they appear well-suited for solving mathematical word\nproblems. Yet their real competence, whether they can make sense of the\nreal-world context, and the implications for classrooms remain unclear. We\nconducted a scoping review from a mathematics-education perspective, including\nthree parts: a technical overview, a systematic review of word problems used in\nresearch, and a state-of-the-art empirical evaluation of LLMs on mathematical\nword problems. First, in the technical overview, we contrast the\nconceptualization of word problems and their solution processes between LLMs\nand students. In computer-science research this is typically labeled\nmathematical reasoning, a term that does not align with usage in mathematics\neducation. Second, our literature review of 213 studies shows that the most\npopular word-problem corpora are dominated by s-problems, which do not require\na consideration of realities of their real-world context. Finally, our\nevaluation of GPT-3.5-turbo, GPT-4o-mini, GPT-4.1, and o3 on 287 word problems\nshows that most recent LLMs solve these s-problems with near-perfect accuracy,\nincluding a perfect score on 20 problems from PISA. LLMs still showed\nweaknesses in tackling problems where the real-world context is problematic or\nnon-sensical. In sum, we argue based on all three aspects that LLMs have\nmastered a superficial solution process but do not make sense of word problems,\nwhich potentially limits their value as instructional tools in mathematics\nclassrooms.",
        "url": "http://arxiv.org/abs/2506.24006v1",
        "pdf_url": "http://arxiv.org/pdf/2506.24006v1",
        "arxiv_id": "2506.24006v1",
        "authors": [
            "Anselm R. Strohmaier",
            "Wim Van Dooren",
            "Kathrin Se√üler",
            "Brian Greer",
            "Lieven Verschaffel"
        ],
        "submitted": "2025-06-30 16:10:42",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. It focuses on the application of Large Language Models in mathematics education, which is outside the scope of the user's research interests."
    },
    {
        "title": "Machine Understanding of Scientific Language",
        "abstract": "Scientific information expresses human understanding of nature. This\nknowledge is largely disseminated in different forms of text, including\nscientific papers, news articles, and discourse among people on social media.\nWhile important for accelerating our pursuit of knowledge, not all scientific\ntext is faithful to the underlying science. As the volume of this text has\nburgeoned online in recent years, it has become a problem of societal\nimportance to be able to identify the faithfulness of a given piece of\nscientific text automatically. This thesis is concerned with the cultivation of\ndatasets, methods, and tools for machine understanding of scientific language,\nin order to analyze and understand science communication at scale. To arrive at\nthis, I present several contributions in three areas of natural language\nprocessing and machine learning: automatic fact checking, learning with limited\ndata, and scientific text processing. These contributions include new methods\nand resources for identifying check-worthy claims, adversarial claim\ngeneration, multi-source domain adaptation, learning from crowd-sourced labels,\ncite-worthiness detection, zero-shot scientific fact checking, detecting\nexaggerated scientific claims, and modeling degrees of information change in\nscience communication. Critically, I demonstrate how the research outputs of\nthis thesis are useful for effectively learning from limited amounts of\nscientific text in order to identify misinformative scientific statements and\ngenerate new insights into the science communication process",
        "url": "http://arxiv.org/abs/2506.23990v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23990v1",
        "arxiv_id": "2506.23990v1",
        "authors": [
            "Dustin Wright"
        ],
        "submitted": "2025-06-30 15:55:10",
        "source": "arxiv",
        "comment": "PhD Thesis, 210 pages",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores machine understanding of scientific language, which is related to information retrieval and natural language processing. The focus on automatic fact checking, learning with limited data, and scientific text processing is somewhat relevant to query understanding and ranking models. However, the paper's primary focus on scientific language understanding and science communication is not directly aligned with the user's core research themes."
    },
    {
        "title": "IMPACT: Inflectional Morphology Probes Across Complex Typologies",
        "abstract": "Large Language Models (LLMs) have shown significant progress on various\nmultilingual benchmarks and are increasingly used to generate and evaluate text\nin non-English languages. However, while they may produce fluent outputs, it\nremains unclear to what extent these models truly grasp the underlying\nlinguistic complexity of those languages, particularly in morphology. To\ninvestigate this, we introduce IMPACT, a synthetically generated evaluation\nframework focused on inflectional morphology, which we publicly release,\ndesigned to evaluate LLM performance across five morphologically rich\nlanguages: Arabic, Russian, Finnish, Turkish, and Hebrew. IMPACT includes\nunit-test-style cases covering both shared and language-specific phenomena,\nfrom basic verb inflections (e.g., tense, number, gender) to unique features\nlike Arabic's reverse gender agreement and vowel harmony in Finnish and\nTurkish. We assess eight multilingual LLMs that, despite strong English\nperformance, struggle with other languages and uncommon morphological patterns,\nespecially when judging ungrammatical examples. We also show that Chain of\nThought and Thinking Models can degrade performance. Our work exposes gaps in\nLLMs' handling of linguistic complexity, pointing to clear room for\nimprovement. To support further research, we publicly release the IMPACT\nframework.",
        "url": "http://arxiv.org/abs/2506.23929v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23929v1",
        "arxiv_id": "2506.23929v1",
        "authors": [
            "Mohammed J. Saeed",
            "Tommi Vehvilainen",
            "Evgeny Fedoseev",
            "Sevil Caliskan",
            "Tatiana Vodolazova"
        ],
        "submitted": "2025-06-30 14:58:23",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on evaluating the performance of Large Language Models on inflectional morphology in five languages, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on the topic of linguistic complexity, it does not address the specific areas of interest in query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Efficient Interleaved Speech Modeling through Knowledge Distillation",
        "abstract": "Current speech language models exceed the size and latency constraints of\nmany deployment environments. We build compact, expressive speech generation\nmodels through layer-aligned distillation, matching hidden states, attention\nmaps, and softened logits to compress large multimodal transformers by 3x with\nminimal loss in performance. We introduce TinyWave, a family of 2B-parameter\nmodels for speech-to-speech and interleaved speech-text generation, trained on\n50,000 hours of public audio. TinyWave supports (i) speech-only generation\nusing phonetic or expressive tokens and (ii) mixed speech-text continuations.\nEvaluation on Libri-Light shows TinyWave within 1.4 normalized perplexity\npoints of its teacher. Accuracy on spoken StoryCloze and SALMon reaches 93-97%\nof the teacher's performance, outperforming size-matched baselines. These\nmodels are optimized for deployment on commodity hardware, enabling\napplications in real-time conversational agents, assistive technologies, and\nlow-resource environments. We release models, training code, and evaluation\nscripts to support reproducible research on compact, expressive speech\ngeneration.",
        "url": "http://arxiv.org/abs/2506.23670v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23670v1",
        "arxiv_id": "2506.23670v1",
        "authors": [
            "Mohammadmahdi Nouriborji",
            "Morteza Rohanian"
        ],
        "submitted": "2025-06-30 09:47:37",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on speech language models, knowledge distillation, and compact speech generation, which are not directly related to your areas of interest."
    },
    {
        "title": "Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack",
        "abstract": "We extend BeamAttack, an adversarial attack algorithm designed to evaluate\nthe robustness of text classification systems through word-level modifications\nguided by beam search. Our extensions include support for word deletions and\nthe option to skip substitutions, enabling the discovery of minimal\nmodifications that alter model predictions. We also integrate LIME to better\nprioritize word replacements. Evaluated across multiple datasets and victim\nmodels (BiLSTM, BERT, and adversarially trained RoBERTa) within the BODEGA\nframework, our approach achieves over a 99\\% attack success rate while\npreserving the semantic and lexical similarity of the original texts. Through\nboth quantitative and qualitative analysis, we highlight BeamAttack's\neffectiveness and its limitations. Our implementation is available at\nhttps://github.com/LucK1Y/BeamAttack",
        "url": "http://arxiv.org/abs/2506.23661v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23661v1",
        "arxiv_id": "2506.23661v1",
        "authors": [
            "Arnisa Fazla",
            "Lucas Krauter",
            "David Guzman Piedrahita",
            "Andrianos Michail"
        ],
        "submitted": "2025-06-30 09:37:19",
        "source": "arxiv",
        "comment": "12 pages main text, 27 pages total including references and\n  appendices. 13 figures, 10 tables. Accepted for publication in the LNCS\n  proceedings of CLEF 2025 (Best-of-Labs track)",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on adversarial attacks on text classification systems, which is not directly related to the user's interests in Information Retrieval, Search technologies, and query understanding. While it touches on NLP, the specific topic of robustness to adversarial examples is not a central match for the user's research themes."
    },
    {
        "title": "MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI",
        "abstract": "Reasoning plays a crucial role in advancing Multimodal Large Language Models\n(MLLMs) toward Artificial General Intelligence. However, existing MLLM\nbenchmarks often fall short in precisely and comprehensively evaluating\nlong-chain reasoning abilities from three key aspects: (1) lack of difficulty\nand diversity, (2) susceptibility to guessability and memorization, (3)\ninadequate assessment of intermediate reasoning steps. To fill this gap, we\nintroduce MMReason, a new benchmark designed to precisely and comprehensively\nevaluate MLLM long-chain reasoning capability with diverse, open-ended,\nchallenging questions. First, we curate challenging questions requiring\nmulti-step reasoning from various fields (i.e., 6 disciplines) and multiple\ndifficulty levels (i.e., from pre-university to university, and from\nfoundational to competition tiers). Second, these questions are reformulated\ninto an open-ended format and filtered using a multi-model voting technique to\neliminate shortcut cases related to guessing and memorization, ensuring robust\nreasoning evaluations. Third, we annotate the questions with detailed\nstep-by-step solutions, and design a reference-based ternary scoring mechanism\nto reliably assess intermediate reasoning steps. With MMReason, we benchmark\npopular leading MLLMs and provide an in-depth analysis of their reasoning\ncapabilities. We hope MMReason will serve as a valuable resource for advancing\nMLLM reasoning research. Code will be available at\nhttps://github.com/HJYao00/MMReason.",
        "url": "http://arxiv.org/abs/2506.23563v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23563v1",
        "arxiv_id": "2506.23563v1",
        "authors": [
            "Huanjin Yao",
            "Jiaxing Huang",
            "Yawen Qiu",
            "Michael K. Chen",
            "Wenzheng Liu",
            "Wei Zhang",
            "Wenjie Zeng",
            "Xikun Zhang",
            "Jingyi Zhang",
            "Yuxin Song",
            "Wenhao Wu",
            "Dacheng Tao"
        ],
        "submitted": "2025-06-30 07:14:38",
        "source": "arxiv",
        "comment": "Technical report",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on multimodal large language models and their ability to perform long-chain reasoning, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on the topic of evaluating AI models, it does not address the specific areas of interest in the user's research, such as ranking models, user behavior modeling, or deep semantic understanding."
    },
    {
        "title": "Teaching a Language Model to Speak the Language of Tools",
        "abstract": "External tool integration through function-calling is essential for practical\nlanguage model applications, yet most multilingual models lack reliable\ntool-use capabilities in non-English languages. Even state-of-the-art\nmultilingual models struggle with determining when to use tools and generating\nthe structured outputs required for function calls, often exhibiting language\nconfusion when prompted in lower-resource languages. This work presents a\nmethodology for adapting existing language models to enable robust tool use in\nany target language, using Bulgarian as a case study. The approach involves\ncontinued training of the BgGPT model series (2.6B, 9B, 27B parameters) on a\nnovel bilingual dataset of 10,035 function-calling examples designed to support\nstandardized protocols like MCP (Model Context Protocol). The research\nintroduces TUCAN (Tool-Using Capable Assistant Navigator), which achieves up to\n28.75% improvement in function-calling accuracy over base models while\npreserving core language understanding, as verified on established Bulgarian\nbenchmarks. Beyond accuracy gains, TUCAN models demonstrate production-ready\nresponse formatting with clean, parsable function calls, contrasting with the\nverbose and inconsistent outputs of base models. The models, evaluation\nframework, and dataset are released to enable replication for other languages.\nThis work demonstrates a practical approach for extending tool-augmented\ncapabilities beyond English-centric systems.",
        "url": "http://arxiv.org/abs/2506.23394v1",
        "pdf_url": "http://arxiv.org/pdf/2506.23394v1",
        "arxiv_id": "2506.23394v1",
        "authors": [
            "Simeon Emanuilov"
        ],
        "submitted": "2025-06-29 20:47:27",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on adapting language models for tool-use capabilities in non-English languages, which is related to query understanding and ranking models in Information Retrieval. However, the paper's primary focus is on language models and tool integration, rather than search technologies or user behavior modeling, making it only loosely relevant to the user's research interests."
    }
]