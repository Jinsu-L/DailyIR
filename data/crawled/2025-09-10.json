[
    {
        "title": "Parallel-R1: Towards Parallel Thinking via Reinforcement Learning",
        "abstract": "Parallel thinking has emerged as a novel approach for enhancing the reasoning\ncapabilities of large language models (LLMs) by exploring multiple reasoning\npaths concurrently. However, activating such capabilities through training\nremains challenging, as existing methods predominantly rely on supervised\nfine-tuning (SFT) over synthetic data, which encourages teacher-forced\nimitation rather than exploration and generalization. Different from them, we\npropose \\textbf{Parallel-R1}, the first reinforcement learning (RL) framework\nthat enables parallel thinking behaviors for complex real-world reasoning\ntasks. Our framework employs a progressive curriculum that explicitly addresses\nthe cold-start problem in training parallel thinking with RL. We first use SFT\non prompt-generated trajectories from easier tasks to instill the parallel\nthinking ability, then transition to RL to explore and generalize this skill on\nharder problems. Experiments on various math benchmarks, including MATH, AMC23,\nand AIME, show that Parallel-R1 successfully instills parallel thinking,\nleading to 8.4% accuracy improvements over the sequential thinking model\ntrained directly on challenging tasks with RL. Further analysis reveals a clear\nshift in the model's thinking behavior: at an early stage, it uses parallel\nthinking as an exploration strategy, while in a later stage, it uses the same\ncapability for multi-perspective verification. Most significantly, we validate\nparallel thinking as a \\textbf{mid-training exploration scaffold}, where this\ntemporary exploratory phase unlocks a higher performance ceiling after RL,\nyielding a 42.9% improvement over the baseline on AIME25. Our model, data, and\ncode will be open-source at https://github.com/zhengkid/Parallel-R1.",
        "url": "http://arxiv.org/abs/2509.07980v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07980v1",
        "arxiv_id": "2509.07980v1",
        "authors": [
            "Tong Zheng",
            "Hongming Zhang",
            "Wenhao Yu",
            "Xiaoyang Wang",
            "Xinyu Yang",
            "Runpeng Dai",
            "Rui Liu",
            "Huiwen Bao",
            "Chengsong Huang",
            "Heng Huang",
            "Dong Yu"
        ],
        "submitted": "2025-09-09 17:59:35",
        "source": "arxiv",
        "comment": "Project website: https://zhengkid.github.io/Parallel_R1.github.io/"
    },
    {
        "title": "Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search",
        "abstract": "Recent advances in large multimodal models have leveraged image-based tools\nwith reinforcement learning to tackle visual problems. However, existing\nopen-source approaches often exhibit monotonous reasoning patterns and allow\nonly a limited number of interaction turns, making them inadequate for\ndifficult tasks that require trial-and-error exploration. In this work, we\naddress this limitation by scaling up tool-based interactions and introduce\nMini-o3, a system that executes deep, multi-turn reasoning -- spanning tens of\nsteps -- and achieves state-of-the-art performance on challenging visual search\ntasks. Our recipe for reproducing OpenAI o3-style behaviors comprises three key\ncomponents. First, we construct the Visual Probe Dataset, a collection of\nthousands of challenging visual search problems designed for exploratory\nreasoning. Second, we develop an iterative data collection pipeline to obtain\ncold-start trajectories that exhibit diverse reasoning patterns, including\ndepth-first search, trial-and-error, and goal maintenance. Third, we propose an\nover-turn masking strategy that prevents penalization of over-turn responses\n(those that hit the maximum number of turns) during reinforcement learning,\nthereby balancing training-time efficiency with test-time scalability. Despite\ntraining with an upper bound of only six interaction turns, our model generates\ntrajectories that naturally scale to tens of turns at inference time, with\naccuracy improving as the number of turns increases. Extensive experiments\ndemonstrate that Mini-o3 produces rich reasoning patterns and deep thinking\npaths, effectively solving challenging visual search problems.",
        "url": "http://arxiv.org/abs/2509.07969v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07969v1",
        "arxiv_id": "2509.07969v1",
        "authors": [
            "Xin Lai",
            "Junyi Li",
            "Wei Li",
            "Tao Liu",
            "Tianjian Li",
            "Hengshuang Zhao"
        ],
        "submitted": "2025-09-09 17:54:21",
        "source": "arxiv",
        "comment": "Code, datasets, models are available at\n  https://github.com/Mini-o3/Mini-o3. Project Page: https://mini-o3.github.io/"
    },
    {
        "title": "SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge",
        "abstract": "We introduce SimpleQA Verified, a 1,000-prompt benchmark for evaluating Large\nLanguage Model (LLM) short-form factuality based on OpenAI's SimpleQA. It\naddresses critical limitations in OpenAI's benchmark, including noisy and\nincorrect labels, topical biases, and question redundancy. SimpleQA Verified\nwas created through a rigorous multi-stage filtering process involving\nde-duplication, topic balancing, and source reconciliation to produce a more\nreliable and challenging evaluation set, alongside improvements in the\nautorater prompt. On this new benchmark, Gemini 2.5 Pro achieves a\nstate-of-the-art F1-score of 55.6, outperforming other frontier models,\nincluding GPT-5. This work provides the research community with a\nhigher-fidelity tool to track genuine progress in parametric model factuality\nand to mitigate hallucinations. The benchmark dataset, evaluation code, and\nleaderboard are available at:\nhttps://www.kaggle.com/benchmarks/deepmind/simpleqa-verified.",
        "url": "http://arxiv.org/abs/2509.07968v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07968v1",
        "arxiv_id": "2509.07968v1",
        "authors": [
            "Lukas Haas",
            "Gal Yona",
            "Giovanni D'Antonio",
            "Sasha Goldshtein",
            "Dipanjan Das"
        ],
        "submitted": "2025-09-09 17:53:58",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Visual-TableQA: Open-Domain Benchmark for Reasoning over Table Images",
        "abstract": "Visual reasoning over structured data such as tables is a critical capability\nfor modern vision-language models (VLMs), yet current benchmarks remain limited\nin scale, diversity, or reasoning depth, especially when it comes to rendered\ntable images. Addressing this gap, we introduce Visual-TableQA, a large-scale,\nopen-domain multimodal dataset specifically designed to evaluate and enhance\nvisual reasoning over complex tabular data. Our generation pipeline is modular,\nscalable, and fully autonomous, involving multiple reasoning LLMs collaborating\nacross distinct roles: generation, validation, and inspiration. Visual-TableQA\ncomprises 2.5k richly structured LaTeX-rendered tables and 6k\nreasoning-intensive QA pairs, all produced at a cost of under USD 100. To\npromote diversity and creativity, our pipeline performs multi-model\ncollaborative data generation via cross-model prompting ('inspiration') and\nLLM-jury filtering. Stronger models seed layouts and topics that weaker models\nelaborate, collectively distilling diverse reasoning patterns and visual\nstructures into the dataset. Empirical results show that models fine-tuned on\nVisual-TableQA generalize robustly to external benchmarks, outperforming\nseveral proprietary models despite the dataset's synthetic nature. The full\npipeline and resources are publicly available at\nhttps://github.com/AI-4-Everyone/Visual-TableQA.",
        "url": "http://arxiv.org/abs/2509.07966v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07966v1",
        "arxiv_id": "2509.07966v1",
        "authors": [
            "Boammani Aser Lompo",
            "Marc Haraoui"
        ],
        "submitted": "2025-09-09 17:52:26",
        "source": "arxiv",
        "comment": "Work in Progress"
    },
    {
        "title": "Smart Fast Finish: Preventing Overdelivery via Daily Budget Pacing at DoorDash",
        "abstract": "We present a budget pacing feature called Smart Fast Finish (SFF). SFF builds\nupon the industry standard Fast Finish (FF) feature in budget pacing systems\nthat depletes remaining advertising budget as quickly as possible towards the\nend of some fixed time period. SFF dynamically updates system parameters such\nas start time and throttle rate depending on historical ad-campaign data. SFF\nis currently in use at DoorDash, one of the largest delivery platforms in the\nUS, and is part of its budget pacing system. We show via online budget-split\nexperimentation data and offline simulations that SFF is a robust solution for\noverdelivery mitigation when pacing budget.",
        "url": "http://arxiv.org/abs/2509.07929v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07929v1",
        "arxiv_id": "2509.07929v1",
        "authors": [
            "Rohan Garg",
            "Yongjin Xiao",
            "Jason",
            "Yang",
            "Mandar Rahurkar"
        ],
        "submitted": "2025-09-09 17:14:09",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "GENUINE: Graph Enhanced Multi-level Uncertainty Estimation for Large Language Models",
        "abstract": "Uncertainty estimation is essential for enhancing the reliability of Large\nLanguage Models (LLMs), particularly in high-stakes applications. Existing\nmethods often overlook semantic dependencies, relying on token-level\nprobability measures that fail to capture structural relationships within the\ngenerated text. We propose GENUINE: Graph ENhanced mUlti-level uncertaINty\nEstimation for Large Language Models, a structure-aware framework that\nleverages dependency parse trees and hierarchical graph pooling to refine\nuncertainty quantification. By incorporating supervised learning, GENUINE\neffectively models semantic and structural relationships, improving confidence\nassessments. Extensive experiments across NLP tasks show that GENUINE achieves\nup to 29% higher AUROC than semantic entropy-based approaches and reduces\ncalibration errors by over 15%, demonstrating the effectiveness of graph-based\nuncertainty modeling. The code is available at\nhttps://github.com/ODYSSEYWT/GUQ.",
        "url": "http://arxiv.org/abs/2509.07925v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07925v1",
        "arxiv_id": "2509.07925v1",
        "authors": [
            "Tuo Wang",
            "Adithya Kulkarni",
            "Tyler Cody",
            "Peter A. Beling",
            "Yujun Yan",
            "Dawei Zhou"
        ],
        "submitted": "2025-09-09 17:07:44",
        "source": "arxiv",
        "comment": "Accepted by EMNLP 2025"
    },
    {
        "title": "Uncovering Scaling Laws for Large Language Models via Inverse Problems",
        "abstract": "Large Language Models (LLMs) are large-scale pretrained models that have\nachieved remarkable success across diverse domains. These successes have been\ndriven by unprecedented complexity and scale in both data and computations.\nHowever, due to the high costs of training such models, brute-force\ntrial-and-error approaches to improve LLMs are not feasible. Inspired by the\nsuccess of inverse problems in uncovering fundamental scientific laws, this\nposition paper advocates that inverse problems can also efficiently uncover\nscaling laws that guide the building of LLMs to achieve the desirable\nperformance with significantly better cost-effectiveness.",
        "url": "http://arxiv.org/abs/2509.07909v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07909v1",
        "arxiv_id": "2509.07909v1",
        "authors": [
            "Arun Verma",
            "Zhaoxuan Wu",
            "Zijian Zhou",
            "Xiaoqiang Lin",
            "Zhiliang Chen",
            "Rachael Hwee Ling Sim",
            "Rui Qiao",
            "Jingtan Wang",
            "Nhung Bui",
            "Xinyuan Niu",
            "Wenyang Hu",
            "Gregory Kang Ruey Lau",
            "Zi-Yu Khoo",
            "Zitong Zhao",
            "Xinyi Xu",
            "Apivich Hemachandra",
            "See-Kiong Ng",
            "Bryan Kian Hsiang Low"
        ],
        "submitted": "2025-09-09 16:53:21",
        "source": "arxiv",
        "comment": "Accepted at EMNLP Findings 2025"
    },
    {
        "title": "Biased Tales: Cultural and Topic Bias in Generating Children's Stories",
        "abstract": "Stories play a pivotal role in human communication, shaping beliefs and\nmorals, particularly in children. As parents increasingly rely on large\nlanguage models (LLMs) to craft bedtime stories, the presence of cultural and\ngender stereotypes in these narratives raises significant concerns. To address\nthis issue, we present Biased Tales, a comprehensive dataset designed to\nanalyze how biases influence protagonists' attributes and story elements in\nLLM-generated stories. Our analysis uncovers striking disparities. When the\nprotagonist is described as a girl (as compared to a boy), appearance-related\nattributes increase by 55.26%. Stories featuring non-Western children\ndisproportionately emphasize cultural heritage, tradition, and family themes\nfar more than those for Western children. Our findings highlight the role of\nsociocultural bias in making creative AI use more equitable and diverse.",
        "url": "http://arxiv.org/abs/2509.07908v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07908v1",
        "arxiv_id": "2509.07908v1",
        "authors": [
            "Donya Rooein",
            "Vilém Zouhar",
            "Debora Nozza",
            "Dirk Hovy"
        ],
        "submitted": "2025-09-09 16:51:16",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "From Detection to Mitigation: Addressing Gender Bias in Chinese Texts via Efficient Tuning and Voting-Based Rebalancing",
        "abstract": "This paper presents our team's solution to Shared Task 7 of NLPCC-2025, which\nfocuses on sentence-level gender bias detection and mitigation in Chinese. The\ntask aims to promote fairness and controllability in natural language\ngeneration by automatically detecting, classifying, and mitigating gender bias.\nTo address this challenge, we adopt a fine-tuning approach based on large\nlanguage models (LLMs), efficiently adapt to the bias detection task via\nLow-Rank Adaptation (LoRA). In terms of data processing, we construct a more\nbalanced training set to alleviate class imbalance and introduce heterogeneous\nsamples from multiple sources to enhance model generalization. For the\ndetection and classification sub-tasks, we employ a majority voting strategy\nthat integrates outputs from multiple expert models to boost performance.\nAdditionally, to improve bias generation detection and mitigation, we design a\nmulti-temperature sampling mechanism to capture potential variations in bias\nexpression styles. Experimental results demonstrate the effectiveness of our\napproach in bias detection, classification, and mitigation. Our method\nultimately achieves an average score of 47.90%, ranking fourth in the shared\ntask.",
        "url": "http://arxiv.org/abs/2509.07889v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07889v1",
        "arxiv_id": "2509.07889v1",
        "authors": [
            "Chengyan Wu",
            "Yiqiang Cai",
            "Yufei Cheng",
            "Yun Xue"
        ],
        "submitted": "2025-09-09 16:12:11",
        "source": "arxiv",
        "comment": "NLPCC 2025"
    },
    {
        "title": "SciGPT: A Large Language Model for Scientific Literature Understanding and Knowledge Discovery",
        "abstract": "Scientific literature is growing exponentially, creating a critical\nbottleneck for researchers to efficiently synthesize knowledge. While\ngeneral-purpose Large Language Models (LLMs) show potential in text processing,\nthey often fail to capture scientific domain-specific nuances (e.g., technical\njargon, methodological rigor) and struggle with complex scientific tasks,\nlimiting their utility for interdisciplinary research. To address these gaps,\nthis paper presents SciGPT, a domain-adapted foundation model for scientific\nliterature understanding and ScienceBench, an open source benchmark tailored to\nevaluate scientific LLMs.\n  Built on the Qwen3 architecture, SciGPT incorporates three key innovations:\n(1) low-cost domain distillation via a two-stage pipeline to balance\nperformance and efficiency; (2) a Sparse Mixture-of-Experts (SMoE) attention\nmechanism that cuts memory consumption by 55\\% for 32,000-token long-document\nreasoning; and (3) knowledge-aware adaptation integrating domain ontologies to\nbridge interdisciplinary knowledge gaps.\n  Experimental results on ScienceBench show that SciGPT outperforms GPT-4o in\ncore scientific tasks including sequence labeling, generation, and inference.\nIt also exhibits strong robustness in unseen scientific tasks, validating its\npotential to facilitate AI-augmented scientific discovery.",
        "url": "http://arxiv.org/abs/2509.08032v1",
        "pdf_url": "http://arxiv.org/pdf/2509.08032v1",
        "arxiv_id": "2509.08032v1",
        "authors": [
            "Fengyu She",
            "Nan Wang",
            "Hongfei Wu",
            "Ziyi Wan",
            "Jingmian Wang",
            "Chang Wang"
        ],
        "submitted": "2025-09-09 16:09:19",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Are Humans as Brittle as Large Language Models?",
        "abstract": "The output of large language models (LLM) is unstable, due to both\nnon-determinism of the decoding process as well as to prompt brittleness. While\nthe intrinsic non-determinism of LLM generation may mimic existing uncertainty\nin human annotations through distributional shifts in outputs, it is largely\nassumed, yet unexplored, that the prompt brittleness effect is unique to LLMs.\nThis raises the question: do human annotators show similar sensitivity to\ninstruction changes? If so, should prompt brittleness in LLMs be considered\nproblematic? One may alternatively hypothesize that prompt brittleness\ncorrectly reflects human annotation variances. To fill this research gap, we\nsystematically compare the effects of prompt modifications on LLMs and\nidentical instruction modifications for human annotators, focusing on the\nquestion of whether humans are similarly sensitive to prompt perturbations. To\nstudy this, we prompt both humans and LLMs for a set of text classification\ntasks conditioned on prompt variations. Our findings indicate that both humans\nand LLMs exhibit increased brittleness in response to specific types of prompt\nmodifications, particularly those involving the substitution of alternative\nlabel sets or label formats. However, the distribution of human judgments is\nless affected by typographical errors and reversed label order than that of\nLLMs.",
        "url": "http://arxiv.org/abs/2509.07869v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07869v1",
        "arxiv_id": "2509.07869v1",
        "authors": [
            "Jiahui Li",
            "Sean Papay",
            "Roman Klinger"
        ],
        "submitted": "2025-09-09 15:56:51",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "KLIPA: A Knowledge Graph and LLM-Driven QA Framework for IP Analysis",
        "abstract": "Effectively managing intellectual property is a significant challenge.\nTraditional methods for patent analysis depend on labor-intensive manual\nsearches and rigid keyword matching. These approaches are often inefficient and\nstruggle to reveal the complex relationships hidden within large patent\ndatasets, hindering strategic decision-making. To overcome these limitations,\nwe introduce KLIPA, a novel framework that leverages a knowledge graph and a\nlarge language model (LLM) to significantly advance patent analysis. Our\napproach integrates three key components: a structured knowledge graph to map\nexplicit relationships between patents, a retrieval-augmented generation(RAG)\nsystem to uncover contextual connections, and an intelligent agent that\ndynamically determines the optimal strategy for resolving user queries. We\nvalidated KLIPA on a comprehensive, real-world patent database, where it\ndemonstrated substantial improvements in knowledge extraction, discovery of\nnovel connections, and overall operational efficiency. This combination of\ntechnologies enhances retrieval accuracy, reduces reliance on domain experts,\nand provides a scalable, automated solution for any organization managing\nintellectual property, including technology corporations and legal firms,\nallowing them to better navigate the complexities of strategic innovation and\ncompetitive intelligence.",
        "url": "http://arxiv.org/abs/2509.07860v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07860v1",
        "arxiv_id": "2509.07860v1",
        "authors": [
            "Guanzhi Deng",
            "Yi Xie",
            "Yu-Keung Ng",
            "Mingyang Liu",
            "Peijun Zheng",
            "Jie Liu",
            "Dapeng Wu",
            "Yinqiao Li",
            "Linqi Song"
        ],
        "submitted": "2025-09-09 15:40:23",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Small Open Models Achieve Near Parity with Large Models in Low Resource Literary Translation at a Fraction of the Cost",
        "abstract": "Literary translation has recently gained attention as a distinct and complex\ntask in machine translation research. However, the translation by small open\nmodels remains an open problem. We contribute to this ongoing research by\nintroducing TINYFABULIST TRANSLATION FRAMEWORK (TF2), a unified framework for\ndataset creation, fine tuning, and evaluation in English-Romanian literary\ntranslations, centred on the creation and open release of both a compact, fine\ntuned language model (TF2-12B) and large scale synthetic parallel datasets\n(DS-TF2-EN-RO-3M and DS-TF2-EN-RO-15K). Building on DS-TF1-EN-3M (TF1), the\nlargest collection of synthetic English fables to date, we address the need for\nrich, high quality literary datasets in low resource languages such as\nRomanian. Our pipeline first generates 15k high quality Romanian references\nfrom the TF1 pool using a high performing LLM. We then apply a two stage fine\ntuning process to a 12B parameter open weight model: (i) instruction tuning to\ncapture genre specific narrative style, and (ii) adapter compression for\nefficient deployment. Evaluation combines corpus level BLEU and a five\ndimension LLM based rubric (accuracy, fluency, coherence, style, cultural\nadaptation) to provide a nuanced assessment of translation quality. Results\nshow that our fine tuned model achieves fluency and adequacy competitive with\ntop performing large proprietary models, while being open, accessible, and\nsignificantly more cost effective. Alongside the fine tuned model and both\ndatasets, we publicly release all scripts and evaluation prompts. TF2 thus\nprovides an end-to-end, reproducible pipeline for research on cost efficient\ntranslation, cross lingual narrative generation, and the broad adoption of open\nmodels for culturally significant literary content in low resource settings.",
        "url": "http://arxiv.org/abs/2509.07829v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07829v1",
        "arxiv_id": "2509.07829v1",
        "authors": [
            "Mihai Nadas",
            "Laura Diosan",
            "Andreea Tomescu",
            "Andrei Piscoran"
        ],
        "submitted": "2025-09-09 15:07:14",
        "source": "arxiv",
        "comment": "25 pages, 8 figures, includes datasets and models released on Hugging\n  Face"
    },
    {
        "title": "Dual Knowledge-Enhanced Two-Stage Reasoner for Multimodal Dialog Systems",
        "abstract": "Textual response generation is pivotal for multimodal \\mbox{task-oriented}\ndialog systems, which aims to generate proper textual responses based on the\nmultimodal context. While existing efforts have demonstrated remarkable\nprogress, there still exist the following limitations: 1) \\textit{neglect of\nunstructured review knowledge} and 2) \\textit{underutilization of large\nlanguage models (LLMs)}. Inspired by this, we aim to fully utilize dual\nknowledge (\\textit{i.e., } structured attribute and unstructured review\nknowledge) with LLMs to promote textual response generation in multimodal\ntask-oriented dialog systems. However, this task is non-trivial due to two key\nchallenges: 1) \\textit{dynamic knowledge type selection} and 2)\n\\textit{intention-response decoupling}. To address these challenges, we propose\na novel dual knowledge-enhanced two-stage reasoner by adapting LLMs for\nmultimodal dialog systems (named DK2R). To be specific, DK2R first extracts\nboth structured attribute and unstructured review knowledge from external\nknowledge base given the dialog context. Thereafter, DK2R uses an LLM to\nevaluate each knowledge type's utility by analyzing LLM-generated provisional\nprobe responses. Moreover, DK2R separately summarizes the intention-oriented\nkey clues via dedicated reasoning, which are further used as auxiliary signals\nto enhance LLM-based textual response generation. Extensive experiments\nconducted on a public dataset verify the superiority of DK2R. We have released\nthe codes and parameters.",
        "url": "http://arxiv.org/abs/2509.07817v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07817v1",
        "arxiv_id": "2509.07817v1",
        "authors": [
            "Xiaolin Chen",
            "Xuemeng Song",
            "Haokun Wen",
            "Weili Guan",
            "Xiangyu Zhao",
            "Liqiang Nie"
        ],
        "submitted": "2025-09-09 14:55:28",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and Relation Extraction in NLP",
        "abstract": "Structured information extraction from scientific literature is crucial for\ncapturing core concepts and emerging trends in specialized fields. While\nexisting datasets aid model development, most focus on specific publication\nsections due to domain complexity and the high cost of annotating scientific\ntexts. To address this limitation, we introduce SciNLP - a specialized\nbenchmark for full-text entity and relation extraction in the Natural Language\nProcessing (NLP) domain. The dataset comprises 60 manually annotated full-text\nNLP publications, covering 7,072 entities and 1,826 relations. Compared to\nexisting research, SciNLP is the first dataset providing full-text annotations\nof entities and their relationships in the NLP domain. To validate the\neffectiveness of SciNLP, we conducted comparative experiments with similar\ndatasets and evaluated the performance of state-of-the-art supervised models on\nthis dataset. Results reveal varying extraction capabilities of existing models\nacross academic texts of different lengths. Cross-comparisons with existing\ndatasets show that SciNLP achieves significant performance improvements on\ncertain baseline models. Using models trained on SciNLP, we implemented\nautomatic construction of a fine-grained knowledge graph for the NLP domain.\nOur KG has an average node degree of 3.2 per entity, indicating rich semantic\ntopological information that enhances downstream applications. The dataset is\npublicly available at https://github.com/AKADDC/SciNLP.",
        "url": "http://arxiv.org/abs/2509.07801v2",
        "pdf_url": "http://arxiv.org/pdf/2509.07801v2",
        "arxiv_id": "2509.07801v2",
        "authors": [
            "Decheng Duan",
            "Yingyi Zhang",
            "Jitong Peng",
            "Chengzhi Zhang"
        ],
        "submitted": "2025-09-09 14:41:40",
        "source": "arxiv",
        "comment": "EMNLP 2025 Main"
    },
    {
        "title": "Query Expansion in the Age of Pre-trained and Large Language Models: A Comprehensive Survey",
        "abstract": "Modern information retrieval (IR) must bridge short, ambiguous queries and\never more diverse, rapidly evolving corpora. Query Expansion (QE) remains a key\nmechanism for mitigating vocabulary mismatch, but the design space has shifted\nmarkedly with pre-trained language models (PLMs) and large language models\n(LLMs). This survey synthesizes the field from three angles: (i) a\nfour-dimensional framework of query expansion - from the point of injection\n(explicit vs. implicit QE), through grounding and interaction (knowledge bases,\nmodel-internal capabilities, multi-turn retrieval) and learning alignment, to\nknowledge graph-based argumentation; (ii) a model-centric taxonomy spanning\nencoder-only, encoder-decoder, decoder-only, instruction-tuned, and\ndomain/multilingual variants, highlighting their characteristic affordances for\nQE (contextual disambiguation, controllable generation, zero-/few-shot\nreasoning); and (iii) practice-oriented guidance on where and how neural QE\nhelps in first-stage retrieval, multi-query fusion, re-ranking, and\nretrieval-augmented generation (RAG). We compare traditional query expansion\nwith PLM/LLM-based methods across seven key aspects, and we map applications\nacross web search, biomedicine, e-commerce, open-domain QA/RAG, conversational\nand code search, and cross-lingual settings. The review distills design\ngrounding and interaction, alignment/distillation (SFT/PEFT/DPO), and KG\nconstraints - as robust remedies to topic drift and hallucination. We conclude\nwith an agenda on quality control, cost-aware invocation, domain/temporal\nadaptation, evaluation beyond end-task metrics, and fairness/privacy.\nCollectively, these insights provide a principled blueprint for selecting and\ncombining QE techniques under real-world constraints.",
        "url": "http://arxiv.org/abs/2509.07794v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07794v1",
        "arxiv_id": "2509.07794v1",
        "authors": [
            "Minghan Li",
            "Xinxuan Lv",
            "Junjie Zou",
            "Tongna Chen",
            "Chao Zhang",
            "Suchao An",
            "Ercong Nie",
            "Guodong Zhou"
        ],
        "submitted": "2025-09-09 14:31:11",
        "source": "arxiv",
        "comment": "38 pages,3 figures"
    },
    {
        "title": "Are LLMs Enough for Hyperpartisan, Fake, Polarized and Harmful Content Detection? Evaluating In-Context Learning vs. Fine-Tuning",
        "abstract": "The spread of fake news, polarizing, politically biased, and harmful content\non online platforms has been a serious concern. With large language models\nbecoming a promising approach, however, no study has properly benchmarked their\nperformance across different models, usage methods, and languages. This study\npresents a comprehensive overview of different Large Language Models adaptation\nparadigms for the detection of hyperpartisan and fake news, harmful tweets, and\npolitical bias. Our experiments spanned 10 datasets and 5 different languages\n(English, Spanish, Portuguese, Arabic and Bulgarian), covering both binary and\nmulticlass classification scenarios. We tested different strategies ranging\nfrom parameter efficient Fine-Tuning of language models to a variety of\ndifferent In-Context Learning strategies and prompts. These included zero-shot\nprompts, codebooks, few-shot (with both randomly-selected and\ndiversely-selected examples using Determinantal Point Processes), and\nChain-of-Thought. We discovered that In-Context Learning often underperforms\nwhen compared to Fine-Tuning a model. This main finding highlights the\nimportance of Fine-Tuning even smaller models on task-specific settings even\nwhen compared to the largest models evaluated in an In-Context Learning setup -\nin our case LlaMA3.1-8b-Instruct, Mistral-Nemo-Instruct-2407 and\nQwen2.5-7B-Instruct.",
        "url": "http://arxiv.org/abs/2509.07768v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07768v1",
        "arxiv_id": "2509.07768v1",
        "authors": [
            "Michele Joshua Maggini",
            "Dhia Merzougui",
            "Rabiraj Bandyopadhyay",
            "Gaël Dias",
            "Fabrice Maurel",
            "Pablo Gamallo"
        ],
        "submitted": "2025-09-09 14:01:15",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "A Survey of Long-Document Retrieval in the PLM and LLM Era",
        "abstract": "The proliferation of long-form documents presents a fundamental challenge to\ninformation retrieval (IR), as their length, dispersed evidence, and complex\nstructures demand specialized methods beyond standard passage-level techniques.\nThis survey provides the first comprehensive treatment of long-document\nretrieval (LDR), consolidating methods, challenges, and applications across\nthree major eras. We systematize the evolution from classical lexical and early\nneural models to modern pre-trained (PLM) and large language models (LLMs),\ncovering key paradigms like passage aggregation, hierarchical encoding,\nefficient attention, and the latest LLM-driven re-ranking and retrieval\ntechniques. Beyond the models, we review domain-specific applications,\nspecialized evaluation resources, and outline critical open challenges such as\nefficiency trade-offs, multimodal alignment, and faithfulness. This survey aims\nto provide both a consolidated reference and a forward-looking agenda for\nadvancing long-document retrieval in the era of foundation models.",
        "url": "http://arxiv.org/abs/2509.07759v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07759v1",
        "arxiv_id": "2509.07759v1",
        "authors": [
            "Minghan Li",
            "Miyang Luo",
            "Tianrui Lv",
            "Yishuai Zhang",
            "Siqi Zhao",
            "Ercong Nie",
            "Guodong Zhou"
        ],
        "submitted": "2025-09-09 13:57:53",
        "source": "arxiv",
        "comment": "33 pages, 6 figures"
    },
    {
        "title": "Factuality Beyond Coherence: Evaluating LLM Watermarking Methods for Medical Texts",
        "abstract": "As large language models (LLMs) adapted to sensitive domains such as\nmedicine, their fluency raises safety risks, particularly regarding provenance\nand accountability. Watermarking embeds detectable patterns to mitigate these\nrisks, yet its reliability in medical contexts remains untested. Existing\nbenchmarks focus on detection-quality tradeoffs, overlooking factual risks\nunder low-entropy settings often exploited by watermarking's reweighting\nstrategy. We propose a medical-focused evaluation workflow that jointly\nassesses factual accuracy and coherence. Using GPT-Judger and further human\nvalidation, we introduce the Factuality-Weighted Score (FWS), a composite\nmetric prioritizing factual accuracy beyond coherence to guide watermarking\ndeployment in medical domains. Our evaluation shows current watermarking\nmethods substantially compromise medical factuality, with entropy shifts\ndegrading medical entity representation. These findings underscore the need for\ndomain-aware watermarking approaches that preserve the integrity of medical\ncontent.",
        "url": "http://arxiv.org/abs/2509.07755v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07755v1",
        "arxiv_id": "2509.07755v1",
        "authors": [
            "Rochana Prih Hastuti",
            "Rian Adam Rajagede",
            "Mansour Al Ghanim",
            "Mengxin Zheng",
            "Qian Lou"
        ],
        "submitted": "2025-09-09 13:54:34",
        "source": "arxiv",
        "comment": "Accepted at EMNLP 2025 Findings"
    },
    {
        "title": "M-BRe: Discovering Training Samples for Relation Extraction from Unlabeled Texts with Large Language Models",
        "abstract": "For Relation Extraction (RE), the manual annotation of training data may be\nprohibitively expensive, since the sentences that contain the target relations\nin texts can be very scarce and difficult to find. It is therefore beneficial\nto develop an efficient method that can automatically extract training\ninstances from unlabeled texts for training RE models. Recently, large language\nmodels (LLMs) have been adopted in various natural language processing tasks,\nwith RE also benefiting from their advances. However, when leveraging LLMs for\nRE with predefined relation categories, two key challenges arise. First, in a\nmulti-class classification setting, LLMs often struggle to comprehensively\ncapture the semantics of every relation, leading to suboptimal results. Second,\nalthough employing binary classification for each relation individually can\nmitigate this issue, it introduces significant computational overhead,\nresulting in impractical time complexity for real-world applications.\nTherefore, this paper proposes a framework called M-BRe to extract training\ninstances from unlabeled texts for RE. It utilizes three modules to combine the\nadvantages of both of the above classification approaches: Relation Grouping,\nRelation Extraction, and Label Decision. Extensive experiments confirm its\nsuperior capability in discovering high-quality training samples from unlabeled\ntexts for RE.",
        "url": "http://arxiv.org/abs/2509.07730v2",
        "pdf_url": "http://arxiv.org/pdf/2509.07730v2",
        "arxiv_id": "2509.07730v2",
        "authors": [
            "Zexuan Li",
            "Hongliang Dai",
            "Piji Li"
        ],
        "submitted": "2025-09-09 13:32:29",
        "source": "arxiv",
        "comment": "Accepted by EMNLP2025 Main Conference"
    },
    {
        "title": "NOWJ@COLIEE 2025: A Multi-stage Framework Integrating Embedding Models and Large Language Models for Legal Retrieval and Entailment",
        "abstract": "This paper presents the methodologies and results of the NOWJ team's\nparticipation across all five tasks at the COLIEE 2025 competition, emphasizing\nadvancements in the Legal Case Entailment task (Task 2). Our comprehensive\napproach systematically integrates pre-ranking models (BM25, BERT, monoT5),\nembedding-based semantic representations (BGE-m3, LLM2Vec), and advanced Large\nLanguage Models (Qwen-2, QwQ-32B, DeepSeek-V3) for summarization, relevance\nscoring, and contextual re-ranking. Specifically, in Task 2, our two-stage\nretrieval system combined lexical-semantic filtering with contextualized LLM\nanalysis, achieving first place with an F1 score of 0.3195. Additionally, in\nother tasks--including Legal Case Retrieval, Statute Law Retrieval, Legal\nTextual Entailment, and Legal Judgment Prediction--we demonstrated robust\nperformance through carefully engineered ensembles and effective prompt-based\nreasoning strategies. Our findings highlight the potential of hybrid models\nintegrating traditional IR techniques with contemporary generative models,\nproviding a valuable reference for future advancements in legal information\nprocessing.",
        "url": "http://arxiv.org/abs/2509.08025v1",
        "pdf_url": "http://arxiv.org/pdf/2509.08025v1",
        "arxiv_id": "2509.08025v1",
        "authors": [
            "Hoang-Trung Nguyen",
            "Tan-Minh Nguyen",
            "Xuan-Bach Le",
            "Tuan-Kiet Le",
            "Khanh-Huyen Nguyen",
            "Ha-Thanh Nguyen",
            "Thi-Hai-Yen Vuong",
            "Le-Minh Nguyen"
        ],
        "submitted": "2025-09-09 12:05:52",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "MaLei at MultiClinSUM: Summarisation of Clinical Documents using Perspective-Aware Iterative Self-Prompting with LLMs",
        "abstract": "Efficient communication between patients and clinicians plays an important\nrole in shared decision-making. However, clinical reports are often lengthy and\nfilled with clinical jargon, making it difficult for domain experts to identify\nimportant aspects in the document efficiently. This paper presents the\nmethodology we applied in the MultiClinSUM shared task for summarising clinical\ncase documents. We used an Iterative Self-Prompting technique on large language\nmodels (LLMs) by asking LLMs to generate task-specific prompts and refine them\nvia example-based few-shot learning. Furthermore, we used lexical and embedding\nspace metrics, ROUGE and BERT-score, to guide the model fine-tuning with\nepochs. Our submission using perspective-aware ISP on GPT-4 and GPT-4o achieved\nROUGE scores (46.53, 24.68, 30.77) and BERTscores (87.84, 83.25, 85.46) for (P,\nR, F1) from the official evaluation on 3,396 clinical case reports from various\nspecialties extracted from open journals. The high BERTscore indicates that the\nmodel produced semantically equivalent output summaries compared to the\nreferences, even though the overlap at the exact lexicon level is lower, as\nreflected in the lower ROUGE scores. This work sheds some light on how\nperspective-aware ISP (PA-ISP) can be deployed for clinical report\nsummarisation and support better communication between patients and clinicians.",
        "url": "http://arxiv.org/abs/2509.07622v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07622v1",
        "arxiv_id": "2509.07622v1",
        "authors": [
            "Libo Ren",
            "Yee Man Ng",
            "Lifeng Han"
        ],
        "submitted": "2025-09-09 11:52:16",
        "source": "arxiv",
        "comment": "system paper at CLEF 2025"
    },
    {
        "title": "Towards End-to-End Model-Agnostic Explanations for RAG Systems",
        "abstract": "Retrieval Augmented Generation (RAG) systems, despite their growing\npopularity for enhancing model response reliability, often struggle with\ntrustworthiness and explainability. In this work, we present a novel, holistic,\nmodel-agnostic, post-hoc explanation framework leveraging perturbation-based\ntechniques to explain the retrieval and generation processes in a RAG system.\nWe propose different strategies to evaluate these explanations and discuss the\nsufficiency of model-agnostic explanations in RAG systems. With this work, we\nfurther aim to catalyze a collaborative effort to build reliable and\nexplainable RAG systems.",
        "url": "http://arxiv.org/abs/2509.07620v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07620v1",
        "arxiv_id": "2509.07620v1",
        "authors": [
            "Viju Sudhi",
            "Sinchana Ramakanth Bhat",
            "Max Rudat",
            "Roman Teucher",
            "Nicolas Flores-Herr"
        ],
        "submitted": "2025-09-09 11:47:40",
        "source": "arxiv",
        "comment": "Accepted to Workshop on Explainability in Information Retrieval\n  (WExIR), SIGIR 2025 - July 17, 2025"
    },
    {
        "title": "ELEC: Efficient Large Language Model-Empowered Click-Through Rate Prediction",
        "abstract": "Click-through rate (CTR) prediction plays an important role in online\nadvertising systems. On the one hand, traditional CTR prediction models capture\nthe collaborative signals in tabular data via feature interaction modeling, but\nthey lose semantics in text. On the other hand, Large Language Models (LLMs)\nexcel in understanding the context and meaning behind text, but they face\nchallenges in capturing collaborative signals and they have long inference\nlatency. In this paper, we aim to leverage the benefits of both types of models\nand pursue collaboration, semantics and efficiency. We present ELEC, which is\nan Efficient LLM-Empowered CTR prediction framework. We first adapt an LLM for\nthe CTR prediction task. In order to leverage the ability of the LLM but\nsimultaneously keep efficiency, we utilize the pseudo-siamese network which\ncontains a gain network and a vanilla network. We inject the high-level\nrepresentation vector generated by the LLM into a collaborative CTR model to\nform the gain network such that it can take advantage of both tabular modeling\nand textual modeling. However, its reliance on the LLM limits its efficiency.\nWe then distill the knowledge from the gain network to the vanilla network on\nboth the score level and the representation level, such that the vanilla\nnetwork takes only tabular data as input, but can still generate comparable\nperformance as the gain network. Our approach is model-agnostic. It allows for\nthe integration with various existing LLMs and collaborative CTR models.\nExperiments on real-world datasets demonstrate the effectiveness and efficiency\nof ELEC for CTR prediction.",
        "url": "http://arxiv.org/abs/2509.07594v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07594v1",
        "arxiv_id": "2509.07594v1",
        "authors": [
            "Rui Dong",
            "Wentao Ouyang",
            "Xiangzheng Liu"
        ],
        "submitted": "2025-09-09 11:06:37",
        "source": "arxiv",
        "comment": "SIGIR 2025"
    },
    {
        "title": "BALI: Enhancing Biomedical Language Representations through Knowledge Graph and Language Model Alignment",
        "abstract": "In recent years, there has been substantial progress in using pretrained\nLanguage Models (LMs) on a range of tasks aimed at improving the understanding\nof biomedical texts. Nonetheless, existing biomedical LLMs show limited\ncomprehension of complex, domain-specific concept structures and the factual\ninformation encoded in biomedical Knowledge Graphs (KGs). In this work, we\npropose BALI (Biomedical Knowledge Graph and Language Model Alignment), a novel\njoint LM and KG pre-training method that augments an LM with external knowledge\nby the simultaneous learning of a dedicated KG encoder and aligning the\nrepresentations of both the LM and the graph. For a given textual sequence, we\nlink biomedical concept mentions to the Unified Medical Language System (UMLS)\nKG and utilize local KG subgraphs as cross-modal positive samples for these\nmentions. Our empirical findings indicate that implementing our method on\nseveral leading biomedical LMs, such as PubMedBERT and BioLinkBERT, improves\ntheir performance on a range of language understanding tasks and the quality of\nentity representations, even with minimal pre-training on a small alignment\ndataset sourced from PubMed scientific abstracts.",
        "url": "http://arxiv.org/abs/2509.07588v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07588v1",
        "arxiv_id": "2509.07588v1",
        "authors": [
            "Andrey Sakhovskiy",
            "Elena Tutubalina"
        ],
        "submitted": "2025-09-09 10:59:47",
        "source": "arxiv",
        "comment": "9 pages, 1 figure, published in \"The 48th International ACM SIGIR\n  Conference on Research and Development in Information Retrieval (SIGIR 2025)\""
    },
    {
        "title": "Avoiding Knowledge Edit Skipping in Multi-hop Question Answering with Guided Decomposition",
        "abstract": "In a rapidly evolving world where information updates swiftly, knowledge in\nlarge language models (LLMs) becomes outdated quickly. Retraining LLMs is not a\ncost-effective option, making knowledge editing (KE) without modifying\nparameters particularly necessary. We find that although existing\nretrieval-augmented generation (RAG)-based KE methods excel at editing simple\nknowledge, they struggle with KE in multi-hop question answering due to the\nissue of \"edit skipping\", which refers to skipping the relevant edited fact in\ninference. In addition to the diversity of natural language expressions of\nknowledge, edit skipping also arises from the mismatch between the granularity\nof LLMs in problem-solving and the facts in the edited memory. To address this\nissue, we propose a novel Iterative Retrieval-Augmented Knowledge Editing\nmethod with guided decomposition (IRAKE) through the guidance from single\nedited facts and entire edited cases. Experimental results demonstrate that\nIRAKE mitigates the failure of editing caused by edit skipping and outperforms\nstate-of-the-art methods for KE in multi-hop question answering.",
        "url": "http://arxiv.org/abs/2509.07555v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07555v1",
        "arxiv_id": "2509.07555v1",
        "authors": [
            "Yi Liu",
            "Xiangrong Zhu",
            "Xiangyu Liu",
            "Wei Wei",
            "Wei Hu"
        ],
        "submitted": "2025-09-09 09:49:23",
        "source": "arxiv",
        "comment": "Accepted in EMNLP Findings 2025"
    },
    {
        "title": "VeriOS: Query-Driven Proactive Human-Agent-GUI Interaction for Trustworthy OS Agents",
        "abstract": "With the rapid progress of multimodal large language models, operating system\n(OS) agents become increasingly capable of automating tasks through on-device\ngraphical user interfaces (GUIs). However, most existing OS agents are designed\nfor idealized settings, whereas real-world environments often present\nuntrustworthy conditions. To mitigate risks of over-execution in such\nscenarios, we propose a query-driven human-agent-GUI interaction framework that\nenables OS agents to decide when to query humans for more reliable task\ncompletion. Built upon this framework, we introduce VeriOS-Agent, a trustworthy\nOS agent trained with a two-stage learning paradigm that falicitate the\ndecoupling and utilization of meta-knowledge. Concretely, VeriOS-Agent\nautonomously executes actions in normal conditions while proactively querying\nhumans in untrustworthy scenarios. Experiments show that VeriOS-Agent improves\nthe average step-wise success rate by 20.64\\% in untrustworthy scenarios over\nthe state-of-the-art, without compromising normal performance. Analysis\nhighlights VeriOS-Agent's rationality, generalizability, and scalability. The\ncodes, datasets and models are available at\nhttps://github.com/Wuzheng02/VeriOS.",
        "url": "http://arxiv.org/abs/2509.07553v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07553v1",
        "arxiv_id": "2509.07553v1",
        "authors": [
            "Zheng Wu",
            "Heyuan Huang",
            "Xingyu Lou",
            "Xiangmou Qu",
            "Pengzhou Cheng",
            "Zongru Wu",
            "Weiwen Liu",
            "Weinan Zhang",
            "Jun Wang",
            "Zhaoxiang Wang",
            "Zhuosheng Zhang"
        ],
        "submitted": "2025-09-09 09:46:01",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values",
        "abstract": "The alignment of large language models (LLMs) with human values is critical\nfor their safe and effective deployment across diverse user populations.\nHowever, existing benchmarks often neglect cultural and demographic diversity,\nleading to limited understanding of how value alignment generalizes globally.\nIn this work, we introduce MVPBench, a novel benchmark that systematically\nevaluates LLMs' alignment with multi-dimensional human value preferences across\n75 countries. MVPBench contains 24,020 high-quality instances annotated with\nfine-grained value labels, personalized questions, and rich demographic\nmetadata, making it the most comprehensive resource of its kind to date. Using\nMVPBench, we conduct an in-depth analysis of several state-of-the-art LLMs,\nrevealing substantial disparities in alignment performance across geographic\nand demographic lines. We further demonstrate that lightweight fine-tuning\nmethods, such as Low-Rank Adaptation (LoRA) and Direct Preference Optimization\n(DPO), can significantly enhance value alignment in both in-domain and\nout-of-domain settings. Our findings underscore the necessity for\npopulation-aware alignment evaluation and provide actionable insights for\nbuilding culturally adaptive and value-sensitive LLMs. MVPBench serves as a\npractical foundation for future research on global alignment, personalized\nvalue modeling, and equitable AI development.",
        "url": "http://arxiv.org/abs/2509.08022v1",
        "pdf_url": "http://arxiv.org/pdf/2509.08022v1",
        "arxiv_id": "2509.08022v1",
        "authors": [
            "Yao Liang",
            "Dongcheng Zhao",
            "Feifei Zhao",
            "Guobin Shen",
            "Yuwei Wang",
            "Dongqi Liang",
            "Yi Zeng"
        ],
        "submitted": "2025-09-09 09:25:08",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "FLeW: Facet-Level and Adaptive Weighted Representation Learning of Scientific Documents",
        "abstract": "Scientific document representation learning provides powerful embeddings for\nvarious tasks, while current methods face challenges across three approaches.\n1) Contrastive training with citation-structural signals underutilizes citation\ninformation and still generates single-vector representations. 2) Fine-grained\nrepresentation learning, which generates multiple vectors at the sentence or\naspect level, requires costly integration and lacks domain generalization. 3)\nTask-aware learning depends on manually predefined task categorization,\noverlooking nuanced task distinctions and requiring extra training data for\ntask-specific modules. To address these problems, we propose a new method that\nunifies the three approaches for better representations, namely FLeW.\nSpecifically, we introduce a novel triplet sampling method that leverages\ncitation intent and frequency to enhance citation-structural signals for\ntraining. Citation intents (background, method, result), aligned with the\ngeneral structure of scientific writing, facilitate a domain-generalized facet\npartition for fine-grained representation learning. Then, we adopt a simple\nweight search to adaptively integrate three facet-level embeddings into a\ntask-specific document embedding without task-aware fine-tuning. Experiments\nshow the applicability and robustness of FLeW across multiple scientific tasks\nand fields, compared to prior models.",
        "url": "http://arxiv.org/abs/2509.07531v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07531v1",
        "arxiv_id": "2509.07531v1",
        "authors": [
            "Zheng Dou",
            "Deqing Wang",
            "Fuzhen Zhuang",
            "Jian Ren",
            "Yanlin Hu"
        ],
        "submitted": "2025-09-09 09:08:44",
        "source": "arxiv",
        "comment": "Accepted by DASFAA2025"
    },
    {
        "title": "Competitive Audio-Language Models with Data-Efficient Single-Stage Training on Public Data",
        "abstract": "Large language models (LLMs) have transformed NLP, yet their integration with\naudio remains underexplored -- despite audio's centrality to human\ncommunication. We introduce Falcon3-Audio, a family of Audio-Language Models\n(ALMs) built on instruction-tuned LLMs and Whisper encoders. Using a remarkably\nsmall amount of public audio data -- less than 30K hours (5K unique) --\nFalcon3-Audio-7B matches the best reported performance among open-weight models\non the MMAU benchmark, with a score of 64.14, matching R1-AQA, while\ndistinguishing itself through superior data and parameter efficiency,\nsingle-stage training, and transparency. Notably, our smallest 1B model remains\ncompetitive with larger open models ranging from 2B to 13B parameters. Through\nextensive ablations, we find that common complexities -- such as curriculum\nlearning, multiple audio encoders, and intricate cross-attention connectors --\nare not required for strong performance, even compared to models trained on\nover 500K hours of data.",
        "url": "http://arxiv.org/abs/2509.07526v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07526v1",
        "arxiv_id": "2509.07526v1",
        "authors": [
            "Gokul Karthik Kumar",
            "Rishabh Saraf",
            "Ludovick Lepauloux",
            "Abdul Muneer",
            "Billel Mokeddem",
            "Hakim Hacid"
        ],
        "submitted": "2025-09-09 09:01:01",
        "source": "arxiv",
        "comment": "Accepted at ASRU 2025"
    },
    {
        "title": "ALLabel: Three-stage Active Learning for LLM-based Entity Recognition using Demonstration Retrieval",
        "abstract": "Many contemporary data-driven research efforts in the natural sciences, such\nas chemistry and materials science, require large-scale, high-performance\nentity recognition from scientific datasets. Large language models (LLMs) have\nincreasingly been adopted to solve the entity recognition task, with the same\ntrend being observed on all-spectrum NLP tasks. The prevailing entity\nrecognition LLMs rely on fine-tuned technology, yet the fine-tuning process\noften incurs significant cost. To achieve a best performance-cost trade-off, we\npropose ALLabel, a three-stage framework designed to select the most\ninformative and representative samples in preparing the demonstrations for LLM\nmodeling. The annotated examples are used to construct a ground-truth retrieval\ncorpus for LLM in-context learning. By sequentially employing three distinct\nactive learning strategies, ALLabel consistently outperforms all baselines\nunder the same annotation budget across three specialized domain datasets.\nExperimental results also demonstrate that selectively annotating only 5\\%-10\\%\nof the dataset with ALLabel can achieve performance comparable to the method\nannotating the entire dataset. Further analyses and ablation studies verify the\neffectiveness and generalizability of our proposal.",
        "url": "http://arxiv.org/abs/2509.07512v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07512v1",
        "arxiv_id": "2509.07512v1",
        "authors": [
            "Zihan Chen",
            "Lei Shi",
            "Weize Wu",
            "Qiji Zhou",
            "Yue Zhang"
        ],
        "submitted": "2025-09-09 08:47:13",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Astra: A Multi-Agent System for GPU Kernel Performance Optimization",
        "abstract": "GPU kernel optimization has long been a central challenge at the intersection\nof high-performance computing and machine learning. Efficient kernels are\ncrucial for accelerating large language model (LLM) training and serving, yet\nattaining high performance typically requires extensive manual tuning.\nCompiler-based systems reduce some of this burden, but still demand substantial\nmanual design and engineering effort. Recently, researchers have explored using\nLLMs for GPU kernel generation, though prior work has largely focused on\ntranslating high-level PyTorch modules into CUDA code. In this work, we\nintroduce Astra, the first LLM-based multi-agent system for GPU kernel\noptimization. Unlike previous approaches, Astra starts from existing CUDA\nimplementations extracted from SGLang, a widely deployed framework for serving\nLLMs, rather than treating PyTorch modules as the specification. Within Astra,\nspecialized LLM agents collaborate through iterative code generation, testing,\nprofiling, and planning to produce kernels that are both correct and\nhigh-performance. On kernels from SGLang, Astra achieves an average speedup of\n1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study\nfurther demonstrates that LLMs can autonomously apply loop transformations,\noptimize memory access patterns, exploit CUDA intrinsics, and leverage fast\nmath operations to yield substantial performance gains. Our work highlights\nmulti-agent LLM systems as a promising new paradigm for GPU kernel\noptimization.",
        "url": "http://arxiv.org/abs/2509.07506v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07506v1",
        "arxiv_id": "2509.07506v1",
        "authors": [
            "Anjiang Wei",
            "Tianran Sun",
            "Yogesh Seenichamy",
            "Hang Song",
            "Anne Ouyang",
            "Azalia Mirhoseini",
            "Ke Wang",
            "Alex Aiken"
        ],
        "submitted": "2025-09-09 08:39:50",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Multi-view-guided Passage Reranking with Large Language Models",
        "abstract": "Recent advances in large language models (LLMs) have shown impressive\nperformance in passage reranking tasks. Despite their success, LLM-based\nmethods still face challenges in efficiency and sensitivity to external biases.\n(1) Existing models rely mostly on autoregressive generation and sliding window\nstrategies to rank passages, which incur heavy computational overhead as the\nnumber of passages increases. (2) External biases, such as position or\nselection bias, hinder the model's ability to accurately represent passages and\nincrease input-order sensitivity. To address these limitations, we introduce a\nnovel passage reranking model, called Multi-View-guided Passage Reranking\n(MVP). MVP is a non-generative LLM-based reranking method that encodes\nquery-passage information into diverse view embeddings without being influenced\nby external biases. For each view, it combines query-aware passage embeddings\nto produce a distinct anchor vector, which is then used to directly compute\nrelevance scores in a single decoding step. In addition, it employs an\northogonal loss to make the views more distinctive. Extensive experiments\ndemonstrate that MVP, with just 220M parameters, matches the performance of\nmuch larger 7B-scale fine-tuned models while achieving a 100x reduction in\ninference latency. Notably, the 3B-parameter variant of MVP achieves\nstate-of-the-art performance on both in-domain and out-of-domain benchmarks.\nThe source code is available at: https://github.com/bulbna/MVP",
        "url": "http://arxiv.org/abs/2509.07485v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07485v1",
        "arxiv_id": "2509.07485v1",
        "authors": [
            "Jeongwoo Na",
            "Jun Kwon",
            "Eunseong Choi",
            "Jongwuk Lee"
        ],
        "submitted": "2025-09-09 08:05:16",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "HALT-RAG: A Task-Adaptable Framework for Hallucination Detection with Calibrated NLI Ensembles and Abstention",
        "abstract": "Detecting content that contradicts or is unsupported by a given source text\nis a critical challenge for the safe deployment of generative language models.\nWe introduce HALT-RAG, a post-hoc verification system designed to identify\nhallucinations in the outputs of Retrieval-Augmented Generation (RAG)\npipelines. Our flexible and task-adaptable framework uses a universal feature\nset derived from an ensemble of two frozen, off-the-shelf Natural Language\nInference (NLI) models and lightweight lexical signals. These features are used\nto train a simple, calibrated, and task-adapted meta-classifier. Using a\nrigorous 5-fold out-of-fold (OOF) training protocol to prevent data leakage and\nproduce unbiased estimates, we evaluate our system on the HaluEval benchmark.\nBy pairing our universal feature set with a lightweight, task-adapted\nclassifier and a precision-constrained decision policy, HALT-RAG achieves\nstrong OOF F1-scores of 0.7756, 0.9786, and 0.7391 on the summarization, QA,\nand dialogue tasks, respectively. The system's well-calibrated probabilities\nenable a practical abstention mechanism, providing a reliable tool for\nbalancing model performance with safety requirements.",
        "url": "http://arxiv.org/abs/2509.07475v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07475v1",
        "arxiv_id": "2509.07475v1",
        "authors": [
            "Saumya Goswami",
            "Siddharth Kurra"
        ],
        "submitted": "2025-09-09 07:58:46",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "From Scarcity to Efficiency: Investigating the Effects of Data Augmentation on African Machine Translation",
        "abstract": "The linguistic diversity across the African continent presents different\nchallenges and opportunities for machine translation. This study explores the\neffects of data augmentation techniques in improving translation systems in\nlow-resource African languages. We focus on two data augmentation techniques:\nsentence concatenation with back translation and switch-out, applying them\nacross six African languages. Our experiments show significant improvements in\nmachine translation performance, with a minimum increase of 25\\% in BLEU score\nacross all six languages.We provide a comprehensive analysis and highlight the\npotential of these techniques to improve machine translation systems for\nlow-resource languages, contributing to the development of more robust\ntranslation systems for under-resourced languages.",
        "url": "http://arxiv.org/abs/2509.07471v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07471v1",
        "arxiv_id": "2509.07471v1",
        "authors": [
            "Mardiyyah Oduwole",
            "Oluwatosin Olajide",
            "Jamiu Suleiman",
            "Faith Hunja",
            "Busayo Awobade",
            "Fatimo Adebanjo",
            "Comfort Akanni",
            "Chinonyelum Igwe",
            "Peace Ododo",
            "Promise Omoigui",
            "Steven Kolawole",
            "Abraham Owodunni"
        ],
        "submitted": "2025-09-09 07:49:37",
        "source": "arxiv",
        "comment": "8 pages, 3 tables. Exploratory work on Data Augmentation for African\n  Machine Translation"
    },
    {
        "title": "Understanding Stigmatizing Language Lexicons: A Comparative Analysis in Clinical Contexts",
        "abstract": "Stigmatizing language results in healthcare inequities, yet there is no\nuniversally accepted or standardized lexicon defining which words, terms, or\nphrases constitute stigmatizing language in healthcare. We conducted a\nsystematic search of the literature to identify existing stigmatizing language\nlexicons and then analyzed them comparatively to examine: 1) similarities and\ndiscrepancies between these lexicons, and 2) the distribution of positive,\nnegative, or neutral terms based on an established sentiment dataset. Our\nsearch identified four lexicons. The analysis results revealed moderate\nsemantic similarity among them, and that most stigmatizing terms are related to\njudgmental expressions by clinicians to describe perceived negative behaviors.\nSentiment analysis showed a predominant proportion of negatively classified\nterms, though variations exist across lexicons. Our findings underscore the\nneed for a standardized lexicon and highlight challenges in defining\nstigmatizing language in clinical texts.",
        "url": "http://arxiv.org/abs/2509.07462v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07462v1",
        "arxiv_id": "2509.07462v1",
        "authors": [
            "Yiliang Zhou",
            "Di Hu",
            "Tianchu Lyu",
            "Jasmine Dhillon",
            "Alexandra L. Beck",
            "Gelareh Sadigh",
            "Kai Zheng"
        ],
        "submitted": "2025-09-09 07:41:20",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "AIxcellent Vibes at GermEval 2025 Shared Task on Candy Speech Detection: Improving Model Performance by Span-Level Training",
        "abstract": "Positive, supportive online communication in social media (candy speech) has\nthe potential to foster civility, yet automated detection of such language\nremains underexplored, limiting systematic analysis of its impact. We\ninvestigate how candy speech can be reliably detected in a 46k-comment German\nYouTube corpus by monolingual and multilingual language models, including\nGBERT, Qwen3 Embedding, and XLM-RoBERTa. We find that a multilingual\nXLM-RoBERTa-Large model trained to detect candy speech at the span level\noutperforms other approaches, ranking first in both binary positive F1: 0.8906)\nand categorized span-based detection (strict F1: 0.6307) subtasks at the\nGermEval 2025 Shared Task on Candy Speech Detection. We speculate that\nspan-based training, multilingual capabilities, and emoji-aware tokenizers\nimproved detection performance. Our results demonstrate the effectiveness of\nmultilingual models in identifying positive, supportive language.",
        "url": "http://arxiv.org/abs/2509.07459v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07459v1",
        "arxiv_id": "2509.07459v1",
        "authors": [
            "Christian Rene Thelen",
            "Patrick Gustav Blaneck",
            "Tobias Bornheim",
            "Niklas Grieger",
            "Stephan Bialonski"
        ],
        "submitted": "2025-09-09 07:29:14",
        "source": "arxiv",
        "comment": "6 pages, 1 figure, 2 tables"
    },
    {
        "title": "GLEAM: Learning to Match and Explain in Cross-View Geo-Localization",
        "abstract": "Cross-View Geo-Localization (CVGL) focuses on identifying correspondences\nbetween images captured from distinct perspectives of the same geographical\nlocation. However, existing CVGL approaches are typically restricted to a\nsingle view or modality, and their direct visual matching strategy lacks\ninterpretability: they merely predict whether two images correspond, without\nexplaining the rationale behind the match. In this paper, we present GLEAM-C, a\nfoundational CVGL model that unifies multiple views and modalities-including\nUAV imagery, street maps, panoramic views, and ground photographs-by aligning\nthem exclusively with satellite imagery. Our framework enhances training\nefficiency through optimized implementation while achieving accuracy comparable\nto prior modality-specific CVGL models through a two-phase training strategy.\nMoreover, to address the lack of interpretability in traditional CVGL methods,\nwe leverage the reasoning capabilities of multimodal large language models\n(MLLMs) to propose a new task, GLEAM-X, which combines cross-view\ncorrespondence prediction with explainable reasoning. To support this task, we\nconstruct a bilingual benchmark using GPT-4o and Doubao-1.5-Thinking-Vision-Pro\nto generate training and testing data. The test set is further refined through\ndetailed human revision, enabling systematic evaluation of explainable\ncross-view reasoning and advancing transparency and scalability in\ngeo-localization. Together, GLEAM-C and GLEAM-X form a comprehensive CVGL\npipeline that integrates multi-modal, multi-view alignment with interpretable\ncorrespondence analysis, unifying accurate cross-view matching with explainable\nreasoning and advancing Geo-Localization by enabling models to better Explain\nAnd Match. Code and datasets used in this work will be made publicly accessible\nat https://github.com/Lucky-Lance/GLEAM.",
        "url": "http://arxiv.org/abs/2509.07450v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07450v1",
        "arxiv_id": "2509.07450v1",
        "authors": [
            "Xudong Lu",
            "Zhi Zheng",
            "Yi Wan",
            "Yongxiang Yao",
            "Annan Wang",
            "Renrui Zhang",
            "Panwang Xia",
            "Qiong Wu",
            "Qingyun Li",
            "Weifeng Lin",
            "Xiangyu Zhao",
            "Xue Yang",
            "Hongsheng Li"
        ],
        "submitted": "2025-09-09 07:14:31",
        "source": "arxiv",
        "comment": "18 pages"
    },
    {
        "title": "Language Self-Play For Data-Free Training",
        "abstract": "Large language models (LLMs) have advanced rapidly in recent years, driven by\nscale, abundant high-quality training data, and reinforcement learning. Yet\nthis progress faces a fundamental bottleneck: the need for ever more data from\nwhich models can continue to learn. In this work, we propose a reinforcement\nlearning approach that removes this dependency by enabling models to improve\nwithout additional data. Our method leverages a game-theoretic framework of\nself-play, where a model's capabilities are cast as performance in a\ncompetitive game and stronger policies emerge by having the model play against\nitself - a process we call Language Self-Play (LSP). Experiments with\nLlama-3.2-3B-Instruct on instruction-following benchmarks show that pretrained\nmodels can not only enhance their performance on challenging tasks through\nself-play alone, but can also do so more effectively than data-driven\nbaselines.",
        "url": "http://arxiv.org/abs/2509.07414v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07414v1",
        "arxiv_id": "2509.07414v1",
        "authors": [
            "Jakub Grudzien Kuba",
            "Mengting Gu",
            "Qi Ma",
            "Yuandong Tian",
            "Vijai Mohan"
        ],
        "submitted": "2025-09-09 05:51:34",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "LongEmotion: Measuring Emotional Intelligence of Large Language Models in Long-Context Interaction",
        "abstract": "Large language models (LLMs) make significant progress in Emotional\nIntelligence (EI) and long-context understanding. However, existing benchmarks\ntend to overlook certain aspects of EI in long-context scenarios, especially\nunder realistic, practical settings where interactions are lengthy, diverse,\nand often noisy. To move towards such realistic settings, we present\nLongEmotion, a benchmark specifically designed for long-context EI tasks. It\ncovers a diverse set of tasks, including Emotion Classification, Emotion\nDetection, Emotion QA, Emotion Conversation, Emotion Summary, and Emotion\nExpression. On average, the input length for these tasks reaches 8,777 tokens,\nwith long-form generation required for Emotion Expression. To enhance\nperformance under realistic constraints, we incorporate Retrieval-Augmented\nGeneration (RAG) and Collaborative Emotional Modeling (CoEM), and compare them\nwith standard prompt-based methods. Unlike conventional approaches, our RAG\nmethod leverages both the conversation context and the large language model\nitself as retrieval sources, avoiding reliance on external knowledge bases. The\nCoEM method further improves performance by decomposing the task into five\nstages, integrating both retrieval augmentation and limited knowledge\ninjection. Experimental results show that both RAG and CoEM consistently\nenhance EI-related performance across most long-context tasks, advancing LLMs\ntoward more practical and real-world EI applications. Furthermore, we conducted\na comparative case study experiment on the GPT series to demonstrate the\ndifferences among various models in terms of EI. Code is available on GitHub at\nhttps://github.com/LongEmotion/LongEmotion, and the project page can be found\nat https://longemotion.github.io/.",
        "url": "http://arxiv.org/abs/2509.07403v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07403v1",
        "arxiv_id": "2509.07403v1",
        "authors": [
            "Weichu Liu",
            "Jing Xiong",
            "Yuxuan Hu",
            "Zixuan Li",
            "Minghuan Tan",
            "Ningning Mao",
            "Chenyang Zhao",
            "Zhongwei Wan",
            "Chaofan Tao",
            "Wendong Xu",
            "Hui Shen",
            "Chengming Li",
            "Lingpeng Kong",
            "Ngai Wong"
        ],
        "submitted": "2025-09-09 05:32:45",
        "source": "arxiv",
        "comment": "Technical Report"
    },
    {
        "title": "The Role of Exploration Modules in Small Language Models for Knowledge Graph Question Answering",
        "abstract": "Integrating knowledge graphs (KGs) into the reasoning processes of large\nlanguage models (LLMs) has emerged as a promising approach to mitigate\nhallucination. However, existing work in this area often relies on proprietary\nor extremely large models, limiting accessibility and scalability. In this\nstudy, we investigate the capabilities of existing integration methods for\nsmall language models (SLMs) in KG-based question answering and observe that\ntheir performance is often constrained by their limited ability to traverse and\nreason over knowledge graphs. To address this limitation, we propose leveraging\nsimple and efficient exploration modules to handle knowledge graph traversal in\nplace of the language model itself. Experiment results demonstrate that these\nlightweight modules effectively improve the performance of small language\nmodels on knowledge graph question answering tasks. Source code:\nhttps://github.com/yijie-cheng/SLM-ToG/.",
        "url": "http://arxiv.org/abs/2509.07399v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07399v1",
        "arxiv_id": "2509.07399v1",
        "authors": [
            "Yi-Jie Cheng",
            "Oscar Chew",
            "Yun-Nung Chen"
        ],
        "submitted": "2025-09-09 05:26:29",
        "source": "arxiv",
        "comment": "Extended from ACL 2025 SRW"
    },
    {
        "title": "Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents",
        "abstract": "Existing evaluation studies on linguistic competence of large language models\n(LLM agents) have focused primarily on vocabulary learning, morphological rule\ninduction, syntactic generalization, pragmatic inference, and cross-linguistic\ntransfer. However, none assess whether LLM agents can acquire a language\nthrough pattern recognition and interactive feedback, a central feature of\nhuman language acquisition. We propose a novel experimental framework in which\nan LLM agent is evaluated on its ability to acquire and use a newly constructed\nlanguage (Tinkatongue) in conversation with a bot that understands only\nTinkatongue. Our findings show that LLM agents fail to establish a conversation\nwithin 100 responses, yet they adopt distinct strategies that mirror human\napproaches to language learning. The results suggest a new direction for\nevaluation benchmarks and open pathways to model designs that learn more\neffectively from interactive feedback.",
        "url": "http://arxiv.org/abs/2509.07389v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07389v1",
        "arxiv_id": "2509.07389v1",
        "authors": [
            "Sankalp Tattwadarshi Swain",
            "Anshika Krishnatray",
            "Dhruv Kumar",
            "Jagat Sesh Challa"
        ],
        "submitted": "2025-09-09 05:09:27",
        "source": "arxiv",
        "comment": "Under review"
    },
    {
        "title": "PersonaFuse: A Personality Activation-Driven Framework for Enhancing Human-LLM Interactions",
        "abstract": "Recent advancements in Large Language Models (LLMs) demonstrate remarkable\ncapabilities across various fields. These developments have led to more direct\ncommunication between humans and LLMs in various situations, such as social\ncompanionship and psychological support. However, LLMs often exhibit\nlimitations in emotional perception and social competence during real-world\nconversations. These limitations partly originate from their inability to adapt\ntheir communication style and emotional expression to different social and task\ncontexts. In this work, we introduce PersonaFuse, a novel LLM post-training\nframework that enables LLMs to adapt and express different personalities for\nvarying situations. Inspired by Trait Activation Theory and the Big Five\npersonality model, PersonaFuse employs a Mixture-of-Expert architecture that\ncombines persona adapters with a dynamic routing network, enabling contextual\ntrait expression. Experimental results show that PersonaFuse substantially\noutperforms baseline models across multiple dimensions of social-emotional\nintelligence. Importantly, these gains are achieved without sacrificing general\nreasoning ability or model safety, which remain common limitations of direct\nprompting and supervised fine-tuning approaches. PersonaFuse also delivers\nconsistent improvements in downstream human-centered applications, such as\nmental health counseling and review-based customer service. Finally, human\npreference evaluations against leading LLMs, including GPT-4o and DeepSeek,\ndemonstrate that PersonaFuse achieves competitive response quality despite its\ncomparatively smaller model size. These findings demonstrate that\nPersonaFuse~offers a theoretically grounded and practical approach for\ndeveloping social-emotional enhanced LLMs, marking a significant advancement\ntoward more human-centric AI systems.",
        "url": "http://arxiv.org/abs/2509.07370v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07370v1",
        "arxiv_id": "2509.07370v1",
        "authors": [
            "Yixuan Tang",
            "Yi Yang",
            "Ahmed Abbasi"
        ],
        "submitted": "2025-09-09 03:39:28",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Mitigating Attention Localization in Small Scale: Self-Attention Refinement via One-step Belief Propagation",
        "abstract": "Transformer-based self-attention mechanism serves as the core of modern\nlanguage models, yet it often suffers from localization, where attentions\ncollapse onto a limited subset of tokens and fail to capture long-range\ndependencies. To address this issue, we propose Self-Attention One-step Belief\nPropagation (SAOBP), a refinement framework that injects multi-hop\nrelationships through a belief propagation process. To interpret and quantify\nthese interactions, we introduce Global Token Dependency (GTD) that captures\nthe relative contribution of multihop connections within the attention graph.\nEmpirical results indicate that SAOBP helps prevent entropy collapse in deeper\nlayers and adaptively maintains GTD at task-appropriate levels, thereby\nsupporting improvements in model performance. Importantly, we observe\ncompetitive gains in small-scale models, highlighting its potential for\nimproving inference quality in resource-constrained scenarios.",
        "url": "http://arxiv.org/abs/2509.07324v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07324v1",
        "arxiv_id": "2509.07324v1",
        "authors": [
            "Nakyung Lee",
            "Yeongoon Kim",
            "Minhae Oh",
            "Suhwan Kim",
            "Jin Woo Koo",
            "Hyewon Jo",
            "Jungwoo Lee"
        ],
        "submitted": "2025-09-09 01:43:48",
        "source": "arxiv",
        "comment": "Accepted at EMNLP 2025"
    },
    {
        "title": "MEGG: Replay via Maximally Extreme GGscore in Incremental Learning for Neural Recommendation Models",
        "abstract": "Neural Collaborative Filtering models are widely used in recommender systems\nbut are typically trained under static settings, assuming fixed data\ndistributions. This limits their applicability in dynamic environments where\nuser preferences evolve. Incremental learning offers a promising solution, yet\nconventional methods from computer vision or NLP face challenges in\nrecommendation tasks due to data sparsity and distinct task paradigms. Existing\napproaches for neural recommenders remain limited and often lack\ngeneralizability. To address this, we propose MEGG, Replay Samples with\nMaximally Extreme GGscore, an experience replay based incremental learning\nframework. MEGG introduces GGscore, a novel metric that quantifies sample\ninfluence, enabling the selective replay of highly influential samples to\nmitigate catastrophic forgetting. Being model-agnostic, MEGG integrates\nseamlessly across architectures and frameworks. Experiments on three neural\nmodels and four benchmark datasets show superior performance over\nstate-of-the-art baselines, with strong scalability, efficiency, and\nrobustness. Implementation will be released publicly upon acceptance.",
        "url": "http://arxiv.org/abs/2509.07319v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07319v1",
        "arxiv_id": "2509.07319v1",
        "authors": [
            "Yunxiao Shi",
            "Shuo Yang",
            "Haimin Zhang",
            "Li Wang",
            "Yongze Wang",
            "Qiang Wu",
            "Min Xu"
        ],
        "submitted": "2025-09-09 01:35:51",
        "source": "arxiv",
        "comment": "Accepted by Data Mining and Knowledge Discovery (DMKD) in Sep 2025"
    },
    {
        "title": "Does This Look Familiar to You? Knowledge Analysis via Model Internal Representations",
        "abstract": "Recent advances in large language models (LLMs) have been driven by\npretraining, supervised fine tuning (SFT), and alignment tuning. Among these,\nSFT plays a crucial role in transforming a model 's general knowledge into\nstructured responses tailored to specific tasks. However, there is no clearly\nestablished methodology for effective training data selection. Simply\nincreasing the volume of data does not guarantee performance improvements,\nwhile preprocessing, sampling, and validation require substantial time and\ncost.\n  To address this issue, a variety of data selection methods have been\nproposed. Among them, knowledge based selection approaches identify suitable\ntraining data by analyzing the model 's responses. Nevertheless, these methods\ntypically rely on prompt engineering, making them sensitive to variations and\nincurring additional costs for prompt design.\n  In this study, we propose Knowledge Analysis via Model Internal\nRepresentations (KAMIR), a novel approach that overcomes these limitations by\nanalyzing data based on the model 's internal representations. KAMIR computes\nsimilarities between the hidden states of each layer (block) and the final\nhidden states for a given input to assess the data. Unlike prior methods that\nwere largely limited to multiple choice tasks, KAMIR can be applied to a wide\nrange of tasks such as machine reading comprehension and summarization.\nMoreover, it selects data useful for training based on the model 's familiarity\nwith the input, even with a small dataset and a simple classifier architecture.\nExperiments across diverse task datasets demonstrate that training with less\nfamiliar data leads to better generalization performance.",
        "url": "http://arxiv.org/abs/2509.07311v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07311v1",
        "arxiv_id": "2509.07311v1",
        "authors": [
            "Sihyun Park"
        ],
        "submitted": "2025-09-09 01:08:15",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Instance-level Performance Prediction for Long-form Generation Tasks",
        "abstract": "We motivate and share a new benchmark for instance-level performance\nprediction of long-form generation tasks having multi-faceted, fine-grained\nquality metrics. Our task-, model- and metric-agnostic formulation predicts\ncontinuous evaluation metric scores given only black-box model inputs and\noutputs. Beyond predicting point estimates of metric scores, the benchmark also\nrequires inferring prediction intervals to quantify uncertainty around point\nestimates. Evaluation spans 11 long-form datasets/tasks with multiple LLMs,\nbaselines, and metrics per task. We show that scores can be effectively\npredicted across long-form generation tasks using as few as 16 training\nexamples. Overall, we introduce a novel and useful task, a valuable benchmark\nto drive progress, and baselines ready for practical adoption today.",
        "url": "http://arxiv.org/abs/2509.07309v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07309v1",
        "arxiv_id": "2509.07309v1",
        "authors": [
            "Chi-Yang Hsu",
            "Alexander Braylan",
            "Yiheng Su",
            "Omar Alonso",
            "Matthew Lease"
        ],
        "submitted": "2025-09-09 00:59:34",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Basis Vector Metric: A Method for Robust Open-Ended State Change Detection",
        "abstract": "We test a new method, which we will abbreviate using the acronym BVM (Basis\nVectors Method), in its ability to judge the state changes in images through\nusing language embeddings. We used the MIT-States dataset, containing about\n53,000 images, to gather all of our data, which has 225 nouns and 115\nadjectives, with each noun having about 9 different adjectives, forming\napproximately 1000 noun-adjective pairs. For our first experiment, we test our\nmethod's ability to determine the state of each noun class separately against\nother metrics for comparison. These metrics are cosine similarity, dot product,\nproduct quantization, binary index, Naive Bayes, and a custom neural network.\nAmong these metrics, we found that our proposed BVM performs the best in\nclassifying the states for each noun. We then perform a second experiment where\nwe try using BVM to determine if it can differentiate adjectives from one\nanother for each adjective separately. We compared the abilities of BVM to\ndifferentiate adjectives against the proposed method the MIT-States paper\nsuggests: using a logistic regression model. In the end, we did not find\nconclusive evidence that our BVM metric could perform better than the logistic\nregression model at discerning adjectives. Yet, we were able to find evidence\nfor possible improvements to our method; this leads to the chance of increasing\nour method's accuracy through certain changes in our methodologies.",
        "url": "http://arxiv.org/abs/2509.07308v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07308v1",
        "arxiv_id": "2509.07308v1",
        "authors": [
            "David Oprea",
            "Sam Powers"
        ],
        "submitted": "2025-09-09 00:58:43",
        "source": "arxiv",
        "comment": "24 pages"
    },
    {
        "title": "Causal Attention with Lookahead Keys",
        "abstract": "In standard causal attention, each token's query, key, and value (QKV) are\nstatic and encode only preceding context. We introduce CAuSal aTtention with\nLookahead kEys (CASTLE), an attention mechanism that continually updates each\ntoken's keys as the context unfolds. We term these updated keys lookahead keys\nbecause they belong to earlier positions yet integrate information from tokens\nthat appear later relative to those positions, while strictly preserving the\nautoregressive property. Although the mechanism appears sequential, we derive a\nmathematical equivalence that avoids explicitly materializing lookahead keys at\neach position and enables efficient parallel training. On language modeling\nbenchmarks, CASTLE consistently outperforms standard causal attention across\nmodel scales, reducing validation perplexity and improving performance on a\nrange of downstream tasks.",
        "url": "http://arxiv.org/abs/2509.07301v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07301v1",
        "arxiv_id": "2509.07301v1",
        "authors": [
            "Zhuoqing Song",
            "Peng Sun",
            "Huizhuo Yuan",
            "Quanquan Gu"
        ],
        "submitted": "2025-09-09 00:15:23",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "ALICE: An Interpretable Neural Architecture for Generalization in Substitution Ciphers",
        "abstract": "We present cryptogram solving as an ideal testbed for studying neural network\ngeneralization in combinatorially complex domains. In this task, models must\ndecrypt text encoded with substitution ciphers, choosing from 26! possible\nmappings without explicit access to the cipher. We develop ALICE (an\nArchitecture for Learning Interpretable Cryptogram dEcipherment): a simple\nencoder-only Transformer that sets a new state-of-the-art for both accuracy and\nspeed on this decryption problem. Surprisingly, ALICE generalizes to unseen\nciphers after training on only ${\\sim}1500$ unique ciphers, a minute fraction\n($3.7 \\times 10^{-24}$) of the possible cipher space. To enhance\ninterpretability, we introduce a novel bijective decoding head that explicitly\nmodels permutations via the Gumbel-Sinkhorn method, enabling direct extraction\nof learned cipher mappings. Through early exit analysis, we reveal how ALICE\nprogressively refines its predictions in a way that appears to mirror common\nhuman strategies for this task: early layers employ frequency-based heuristics,\nmiddle layers form word structures, and final layers correct individual\ncharacters. Our architectural innovations and analysis methods extend beyond\ncryptograms to any domain with bijective mappings and combinatorial structure,\noffering new insights into neural network generalization and interpretability.",
        "url": "http://arxiv.org/abs/2509.07282v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07282v1",
        "arxiv_id": "2509.07282v1",
        "authors": [
            "Jeff Shen",
            "Lindsay Smith"
        ],
        "submitted": "2025-09-08 23:33:53",
        "source": "arxiv",
        "comment": "Preprint. Project page at https://jshen.net/alice"
    },
    {
        "title": "LLM Analysis of 150+ years of German Parliamentary Debates on Migration Reveals Shift from Post-War Solidarity to Anti-Solidarity in the Last Decade",
        "abstract": "Migration has been a core topic in German political debate, from millions of\nexpellees post World War II over labor migration to refugee movements in the\nrecent past. Studying political speech regarding such wide-ranging phenomena in\ndepth traditionally required extensive manual annotations, limiting the scope\nof analysis to small subsets of the data. Large language models (LLMs) have the\npotential to partially automate even complex annotation tasks. We provide an\nextensive evaluation of a multiple LLMs in annotating (anti-)solidarity\nsubtypes in German parliamentary debates compared to a large set of thousands\nof human reference annotations (gathered over a year). We evaluate the\ninfluence of model size, prompting differences, fine-tuning, historical versus\ncontemporary data; and we investigate systematic errors. Beyond methodological\nevaluation, we also interpret the resulting annotations from a social science\nlense, gaining deeper insight into (anti-)solidarity trends towards migrants in\nthe German post-World War II period and recent past. Our data reveals a high\ndegree of migrant-directed solidarity in the postwar period, as well as a\nstrong trend towards anti-solidarity in the German parliament since 2015,\nmotivating further research. These findings highlight the promise of LLMs for\npolitical text analysis and the importance of migration debates in Germany,\nwhere demographic decline and labor shortages coexist with rising polarization.",
        "url": "http://arxiv.org/abs/2509.07274v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07274v1",
        "arxiv_id": "2509.07274v1",
        "authors": [
            "Aida Kostikova",
            "Ole Pütz",
            "Steffen Eger",
            "Olga Sabelfeld",
            "Benjamin Paassen"
        ],
        "submitted": "2025-09-08 23:16:03",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Datasets for Navigating Sensitive Topics in Recommendation Systems",
        "abstract": "Personalized AI systems, from recommendation systems to chatbots, are a\nprevalent method for distributing content to users based on their learned\npreferences. However, there is growing concern about the adverse effects of\nthese systems, including their potential tendency to expose users to sensitive\nor harmful material, negatively impacting overall well-being. To address this\nconcern quantitatively, it is necessary to create datasets with relevant\nsensitivity labels for content, enabling researchers to evaluate personalized\nsystems beyond mere engagement metrics. To this end, we introduce two novel\ndatasets that include a taxonomy of sensitivity labels alongside user-content\nratings: one that integrates MovieLens rating data with content warnings from\nthe Does the Dog Die? community ratings website, and another that combines\nfan-fiction interaction data and user-generated warnings from Archive of Our\nOwn.",
        "url": "http://arxiv.org/abs/2509.07269v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07269v1",
        "arxiv_id": "2509.07269v1",
        "authors": [
            "Amelia Kovacs",
            "Jerry Chee",
            "Kimia Kazemian",
            "Sarah Dean"
        ],
        "submitted": "2025-09-08 22:58:17",
        "source": "arxiv",
        "comment": "Companion Proceedings of the ACM on Web Conference 2025, 2025"
    },
    {
        "title": "Benchmarking Information Retrieval Models on Complex Retrieval Tasks",
        "abstract": "Large language models (LLMs) are incredible and versatile tools for\ntext-based tasks that have enabled countless, previously unimaginable,\napplications. Retrieval models, in contrast, have not yet seen such capable\ngeneral-purpose models emerge. To achieve this goal, retrieval models must be\nable to perform complex retrieval tasks, where queries contain multiple parts,\nconstraints, or requirements in natural language. These tasks represent a\nnatural progression from the simple, single-aspect queries that are used in the\nvast majority of existing, commonly used evaluation sets. Complex queries\nnaturally arise as people expect search systems to handle more specific and\noften ambitious information requests, as is demonstrated by how people use\nLLM-based information systems. Despite the growing desire for retrieval models\nto expand their capabilities in complex retrieval tasks, there exist limited\nresources to assess the ability of retrieval models on a comprehensive set of\ndiverse complex tasks. The few resources that do exist feature a limited scope\nand often lack realistic settings making it hard to know the true capabilities\nof retrieval models on complex real-world retrieval tasks. To address this\nshortcoming and spur innovation in next-generation retrieval models, we\nconstruct a diverse and realistic set of complex retrieval tasks and benchmark\na representative set of state-of-the-art retrieval models. Additionally, we\nexplore the impact of LLM-based query expansion and rewriting on retrieval\nquality. Our results show that even the best models struggle to produce\nhigh-quality retrieval results with the highest average nDCG@10 of only 0.346\nand R@100 of only 0.587 across all tasks. Although LLM augmentation can help\nweaker models, the strongest model has decreased performance across all metrics\nwith all rewriting techniques.",
        "url": "http://arxiv.org/abs/2509.07253v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07253v1",
        "arxiv_id": "2509.07253v1",
        "authors": [
            "Julian Killingback",
            "Hamed Zamani"
        ],
        "submitted": "2025-09-08 22:11:10",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Neurocognitive Modeling for Text Generation: Deep Learning Architecture for EEG Data",
        "abstract": "Text generating capabilities have undergone a substantial transformation with\nthe introduction of large language models (LLMs). Electroencephalography\n(EEG)-based text production is still difficult, though, because it requires a\nlot of data and processing power. This paper introduces a new method that\ncombines the use of the Gemma 2B LLM with a classifier-LLM architecture to\nincorporate a Recurrent Neural Network (RNN) encoder. Our approach drastically\nlowers the amount of data and compute power needed while achieving performance\nclose to that of cutting-edge methods. Notably, compared to current\nmethodologies, our methodology delivers an overall performance improvement of\n10%. The suggested architecture demonstrates the possibility of effective\ntransfer learning for EEG-based text production, remaining strong and\nfunctional even in the face of data limits. This work highlights the potential\nof integrating LLMs with EEG decoding to improve assistive technologies and\nimprove independence and communication for those with severe motor limitations.\nOur method pushes the limits of present capabilities and opens new paths for\nresearch and application in brain-computer interfaces by efficiently using the\nstrengths of pre-trained language models. This makes EEG-based text production\nmore accessible and efficient.",
        "url": "http://arxiv.org/abs/2509.07202v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07202v1",
        "arxiv_id": "2509.07202v1",
        "authors": [
            "Khushiyant"
        ],
        "submitted": "2025-09-08 20:32:41",
        "source": "arxiv",
        "comment": "15 pages, 10 figures, 5 tables"
    },
    {
        "title": "Rule-Based Moral Principles for Explaining Uncertainty in Natural Language Generation",
        "abstract": "Large language models (LLMs) are increasingly used in high-stakes settings,\nwhere explaining uncertainty is both technical and ethical. Probabilistic\nmethods are often opaque and misaligned with expectations of transparency. We\npropose a framework based on rule-based moral principles for handling\nuncertainty in LLM-generated text. Using insights from moral psychology and\nvirtue ethics, we define rules such as precaution, deference, and\nresponsibility to guide responses under epistemic or aleatoric uncertainty.\nThese rules are encoded in a lightweight Prolog engine, where uncertainty\nlevels (low, medium, high) trigger aligned system actions with plain-language\nrationales. Scenario-based simulations benchmark rule coverage, fairness, and\ntrust calibration. Use cases in clinical and legal domains illustrate how moral\nreasoning can improve trust and interpretability. Our approach offers a\ntransparent, lightweight alternative to probabilistic models for socially\nresponsible natural language generation.",
        "url": "http://arxiv.org/abs/2509.07190v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07190v1",
        "arxiv_id": "2509.07190v1",
        "authors": [
            "Zahra Atf",
            "Peter R Lewis"
        ],
        "submitted": "2025-09-08 20:14:03",
        "source": "arxiv",
        "comment": "This paper was accepted for presentation at the 35th IEEE\n  International Conference on Collaborative Advances in Software and Computing.\n  Conference website:https://conf.researchr.org/home/cascon-2025"
    },
    {
        "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge",
        "abstract": "Discharge communication is a critical yet underexplored component of patient\ncare, where the goal shifts from diagnosis to education. While recent large\nlanguage model (LLM) benchmarks emphasize in-visit diagnostic reasoning, they\nfail to evaluate models' ability to support patients after the visit. We\nintroduce DischargeSim, a novel benchmark that evaluates LLMs on their ability\nto act as personalized discharge educators. DischargeSim simulates post-visit,\nmulti-turn conversations between LLM-driven DoctorAgents and PatientAgents with\ndiverse psychosocial profiles (e.g., health literacy, education, emotion).\nInteractions are structured across six clinically grounded discharge topics and\nassessed along three axes: (1) dialogue quality via automatic and LLM-as-judge\nevaluation, (2) personalized document generation including free-text summaries\nand structured AHRQ checklists, and (3) patient comprehension through a\ndownstream multiple-choice exam. Experiments across 18 LLMs reveal significant\ngaps in discharge education capability, with performance varying widely across\npatient profiles. Notably, model size does not always yield better education\noutcomes, highlighting trade-offs in strategy use and content prioritization.\nDischargeSim offers a first step toward benchmarking LLMs in post-visit\nclinical education and promoting equitable, personalized patient support.",
        "url": "http://arxiv.org/abs/2509.07188v2",
        "pdf_url": "http://arxiv.org/pdf/2509.07188v2",
        "arxiv_id": "2509.07188v2",
        "authors": [
            "Zonghai Yao",
            "Michael Sun",
            "Won Seok Jang",
            "Sunjae Kwon",
            "Soie Kwon",
            "Hong Yu"
        ],
        "submitted": "2025-09-08 20:07:30",
        "source": "arxiv",
        "comment": "Equal contribution for the first two authors. To appear in the\n  proceedings of the Main Conference on Empirical Methods in Natural Language\n  Processing (EMNLP) 2025"
    },
    {
        "title": "Towards EnergyGPT: A Large Language Model Specialized for the Energy Sector",
        "abstract": "Large Language Models have demonstrated impressive capabilities across\nvarious domains. However, their general-purpose nature often limits their\neffectiveness in specialized fields such as energy, where deep technical\nexpertise and precise domain knowledge are essential. In this paper, we\nintroduce EnergyGPT, a domain-specialized language model tailored for the\nenergy sector, developed by fine-tuning LLaMA 3.1-8B model using Supervised\nFine-Tuning on a high-quality, curated corpus of energy-related texts. We\npresent a complete development pipeline, including data collection and\ncuration, model fine-tuning, benchmark design and LLM-judge choice, evaluation\nand deployment. Through this work, we demonstrate that our training strategy\nenables improvements in domain relevance and performance without the need for\nlarge-scale infrastructure. By evaluating the performance of the model using\ndomain-specific question-answering benchmarks, our results demonstrate that\nEnergyGPT outperforms the base model in most of the energy-related language\nunderstanding and generation tasks.",
        "url": "http://arxiv.org/abs/2509.07177v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07177v1",
        "arxiv_id": "2509.07177v1",
        "authors": [
            "Amal Chebbi",
            "Babajide Kolade"
        ],
        "submitted": "2025-09-08 19:48:52",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "That's So FETCH: Fashioning Ensemble Techniques for LLM Classification in Civil Legal Intake and Referral",
        "abstract": "Each year millions of people seek help for their legal problems by calling a\nlegal aid program hotline, walking into a legal aid office, or using a lawyer\nreferral service. The first step to match them to the right help is to identify\nthe legal problem the applicant is experiencing. Misdirection has consequences.\nApplicants may miss a deadline, experience physical abuse, lose housing or lose\ncustody of children while waiting to connect to the right legal help. We\nintroduce and evaluate the FETCH classifier for legal issue classification and\ndescribe two methods for improving accuracy: a hybrid LLM/ML ensemble\nclassification method, and the automatic generation of follow-up questions to\nenrich the initial problem narrative. We employ a novel data set of 419\nreal-world queries to a nonprofit lawyer referral service. Ultimately, we show\nclassification accuracy (hits@2) of 97.37\\% using a mix of inexpensive models,\nexceeding the performance of the current state-of-the-art GPT-5 model. Our\napproach shows promise in significantly reducing the cost of guiding users of\nthe legal system to the right resource for their problem while achieving high\naccuracy.",
        "url": "http://arxiv.org/abs/2509.07170v2",
        "pdf_url": "http://arxiv.org/pdf/2509.07170v2",
        "arxiv_id": "2509.07170v2",
        "authors": [
            "Quinten Steenhuis"
        ],
        "submitted": "2025-09-08 19:34:57",
        "source": "arxiv",
        "comment": "Submission to JURIX 2025"
    },
    {
        "title": "Beyond Sequential Reranking: Reranker-Guided Search Improves Reasoning Intensive Retrieval",
        "abstract": "The widely used retrieve-and-rerank pipeline faces two critical limitations:\nthey are constrained by the initial retrieval quality of the top-k documents,\nand the growing computational demands of LLM-based rerankers restrict the\nnumber of documents that can be effectively processed. We introduce\nReranker-Guided-Search (RGS), a novel approach that bypasses these limitations\nby directly retrieving documents according to reranker preferences rather than\nfollowing the traditional sequential reranking method. Our method uses a greedy\nsearch on proximity graphs generated by approximate nearest neighbor\nalgorithms, strategically prioritizing promising documents for reranking based\non document similarity. Experimental results demonstrate substantial\nperformance improvements across multiple benchmarks: 3.5 points on BRIGHT, 2.9\non FollowIR, and 5.1 on M-BEIR, all within a constrained reranker budget of 100\ndocuments. Our analysis suggests that, given a fixed pair of embedding and\nreranker models, strategically selecting documents to rerank can significantly\nimprove retrieval accuracy under limited reranker budget.",
        "url": "http://arxiv.org/abs/2509.07163v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07163v1",
        "arxiv_id": "2509.07163v1",
        "authors": [
            "Haike Xu",
            "Tong Chen"
        ],
        "submitted": "2025-09-08 19:24:09",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Measuring Uncertainty in Transformer Circuits with Effective Information Consistency",
        "abstract": "Mechanistic interpretability has identified functional subgraphs within large\nlanguage models (LLMs), known as Transformer Circuits (TCs), that appear to\nimplement specific algorithms. Yet we lack a formal, single-pass way to\nquantify when an active circuit is behaving coherently and thus likely\ntrustworthy. Building on prior systems-theoretic proposals, we specialize a\nsheaf/cohomology and causal emergence perspective to TCs and introduce the\nEffective-Information Consistency Score (EICS). EICS combines (i) a normalized\nsheaf inconsistency computed from local Jacobians and activations, with (ii) a\nGaussian EI proxy for circuit-level causal emergence derived from the same\nforward state. The construction is white-box, single-pass, and makes units\nexplicit so that the score is dimensionless. We further provide practical\nguidance on score interpretation, computational overhead (with fast and exact\nmodes), and a toy sanity-check analysis. Empirical validation on LLM tasks is\ndeferred.",
        "url": "http://arxiv.org/abs/2509.07149v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07149v1",
        "arxiv_id": "2509.07149v1",
        "authors": [
            "Anatoly A. Krasnovsky"
        ],
        "submitted": "2025-09-08 18:54:56",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Toward Purpose-oriented Topic Model Evaluation enabled by Large Language Models",
        "abstract": "This study presents a framework for automated evaluation of dynamically\nevolving topic models using Large Language Models (LLMs). Topic modeling is\nessential for organizing and retrieving scholarly content in digital library\nsystems, helping users navigate complex and evolving knowledge domains.\nHowever, widely used automated metrics, such as coherence and diversity, often\ncapture only narrow statistical patterns and fail to explain semantic failures\nin practice. We introduce a purpose-oriented evaluation framework that employs\nnine LLM-based metrics spanning four key dimensions of topic quality: lexical\nvalidity, intra-topic semantic soundness, inter-topic structural soundness, and\ndocument-topic alignment soundness. The framework is validated through\nadversarial and sampling-based protocols, and is applied across datasets\nspanning news articles, scholarly publications, and social media posts, as well\nas multiple topic modeling methods and open-source LLMs. Our analysis shows\nthat LLM-based metrics provide interpretable, robust, and task-relevant\nassessments, uncovering critical weaknesses in topic models such as redundancy\nand semantic drift, which are often missed by traditional metrics. These\nresults support the development of scalable, fine-grained evaluation tools for\nmaintaining topic relevance in dynamic datasets. All code and data supporting\nthis work are accessible at\nhttps://github.com/zhiyintan/topic-model-LLMjudgment.",
        "url": "http://arxiv.org/abs/2509.07142v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07142v1",
        "arxiv_id": "2509.07142v1",
        "authors": [
            "Zhiyin Tan",
            "Jennifer D'Souza"
        ],
        "submitted": "2025-09-08 18:46:08",
        "source": "arxiv",
        "comment": "Accepted for publication in International Journal on Digital\n  Libraries (IJDL)"
    },
    {
        "title": "The ML-SUPERB 2.0 Challenge: Towards Inclusive ASR Benchmarking for All Language Varieties",
        "abstract": "Recent improvements in multilingual ASR have not been equally distributed\nacross languages and language varieties. To advance state-of-the-art (SOTA) ASR\nmodels, we present the Interspeech 2025 ML-SUPERB 2.0 Challenge. We construct a\nnew test suite that consists of data from 200+ languages, accents, and dialects\nto evaluate SOTA multilingual speech models. The challenge also introduces an\nonline evaluation server based on DynaBench, allowing for flexibility in model\ndesign and architecture for participants. The challenge received 5 submissions\nfrom 3 teams, all of which outperformed our baselines. The best-performing\nsubmission achieved an absolute improvement in LID accuracy of 23% and a\nreduction in CER of 18% when compared to the best baseline on a general\nmultilingual test set. On accented and dialectal data, the best submission\nobtained 30.2% lower CER and 15.7% higher LID accuracy, showing the importance\nof community challenges in making speech technologies more inclusive.",
        "url": "http://arxiv.org/abs/2509.07139v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07139v1",
        "arxiv_id": "2509.07139v1",
        "authors": [
            "William Chen",
            "Chutong Meng",
            "Jiatong Shi",
            "Martijn Bartelds",
            "Shih-Heng Wang",
            "Hsiu-Hsuan Wang",
            "Rafael Mosquera",
            "Sara Hincapie",
            "Dan Jurafsky",
            "Antonis Anastasopoulos",
            "Hung-yi Lee",
            "Karen Livescu",
            "Shinji Watanabe"
        ],
        "submitted": "2025-09-08 18:42:36",
        "source": "arxiv",
        "comment": "Interspeech 2025"
    },
    {
        "title": "MedBench-IT: A Comprehensive Benchmark for Evaluating Large Language Models on Italian Medical Entrance Examinations",
        "abstract": "Large language models (LLMs) show increasing potential in education, yet\nbenchmarks for non-English languages in specialized domains remain scarce. We\nintroduce MedBench-IT, the first comprehensive benchmark for evaluating LLMs on\nItalian medical university entrance examinations. Sourced from Edizioni Simone,\na leading preparatory materials publisher, MedBench-IT comprises 17,410\nexpert-written multiple-choice questions across six subjects (Biology,\nChemistry, Logic, General Culture, Mathematics, Physics) and three difficulty\nlevels. We evaluated diverse models including proprietary LLMs (GPT-4o, Claude\nseries) and resource-efficient open-source alternatives (<30B parameters)\nfocusing on practical deployability.\n  Beyond accuracy, we conducted rigorous reproducibility tests (88.86% response\nconsistency, varying by subject), ordering bias analysis (minimal impact), and\nreasoning prompt evaluation. We also examined correlations between question\nreadability and model performance, finding a statistically significant but\nsmall inverse relationship. MedBench-IT provides a crucial resource for Italian\nNLP community, EdTech developers, and practitioners, offering insights into\ncurrent capabilities and standardized evaluation methodology for this critical\ndomain.",
        "url": "http://arxiv.org/abs/2509.07135v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07135v1",
        "arxiv_id": "2509.07135v1",
        "authors": [
            "Ruggero Marino Lazzaroni",
            "Alessandro Angioi",
            "Michelangelo Puliga",
            "Davide Sanna",
            "Roberto Marras"
        ],
        "submitted": "2025-09-08 18:39:35",
        "source": "arxiv",
        "comment": "Accepted as an oral presentation at CLiC-it 2025"
    },
    {
        "title": "Avoiding Over-Personalization with Rule-Guided Knowledge Graph Adaptation for LLM Recommendations",
        "abstract": "We present a lightweight neuro-symbolic framework to mitigate\nover-personalization in LLM-based recommender systems by adapting user-side\nKnowledge Graphs (KGs) at inference time. Instead of retraining models or\nrelying on opaque heuristics, our method restructures a user's Personalized\nKnowledge Graph (PKG) to suppress feature co-occurrence patterns that reinforce\nPersonalized Information Environments (PIEs), i.e., algorithmically induced\nfilter bubbles that constrain content diversity. These adapted PKGs are used to\nconstruct structured prompts that steer the language model toward more diverse,\nOut-PIE recommendations while preserving topical relevance. We introduce a\nfamily of symbolic adaptation strategies, including soft reweighting, hard\ninversion, and targeted removal of biased triples, and a client-side learning\nalgorithm that optimizes their application per user. Experiments on a recipe\nrecommendation benchmark show that personalized PKG adaptations significantly\nincrease content novelty while maintaining recommendation quality,\noutperforming global adaptation and naive prompt-based methods.",
        "url": "http://arxiv.org/abs/2509.07133v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07133v1",
        "arxiv_id": "2509.07133v1",
        "authors": [
            "Fernando Spadea",
            "Oshani Seneviratne"
        ],
        "submitted": "2025-09-08 18:33:36",
        "source": "arxiv",
        "comment": "5 pages, 2 figures, ISWC"
    },
    {
        "title": "Neuro-Symbolic Frameworks: Conceptual Characterization and Empirical Comparative Analysis",
        "abstract": "Neurosymbolic (NeSy) frameworks combine neural representations and learning\nwith symbolic representations and reasoning. Combining the reasoning\ncapacities, explainability, and interpretability of symbolic processing with\nthe flexibility and power of neural computing allows us to solve complex\nproblems with more reliability while being data-efficient. However, this\nrecently growing topic poses a challenge to developers with its learning curve,\nlack of user-friendly tools, libraries, and unifying frameworks. In this paper,\nwe characterize the technical facets of existing NeSy frameworks, such as the\nsymbolic representation language, integration with neural models, and the\nunderlying algorithms. A majority of the NeSy research focuses on algorithms\ninstead of providing generic frameworks for declarative problem specification\nto leverage problem solving. To highlight the key aspects of Neurosymbolic\nmodeling, we showcase three generic NeSy frameworks - \\textit{DeepProbLog},\n\\textit{Scallop}, and \\textit{DomiKnowS}. We identify the challenges within\neach facet that lay the foundation for identifying the expressivity of each\nframework in solving a variety of problems. Building on this foundation, we aim\nto spark transformative action and encourage the community to rethink this\nproblem in novel ways.",
        "url": "http://arxiv.org/abs/2509.07122v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07122v1",
        "arxiv_id": "2509.07122v1",
        "authors": [
            "Sania Sinha",
            "Tanawan Premsri",
            "Danial Kamali",
            "Parisa Kordjamshidi"
        ],
        "submitted": "2025-09-08 18:17:33",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Instruction Agent: Enhancing Agent with Expert Demonstration",
        "abstract": "Graphical user interface (GUI) agents have advanced rapidly but still\nstruggle with complex tasks involving novel UI elements, long-horizon actions,\nand personalized trajectories. In this work, we introduce Instruction Agent, a\nGUI agent that leverages expert demonstrations to solve such tasks, enabling\ncompletion of otherwise difficult workflows. Given a single demonstration, the\nagent extracts step-by-step instructions and executes them by strictly\nfollowing the trajectory intended by the user, which avoids making mistakes\nduring execution. The agent leverages the verifier and backtracker modules\nfurther to improve robustness. Both modules are critical to understand the\ncurrent outcome from each action and handle unexpected interruptions(such as\npop-up windows) during execution. Our experiments show that Instruction Agent\nachieves a 60% success rate on a set of tasks in OSWorld that all top-ranked\nagents failed to complete. The Instruction Agent offers a practical and\nextensible framework, bridging the gap between current GUI agents and reliable\nreal-world GUI task automation.",
        "url": "http://arxiv.org/abs/2509.07098v1",
        "pdf_url": "http://arxiv.org/pdf/2509.07098v1",
        "arxiv_id": "2509.07098v1",
        "authors": [
            "Yinheng Li",
            "Hailey Hultquist",
            "Justin Wagle",
            "Kazuhito Koishida"
        ],
        "submitted": "2025-09-08 18:00:12",
        "source": "arxiv",
        "comment": null
    }
]