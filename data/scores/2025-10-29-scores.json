[
    {
        "title": "PICOs-RAG: PICO-supported Query Rewriting for Retrieval-Augmented Generation in Evidence-Based Medicine",
        "abstract": "Evidence-based medicine (EBM) research has always been of paramount\nimportance. It is important to find appropriate medical theoretical support for\nthe needs from physicians or patients to reduce the occurrence of medical\naccidents. This process is often carried out by human querying relevant\nliterature databases, which lacks objectivity and efficiency. Therefore,\nresearchers utilize retrieval-augmented generation (RAG) to search for evidence\nand generate responses automatically. However, current RAG methods struggle to\nhandle complex queries in real-world clinical scenarios. For example, when\nqueries lack certain information or use imprecise language, the model may\nretrieve irrelevant evidence and generate unhelpful answers. To address this\nissue, we present the PICOs-RAG to expand the user queries into a better\nformat. Our method can expand and normalize the queries into professional ones\nand use the PICO format, a search strategy tool present in EBM, to extract the\nmost important information used for retrieval. This approach significantly\nenhances retrieval efficiency and relevance, resulting in up to an 8.8\\%\nimprovement compared to the baseline evaluated by our method. Thereby the\nPICOs-RAG improves the performance of the large language models into a helpful\nand reliable medical assistant in EBM.",
        "url": "http://arxiv.org/abs/2510.23998v1",
        "pdf_url": "http://arxiv.org/pdf/2510.23998v1",
        "arxiv_id": "2510.23998v1",
        "authors": [
            "Mengzhou Sun",
            "Sendong Zhao",
            "Jianyu Chen",
            "Bin Qin"
        ],
        "submitted": "2025-10-28 02:01:05",
        "source": "arxiv",
        "comment": null,
        "score": 14,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores Retrieval-Augmented Generation (RAG) in Evidence-Based Medicine, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the focus on medical evidence and clinical scenarios is not a central match for your background in e-commerce and interests in deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "InteractComp: Evaluating Search Agents With Ambiguous Queries",
        "abstract": "Language agents have demonstrated remarkable potential in web search and\ninformation retrieval. However, these search agents assume user queries are\ncomplete and unambiguous, an assumption that diverges from reality where users\nbegin with incomplete queries requiring clarification through interaction. Yet\nmost agents lack interactive mechanisms during the search process, and existing\nbenchmarks cannot assess this capability. To address this gap, we introduce\nInteractComp, a benchmark designed to evaluate whether search agents can\nrecognize query ambiguity and actively interact to resolve it during search.\nFollowing the principle of easy to verify, interact to disambiguate, we\nconstruct 210 expert-curated questions across 9 domains through a\ntarget-distractor methodology that creates genuine ambiguity resolvable only\nthrough interaction. Evaluation of 17 models reveals striking failure: the best\nmodel achieves only 13.73% accuracy despite 71.50% with complete context,\nexposing systematic overconfidence rather than reasoning deficits. Forced\ninteraction produces dramatic gains, demonstrating latent capability current\nstrategies fail to engage. Longitudinal analysis shows interaction capabilities\nstagnated over 15 months while search performance improved seven-fold,\nrevealing a critical blind spot. This stagnation, coupled with the immediate\nfeedback inherent to search tasks, makes InteractComp a valuable resource for\nboth evaluating and training interaction capabilities in search agents. The\ncode is available at https://github.com/FoundationAgents/InteractComp.",
        "url": "http://arxiv.org/abs/2510.24668v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24668v1",
        "arxiv_id": "2510.24668v1",
        "authors": [
            "Mingyi Deng",
            "Lijun Huang",
            "Yani Fan",
            "Jiayi Zhang",
            "Fashen Ren",
            "Jinyi Bai",
            "Fuzhen Yang",
            "Dayi Miao",
            "Zhaoyang Yu",
            "Yifan Wu",
            "Yanfei Zhang",
            "Fengwei Teng",
            "Yingjia Wan",
            "Song Hu",
            "Yude Li",
            "Xin Jin",
            "Conghao Hu",
            "Haoyu Li",
            "Qirui Fu",
            "Tai Zhong",
            "Xinyu Wang",
            "Xiangru Tang",
            "Nan Tang",
            "Chenglin Wu",
            "Yuyu Luo"
        ],
        "submitted": "2025-10-28 17:35:54",
        "source": "arxiv",
        "comment": null,
        "score": 13,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'web search' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and search technologies. The focus on evaluating search agents with ambiguous queries aligns with your interests in deep semantic understanding and real-time relevance optimization. However, the specific domain of web search and language agents is not a primary focus of your research."
    },
    {
        "title": "Optimizing Retrieval for RAG via Reinforced Contrastive Learning",
        "abstract": "As retrieval-augmented generation (RAG) becomes increasingly widespread, the\nrole of information retrieval (IR) is shifting from retrieving information for\nhuman users to retrieving contextual knowledge for artificial intelligence (AI)\nsystems, where relevance becomes difficult to define or annotate beforehand. To\naddress this challenge, we propose R3, a Retrieval framework optimized for RAG\nthrough trialand-feedback Reinforced contrastive learning. Unlike prior\napproaches that rely on annotated or synthetic data for supervised fine-tuning,\nR3 enables the retriever to dynamically explore and optimize relevance within\nthe RAG environment. During training, the retrieved results interact with the\nenvironment to produce contrastive signals that automatically guide the\nretriever's self-improvement. Extensive experiments across diverse tasks\ndemonstrate that R3 improves RAG performance by 5.2% over the original\nretriever and surpasses state-of-the-art retrievers by 4.9%, while achieving\ncomparable results to LLM-augmented retrieval and RAG systems built on\npost-trained or instruction-tuned LLMs. It is both efficient and practical,\nrequiring only 4 GPUs and completing training within a single day.",
        "url": "http://arxiv.org/abs/2510.24652v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24652v1",
        "arxiv_id": "2510.24652v1",
        "authors": [
            "Jiawei Zhou",
            "Lei Chen"
        ],
        "submitted": "2025-10-28 17:18:30",
        "source": "arxiv",
        "comment": null,
        "score": 13,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retriever' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of retrieval-augmented generation (RAG) and the role of IR in AI systems. The use of reinforced contrastive learning to optimize retrieval is also aligned with your interests in ranking models and real-time relevance optimization."
    },
    {
        "title": "Metadata-Driven Retrieval-Augmented Generation for Financial Question Answering",
        "abstract": "Retrieval-Augmented Generation (RAG) struggles on long, structured financial\nfilings where relevant evidence is sparse and cross-referenced. This paper\npresents a systematic investigation of advanced metadata-driven\nRetrieval-Augmented Generation (RAG) techniques, proposing and evaluating a\nnovel, multi-stage RAG architecture that leverages LLM-generated metadata. We\nintroduce a sophisticated indexing pipeline to create contextually rich\ndocument chunks and benchmark a spectrum of enhancements, including\npre-retrieval filtering, post-retrieval reranking, and enriched embeddings,\nbenchmarked on the FinanceBench dataset. Our results reveal that while a\npowerful reranker is essential for precision, the most significant performance\ngains come from embedding chunk metadata directly with text (\"contextual\nchunks\"). Our proposed optimal architecture combines LLM-driven pre-retrieval\noptimizations with these contextual embeddings to achieve superior performance.\nAdditionally, we present a custom metadata reranker that offers a compelling,\ncost-effective alternative to commercial solutions, highlighting a practical\ntrade-off between peak performance and operational efficiency. This study\nprovides a blueprint for building robust, metadata-aware RAG systems for\nfinancial document analysis.",
        "url": "http://arxiv.org/abs/2510.24402v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24402v1",
        "arxiv_id": "2510.24402v1",
        "authors": [
            "Michail Dadopoulos",
            "Anestis Ladas",
            "Stratos Moschidis",
            "Ioannis Negkakis"
        ],
        "submitted": "2025-10-28 13:16:36",
        "source": "arxiv",
        "comment": "Preprint version submitted to the International Journal of Accounting\n  Information Systems; currently under major revision. 20 pages, 1 figure, 1\n  table",
        "score": 13,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores Retrieval-Augmented Generation (RAG) techniques for financial question answering, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the focus on financial domain and metadata-driven approaches is not a central match to your core research themes."
    },
    {
        "title": "Talk2Ref: A Dataset for Reference Prediction from Scientific Talks",
        "abstract": "Scientific talks are a growing medium for disseminating research, and\nautomatically identifying relevant literature that grounds or enriches a talk\nwould be highly valuable for researchers and students alike. We introduce\nReference Prediction from Talks (RPT), a new task that maps long, and\nunstructured scientific presentations to relevant papers. To support research\non RPT, we present Talk2Ref, the first large-scale dataset of its kind,\ncontaining 6,279 talks and 43,429 cited papers (26 per talk on average), where\nrelevance is approximated by the papers cited in the talk's corresponding\nsource publication. We establish strong baselines by evaluating\nstate-of-the-art text embedding models in zero-shot retrieval scenarios, and\npropose a dual-encoder architecture trained on Talk2Ref. We further explore\nstrategies for handling long transcripts, as well as training for domain\nadaptation. Our results show that fine-tuning on Talk2Ref significantly\nimproves citation prediction performance, demonstrating both the challenges of\nthe task and the effectiveness of our dataset for learning semantic\nrepresentations from spoken scientific content. The dataset and trained models\nare released under an open license to foster future research on integrating\nspoken scientific communication into citation recommendation systems.",
        "url": "http://arxiv.org/abs/2510.24478v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24478v1",
        "arxiv_id": "2510.24478v1",
        "authors": [
            "Frederik Broy",
            "Maike Züfle",
            "Jan Niehues"
        ],
        "submitted": "2025-10-28 14:50:03",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of query understanding and ranking models. The task of Reference Prediction from Talks (RPT) involves mapping scientific talks to relevant papers, which aligns with your focus on deep semantic understanding and real-time relevance optimization. However, the specific domain of scientific talks and citation recommendation systems is somewhat niche compared to your broader interests in e-commerce and general search technologies."
    },
    {
        "title": "META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine",
        "abstract": "Evidence-based medicine (EBM) holds a crucial role in clinical application.\nGiven suitable medical articles, doctors effectively reduce the incidence of\nmisdiagnoses. Researchers find it efficient to use large language models (LLMs)\ntechniques like RAG for EBM tasks. However, the EBM maintains stringent\nrequirements for evidence, and RAG applications in EBM struggle to efficiently\ndistinguish high-quality evidence. Therefore, inspired by the meta-analysis\nused in EBM, we provide a new method to re-rank and filter the medical\nevidence. This method presents multiple principles to filter the best evidence\nfor LLMs to diagnose. We employ a combination of several EBM methods to emulate\nthe meta-analysis, which includes reliability analysis, heterogeneity analysis,\nand extrapolation analysis. These processes allow the users to retrieve the\nbest medical evidence for the LLMs. Ultimately, we evaluate these high-quality\narticles and show an accuracy improvement of up to 11.4% in our experiments and\nresults. Our method successfully enables RAG to extract higher-quality and more\nreliable evidence from the PubMed dataset. This work can reduce the infusion of\nincorrect knowledge into responses and help users receive more effective\nreplies.",
        "url": "http://arxiv.org/abs/2510.24003v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24003v1",
        "arxiv_id": "2510.24003v1",
        "authors": [
            "Mengzhou Sun",
            "Sendong Zhao",
            "Jianyu Chen",
            "Haochun Wang",
            "Bin Qin"
        ],
        "submitted": "2025-10-28 02:18:09",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses Retrieval-Augmented Generation (RAG) in Evidence-Based Medicine, which is somewhat related to Information Retrieval and Natural Language Processing. However, the focus on medical evidence and meta-analysis is not directly aligned with the user's core research themes, particularly query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "DUET: Dual Model Co-Training for Entire Space CTR Prediction",
        "abstract": "The pre-ranking stage plays a pivotal role in large-scale recommender systems\nbut faces an intrinsic trade-off between model expressiveness and computational\nefficiency. Owing to the massive candidate pool and strict latency constraints,\nindustry systems often rely on lightweight two-tower architectures, which are\ncomputationally efficient yet limited in estimation capability. As a result,\nthey struggle to capture the complex synergistic and suppressive relationships\namong candidate items, which are essential for producing contextually coherent\nand diverse recommendation lists. Moreover, this simplicity further amplifies\nthe Sample Selection Bias (SSB) problem, as coarse-grained models trained on\nbiased exposure data must generalize to a much larger candidate space with\ndistinct distributions.\n  To address these issues, we propose \\textbf{DUET} (\\textbf{DU}al Model\nCo-Training for \\textbf{E}ntire Space C\\textbf{T}R Prediction), a set-wise\npre-ranking framework that achieves expressive modeling under tight\ncomputational budgets. Instead of scoring items independently, DUET performs\nset-level prediction over the entire candidate subset in a single forward pass,\nenabling information-aware interactions among candidates while amortizing the\ncomputational cost across the set. Moreover, a dual model co-training mechanism\nextends supervision to unexposed items via mutual pseudo-label refinement,\neffectively mitigating SSB. Validated through extensive offline experiments and\nonline A/B testing, DUET consistently outperforms state-of-the-art baselines\nand achieves improvements across multiple core business metrics. At present,\nDUET has been fully deployed in Kuaishou and Kuaishou Lite Apps, serving the\nmain traffic for hundreds of millions of users.",
        "url": "http://arxiv.org/abs/2510.24369v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24369v1",
        "arxiv_id": "2510.24369v1",
        "authors": [
            "Yutian Xiao",
            "Meng Yuan",
            "Fuzhen Zhuang",
            "Wei Chen",
            "Shukuan Wang",
            "Shanqi Liu",
            "Chao Feng",
            "Wenhui Yu",
            "Xiang Li",
            "Lantao Hu",
            "Han Li",
            "Zhao Zhang"
        ],
        "submitted": "2025-10-28 12:46:33",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'ctr' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on recommender systems, specifically addressing the challenges of large-scale recommendation and sample selection bias. While it touches on aspects of information retrieval, such as ranking and relevance optimization, the primary focus is on recommender systems, which is somewhat related to your interests in information retrieval but not a central match."
    },
    {
        "title": "Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems",
        "abstract": "Hallucination remains one of the key obstacles to the reliable deployment of\nlarge language models (LLMs), particularly in real-world applications. Among\nvarious mitigation strategies, Retrieval-Augmented Generation (RAG) and\nreasoning enhancement have emerged as two of the most effective and widely\nadopted approaches, marking a shift from merely suppressing hallucinations to\nbalancing creativity and reliability. However, their synergistic potential and\nunderlying mechanisms for hallucination mitigation have not yet been\nsystematically examined. This survey adopts an application-oriented perspective\nof capability enhancement to analyze how RAG, reasoning enhancement, and their\nintegration in Agentic Systems mitigate hallucinations. We propose a taxonomy\ndistinguishing knowledge-based and logic-based hallucinations, systematically\nexamine how RAG and reasoning address each, and present a unified framework\nsupported by real-world applications, evaluations, and benchmarks.",
        "url": "http://arxiv.org/abs/2510.24476v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24476v1",
        "arxiv_id": "2510.24476v1",
        "authors": [
            "Yihan Li",
            "Xiyuan Fu",
            "Ghanshyam Verma",
            "Paul Buitelaar",
            "Mingming Liu"
        ],
        "submitted": "2025-10-28 14:48:57",
        "source": "arxiv",
        "comment": "25 pages, 7 figures, 3 tables",
        "score": 6,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat relevant to your research interests in Information Retrieval and Natural Language Processing, as it discusses Retrieval-Augmented Generation (RAG), a technique that combines retrieval and generation for more reliable language models. However, the focus on hallucination mitigation in large language models is not directly related to your primary areas of interest in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space",
        "abstract": "Multimodal large language models (MLLMs) have shown impressive capabilities\nin vision-language tasks such as reasoning segmentation, where models generate\nsegmentation masks based on textual queries. While prior work has primarily\nfocused on perturbing image inputs, semantically equivalent textual\nparaphrases-crucial in real-world applications where users express the same\nintent in varied ways-remain underexplored. To address this gap, we introduce a\nnovel adversarial paraphrasing task: generating grammatically correct\nparaphrases that preserve the original query meaning while degrading\nsegmentation performance. To evaluate the quality of adversarial paraphrases,\nwe develop a comprehensive automatic evaluation protocol validated with human\nstudies. Furthermore, we introduce SPARTA-a black-box, sentence-level\noptimization method that operates in the low-dimensional semantic latent space\nof a text autoencoder, guided by reinforcement learning. SPARTA achieves\nsignificantly higher success rates, outperforming prior methods by up to 2x on\nboth the ReasonSeg and LLMSeg-40k datasets. We use SPARTA and competitive\nbaselines to assess the robustness of advanced reasoning segmentation models.\nWe reveal that they remain vulnerable to adversarial paraphrasing-even under\nstrict semantic and grammatical constraints. All code and data will be released\npublicly upon acceptance.",
        "url": "http://arxiv.org/abs/2510.24446v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24446v1",
        "arxiv_id": "2510.24446v1",
        "authors": [
            "Viktoriia Zinkovich",
            "Anton Antonov",
            "Andrei Spiridonov",
            "Denis Shepelev",
            "Andrey Moskalenko",
            "Daria Pugacheva",
            "Elena Tutubalina",
            "Andrey Kuznetsov",
            "Vlad Shakhuro"
        ],
        "submitted": "2025-10-28 14:09:05",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and text understanding, but it does not directly align with their primary focus on Information Retrieval (IR), query understanding, and ranking models. The paper's focus on adversarial paraphrasing and text autoencoder latent space is an interesting area, but it does not seem to be a central match for the user's research themes."
    },
    {
        "title": "LongWeave: A Long-Form Generation Benchmark Bridging Real-World Relevance and Verifiability",
        "abstract": "Generating long, informative, and factual outputs remains a major challenge\nfor Large Language Models (LLMs). Existing benchmarks for long-form generation\ntypically assess real-world queries with hard-to-verify metrics or use\nsynthetic setups that ease evaluation but overlook real-world intricacies. In\nthis paper, we introduce \\textbf{LongWeave}, which balances real-world and\nverifiable assessment with Constraint-Verifier Evaluation (CoV-Eval). CoV-Eval\nconstructs tasks by first defining verifiable targets within real-world\nscenarios, then systematically generating corresponding queries, textual\nmaterials, and constraints based on these targets. This ensures that tasks are\nboth realistic and objectively assessable, enabling rigorous assessment of\nmodel capabilities in meeting complex real-world constraints. LongWeave\nsupports customizable input/output lengths (up to 64K/8K tokens) across seven\ndistinct tasks. Evaluation on 23 LLMs shows that even state-of-the-art models\nencounter significant challenges in long-form generation as real-world\ncomplexity and output length increase.",
        "url": "http://arxiv.org/abs/2510.24345v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24345v1",
        "arxiv_id": "2510.24345v1",
        "authors": [
            "Zikai Xiao",
            "Fei Huang",
            "Jianhong Tu",
            "Jianhui Wei",
            "Wen Ma",
            "Yuxuan Zhou",
            "Jian Wu",
            "Bowen Yu",
            "Zuozhu Liu",
            "Junyang Lin"
        ],
        "submitted": "2025-10-28 12:11:12",
        "source": "arxiv",
        "comment": "EMNLP Findings 2025",
        "score": 6,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it does involve language models and generation, its focus on long-form generation and benchmarking is not a central match for your core themes."
    },
    {
        "title": "WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling Info-Rich Seeking",
        "abstract": "Large Language Model (LLM)-based agents have emerged as a transformative\napproach for open-ended problem solving, with information seeking (IS) being a\ncore capability that enables autonomous reasoning and decision-making. While\nprior research has largely focused on improving retrieval depth, we observe\nthat current IS agents often suffer from low search efficiency, which in turn\nconstrains overall performance. A key factor underlying this inefficiency is\nthe sparsity of target entities in training tasks, which limits opportunities\nfor agents to learn and generalize efficient search behaviors. To address these\nchallenges, we propose WebLeaper, a framework for constructing high-coverage IS\ntasks and generating efficient solution trajectories. We formulate IS as a\ntree-structured reasoning problem, enabling a substantially larger set of\ntarget entities to be embedded within a constrained context. Leveraging curated\nWikipedia tables, we propose three variants for synthesizing IS tasks, Basic,\nUnion, and Reverse-Union, to systematically increase both IS efficiency and\nefficacy. Finally, we curate training trajectories by retaining only those that\nare simultaneously accurate and efficient, ensuring that the model is optimized\nfor both correctness and search performance. Extensive experiments on both\nbasic and comprehensive settings, conducted on five IS benchmarks, BrowserComp,\nGAIA, xbench-DeepSearch, WideSearch, and Seal-0, demonstrate that our method\nconsistently achieves improvements in both effectiveness and efficiency over\nstrong baselines.",
        "url": "http://arxiv.org/abs/2510.24697v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24697v1",
        "arxiv_id": "2510.24697v1",
        "authors": [
            "Zhengwei Tao",
            "Haiyang Shen",
            "Baixuan Li",
            "Wenbiao Yin",
            "Jialong Wu",
            "Kuan Li",
            "Zhongwang Zhang",
            "Huifeng Yin",
            "Rui Ye",
            "Liwen Zhang",
            "Xinyu Wang",
            "Pengjun Xie",
            "Jingren Zhou",
            "Yong Jiang"
        ],
        "submitted": "2025-10-28 17:51:42",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in areas that require deep semantic understanding and real-time relevance optimization. The proposed framework, WebLeaper, addresses search efficiency and efficacy, which aligns with your focus on query understanding and ranking models. However, the paper's primary focus on large language models and information seeking might not be as central to your interests as other topics."
    },
    {
        "title": "Iterative Critique-Refine Framework for Enhancing LLM Personalization",
        "abstract": "Personalized text generation requires models not only to produce coherent\ntext but also to align with a target user's style, tone, and topical focus.\nExisting retrieval-augmented approaches such as LaMP and PGraphRAG enrich\nprofiles with user and neighbor histories, but they stop at generation and\noften yield outputs that drift in tone, topic, or style. We present PerFine, a\nunified, training-free critique-refine framework that enhances personalization\nthrough iterative, profile-grounded feedback. In each iteration, an LLM\ngenerator produces a draft conditioned on the retrieved profile, and a critic\nLLM - also conditioned on the same profile - provides structured feedback on\ntone, vocabulary, sentence structure, and topicality. The generator then\nrevises, while a novel knockout strategy retains the stronger draft across\niterations. We further study additional inference-time strategies such as\nBest-of-N and Topic Extraction to balance quality and efficiency. Across Yelp,\nGoodreads, and Amazon datasets, PerFine consistently improves personalization\nover PGraphRAG, with GEval gains of +7-13%, steady improvements over 3-5\nrefinement iterations, and scalability with increasing critic size. These\nresults highlight that post-hoc, profile-aware feedback offers a powerful\nparadigm for personalized LLM generation that is both training-free and\nmodel-agnostic.",
        "url": "http://arxiv.org/abs/2510.24469v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24469v1",
        "arxiv_id": "2510.24469v1",
        "authors": [
            "Durga Prasad Maram",
            "Dhruvin Gandhi",
            "Zonghai Yao",
            "Gayathri Akkinapalli",
            "Franck Dernoncourt",
            "Yu Wang",
            "Ryan A. Rossi",
            "Nesreen K. Ahmed"
        ],
        "submitted": "2025-10-28 14:36:22",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper presents a framework for enhancing LLM personalization through iterative feedback. While it touches on aspects related to information retrieval (e.g., profile retrieval), its primary focus is on text generation and personalization, which aligns with your broader interests in NLP and related topics. However, it does not directly address your core research themes in IR, query understanding, or ranking models."
    },
    {
        "title": "MiniOneRec: An Open-Source Framework for Scaling Generative Recommendation",
        "abstract": "The recent success of large language models (LLMs) has renewed interest in\nwhether recommender systems can achieve similar scaling benefits. Conventional\nrecommenders, dominated by massive embedding tables, tend to plateau as\nembedding dimensions grow. In contrast, the emerging generative paradigm\nreplaces embeddings with compact Semantic ID (SID) sequences produced by\nautoregressive Transformers. Yet most industrial deployments remain\nproprietary, leaving two fundamental questions open: (1) Do the expected\nscaling laws hold on public benchmarks? (2) What is the minimal post-training\nrecipe that enables competitive performance?\n  We present MiniOneRec, to the best of our knowledge, the first fully\nopen-source generative recommendation framework, which provides an end-to-end\nworkflow spanning SID construction, supervised fine-tuning, and\nrecommendation-oriented reinforcement learning. We generate SIDs via a Residual\nQuantized VAE and post-train Qwen backbones ranging from 0.5B to 7B parameters\non the Amazon Review dataset. Our experiments reveal a consistent downward\ntrend in both training and evaluation losses with increasing model size,\nvalidating the parameter efficiency of the generative approach. To further\nenhance performance, we propose a lightweight yet effective post-training\npipeline that (1) enforces full-process SID alignment and (2) applies\nreinforcement learning with constrained decoding and hybrid rewards. Together,\nthese techniques yield significant improvements in both ranking accuracy and\ncandidate diversity.",
        "url": "http://arxiv.org/abs/2510.24431v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24431v1",
        "arxiv_id": "2510.24431v1",
        "authors": [
            "Xiaoyu Kong",
            "Leheng Sheng",
            "Junfei Tan",
            "Yuxin Chen",
            "Jiancan Wu",
            "An Zhang",
            "Xiang Wang",
            "Xiangnan He"
        ],
        "submitted": "2025-10-28 13:58:36",
        "source": "arxiv",
        "comment": "Technical Report",
        "score": 5,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a generative recommendation framework, which is related to recommender systems, but it does not directly address information retrieval, query understanding, or ranking models. While it touches on deep semantic understanding, the focus is on the generative paradigm, which is not a primary area of interest for the user."
    },
    {
        "title": "Evaluating Long-Term Memory for Long-Context Question Answering",
        "abstract": "In order for large language models to achieve true conversational continuity\nand benefit from experiential learning, they need memory. While research has\nfocused on the development of complex memory systems, it remains unclear which\ntypes of memory are most effective for long-context conversational tasks. We\npresent a systematic evaluation of memory-augmented methods using LoCoMo, a\nbenchmark of synthetic long-context dialogues annotated for question-answering\ntasks that require diverse reasoning strategies. We analyse full-context\nprompting, semantic memory through retrieval-augmented generation and agentic\nmemory, episodic memory through in-context learning, and procedural memory\nthrough prompt optimization. Our findings show that memory-augmented approaches\nreduce token usage by over 90% while maintaining competitive accuracy. Memory\narchitecture complexity should scale with model capability, with small\nfoundation models benefitting most from RAG, and strong instruction-tuned\nreasoning model gaining from episodic learning through reflections and more\ncomplex agentic semantic memory. In particular, episodic memory can help LLMs\nrecognise the limits of their own knowledge.",
        "url": "http://arxiv.org/abs/2510.23730v1",
        "pdf_url": "http://arxiv.org/pdf/2510.23730v1",
        "arxiv_id": "2510.23730v1",
        "authors": [
            "Alessandra Terranova",
            "Björn Ross",
            "Alexandra Birch"
        ],
        "submitted": "2025-10-27 18:03:50",
        "source": "arxiv",
        "comment": "14 pages including appendix, 3 figures. Submitted to October ARR and\n  to Metacognition in Generative AI EurIPS workshop (under review for both)",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on memory-augmented methods for long-context conversational tasks, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on conversational AI and question-answering tasks makes it less directly relevant to your core research themes. The use of memory-augmented approaches and analysis of different memory architectures may be of interest, but it is not a central match for your research interests."
    },
    {
        "title": "From Memorization to Reasoning in the Spectrum of Loss Curvature",
        "abstract": "We characterize how memorization is represented in transformer models and\nshow that it can be disentangled in the weights of both language models (LMs)\nand vision transformers (ViTs) using a decomposition based on the loss\nlandscape curvature. This insight is based on prior theoretical and empirical\nwork showing that the curvature for memorized training points is much sharper\nthan non memorized, meaning ordering weight components from high to low\ncurvature can reveal a distinction without explicit labels. This motivates a\nweight editing procedure that suppresses far more recitation of untargeted\nmemorized data more effectively than a recent unlearning method\n(BalancedSubnet), while maintaining lower perplexity. Since the basis of\ncurvature has a natural interpretation for shared structure in model weights,\nwe analyze the editing procedure extensively on its effect on downstream tasks\nin LMs, and find that fact retrieval and arithmetic are specifically and\nconsistently negatively affected, even though open book fact retrieval and\ngeneral logical reasoning is conserved. We posit these tasks rely heavily on\nspecialized directions in weight space rather than general purpose mechanisms,\nregardless of whether those individual datapoints are memorized. We support\nthis by showing a correspondence between task data's activation strength with\nlow curvature components that we edit out, and the drop in task performance\nafter the edit. Our work enhances the understanding of memorization in neural\nnetworks with practical applications towards removing it, and provides evidence\nfor idiosyncratic, narrowly-used structures involved in solving tasks like math\nand fact retrieval.",
        "url": "http://arxiv.org/abs/2510.24256v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24256v1",
        "arxiv_id": "2510.24256v1",
        "authors": [
            "Jack Merullo",
            "Srihita Vatsavaya",
            "Lucius Bushnaq",
            "Owen Lewis"
        ],
        "submitted": "2025-10-28 10:09:35",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the theoretical and empirical analysis of memorization in transformer models, which is not directly related to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on neural networks, the context and applications are not aligned with your interests."
    },
    {
        "title": "Squrve: A Unified and Modular Framework for Complex Real-World Text-to-SQL Tasks",
        "abstract": "Text-to-SQL technology has evolved rapidly, with diverse academic methods\nachieving impressive results. However, deploying these techniques in real-world\nsystems remains challenging due to limited integration tools. Despite these\nadvances, we introduce Squrve, a unified, modular, and extensive Text-to-SQL\nframework designed to bring together research advances and real-world\napplications. Squrve first establishes a universal execution paradigm that\nstandardizes invocation interfaces, then proposes a multi-actor collaboration\nmechanism based on seven abstracted effective atomic actor components.\nExperiments on widely adopted benchmarks demonstrate that the collaborative\nworkflows consistently outperform the original individual methods, thereby\nopening up a new effective avenue for tackling complex real-world queries. The\ncodes are available at https://github.com/Satissss/Squrve.",
        "url": "http://arxiv.org/abs/2510.24102v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24102v1",
        "arxiv_id": "2510.24102v1",
        "authors": [
            "Yihan Wang",
            "Peiyu Liu",
            "Runyu Chen",
            "Jiaxing Pu",
            "Wei Xu"
        ],
        "submitted": "2025-10-28 06:16:38",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Text-to-SQL tasks, which, while related to information retrieval, does not directly align with the user's core research themes in query understanding, ranking models, and user behavior modeling. Although it involves text processing, the context is more aligned with NLP and data mining, but the specific application and methodology do not seem to be directly relevant to the user's interests."
    },
    {
        "title": "M-Eval: A Heterogeneity-Based Framework for Multi-evidence Validation in Medical RAG Systems",
        "abstract": "Retrieval-augmented Generation (RAG) has demonstrated potential in enhancing\nmedical question-answering systems through the integration of large language\nmodels (LLMs) with external medical literature. LLMs can retrieve relevant\nmedical articles to generate more professional responses efficiently. However,\ncurrent RAG applications still face problems. They generate incorrect\ninformation, such as hallucinations, and they fail to use external knowledge\ncorrectly. To solve these issues, we propose a new method named M-Eval. This\nmethod is inspired by the heterogeneity analysis approach used in\nEvidence-Based Medicine (EBM). Our approach can check for factual errors in RAG\nresponses using evidence from multiple sources. First, we extract additional\nmedical literature from external knowledge bases. Then, we retrieve the\nevidence documents generated by the RAG system. We use heterogeneity analysis\nto check whether the evidence supports different viewpoints in the response. In\naddition to verifying the accuracy of the response, we also assess the\nreliability of the evidence provided by the RAG system. Our method shows an\nimprovement of up to 23.31% accuracy across various LLMs. This work can help\ndetect errors in current RAG-based medical systems. It also makes the\napplications of LLMs more reliable and reduces diagnostic errors.",
        "url": "http://arxiv.org/abs/2510.23995v1",
        "pdf_url": "http://arxiv.org/pdf/2510.23995v1",
        "arxiv_id": "2510.23995v1",
        "authors": [
            "Mengzhou Sun",
            "Sendong Zhao",
            "Jianyu Chen",
            "Haochun Wang",
            "Bin Qin"
        ],
        "submitted": "2025-10-28 01:57:40",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to information retrieval, specifically in the context of Retrieval-augmented Generation (RAG) systems, but its focus on medical question-answering and evidence validation is not directly aligned with the user's core research themes. While it involves query understanding and ranking models, the application domain and specific challenges addressed are distinct from the user's primary interests in e-commerce and deep semantic understanding."
    },
    {
        "title": "emg2speech: synthesizing speech from electromyography using self-supervised speech models",
        "abstract": "We present a neuromuscular speech interface that translates electromyographic\n(EMG) signals collected from orofacial muscles during speech articulation\ndirectly into audio. We show that self-supervised speech (SS) representations\nexhibit a strong linear relationship with the electrical power of muscle action\npotentials: SS features can be linearly mapped to EMG power with a correlation\nof $r = 0.85$. Moreover, EMG power vectors corresponding to different\narticulatory gestures form structured and separable clusters in feature space.\nThis relationship: $\\text{SS features}$ $\\xrightarrow{\\texttt{linear mapping}}$\n$\\text{EMG power}$ $\\xrightarrow{\\texttt{gesture-specific clustering}}$\n$\\text{articulatory movements}$, highlights that SS models implicitly encode\narticulatory mechanisms. Leveraging this property, we directly map EMG signals\nto SS feature space and synthesize speech, enabling end-to-end EMG-to-speech\ngeneration without explicit articulatory models and vocoder training.",
        "url": "http://arxiv.org/abs/2510.23969v1",
        "pdf_url": "http://arxiv.org/pdf/2510.23969v1",
        "arxiv_id": "2510.23969v1",
        "authors": [
            "Harshavardhana T. Gowda",
            "Lee M. Miller"
        ],
        "submitted": "2025-10-28 00:50:15",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper focuses on speech synthesis from electromyography signals, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "Latent Chain-of-Thought for Visual Reasoning",
        "abstract": "Chain-of-thought (CoT) reasoning is critical for improving the\ninterpretability and reliability of Large Vision-Language Models (LVLMs).\nHowever, existing training algorithms such as SFT, PPO, and GRPO may not\ngeneralize well across unseen reasoning tasks and heavily rely on a biased\nreward model. To address this challenge, we reformulate reasoning in LVLMs as\nposterior inference and propose a scalable training algorithm based on\namortized variational inference. By leveraging diversity-seeking reinforcement\nlearning algorithms, we introduce a novel sparse reward function for\ntoken-level learning signals that encourage diverse, high-likelihood latent\nCoT, overcoming deterministic sampling limitations and avoiding reward hacking.\nAdditionally, we implement a Bayesian inference-scaling strategy that replaces\ncostly Best-of-N and Beam Search with a marginal likelihood to efficiently rank\noptimal rationales and answers. We empirically demonstrate that the proposed\nmethod enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in\nterms of effectiveness, generalization, and interpretability.",
        "url": "http://arxiv.org/abs/2510.23925v1",
        "pdf_url": "http://arxiv.org/pdf/2510.23925v1",
        "arxiv_id": "2510.23925v1",
        "authors": [
            "Guohao Sun",
            "Hang Hua",
            "Jian Wang",
            "Jiebo Luo",
            "Sohail Dianat",
            "Majid Rabbani",
            "Raghuveer Rao",
            "Zhiqiang Tao"
        ],
        "submitted": "2025-10-27 23:10:06",
        "source": "arxiv",
        "comment": "NeurIPS 2025",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and deep semantic understanding, but it focuses on visual reasoning and Large Vision-Language Models (LVLMs), which is not a central match to your primary focus on information retrieval and search technologies."
    },
    {
        "title": "OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL Reasoning",
        "abstract": "We present OraPlan-SQL, our system for the Archer NL2SQL Evaluation Challenge\n2025, a bilingual benchmark requiring complex reasoning such as arithmetic,\ncommonsense, and hypothetical inference. OraPlan-SQL ranked first, exceeding\nthe second-best system by more than 6% in execution accuracy (EX), with 55.0%\nin English and 56.7% in Chinese, while maintaining over 99% SQL validity (VA).\nOur system follows an agentic framework with two components: Planner agent that\ngenerates stepwise natural language plans, and SQL agent that converts these\nplans into executable SQL. Since SQL agent reliably adheres to the plan, our\nrefinements focus on the planner. Unlike prior methods that rely on multiple\nsub-agents for planning and suffer from orchestration overhead, we introduce a\nfeedback-guided meta-prompting strategy to refine a single planner. Failure\ncases from a held-out set are clustered with human input, and an LLM distills\nthem into corrective guidelines that are integrated into the planner's system\nprompt, improving generalization without added complexity. For the multilingual\nscenario, to address transliteration and entity mismatch issues, we incorporate\nentity-linking guidelines that generate alternative surface forms for entities\nand explicitly include them in the plan. Finally, we enhance reliability\nthrough plan diversification: multiple candidate plans are generated for each\nquery, with the SQL agent producing a query for each plan, and final output\nselected via majority voting over their executions.",
        "url": "http://arxiv.org/abs/2510.23870v1",
        "pdf_url": "http://arxiv.org/pdf/2510.23870v1",
        "arxiv_id": "2510.23870v1",
        "authors": [
            "Marianne Menglin Liu",
            "Sai Ashish Somayajula",
            "Syed Fahad Allam Shah",
            "Sujith Ravi",
            "Dan Roth"
        ],
        "submitted": "2025-10-27 21:22:41",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to the user's interests in Natural Language Processing (NLP) and query understanding, but it is primarily focused on NL2SQL reasoning, which is not a central match for the user's core research themes in Information Retrieval and Search technologies."
    },
    {
        "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents",
        "abstract": "Public research results on large-scale supervised finetuning of AI agents\nremain relatively rare, since the collection of agent training data presents\nunique challenges. In this work, we argue that the bottleneck is not a lack of\nunderlying data sources, but that a large variety of data is fragmented across\nheterogeneous formats, tools, and interfaces. To this end, we introduce the\nagent data protocol (ADP), a light-weight representation language that serves\nas an \"interlingua\" between agent datasets in diverse formats and unified agent\ntraining pipelines downstream. The design of ADP is expressive enough to\ncapture a large variety of tasks, including API/tool use, browsing, coding,\nsoftware engineering, and general agentic workflows, while remaining simple to\nparse and train on without engineering at a per-dataset level. In experiments,\nwe unified a broad collection of 13 existing agent training datasets into ADP\nformat, and converted the standardized ADP data into training-ready formats for\nmultiple agent frameworks. We performed SFT on these data, and demonstrated an\naverage performance gain of ~20% over corresponding base models, and delivers\nstate-of-the-art or near-SOTA performance on standard coding, browsing, tool\nuse, and research benchmarks, without domain-specific tuning. All code and data\nare released publicly, in the hope that ADP could help lower the barrier to\nstandardized, scalable, and reproducible agent training.",
        "url": "http://arxiv.org/abs/2510.24702v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24702v1",
        "arxiv_id": "2510.24702v1",
        "authors": [
            "Yueqi Song",
            "Ketan Ramaneti",
            "Zaid Sheikh",
            "Ziru Chen",
            "Boyu Gou",
            "Tianbao Xie",
            "Yiheng Xu",
            "Danyang Zhang",
            "Apurva Gandhi",
            "Fan Yang",
            "Joseph Liu",
            "Tianyue Ou",
            "Zhihao Yuan",
            "Frank Xu",
            "Shuyan Zhou",
            "Xingyao Wang",
            "Xiang Yue",
            "Tao Yu",
            "Huan Sun",
            "Yu Su",
            "Graham Neubig"
        ],
        "submitted": "2025-10-28 17:53:13",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a protocol for unifying datasets for fine-tuning LLM agents, which is somewhat related to the user's interests in Information Retrieval and Natural Language Processing. However, the focus on agent training data and LLM agents is not directly aligned with the user's core research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Repurposing Synthetic Data for Fine-grained Search Agent Supervision",
        "abstract": "LLM-based search agents are increasingly trained on entity-centric synthetic\ndata to solve complex, knowledge-intensive tasks. However, prevailing training\nmethods like Group Relative Policy Optimization (GRPO) discard this rich entity\ninformation, relying instead on sparse, outcome-based rewards. This critical\nlimitation renders them unable to distinguish informative \"near-miss\"\nsamples-those with substantially correct reasoning but a flawed final\nanswer-from complete failures, thus discarding valuable learning signals. We\naddress this by leveraging the very entities discarded during training. Our\nempirical analysis reveals a strong positive correlation between the number of\nground-truth entities identified during an agent's reasoning process and final\nanswer accuracy. Building on this insight, we introduce Entity-aware Group\nRelative Policy Optimization (E-GRPO), a novel framework that formulates a\ndense entity-aware reward function. E-GRPO assigns partial rewards to incorrect\nsamples proportional to their entity match rate, enabling the model to\neffectively learn from these \"near-misses\". Experiments on diverse\nquestion-answering (QA) and deep research benchmarks show that E-GRPO\nconsistently and significantly outperforms the GRPO baseline. Furthermore, our\nanalysis reveals that E-GRPO not only achieves superior accuracy but also\ninduces more efficient reasoning policies that require fewer tool calls,\ndemonstrating a more effective and sample-efficient approach to aligning search\nagents.",
        "url": "http://arxiv.org/abs/2510.24694v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24694v1",
        "arxiv_id": "2510.24694v1",
        "authors": [
            "Yida Zhao",
            "Kuan Li",
            "Xixi Wu",
            "Liwen Zhang",
            "Dingchu Zhang",
            "Baixuan Li",
            "Maojia Song",
            "Zhuo Chen",
            "Chenxi Wang",
            "Xinyu Wang",
            "Kewei Tu",
            "Pengjun Xie",
            "Jingren Zhou",
            "Yong Jiang"
        ],
        "submitted": "2025-10-28 17:50:40",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your interests in Information Retrieval, particularly in the area of query understanding and ranking models. The paper focuses on improving search agents using entity-aware rewards, which is a novel approach to optimizing search results. While it's not directly related to your e-commerce background, the techniques and ideas presented can be applied to various domains, including e-commerce."
    },
    {
        "title": "Evolving Diagnostic Agents in a Virtual Clinical Environment",
        "abstract": "In this paper, we present a framework for training large language models\n(LLMs) as diagnostic agents with reinforcement learning, enabling them to\nmanage multi-turn diagnostic processes, adaptively select examinations, and\ncommit to final diagnoses. Unlike instruction-tuned models trained on static\ncase summaries, our method acquires diagnostic strategies through interactive\nexploration and outcome-based feedback. Our contributions are fourfold: (i) We\npresent DiagGym, a diagnostics world model trained with electronic health\nrecords that emits examination outcomes conditioned on patient history and\nrecommended examination, serving as a virtual clinical environment for\nrealistic diagnosis training and evaluation; (ii) We train DiagAgent via\nend-to-end, multi-turn reinforcement learning to learn diagnostic policies that\noptimize both information yield and diagnostic accuracy; (iii) We introduce\nDiagBench, a diagnostic benchmark comprising 750 cases with physician-validated\nexamination recommendations and 99 cases annotated with 973 physician-written\nrubrics on diagnosis process; (iv) we demonstrate superior performance across\ndiverse diagnostic settings. DiagAgent significantly outperforms 10\nstate-of-the-art LLMs, including DeepSeek-v3 and GPT-4o, as well as two\nprompt-engineered agents. In single-turn settings, DiagAgent achieves 9.34%\nhigher diagnostic accuracy and 44.03% improvement in examination recommendation\nhit ratio. In end-to-end settings, it delivers 15.12% increase in diagnostic\naccuracy and 23.09% boost in examination recommendation F1 score. In\nrubric-based evaluation, it surpasses the next-best model, Claude-sonnet-4, by\n7.1% in weighted rubric score. These findings indicate that learning policies\nin interactive clinical environments confers dynamic and clinically meaningful\ndiagnostic management abilities unattainable through passive training alone.",
        "url": "http://arxiv.org/abs/2510.24654v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24654v1",
        "arxiv_id": "2510.24654v1",
        "authors": [
            "Pengcheng Qiu",
            "Chaoyi Wu",
            "Junwei Liu",
            "Qiaoyu Zheng",
            "Yusheng Liao",
            "Haowen Wang",
            "Yun Yue",
            "Qianrui Fan",
            "Shuai Zhen",
            "Jian Wang",
            "Jinjie Gu",
            "Yanfeng Wang",
            "Ya Zhang",
            "Weidi Xie"
        ],
        "submitted": "2025-10-28 17:19:47",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 0,
        "llm_reason": "LLM scoring failed."
    },
    {
        "title": "OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement Learning",
        "abstract": "Reward models (RMs) have become essential for aligning large language models\n(LLMs), serving as scalable proxies for human evaluation in both training and\ninference. However, existing RMs struggle on knowledge-intensive and long-form\ntasks, where evaluating correctness requires grounding beyond the model's\ninternal knowledge. This limitation hinders them from reliably discriminating\nsubtle quality differences, especially when external evidence is necessary. To\naddress this, we introduce OpenRM, a tool-augmented long-form reward model that\nsystematically judges open-ended responses by invoking external tools to gather\nrelevant evidence. We train OpenRM with Group Relative Policy Optimization\n(GRPO) on over 27K synthesized pairwise examples generated through a\ncontrollable data synthesis framework. The training objective jointly\nsupervises intermediate tool usage and final outcome accuracy, incentivizing\nour reward model to learn effective evidence-based judgment strategies.\nExtensive experiments on three newly-collected datasets and two widely-used\nbenchmarks demonstrate that OpenRM substantially outperforms existing reward\nmodeling approaches. As a further step, we integrate OpenRM into both\ninference-time response selection and training-time data selection. This yields\nconsistent gains in downstream LLM alignment tasks, highlighting the potential\nof tool-augmented reward models for scaling reliable long-form evaluation.",
        "url": "http://arxiv.org/abs/2510.24636v2",
        "pdf_url": "http://arxiv.org/pdf/2510.24636v2",
        "arxiv_id": "2510.24636v2",
        "authors": [
            "Ziyou Hu",
            "Zhengliang Shi",
            "Minghang Zhu",
            "Haitao Li",
            "Teng Sun",
            "Pengjie Ren",
            "Suzan Verberne",
            "Zhaochun Ren"
        ],
        "submitted": "2025-10-28 17:02:46",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a tool-augmented reward model for evaluating long-form tasks, which is somewhat related to information retrieval and ranking models. However, the focus on reward models and reinforcement learning is not a central match to the user's primary research interests in query understanding, ranking models, and user behavior modeling. The connection to natural language processing is relevant, but the paper's emphasis on large language models and external tools limits its alignment with the user's research themes."
    },
    {
        "title": "Open Korean Historical Corpus: A Millennia-Scale Diachronic Collection of Public Domain Texts",
        "abstract": "The history of the Korean language is characterized by a discrepancy between\nits spoken and written forms and a pivotal shift from Chinese characters to the\nHangul alphabet. However, this linguistic evolution has remained largely\nunexplored in NLP due to a lack of accessible historical corpora. To address\nthis gap, we introduce the Open Korean Historical Corpus, a large-scale, openly\nlicensed dataset spanning 1,300 years and 6 languages, as well as\nunder-represented writing systems like Korean-style Sinitic (Idu) and\nHanja-Hangul mixed script. This corpus contains 18 million documents and 5\nbillion tokens from 19 sources, ranging from the 7th century to 2025. We\nleverage this resource to quantitatively analyze major linguistic shifts: (1)\nIdu usage peaked in the 1860s before declining sharply; (2) the transition from\nHanja to Hangul was a rapid transformation starting around 1890; and (3) North\nKorea's lexical divergence causes modern tokenizers to produce up to 51 times\nhigher out-of-vocabulary rates. This work provides a foundational resource for\nquantitative diachronic analysis by capturing the history of the Korean\nlanguage. Moreover, it can serve as a pre-training corpus for large language\nmodels, potentially improving their understanding of Sino-Korean vocabulary in\nmodern Hangul as well as archaic writing systems.",
        "url": "http://arxiv.org/abs/2510.24541v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24541v1",
        "arxiv_id": "2510.24541v1",
        "authors": [
            "Seyoung Song",
            "Nawon Kim",
            "Songeun Chae",
            "Kiwoong Park",
            "Jiho Jin",
            "Haneul Yoo",
            "Kyunghyun Cho",
            "Alice Oh"
        ],
        "submitted": "2025-10-28 15:43:26",
        "source": "arxiv",
        "comment": "Dataset and code available at https://github.com/seyoungsong/OKHC",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'korea' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and its application to a specific domain (Korean language history). However, it does not directly align with the user's core research themes in Information Retrieval, query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated Islamic Content",
        "abstract": "Large language models are increasingly used for Islamic guidance, but risk\nmisquoting texts, misapplying jurisprudence, or producing culturally\ninconsistent responses. We pilot an evaluation of GPT-4o, Ansari AI, and Fanar\non prompts from authentic Islamic blogs. Our dual-agent framework uses a\nquantitative agent for citation verification and six-dimensional scoring (e.g.,\nStructure, Islamic Consistency, Citations) and a qualitative agent for\nfive-dimensional side-by-side comparison (e.g., Tone, Depth, Originality).\nGPT-4o scored highest in Islamic Accuracy (3.93) and Citation (3.38), Ansari AI\nfollowed (3.68, 3.32), and Fanar lagged (2.76, 1.82). Despite relatively strong\nperformance, models still fall short in reliably producing accurate Islamic\ncontent and citations -- a paramount requirement in faith-sensitive writing.\nGPT-4o had the highest mean quantitative score (3.90/5), while Ansari AI led\nqualitative pairwise wins (116/200). Fanar, though trailing, introduces\ninnovations for Islamic and Arabic contexts. This study underscores the need\nfor community-driven benchmarks centering Muslim perspectives, offering an\nearly step toward more reliable AI in Islamic knowledge and other high-stakes\ndomains such as medicine, law, and journalism.",
        "url": "http://arxiv.org/abs/2510.24438v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24438v1",
        "arxiv_id": "2510.24438v1",
        "authors": [
            "Abdullah Mushtaq",
            "Rafay Naeem",
            "Ezieddin Elmahjub",
            "Ibrahim Ghaznavi",
            "Shawqi Al-Maliki",
            "Mohamed Abdallah",
            "Ala Al-Fuqaha",
            "Junaid Qadir"
        ],
        "submitted": "2025-10-28 14:05:55",
        "source": "arxiv",
        "comment": "Accepted at 39th Conference on Neural Information Processing Systems\n  (NeurIPS 2025) Workshop: 5th Muslims in Machine Learning (MusIML) Workshop",
        "score": 3,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the evaluation of Large Language Models (LLMs) for generating Islamic content, which is not directly related to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on aspects of NLP, the context and application are quite specific and not aligned with your primary interests."
    },
    {
        "title": "Text Simplification with Sentence Embeddings",
        "abstract": "Sentence embeddings can be decoded to give approximations of the original\ntexts used to create them. We explore this effect in the context of text\nsimplification, demonstrating that reconstructed text embeddings preserve\ncomplexity levels. We experiment with a small feed forward neural network to\neffectively learn a transformation between sentence embeddings representing\nhigh-complexity and low-complexity texts. We provide comparison to a Seq2Seq\nand LLM-based approach, showing encouraging results in our much smaller\nlearning setting. Finally, we demonstrate the applicability of our\ntransformation to an unseen simplification dataset (MedEASI), as well as\ndatasets from languages outside the training data (ES,DE). We conclude that\nlearning transformations in sentence embedding space is a promising direction\nfor future research and has potential to unlock the ability to develop small,\nbut powerful models for text simplification and other natural language\ngeneration tasks.",
        "url": "http://arxiv.org/abs/2510.24365v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24365v1",
        "arxiv_id": "2510.24365v1",
        "authors": [
            "Matthew Shardlow"
        ],
        "submitted": "2025-10-28 12:41:10",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores text simplification using sentence embeddings, which is somewhat related to information retrieval, particularly in the context of natural language processing. However, the focus on text simplification and natural language generation tasks is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is loosely related to the user's background in e-commerce and NLP, but it does not address the user's core research themes."
    },
    {
        "title": "HACK: Hallucinations Along Certainty and Knowledge Axes",
        "abstract": "Hallucinations in LLMs present a critical barrier to their reliable usage.\nExisting research usually categorizes hallucination by their external\nproperties rather than by the LLMs' underlying internal properties. This\nexternal focus overlooks that hallucinations may require tailored mitigation\nstrategies based on their underlying mechanism. We propose a framework for\ncategorizing hallucinations along two axes: knowledge and certainty. Since\nparametric knowledge and certainty may vary across models, our categorization\nmethod involves a model-specific dataset construction process that\ndifferentiates between those types of hallucinations. Along the knowledge axis,\nwe distinguish between hallucinations caused by a lack of knowledge and those\noccurring despite the model having the knowledge of the correct response. To\nvalidate our framework along the knowledge axis, we apply steering mitigation,\nwhich relies on the existence of parametric knowledge to manipulate model\nactivations. This addresses the lack of existing methods to validate knowledge\ncategorization by showing a significant difference between the two\nhallucination types. We further analyze the distinct knowledge and\nhallucination patterns between models, showing that different hallucinations do\noccur despite shared parametric knowledge. Turning to the certainty axis, we\nidentify a particularly concerning subset of hallucinations where models\nhallucinate with certainty despite having the correct knowledge internally. We\nintroduce a new evaluation metric to measure the effectiveness of mitigation\nmethods on this subset, revealing that while some methods perform well on\naverage, they fail disproportionately on these critical cases. Our findings\nhighlight the importance of considering both knowledge and certainty in\nhallucination analysis and call for targeted mitigation approaches that\nconsider the hallucination underlying factors.",
        "url": "http://arxiv.org/abs/2510.24222v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24222v1",
        "arxiv_id": "2510.24222v1",
        "authors": [
            "Adi Simhi",
            "Jonathan Herzig",
            "Itay Itzhak",
            "Dana Arad",
            "Zorik Gekhman",
            "Roi Reichart",
            "Fazl Barez",
            "Gabriel Stanovsky",
            "Idan Szpektor",
            "Yonatan Belinkov"
        ],
        "submitted": "2025-10-28 09:34:31",
        "source": "arxiv",
        "comment": "The code is available at\n  https://github.com/technion-cs-nlp/HACK_Hallucinations_Along_Certainty_and_Knowledge_axes",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on hallucinations in Large Language Models (LLMs), which is a topic related to NLP, but it does not directly relate to information retrieval, query understanding, or ranking models, which are core areas of your research interests."
    },
    {
        "title": "Reinforcement Learning for Long-Horizon Multi-Turn Search Agents",
        "abstract": "Large Language Model (LLM) agents can leverage multiple turns and tools to\nsolve complex tasks, with prompt-based approaches achieving strong performance.\nThis work demonstrates that Reinforcement Learning (RL) can push capabilities\nsignificantly further by learning from experience. Through experiments on a\nlegal document search benchmark, we show that our RL-trained 14 Billion\nparameter model outperforms frontier class models (85% vs 78% accuracy). In\naddition, we explore turn-restricted regimes, during training and at test-time,\nthat show these agents achieve better results if allowed to operate over longer\nmulti-turn horizons.",
        "url": "http://arxiv.org/abs/2510.24126v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24126v1",
        "arxiv_id": "2510.24126v1",
        "authors": [
            "Vivek Kalyan",
            "Martin Andrews"
        ],
        "submitted": "2025-10-28 07:00:42",
        "source": "arxiv",
        "comment": "4 pages plus references and appendices. Accepted into the First\n  Workshop on Multi-Turn Interactions in Large Language Models at NeurIPS 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of Reinforcement Learning in search agents, which is somewhat related to the user's interests in Information Retrieval and Search technologies. However, the focus on long-horizon multi-turn search agents and legal document search is not directly aligned with the user's core research themes, particularly query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Can LLMs Narrate Tabular Data? An Evaluation Framework for Natural Language Representations of Text-to-SQL System Outputs",
        "abstract": "In modern industry systems like multi-turn chat agents, Text-to-SQL\ntechnology bridges natural language (NL) questions and database (DB) querying.\nThe conversion of tabular DB results into NL representations (NLRs) enables the\nchat-based interaction. Currently, NLR generation is typically handled by large\nlanguage models (LLMs), but information loss or errors in presenting tabular\nresults in NL remains largely unexplored. This paper introduces a novel\nevaluation method - Combo-Eval - for judgment of LLM-generated NLRs that\ncombines the benefits of multiple existing methods, optimizing evaluation\nfidelity and achieving a significant reduction in LLM calls by 25-61%.\nAccompanying our method is NLR-BIRD, the first dedicated dataset for NLR\nbenchmarking. Through human evaluations, we demonstrate the superior alignment\nof Combo-Eval with human judgments, applicable across scenarios with and\nwithout ground truth references.",
        "url": "http://arxiv.org/abs/2510.23854v1",
        "pdf_url": "http://arxiv.org/pdf/2510.23854v1",
        "arxiv_id": "2510.23854v1",
        "authors": [
            "Jyotika Singh",
            "Weiyi Sun",
            "Amit Agarwal",
            "Viji Krishnamurthy",
            "Yassine Benajiba",
            "Sujith Ravi",
            "Dan Roth"
        ],
        "submitted": "2025-10-27 20:52:19",
        "source": "arxiv",
        "comment": "Accepted at EMNLP 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the evaluation of Natural Language Representations of Text-to-SQL system outputs, which is related to query understanding and NLP. However, it does not directly address ranking models, user behavior modeling, or real-time relevance optimization, which are core aspects of the user's research interests."
    },
    {
        "title": "Beyond Understanding: Evaluating the Pragmatic Gap in LLMs' Cultural Processing of Figurative Language",
        "abstract": "We present a comprehensive evaluation of the ability of large language models\n(LLMs) to process culturally grounded language, specifically to understand and\npragmatically use figurative expressions that encode local knowledge and\ncultural nuance. Using figurative language as a proxy for cultural nuance and\nlocal knowledge, we design evaluation tasks for contextual understanding,\npragmatic use, and connotation interpretation in Arabic and English. We\nevaluate 22 open- and closed-source LLMs on Egyptian Arabic idioms,\nmultidialectal Arabic proverbs, and English proverbs. Our results show a\nconsistent hierarchy: the average accuracy for Arabic proverbs is 4.29% lower\nthan for English proverbs, and performance for Egyptian idioms is 10.28% lower\nthan for Arabic proverbs. For the pragmatic use task, accuracy drops by 14.07%\nrelative to understanding, though providing contextual idiomatic sentences\nimproves accuracy by 10.66%. Models also struggle with connotative meaning,\nreaching at most 85.58% agreement with human annotators on idioms with 100%\ninter-annotator agreement. These findings demonstrate that figurative language\nserves as an effective diagnostic for cultural reasoning: while LLMs can often\ninterpret figurative meaning, they face challenges in using it appropriately.\nTo support future research, we release Kinayat, the first dataset of Egyptian\nArabic idioms designed for both figurative understanding and pragmatic use\nevaluation.",
        "url": "http://arxiv.org/abs/2510.23828v1",
        "pdf_url": "http://arxiv.org/pdf/2510.23828v1",
        "arxiv_id": "2510.23828v1",
        "authors": [
            "Mena Attia",
            "Aashiq Muhamed",
            "Mai Alkhamissi",
            "Thamar Solorio",
            "Mona Diab"
        ],
        "submitted": "2025-10-27 20:13:32",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the evaluation of large language models' ability to process culturally grounded language, specifically figurative expressions. While it touches on aspects of natural language processing, it does not directly relate to information retrieval, query understanding, ranking models, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "Relative Scaling Laws for LLMs",
        "abstract": "Scaling laws describe how language models improve with additional data,\nparameters, and compute. While widely used, they are typically measured on\naggregate test sets. Aggregate evaluations yield clean trends but average over\nheterogeneous subpopulations, obscuring performance disparities. We introduce\nrelative scaling laws, which track how performance gaps between test\ndistributions evolve with scale rather than focusing solely on absolute error.\nUsing 255 decoder-only Transformers trained under matched-compute (IsoFLOP)\nbudgets from $10^{18}$--$10^{20}$ FLOPs on standard pretraining datasets, we\nfind diverse trajectories: academic domains on MMLU converge toward parity;\nregional English dialects shift depending on population size; and clusters of\nAI risk behaviours split, with capability- and influence-related risks\nincreasing during pretraining while adversarial risks do not. These results\nshow that although scaling improves overall performance, it is not a universal\nequalizer. To support further study, we release all model checkpoints from this\nwork to enable practitioners to measure relative alongside traditional scaling\nlaws, in order to better prioritize robustness challenges in light of the\nbitter lesson.",
        "url": "http://arxiv.org/abs/2510.24626v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24626v1",
        "arxiv_id": "2510.24626v1",
        "authors": [
            "William Held",
            "David Hall",
            "Percy Liang",
            "Diyi Yang"
        ],
        "submitted": "2025-10-28 16:55:22",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on scaling laws for Large Language Models (LLMs), which is a topic outside of the user's primary research interests in Information Retrieval and Search technologies. While it touches on the concept of performance improvement, it does not address query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's research."
    },
    {
        "title": "Long-Context Modeling with Dynamic Hierarchical Sparse Attention for On-Device LLMs",
        "abstract": "The quadratic cost of attention hinders the scalability of long-context LLMs,\nespecially in resource-constrained settings. Existing static sparse methods\nsuch as sliding windows or global tokens utilizes the sparsity of attention to\nreduce the cost of attention, but poorly adapts to the content-dependent\nvariations in attention due to their staticity. While previous work has\nproposed several dynamic approaches to improve flexibility, they still depend\non predefined templates or heuristic mechanisms. Such strategies reduce\ngenerality and prune tokens that remain contextually important, limiting their\naccuracy across diverse tasks. To tackle these bottlenecks of existing methods\nfor long-context modeling, we introduce Dynamic Hierarchical Sparse Attention\n(DHSA), a data-driven framework that dynamically predicts attention sparsity\nonline without retraining. Our proposed DHSA adaptively segments sequences into\nvariable-length chunks, then computes chunk representations by aggregating the\ntoken embeddings within each chunk. To avoid the bias introduced by varying\nchunk lengths, we apply length-normalized aggregation that scales the averaged\nembeddings by the square root of the chunk size. Finally, DHSA upsamples the\nchunk-level similarity scores to token level similarities to calculate\nimportance scores that determine which token-level interactions should be\npreserved. Our experiments on Gemma2 with Needle-in-a-Haystack Test and\nLongBench show that DHSA matches dense attention in accuracy, while reducing\nprefill latency by 20-60% and peak memory usage by 35%. Compared to other\nrepresentative baselines such as block sparse attention, DHSA achieves\nconsistently higher accuracy (6-18% relative gains) with comparable or lower\ncost, offering an efficient and adaptable solution for long-context on-device\nLLMs.",
        "url": "http://arxiv.org/abs/2510.24606v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24606v1",
        "arxiv_id": "2510.24606v1",
        "authors": [
            "Siheng Xiong",
            "Joe Zou",
            "Faramarz Fekri",
            "Yae Jee Cho"
        ],
        "submitted": "2025-10-28 16:34:18",
        "source": "arxiv",
        "comment": "Accepted to NeurIPS 2025 Workshop on Efficient Reasoning",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving the scalability of long-context LLMs using attention mechanisms, but it does not directly relate to information retrieval, query understanding, ranking models, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization",
        "abstract": "Autoformalization, which translates natural language mathematics into\nmachine-verifiable formal statements, is critical for using formal mathematical\nreasoning to solve math problems stated in natural language. While Large\nLanguage Models can generate syntactically correct formal statements, they\noften fail to preserve the original problem's semantic intent. This limitation\narises from the LLM approaches' treating autoformalization as a simplistic\ntranslation task which lacks mechanisms for self-reflection and iterative\nrefinement that human experts naturally employ. To address these issues, we\npropose ReForm, a Reflective Autoformalization method that tightly integrates\nsemantic consistency evaluation into the autoformalization process. This\nenables the model to iteratively generate formal statements, assess its\nsemantic fidelity, and self-correct identified errors through progressive\nrefinement. To effectively train this reflective model, we introduce\nProspective Bounded Sequence Optimization (PBSO), which employs different\nrewards at different sequence positions to ensure that the model develops both\naccurate autoformalization and correct semantic validations, preventing\nsuperficial critiques that would undermine the purpose of reflection. Extensive\nexperiments across four autoformalization benchmarks demonstrate that ReForm\nachieves an average improvement of 17.2 percentage points over the strongest\nbaselines. To further ensure evaluation reliability, we introduce\nConsistencyCheck, a benchmark of 859 expert-annotated items that not only\nvalidates LLMs as judges but also reveals that autoformalization is inherently\ndifficult: even human experts produce semantic errors in up to 38.5% of cases.",
        "url": "http://arxiv.org/abs/2510.24592v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24592v1",
        "arxiv_id": "2510.24592v1",
        "authors": [
            "Guoxin Chen",
            "Jing Wu",
            "Xinjie Chen",
            "Wayne Xin Zhao",
            "Ruihua Song",
            "Chengxi Li",
            "Kai Fan",
            "Dayiheng Liu",
            "Minpeng Liao"
        ],
        "submitted": "2025-10-28 16:22:54",
        "source": "arxiv",
        "comment": "Ongoing Work",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "LLM scoring failed."
    },
    {
        "title": "CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?",
        "abstract": "Accurate confidence calibration in Large Language Models (LLMs) is critical\nfor safe use in high-stakes domains, where clear verbalized confidence enhances\nuser trust. Traditional methods that mimic reference confidence expressions\noften fail to capture the reasoning needed for accurate confidence assessment.\nWe propose natural language critiques as a solution, ideally suited for\nconfidence calibration, as precise gold confidence labels are hard to obtain\nand often require multiple generations. This paper studies how natural language\ncritiques can enhance verbalized confidence, addressing: (1) What to critique:\nuncertainty (question-focused) or confidence (answer-specific)? Analysis shows\nconfidence suits multiple-choice tasks, while uncertainty excels in open-ended\nscenarios. (2) How to critique: self-critique or critique calibration training?\nWe propose Self-Critique, enabling LLMs to critique and optimize their\nconfidence beyond mere accuracy, and CritiCal, a novel Critique Calibration\ntraining method that leverages natural language critiques to improve confidence\ncalibration, moving beyond direct numerical optimization. Experiments show that\nCritiCal significantly outperforms Self-Critique and other competitive\nbaselines, even surpassing its teacher model, GPT-4o, in complex reasoning\ntasks. CritiCal also shows robust generalization in out-of-distribution\nsettings, advancing LLM's reliability.",
        "url": "http://arxiv.org/abs/2510.24505v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24505v1",
        "arxiv_id": "2510.24505v1",
        "authors": [
            "Qing Zong",
            "Jiayu Liu",
            "Tianshi Zheng",
            "Chunyang Li",
            "Baixuan Xu",
            "Haochen Shi",
            "Weiqi Wang",
            "Zhaowei Wang",
            "Chunkit Chan",
            "Yangqiu Song"
        ],
        "submitted": "2025-10-28 15:16:06",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the application of natural language critiques for confidence calibration in Large Language Models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on LLMs and confidence calibration is not directly aligned with the user's primary research interests in IR and search technologies. The connection to NLP is relevant, but the paper's scope is more narrow than the user's broader interests."
    },
    {
        "title": "From Time and Place to Preference: LLM-Driven Geo-Temporal Context in Recommendations",
        "abstract": "Most recommender systems treat timestamps as numeric or cyclical values,\noverlooking real-world context such as holidays, events, and seasonal patterns.\nWe propose a scalable framework that uses large language models (LLMs) to\ngenerate geo-temporal embeddings from only a timestamp and coarse location,\ncapturing holidays, seasonal trends, and local/global events. We then introduce\na geo-temporal embedding informativeness test as a lightweight diagnostic,\ndemonstrating on MovieLens, LastFM, and a production dataset that these\nembeddings provide predictive signal consistent with the outcomes of full model\nintegrations. Geo-temporal embeddings are incorporated into sequential models\nthrough (1) direct feature fusion with metadata embeddings or (2) an auxiliary\nloss that enforces semantic and geo-temporal alignment. Our findings highlight\nthe need for adaptive or hybrid recommendation strategies, and we release a\ncontext-enriched MovieLens dataset to support future research.",
        "url": "http://arxiv.org/abs/2510.24430v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24430v1",
        "arxiv_id": "2510.24430v1",
        "authors": [
            "Yejin Kim",
            "Shaghayegh Agah",
            "Mayur Nankani",
            "Neeraj Sharma",
            "Feifei Peng",
            "Maria Peifer",
            "Sardar Hamidian",
            "H Howie Huang"
        ],
        "submitted": "2025-10-28 13:57:23",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper explores recommender systems with a focus on geo-temporal context, leveraging large language models to generate embeddings. While it touches on aspects of information retrieval, its primary focus is on recommendation strategies, which is somewhat related to your interests in IR and search technologies. However, the emphasis on recommender systems and NLP aspects is not a central match to your core research themes."
    },
    {
        "title": "SynthWorlds: Controlled Parallel Worlds for Disentangling Reasoning and Knowledge in Language Models",
        "abstract": "Evaluating the reasoning ability of language models (LMs) is complicated by\ntheir extensive parametric world knowledge, where benchmark performance often\nreflects factual recall rather than genuine reasoning. Existing datasets and\napproaches (e.g., temporal filtering, paraphrasing, adversarial substitution)\ncannot cleanly separate the two. We present SynthWorlds, a framework that\ndisentangles task reasoning complexity from factual knowledge. In SynthWorlds,\nwe construct parallel corpora representing two worlds with identical\ninterconnected structure: a real-mapped world, where models may exploit\nparametric knowledge, and a synthetic-mapped world, where such knowledge is\nmeaningless. On top of these corpora, we design two mirrored tasks as case\nstudies: multi-hop question answering and page navigation, which maintain equal\nreasoning difficulty across worlds. Experiments in parametric-only (e.g.,\nclosed-book QA) and knowledge-augmented (e.g., retrieval-augmented) LM settings\nreveal a persistent knowledge advantage gap, defined as the performance boost\nmodels gain from memorized parametric world knowledge. Knowledge acquisition\nand integration mechanisms reduce but do not eliminate this gap, highlighting\nopportunities for system improvements. Fully automatic and scalable,\nSynthWorlds provides a controlled environment for evaluating LMs in ways that\nwere previously challenging, enabling precise and testable comparisons of\nreasoning and memorization.",
        "url": "http://arxiv.org/abs/2510.24427v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24427v1",
        "arxiv_id": "2510.24427v1",
        "authors": [
            "Ken Gu",
            "Advait Bhat",
            "Mike A Merrill",
            "Robert West",
            "Xin Liu",
            "Daniel McDuff",
            "Tim Althoff"
        ],
        "submitted": "2025-10-28 13:47:23",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on evaluating the reasoning ability of language models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the paper's primary focus on language models and their knowledge acquisition mechanisms makes it less relevant to the user's core research themes in IR and Search technologies."
    },
    {
        "title": "Comprehensive and Efficient Distillation for Lightweight Sentiment Analysis Models",
        "abstract": "Recent efforts leverage knowledge distillation techniques to develop\nlightweight and practical sentiment analysis models. These methods are grounded\nin human-written instructions and large-scale user texts. Despite the promising\nresults, two key challenges remain: (1) manually written instructions are\nlimited in diversity and quantity, making them insufficient to ensure\ncomprehensive coverage of distilled knowledge; (2) large-scale user texts incur\nhigh computational cost, hindering the practicality of these methods. To this\nend, we introduce COMPEFFDIST, a comprehensive and efficient distillation\nframework for sentiment analysis. Our framework consists of two key modules:\nattribute-based automatic instruction construction and difficulty-based data\nfiltering, which correspondingly tackle the aforementioned challenges. Applying\nour method across multiple model series (Llama-3, Qwen-3, and Gemma-3), we\nenable 3B student models to match the performance of 20x larger teacher models\non most tasks. In addition, our approach greatly outperforms baseline methods\nin data efficiency, attaining the same performance level with only 10% of the\ndata.",
        "url": "http://arxiv.org/abs/2510.24425v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24425v1",
        "arxiv_id": "2510.24425v1",
        "authors": [
            "Guangyu Xie",
            "Yice Zhang",
            "Jianzhu Bao",
            "Qianlong Wang",
            "Yang Sun",
            "Bingbing Wang",
            "Ruifeng Xu"
        ],
        "submitted": "2025-10-28 13:46:48",
        "source": "arxiv",
        "comment": "Accepted by EMNLP 2025. 22 pages, 9 figures. The first two authors\n  contribute equally",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Information Retrieval (IR), as it deals with sentiment analysis models. However, the focus on lightweight models and knowledge distillation is not directly aligned with your primary interests in query understanding, ranking models, and user behavior modeling. The paper's emphasis on efficiency and data efficiency is also not a central match for your research themes."
    },
    {
        "title": "Automatically Benchmarking LLM Code Agents through Agent-Driven Annotation and Evaluation",
        "abstract": "Recent advances in code agents have enabled automated software development at\nthe project level, supported by large language models (LLMs) and widely adopted\ntools. However, existing benchmarks for code agent evaluation face two major\nlimitations: high annotation cost and expertise requirements, and rigid\nevaluation metrics that rely primarily on unit tests. To address these\nchallenges, we propose an agent-driven benchmark construction pipeline that\nleverages human supervision to efficiently generate diverse and challenging\nproject-level tasks. Based on this approach, we introduce PRDBench, a novel\nbenchmark comprising 50 real-world Python projects across 20 domains, each with\nstructured Product Requirement Document (PRD) requirements, comprehensive\nevaluation criteria, and reference implementations. PRDBench features rich data\nsources, high task complexity, and flexible metrics. We further employ an\nAgent-as-a-Judge paradigm to score agent outputs, enabling the evaluation of\nvarious test types beyond unit tests. Extensive experiments on PRDBench\ndemonstrate its effectiveness in assessing the capabilities of both code agents\nand evaluation agents, providing a scalable and robust framework for annotation\nand evaluation.",
        "url": "http://arxiv.org/abs/2510.24358v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24358v1",
        "arxiv_id": "2510.24358v1",
        "authors": [
            "Lingyue Fu",
            "Bolun Zhang",
            "Hao Guan",
            "Yaoming Zhu",
            "Lin Qiu",
            "Weiwen Liu",
            "Xuezhi Cao",
            "Xunliang Cai",
            "Weinan Zhang",
            "Yong Yu"
        ],
        "submitted": "2025-10-28 12:26:45",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat relevant to the user's interests in Information Retrieval and Natural Language Processing, as it involves the use of large language models (LLMs) and evaluation metrics. However, the focus on code agents and software development is not a central match to the user's primary research themes. The paper's relevance to recommender systems is also limited."
    },
    {
        "title": "Lookahead Tree-Based Rollouts for Enhanced Trajectory-Level Exploration in Reinforcement Learning with Verifiable Rewards",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR), particularly with\nalgorithms like Group Relative Policy Optimization (GRPO), has proven highly\neffective in enhancing the reasoning capabilities of large language models.\nHowever, a critical bottleneck in current pipelines lies in the limited\ndiversity of sampled trajectories during group rollouts. Homogeneous\ntrajectories and their associated rewards would diminish the return signals for\npolicy updates, thereby hindering effective policy learning. This lack of\ndiversity stems primarily from token-level stochastic sampling, where local\nvariations are likely to collapse into near-identical reasoning paths. To\naddress this limitation, we propose Lookahead Tree-Based Rollouts (LATR), a\nnovel rollout strategy designed to explicitly promotes trajectory-level\ndiversity by enforcing branching into different candidate tokens likely to\nyield distinct continuations. Specifically, LATR iteratively operates in three\nstages: (1) branching at high-uncertainty generation steps, (2) performing\nlookahead simulation for each new branch, and (3) pruning branches that\nexhibits prolonged similarity during simulation. Compared with stochastic\nSampling, LATR accelerates policy learning by 131% on average and improves\nfinal pass@1 performance by 4.2% on both GRPO and Dynamic sAmpling Policy\nOptimization (DAPO) algorithms across different reasoning tasks. Our code and\ndata are publicly available at https://github.com/starreeze/latr.",
        "url": "http://arxiv.org/abs/2510.24302v2",
        "pdf_url": "http://arxiv.org/pdf/2510.24302v2",
        "arxiv_id": "2510.24302v2",
        "authors": [
            "Shangyu Xing",
            "Siyuan Wang",
            "Chenyuan Yang",
            "Xinyu Dai",
            "Xiang Ren"
        ],
        "submitted": "2025-10-28 11:12:02",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or user behavior modeling, which are the core areas of your research interests. While it involves reinforcement learning and large language models, the focus is on trajectory-level exploration and rewards, which is not a central match to your research themes."
    },
    {
        "title": "ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model",
        "abstract": "The limited capacity for fine-grained visual perception presents a critical\nbottleneck for Vision-Language Models (VLMs) in real-world applications.\nAddressing this is challenging due to the scarcity of high-quality data and the\nlimitations of existing methods: supervised fine-tuning (SFT) often compromises\ngeneral capabilities, while reinforcement fine-tuning (RFT) prioritizes textual\nreasoning over visual perception. To bridge this gap, we propose a novel\ntwo-stage task that structures visual perception learning as a coarse-to-fine\nprogressive process. Based on this task formulation, we develop ViPER, a\nself-bootstrapping framework specifically designed to enable iterative\nevolution through self-critiquing and self-prediction. By synergistically\nintegrating image-level and instance-level reconstruction with a two-stage\nreinforcement learning strategy, ViPER establishes a closed-loop training\nparadigm, where internally synthesized data directly fuel the enhancement of\nperceptual ability. Applied to the Qwen2.5-VL family, ViPER produces the\nQwen-Viper series. With an average gain of 1.7% on seven comprehensive\nbenchmarks spanning various tasks and up to 6.0% on fine-grained perception,\nQwen-Viper consistently demonstrates superior performance across different\nvision-language scenarios while maintaining generalizability. Beyond enabling\nself-improvement in perceptual capabilities, ViPER provides concrete evidence\nfor the reciprocal relationship between generation and understanding, a\nbreakthrough to developing more autonomous and capable VLMs.",
        "url": "http://arxiv.org/abs/2510.24285v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24285v1",
        "arxiv_id": "2510.24285v1",
        "authors": [
            "Juntian Zhang",
            "Song Jin",
            "Chuanqi Cheng",
            "Yuhan Liu",
            "Yankai Lin",
            "Xun Zhang",
            "Yufei Zhang",
            "Fei Jiang",
            "Guojun Yin",
            "Wei Lin",
            "Rui Yan"
        ],
        "submitted": "2025-10-28 10:42:57",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Vision-Language Models and their ability to perform fine-grained visual perception, which is not directly related to the user's primary research interests in Information Retrieval and Search technologies. While it does involve deep semantic understanding, the context is different and the paper's contribution is more aligned with computer vision and NLP rather than IR and Search technologies."
    },
    {
        "title": "Abjad AI at NADI 2025: CATT-Whisper: Multimodal Diacritic Restoration Using Text and Speech Representations",
        "abstract": "In this work, we tackle the Diacritic Restoration (DR) task for Arabic\ndialectal sentences using a multimodal approach that combines both textual and\nspeech information. We propose a model that represents the text modality using\nan encoder extracted from our own pre-trained model named CATT. The speech\ncomponent is handled by the encoder module of the OpenAI Whisper base model.\nOur solution is designed following two integration strategies. The former\nconsists of fusing the speech tokens with the input at an early stage, where\nthe 1500 frames of the audio segment are averaged over 10 consecutive frames,\nresulting in 150 speech tokens. To ensure embedding compatibility, these\naveraged tokens are processed through a linear projection layer prior to\nmerging them with the text tokens. Contextual encoding is guaranteed by the\nCATT encoder module. The latter strategy relies on cross-attention, where text\nand speech embeddings are fused. The cross-attention output is then fed to the\nCATT classification head for token-level diacritic prediction. To further\nimprove model robustness, we randomly deactivate the speech input during\ntraining, allowing the model to perform well with or without speech. Our\nexperiments show that the proposed approach achieves a word error rate (WER) of\n0.25 and a character error rate (CER) of 0.9 on the development set. On the\ntest set, our model achieved WER and CER scores of 0.55 and 0.13, respectively.",
        "url": "http://arxiv.org/abs/2510.24247v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24247v1",
        "arxiv_id": "2510.24247v1",
        "authors": [
            "Ahmad Ghannam",
            "Naif Alharthi",
            "Faris Alasmary",
            "Kholood Al Tabash",
            "Shouq Sadah",
            "Lahouari Ghouti"
        ],
        "submitted": "2025-10-28 09:58:18",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Diacritic Restoration for Arabic dialectal sentences using multimodal approaches, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves text and speech representations, the context and application are quite different from the user's interests."
    },
    {
        "title": "Beyond Neural Incompatibility: Easing Cross-Scale Knowledge Transfer in Large Language Models through Latent Semantic Alignment",
        "abstract": "Large Language Models (LLMs) encode vast amounts of knowledge in their\nmassive parameters, which is accessible to locate, trace, and analyze. Despite\nadvances in neural interpretability, it is still not clear how to transfer\nknowledge in a fine-grained manner, namely parametric knowledge transfer (PKT).\nA key problem is enabling effective and efficient knowledge transfer across\nLLMs of different scales, which is essential for achieving greater flexibility\nand broader applicability in transferring knowledge between LLMs. Due to neural\nincompatibility, referring to the architectural and parametric differences\nbetween LLMs of varying scales, existing methods that directly reuse layer\nparameters are severely limited. In this paper, we identify the semantic\nalignment in latent space as the fundamental prerequisite for LLM cross-scale\nknowledge transfer. Instead of directly using the layer parameters, our\napproach takes activations as the medium of layer-wise knowledge transfer.\nLeveraging the semantics in latent space, our approach is simple and\noutperforms prior work, better aligning model behaviors across varying scales.\nEvaluations on four benchmarks demonstrate the efficacy of our method. Further\nanalysis reveals the key factors easing cross-scale knowledge transfer and\nprovides insights into the nature of latent semantic alignment.",
        "url": "http://arxiv.org/abs/2510.24208v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24208v1",
        "arxiv_id": "2510.24208v1",
        "authors": [
            "Jian Gu",
            "Aldeida Aleti",
            "Chunyang Chen",
            "Hongyu Zhang"
        ],
        "submitted": "2025-10-28 09:25:40",
        "source": "arxiv",
        "comment": "an early-stage version",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on cross-scale knowledge transfer in Large Language Models, which is somewhat related to information retrieval and search technologies. However, the primary focus on neural incompatibility and latent semantic alignment is more aligned with NLP and deep learning, rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Exploring the Influence of Relevant Knowledge for Natural Language Generation Interpretability",
        "abstract": "This paper explores the influence of external knowledge integration in\nNatural Language Generation (NLG), focusing on a commonsense generation task.\nWe extend the CommonGen dataset by creating KITGI, a benchmark that pairs input\nconcept sets with retrieved semantic relations from ConceptNet and includes\nmanually annotated outputs. Using the T5-Large model, we compare sentence\ngeneration under two conditions: with full external knowledge and with filtered\nknowledge where highly relevant relations were deliberately removed. Our\ninterpretability benchmark follows a three-stage method: (1) identifying and\nremoving key knowledge, (2) regenerating sentences, and (3) manually assessing\noutputs for commonsense plausibility and concept coverage. Results show that\nsentences generated with full knowledge achieved 91\\% correctness across both\ncriteria, while filtering reduced performance drastically to 6\\%. These\nfindings demonstrate that relevant external knowledge is critical for\nmaintaining both coherence and concept coverage in NLG. This work highlights\nthe importance of designing interpretable, knowledge-enhanced NLG systems and\ncalls for evaluation frameworks that capture the underlying reasoning beyond\nsurface-level metrics.",
        "url": "http://arxiv.org/abs/2510.24179v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24179v1",
        "arxiv_id": "2510.24179v1",
        "authors": [
            "Iván Martínez-Murillo",
            "Paloma Moreda",
            "Elena Lloret"
        ],
        "submitted": "2025-10-28 08:34:01",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the influence of external knowledge in Natural Language Generation (NLG), which is somewhat related to your interests in Natural Language Processing (NLP). However, it does not directly address your core research themes in Information Retrieval (IR), query understanding, or ranking models, limiting its relevance."
    },
    {
        "title": "Success and Cost Elicit Convention Formation for Efficient Communication",
        "abstract": "Humans leverage shared conversational context to become increasingly\nsuccessful and efficient at communicating over time. One manifestation of this\nis the formation of ad hoc linguistic conventions, which allow people to\ncoordinate on short, less costly utterances that are understood using shared\nconversational context. We present a method to train large multimodal models to\nform conventions, enabling efficient communication. Our approach uses simulated\nreference games between models, and requires no additional human-produced data.\nIn repeated reference games involving photographs and tangram images, our\nmethod enables models to communicate efficiently with people: reducing the\nmessage length by up to 41% while increasing success by 15% over the course of\nthe interaction. Human listeners respond faster when interacting with our model\nthat forms conventions. We also show that training based on success or cost\nalone is insufficient - both are necessary to elicit convention formation.",
        "url": "http://arxiv.org/abs/2510.24023v1",
        "pdf_url": "http://arxiv.org/pdf/2510.24023v1",
        "arxiv_id": "2510.24023v1",
        "authors": [
            "Saujas Vaduguru",
            "Yilun Hua",
            "Yoav Artzi",
            "Daniel Fried"
        ],
        "submitted": "2025-10-28 03:06:07",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval or Search technologies. It focuses on multimodal models for efficient communication, which is more aligned with Natural Language Processing and Human-Computer Interaction. While it involves training models, the context and goals are distinct from query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Leveraging LLMs for Early Alzheimer's Prediction",
        "abstract": "We present a connectome-informed LLM framework that encodes dynamic fMRI\nconnectivity as temporal sequences, applies robust normalization, and maps\nthese data into a representation suitable for a frozen pre-trained LLM for\nclinical prediction. Applied to early Alzheimer's detection, our method\nachieves sensitive prediction with error rates well below clinically recognized\nmargins, with implications for timely Alzheimer's intervention.",
        "url": "http://arxiv.org/abs/2510.23946v1",
        "pdf_url": "http://arxiv.org/pdf/2510.23946v1",
        "arxiv_id": "2510.23946v1",
        "authors": [
            "Tananun Songdechakraiwut"
        ],
        "submitted": "2025-10-27 23:59:03",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on leveraging Large Language Models (LLMs) for early Alzheimer's prediction, which is outside the scope of Information Retrieval, Search technologies, and related topics."
    },
    {
        "title": "Auto prompting without training labels: An LLM cascade for product quality assessment in e-commerce catalogs",
        "abstract": "We introduce a novel, training free cascade for auto-prompting Large Language\nModels (LLMs) to assess product quality in e-commerce. Our system requires no\ntraining labels or model fine-tuning, instead automatically generating and\nrefining prompts for evaluating attribute quality across tens of thousands of\nproduct category-attribute pairs. Starting from a seed of human-crafted\nprompts, the cascade progressively optimizes instructions to meet\ncatalog-specific requirements. This approach bridges the gap between general\nlanguage understanding and domain-specific knowledge at scale in complex\nindustrial catalogs. Our extensive empirical evaluations shows the auto-prompt\ncascade improves precision and recall by $8-10\\%$ over traditional\nchain-of-thought prompting. Notably, it achieves these gains while reducing\ndomain expert effort from 5.1 hours to 3 minutes per attribute - a $99\\%$\nreduction. Additionally, the cascade generalizes effectively across five\nlanguages and multiple quality assessment tasks, consistently maintaining\nperformance gains.",
        "url": "http://arxiv.org/abs/2510.23941v1",
        "pdf_url": "http://arxiv.org/pdf/2510.23941v1",
        "arxiv_id": "2510.23941v1",
        "authors": [
            "Soham Satyadharma",
            "Fatemeh Sheikholeslami",
            "Swati Kaul",
            "Aziz Umit Batur",
            "Suleiman A. Khan"
        ],
        "submitted": "2025-10-27 23:49:31",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of e-commerce and query understanding. However, its focus on product quality assessment and auto-prompting Large Language Models is not a central match to your primary research themes. The paper's emphasis on domain-specific knowledge and industrial catalogs is somewhat relevant to your background in e-commerce, but it does not directly address your interests in ranking models, user behavior modeling, or deep semantic understanding."
    },
    {
        "title": "AfriMTEB and AfriE5: Benchmarking and Adapting Text Embedding Models for African Languages",
        "abstract": "Text embeddings are an essential building component of several NLP tasks such\nas retrieval-augmented generation which is crucial for preventing\nhallucinations in LLMs. Despite the recent release of massively multilingual\nMTEB (MMTEB), African languages remain underrepresented, with existing tasks\noften repurposed from translation benchmarks such as FLORES clustering or\nSIB-200. In this paper, we introduce AfriMTEB -- a regional expansion of MMTEB\ncovering 59 languages, 14 tasks, and 38 datasets, including six newly added\ndatasets. Unlike many MMTEB datasets that include fewer than five languages,\nthe new additions span 14 to 56 African languages and introduce entirely new\ntasks, such as hate speech detection, intent detection, and emotion\nclassification, which were not previously covered. Complementing this, we\npresent AfriE5, an adaptation of the instruction-tuned mE5 model to African\nlanguages through cross-lingual contrastive distillation. Our evaluation shows\nthat AfriE5 achieves state-of-the-art performance, outperforming strong\nbaselines such as Gemini-Embeddings and mE5.",
        "url": "http://arxiv.org/abs/2510.23896v1",
        "pdf_url": "http://arxiv.org/pdf/2510.23896v1",
        "arxiv_id": "2510.23896v1",
        "authors": [
            "Kosei Uemura",
            "Miaoran Zhang",
            "David Ifeoluwa Adelani"
        ],
        "submitted": "2025-10-27 22:06:43",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on text embedding models for African languages, which is somewhat related to the user's interests in NLP and IR. However, the specific context of African languages and the tasks mentioned (e.g., hate speech detection, intent detection) are not directly aligned with the user's core research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "A Neural Model for Contextual Biasing Score Learning and Filtering",
        "abstract": "Contextual biasing improves automatic speech recognition (ASR) by integrating\nexternal knowledge, such as user-specific phrases or entities, during decoding.\nIn this work, we use an attention-based biasing decoder to produce scores for\ncandidate phrases based on acoustic information extracted by an ASR encoder,\nwhich can be used to filter out unlikely phrases and to calculate bonus for\nshallow-fusion biasing. We introduce a per-token discriminative objective that\nencourages higher scores for ground-truth phrases while suppressing\ndistractors. Experiments on the Librispeech biasing benchmark show that our\nmethod effectively filters out majority of the candidate phrases, and\nsignificantly improves recognition accuracy under different biasing conditions\nwhen the scores are used in shallow fusion biasing. Our approach is modular and\ncan be used with any ASR system, and the filtering mechanism can potentially\nboost performance of other biasing methods.",
        "url": "http://arxiv.org/abs/2510.23849v1",
        "pdf_url": "http://arxiv.org/pdf/2510.23849v1",
        "arxiv_id": "2510.23849v1",
        "authors": [
            "Wanting Huang",
            "Weiran Wang"
        ],
        "submitted": "2025-10-27 20:41:52",
        "source": "arxiv",
        "comment": "Accepted to IEEE ASRU 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving automatic speech recognition using contextual biasing, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. The paper's use of attention-based biasing decoder and discriminative objective is also not directly related to the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "How Pragmatics Shape Articulation: A Computational Case Study in STEM ASL Discourse",
        "abstract": "Most state-of-the-art sign language models are trained on interpreter or\nisolated vocabulary data, which overlooks the variability that characterizes\nnatural dialogue. However, human communication dynamically adapts to contexts\nand interlocutors through spatiotemporal changes and articulation style. This\nspecifically manifests itself in educational settings, where novel vocabularies\nare used by teachers, and students. To address this gap, we collect a motion\ncapture dataset of American Sign Language (ASL) STEM (Science, Technology,\nEngineering, and Mathematics) dialogue that enables quantitative comparison\nbetween dyadic interactive signing, solo signed lecture, and interpreted\narticles. Using continuous kinematic features, we disentangle dialogue-specific\nentrainment from individual effort reduction and show spatiotemporal changes\nacross repeated mentions of STEM terms. On average, dialogue signs are\n24.6%-44.6% shorter in duration than the isolated signs, and show significant\nreductions absent in monologue contexts. Finally, we evaluate sign embedding\nmodels on their ability to recognize STEM signs and approximate how entrained\nthe participants become over time. Our study bridges linguistic analysis and\ncomputational modeling to understand how pragmatics shape sign articulation and\nits representation in sign language technologies.",
        "url": "http://arxiv.org/abs/2510.23842v1",
        "pdf_url": "http://arxiv.org/pdf/2510.23842v1",
        "arxiv_id": "2510.23842v1",
        "authors": [
            "Saki Imai",
            "Lee Kezar",
            "Laurel Aichler",
            "Mert Inan",
            "Erin Walker",
            "Alicia Wooten",
            "Lorna Quandt",
            "Malihe Alikhani"
        ],
        "submitted": "2025-10-27 20:29:46",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on sign language and its computational modeling, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves computational modeling, it is specific to sign language and does not align with your background in e-commerce or interests in deep semantic understanding and real-time relevance optimization."
    }
]