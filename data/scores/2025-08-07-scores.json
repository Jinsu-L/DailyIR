[
    {
        "title": "Query Attribute Modeling: Improving search relevance with Semantic Search and Meta Data Filtering",
        "abstract": "This study introduces Query Attribute Modeling (QAM), a hybrid framework that\nenhances search precision and relevance by decomposing open text queries into\nstructured metadata tags and semantic elements. QAM addresses traditional\nsearch limitations by automatically extracting metadata filters from free-form\ntext queries, reducing noise and enabling focused retrieval of relevant items.\n  Experimental evaluation using the Amazon Toys Reviews dataset (10,000 unique\nitems with 40,000+ reviews and detailed product attributes) demonstrated QAM's\nsuperior performance, achieving a mean average precision at 5 (mAP@5) of\n52.99\\%. This represents significant improvement over conventional methods,\nincluding BM25 keyword search, encoder-based semantic similarity search,\ncross-encoder re-ranking, and hybrid search combining BM25 and semantic results\nvia Reciprocal Rank Fusion (RRF). The results establish QAM as a robust\nsolution for Enterprise Search applications, particularly in e-commerce\nsystems.",
        "url": "http://arxiv.org/abs/2508.04683v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04683v1",
        "arxiv_id": "2508.04683v1",
        "authors": [
            "Karthik Menon",
            "Batool Arhamna Haider",
            "Muhammad Arham",
            "Kanwal Mehreen",
            "Ram Mohan Rao Kadiyala",
            "Hamza Farooq"
        ],
        "submitted": "2025-08-06 17:47:00",
        "source": "arxiv",
        "comment": null,
        "score": 23,
        "keyword_reasons": [
            "Found 'semantic search' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "The paper's focus on query attribute modeling, semantic search, and metadata filtering aligns with your interests in information retrieval, query understanding, and ranking models. The use of a hybrid framework and experimental evaluation on a large e-commerce dataset also resonates with your background in e-commerce and experience with search technologies."
    },
    {
        "title": "ConvMix: A Mixed-Criteria Data Augmentation Framework for Conversational Dense Retrieval",
        "abstract": "Conversational search aims to satisfy users' complex information needs via\nmultiple-turn interactions. The key challenge lies in revealing real users'\nsearch intent from the context-dependent queries. Previous studies achieve\nconversational search by fine-tuning a conversational dense retriever with\nrelevance judgments between pairs of context-dependent queries and documents.\nHowever, this training paradigm encounters data scarcity issues. To this end,\nwe propose ConvMix, a mixed-criteria framework to augment conversational dense\nretrieval, which covers more aspects than existing data augmentation\nframeworks. We design a two-sided relevance judgment augmentation schema in a\nscalable manner via the aid of large language models. Besides, we integrate the\nframework with quality control mechanisms to obtain semantically diverse\nsamples and near-distribution supervisions to combine various annotated data.\nExperimental results on five widely used benchmarks show that the\nconversational dense retriever trained by our ConvMix framework outperforms\nprevious baseline methods, which demonstrates our superior effectiveness.",
        "url": "http://arxiv.org/abs/2508.04001v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04001v1",
        "arxiv_id": "2508.04001v1",
        "authors": [
            "Fengran Mo",
            "Jinghan Zhang",
            "Yuchen Hui",
            "Jia Ao Sun",
            "Zhichao Xu",
            "Zhan Su",
            "Jian-Yun Nie"
        ],
        "submitted": "2025-08-06 01:28:49",
        "source": "arxiv",
        "comment": null,
        "score": 15,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'dense retrieval' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on conversational dense retrieval, which is related to information retrieval and search technologies. However, the specific context of conversational search and the proposed framework, ConvMix, do not directly align with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is somewhat limited to the user's broader interests in NLP and data mining."
    },
    {
        "title": "PAIRS: Parametric-Verified Adaptive Information Retrieval and Selection for Efficient RAG",
        "abstract": "Retrieval-Augmented Generation (RAG) has become a cornerstone technique for\nenhancing large language models (LLMs) with external knowledge. However,\ncurrent RAG systems face two critical limitations: (1) they inefficiently\nretrieve information for every query, including simple questions that could be\nresolved using the LLM's parametric knowledge alone, and (2) they risk\nretrieving irrelevant documents when queries contain sparse information\nsignals. To address these gaps, we introduce Parametric-verified Adaptive\nInformation Retrieval and Selection (PAIRS), a training-free framework that\nintegrates parametric and retrieved knowledge to adaptively determine whether\nto retrieve and how to select external information. Specifically, PAIRS employs\na dual-path generation mechanism: First, the LLM produces both a direct answer\nand a context-augmented answer using self-generated pseudo-context. When these\noutputs converge, PAIRS bypasses external retrieval entirely, dramatically\nimproving the RAG system's efficiency. For divergent cases, PAIRS activates a\ndual-path retrieval (DPR) process guided by both the original query and\nself-generated contextual signals, followed by an Adaptive Information\nSelection (AIS) module that filters documents through weighted similarity to\nboth sources. This simple yet effective approach can not only enhance\nefficiency by eliminating unnecessary retrievals but also improve accuracy\nthrough contextually guided retrieval and adaptive information selection.\nExperimental results on six question-answering (QA) benchmarks show that PAIRS\nreduces retrieval costs by around 25% (triggering for only 75% of queries)\nwhile still improving accuracy-achieving +1.1% EM and +1.0% F1 over prior\nbaselines on average.",
        "url": "http://arxiv.org/abs/2508.04057v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04057v1",
        "arxiv_id": "2508.04057v1",
        "authors": [
            "Wang Chen",
            "Guanqiang Qi",
            "Weikang Li",
            "Yang Li",
            "Deguo Xia",
            "Jizhou Huang"
        ],
        "submitted": "2025-08-06 03:33:01",
        "source": "arxiv",
        "comment": null,
        "score": 13,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper presents a novel approach to Retrieval-Augmented Generation (RAG) that addresses limitations in current RAG systems. While it doesn't directly focus on query understanding, ranking models, or user behavior modeling, it does explore efficient information retrieval and selection, which is relevant to your interests in Information Retrieval. The paper's emphasis on adapting to query complexity and using contextual signals is also somewhat related to your work on deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Enhancing Serendipity Recommendation System by Constructing Dynamic User Knowledge Graphs with Large Language Models",
        "abstract": "The feedback loop in industrial recommendation systems reinforces homogeneous\ncontent, creates filter bubble effects, and diminishes user satisfaction.\nRecently, large language models(LLMs) have demonstrated potential in\nserendipity recommendation, thanks to their extensive world knowledge and\nsuperior reasoning capabilities. However, these models still face challenges in\nensuring the rationality of the reasoning process, the usefulness of the\nreasoning results, and meeting the latency requirements of industrial\nrecommendation systems (RSs). To address these challenges, we propose a method\nthat leverages llm to dynamically construct user knowledge graphs, thereby\nenhancing the serendipity of recommendation systems. This method comprises a\ntwo stage framework:(1) two-hop interest reasoning, where user static profiles\nand historical behaviors are utilized to dynamically construct user knowledge\ngraphs via llm. Two-hop reasoning, which can enhance the quality and accuracy\nof LLM reasoning results, is then performed on the constructed graphs to\nidentify users' potential interests; and(2) Near-line adaptation, a\ncost-effective approach to deploying the aforementioned models in industrial\nrecommendation systems. We propose a u2i (user-to-item) retrieval model that\nalso incorporates i2i (item-to-item) retrieval capabilities, the retrieved\nitems not only exhibit strong relevance to users' newly emerged interests but\nalso retain the high conversion rate of traditional u2i retrieval. Our online\nexperiments on the Dewu app, which has tens of millions of users, indicate that\nthe method increased the exposure novelty rate by 4.62%, the click novelty rate\nby 4.85%, the average view duration per person by 0.15%, unique visitor click\nthrough rate by 0.07%, and unique visitor interaction penetration by 0.30%,\nenhancing user experience.",
        "url": "http://arxiv.org/abs/2508.04032v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04032v1",
        "arxiv_id": "2508.04032v1",
        "authors": [
            "Qian Yong",
            "Yanhui Li",
            "Jialiang Shi",
            "Yaguang Dou",
            "Tian Qi"
        ],
        "submitted": "2025-08-06 02:52:09",
        "source": "arxiv",
        "comment": "8 pages",
        "score": 12,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'click' (score: +2)",
            "Found 'conversion rate' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores serendipity recommendation systems, leveraging large language models to construct dynamic user knowledge graphs. While it touches on some aspects of query understanding and user behavior modeling, the focus is more on recommender systems and industrial recommendation systems, which is somewhat related to the user's interests in information retrieval and search technologies."
    },
    {
        "title": "TURA: Tool-Augmented Unified Retrieval Agent for AI Search",
        "abstract": "The advent of Large Language Models (LLMs) is transforming search engines\ninto conversational AI search products, primarily using Retrieval-Augmented\nGeneration (RAG) on web corpora. However, this paradigm has significant\nindustrial limitations. Traditional RAG approaches struggle with real-time\nneeds and structured queries that require accessing dynamically generated\ncontent like ticket availability or inventory. Limited to indexing static\npages, search engines cannot perform the interactive queries needed for such\ntime-sensitive data. Academic research has focused on optimizing RAG for static\ncontent, overlooking complex intents and the need for dynamic sources like\ndatabases and real-time APIs. To bridge this gap, we introduce TURA\n(Tool-Augmented Unified Retrieval Agent for AI Search), a novel three-stage\nframework that combines RAG with agentic tool-use to access both static content\nand dynamic, real-time information. TURA has three key components: an\nIntent-Aware Retrieval module to decompose queries and retrieve information\nsources encapsulated as Model Context Protocol (MCP) Servers, a DAG-based Task\nPlanner that models task dependencies as a Directed Acyclic Graph (DAG) for\noptimal parallel execution, and a lightweight Distilled Agent Executor for\nefficient tool calling. TURA is the first architecture to systematically bridge\nthe gap between static RAG and dynamic information sources for a world-class AI\nsearch product. Serving tens of millions of users, it leverages an agentic\nframework to deliver robust, real-time answers while meeting the low-latency\ndemands of a large-scale industrial system.",
        "url": "http://arxiv.org/abs/2508.04604v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04604v1",
        "arxiv_id": "2508.04604v1",
        "authors": [
            "Zhejun Zhao",
            "Yuehu Dong",
            "Alley Liu",
            "Lixue Zheng",
            "Pingsheng Liu",
            "Dongdong Shen",
            "Long Xia",
            "Jiashu Zhao",
            "Dawei Yin"
        ],
        "submitted": "2025-08-06 16:24:17",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper discusses a novel framework for AI search, combining Retrieval-Augmented Generation with agentic tool-use to access both static and dynamic information sources. While it doesn't directly focus on query understanding, ranking models, or user behavior modeling, it explores the intersection of information retrieval and natural language processing, which aligns with your interests. However, the paper's primary focus is on the architecture and implementation of the TURA framework, rather than the specific topics you mentioned."
    },
    {
        "title": "Bridging Search and Recommendation through Latent Cross Reasoning",
        "abstract": "Search and recommendation (S&R) are fundamental components of modern online\nplatforms, yet effectively leveraging search behaviors to improve\nrecommendation remains a challenging problem. User search histories often\ncontain noisy or irrelevant signals that can even degrade recommendation\nperformance, while existing approaches typically encode S&R histories either\njointly or separately without explicitly identifying which search behaviors are\ntruly useful. Inspired by the human decision-making process, where one first\nidentifies recommendation intent and then reasons about relevant evidence, we\ndesign a latent cross reasoning framework that first encodes user S&R histories\nto capture global interests and then iteratively reasons over search behaviors\nto extract signals beneficial for recommendation. Contrastive learning is\nemployed to align latent reasoning states with target items, and reinforcement\nlearning is further introduced to directly optimize ranking performance.\nExtensive experiments on public benchmarks demonstrate consistent improvements\nover strong baselines, validating the importance of reasoning in enhancing\nsearch-aware recommendation.",
        "url": "http://arxiv.org/abs/2508.04152v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04152v1",
        "arxiv_id": "2508.04152v1",
        "authors": [
            "Teng Shi",
            "Weicong Qin",
            "Weijie Yu",
            "Xiao Zhang",
            "Ming He",
            "Jianping Fan",
            "Jun Xu"
        ],
        "submitted": "2025-08-06 07:28:11",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "The paper explores the intersection of search and recommendation, which aligns with your interest in Information Retrieval and Search technologies. The use of latent cross reasoning and contrastive learning to improve recommendation performance is also relevant to your focus on query understanding and ranking models. However, the paper's primary focus on recommendation rather than information retrieval might reduce its relevance to your core research themes."
    },
    {
        "title": "RAVID: Retrieval-Augmented Visual Detection: A Knowledge-Driven Approach for AI-Generated Image Identification",
        "abstract": "In this paper, we introduce RAVID, the first framework for AI-generated image\ndetection that leverages visual retrieval-augmented generation (RAG). While RAG\nmethods have shown promise in mitigating factual inaccuracies in foundation\nmodels, they have primarily focused on text, leaving visual knowledge\nunderexplored. Meanwhile, existing detection methods, which struggle with\ngeneralization and robustness, often rely on low-level artifacts and\nmodel-specific features, limiting their adaptability. To address this, RAVID\ndynamically retrieves relevant images to enhance detection. Our approach\nutilizes a fine-tuned CLIP image encoder, RAVID CLIP, enhanced with\ncategory-related prompts to improve representation learning. We further\nintegrate a vision-language model (VLM) to fuse retrieved images with the\nquery, enriching the input and improving accuracy. Given a query image, RAVID\ngenerates an embedding using RAVID CLIP, retrieves the most relevant images\nfrom a database, and combines these with the query image to form an enriched\ninput for a VLM (e.g., Qwen-VL or Openflamingo). Experiments on the\nUniversalFakeDetect benchmark, which covers 19 generative models, show that\nRAVID achieves state-of-the-art performance with an average accuracy of 93.85%.\nRAVID also outperforms traditional methods in terms of robustness, maintaining\nhigh accuracy even under image degradations such as Gaussian blur and JPEG\ncompression. Specifically, RAVID achieves an average accuracy of 80.27% under\ndegradation conditions, compared to 63.44% for the state-of-the-art model\nC2P-CLIP, demonstrating consistent improvements in both Gaussian blur and JPEG\ncompression scenarios. The code will be publicly available upon acceptance.",
        "url": "http://arxiv.org/abs/2508.03967v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03967v1",
        "arxiv_id": "2508.03967v1",
        "authors": [
            "Mamadou Keita",
            "Wassim Hamidouche",
            "Hessen Bougueffa Eutamene",
            "Abdelmalik Taleb-Ahmed",
            "Abdenour Hadid"
        ],
        "submitted": "2025-08-05 23:10:56",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on visual detection and image identification, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's approach, while innovative, does not address query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user."
    },
    {
        "title": "Accelerating Scientific Discovery with Multi-Document Summarization of Impact-Ranked Papers",
        "abstract": "The growing volume of scientific literature makes it challenging for\nscientists to move from a list of papers to a synthesized understanding of a\ntopic. Because of the constant influx of new papers on a daily basis, even if a\nscientist identifies a promising set of papers, they still face the tedious\ntask of individually reading through dozens of titles and abstracts to make\nsense of occasionally conflicting findings. To address this critical bottleneck\nin the research workflow, we introduce a summarization feature to BIP! Finder,\na scholarly search engine that ranks literature based on distinct impact\naspects like popularity and influence. Our approach enables users to generate\ntwo types of summaries from top-ranked search results: a concise summary for an\ninstantaneous at-a-glance comprehension and a more comprehensive literature\nreview-style summary for greater, better-organized comprehension. This ability\ndynamically leverages BIP! Finder's already existing impact-based ranking and\nfiltering features to generate context-sensitive, synthesized narratives that\ncan significantly accelerate literature discovery and comprehension.",
        "url": "http://arxiv.org/abs/2508.03962v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03962v1",
        "arxiv_id": "2508.03962v1",
        "authors": [
            "Paris Koloveas",
            "Serafeim Chatzopoulos",
            "Dionysis Diamantis",
            "Christos Tryfonopoulos",
            "Thanasis Vergoulis"
        ],
        "submitted": "2025-08-05 22:56:09",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on summarization of scientific papers, which is related to information retrieval and search technologies. However, the specific application to scientific literature and the emphasis on summarization rather than query understanding or ranking models makes it less directly relevant to the user's core research interests."
    },
    {
        "title": "P-Aligner: Enabling Pre-Alignment of Language Models via Principled Instruction Synthesis",
        "abstract": "Large Language Models (LLMs) are expected to produce safe, helpful, and\nhonest content during interaction with human users, but they frequently fail to\nalign with such values when given flawed instructions, e.g., missing context,\nambiguous directives, or inappropriate tone, leaving substantial room for\nimprovement along multiple dimensions. A cost-effective yet high-impact way is\nto pre-align instructions before the model begins decoding. Existing approaches\neither rely on prohibitive test-time search costs or end-to-end model rewrite,\nwhich is powered by a customized training corpus with unclear objectives. In\nthis work, we demonstrate that the goal of efficient and effective preference\nalignment can be achieved by P-Aligner, a lightweight module generating\ninstructions that preserve the original intents while being expressed in a more\nhuman-preferred form. P-Aligner is trained on UltraPrompt, a new dataset\nsynthesized via a proposed principle-guided pipeline using Monte-Carlo Tree\nSearch, which systematically explores the space of candidate instructions that\nare closely tied to human preference. Experiments across different methods show\nthat P-Aligner generally outperforms strong baselines across various models and\nbenchmarks, including average win-rate gains of 28.35% and 8.69% on GPT-4-turbo\nand Gemma-2-SimPO, respectively. Further analyses validate its effectiveness\nand efficiency through multiple perspectives, including data quality, search\nstrategies, iterative deployment, and time overhead.",
        "url": "http://arxiv.org/abs/2508.04626v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04626v1",
        "arxiv_id": "2508.04626v1",
        "authors": [
            "Feifan Song",
            "Bofei Gao",
            "Yifan Song",
            "Yi Liu",
            "Weimin Xiong",
            "Yuyang Song",
            "Tianyu Liu",
            "Guoyin Wang",
            "Houfeng Wang"
        ],
        "submitted": "2025-08-06 16:51:38",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'ltr' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on pre-aligning language model instructions to improve their safety, helpfulness, and honesty. While it touches on the topic of instruction synthesis, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval and Search technologies. The paper's focus on language models and instruction synthesis is more relevant to Natural Language Processing and related topics."
    },
    {
        "title": "A Reproducible, Scalable Pipeline for Synthesizing Autoregressive Model Literature",
        "abstract": "The accelerating pace of research on autoregressive generative models has\nproduced thousands of papers, making manual literature surveys and reproduction\nstudies increasingly impractical. We present a fully open-source, reproducible\npipeline that automatically retrieves candidate documents from public\nrepositories, filters them for relevance, extracts metadata, hyper-parameters\nand reported results, clusters topics, produces retrieval-augmented summaries\nand generates containerised scripts for re-running selected experiments.\nQuantitative evaluation on 50 manually-annotated papers shows F1 scores above\n0.85 for relevance classification, hyper-parameter extraction and citation\nidentification. Experiments on corpora of up to 1000 papers demonstrate\nnear-linear scalability with eight CPU workers. Three case studies -- AWD-LSTM\non WikiText-2, Transformer-XL on WikiText-103 and an autoregressive music model\non the Lakh MIDI dataset -- confirm that the extracted settings support\nfaithful reproduction, achieving test perplexities within 1--3% of the original\nreports.",
        "url": "http://arxiv.org/abs/2508.04612v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04612v1",
        "arxiv_id": "2508.04612v1",
        "authors": [
            "Faruk Alpay",
            "Bugra Kilictas",
            "Hamdi Alakkad"
        ],
        "submitted": "2025-08-06 16:33:20",
        "source": "arxiv",
        "comment": "9 pages",
        "score": 6,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it touches on topics like metadata extraction and citation identification, the focus is on autoregressive generative models and reproducibility, which is not a primary area of interest for you."
    },
    {
        "title": "ViLLA-MMBench: A Unified Benchmark Suite for LLM-Augmented Multimodal Movie Recommendation",
        "abstract": "Recommending long-form video content demands joint modeling of visual, audio,\nand textual modalities, yet most benchmarks address only raw features or narrow\nfusion. We present ViLLA-MMBench, a reproducible, extensible benchmark for\nLLM-augmented multimodal movie recommendation. Built on MovieLens and MMTF-14K,\nit aligns dense item embeddings from three modalities: audio (block-level,\ni-vector), visual (CNN, AVF), and text. Missing or sparse metadata is\nautomatically enriched using state-of-the-art LLMs (e.g., OpenAI Ada),\ngenerating high-quality synopses for thousands of movies. All text (raw or\naugmented) is embedded with configurable encoders (Ada, LLaMA-2, Sentence-T5),\nproducing multiple ready-to-use sets. The pipeline supports interchangeable\nearly-, mid-, and late-fusion (concatenation, PCA, CCA, rank-aggregation) and\nmultiple backbones (MF, VAECF, VBPR, AMR, VMF) for ablation. Experiments are\nfully declarative via a single YAML file. Evaluation spans accuracy (Recall,\nnDCG) and beyond-accuracy metrics: cold-start rate, coverage, novelty,\ndiversity, fairness. Results show LLM-based augmentation and strong text\nembeddings boost cold-start and coverage, especially when fused with\naudio-visual features. Systematic benchmarking reveals universal versus\nbackbone- or metric-specific combinations. Open-source code, embeddings, and\nconfigs enable reproducible, fair multimodal RS research and advance principled\ngenerative AI integration in large-scale recommendation. Code:\nhttps://recsys-lab.github.io/ViLLA-MMBench",
        "url": "http://arxiv.org/abs/2508.04206v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04206v1",
        "arxiv_id": "2508.04206v1",
        "authors": [
            "Fatemeh Nazary",
            "Ali Tourani",
            "Yashar Deldjoo",
            "Tommaso Di Noia"
        ],
        "submitted": "2025-08-06 08:39:07",
        "source": "arxiv",
        "comment": "17 pages, 3 figures, 5 tables",
        "score": 6,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)",
            "Found 'recsys' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a benchmark suite for multimodal movie recommendation, focusing on LLM-augmented models. While it touches on some aspects of information retrieval, such as text embedding and fusion, its primary focus is on recommender systems, which is a secondary interest of yours. The paper's emphasis on multimodal fusion and LLM-based augmentation is not directly related to your core research themes in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "ToolGrad: Efficient Tool-use Dataset Generation with Textual \"Gradients\"",
        "abstract": "Prior work synthesizes tool-use LLM datasets by first generating a user\nquery, followed by complex tool-use annotations like DFS. This leads to\ninevitable annotation failures and low efficiency in data generation. We\nintroduce ToolGrad, an agentic framework that inverts this paradigm. ToolGrad\nfirst constructs valid tool-use chains through an iterative process guided by\ntextual \"gradients\", and then synthesizes corresponding user queries. This\n\"answer-first\" approach led to ToolGrad-5k, a dataset generated with more\ncomplex tool use, lower cost, and 100% pass rate. Experiments show that models\ntrained on ToolGrad-5k outperform those on expensive baseline datasets and\nproprietary LLMs, even on OOD benchmarks.",
        "url": "http://arxiv.org/abs/2508.04086v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04086v1",
        "arxiv_id": "2508.04086v1",
        "authors": [
            "Zhongyi Zhou",
            "Kohei Uehara",
            "Haoyu Zhang",
            "Jingtao Zhou",
            "Lin Gu",
            "Ruofei Du",
            "Zheng Xu",
            "Tatsuya Harada"
        ],
        "submitted": "2025-08-06 05:04:00",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on generating tool-use datasets for language models, which is not directly related to information retrieval, search technologies, or user behavior modeling. Although it mentions textual 'gradients', the context is unclear and does not seem to be relevant to query understanding, ranking models, or real-time relevance optimization."
    },
    {
        "title": "Automated Generation of Curriculum-Aligned Multiple-Choice Questions for Malaysian Secondary Mathematics Using Generative AI",
        "abstract": "This paper addresses the critical need for scalable and high-quality\neducational assessment tools within the Malaysian education system. It\nhighlights the potential of Generative AI (GenAI) while acknowledging the\nsignificant challenges of ensuring factual accuracy and curriculum alignment,\nespecially for low-resource languages like Bahasa Melayu. This research\nintroduces and compares four incremental pipelines for generating Form 1\nMathematics multiple-choice questions (MCQs) in Bahasa Melayu using OpenAI's\nGPT-4o. The methods range from non-grounded prompting (structured and basic) to\nRetrieval-Augmented Generation (RAG) approaches (one using the LangChain\nframework, one implemented manually). The system is grounded in official\ncurriculum documents, including teacher-prepared notes and the yearly teaching\nplan (RPT). A dual-pronged automated evaluation framework is employed to assess\nthe generated questions. Curriculum alignment is measured using Semantic\nTextual Similarity (STS) against the RPT, while contextual validity is verified\nthrough a novel RAG-based Question-Answering (RAG-QA) method. The results\ndemonstrate that RAG-based pipelines significantly outperform non-grounded\nprompting methods, producing questions with higher curriculum alignment and\nfactual validity. The study further analyzes the trade-offs between the ease of\nimplementation of framework-based RAG and the fine-grained control offered by a\nmanual pipeline. This work presents a validated methodology for generating\ncurriculum-specific educational content in a low-resource language, introduces\na symbiotic RAG-QA evaluation technique, and provides actionable insights for\nthe development and deployment of practical EdTech solutions in Malaysia and\nsimilar regions.",
        "url": "http://arxiv.org/abs/2508.04442v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04442v1",
        "arxiv_id": "2508.04442v1",
        "authors": [
            "Rohaizah Abdul Wahid",
            "Muhamad Said Nizamuddin Nadim",
            "Suliana Sulaiman",
            "Syahmi Akmal Shaharudin",
            "Muhammad Danial Jupikil",
            "Iqqwan Jasman Su Azlan Su"
        ],
        "submitted": "2025-08-06 13:30:51",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on educational assessment tools and Generative AI for generating multiple-choice questions in Bahasa Melayu, which is outside your primary areas of interest."
    },
    {
        "title": "Algorithm Selection for Recommender Systems via Meta-Learning on Algorithm Characteristics",
        "abstract": "The Algorithm Selection Problem for recommender systems-choosing the best\nalgorithm for a given user or context-remains a significant challenge.\nTraditional meta-learning approaches often treat algorithms as categorical\nchoices, ignoring their intrinsic properties. Recent work has shown that\nexplicitly characterizing algorithms with features can improve model\nperformance in other domains. Building on this, we propose a per-user\nmeta-learning approach for recommender system selection that leverages both\nuser meta-features and automatically extracted algorithm features from source\ncode. Our preliminary results, averaged over six diverse datasets, show that\naugmenting a meta-learner with algorithm features improves its average NDCG@10\nperformance by 8.83% from 0.135 (user features only) to 0.147. This enhanced\nmodel outperforms the Single Best Algorithm baseline (0.131) and successfully\ncloses 10.5% of the performance gap to a theoretical oracle selector. These\nfindings show that even static source code metrics provide a valuable\npredictive signal, presenting a promising direction for building more robust\nand intelligent recommender systems.",
        "url": "http://arxiv.org/abs/2508.04419v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04419v1",
        "arxiv_id": "2508.04419v1",
        "authors": [
            "Jarne Mathi Decker",
            "Joeran Beel"
        ],
        "submitted": "2025-08-06 13:06:24",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to your interests in Information Retrieval and Search technologies, but it focuses on recommender systems and algorithm selection, which is not a central match. The use of meta-learning and algorithm features is an interesting aspect, but the paper does not address query understanding, ranking models, or user behavior modeling, which are key areas of your research focus."
    },
    {
        "title": "Audio Does Matter: Importance-Aware Multi-Granularity Fusion for Video Moment Retrieval",
        "abstract": "Video Moment Retrieval (VMR) aims to retrieve a specific moment semantically\nrelated to the given query. To tackle this task, most existing VMR methods\nsolely focus on the visual and textual modalities while neglecting the\ncomplementary but important audio modality. Although a few recent works try to\ntackle the joint audio-vision-text reasoning, they treat all modalities equally\nand simply embed them without fine-grained interaction for moment retrieval.\nThese designs are counter-practical as: Not all audios are helpful for video\nmoment retrieval, and the audio of some videos may be complete noise or\nbackground sound that is meaningless to the moment determination. To this end,\nwe propose a novel Importance-aware Multi-Granularity fusion model (IMG), which\nlearns to dynamically and selectively aggregate the audio-vision-text contexts\nfor VMR. Specifically, after integrating the textual guidance with vision and\naudio separately, we first design a pseudo-label-supervised audio importance\npredictor that predicts the importance score of the audio, and accordingly\nassigns weights to mitigate the interference caused by noisy audio. Then, we\ndesign a multi-granularity audio fusion module that adaptively fuses audio and\nvisual modalities at local-, event-, and global-level, fully capturing their\ncomplementary contexts. We further propose a cross-modal knowledge distillation\nstrategy to address the challenge of missing audio modality during inference.\nTo evaluate our method, we further construct a new VMR dataset, i.e.,\nCharades-AudioMatter, where audio-related samples are manually selected and\nre-organized from the original Charades-STA to validate the model's capability\nin utilizing audio modality. Extensive experiments validate the effectiveness\nof our method, achieving state-of-the-art with audio-video fusion in VMR\nmethods. Our code is available at https://github.com/HuiGuanLab/IMG.",
        "url": "http://arxiv.org/abs/2508.04273v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04273v1",
        "arxiv_id": "2508.04273v1",
        "authors": [
            "Junan Lin",
            "Daizong Liu",
            "Xianke Chen",
            "Xiaoye Qu",
            "Xun Yang",
            "Jixiang Zhu",
            "Sanyuan Zhang",
            "Jianfeng Dong"
        ],
        "submitted": "2025-08-06 09:58:43",
        "source": "arxiv",
        "comment": "Accepted to ACM MM 2025",
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Video Moment Retrieval, which is not directly related to Information Retrieval or Search technologies. Although it involves multi-modal fusion, the emphasis is on audio-visual fusion for video moment retrieval, which is not a core area of interest for the user. The paper's relevance to the user's research themes is limited."
    },
    {
        "title": "ShoppingBench: A Real-World Intent-Grounded Shopping Benchmark for LLM-based Agents",
        "abstract": "Existing benchmarks in e-commerce primarily focus on basic user intents, such\nas finding or purchasing products. However, real-world users often pursue more\ncomplex goals, such as applying vouchers, managing budgets, and finding\nmulti-products seller. To bridge this gap, we propose ShoppingBench, a novel\nend-to-end shopping benchmark designed to encompass increasingly challenging\nlevels of grounded intent. Specifically, we propose a scalable framework to\nsimulate user instructions based on various intents derived from sampled\nreal-world products. To facilitate consistent and reliable evaluations, we\nprovide a large-scale shopping sandbox that serves as an interactive simulated\nenvironment, incorporating over 2.5 million real-world products. Experimental\nresults demonstrate that even state-of-the-art language agents (such as\nGPT-4.1) achieve absolute success rates under 50% on our benchmark tasks,\nhighlighting the significant challenges posed by our ShoppingBench. In\naddition, we propose a trajectory distillation strategy and leverage supervised\nfine-tuning, along with reinforcement learning on synthetic trajectories, to\ndistill the capabilities of a large language agent into a smaller one. As a\nresult, our trained agent achieves competitive performance compared to GPT-4.1.",
        "url": "http://arxiv.org/abs/2508.04266v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04266v1",
        "arxiv_id": "2508.04266v1",
        "authors": [
            "Jiangyuan Wang",
            "Kejun Xiao",
            "Qi Sun",
            "Huaipeng Zhao",
            "Tao Luo",
            "Jiandong Zhang",
            "Xiaoyi Zeng"
        ],
        "submitted": "2025-08-06 09:51:30",
        "source": "arxiv",
        "comment": "submit to AAAI2026",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'shopping' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper proposes a novel benchmark for e-commerce, focusing on complex user intents and real-world scenarios. While it's not directly related to query understanding, ranking models, or user behavior modeling, it's relevant to information retrieval and search technologies in the context of e-commerce. The paper's emphasis on language agents and their capabilities is also of interest in the broader context of NLP."
    },
    {
        "title": "SSEmb: A Joint Structural and Semantic Embedding Framework for Mathematical Formula Retrieval",
        "abstract": "Formula retrieval is an important topic in Mathematical Information\nRetrieval. We propose SSEmb, a novel embedding framework capable of capturing\nboth structural and semantic features of mathematical formulas. Structurally,\nwe employ Graph Contrastive Learning to encode formulas represented as Operator\nGraphs. To enhance structural diversity while preserving mathematical validity\nof these formula graphs, we introduce a novel graph data augmentation approach\nthrough a substitution strategy. Semantically, we utilize Sentence-BERT to\nencode the surrounding text of formulas. Finally, for each query and its\ncandidates, structural and semantic similarities are calculated separately and\nthen fused through a weighted scheme. In the ARQMath-3 formula retrieval task,\nSSEmb outperforms existing embedding-based methods by over 5 percentage points\non P'@10 and nDCG'@10. Furthermore, SSEmb enhances the performance of all runs\nof other methods and achieves state-of-the-art results when combined with\nApproach0.",
        "url": "http://arxiv.org/abs/2508.04162v2",
        "pdf_url": "http://arxiv.org/pdf/2508.04162v2",
        "arxiv_id": "2508.04162v2",
        "authors": [
            "Ruyin Li",
            "Xiaoyu Chen"
        ],
        "submitted": "2025-08-06 07:39:17",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper's focus on mathematical formula retrieval and its use of graph contrastive learning and sentence-BERT are somewhat related to my interests in information retrieval and natural language processing. However, the specific domain of mathematical formula retrieval and the lack of relevance to query understanding, ranking models, and user behavior modeling make it less relevant to my core research themes."
    },
    {
        "title": "AgREE: Agentic Reasoning for Knowledge Graph Completion on Emerging Entities",
        "abstract": "Open-domain Knowledge Graph Completion (KGC) faces significant challenges in\nan ever-changing world, especially when considering the continual emergence of\nnew entities in daily news. Existing approaches for KGC mainly rely on\npretrained language models' parametric knowledge, pre-constructed queries, or\nsingle-step retrieval, typically requiring substantial supervision and training\ndata. Even so, they often fail to capture comprehensive and up-to-date\ninformation about unpopular and/or emerging entities. To this end, we introduce\nAgentic Reasoning for Emerging Entities (AgREE), a novel agent-based framework\nthat combines iterative retrieval actions and multi-step reasoning to\ndynamically construct rich knowledge graph triplets. Experiments show that,\ndespite requiring zero training efforts, AgREE significantly outperforms\nexisting methods in constructing knowledge graph triplets, especially for\nemerging entities that were not seen during language models' training\nprocesses, outperforming previous methods by up to 13.7%. Moreover, we propose\na new evaluation methodology that addresses a fundamental weakness of existing\nsetups and a new benchmark for KGC on emerging entities. Our work demonstrates\nthe effectiveness of combining agent-based reasoning with strategic information\nretrieval for maintaining up-to-date knowledge graphs in dynamic information\nenvironments.",
        "url": "http://arxiv.org/abs/2508.04118v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04118v1",
        "arxiv_id": "2508.04118v1",
        "authors": [
            "Ruochen Zhao",
            "Simone Conia",
            "Eric Peng",
            "Min Li",
            "Saloni Potdar"
        ],
        "submitted": "2025-08-06 06:34:22",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Knowledge Graph Completion, which is not directly related to Information Retrieval or Search technologies. While it mentions information retrieval as part of the framework, the primary focus is on knowledge graph construction and reasoning. The paper's emphasis on emerging entities and dynamic information environments is somewhat relevant to user behavior modeling, but the connection is loose."
    },
    {
        "title": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models",
        "abstract": "Large Language Models (LLMs) are trained on vast and diverse internet corpora\nthat often include inaccurate or misleading content. Consequently, LLMs can\ngenerate misinformation, making robust fact-checking essential. This review\nsystematically analyzes how LLM-generated content is evaluated for factual\naccuracy by exploring key challenges such as hallucinations, dataset\nlimitations, and the reliability of evaluation metrics. The review emphasizes\nthe need for strong fact-checking frameworks that integrate advanced prompting\nstrategies, domain-specific fine-tuning, and retrieval-augmented generation\n(RAG) methods. It proposes five research questions that guide the analysis of\nthe recent literature from 2020 to 2025, focusing on evaluation methods and\nmitigation techniques. The review also discusses the role of instruction\ntuning, multi-agent reasoning, and external knowledge access via RAG\nframeworks. Key findings highlight the limitations of current metrics, the\nvalue of grounding outputs with validated external evidence, and the importance\nof domain-specific customization to improve factual consistency. Overall, the\nreview underlines the importance of building LLMs that are not only accurate\nand explainable but also tailored for domain-specific fact-checking. These\ninsights contribute to the advancement of research toward more trustworthy and\ncontext-aware language models.",
        "url": "http://arxiv.org/abs/2508.03860v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03860v1",
        "arxiv_id": "2508.03860v1",
        "authors": [
            "Subhey Sadi Rahman",
            "Md. Adnanul Islam",
            "Md. Mahbub Alam",
            "Musarrat Zeba",
            "Md. Abdur Rahman",
            "Sadia Sultana Chowa",
            "Mohaimenul Azam Khan Raiaan",
            "Sami Azam"
        ],
        "submitted": "2025-08-05 19:20:05",
        "source": "arxiv",
        "comment": "30 pages, 11 figures, 6 tables. Submitted to Artificial Intelligence\n  Review for peer review",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper discusses fact-checking and factuality evaluation in Large Language Models, which is related to information retrieval and search technologies. However, the focus is more on the evaluation of language models rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user."
    },
    {
        "title": "FaST: Feature-aware Sampling and Tuning for Personalized Preference Alignment with Limited Data",
        "abstract": "LLM-powered conversational assistants are often deployed in a\none-size-fits-all manner, which fails to accommodate individual user\npreferences. Recently, LLM personalization -- tailoring models to align with\nspecific user preferences -- has gained increasing attention as a way to bridge\nthis gap. In this work, we specifically focus on a practical yet challenging\nsetting where only a small set of preference annotations can be collected per\nuser -- a problem we define as Personalized Preference Alignment with Limited\nData (PPALLI). To support research in this area, we introduce two datasets --\nDnD and ELIP -- and benchmark a variety of alignment techniques on them. We\nfurther propose FaST, a highly parameter-efficient approach that leverages\nhigh-level features automatically discovered from the data, achieving the best\noverall performance.",
        "url": "http://arxiv.org/abs/2508.04698v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04698v1",
        "arxiv_id": "2508.04698v1",
        "authors": [
            "Thibaut Thonet",
            "Germán Kruszewski",
            "Jos Rozen",
            "Pierre Erbacher",
            "Marc Dymetman"
        ],
        "submitted": "2025-08-06 17:58:26",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'personalization' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on personalized preference alignment with limited data, which is related to user behavior modeling and query understanding in Information Retrieval. However, it does not directly address ranking models or real-time relevance optimization, which are core areas of interest. The paper's emphasis on conversational assistants and LLMs is also outside of the e-commerce domain, although it does touch on personalization, which is a related topic."
    },
    {
        "title": "Share Your Attention: Transformer Weight Sharing via Matrix-based Dictionary Learning",
        "abstract": "Large language models (LLMs) have revolutionized AI applications, yet their\nhigh computational and memory demands hinder their widespread deployment.\nExisting compression techniques focus on intra-block optimizations (e.g.\nlow-rank approximation, attention head pruning), while the repetitive layered\nstructure of transformers implies significant inter-block redundancy - a\ndimension largely unexplored beyond key-value (KV) caching. Inspired by\ndictionary learning in CNNs, we propose a framework for structured weight\nsharing across transformer layers. Our approach decomposes attention projection\nmatrices into shared dictionary atoms, reducing the attention module's\nparameters by 66.7% while achieving on-par performance. Unlike complex methods\nrequiring distillation or architectural changes, MASA (Matrix Atom Sharing in\nAttention) operates as a drop-in replacement - trained with standard optimizers\n- and represents each layer's weights as linear combinations of shared matrix\natoms. Experiments across scales (100M-700M parameters) show that MASA achieves\nbetter benchmark accuracy and perplexity than grouped-query attention (GQA),\nlow-rank baselines and recently proposed Repeat-all-over/Sequential sharing at\ncomparable parameter budgets. Ablation studies confirm robustness to the\ndictionary size and the efficacy of shared representations in capturing\ncross-layer statistical regularities. Extending to Vision Transformers (ViT),\nMASA matches performance metrics on image classification and detection tasks\nwith 66.7% fewer attention parameters. By combining dictionary learning\nstrategies with transformer efficiency, MASA offers a scalable blueprint for\nparameter-efficient models without sacrificing performance. Finally, we\ninvestigate the possibility of employing MASA on pretrained LLMs to reduce\ntheir number of parameters without experiencing any significant drop in their\nperformance.",
        "url": "http://arxiv.org/abs/2508.04581v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04581v1",
        "arxiv_id": "2508.04581v1",
        "authors": [
            "Magauiya Zhussip",
            "Dmitriy Shopkhoev",
            "Ammar Ali",
            "Stamatios Lefkimmiatis"
        ],
        "submitted": "2025-08-06 16:06:43",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on transformer weight sharing and compression, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on attention mechanisms, the context is different from the user's interests in ranking models and user behavior modeling."
    },
    {
        "title": "OS Agents: A Survey on MLLM-based Agents for General Computing Devices Use",
        "abstract": "The dream to create AI assistants as capable and versatile as the fictional\nJ.A.R.V.I.S from Iron Man has long captivated imaginations. With the evolution\nof (multi-modal) large language models ((M)LLMs), this dream is closer to\nreality, as (M)LLM-based Agents using computing devices (e.g., computers and\nmobile phones) by operating within the environments and interfaces (e.g.,\nGraphical User Interface (GUI)) provided by operating systems (OS) to automate\ntasks have significantly advanced. This paper presents a comprehensive survey\nof these advanced agents, designated as OS Agents. We begin by elucidating the\nfundamentals of OS Agents, exploring their key components including the\nenvironment, observation space, and action space, and outlining essential\ncapabilities such as understanding, planning, and grounding. We then examine\nmethodologies for constructing OS Agents, focusing on domain-specific\nfoundation models and agent frameworks. A detailed review of evaluation\nprotocols and benchmarks highlights how OS Agents are assessed across diverse\ntasks. Finally, we discuss current challenges and identify promising directions\nfor future research, including safety and privacy, personalization and\nself-evolution. This survey aims to consolidate the state of OS Agents\nresearch, providing insights to guide both academic inquiry and industrial\ndevelopment. An open-source GitHub repository is maintained as a dynamic\nresource to foster further innovation in this field. We present a 9-page\nversion of our work, accepted by ACL 2025, to provide a concise overview to the\ndomain.",
        "url": "http://arxiv.org/abs/2508.04482v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04482v1",
        "arxiv_id": "2508.04482v1",
        "authors": [
            "Xueyu Hu",
            "Tao Xiong",
            "Biao Yi",
            "Zishu Wei",
            "Ruixuan Xiao",
            "Yurun Chen",
            "Jiasheng Ye",
            "Meiling Tao",
            "Xiangxin Zhou",
            "Ziyu Zhao",
            "Yuhuai Li",
            "Shengze Xu",
            "Shenzhi Wang",
            "Xinchen Xu",
            "Shuofei Qiao",
            "Zhaokai Wang",
            "Kun Kuang",
            "Tieyong Zeng",
            "Liang Wang",
            "Jiwei Li",
            "Yuchen Eleanor Jiang",
            "Wangchunshu Zhou",
            "Guoyin Wang",
            "Keting Yin",
            "Zhou Zhao",
            "Hongxia Yang",
            "Fan Wu",
            "Shengyu Zhang",
            "Fei Wu"
        ],
        "submitted": "2025-08-06 14:33:45",
        "source": "arxiv",
        "comment": "ACL 2025 (Oral)",
        "score": 4,
        "keyword_reasons": [
            "Found 'personalization' (score: +1)",
            "Found 'search' (score: +1)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on MLLM-based agents for general computing devices, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on AI assistants, the primary focus is on agent construction and evaluation, which is outside the scope of the user's research interests."
    },
    {
        "title": "A Few Words Can Distort Graphs: Knowledge Poisoning Attacks on Graph-based Retrieval-Augmented Generation of Large Language Models",
        "abstract": "Graph-based Retrieval-Augmented Generation (GraphRAG) has recently emerged as\na promising paradigm for enhancing large language models (LLMs) by converting\nraw text into structured knowledge graphs, improving both accuracy and\nexplainability. However, GraphRAG relies on LLMs to extract knowledge from raw\ntext during graph construction, and this process can be maliciously manipulated\nto implant misleading information. Targeting this attack surface, we propose\ntwo knowledge poisoning attacks (KPAs) and demonstrate that modifying only a\nfew words in the source text can significantly change the constructed graph,\npoison the GraphRAG, and severely mislead downstream reasoning. The first\nattack, named Targeted KPA (TKPA), utilizes graph-theoretic analysis to locate\nvulnerable nodes in the generated graphs and rewrites the corresponding\nnarratives with LLMs, achieving precise control over specific\nquestion-answering (QA) outcomes with a success rate of 93.1\\%, while keeping\nthe poisoned text fluent and natural. The second attack, named Universal KPA\n(UKPA), exploits linguistic cues such as pronouns and dependency relations to\ndisrupt the structural integrity of the generated graph by altering globally\ninfluential words. With fewer than 0.05\\% of full text modified, the QA\naccuracy collapses from 95\\% to 50\\%. Furthermore, experiments show that\nstate-of-the-art defense methods fail to detect these attacks, highlighting\nthat securing GraphRAG pipelines against knowledge poisoning remains largely\nunexplored.",
        "url": "http://arxiv.org/abs/2508.04276v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04276v1",
        "arxiv_id": "2508.04276v1",
        "authors": [
            "Jiayi Wen",
            "Tianxin Chen",
            "Zhirun Zheng",
            "Cheng Huang"
        ],
        "submitted": "2025-08-06 10:01:26",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses knowledge poisoning attacks on graph-based retrieval-augmented generation of large language models, which is a topic in Natural Language Processing (NLP). While it touches on the concept of graph construction and manipulation, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval (IR)."
    },
    {
        "title": "Benefit from Rich: Tackling Search Interaction Sparsity in Search Enhanced Recommendation",
        "abstract": "In modern online platforms, search and recommendation (S&R) often coexist,\noffering opportunities for performance improvement through search-enhanced\napproaches. Existing studies show that incorporating search signals boosts\nrecommendation performance. However, the effectiveness of these methods relies\nheavily on rich search interactions. They primarily benefit a small subset of\nusers with abundant search behavior, while offering limited improvements for\nthe majority of users who exhibit only sparse search activity. To address the\nproblem of sparse search data in search-enhanced recommendation, we face two\nkey challenges: (1) how to learn useful search features for users with sparse\nsearch interactions, and (2) how to design effective training objectives under\nsparse conditions. Our idea is to leverage the features of users with rich\nsearch interactions to enhance those of users with sparse search interactions.\nBased on this idea, we propose GSERec, a method that utilizes message passing\non the User-Code Graphs to alleviate data sparsity in Search-Enhanced\nRecommendation. Specifically, we utilize Large Language Models (LLMs) with\nvector quantization to generate discrete codes, which connect similar users and\nthereby construct the graph. Through message passing on this graph, embeddings\nof users with rich search data are propagated to enhance the embeddings of\nusers with sparse interactions. To further ensure that the message passing\ncaptures meaningful information from truly similar users, we introduce a\ncontrastive loss to better model user similarities. The enhanced user\nrepresentations are then integrated into downstream search-enhanced\nrecommendation models. Experiments on three real-world datasets show that\nGSERec consistently outperforms baselines, especially for users with sparse\nsearch behaviors.",
        "url": "http://arxiv.org/abs/2508.04145v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04145v1",
        "arxiv_id": "2508.04145v1",
        "authors": [
            "Teng Shi",
            "Weijie Yu",
            "Xiao Zhang",
            "Ming He",
            "Jianping Fan",
            "Jun Xu"
        ],
        "submitted": "2025-08-06 07:16:40",
        "source": "arxiv",
        "comment": "Accepted by CIKM 2025",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores search-enhanced recommendation, which is related to information retrieval and search technologies. However, the focus is on leveraging search signals for recommendation, rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's use of large language models and vector quantization is also relevant to NLP, but the application is primarily in the recommender systems domain."
    },
    {
        "title": "Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis",
        "abstract": "The emergence of reasoning models and their integration into practical AI\nchat bots has led to breakthroughs in solving advanced math, deep search, and\nextractive question answering problems that requires a complex and multi-step\nthought process. Yet, a complete understanding of why these models hallucinate\nmore than general purpose language models is missing. In this investigative\nstudy, we systematicallyexplore reasoning failures of contemporary language\nmodels on multi-hop question answering tasks. We introduce a novel, nuanced\nerror categorization framework that examines failures across three critical\ndimensions: the diversity and uniqueness of source documents involved (\"hops\"),\ncompleteness in capturing relevant information (\"coverage\"), and cognitive\ninefficiency (\"overthinking\"). Through rigorous hu-man annotation, supported by\ncomplementary automated metrics, our exploration uncovers intricate error\npatterns often hidden by accuracy-centric evaluations. This investigative\napproach provides deeper insights into the cognitive limitations of current\nmodels and offers actionable guidance toward enhancing reasoning fidelity,\ntransparency, and robustness in future language modeling efforts.",
        "url": "http://arxiv.org/abs/2508.04699v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04699v1",
        "arxiv_id": "2508.04699v1",
        "authors": [
            "Anushka Yadav",
            "Isha Nalawade",
            "Srujana Pillarichety",
            "Yashwanth Babu",
            "Reshmi Ghosh",
            "Samyadeep Basu",
            "Wenlong Zhao",
            "Ali Nasaeh",
            "Sriram Balasubramanian",
            "Soundararajan Srinivasan"
        ],
        "submitted": "2025-08-06 17:58:36",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the limitations of reasoning models in multi-hop question answering tasks, introducing a novel error categorization framework. While it touches on language models, it doesn't specifically focus on query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval and Search technologies."
    },
    {
        "title": "Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management",
        "abstract": "Large Language Models (LLMs) suffer from significant performance degradation\nwhen processing long contexts due to proactive interference, where irrelevant\ninformation in earlier parts of the context disrupts reasoning and memory\nrecall. While most research focuses on external memory systems to augment LLMs'\ncapabilities, we propose a complementary approach: empowering LLMs with Active\nContext Management (ACM) tools to actively sculpt their internal working\nmemory. We introduce Sculptor, a framework that equips LLMs with three\ncategories of tools: (1) context fragmentation, (2) summary, hide, and restore,\nand (3) intelligent search. Our approach enables LLMs to proactively manage\ntheir attention and working memory, analogous to how humans selectively focus\non relevant information while filtering out distractions. Experimental\nevaluation on information-sparse benchmarks-PI-LLM (proactive interference) and\nNeedleBench Multi-Needle Reasoning-demonstrates that Sculptor significantly\nimproves performance even without specific training, leveraging LLMs' inherent\ntool calling generalization capabilities. By enabling Active Context\nManagement, Sculptor not only mitigates proactive interference but also\nprovides a cognitive foundation for more reliable reasoning across diverse\nlong-context tasks-highlighting that explicit context-control strategies,\nrather than merely larger token windows, are key to robustness at scale.",
        "url": "http://arxiv.org/abs/2508.04664v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04664v1",
        "arxiv_id": "2508.04664v1",
        "authors": [
            "Mo Li",
            "L. H. Xu",
            "Qitai Tan",
            "Ting Cao",
            "Yunxin Liu"
        ],
        "submitted": "2025-08-06 17:32:58",
        "source": "arxiv",
        "comment": "Preprint. Work in progress",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper introduces a framework called Sculptor that enables Large Language Models (LLMs) to actively manage their internal working memory, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on LLMs and cognitive agency is not directly aligned with the user's primary research interests in IR and search technologies."
    },
    {
        "title": "Multi-module GRPO: Composing Policy Gradients and Prompt Optimization for Language Model Programs",
        "abstract": "Group Relative Policy Optimization (GRPO) has proven to be an effective tool\nfor post-training language models (LMs). However, AI systems are increasingly\nexpressed as modular programs that mix together multiple LM calls with distinct\nprompt templates and other tools, and it is not clear how best to leverage GRPO\nto improve these systems. We begin to address this challenge by defining\nmmGRPO, a simple multi-module generalization of GRPO that groups LM calls by\nmodule across rollouts and handles variable-length and interrupted\ntrajectories. We find that mmGRPO, composed with automatic prompt optimization,\nimproves accuracy by 11% on average across classification, many-hop search, and\nprivacy-preserving delegation tasks against the post-trained LM, and by 5%\nagainst prompt optimization on its own. We open-source mmGRPO in DSPy as the\ndspy.GRPO optimizer.",
        "url": "http://arxiv.org/abs/2508.04660v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04660v1",
        "arxiv_id": "2508.04660v1",
        "authors": [
            "Noah Ziems",
            "Dilara Soylu",
            "Lakshya A Agrawal",
            "Isaac Miller",
            "Liheng Lai",
            "Chen Qian",
            "Kaiqiang Song",
            "Meng Jiang",
            "Dan Klein",
            "Matei Zaharia",
            "Karel D'Oosterlinck",
            "Christopher Potts",
            "Omar Khattab"
        ],
        "submitted": "2025-08-06 17:28:31",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on optimizing language models for specific tasks, using a multi-module approach. While it involves some aspects of search and optimization, it is primarily concerned with language model programs and prompt optimization, which is not directly related to the user's interests in Information Retrieval, query understanding, and ranking models."
    },
    {
        "title": "Lightweight Transformers for Zero-Shot and Fine-Tuned Text-to-SQL Generation Using Spider",
        "abstract": "Text-to-SQL translation enables non-expert users to query relational\ndatabases using natural language, with applications in education and business\nintelligence. This study evaluates three lightweight transformer models -\nT5-Small, BART-Small, and GPT-2 - on the Spider dataset, focusing on\nlow-resource settings. We developed a reusable, model-agnostic pipeline that\ntailors schema formatting to each model's architecture, training them across\n1000 to 5000 iterations and evaluating on 1000 test samples using Logical Form\nAccuracy (LFAcc), BLEU, and Exact Match (EM) metrics. Fine-tuned T5-Small\nachieves the highest LFAcc (27.8%), outperforming BART-Small (23.98%) and GPT-2\n(20.1%), highlighting encoder-decoder models' superiority in schema-aware SQL\ngeneration. Despite resource constraints limiting performance, our pipeline's\nmodularity supports future enhancements, such as advanced schema linking or\nalternative base models. This work underscores the potential of compact\ntransformers for accessible text-to-SQL solutions in resource-scarce\nenvironments.",
        "url": "http://arxiv.org/abs/2508.04623v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04623v1",
        "arxiv_id": "2508.04623v1",
        "authors": [
            "Chirag Seth",
            "Utkarsh Singh"
        ],
        "submitted": "2025-08-06 16:49:13",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on text-to-SQL generation using transformers, which is related to information retrieval and search technologies. However, the primary focus is on natural language processing and text generation, rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user."
    },
    {
        "title": "Do Recommender Systems Really Leverage Multimodal Content? A Comprehensive Analysis on Multimodal Representations for Recommendation",
        "abstract": "Multimodal Recommender Systems aim to improve recommendation accuracy by\nintegrating heterogeneous content, such as images and textual metadata. While\neffective, it remains unclear whether their gains stem from true multimodal\nunderstanding or increased model complexity. This work investigates the role of\nmultimodal item embeddings, emphasizing the semantic informativeness of the\nrepresentations. Initial experiments reveal that embeddings from standard\nextractors (e.g., ResNet50, Sentence-Bert) enhance performance, but rely on\nmodality-specific encoders and ad hoc fusion strategies that lack control over\ncross-modal alignment. To overcome these limitations, we leverage Large\nVision-Language Models (LVLMs) to generate multimodal-by-design embeddings via\nstructured prompts. This approach yields semantically aligned representations\nwithout requiring any fusion. Experiments across multiple settings show notable\nperformance improvements. Furthermore, LVLMs embeddings offer a distinctive\nadvantage: they can be decoded into structured textual descriptions, enabling\ndirect assessment of their multimodal comprehension. When such descriptions are\nincorporated as side content into recommender systems, they improve\nrecommendation performance, empirically validating the semantic depth and\nalignment encoded within LVLMs outputs. Our study highlights the importance of\nsemantically rich representations and positions LVLMs as a compelling\nfoundation for building robust and meaningful multimodal representations in\nrecommendation tasks.",
        "url": "http://arxiv.org/abs/2508.04571v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04571v1",
        "arxiv_id": "2508.04571v1",
        "authors": [
            "Claudio Pomo",
            "Matteo Attimonelli",
            "Danilo Danese",
            "Fedelucio Narducci",
            "Tommaso Di Noia"
        ],
        "submitted": "2025-08-06 15:53:58",
        "source": "arxiv",
        "comment": "Accepted as Full Research Papers at CIKM 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on multimodal recommender systems, which is related to your interest in recommender systems. However, the emphasis on multimodal content and LVLMs is not directly aligned with your primary focus on information retrieval, query understanding, and ranking models. The paper's relevance is somewhat limited to your broader interests in NLP and data mining."
    },
    {
        "title": "Unveiling the Landscape of Clinical Depression Assessment: From Behavioral Signatures to Psychiatric Reasoning",
        "abstract": "Depression is a widespread mental disorder that affects millions worldwide.\nWhile automated depression assessment shows promise, most studies rely on\nlimited or non-clinically validated data, and often prioritize complex model\ndesign over real-world effectiveness. In this paper, we aim to unveil the\nlandscape of clinical depression assessment. We introduce C-MIND, a clinical\nneuropsychiatric multimodal diagnosis dataset collected over two years from\nreal hospital visits. Each participant completes three structured psychiatric\ntasks and receives a final diagnosis from expert clinicians, with informative\naudio, video, transcript, and functional near-infrared spectroscopy (fNIRS)\nsignals recorded. Using C-MIND, we first analyze behavioral signatures relevant\nto diagnosis. We train a range of classical models to quantify how different\ntasks and modalities contribute to diagnostic performance, and dissect the\neffectiveness of their combinations. We then explore whether LLMs can perform\npsychiatric reasoning like clinicians and identify their clear limitations in\nrealistic clinical settings. In response, we propose to guide the reasoning\nprocess with clinical expertise and consistently improves LLM diagnostic\nperformance by up to 10% in Macro-F1 score. We aim to build an infrastructure\nfor clinical depression assessment from both data and algorithmic perspectives,\nenabling C-MIND to facilitate grounded and reliable research for mental\nhealthcare.",
        "url": "http://arxiv.org/abs/2508.04531v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04531v1",
        "arxiv_id": "2508.04531v1",
        "authors": [
            "Zhuang Chen",
            "Guanqun Bi",
            "Wen Zhang",
            "Jiawei Hu",
            "Aoyun Wang",
            "Xiyao Xiao",
            "Kun Feng",
            "Minlie Huang"
        ],
        "submitted": "2025-08-06 15:13:24",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it mentions Learning to Rank (LLMs) and uses them for psychiatric reasoning, the focus is on clinical depression assessment and diagnosis, which is outside the user's primary research area."
    },
    {
        "title": "FrEVL: Leveraging Frozen Pretrained Embeddings for Efficient Vision-Language Understanding",
        "abstract": "The deployment of vision-language models remains constrained by substantial\ncomputational requirements. We present \\textbf{FrEVL}, a framework exploring\nwhether frozen pretrained embeddings can support effective vision-language\nunderstanding. Our analysis reveals that frozen embeddings contain rich\ninformation for discriminative tasks, achieving 85\\% to 95\\% of\nstate-of-the-art performance on standard benchmarks with only 68.4M trainable\nparameters. This performance dichotomy reveals a critical insight: frozen\nembedding effectiveness depends on alignment between pretraining objectives and\ndownstream task requirements. When accounting for end-to-end computation\nincluding embedding extraction, FrEVL provides $2.3\\times$ speedup with 52\\%\nlower energy consumption, making it suitable for scenarios with pre-computable\ninputs or when deployment constraints outweigh marginal performance gains. Our\nevaluation provides practitioners with guidance on when frozen embedding\napproaches represent viable alternatives to full model deployment. We will\nrelease our complete implementation and evaluation framework to facilitate\nfurther research into efficient multi-modal understanding.",
        "url": "http://arxiv.org/abs/2508.04469v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04469v1",
        "arxiv_id": "2508.04469v1",
        "authors": [
            "Emmanuelle Bourigault",
            "Pauline Bourigault"
        ],
        "submitted": "2025-08-06 14:12:05",
        "source": "arxiv",
        "comment": "8 pages, 4 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on vision-language understanding, leveraging frozen pretrained embeddings, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper explores efficient multi-modal understanding, it does not address query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user."
    },
    {
        "title": "Discrete-event Tensor Factorization: Learning a Smooth Embedding for Continuous Domains",
        "abstract": "Recommender systems learn from past user behavior to predict future user\npreferences. Intuitively, it has been established that the most recent\ninteractions are more indicative of future preferences than older interactions.\nMany recommendation algorithms use this notion to either drop older\ninteractions or to assign them a lower weight, so the model can focus on the\nmore informative, recent information. However, very few approaches model the\nflow of time explicitly.\n  This paper analyzes how time can be encoded in factorization-style\nrecommendation models. By including absolute time as a feature, our models can\nlearn varying user preferences and changing item perception over time. In\naddition to simple binning approaches, we also propose a novel, fully\ncontinuous time encoding mechanism. Through the use of a polynomial fit inside\nthe loss function, our models completely avoid the need for discretization, and\nthey are able to capture the time dimension in arbitrary resolution.\n  We perform a comparative study on three real-world datasets that span\nmultiple years, where long user histories are present, and items stay relevant\nfor a longer time. Empirical results show that, by explicitly modeling time,\nour models are very effective at capturing temporal signals, such as varying\nitem popularities over time. Despite this however, our experiments also\nindicate that a simple post-hoc popularity adjustment is often sufficient to\nachieve the best performance on the unseen test set. This teaches us that, for\nthe recommendation task, predicting the future is more important than capturing\npast trends. As such, we argue that specialized mechanisms are needed for\nextrapolation to future data.",
        "url": "http://arxiv.org/abs/2508.04221v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04221v1",
        "arxiv_id": "2508.04221v1",
        "authors": [
            "Joey De Pauw",
            "Bart Goethals"
        ],
        "submitted": "2025-08-06 08:54:57",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'user behavior' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses recommender systems, which is a related topic, but it focuses on modeling time and user preferences, which is not directly aligned with the user's primary interest in information retrieval and query understanding. The paper's emphasis on capturing temporal signals and predicting future user behavior is somewhat relevant, but it does not address the user's core research themes."
    },
    {
        "title": "DTPA: Dynamic Token-level Prefix Augmentation for Controllable Text Generation",
        "abstract": "Controllable Text Generation (CTG) is a vital subfield in Natural Language\nProcessing (NLP), aiming to generate text that aligns with desired attributes.\nHowever, previous studies commonly focus on the quality of controllable text\ngeneration for short sequences, while the generation of long-form text remains\nlargely underexplored. In this paper, we observe that the controllability of\ntexts generated by the powerful prefix-based method Air-Decoding tends to\ndecline with increasing sequence length, which we hypothesize primarily arises\nfrom the observed decay in attention to the prefixes. Meanwhile, different\ntypes of prefixes including soft and hard prefixes are also key factors\ninfluencing performance. Building on these insights, we propose a lightweight\nand effective framework called Dynamic Token-level Prefix Augmentation (DTPA)\nbased on Air-Decoding for controllable text generation. Specifically, it first\nselects the optimal prefix type for a given task. Then we dynamically amplify\nthe attention to the prefix for the attribute distribution to enhance\ncontrollability, with a scaling factor growing exponentially as the sequence\nlength increases. Moreover, based on the task, we optionally apply a similar\naugmentation to the original prompt for the raw distribution to balance text\nquality. After attribute distribution reconstruction, the generated text\nsatisfies the attribute constraints well. Experiments on multiple CTG tasks\ndemonstrate that DTPA generally outperforms other methods in attribute control\nwhile maintaining competitive fluency, diversity, and topic relevance. Further\nanalysis highlights DTPA's superior effectiveness in long text generation.",
        "url": "http://arxiv.org/abs/2508.04047v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04047v1",
        "arxiv_id": "2508.04047v1",
        "authors": [
            "Jiabing Yang",
            "Yixiang Chen",
            "Zichen Wen",
            "Chenhang Cui",
            "Peiyan Li",
            "Yuan Xu",
            "Bowen Fang",
            "Yan Huang",
            "Liang Wang"
        ],
        "submitted": "2025-08-06 03:20:33",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on controllable text generation, a topic in NLP, but it does not relate to information retrieval, search technologies, or query understanding, which are the user's primary research interests. The paper's emphasis on controllable text generation for long-form text also does not align with the user's interests in real-time relevance optimization."
    },
    {
        "title": "HarmonyGuard: Toward Safety and Utility in Web Agents via Adaptive Policy Enhancement and Dual-Objective Optimization",
        "abstract": "Large language models enable agents to autonomously perform tasks in open web\nenvironments. However, as hidden threats within the web evolve, web agents face\nthe challenge of balancing task performance with emerging risks during\nlong-sequence operations. Although this challenge is critical, current research\nremains limited to single-objective optimization or single-turn scenarios,\nlacking the capability for collaborative optimization of both safety and\nutility in web environments. To address this gap, we propose HarmonyGuard, a\nmulti-agent collaborative framework that leverages policy enhancement and\nobjective optimization to jointly improve both utility and safety. HarmonyGuard\nfeatures a multi-agent architecture characterized by two fundamental\ncapabilities: (1) Adaptive Policy Enhancement: We introduce the Policy Agent\nwithin HarmonyGuard, which automatically extracts and maintains structured\nsecurity policies from unstructured external documents, while continuously\nupdating policies in response to evolving threats. (2) Dual-Objective\nOptimization: Based on the dual objectives of safety and utility, the Utility\nAgent integrated within HarmonyGuard performs the Markovian real-time reasoning\nto evaluate the objectives and utilizes metacognitive capabilities for their\noptimization. Extensive evaluations on multiple benchmarks show that\nHarmonyGuard improves policy compliance by up to 38% and task completion by up\nto 20% over existing baselines, while achieving over 90% policy compliance\nacross all tasks. Our project is available here:\nhttps://github.com/YurunChen/HarmonyGuard.",
        "url": "http://arxiv.org/abs/2508.04010v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04010v1",
        "arxiv_id": "2508.04010v1",
        "authors": [
            "Yurun Chen",
            "Xavier Hu",
            "Yuhan Liu",
            "Keting Yin",
            "Juncheng Li",
            "Zhuosheng Zhang",
            "Shengyu Zhang"
        ],
        "submitted": "2025-08-06 01:49:32",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on web agents and policy enhancement, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions optimization, it's not in the context of ranking models or user behavior modeling, and the paper's primary concern is safety and utility in web environments, which is outside the user's primary research interests."
    },
    {
        "title": "CAP-LLM: Context-Augmented Personalized Large Language Models for News Headline Generation",
        "abstract": "In the era of information overload, personalized news headline generation is\ncrucial for engaging users by tailoring content to their preferences while\naccurately conveying news facts. Existing methods struggle with effectively\ncapturing complex user interests and ensuring factual consistency, often\nleading to generic or misleading headlines. Leveraging the unprecedented\ncapabilities of Large Language Models (LLMs) in text generation, we propose\nContext-Augmented Personalized LLM (CAP-LLM), a novel framework that integrates\nuser preferences and factual consistency constraints into a powerful\npre-trained LLM backbone. CAP-LLM features a User Preference Encoder to capture\nlong-term user interests, a Context Injection Adapter to seamlessly integrate\nthese preferences and current article context into the LLM's generation\nprocess, and a Fact-Consistency Reinforcement Module employing a novel\ncontrastive loss to mitigate hallucination. Evaluated on the real-world PENS\ndataset, CAP-LLM achieves state-of-the-art performance across all metrics.\nNotably, it significantly improves factual consistency (FactCC of 87.50) over\nstrong baselines like BART (86.67), while simultaneously enhancing\npersonalization (Pc(avg) 2.73, Pc(max) 17.25) and content coverage (ROUGE-1\n26.55, ROUGE-2 9.95, ROUGE-L 23.01). Our ablation studies, human evaluations,\nand sensitivity analyses further validate the effectiveness of each component\nand the robustness of our approach, demonstrating CAP-LLM's ability to achieve\na superior balance between personalization and factual accuracy in news\nheadline generation.",
        "url": "http://arxiv.org/abs/2508.03935v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03935v1",
        "arxiv_id": "2508.03935v1",
        "authors": [
            "Raymond Wilson",
            "Cole Graham",
            "Chase Carter",
            "Zefeng Yang",
            "Ruiqi Gu"
        ],
        "submitted": "2025-08-05 21:55:44",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on personalized news headline generation using Large Language Models, which is not directly related to my research interests in Information Retrieval, Search technologies, and query understanding. While it touches on user behavior modeling, the context is specific to news headline generation and does not align with my broader interests in e-commerce and real-time relevance optimization."
    },
    {
        "title": "MegaWika 2: A More Comprehensive Multilingual Collection of Articles and their Sources",
        "abstract": "We introduce MegaWika 2, a large, multilingual dataset of Wikipedia articles\nwith their citations and scraped web sources; articles are represented in a\nrich data structure, and scraped source texts are stored inline with precise\ncharacter offsets of their citations in the article text. MegaWika 2 is a major\nupgrade from the original MegaWika, spanning six times as many articles and\ntwice as many fully scraped citations. Both MegaWika and MegaWika 2 support\nreport generation research ; whereas MegaWika also focused on supporting\nquestion answering and retrieval applications, MegaWika 2 is designed to\nsupport fact checking and analyses across time and language.",
        "url": "http://arxiv.org/abs/2508.03828v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03828v1",
        "arxiv_id": "2508.03828v1",
        "authors": [
            "Samuel Barham",
            "Chandler May",
            "Benjamin Van Durme"
        ],
        "submitted": "2025-08-05 18:18:17",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on building a large multilingual dataset for report generation research, fact checking, and analysis, which is not directly related to the user's interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. Although it mentions Wikipedia articles, the primary focus is on data collection and representation, rather than search or retrieval technologies."
    },
    {
        "title": "GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay",
        "abstract": "The continual learning capability of large language models (LLMs) is crucial\nfor advancing artificial general intelligence. However, continual fine-tuning\nLLMs across various domains often suffers from catastrophic forgetting,\ncharacterized by: 1) significant forgetting of their general capabilities, and\n2) sharp performance declines in previously learned tasks. To simultaneously\naddress both issues in a simple yet stable manner, we propose General Sample\nReplay (GeRe), a framework that use usual pretraining texts for efficient\nanti-forgetting. Beyond revisiting the most prevalent replay-based practices\nunder GeRe, we further leverage neural states to introduce a enhanced\nactivation states constrained optimization method using threshold-based margin\n(TM) loss, which maintains activation state consistency during replay learning.\nWe are the first to validate that a small, fixed set of pre-collected general\nreplay samples is sufficient to resolve both concerns--retaining general\ncapabilities while promoting overall performance across sequential tasks.\nIndeed, the former can inherently facilitate the latter. Through controlled\nexperiments, we systematically compare TM with different replay strategies\nunder the GeRe framework, including vanilla label fitting, logit imitation via\nKL divergence and feature imitation via L1/L2 losses. Results demonstrate that\nTM consistently improves performance and exhibits better robustness. Our work\npaves the way for efficient replay of LLMs for the future. Our code and data\nare available at https://github.com/Qznan/GeRe.",
        "url": "http://arxiv.org/abs/2508.04676v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04676v1",
        "arxiv_id": "2508.04676v1",
        "authors": [
            "Yunan Zhang",
            "Shuoran Jiang",
            "Mengchen Zhao",
            "Yuefeng Li",
            "Yang Fan",
            "Xiangping Wu",
            "Qingcai Chen"
        ],
        "submitted": "2025-08-06 17:42:22",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on continual learning of large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions neural states and optimization methods, the context is not relevant to the user's primary research interests."
    },
    {
        "title": "Can NLP Tackle Hate Speech in the Real World? Stakeholder-Informed Feedback and Survey on Counterspeech",
        "abstract": "Counterspeech, i.e. the practice of responding to online hate speech, has\ngained traction in NLP as a promising intervention. While early work emphasised\ncollaboration with non-governmental organisation stakeholders, recent research\ntrends have shifted toward automated pipelines that reuse a small set of legacy\ndatasets, often without input from affected communities. This paper presents a\nsystematic review of 74 NLP studies on counterspeech, analysing the extent to\nwhich stakeholder participation influences dataset creation, model development,\nand evaluation. To complement this analysis, we conducted a participatory case\nstudy with five NGOs specialising in online Gender-Based Violence (oGBV),\nidentifying stakeholder-informed practices for counterspeech generation. Our\nfindings reveal a growing disconnect between current NLP research and the needs\nof communities most impacted by toxic online content. We conclude with concrete\nrecommendations for re-centring stakeholder expertise in counterspeech\nresearch.",
        "url": "http://arxiv.org/abs/2508.04638v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04638v1",
        "arxiv_id": "2508.04638v1",
        "authors": [
            "Tanvi Dinkar",
            "Aiqi Jiang",
            "Simona Frenda",
            "Poppy Gerrard-Abbott",
            "Nancie Gunson",
            "Gavin Abercrombie",
            "Ioannis Konstas"
        ],
        "submitted": "2025-08-06 17:04:58",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on NLP and counterspeech, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and query understanding. While it touches on stakeholder-informed practices, it does not address ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest for the user."
    },
    {
        "title": "HiD-VAE: Interpretable Generative Recommendation via Hierarchical and Disentangled Semantic IDs",
        "abstract": "Recommender systems are indispensable for helping users navigate the immense\nitem catalogs of modern online platforms. Recently, generative recommendation\nhas emerged as a promising paradigm, unifying the conventional\nretrieve-and-rank pipeline into an end-to-end model capable of dynamic\ngeneration. However, existing generative methods are fundamentally constrained\nby their unsupervised tokenization, which generates semantic IDs suffering from\ntwo critical flaws: (1) they are semantically flat and uninterpretable, lacking\na coherent hierarchy, and (2) they are prone to representation entanglement\n(i.e., ``ID collisions''), which harms recommendation accuracy and diversity.\nTo overcome these limitations, we propose HiD-VAE, a novel framework that\nlearns hierarchically disentangled item representations through two core\ninnovations. First, HiD-VAE pioneers a hierarchically-supervised quantization\nprocess that aligns discrete codes with multi-level item tags, yielding more\nuniform and disentangled IDs. Crucially, the trained codebooks can predict\nhierarchical tags, providing a traceable and interpretable semantic path for\neach recommendation. Second, to combat representation entanglement, HiD-VAE\nincorporates a novel uniqueness loss that directly penalizes latent space\noverlap. This mechanism not only resolves the critical ID collision problem but\nalso promotes recommendation diversity by ensuring a more comprehensive\nutilization of the item representation space. These high-quality, disentangled\nIDs provide a powerful foundation for downstream generative models. Extensive\nexperiments on three public benchmarks validate HiD-VAE's superior performance\nagainst state-of-the-art methods. The code is available at\nhttps://anonymous.4open.science/r/HiD-VAE-84B2.",
        "url": "http://arxiv.org/abs/2508.04618v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04618v1",
        "arxiv_id": "2508.04618v1",
        "authors": [
            "Dengzhao Fang",
            "Jingtong Gao",
            "Chengcheng Zhu",
            "Yu Li",
            "Xiangyu Zhao",
            "Yi Chang"
        ],
        "submitted": "2025-08-06 16:45:05",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a novel framework for generative recommendation, focusing on hierarchical and disentangled item representations. While it touches on some aspects of information retrieval, such as recommendation and item representation, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user."
    },
    {
        "title": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference",
        "abstract": "Artificial Intelligence (AI) conferences are essential for advancing\nresearch, sharing knowledge, and fostering academic community. However, their\nrapid expansion has rendered the centralized conference model increasingly\nunsustainable. This paper offers a data-driven diagnosis of a structural crisis\nthat threatens the foundational goals of scientific dissemination, equity, and\ncommunity well-being. We identify four key areas of strain: (1) scientifically,\nwith per-author publication rates more than doubling over the past decade to\nover 4.5 papers annually; (2) environmentally, with the carbon footprint of a\nsingle conference exceeding the daily emissions of its host city; (3)\npsychologically, with 71% of online community discourse reflecting negative\nsentiment and 35% referencing mental health concerns; and (4) logistically,\nwith attendance at top conferences such as NeurIPS 2024 beginning to outpace\nvenue capacity. These pressures point to a system that is misaligned with its\ncore mission. In response, we propose the Community-Federated Conference (CFC)\nmodel, which separates peer review, presentation, and networking into globally\ncoordinated but locally organized components, offering a more sustainable,\ninclusive, and resilient path forward for AI research.",
        "url": "http://arxiv.org/abs/2508.04586v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04586v1",
        "arxiv_id": "2508.04586v1",
        "authors": [
            "Nuo Chen",
            "Moming Duan",
            "Andre Huikai Lin",
            "Qian Wang",
            "Jiaying Wu",
            "Bingsheng He"
        ],
        "submitted": "2025-08-06 16:08:27",
        "source": "arxiv",
        "comment": "Preprint",
        "score": 2,
        "keyword_reasons": [
            "Found 'search' (score: +1)",
            "Found 'neurips' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper discusses the sustainability of AI conferences, which is a topic outside your primary focus. While it touches on some general issues related to scientific dissemination and community well-being, it does not address any specific technical aspects of IR or NLP."
    },
    {
        "title": "Analyzing and Mitigating Object Hallucination: A Training Bias Perspective",
        "abstract": "As scaling up training data has significantly improved the general multimodal\ncapabilities of Large Vision-Language Models (LVLMs), they still suffer from\nthe hallucination issue, generating text that is inconsistent with the visual\ninput. This phenomenon motivates us to systematically investigate the role of\ntraining data in hallucination. We introduce a new benchmark, POPEv2, which\nconsists of counterfactual images collected from the training data of LVLMs\nwith certain objects masked. Through comprehensive evaluation on POPEv2, we\nfind that current LVLMs suffer from training bias: they fail to fully leverage\ntheir training data and hallucinate more frequently on images seen during\ntraining. Specifically, they perform poorly on counterfactual images, often\nincorrectly answering ``Yes'' to questions about masked objects. To understand\nthis issue, we conduct probing experiments on the models' internal components,\nrevealing that this training bias is primarily located in the language modeling\n(LM) head. Based on these findings, we propose Obliviate, an efficient and\nlightweight unlearning method designed to mitigate object hallucination via\ntraining bias unlearning. Obliviate identifies the discrepancy between\nground-truth labels and model outputs on the training data as a proxy for bias\nand adopts a parameter- and data-efficient fine-tuning strategy that only\nupdates the LM head. Extensive experiments demonstrate the effectiveness of our\napproach. While only reusing the training data and updating approximately 2\\%\nof the parameters, Obliviate significantly reduces hallucination across both\ndiscriminative and generative tasks. Furthermore, it demonstrates strong\nscalability with respect to both model size (2B to 72B) and training data\nvolume, and exhibits promising generalization to hallucination types beyond\nobject-level hallucination. Our code and data will be publicly released.",
        "url": "http://arxiv.org/abs/2508.04567v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04567v1",
        "arxiv_id": "2508.04567v1",
        "authors": [
            "Yifan Li",
            "Kun Zhou",
            "Wayne Xin Zhao",
            "Lei Fang",
            "Ji-Rong Wen"
        ],
        "submitted": "2025-08-06 15:51:02",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on object hallucination in Large Vision-Language Models, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on training data and bias, the context is specific to computer vision and language models, making it only loosely relevant to the user's research interests."
    },
    {
        "title": "CALE : Concept-Aligned Embeddings for Both Within-Lemma and Inter-Lemma Sense Differentiation",
        "abstract": "Lexical semantics is concerned with both the multiple senses a word can adopt\nin different contexts, and the semantic relations that exist between meanings\nof different words. To investigate them, Contextualized Language Models are a\nvaluable tool that provides context-sensitive representations that can be used\nto investigate lexical meaning. Recent works like XL-LEXEME have leveraged the\ntask of Word-in-Context to fine-tune them to get more semantically accurate\nrepresentations, but Word-in-Context only compares occurrences of the same\nlemma, limiting the range of captured information. In this paper, we propose an\nextension, Concept Differentiation, to include inter-words scenarios. We\nprovide a dataset for this task, derived from SemCor data. Then we fine-tune\nseveral representation models on this dataset. We call these models\nConcept-Aligned Embeddings (CALE). By challenging our models and other models\non various lexical semantic tasks, we demonstrate that the proposed models\nprovide efficient multi-purpose representations of lexical meaning that reach\nbest performances in our experiments. We also show that CALE's fine-tuning\nbrings valuable changes to the spatial organization of embeddings.",
        "url": "http://arxiv.org/abs/2508.04494v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04494v1",
        "arxiv_id": "2508.04494v1",
        "authors": [
            "Bastien Liétard",
            "Gabriel Loiseau"
        ],
        "submitted": "2025-08-06 14:43:22",
        "source": "arxiv",
        "comment": "Under review in ARR July 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a new approach to lexical semantics, using contextualized language models to capture multiple senses of words and their semantic relations. While it touches on the topic of semantic understanding, it is primarily focused on lexical semantics and does not directly relate to information retrieval, search technologies, or user behavior modeling. The paper's relevance to the user's interests is somewhat limited, but it may still be of interest to those with a broader background in NLP and data mining."
    },
    {
        "title": "TRAIL: Joint Inference and Refinement of Knowledge Graphs with Large Language Models",
        "abstract": "Recent advances in large language models (LLMs) have unlocked powerful\nreasoning and decision-making capabilities. However, their inherent dependence\non static parametric memory fundamentally limits their adaptability, factual\naccuracy, and interpretability in knowledge-intensive scenarios. Knowledge\ngraphs (KGs), as structured repositories of explicit relational knowledge,\noffer a promising approach for augmenting LLMs with external, interpretable\nmemory. Nevertheless, most existing methods that combine LLMs with KGs treat\nreasoning and knowledge updating as separate processes, resulting in suboptimal\nutilization of new information and hindering real-time updates. In this work,\nwe propose TRAIL: a novel, unified framework for Thinking, Reasoning, And\nIncremental Learning that couples joint inference and dynamic KG refinement\nwith large language models. TRAIL enables LLM agents to iteratively explore,\nupdate, and refine knowledge graphs during the reasoning process, employing a\nconfidence-driven mechanism for the generation, validation, and pruning of new\nfacts. This plug-and-play architecture facilitates seamless integration with\nvarious LLMs, supporting continual adaptation without the need for retraining.\nExtensive experiments on multiple benchmarks demonstrate that TRAIL outperforms\nexisting KG-augmented and retrieval-augmented LLM baselines by 3% to 13%. More\nimportantly, these results represent a significant step toward developing\nadaptive, memory-augmented language models capable of continual learning and\nreliable, transparent reasoning.",
        "url": "http://arxiv.org/abs/2508.04474v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04474v1",
        "arxiv_id": "2508.04474v1",
        "authors": [
            "Xinkui Zhao",
            "Haode Li",
            "Yifan Zhang",
            "Guanjie Cheng",
            "Yueshen Xu"
        ],
        "submitted": "2025-08-06 14:25:05",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a framework for combining large language models with knowledge graphs, which is related to information retrieval and natural language processing. However, the focus on knowledge graphs and reasoning processes is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "What Do Humans Hear When Interacting? Experiments on Selective Listening for Evaluating ASR of Spoken Dialogue Systems",
        "abstract": "Spoken dialogue systems (SDSs) utilize automatic speech recognition (ASR) at\nthe front end of their pipeline. The role of ASR in SDSs is to recognize\ninformation in user speech related to response generation appropriately.\nExamining selective listening of humans, which refers to the ability to focus\non and listen to important parts of a conversation during the speech, will\nenable us to identify the ASR capabilities required for SDSs and evaluate them.\nIn this study, we experimentally confirmed selective listening when humans\ngenerate dialogue responses by comparing human transcriptions for generating\ndialogue responses and reference transcriptions. Based on our experimental\nresults, we discuss the possibility of a new ASR evaluation method that\nleverages human selective listening, which can identify the gap between\ntranscription ability between ASR systems and humans.",
        "url": "http://arxiv.org/abs/2508.04402v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04402v1",
        "arxiv_id": "2508.04402v1",
        "authors": [
            "Kiyotada Mori",
            "Seiya Kawano",
            "Chaoran Liu",
            "Carlos Toshinori Ishi",
            "Angel Fernando Garcia Contreras",
            "Koichiro Yoshino"
        ],
        "submitted": "2025-08-06 12:44:57",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, which are the user's core research themes. The focus on spoken dialogue systems and automatic speech recognition is outside the user's primary areas of interest."
    },
    {
        "title": "Chain of Questions: Guiding Multimodal Curiosity in Language Models",
        "abstract": "Reasoning capabilities in large language models (LLMs) have substantially\nadvanced through methods such as chain-of-thought and explicit step-by-step\nexplanations. However, these improvements have not yet fully transitioned to\nmultimodal contexts, where models must proactively decide which sensory\nmodalities such as vision, audio, or spatial perception to engage when\ninteracting with complex real-world environments. In this paper, we introduce\nthe Chain of Questions (CoQ) framework, a curiosity-driven reasoning approach\nthat encourages multimodal language models to dynamically generate targeted\nquestions regarding their surroundings. These generated questions guide the\nmodel to selectively activate relevant modalities, thereby gathering critical\ninformation necessary for accurate reasoning and response generation. We\nevaluate our framework on a novel multimodal benchmark dataset, assembled by\nintegrating WebGPT, ScienceQA, AVSD, and ScanQA datasets. Experimental results\ndemonstrate that our CoQ method improves a foundation model's ability to\neffectively identify and integrate pertinent sensory information. This leads to\nimproved accuracy, interpretability, and alignment of the reasoning process\nwith diverse multimodal tasks.",
        "url": "http://arxiv.org/abs/2508.04350v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04350v1",
        "arxiv_id": "2508.04350v1",
        "authors": [
            "Nima Iji",
            "Kia Dashtipour"
        ],
        "submitted": "2025-08-06 11:42:54",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores multimodal language models and curiosity-driven reasoning, which is not directly related to the user's primary focus on Information Retrieval and Search technologies. While the paper touches on query understanding and relevance optimization, the context is different and the techniques are not directly applicable to the user's interests."
    },
    {
        "title": "GTPO and GRPO-S: Token and Sequence-Level Reward Shaping with Policy Entropy",
        "abstract": "Reinforcement learning (RL) with algorithms like Group Relative Policy\nOptimization (GRPO) improves Large Language Model (LLM) reasoning, but is\nlimited by a coarse-grained credit assignment that applies a uniform reward to\nall tokens in a sequence. This is a major flaw in long-chain reasoning tasks.\nThis paper solves this with \\textbf{Dynamic Entropy Weighting}. Our core idea\nis that high-entropy tokens in correct responses can guide the policy toward a\nhigher performance ceiling. This allows us to create more fine-grained reward\nsignals for precise policy updates via two ways: 1) \\textbf{Group Token Policy\nOptimization} (\\textbf{GTPO}), we assigns a entropy-weighted reward to each\ntoken for fine-grained credit assignment. 2) \\textbf{Sequence-Level Group\nRelative Policy Optimization} (\\textbf{GRPO-S}), we assigns a entropy-weighted\nreward to each sequence based on its average token entropy. Experiments show\nour methods significantly outperform the strong DAPO baseline. The results\nconfirm that our entropy-weighting mechanism is the key driver of this\nperformance boost, offering a better path to enhance deep reasoning in models.",
        "url": "http://arxiv.org/abs/2508.04349v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04349v1",
        "arxiv_id": "2508.04349v1",
        "authors": [
            "Hongze Tan",
            "Jianfei Pan"
        ],
        "submitted": "2025-08-06 11:42:47",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores reinforcement learning with large language models, focusing on fine-grained credit assignment and entropy-weighted rewards. While it's related to query understanding and ranking models, the specific application and techniques are not directly aligned with my research interests in information retrieval and search technologies. The paper's emphasis on deep reasoning and sequence-level optimization is somewhat relevant, but it doesn't seem to address my primary focus areas."
    },
    {
        "title": "ReasoningGuard: Safeguarding Large Reasoning Models with Inference-time Safety Aha Moments",
        "abstract": "Large Reasoning Models (LRMs) have demonstrated impressive performance in\nreasoning-intensive tasks, but they remain vulnerable to harmful content\ngeneration, particularly in the mid-to-late steps of their reasoning processes.\nExisting defense mechanisms, however, rely on costly fine-tuning and additional\nexpert knowledge, which restricts their scalability. In this work, we propose\nReasoningGuard, an inference-time safeguard for LRMs, which injects timely\nsafety aha moments to steer harmless while helpful reasoning processes.\nLeveraging the model's internal attention behavior, our approach accurately\nidentifies critical points in the reasoning path, and triggers spontaneous,\nsafety-oriented reflection. To safeguard both the subsequent reasoning steps\nand the final answers, we further implement a scaling sampling strategy during\nthe decoding phase, selecting the optimal reasoning path. Inducing minimal\nextra inference cost, ReasoningGuard effectively mitigates three types of\njailbreak attacks, including the latest ones targeting the reasoning process of\nLRMs. Our approach outperforms seven existing safeguards, achieving\nstate-of-the-art safety defenses while effectively avoiding the common\nexaggerated safety issues.",
        "url": "http://arxiv.org/abs/2508.04204v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04204v1",
        "arxiv_id": "2508.04204v1",
        "authors": [
            "Yuquan Wang",
            "Mi Zhang",
            "Yining Wang",
            "Geng Hong",
            "Xiaoyu You",
            "Min Yang"
        ],
        "submitted": "2025-08-06 08:35:10",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus on Large Reasoning Models and inference-time safety is outside the scope of the user's research interests."
    },
    {
        "title": "Hacking Hallucinations of MLLMs with Causal Sufficiency and Necessity",
        "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated impressive\ncapabilities across vision-language tasks. However, they may suffer from\nhallucinations--generating outputs that are semantically inconsistent with the\ninput image or text. Through causal analyses, we find that: (i) hallucinations\nwith omission may arise from the failure to adequately capture essential causal\nfactors, and (ii) hallucinations with fabrication are likely caused by the\nmodel being misled by non-causal cues. To address these challenges, we propose\na novel reinforcement learning framework guided by causal completeness, which\njointly considers both causal sufficiency and causal necessity of tokens.\nSpecifically, we evaluate each token's standalone contribution and\ncounterfactual indispensability to define a token-level causal completeness\nreward. This reward is used to construct a causally informed advantage function\nwithin the GRPO optimization framework, encouraging the model to focus on\ntokens that are both causally sufficient and necessary for accurate generation.\nExperimental results across various benchmark datasets and tasks demonstrate\nthe effectiveness of our approach, which effectively mitigates hallucinations\nin MLLMs.",
        "url": "http://arxiv.org/abs/2508.04182v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04182v1",
        "arxiv_id": "2508.04182v1",
        "authors": [
            "Peizheng Guo",
            "Jingyao Wang",
            "Wenwen Qiang",
            "Huijie Guo",
            "Changwen Zheng",
            "Jiahuan Zhou",
            "Gang Hua"
        ],
        "submitted": "2025-08-06 08:09:12",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on multimodal large language models and hallucinations, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on causal completeness and necessity, these concepts are not typically applied in the context of IR or search. The paper's relevance to the user's research interests is limited."
    },
    {
        "title": "COPO: Consistency-Aware Policy Optimization",
        "abstract": "Reinforcement learning has significantly enhanced the reasoning capabilities\nof Large Language Models (LLMs) in complex problem-solving tasks. Recently, the\nintroduction of DeepSeek R1 has inspired a surge of interest in leveraging\nrule-based rewards as a low-cost alternative for computing advantage functions\nand guiding policy optimization. However, a common challenge observed across\nmany replication and extension efforts is that when multiple sampled responses\nunder a single prompt converge to identical outcomes, whether correct or\nincorrect, the group-based advantage degenerates to zero. This leads to\nvanishing gradients and renders the corresponding samples ineffective for\nlearning, ultimately limiting training efficiency and downstream performance.\nTo address this issue, we propose a consistency-aware policy optimization\nframework that introduces a structured global reward based on outcome\nconsistency, the global loss based on it ensures that, even when model outputs\nshow high intra-group consistency, the training process still receives\nmeaningful learning signals, which encourages the generation of correct and\nself-consistent reasoning paths from a global perspective. Furthermore, we\nincorporate an entropy-based soft blending mechanism that adaptively balances\nlocal advantage estimation with global optimization, enabling dynamic\ntransitions between exploration and convergence throughout training. Our method\nintroduces several key innovations in both reward design and optimization\nstrategy. We validate its effectiveness through substantial performance gains\non multiple mathematical reasoning benchmarks, highlighting the proposed\nframework's robustness and general applicability. Code of this work has been\nreleased at https://github.com/hijih/copo-code.git.",
        "url": "http://arxiv.org/abs/2508.04138v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04138v1",
        "arxiv_id": "2508.04138v1",
        "authors": [
            "Jinghang Han",
            "Jiawei Chen",
            "Hang Shao",
            "Hao Ma",
            "Mingcheng Li",
            "Xintian Shen",
            "Lihao Zheng",
            "Wei Chen",
            "Tao Wei",
            "Lihua Zhang"
        ],
        "submitted": "2025-08-06 07:05:18",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on reinforcement learning and policy optimization for Large Language Models, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions rewards and optimization, the context is different from the user's research interests."
    },
    {
        "title": "Unveiling Over-Memorization in Finetuning LLMs for Reasoning Tasks",
        "abstract": "The pretrained large language models (LLMs) are finetuned with labeled data\nfor better instruction following ability and alignment with human values. In\nthis paper, we study the learning dynamics of LLM finetuning on reasoning tasks\nand reveal the uncovered over-memorization phenomenon during a specific stage\nof LLM finetuning. At this stage, the LLMs have excessively memorized training\ndata and exhibit high test perplexity while maintaining good test accuracy. We\ninvestigate the conditions that lead to LLM over-memorization and find that\ntraining epochs and large learning rates contribute to this issue. Although\nmodels with over-memorization demonstrate comparable test accuracy to normal\nmodels, they suffer from reduced robustness, poor out-of-distribution\ngeneralization, and decreased generation diversity. Our experiments unveil the\nover-memorization to be broadly applicable across different tasks, models, and\nfinetuning methods. Our research highlights that overparameterized, extensively\nfinetuned LLMs exhibit unique learning dynamics distinct from traditional\nmachine learning models. Based on our observations of over-memorization, we\nprovide recommendations on checkpoint and learning rate selection during\nfinetuning.",
        "url": "http://arxiv.org/abs/2508.04117v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04117v1",
        "arxiv_id": "2508.04117v1",
        "authors": [
            "Zhiwen Ruan",
            "Yun Chen",
            "Yutao Hou",
            "Peng Li",
            "Yang Liu",
            "Guanhua Chen"
        ],
        "submitted": "2025-08-06 06:34:12",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the phenomenon of over-memorization in fine-tuning large language models for reasoning tasks, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on machine learning models, it does not address ranking models, user behavior modeling, or real-time relevance optimization, making it only loosely relevant to the user's research interests."
    }
]