[
    {
        "title": "Revisiting Query Variants: The Advantage of Retrieval Over Generation of Query Variants for Effective QPP",
        "abstract": "Leveraging query variants (QVs), i.e., queries with potentially similar\ninformation needs to the target query, has been shown to improve the\neffectiveness of query performance prediction (QPP) approaches. Existing\nQV-based QPP methods generate QVs facilitated by either query expansion or\nnon-contextual embeddings, which may introduce topical drifts and\nhallucinations. In this paper, we propose a method that retrieves QVs from a\ntraining set (e.g., MS MARCO) for a given target query of QPP. To achieve a\nhigh recall in retrieving queries with the most similar information needs as\nthe target query from a training set, we extend the directly retrieved QVs\n(1-hop QVs) by a second retrieval using their denoted relevant documents (which\nyields 2-hop QVs). Our experiments, conducted on TREC DL'19 and DL'20, show\nthat the QPP methods with QVs retrieved by our method outperform the\nbest-performing existing generated-QV-based QPP approaches by as much as around\n20\\%, on neural ranking models like MonoT5.",
        "url": "http://arxiv.org/abs/2510.02512v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02512v1",
        "arxiv_id": "2510.02512v1",
        "authors": [
            "Fangzheng Tian",
            "Debasis Ganguly",
            "Craig Macdonald"
        ],
        "submitted": "2025-10-02 19:36:58",
        "source": "arxiv",
        "comment": "11 pages, 4 figures",
        "score": 16,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'trec' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The focus on query variants and retrieval-based methods aligns with your expertise in Learning to Rank and user behavior modeling. The application of the proposed method to neural ranking models like MonoT5 further supports its relevance."
    },
    {
        "title": "A Simple but Effective Elaborative Query Reformulation Approach for Natural Language Recommendation",
        "abstract": "Natural Language (NL) recommender systems aim to retrieve relevant items from\nfree-form user queries and item descriptions. Existing systems often rely on\ndense retrieval (DR), which struggles to interpret challenging queries that\nexpress broad (e.g., \"cities for youth friendly activities\") or indirect (e.g.,\n\"cities for a high school graduation trip\") user intents. While query\nreformulation (QR) has been widely adopted to improve such systems, existing QR\nmethods tend to focus only on expanding the range of query subtopics (breadth)\nor elaborating on the potential meaning of a query (depth), but not both. In\nthis paper, we propose EQR (Elaborative Subtopic Query Reformulation), a large\nlanguage model-based QR method that combines both breadth and depth by\ngenerating potential query subtopics with information-rich elaborations. We\nalso introduce three new natural language recommendation benchmarks in travel,\nhotel, and restaurant domains to establish evaluation of NL recommendation with\nchallenging queries. Experiments show EQR substantially outperforms\nstate-of-the-art QR methods in various evaluation metrics, highlighting that a\nsimple yet effective QR approach can significantly improve NL recommender\nsystems for queries with broad and indirect user intents.",
        "url": "http://arxiv.org/abs/2510.02656v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02656v1",
        "arxiv_id": "2510.02656v1",
        "authors": [
            "Qianfeng Wen",
            "Yifan Liu",
            "Justin Cui",
            "Joshua Zhang",
            "Anton Korikov",
            "George-Kirollos Saad",
            "Scott Sanner"
        ],
        "submitted": "2025-10-03 01:21:55",
        "source": "arxiv",
        "comment": "11 pages, 5 figures",
        "score": 12,
        "keyword_reasons": [
            "Found 'dense retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores query reformulation in Natural Language Recommendation, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the focus on recommender systems and dense retrieval methods is not a central match to your primary research themes, although it does touch on query understanding and real-time relevance optimization."
    },
    {
        "title": "CHORD: Customizing Hybrid-precision On-device Model for Sequential Recommendation with Device-cloud Collaboration",
        "abstract": "With the advancement of mobile device capabilities, deploying reranking\nmodels directly on devices has become feasible, enabling real-time contextual\nrecommendations. When migrating models from cloud to devices, resource\nheterogeneity inevitably necessitates model compression. Recent quantization\nmethods show promise for efficient deployment, yet they overlook\ndevice-specific user interests, resulting in compromised recommendation\naccuracy. While on-device finetuning captures personalized user preference, it\nimposes additional computational burden through local retraining. To address\nthese challenges, we propose a framework for \\underline{\\textbf{C}}ustomizing\n\\underline{\\textbf{H}}ybrid-precision \\underline{\\textbf{O}}n-device model for\nsequential \\underline{\\textbf{R}}ecommendation with\n\\underline{\\textbf{D}}evice-cloud collaboration (\\textbf{CHORD}), leveraging\nchannel-wise mixed-precision quantization to simultaneously achieve\npersonalization and resource-adaptive deployment. CHORD distributes randomly\ninitialized models across heterogeneous devices and identifies user-specific\ncritical parameters through auxiliary hypernetwork modules on the cloud. Our\nparameter sensitivity analysis operates across multiple granularities (layer,\nfilter, and element levels), enabling precise mapping from user profiles to\nquantization strategy. Through on-device mixed-precision quantization, CHORD\ndelivers dynamic model adaptation and accelerated inference without\nbackpropagation, eliminating costly retraining cycles. We minimize\ncommunication overhead by encoding quantization strategies using only 2 bits\nper channel instead of 32-bit weights. Experiments on three real-world datasets\nwith two popular backbones (SASRec and Caser) demonstrate the accuracy,\nefficiency, and adaptivity of CHORD.",
        "url": "http://arxiv.org/abs/2510.03038v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03038v1",
        "arxiv_id": "2510.03038v1",
        "authors": [
            "Tianqi Liu",
            "Kairui Fu",
            "Shengyu Zhang",
            "Wenyan Fan",
            "Zhaocheng Du",
            "Jieming Zhu",
            "Fan Wu",
            "Fei Wu"
        ],
        "submitted": "2025-10-03 14:20:45",
        "source": "arxiv",
        "comment": "accepted by ACM MM'25",
        "score": 11,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'personalization' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on sequential recommendation and model deployment on devices, which is somewhat related to information retrieval, but it primarily deals with recommender systems and model compression, not directly aligning with the user's core research themes in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Grounding Large Language Models in Clinical Evidence: A Retrieval-Augmented Generation System for Querying UK NICE Clinical Guidelines",
        "abstract": "This paper presents the development and evaluation of a Retrieval-Augmented\nGeneration (RAG) system for querying the United Kingdom's National Institute\nfor Health and Care Excellence (NICE) clinical guidelines using Large Language\nModels (LLMs). The extensive length and volume of these guidelines can impede\ntheir utilisation within a time-constrained healthcare system, a challenge this\nproject addresses through the creation of a system capable of providing users\nwith precisely matched information in response to natural language queries. The\nsystem's retrieval architecture, composed of a hybrid embedding mechanism, was\nevaluated against a database of 10,195 text chunks derived from three hundred\nguidelines. It demonstrates high performance, with a Mean Reciprocal Rank (MRR)\nof 0.814, a Recall of 81% at the first chunk and of 99.1% within the top ten\nretrieved chunks, when evaluated on 7901 queries.\n  The most significant impact of the RAG system was observed during the\ngeneration phase. When evaluated on a manually curated dataset of seventy\nquestion-answer pairs, RAG-enhanced models showed substantial gains in\nperformance. Faithfulness, the measure of whether an answer is supported by the\nsource text, was increased by 64.7 percentage points to 99.5% for the\nRAG-enhanced O4-Mini model and significantly outperformed the medical-focused\nMeditron3-8B LLM, which scored 43%. This, combined with a perfect Context\nPrecision score of 1 for all RAG-enhanced models, confirms the system's ability\nto prevent information fabrication by grounding its answers in relevant source\nmaterial. This study thus establishes RAG as an effective, reliable, and\nscalable approach for applying generative AI in healthcare, enabling\ncost-effective access to medical guidelines.",
        "url": "http://arxiv.org/abs/2510.02967v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02967v1",
        "arxiv_id": "2510.02967v1",
        "authors": [
            "Matthew Lewis",
            "Samuel Thio",
            "Richard JB Dobson",
            "Spiros Denaxas"
        ],
        "submitted": "2025-10-03 12:57:13",
        "source": "arxiv",
        "comment": null,
        "score": 11,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to Information Retrieval, particularly in the context of query understanding and ranking models, as it presents a Retrieval-Augmented Generation system for querying clinical guidelines. The system's performance evaluation, including Mean Reciprocal Rank and Recall metrics, is also of interest. However, the focus on healthcare and clinical guidelines is somewhat outside the user's primary domain of e-commerce, which slightly reduces the score."
    },
    {
        "title": "Geolog-IA: Conversational System for Academic Theses",
        "abstract": "This study presents the development of Geolog-IA, a novel conversational\nsystem based on artificial intelligence that responds naturally to questions\nabout geology theses from the Central University of Ecuador. Our proposal uses\nthe Llama 3.1 and Gemini 2.5 language models, which are complemented by a\nRetrieval Augmented Generation (RAG) architecture and an SQLite database. This\nstrategy allows us to overcome problems such as hallucinations and outdated\nknowledge. The evaluation of Geolog-IA's performance with the BLEU metric\nreaches an average of 0.87, indicating high consistency and accuracy in the\nresponses generated. The system offers an intuitive, web-based interface that\nfacilitates interaction and information retrieval for directors, teachers,\nstudents, and administrative staff at the institution. This tool can be a key\nsupport in education, training, and research and establishes a basis for future\napplications in other disciplines.",
        "url": "http://arxiv.org/abs/2510.02653v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02653v1",
        "arxiv_id": "2510.02653v1",
        "authors": [
            "Micaela Fuel Pozo",
            "Andrea Guatumillo Saltos",
            "Yeseña Tipan Llumiquinga",
            "Kelly Lascano Aguirre",
            "Marilyn Castillo Jara",
            "Christian Mejia-Escobar"
        ],
        "submitted": "2025-10-03 01:11:47",
        "source": "arxiv",
        "comment": "17 pages, in Spanish language",
        "score": 10,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval augmented generation' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves conversational systems and language models, its focus on geology theses and education makes it an off-topic application."
    },
    {
        "title": "Knowledge-Graph Based RAG System Evaluation Framework",
        "abstract": "Large language models (LLMs) has become a significant research focus and is\nutilized in various fields, such as text generation and dialog systems. One of\nthe most essential applications of LLM is Retrieval Augmented Generation (RAG),\nwhich greatly enhances generated content's reliability and relevance. However,\nevaluating RAG systems remains a challenging task. Traditional evaluation\nmetrics struggle to effectively capture the key features of modern\nLLM-generated content that often exhibits high fluency and naturalness.\nInspired by the RAGAS tool, a well-known RAG evaluation framework, we extended\nthis framework into a KG-based evaluation paradigm, enabling multi-hop\nreasoning and semantic community clustering to derive more comprehensive\nscoring metrics. By incorporating these comprehensive evaluation criteria, we\ngain a deeper understanding of RAG systems and a more nuanced perspective on\ntheir performance. To validate the effectiveness of our approach, we compare\nits performance with RAGAS scores and construct a human-annotated subset to\nassess the correlation between human judgments and automated metrics. In\naddition, we conduct targeted experiments to demonstrate that our KG-based\nevaluation method is more sensitive to subtle semantic differences in generated\noutputs. Finally, we discuss the key challenges in evaluating RAG systems and\nhighlight potential directions for future research.",
        "url": "http://arxiv.org/abs/2510.02549v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02549v1",
        "arxiv_id": "2510.02549v1",
        "authors": [
            "Sicheng Dong",
            "Vahid Zolfaghari",
            "Nenad Petrovic",
            "Alois Knoll"
        ],
        "submitted": "2025-10-02 20:36:21",
        "source": "arxiv",
        "comment": null,
        "score": 10,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval augmented generation' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper discusses Retrieval Augmented Generation (RAG) systems, which is related to query understanding and ranking models in Information Retrieval. Although it's not directly focused on e-commerce, it explores the evaluation of RAG systems using knowledge graphs, which is relevant to deep semantic understanding and real-time relevance optimization. However, it's not a central match to the user's core research themes."
    },
    {
        "title": "Finding Diamonds in Conversation Haystacks: A Benchmark for Conversational Data Retrieval",
        "abstract": "We present the Conversational Data Retrieval (CDR) benchmark, the first\ncomprehensive test set for evaluating systems that retrieve conversation data\nfor product insights. With 1.6k queries across five analytical tasks and 9.1k\nconversations, our benchmark provides a reliable standard for measuring\nconversational data retrieval performance. Our evaluation of 16 popular\nembedding models shows that even the best models reach only around NDCG@10 of\n0.51, revealing a substantial gap between document and conversational data\nretrieval capabilities. Our work identifies unique challenges in conversational\ndata retrieval (implicit state recognition, turn dynamics, contextual\nreferences) while providing practical query templates and detailed error\nanalysis across different task categories. The benchmark dataset and code are\navailable at https://github.com/l-yohai/CDR-Benchmark.",
        "url": "http://arxiv.org/abs/2510.02938v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02938v1",
        "arxiv_id": "2510.02938v1",
        "authors": [
            "Yohan Lee",
            "Yongwoo Song",
            "Sangyeop Kim"
        ],
        "submitted": "2025-10-03 12:29:44",
        "source": "arxiv",
        "comment": "Accepted by EMNLP 2025 Industry Track",
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in conversational data retrieval, which requires deep semantic understanding and real-time relevance optimization. The focus on conversational data retrieval and the evaluation of embedding models aligns with your interests in query understanding and ranking models. However, the e-commerce domain focus is somewhat narrower than your broader interests in IR and NLP."
    },
    {
        "title": "StepChain GraphRAG: Reasoning Over Knowledge Graphs for Multi-Hop Question Answering",
        "abstract": "Recent progress in retrieval-augmented generation (RAG) has led to more\naccurate and interpretable multi-hop question answering (QA). Yet, challenges\npersist in integrating iterative reasoning steps with external knowledge\nretrieval. To address this, we introduce StepChain GraphRAG, a framework that\nunites question decomposition with a Breadth-First Search (BFS) Reasoning Flow\nfor enhanced multi-hop QA. Our approach first builds a global index over the\ncorpus; at inference time, only retrieved passages are parsed on-the-fly into a\nknowledge graph, and the complex query is split into sub-questions. For each\nsub-question, a BFS-based traversal dynamically expands along relevant edges,\nassembling explicit evidence chains without overwhelming the language model\nwith superfluous context. Experiments on MuSiQue, 2WikiMultiHopQA, and HotpotQA\nshow that StepChain GraphRAG achieves state-of-the-art Exact Match and F1\nscores. StepChain GraphRAG lifts average EM by 2.57% and F1 by 2.13% over the\nSOTA method, achieving the largest gain on HotpotQA (+4.70% EM, +3.44% F1).\nStepChain GraphRAG also fosters enhanced explainability by preserving the\nchain-of-thought across intermediate retrieval steps. We conclude by discussing\nhow future work can mitigate the computational overhead and address potential\nhallucinations from large language models to refine efficiency and reliability\nin multi-hop QA.",
        "url": "http://arxiv.org/abs/2510.02827v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02827v1",
        "arxiv_id": "2510.02827v1",
        "authors": [
            "Tengjun Ni",
            "Xin Yuan",
            "Shenghong Li",
            "Kai Wu",
            "Ren Ping Liu",
            "Wei Ni",
            "Wenjie Zhang"
        ],
        "submitted": "2025-10-03 09:06:37",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on multi-hop question answering and knowledge graph reasoning, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on question answering and knowledge graphs does not directly align with the user's core research themes, and the relevance to user's interests is limited."
    },
    {
        "title": "Less LLM, More Documents: Searching for Improved RAG",
        "abstract": "Retrieval-Augmented Generation (RAG) couples document retrieval with large\nlanguage models (LLMs). While scaling generators improves accuracy, it also\nraises cost and limits deployability. We explore an orthogonal axis: enlarging\nthe retriever's corpus to reduce reliance on large LLMs. Experimental results\nshow that corpus scaling consistently strengthens RAG and can often serve as a\nsubstitute for increasing model size, though with diminishing returns at larger\nscales. Small- and mid-sized generators paired with larger corpora often rival\nmuch larger models with smaller corpora; mid-sized models tend to gain the\nmost, while tiny and large models benefit less. Our analysis shows that\nimprovements arise primarily from increased coverage of answer-bearing\npassages, while utilization efficiency remains largely unchanged. These\nfindings establish a principled corpus-generator trade-off: investing in larger\ncorpora offers an effective path to stronger RAG, often comparable to enlarging\nthe LLM itself.",
        "url": "http://arxiv.org/abs/2510.02657v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02657v1",
        "arxiv_id": "2510.02657v1",
        "authors": [
            "Jingjie Ning",
            "Yibo Kong",
            "Yunfan Long",
            "Jamie Callan"
        ],
        "submitted": "2025-10-03 01:26:13",
        "source": "arxiv",
        "comment": "16 pages. Submitted to ECIR 2026",
        "score": 8,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to Information Retrieval, specifically in the context of Retrieval-Augmented Generation (RAG), which is a query understanding and ranking model. The focus on corpus scaling as an alternative to increasing model size aligns with the user's interest in real-time relevance optimization and deep semantic understanding. However, the e-commerce domain is not explicitly mentioned, which is why the score is not a perfect 10."
    },
    {
        "title": "FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents",
        "abstract": "Web agents powered by large language models (LLMs) must process lengthy web\npage observations to complete user goals; these pages often exceed tens of\nthousands of tokens. This saturates context limits and increases computational\ncost processing; moreover, processing full pages exposes agents to security\nrisks such as prompt injection. Existing pruning strategies either discard\nrelevant content or retain irrelevant context, leading to suboptimal action\nprediction. We introduce FocusAgent, a simple yet effective approach that\nleverages a lightweight LLM retriever to extract the most relevant lines from\naccessibility tree (AxTree) observations, guided by task goals. By pruning\nnoisy and irrelevant content, FocusAgent enables efficient reasoning while\nreducing vulnerability to injection attacks. Experiments on WorkArena and\nWebArena benchmarks show that FocusAgent matches the performance of strong\nbaselines, while reducing observation size by over 50%. Furthermore, a variant\nof FocusAgent significantly reduces the success rate of prompt-injection\nattacks, including banner and pop-up attacks, while maintaining task success\nperformance in attack-free settings. Our results highlight that targeted\nLLM-based retrieval is a practical and robust strategy for building web agents\nthat are efficient, effective, and secure.",
        "url": "http://arxiv.org/abs/2510.03204v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03204v1",
        "arxiv_id": "2510.03204v1",
        "authors": [
            "Imene Kerboua",
            "Sahar Omidi Shayegan",
            "Megh Thakkar",
            "Xing Han Lù",
            "Léo Boisvert",
            "Massimo Caccia",
            "Jérémy Espinas",
            "Alexandre Aussem",
            "Véronique Eglin",
            "Alexandre Lacoste"
        ],
        "submitted": "2025-10-03 17:41:30",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses web agents and large language models, but its focus on pruning irrelevant content and improving efficiency in web agents doesn't directly align with your core research themes in Information Retrieval and Search technologies. While it touches on relevant topics like query understanding and real-time relevance optimization, the context is more specific to web agents and security, which is not a central match to your interests."
    },
    {
        "title": "AgenticRAG: Tool-Augmented Foundation Models for Zero-Shot Explainable Recommender Systems",
        "abstract": "Foundation models have revolutionized artificial intelligence, yet their\napplication in recommender systems remains limited by reasoning opacity and\nknowledge constraints. This paper introduces AgenticRAG, a novel framework that\ncombines tool-augmented foundation models with retrieval-augmented generation\nfor zero-shot explainable recommendations. Our approach integrates external\ntool invocation, knowledge retrieval, and chain-of-thought reasoning to create\nautonomous recommendation agents capable of transparent decision-making without\ntask-specific training. Experimental results on three real-world datasets\ndemonstrate that AgenticRAG achieves consistent improvements over\nstate-of-the-art baselines, with NDCG@10 improvements of 0.4\\% on Amazon\nElectronics, 0.8\\% on MovieLens-1M, and 1.6\\% on Yelp datasets. The framework\nexhibits superior explainability while maintaining computational efficiency\ncomparable to traditional methods.",
        "url": "http://arxiv.org/abs/2510.02668v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02668v1",
        "arxiv_id": "2510.02668v1",
        "authors": [
            "Bo Ma",
            "Hang Li",
            "ZeHua Hu",
            "XiaoFan Gui",
            "LuYao Liu",
            "Simon Liu"
        ],
        "submitted": "2025-10-03 01:52:37",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper introduces a novel framework for recommender systems, leveraging foundation models and retrieval-augmented generation. While it touches on explainability and transparency, the primary focus is on recommender systems rather than information retrieval. The paper's emphasis on tool-augmented foundation models and zero-shot explainable recommendations is somewhat related to query understanding and ranking models, but it does not directly align with the user's core research themes in IR and search technologies."
    },
    {
        "title": "Hierarchical Semantic Retrieval with Cobweb",
        "abstract": "Neural document retrieval often treats a corpus as a flat cloud of vectors\nscored at a single granularity, leaving corpus structure underused and\nexplanations opaque. We use Cobweb--a hierarchy-aware framework--to organize\nsentence embeddings into a prototype tree and rank documents via coarse-to-fine\ntraversal. Internal nodes act as concept prototypes, providing multi-granular\nrelevance signals and a transparent rationale through retrieval paths. We\ninstantiate two inference approaches: a generalized best-first search and a\nlightweight path-sum ranker. We evaluate our approaches on MS MARCO and QQP\nwith encoder (e.g., BERT/T5) and decoder (GPT-2) representations. Our results\nshow that our retrieval approaches match the dot product search on strong\nencoder embeddings while remaining robust when kNN degrades: with GPT-2\nvectors, dot product performance collapses whereas our approaches still\nretrieve relevant results. Overall, our experiments suggest that Cobweb\nprovides competitive effectiveness, improved robustness to embedding quality,\nscalability, and interpretable retrieval via hierarchical prototypes.",
        "url": "http://arxiv.org/abs/2510.02539v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02539v1",
        "arxiv_id": "2510.02539v1",
        "authors": [
            "Anant Gupta",
            "Karthik Singaravadivelan",
            "Zekun Wang"
        ],
        "submitted": "2025-10-02 20:14:52",
        "source": "arxiv",
        "comment": "20 pages, 7 tables, 4 figures",
        "score": 7,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper explores hierarchical semantic retrieval, which aligns with your interest in query understanding and ranking models. The use of a hierarchy-aware framework and prototype tree for ranking documents is particularly relevant to your focus on deep semantic understanding and real-time relevance optimization in information retrieval."
    },
    {
        "title": "Model-Based Ranking of Source Languages for Zero-Shot Cross-Lingual Transfer",
        "abstract": "We present NN-Rank, an algorithm for ranking source languages for\ncross-lingual transfer, which leverages hidden representations from\nmultilingual models and unlabeled target-language data. We experiment with two\npretrained multilingual models and two tasks: part-of-speech tagging (POS) and\nnamed entity recognition (NER). We consider 51 source languages and evaluate on\n56 and 72 target languages for POS and NER, respectively. When using in-domain\ndata, NN-Rank beats state-of-the-art baselines that leverage lexical and\nlinguistic features, with average improvements of up to 35.56 NDCG for POS and\n18.14 NDCG for NER. As prior approaches can fall back to language-level\nfeatures if target language data is not available, we show that NN-Rank remains\ncompetitive using only the Bible, an out-of-domain corpus available for a large\nnumber of languages. Ablations on the amount of unlabeled target data show\nthat, for subsets consisting of as few as 25 examples, NN-Rank produces\nhigh-quality rankings which achieve 92.8% of the NDCG achieved using all\navailable target data for ranking.",
        "url": "http://arxiv.org/abs/2510.03202v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03202v1",
        "arxiv_id": "2510.03202v1",
        "authors": [
            "Abteen Ebrahimi",
            "Adam Wiemerslage",
            "Katharina von der Wense"
        ],
        "submitted": "2025-10-03 17:39:44",
        "source": "arxiv",
        "comment": "Accepted to EMNLP 2025 (Main)",
        "score": 6,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it involves ranking models and cross-lingual transfer. However, the focus on source language ranking for zero-shot cross-lingual transfer is not directly aligned with your primary interests in query understanding, ranking models, and user behavior modeling. While the paper does leverage multilingual models, it is more focused on NLP applications rather than search technologies."
    },
    {
        "title": "EditLens: Quantifying the Extent of AI Editing in Text",
        "abstract": "A significant proportion of queries to large language models ask them to edit\nuser-provided text, rather than generate new text from scratch. While previous\nwork focuses on detecting fully AI-generated text, we demonstrate that\nAI-edited text is distinguishable from human-written and AI-generated text.\nFirst, we propose using lightweight similarity metrics to quantify the\nmagnitude of AI editing present in a text given the original human-written text\nand validate these metrics with human annotators. Using these similarity\nmetrics as intermediate supervision, we then train EditLens, a regression model\nthat predicts the amount of AI editing present within a text. Our model\nachieves state-of-the-art performance on both binary (F1=94.7%) and ternary\n(F1=90.4%) classification tasks in distinguishing human, AI, and mixed writing.\nNot only do we show that AI-edited text can be detected, but also that the\ndegree of change made by AI to human writing can be detected, which has\nimplications for authorship attribution, education, and policy. Finally, as a\ncase study, we use our model to analyze the effects of AI-edits applied by\nGrammarly, a popular writing assistance tool. To encourage further research, we\ncommit to publicly releasing our models and dataset.",
        "url": "http://arxiv.org/abs/2510.03154v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03154v1",
        "arxiv_id": "2510.03154v1",
        "authors": [
            "Katherine Thai",
            "Bradley Emi",
            "Elyas Masrour",
            "Mohit Iyyer"
        ],
        "submitted": "2025-10-03 16:27:48",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Information Retrieval (IR), particularly in the context of query understanding and text analysis. However, it focuses on text editing and authorship attribution, which is not a central match to your primary focus on query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Evaluating Large Language Models for IUCN Red List Species Information",
        "abstract": "Large Language Models (LLMs) are rapidly being adopted in conservation to\naddress the biodiversity crisis, yet their reliability for species evaluation\nis uncertain. This study systematically validates five leading models on 21,955\nspecies across four core IUCN Red List assessment components: taxonomy,\nconservation status, distribution, and threats. A critical paradox was\nrevealed: models excelled at taxonomic classification (94.9%) but consistently\nfailed at conservation reasoning (27.2% for status assessment). This\nknowledge-reasoning gap, evident across all models, suggests inherent\narchitectural constraints, not just data limitations. Furthermore, models\nexhibited systematic biases favoring charismatic vertebrates, potentially\namplifying existing conservation inequities. These findings delineate clear\nboundaries for responsible LLM deployment: they are powerful tools for\ninformation retrieval but require human oversight for judgment-based decisions.\nA hybrid approach is recommended, where LLMs augment expert capacity while\nhuman experts retain sole authority over risk assessment and policy.",
        "url": "http://arxiv.org/abs/2510.02830v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02830v1",
        "arxiv_id": "2510.02830v1",
        "authors": [
            "Shinya Uryu"
        ],
        "submitted": "2025-10-03 09:09:35",
        "source": "arxiv",
        "comment": "20 pages, 7 figures",
        "score": 6,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses the application of Large Language Models (LLMs) in conservation, specifically their reliability for species evaluation. While it touches on information retrieval, the focus is on the limitations and biases of LLMs in conservation reasoning, which is somewhat related to the user's interests in query understanding and ranking models, but not a central match."
    },
    {
        "title": "AutoMaAS: Self-Evolving Multi-Agent Architecture Search for Large Language Models",
        "abstract": "Multi-agent systems powered by large language models have demonstrated\nremarkable capabilities across diverse domains, yet existing automated design\napproaches seek monolithic solutions that fail to adapt resource allocation\nbased on query complexity and domain requirements. This paper introduces\nAutoMaAS, a self-evolving multi-agent architecture search framework that\nleverages neural architecture search principles to automatically discover\noptimal agent configurations through dynamic operator lifecycle management and\nautomated machine learning techniques. Our approach incorporates four key\ninnovations: (1) automatic operator generation, fusion, and elimination based\non performance-cost analysis, (2) dynamic cost-aware optimization with\nreal-time parameter adjustment, (3) online feedback integration for continuous\narchitecture refinement, and (4) enhanced interpretability through decision\ntracing mechanisms. Extensive experiments across six benchmarks demonstrate\nthat AutoMaAS achieves 1.0-7.1\\% performance improvement while reducing\ninference costs by 3-5\\% compared to state-of-the-art methods. The framework\nshows superior transferability across datasets and LLM backbones, establishing\na new paradigm for automated multi-agent system design in the era of large\nlanguage models.",
        "url": "http://arxiv.org/abs/2510.02669v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02669v1",
        "arxiv_id": "2510.02669v1",
        "authors": [
            "Bo Ma",
            "Hang Li",
            "ZeHua Hu",
            "XiaoFan Gui",
            "LuYao Liu",
            "Simon Liu"
        ],
        "submitted": "2025-10-03 01:57:07",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "While the paper discusses the application of large language models, it primarily focuses on multi-agent architecture search, which is somewhat related to my interests in Information Retrieval and Search technologies. However, the paper's emphasis on large language models and multi-agent systems is not directly aligned with my core research themes, which include query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language Models",
        "abstract": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
        "url": "http://arxiv.org/abs/2510.03215v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03215v1",
        "arxiv_id": "2510.03215v1",
        "authors": [
            "Tianyu Fu",
            "Zihan Min",
            "Hanling Zhang",
            "Jichao Yan",
            "Guohao Dai",
            "Wanli Ouyang",
            "Yu Wang"
        ],
        "submitted": "2025-10-03 17:52:32",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on direct semantic communication between Large Language Models, using a neural network to project and fuse their knowledge caches. While it involves NLP and deep semantic understanding, it is primarily concerned with improving the performance of LLMs, which is not a core area of your research interests in Information Retrieval and Search technologies."
    },
    {
        "title": "SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys?",
        "abstract": "Academic survey writing, which distills vast literature into a coherent and\ninsightful narrative, remains a labor-intensive and intellectually demanding\ntask. While recent approaches, such as general DeepResearch agents and\nsurvey-specialized methods, can generate surveys automatically (a.k.a.\nLLM4Survey), their outputs often fall short of human standards and there lacks\na rigorous, reader-aligned benchmark for thoroughly revealing their\ndeficiencies. To fill the gap, we propose a fine-grained, quiz-driven\nevaluation framework SurveyBench, featuring (1) typical survey topics source\nfrom recent 11,343 arXiv papers and corresponding 4,947 high-quality surveys;\n(2) a multifaceted metric hierarchy that assesses the outline quality (e.g.,\ncoverage breadth, logical coherence), content quality (e.g., synthesis\ngranularity, clarity of insights), and non-textual richness; and (3) a\ndual-mode evaluation protocol that includes content-based and quiz-based\nanswerability tests, explicitly aligned with readers' informational needs.\nResults show SurveyBench effectively challenges existing LLM4Survey approaches\n(e.g., on average 21% lower than human in content-based evaluation).",
        "url": "http://arxiv.org/abs/2510.03120v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03120v1",
        "arxiv_id": "2510.03120v1",
        "authors": [
            "Zhaojun Sun",
            "Xuzhou Zhu",
            "Xuanhe Zhou",
            "Xin Tong",
            "Shuo Wang",
            "Jie Fu",
            "Guoliang Li",
            "Zhiyuan Liu",
            "Fan Wu"
        ],
        "submitted": "2025-10-03 15:49:09",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat relevant to your research interests in Information Retrieval, particularly in the area of query understanding and ranking models. However, it focuses on survey writing and evaluation, which is not a central match to your primary focus on real-time relevance optimization and deep semantic understanding. The paper's use of LLMs is also tangentially related to your interests in Learning to Rank and user behavior modeling."
    },
    {
        "title": "Constraint Satisfaction Approaches to Wordle: Novel Heuristics and Cross-Lexicon Validation",
        "abstract": "Wordle presents an algorithmically rich testbed for constraint satisfaction\nproblem (CSP) solving. While existing solvers rely on information-theoretic\nentropy maximization or frequency-based heuristics without formal constraint\ntreatment, we present the first comprehensive CSP formulation of Wordle with\nnovel constraint-aware solving strategies. We introduce CSP-Aware Entropy,\ncomputing information gain after constraint propagation rather than on raw\ncandidate sets, and a Probabilistic CSP framework integrating Bayesian\nword-frequency priors with logical constraints. Through evaluation on 2,315\nEnglish words, CSP-Aware Entropy achieves 3.54 average guesses with 99.9%\nsuccess rate, a statistically significant 1.7% improvement over Forward\nChecking (t=-4.82, p<0.001, Cohen's d=0.07) with 46% faster runtime (12.9ms\nversus 23.7ms per guess). Under 10% noise, CSP-aware approaches maintain 5.3\npercentage point advantages (29.0% versus 23.7%, p=0.041), while Probabilistic\nCSP achieves 100% success across all noise levels (0-20%) through constraint\nrecovery mechanisms. Cross-lexicon validation on 500 Spanish words demonstrates\n88% success with zero language-specific tuning, validating that core CSP\nprinciples transfer across languages despite an 11.2 percentage point gap from\nlinguistic differences (p<0.001, Fisher's exact test). Our open-source\nimplementation with 34 unit tests achieving 91% code coverage provides\nreproducible infrastructure for CSP research. The combination of formal CSP\ntreatment, constraint-aware heuristics, probabilistic-logical integration,\nrobustness analysis, and cross-lexicon validation establishes new performance\nbenchmarks demonstrating that principled constraint satisfaction techniques\noutperform classical information-theoretic and learning-based approaches for\nstructured puzzle-solving domains.",
        "url": "http://arxiv.org/abs/2510.02855v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02855v1",
        "arxiv_id": "2510.02855v1",
        "authors": [
            "Jahidul Arafat",
            "Fariha Tasmin",
            "Sanjaya Poudel",
            "Kamrujjaman",
            "Eftakhar Ahmed Arnob",
            "Ahsan Habib Tareq"
        ],
        "submitted": "2025-10-03 09:44:14",
        "source": "arxiv",
        "comment": "35 pages, 14 figures, 10 tables. Open-source implementation with 91%\n  test coverage available at\n  https://github.com/jahidul-arafat/constraint_satisfaction_wordle_arxiv_preprint",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on constraint satisfaction problem (CSP) solving for the Wordle game, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. While it involves some form of problem-solving and optimization, the context and techniques used are quite different from those in IR and Search."
    },
    {
        "title": "A Computational Framework for Interpretable Text-Based Personality Assessment from Social Media",
        "abstract": "Personality refers to individual differences in behavior, thinking, and\nfeeling. With the growing availability of digital footprints, especially from\nsocial media, automated methods for personality assessment have become\nincreasingly important. Natural language processing (NLP) enables the analysis\nof unstructured text data to identify personality indicators. However, two main\nchallenges remain central to this thesis: the scarcity of large,\npersonality-labeled datasets and the disconnect between personality psychology\nand NLP, which restricts model validity and interpretability. To address these\nchallenges, this thesis presents two datasets -- MBTI9k and PANDORA --\ncollected from Reddit, a platform known for user anonymity and diverse\ndiscussions. The PANDORA dataset contains 17 million comments from over 10,000\nusers and integrates the MBTI and Big Five personality models with demographic\ninformation, overcoming limitations in data size, quality, and label coverage.\nExperiments on these datasets show that demographic variables influence model\nvalidity. In response, the SIMPA (Statement-to-Item Matching Personality\nAssessment) framework was developed - a computational framework for\ninterpretable personality assessment that matches user-generated statements\nwith validated questionnaire items. By using machine learning and semantic\nsimilarity, SIMPA delivers personality assessments comparable to human\nevaluations while maintaining high interpretability and efficiency. Although\nfocused on personality assessment, SIMPA's versatility extends beyond this\ndomain. Its model-agnostic design, layered cue detection, and scalability make\nit suitable for various research and practical applications involving complex\nlabel taxonomies and variable cue associations with target concepts.",
        "url": "http://arxiv.org/abs/2510.02811v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02811v1",
        "arxiv_id": "2510.02811v1",
        "authors": [
            "Matej Gjurković"
        ],
        "submitted": "2025-10-03 08:36:36",
        "source": "arxiv",
        "comment": "Phd thesis",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on personality assessment from social media, which is not directly related to the user's core research themes in Information Retrieval and Search technologies. Although it involves Natural Language Processing, the application domain and methodology are quite different from the user's interests."
    },
    {
        "title": "Self-Improvement in Multimodal Large Language Models: A Survey",
        "abstract": "Recent advancements in self-improvement for Large Language Models (LLMs) have\nefficiently enhanced model capabilities without significantly increasing costs,\nparticularly in terms of human effort. While this area is still relatively\nyoung, its extension to the multimodal domain holds immense potential for\nleveraging diverse data sources and developing more general self-improving\nmodels. This survey is the first to provide a comprehensive overview of\nself-improvement in Multimodal LLMs (MLLMs). We provide a structured overview\nof the current literature and discuss methods from three perspectives: 1) data\ncollection, 2) data organization, and 3) model optimization, to facilitate the\nfurther development of self-improvement in MLLMs. We also include commonly used\nevaluations and downstream applications. Finally, we conclude by outlining open\nchallenges and future research directions.",
        "url": "http://arxiv.org/abs/2510.02665v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02665v1",
        "arxiv_id": "2510.02665v1",
        "authors": [
            "Shijian Deng",
            "Kai Wang",
            "Tianyu Yang",
            "Harsh Singh",
            "Yapeng Tian"
        ],
        "submitted": "2025-10-03 01:48:26",
        "source": "arxiv",
        "comment": "EMNLP 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it touches on Large Language Models, the focus is on self-improvement and multimodal aspects, which do not align with your primary interests."
    },
    {
        "title": "SoT: Structured-of-Thought Prompting Guides Multilingual Reasoning in Large Language Models",
        "abstract": "Recent developments have enabled Large Language Models (LLMs) to engage in\ncomplex reasoning tasks through deep thinking. However, the capacity of\nreasoning has not been successfully transferred to non-high-resource languages\ndue to resource constraints, which struggles with multilingual reasoning tasks.\nTo this end, we propose Structured-of-Thought (SoT), a training-free method\nthat improves the performance on multilingual reasoning through a multi-step\ntransformation: Language Thinking Transformation and Structured Knowledge\nTransformation. The SoT method converts language-specific semantic information\ninto language-agnostic structured representations, enabling the models to\nunderstand the query in different languages more sophisticated. Besides, SoT\neffectively guides LLMs toward more concentrated reasoning to maintain\nconsistent underlying reasoning pathways when handling cross-lingual variations\nin expression. Experimental results demonstrate that SoT outperforms several\nstrong baselines on multiple multilingual reasoning benchmarks when adapting to\nvarious backbones of LLMs. It can also be integrated with other training-free\nstrategies for further improvements. Our code is available at\nhttps://github.com/Cherry-qwq/SoT.",
        "url": "http://arxiv.org/abs/2510.02648v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02648v1",
        "arxiv_id": "2510.02648v1",
        "authors": [
            "Rui Qi",
            "Zhibo Man",
            "Yufeng Chen",
            "Fengran Mo",
            "Jinan Xu",
            "Kaiyu Huang"
        ],
        "submitted": "2025-10-03 01:02:14",
        "source": "arxiv",
        "comment": "EMNLP 2025 (findings)",
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores a method for improving multilingual reasoning in Large Language Models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on language models and multilingual reasoning does not directly align with the user's primary research themes. The paper's relevance is somewhat enhanced by its mention of structured representations and reasoning pathways, which may be of interest in the broader context of NLP and data mining."
    },
    {
        "title": "HyperAdaLoRA: Accelerating LoRA Rank Allocation During Training via Hypernetworks without Sacrificing Performance",
        "abstract": "Parameter-Efficient Fine-Tuning (PEFT), especially Low-Rank Adaptation\n(LoRA), has emerged as a promising approach to fine-tuning large language\nmodels(LLMs) while reducing computational and memory overhead. However, LoRA\nassumes a uniform rank \\textit{r} for each incremental matrix, not accounting\nfor the varying significance of weight matrices across different modules and\nlayers. AdaLoRA leverages Singular Value Decomposition (SVD) to parameterize\nupdates and employs pruning of singular values to introduce dynamic rank\nallocation, thereby enhancing adaptability. However, during the training\nprocess, it often encounters issues of slow convergence speed and high\ncomputational overhead. To address this issue, we propose HyperAdaLoRA, a novel\nframework that accelerates the convergence of AdaLoRA by leveraging a\nhypernetwork. Instead of directly optimizing the components of Singular Value\nDecomposition $(P, \\Lambda, Q)$, HyperAdaLoRA employs a hypernetwork based on\nattention mechanisms to dynamically generate these parameters. By pruning the\noutputs of the hypernetwork that generates the singular values, dynamic rank\nallocation is achieved. Comprehensive experiments on various datasets and\nmodels demonstrate that our method achieves faster convergence without\nsacrificing performance. Additionally, further extension experiments on other\nLoRA-based approaches validate the broad applicability of our method.",
        "url": "http://arxiv.org/abs/2510.02630v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02630v1",
        "arxiv_id": "2510.02630v1",
        "authors": [
            "Hao Zhang",
            "Zhenjia Li",
            "Runfeng Bao",
            "Yifan Gao",
            "Xi Xiao",
            "Bo Huang",
            "Yuhang Wu",
            "Tianyang Wang",
            "Hao Xu"
        ],
        "submitted": "2025-10-03 00:15:59",
        "source": "arxiv",
        "comment": "13 pages",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on a parameter-efficient fine-tuning approach for large language models, specifically addressing the issue of slow convergence speed and high computational overhead in LoRA. While it involves optimization techniques, it does not directly relate to information retrieval, query understanding, ranking models, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "How Confident are Video Models? Empowering Video Models to Express their Uncertainty",
        "abstract": "Generative video models demonstrate impressive text-to-video capabilities,\nspurring widespread adoption in many real-world applications. However, like\nlarge language models (LLMs), video generation models tend to hallucinate,\nproducing plausible videos even when they are factually wrong. Although\nuncertainty quantification (UQ) of LLMs has been extensively studied in prior\nwork, no UQ method for video models exists, raising critical safety concerns.\nTo our knowledge, this paper represents the first work towards quantifying the\nuncertainty of video models. We present a framework for uncertainty\nquantification of generative video models, consisting of: (i) a metric for\nevaluating the calibration of video models based on robust rank correlation\nestimation with no stringent modeling assumptions; (ii) a black-box UQ method\nfor video models (termed S-QUBED), which leverages latent modeling to\nrigorously decompose predictive uncertainty into its aleatoric and epistemic\ncomponents; and (iii) a UQ dataset to facilitate benchmarking calibration in\nvideo models. By conditioning the generation task in the latent space, we\ndisentangle uncertainty arising due to vague task specifications from that\narising from lack of knowledge. Through extensive experiments on benchmark\nvideo datasets, we demonstrate that S-QUBED computes calibrated total\nuncertainty estimates that are negatively correlated with the task accuracy and\neffectively computes the aleatoric and epistemic constituents.",
        "url": "http://arxiv.org/abs/2510.02571v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02571v1",
        "arxiv_id": "2510.02571v1",
        "authors": [
            "Zhiting Mei",
            "Ola Shorinwa",
            "Anirudha Majumdar"
        ],
        "submitted": "2025-10-02 21:20:41",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on uncertainty quantification in video models, which is a topic in the broader field of machine learning and deep learning. While it touches on the concept of uncertainty, it does not directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D Gaussian Splatting",
        "abstract": "Driving scene manipulation with sensor data is emerging as a promising\nalternative to traditional virtual driving simulators. However, existing\nframeworks struggle to generate realistic scenarios efficiently due to limited\nediting capabilities. To address these challenges, we present SIMSplat, a\npredictive driving scene editor with language-aligned Gaussian splatting. As a\nlanguage-controlled editor, SIMSplat enables intuitive manipulation using\nnatural language prompts. By aligning language with Gaussian-reconstructed\nscenes, it further supports direct querying of road objects, allowing precise\nand flexible editing. Our method provides detailed object-level editing,\nincluding adding new objects and modifying the trajectories of both vehicles\nand pedestrians, while also incorporating predictive path refinement through\nmulti-agent motion prediction to generate realistic interactions among all\nagents in the scene. Experiments on the Waymo dataset demonstrate SIMSplat's\nextensive editing capabilities and adaptability across a wide range of\nscenarios. Project page: https://sungyeonparkk.github.io/simsplat/",
        "url": "http://arxiv.org/abs/2510.02469v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02469v1",
        "arxiv_id": "2510.02469v1",
        "authors": [
            "Sung-Yeon Park",
            "Adam Lee",
            "Juanwu Lu",
            "Can Cui",
            "Luyang Jiang",
            "Rohit Gupta",
            "Kyungtae Han",
            "Ahmadreza Moradipari",
            "Ziran Wang"
        ],
        "submitted": "2025-10-02 18:22:03",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper appears to be related to computer vision and driving scene manipulation, but it does not align with the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing."
    },
    {
        "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention Alignment",
        "abstract": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
        "url": "http://arxiv.org/abs/2510.03223v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03223v1",
        "arxiv_id": "2510.03223v1",
        "authors": [
            "Hongxiang Zhang",
            "Yuan Tian",
            "Tianyi Zhang"
        ],
        "submitted": "2025-10-03 17:56:33",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Large Language Models, but it does not directly address query understanding, ranking models, or user behavior modeling in the context of Information Retrieval. The focus on Large Language Model reasoning and attention alignment is an interesting aspect, but it does not seem to be a central match with your primary research themes."
    },
    {
        "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
        "url": "http://arxiv.org/abs/2510.03222v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03222v1",
        "arxiv_id": "2510.03222v1",
        "authors": [
            "Guanhua Huang",
            "Tingqiang Xu",
            "Mingze Wang",
            "Qi Yi",
            "Xue Gong",
            "Siheng Li",
            "Ruibin Xiong",
            "Kejiao Li",
            "Yuhao Jiang",
            "Bo Zhou"
        ],
        "submitted": "2025-10-03 17:56:13",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves reinforcement learning and large language models, its focus on exploration in RLVR and the concept of 'reasoning sparks' does not align with the user's primary research interests in IR and NLP."
    },
    {
        "title": "Coevolutionary Continuous Discrete Diffusion: Make Your Diffusion Language Model a Latent Reasoner",
        "abstract": "Diffusion language models, especially masked discrete diffusion models, have\nachieved great success recently. While there are some theoretical and primary\nempirical results showing the advantages of latent reasoning with looped\ntransformers or continuous chain-of-thoughts, continuous diffusion models\ntypically underperform their discrete counterparts. In this paper, we argue\nthat diffusion language models do not necessarily need to be in the discrete\nspace. In particular, we prove that continuous diffusion models have stronger\nexpressivity than discrete diffusions and looped transformers. We attribute the\ncontradiction between the theoretical expressiveness and empirical performance\nto their practical trainability: while continuous diffusion provides\nintermediate supervision that looped transformers lack, they introduce\nadditional difficulty decoding tokens into the discrete token space from the\ncontinuous representation space. We therefore propose Coevolutionary Continuous\nDiscrete Diffusion (CCDD), which defines a joint multimodal diffusion process\non the union of a continuous representation space and a discrete token space,\nleveraging a single model to simultaneously denoise in the joint space. By\ncombining two modalities, CCDD is expressive with rich semantics in the latent\nspace, as well as good trainability and sample quality with the help of\nexplicit discrete tokens. We also propose effective architectures and advanced\ntraining/sampling techniques for CCDD, which reveals strong empirical\nperformance in extensive language modeling experiments on real-world tasks.",
        "url": "http://arxiv.org/abs/2510.03206v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03206v1",
        "arxiv_id": "2510.03206v1",
        "authors": [
            "Cai Zhou",
            "Chenxiao Yang",
            "Yi Hu",
            "Chenyu Wang",
            "Chubin Zhang",
            "Muhan Zhang",
            "Lester Mackey",
            "Tommi Jaakkola",
            "Stephen Bates",
            "Dinghuai Zhang"
        ],
        "submitted": "2025-10-03 17:44:41",
        "source": "arxiv",
        "comment": "27 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving diffusion language models, which is a topic in Natural Language Processing (NLP). However, it does not appear to be directly related to Information Retrieval (IR), query understanding, ranking models, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning",
        "abstract": "Vision Language Models (VLMs) show strong potential for visual planning but\nstruggle with precise spatial and long-horizon reasoning. In contrast, Planning\nDomain Definition Language (PDDL) planners excel at long-horizon formal\nplanning, but cannot interpret visual inputs. Recent works combine these\ncomplementary advantages by enabling VLMs to turn visual planning problems into\nPDDL files for formal planning. However, while VLMs can generate PDDL problem\nfiles satisfactorily, they struggle to accurately generate the PDDL domain\nfiles, which describe all the planning rules. As a result, prior methods rely\non human experts to predefine domain files or on constant environment access\nfor refinement. We propose VLMFP, a Dual-VLM-guided framework that can\nautonomously generate both PDDL problem and domain files for formal visual\nplanning. VLMFP introduces two VLMs to ensure reliable PDDL file generation: A\nSimVLM that simulates action consequences based on input rule descriptions, and\na GenVLM that generates and iteratively refines PDDL files by comparing the\nPDDL and SimVLM execution results. VLMFP unleashes multiple levels of\ngeneralizability: The same generated PDDL domain file works for all the\ndifferent instances under the same problem, and VLMs generalize to different\nproblems with varied appearances and rules. We evaluate VLMFP with 6 grid-world\ndomains and test its generalization to unseen instances, appearance, and game\nrules. On average, SimVLM accurately describes 95.5%, 82.6% of scenarios,\nsimulates 85.5%, 87.8% of action sequence, and judges 82.4%, 85.6% goal\nreaching for seen and unseen appearances, respectively. With the guidance of\nSimVLM, VLMFP can generate PDDL files to reach 70.0%, 54.1% valid plans for\nunseen instances in seen and unseen appearances, respectively. Project page:\nhttps://sites.google.com/view/vlmfp.",
        "url": "http://arxiv.org/abs/2510.03182v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03182v1",
        "arxiv_id": "2510.03182v1",
        "authors": [
            "Yilun Hao",
            "Yongchao Chen",
            "Chuchu Fan",
            "Yang Zhang"
        ],
        "submitted": "2025-10-03 16:57:01",
        "source": "arxiv",
        "comment": "30 pages, 5 figures, 5 tables",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves a Vision Language Model (VLM), the focus is on formal visual planning and planning domain definition language, which is not a central match to your core research themes."
    },
    {
        "title": "Listening or Reading? Evaluating Speech Awareness in Chain-of-Thought Speech-to-Text Translation",
        "abstract": "Speech-to-Text Translation (S2TT) systems built from Automatic Speech\nRecognition (ASR) and Text-to-Text Translation (T2TT) modules face two major\nlimitations: error propagation and the inability to exploit prosodic or other\nacoustic cues. Chain-of-Thought (CoT) prompting has recently been introduced,\nwith the expectation that jointly accessing speech and transcription will\novercome these issues. Analyzing CoT through attribution methods, robustness\nevaluations with corrupted transcripts, and prosody-awareness, we find that it\nlargely mirrors cascaded behavior, relying mainly on transcripts while barely\nleveraging speech. Simple training interventions, such as adding Direct S2TT\ndata or noisy transcript injection, enhance robustness and increase speech\nattribution. These findings challenge the assumed advantages of CoT and\nhighlight the need for architectures that explicitly integrate acoustic\ninformation into translation.",
        "url": "http://arxiv.org/abs/2510.03115v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03115v1",
        "arxiv_id": "2510.03115v1",
        "authors": [
            "Jacobo Romero-Díaz",
            "Gerard I. Gállego",
            "Oriol Pareras",
            "Federico Costa",
            "Javier Hernando",
            "Cristina España-Bonet"
        ],
        "submitted": "2025-10-03 15:42:38",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Speech-to-Text Translation and Chain-of-Thought prompting, which is not directly related to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves text processing, the context is specific to speech translation and does not align with your interests in query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Self-Reflective Generation at Test Time",
        "abstract": "Large language models (LLMs) increasingly solve complex reasoning tasks via\nlong chain-of-thought, but their forward-only autoregressive generation process\nis fragile; early token errors can cascade, which creates a clear need for\nself-reflection mechanisms. However, existing self-reflection either performs\nrevisions over full drafts or learns self-correction via expensive training,\nboth fundamentally reactive and inefficient. To address this, we propose\nSelf-Reflective Generation at Test Time (SRGen), a lightweight test-time\nframework that reflects before generating at uncertain points. During token\ngeneration, SRGen utilizes dynamic entropy thresholding to identify\nhigh-uncertainty tokens. For each identified token, it trains a specific\ncorrective vector, which fully exploits the already generated context for a\nself-reflective generation to correct the token probability distribution. By\nretrospectively analyzing the partial output, this self-reflection enables more\ntrustworthy decisions, thereby significantly reducing the probability of errors\nat highly uncertain points. Evaluated on challenging mathematical reasoning\nbenchmarks and a diverse set of LLMs, SRGen can consistently strengthen model\nreasoning: improvements in single-pass quality also translate into stronger\nself-consistency voting. Especially, on AIME2024 with\nDeepSeek-R1-Distill-Qwen-7B, SRGen yields absolute improvements of +12.0% on\nPass@1 and +13.3% on Cons@5. Moreover, our findings position SRGen as a\nplug-and-play method that integrates reflection into the generation process for\nreliable LLM reasoning, achieving consistent gains with bounded overhead and\nbroad composability with other training-time (e.g., RLHF) and test-time (e.g.,\nSLOT) techniques.",
        "url": "http://arxiv.org/abs/2510.02919v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02919v1",
        "arxiv_id": "2510.02919v1",
        "authors": [
            "Jian Mu",
            "Qixin Zhang",
            "Zhiyong Wang",
            "Menglin Yang",
            "Shuang Qiu",
            "Chengwei Qin",
            "Zhongxiang Dai",
            "Yao Shu"
        ],
        "submitted": "2025-10-03 11:46:04",
        "source": "arxiv",
        "comment": "24 pages, 8 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on self-reflective generation in large language models, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves deep semantic understanding, the context is not aligned with the user's primary research interests in IR and search technologies."
    },
    {
        "title": "XTRA: Cross-Lingual Topic Modeling with Topic and Representation Alignments",
        "abstract": "Cross-lingual topic modeling aims to uncover shared semantic themes across\nlanguages. Several methods have been proposed to address this problem,\nleveraging both traditional and neural approaches. While previous methods have\nachieved some improvements in topic diversity, they often struggle to ensure\nhigh topic coherence and consistent alignment across languages. We propose XTRA\n(Cross-Lingual Topic Modeling with Topic and Representation Alignments), a\nnovel framework that unifies Bag-of-Words modeling with multilingual\nembeddings. XTRA introduces two core components: (1) representation alignment,\naligning document-topic distributions via contrastive learning in a shared\nsemantic space; and (2) topic alignment, projecting topic-word distributions\ninto the same space to enforce crosslingual consistency. This dual mechanism\nenables XTRA to learn topics that are interpretable (coherent and diverse) and\nwell-aligned across languages. Experiments on multilingual corpora confirm that\nXTRA significantly outperforms strong baselines in topic coherence, diversity,\nand alignment quality. Code and reproducible scripts are available at https:\n//github.com/tienphat140205/XTRA.",
        "url": "http://arxiv.org/abs/2510.02788v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02788v1",
        "arxiv_id": "2510.02788v1",
        "authors": [
            "Tien Phat Nguyen",
            "Vu Minh Ngo",
            "Tung Nguyen",
            "Linh Van Ngo",
            "Duc Anh Nguyen",
            "Sang Dinh",
            "Trung Le"
        ],
        "submitted": "2025-10-03 07:46:23",
        "source": "arxiv",
        "comment": "2025 EMNLP Findings",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on cross-lingual topic modeling, which is somewhat related to information retrieval and natural language processing. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's emphasis on topic coherence and alignment is relevant to deep semantic understanding, but the context is more focused on text analysis rather than search technologies."
    },
    {
        "title": "PGMEL: Policy Gradient-based Generative Adversarial Network for Multimodal Entity Linking",
        "abstract": "The task of entity linking, which involves associating mentions with their\nrespective entities in a knowledge graph, has received significant attention\ndue to its numerous potential applications. Recently, various multimodal entity\nlinking (MEL) techniques have been proposed, targeted to learn comprehensive\nembeddings by leveraging both text and vision modalities. The selection of\nhigh-quality negative samples can potentially play a crucial role in\nmetric/representation learning. However, to the best of our knowledge, this\npossibility remains unexplored in existing literature within the framework of\nMEL. To fill this gap, we address the multimodal entity linking problem in a\ngenerative adversarial setting where the generator is responsible for\ngenerating high-quality negative samples, and the discriminator is assigned the\nresponsibility for the metric learning tasks. Since the generator is involved\nin generating samples, which is a discrete process, we optimize it using policy\ngradient techniques and propose a policy gradient-based generative adversarial\nnetwork for multimodal entity linking (PGMEL). Experimental results based on\nWiki-MEL, Richpedia-MEL and WikiDiverse datasets demonstrate that PGMEL learns\nmeaningful representation by selecting challenging negative samples and\noutperforms state-of-the-art methods.",
        "url": "http://arxiv.org/abs/2510.02726v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02726v1",
        "arxiv_id": "2510.02726v1",
        "authors": [
            "KM Pooja",
            "Cheng Long",
            "Aixin Sun"
        ],
        "submitted": "2025-10-03 05:09:47",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multimodal entity linking using a generative adversarial network, which is not directly related to information retrieval, query understanding, or ranking models. While it involves learning representations, it's more focused on entity linking and knowledge graphs, which doesn't align with the user's primary research interests."
    },
    {
        "title": "On the Role of Temperature Sampling in Test-Time Scaling",
        "abstract": "Large language models (LLMs) can improve reasoning at inference time through\ntest-time scaling (TTS), where multiple reasoning traces are generated and the\nbest one is selected. Prior work shows that increasing the number of samples K\nsteadily improves accuracy. In this paper, we demonstrate that this trend does\nnot hold indefinitely: at large K, further scaling yields no gains, and certain\nhard questions remain unsolved regardless of the number of traces.\nInterestingly, we find that different sampling temperatures solve different\nsubsets of problems, implying that single-temperature scaling explores only\npart of a model's potential. We therefore propose scaling along the temperature\ndimension, which enlarges the reasoning boundary of LLMs. Averaged over Qwen3\n(0.6B, 1.7B, 4B, 8B) and five representative reasoning benchmarks (AIME\n2024/2025, MATH500, LiveCodeBench, Hi-ToM), temperature scaling yields an\nadditional 7.3 points over single-temperature TTS. Temperature scaling also\nenables base models to reach performance comparable to reinforcement learning\n(RL)-trained counterparts, without additional post-training. We further provide\na comprehensive analysis of this phenomenon and design a multi-temperature\nvoting method that reduces the overhead of temperature scaling. Overall, our\nfindings suggest that TTS is more powerful than previously thought, and that\ntemperature scaling offers a simple and effective way to unlock the latent\npotential of base models.",
        "url": "http://arxiv.org/abs/2510.02611v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02611v1",
        "arxiv_id": "2510.02611v1",
        "authors": [
            "Yuheng Wu",
            "Azalia Mirhoseini",
            "Thierry Tambe"
        ],
        "submitted": "2025-10-02 23:09:56",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and deep semantic understanding, but it focuses on test-time scaling and temperature sampling in large language models, which is not a central match for the user's core research themes in Information Retrieval and Search technologies."
    },
    {
        "title": "Beyond Imitation: Recovering Dense Rewards from Demonstrations",
        "abstract": "Conventionally, supervised fine-tuning (SFT) is treated as a simple imitation\nlearning process that only trains a policy to imitate expert behavior on\ndemonstration datasets. In this work, we challenge this view by establishing a\nfundamental equivalence between SFT and Inverse Reinforcement Learning. We\nprove that the SFT objective is a special case of Inverse Q-Learning, which\nimplies that the SFT process does not just learn a policy, but also an\nimplicit, dense, token-level reward model that explains the expert\ndemonstrations. We then show how to recover this dense reward signal directly\nfrom the SFT model by formulating a baseline-relative reward function. The\navailability of such a dense reward model offers numerous benefits, providing\ngranular credit assignment for each token generated. We demonstrate one key\napplication by using these recovered rewards to further improve the policy with\nreinforcement learning. Our method, Dense-Path REINFORCE, consistently\noutperforms the original SFT models on instruction-following benchmarks. This\nwork reframes SFT not merely as policy imitation but as a powerful reward\nlearning mechanism, opening new possibilities for leveraging expert\ndemonstrations.",
        "url": "http://arxiv.org/abs/2510.02493v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02493v1",
        "arxiv_id": "2510.02493v1",
        "authors": [
            "Jiangnan Li",
            "Thuy-Trang Vu",
            "Ehsan Abbasnejad",
            "Gholamreza Haffari"
        ],
        "submitted": "2025-10-02 18:58:26",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Recovering Dense Rewards from Demonstrations using Inverse Reinforcement Learning, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. While it touches on reinforcement learning, it's more aligned with control and decision-making, and doesn't seem to leverage deep semantic understanding or real-time relevance optimization."
    },
    {
        "title": "Litespark Technical Report: High-Throughput, Energy-Efficient LLM Training Framework",
        "abstract": "Training Large Language Models (LLMs) is plagued by long training times and\nmassive energy consumption, with modern models requiring months of computation\nand gigawatt-hours of electricity. In light of these challenges,we introduce\nLitespark, a novel pre-training framework that addresses these inefficiencies\nthrough targeted optimizations to transformer attention and MLP layers. Our\napproach combines architectural improvements with algorithmic enhancements to\nmaximize Model FLOPs Utilization (MFU) while maintaining compatibility with\nstandard transformer implementations. Comprehensive benchmarking on 3B and 30B\nparameter Llama models using the SlimPajama-627B dataset demonstrates\nsubstantial performance gains: 2x-6x training throughput improvement and\n$55\\%-83$% energy consumption reduction across multi-node H200 GPU clusters.\nThese optimizations are model- and hardware-agnostic, enabling broad\napplicability across transformer architectures and extending to post-training\nphases including supervised fine-tuning and direct preference optimization.",
        "url": "http://arxiv.org/abs/2510.02483v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02483v1",
        "arxiv_id": "2510.02483v1",
        "authors": [
            "Nii Osae Osae Dade",
            "Moinul Hossain Rahat"
        ],
        "submitted": "2025-10-02 18:42:07",
        "source": "arxiv",
        "comment": "14 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on optimizing Large Language Model (LLM) training, which is not directly related to Information Retrieval or Search technologies. While it involves transformer architectures, the primary goal is energy efficiency and training speed, rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Reward Models are Metrics in a Trench Coat",
        "abstract": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
        "url": "http://arxiv.org/abs/2510.03231v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03231v1",
        "arxiv_id": "2510.03231v1",
        "authors": [
            "Sebastian Gehrmann"
        ],
        "submitted": "2025-10-03 17:59:44",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper discusses the intersection of reward models and evaluation metrics in the context of reinforcement learning and large language models. While it touches on relevant topics, it does not directly address the user's core research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. The paper's focus on reinforcement learning and post-training of large language models makes it somewhat related but not a central match for the user's research interests."
    },
    {
        "title": "OpenZL: A Graph-Based Model for Compression",
        "abstract": "Research in general-purpose lossless compression over the last decade has\nlargely found improvements in compression ratio that come at great cost to\nresource utilization and processing throughput. However, most production\nworkloads require high throughput and low resource utilization, so most\nresearch systems have seen little adoption. Instead, real world improvements in\ncompression are increasingly often realized by building application-specific\ncompressors which can exploit knowledge about the structure and semantics of\nthe data being compressed. These systems easily outperform even the best\ngeneric compressors, but application-specific compression schemes are not\nwithout drawbacks. They are inherently limited in applicability and are\ndifficult to maintain and deploy.\n  We show that these challenges can be overcome with a new way of thinking\nabout compression. We propose the ``graph model'' of compression, a new\ntheoretical framework for representing compression as a directed acyclic graph\nof modular codecs. This motivates OpenZL, an implementation of this model that\ncompresses data into a self-describing wire format, any configuration of which\ncan be decompressed by a universal decoder. OpenZL's design enables rapid\ndevelopment of tailored compressors with minimal code, its universal decoder\neliminates deployment lag, and its investment in a well-vetted standard\ncomponent library minimizes security risks. Experimental results demonstrate\nthat OpenZL achieves superior compression ratios and speeds compared to\nstate-of-the-art general-purpose compressors on a variety of real-world\ndatasets. Internal deployments at Meta have also shown consistent improvements\nin size and/or speed, with development timelines reduced from months to days.\nOpenZL thus represents an advance in practical, scalable, and maintainable data\ncompression for modern data-intensive applications.",
        "url": "http://arxiv.org/abs/2510.03203v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03203v1",
        "arxiv_id": "2510.03203v1",
        "authors": [
            "Yann Collet",
            "Nick Terrell",
            "W. Felix Handte",
            "Danielle Rozenblit",
            "Victor Zhang",
            "Kevin Zhang",
            "Yaelle Goldschlag",
            "Jennifer Lee",
            "Daniel Riegel",
            "Stan Angelov",
            "Nadav Rotem"
        ],
        "submitted": "2025-10-03 17:40:29",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is primarily focused on data compression, which is not a central theme in your research interests. While it does involve a graph-based model, the context is not related to information retrieval, search technologies, or natural language processing."
    },
    {
        "title": "Neural Correlates of Language Models Are Specific to Human Language",
        "abstract": "Previous work has shown correlations between the hidden states of large\nlanguage models and fMRI brain responses, on language tasks. These correlations\nhave been taken as evidence of the representational similarity of these models\nand brain states. This study tests whether these previous results are robust to\nseveral possible concerns. Specifically this study shows: (i) that the previous\nresults are still found after dimensionality reduction, and thus are not\nattributable to the curse of dimensionality; (ii) that previous results are\nconfirmed when using new measures of similarity; (iii) that correlations\nbetween brain representations and those from models are specific to models\ntrained on human language; and (iv) that the results are dependent on the\npresence of positional encoding in the models. These results confirm and\nstrengthen the results of previous research and contribute to the debate on the\nbiological plausibility and interpretability of state-of-the-art large language\nmodels.",
        "url": "http://arxiv.org/abs/2510.03156v1",
        "pdf_url": "http://arxiv.org/pdf/2510.03156v1",
        "arxiv_id": "2510.03156v1",
        "authors": [
            "Iñigo Parra"
        ],
        "submitted": "2025-10-03 16:28:31",
        "source": "arxiv",
        "comment": "To be presented at NeurIPS 2025 Workshops",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or your other core research themes. It explores the neural correlates of language models and their similarity to human brain states, which is a topic in Natural Language Processing, but not a central match for your interests."
    },
    {
        "title": "Hyperparameter Loss Surfaces Are Simple Near their Optima",
        "abstract": "Hyperparameters greatly impact models' capabilities; however, modern models\nare too large for extensive search. Instead, researchers design recipes that\ntrain well across scales based on their understanding of the hyperparameters.\nDespite this importance, few tools exist for understanding the hyperparameter\nloss surface. We discover novel structure in it and propose a new theory\nyielding such tools. The loss surface is complex, but as you approach the\noptimum simple structure emerges. It becomes characterized by a few basic\nfeatures, like its effective dimension and the best possible loss. To uncover\nthis asymptotic regime, we develop a novel technique based on random search.\nWithin this regime, the best scores from random search take on a new\ndistribution we discover. Its parameters are exactly the features defining the\nloss surface in the asymptotic regime. From these features, we derive a new\nasymptotic law for random search that can explain and extrapolate its\nconvergence. These new tools enable new analyses, such as confidence intervals\nfor the best possible performance or determining the effective number of\nhyperparameters. We make these tools available at\nhttps://github.com/nicholaslourie/opda .",
        "url": "http://arxiv.org/abs/2510.02721v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02721v1",
        "arxiv_id": "2510.02721v1",
        "authors": [
            "Nicholas Lourie",
            "He He",
            "Kyunghyun Cho"
        ],
        "submitted": "2025-10-03 04:52:27",
        "source": "arxiv",
        "comment": "Accepted to COLM 2025. 23 pages, 8 figures",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be unrelated to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, and data mining. The paper focuses on understanding the hyperparameter loss surface in machine learning models, which is a topic more relevant to the broader field of machine learning and optimization."
    },
    {
        "title": "Uncertainty as Feature Gaps: Epistemic Uncertainty Quantification of LLMs in Contextual Question-Answering",
        "abstract": "Uncertainty Quantification (UQ) research has primarily focused on closed-book\nfactual question answering (QA), while contextual QA remains unexplored,\ndespite its importance in real-world applications. In this work, we focus on UQ\nfor the contextual QA task and propose a theoretically grounded approach to\nquantify epistemic uncertainty. We begin by introducing a task-agnostic,\ntoken-level uncertainty measure defined as the cross-entropy between the\npredictive distribution of the given model and the unknown true distribution.\nBy decomposing this measure, we isolate the epistemic component and approximate\nthe true distribution by a perfectly prompted, idealized model. We then derive\nan upper bound for epistemic uncertainty and show that it can be interpreted as\nsemantic feature gaps in the given model's hidden representations relative to\nthe ideal model. We further apply this generic framework to the contextual QA\ntask and hypothesize that three features approximate this gap: context-reliance\n(using the provided context rather than parametric knowledge), context\ncomprehension (extracting relevant information from context), and honesty\n(avoiding intentional lies). Using a top-down interpretability approach, we\nextract these features by using only a small number of labeled samples and\nensemble them to form a robust uncertainty score. Experiments on multiple QA\nbenchmarks in both in-distribution and out-of-distribution settings show that\nour method substantially outperforms state-of-the-art unsupervised\n(sampling-free and sampling-based) and supervised UQ methods, achieving up to a\n13-point PRR improvement while incurring a negligible inference overhead.",
        "url": "http://arxiv.org/abs/2510.02671v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02671v1",
        "arxiv_id": "2510.02671v1",
        "authors": [
            "Yavuz Bakman",
            "Sungmin Kang",
            "Zhiqi Huang",
            "Duygu Nur Yaldiz",
            "Catarina G. Belém",
            "Chenyang Zhu",
            "Anoop Kumar",
            "Alfy Samuel",
            "Salman Avestimehr",
            "Daben Liu",
            "Sai Praneeth Karimireddy"
        ],
        "submitted": "2025-10-03 02:09:25",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of query understanding and ranking models. The focus on uncertainty quantification in contextual question-answering aligns with your interest in deep semantic understanding and real-time relevance optimization. However, the specific application to Large Language Models (LLMs) is a more specialized area, which prevents it from being a perfect match."
    },
    {
        "title": "Unraveling Syntax: How Language Models Learn Context-Free Grammars",
        "abstract": "We introduce a new framework for understanding how language models acquire\nsyntax. While large models achieve impressive results, little is known about\ntheir learning dynamics. Our approach starts with the observation that most\ndomains of interest, such as natural language syntax, coding languages,\narithmetic problems, are captured by probabilistic context-free grammars\n(PCFGs). We study the learning dynamics of small models trained on synthetic\nlanguages generated from PCFGs, enabling precise control over grammar\ncomplexity, recursion depth, and subgrammar structure. We prove several\ngeneral, recursive formulae for the training loss and Kullback-Leibler\ndivergence over the subgrammar structure of a PCFG. Empirically, we find that\nunlike children, who first master simple substructures before progressing to\nmore complex constructions, transformers reduce loss across all subgrammars in\nparallel. We further show that subgrammar pretraining can improve the final\nloss for smaller models, and that pretrained models develop internal\nrepresentations more aligned with the grammar's substructure. Finally, we\ndemonstrate that models struggle with deeper recursive structures (a limitation\neven of large language models), revealing fundamental challenges in how neural\nnetworks represent hierarchical syntax. Overall, our work initiates the study\nof the learning dynamics of transformers on PCFGs as a versatile testbed for\nprobing learning in language models, opening a research direction with many\nopen questions.",
        "url": "http://arxiv.org/abs/2510.02524v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02524v1",
        "arxiv_id": "2510.02524v1",
        "authors": [
            "Laura Ying Schulz",
            "Daniel Mitropolsky",
            "Tomaso Poggio"
        ],
        "submitted": "2025-10-02 19:52:19",
        "source": "arxiv",
        "comment": "Equal contribution by LYS and DM",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the learning dynamics of language models on probabilistic context-free grammars, which is related to deep semantic understanding in NLP. However, the focus is on syntax acquisition rather than query understanding or ranking models, making it somewhat relevant but not a central match for your research interests."
    },
    {
        "title": "How to Train Your Advisor: Steering Black-Box LLMs with Advisor Models",
        "abstract": "Foundation models are increasingly deployed as black-box services, where\nmodel weights cannot be modified and customization is limited to prompting.\nWhile static prompt optimization has shown promise, it produces a single fixed\nprompt that fails to adapt to different inputs, users, or environments. We\nintroduce Advisor Models, lightweight parametric policies trained with\nreinforcement learning to reactively issue natural language steering\ninstructions in-context to black-box models. The advisor is a second small\nmodel that sits between the input and the model, shaping behavior on a\nper-instance basis using reward signals from the environment. Across multiple\ndomains involving reasoning and personalization, we show that Advisor Models\noutperform static prompt optimizers, discovering environment dynamics and\nimproving downstream task performance. We also demonstrate the generalizability\nof advisors by transferring them across black-box models, as well as the\nframework's ability to achieve specialization while retaining robustness to\nout-of-distribution inputs. Viewed more broadly, Advisor Models provide a\nlearnable interface to black-box systems where the advisor acts as a\nparametric, environment-specific memory. We argue that dynamic optimization of\nblack-box models via Advisor Models is a promising direction for enabling\npersonalization and environment-adaptable AI with frontier-level capabilities.",
        "url": "http://arxiv.org/abs/2510.02453v1",
        "pdf_url": "http://arxiv.org/pdf/2510.02453v1",
        "arxiv_id": "2510.02453v1",
        "authors": [
            "Parth Asawa",
            "Alan Zhu",
            "Matei Zaharia",
            "Alexandros G. Dimakis",
            "Joseph E. Gonzalez"
        ],
        "submitted": "2025-10-02 18:02:39",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper introduces Advisor Models, which can be seen as a form of query understanding and ranking model, but its primary focus is on black-box LLMs and dynamic optimization. While it touches on personalization and environment-adaptable AI, it doesn't directly relate to information retrieval or search technologies. The paper's relevance to your interests is somewhat related, but not a central match."
    }
]