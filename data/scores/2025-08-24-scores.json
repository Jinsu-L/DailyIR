[
    {
        "title": "OPERA: A Reinforcement Learning--Enhanced Orchestrated Planner-Executor Architecture for Reasoning-Oriented Multi-Hop Retrieval",
        "abstract": "Recent advances in large language models (LLMs) and dense retrievers have\ndriven significant progress in retrieval-augmented generation (RAG). However,\nexisting approaches face significant challenges in complex reasoning-oriented\nmulti-hop retrieval tasks: 1) Ineffective reasoning-oriented planning: Prior\nmethods struggle to generate robust multi-step plans for complex queries, as\nrule-based decomposers perform poorly on out-of-template questions. 2)\nSuboptimal reasoning-driven retrieval: Related methods employ limited query\nreformulation, leading to iterative retrieval loops that often fail to locate\ngolden documents. 3) Insufficient reasoning-guided filtering: Prevailing\nmethods lack the fine-grained reasoning to effectively filter salient\ninformation from noisy results, hindering utilization of retrieved knowledge.\nFundamentally, these limitations all stem from the weak coupling between\nretrieval and reasoning in current RAG architectures. We introduce the\nOrchestrated Planner-Executor Reasoning Architecture (OPERA), a novel\nreasoning-driven retrieval framework. OPERA's Goal Planning Module (GPM)\ndecomposes questions into sub-goals, which are executed by a Reason-Execute\nModule (REM) with specialized components for precise reasoning and effective\nretrieval. To train OPERA, we propose Multi-Agents Progressive Group Relative\nPolicy Optimization (MAPGRPO), a novel variant of GRPO. Experiments on complex\nmulti-hop benchmarks show OPERA's superior performance, validating both the\nMAPGRPO method and OPERA's design. Code is available at\nhttps://github.com/Ameame1/OPERA.",
        "url": "http://arxiv.org/abs/2508.16438v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16438v1",
        "arxiv_id": "2508.16438v1",
        "authors": [
            "Yu Liu",
            "Yanbing Liu",
            "Fangfang Yuan",
            "Cong Cao",
            "Youbang Sun",
            "Kun Peng",
            "WeiZhuo Chen",
            "Jianjun Li",
            "Zhiyuan Ma"
        ],
        "submitted": "2025-08-22 14:50:26",
        "source": "arxiv",
        "comment": null,
        "score": 13,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper introduces a novel framework for reasoning-oriented multi-hop retrieval, which is related to information retrieval and query understanding. While it does not specifically focus on ranking models or user behavior modeling, it explores the intersection of retrieval and reasoning, which is relevant to the user's interests in deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models",
        "abstract": "Large Language Models (LLMs) remain vulnerable to jailbreak attacks, which\nattempt to elicit harmful responses from LLMs. The evolving nature and\ndiversity of these attacks pose many challenges for defense systems, including\n(1) adaptation to counter emerging attack strategies without costly retraining,\nand (2) control of the trade-off between safety and utility. To address these\nchallenges, we propose Retrieval-Augmented Defense (RAD), a novel framework for\njailbreak detection that incorporates a database of known attack examples into\nRetrieval-Augmented Generation, which is used to infer the underlying,\nmalicious user query and jailbreak strategy used to attack the system. RAD\nenables training-free updates for newly discovered jailbreak strategies and\nprovides a mechanism to balance safety and utility. Experiments on StrongREJECT\nshow that RAD substantially reduces the effectiveness of strong jailbreak\nattacks such as PAP and PAIR while maintaining low rejection rates for benign\nqueries. We propose a novel evaluation scheme and show that RAD achieves a\nrobust safety-utility trade-off across a range of operating points in a\ncontrollable manner.",
        "url": "http://arxiv.org/abs/2508.16406v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16406v1",
        "arxiv_id": "2508.16406v1",
        "authors": [
            "Guangyu Yang",
            "Jinghong Chen",
            "Jingbiao Mei",
            "Weizhe Lin",
            "Bill Byrne"
        ],
        "submitted": "2025-08-22 14:13:16",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on defense mechanisms for Large Language Models against jailbreak attacks, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions retrieval-augmented generation, the context is different from traditional IR and NLP applications."
    },
    {
        "title": "Retrieval Enhanced Feedback via In-context Neural Error-book",
        "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nimproved reasoning capabilities, with in-context learning (ICL) emerging as a\nkey technique for adaptation without retraining. While previous works have\nfocused on leveraging correct examples, recent research highlights the\nimportance of learning from errors to enhance performance. However, existing\nmethods lack a structured framework for analyzing and mitigating errors,\nparticularly in Multimodal Large Language Models (MLLMs), where integrating\nvisual and textual inputs adds complexity. To address this issue, we propose\nREFINE: Retrieval-Enhanced Feedback via In-context Neural Error-book, a\nteacher-student framework that systematically structures errors and provides\ntargeted feedback. REFINE introduces three systematic queries to construct\nstructured feedback -- Feed-Target, Feed-Check, and Feed-Path -- to enhance\nmultimodal reasoning by prioritizing relevant visual information, diagnosing\ncritical failure points, and formulating corrective actions. Unlike prior\napproaches that rely on redundant retrievals, REFINE optimizes structured\nfeedback retrieval, improving inference efficiency, token usage, and\nscalability. Our results demonstrate substantial speedup, reduced computational\ncosts, and successful generalization, highlighting REFINE's potential for\nenhancing multimodal reasoning.",
        "url": "http://arxiv.org/abs/2508.16313v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16313v1",
        "arxiv_id": "2508.16313v1",
        "authors": [
            "Jongyeop Hyun",
            "Bumsoo Kim"
        ],
        "submitted": "2025-08-22 11:50:04",
        "source": "arxiv",
        "comment": "Accepted at EMNLP 2025 main conference",
        "score": 8,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a framework for learning from errors in Large Language Models, which is related to query understanding and ranking models in Information Retrieval. However, the focus is on multimodal reasoning and error analysis, which is not directly aligned with the user's primary interests in search technologies and user behavior modeling."
    },
    {
        "title": "ORCA: Mitigating Over-Reliance for Multi-Task Dwell Time Prediction with Causal Decoupling",
        "abstract": "Dwell time (DT) is a critical post-click metric for evaluating user\npreference in recommender systems, complementing the traditional click-through\nrate (CTR). Although multi-task learning is widely adopted to jointly optimize\nDT and CTR, we observe that multi-task models systematically collapse their DT\npredictions to the shortest and longest bins, under-predicting the moderate\ndurations. We attribute this moderate-duration bin under-representation to\nover-reliance on the CTR-DT spurious correlation, and propose ORCA to address\nit with causal-decoupling. Specifically, ORCA explicitly models and subtracts\nCTR's negative transfer while preserving its positive transfer. We further\nintroduce (i) feature-level counterfactual intervention, and (ii) a\ntask-interaction module with instance inverse-weighting, weakening CTR-mediated\neffect and restoring direct DT semantics. ORCA is model-agnostic and easy to\ndeploy. Experiments show an average 10.6% lift in DT metrics without harming\nCTR. Code is available at\nhttps://github.com/Chrissie-Law/ORCA-Mitigating-Over-Reliance-for-Multi-Task-Dwell-Time-Prediction-with-Causal-Decoupling.",
        "url": "http://arxiv.org/abs/2508.16573v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16573v1",
        "arxiv_id": "2508.16573v1",
        "authors": [
            "Huishi Luo",
            "Fuzhen Zhuang",
            "Yongchun Zhu",
            "Yiqing Wu",
            "Bo Kang",
            "Ruobing Xie",
            "Feng Xia",
            "Deqing Wang",
            "Jin Dong"
        ],
        "submitted": "2025-08-22 17:56:01",
        "source": "arxiv",
        "comment": "Accepted as a short paper at CIKM 2025",
        "score": 7,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'click' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on dwell time prediction in recommender systems, which is somewhat related to my interests in Information Retrieval and Search technologies. However, the paper's primary focus is on recommender systems and dwell time prediction, which is not a central match for my research themes. The paper's use of causal-decoupling and counterfactual intervention is interesting, but it does not directly relate to my interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Spacetime-GR: A Spacetime-Aware Generative Model for Large Scale Online POI Recommendation",
        "abstract": "Building upon the strong sequence modeling capability, Generative\nRecommendation (GR) has gradually assumed a dominant position in the\napplication of recommendation tasks (e.g., video and product recommendation).\nHowever, the application of Generative Recommendation in Point-of-Interest\n(POI) recommendation, where user preferences are significantly affected by\nspatiotemporal variations, remains a challenging open problem. In this paper,\nwe propose Spacetime-GR, the first spacetime-aware generative model for\nlarge-scale online POI recommendation. It extends the strong sequence modeling\nability of generative models by incorporating flexible spatiotemporal\ninformation encoding. Specifically, we first introduce a geographic-aware\nhierarchical POI indexing strategy to address the challenge of large vocabulary\nmodeling. Subsequently, a novel spatiotemporal encoding module is introduced to\nseamlessly incorporate spatiotemporal context into user action sequences,\nthereby enhancing the model's sensitivity to spatiotemporal variations.\nFurthermore, we incorporate multimodal POI embeddings to enrich the semantic\nunderstanding of each POI. Finally, to facilitate practical deployment, we\ndevelop a set of post-training adaptation strategies after sufficient\npre-training on action sequences. These strategies enable Spacetime-GR to\ngenerate outputs in multiple formats (i.e., embeddings, ranking scores and POI\ncandidates) and support a wide range of downstream application scenarios (i.e.,\nranking and end-to-end recommendation). We evaluate the proposed model on both\npublic benchmark datasets and large-scale industrial datasets, demonstrating\nits superior performance over existing methods in terms of POI recommendation\naccuracy and ranking quality. Furthermore, the model is the first generative\nmodel deployed in online POI recommendation services that scale to hundreds of\nmillions of POIs and users.",
        "url": "http://arxiv.org/abs/2508.16126v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16126v1",
        "arxiv_id": "2508.16126v1",
        "authors": [
            "Haitao Lin",
            "Zhen Yang",
            "Jiawei Xue",
            "Ziji Zhang",
            "Luzhu Wang",
            "Yikun Gu",
            "Yao Xu",
            "Xin Li"
        ],
        "submitted": "2025-08-22 06:37:57",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'user action' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a spacetime-aware generative model for POI recommendation, which is somewhat related to information retrieval and search technologies. However, the focus on POI recommendation and geographic-aware indexing strategy is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Text Takes Over: A Study of Modality Bias in Multimodal Intent Detection",
        "abstract": "The rise of multimodal data, integrating text, audio, and visuals, has\ncreated new opportunities for studying multimodal tasks such as intent\ndetection. This work investigates the effectiveness of Large Language Models\n(LLMs) and non-LLMs, including text-only and multi-modal models, in the\nmultimodal intent detection task. Our study reveals that Mistral-7B, a\ntext-only LLM, outperforms most competitive multimodal models by approximately\n9% on MIntRec-1 and 4% on MIntRec2.0 datasets. This performance advantage comes\nfrom a strong textual bias in these datasets, where over 90% of the samples\nrequire textual input, either alone or in combination with other modalities,\nfor correct classification. We confirm the modality bias of these datasets via\nhuman evaluation, too. Next, we propose a framework to debias the datasets, and\nupon debiasing, more than 70% of the samples in MIntRec-1 and more than 50% in\nMIntRec2.0 get removed, resulting in significant performance degradation across\nall models, with smaller multimodal fusion models being the most affected with\nan accuracy drop of over 50 - 60%. Further, we analyze the context-specific\nrelevance of different modalities through empirical analysis. Our findings\nhighlight the challenges posed by modality bias in multimodal intent datasets\nand emphasize the need for unbiased datasets to evaluate multimodal models\neffectively.",
        "url": "http://arxiv.org/abs/2508.16122v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16122v1",
        "arxiv_id": "2508.16122v1",
        "authors": [
            "Ankan Mullick",
            "Saransh Sharma",
            "Abhik Jana",
            "Pawan Goyal"
        ],
        "submitted": "2025-08-22 06:29:29",
        "source": "arxiv",
        "comment": "EMNLP 2025 Main Conference Full Paper",
        "score": 5,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'trec' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on multimodal intent detection, which is not directly related to the user's primary interest in Information Retrieval and Search technologies. While it touches on the topic of bias in datasets, the specific context of multimodal intent detection and the use of Large Language Models are not directly applicable to the user's research areas."
    },
    {
        "title": "MCPVerse: An Expansive, Real-World Benchmark for Agentic Tool Use",
        "abstract": "Large Language Models (LLMs) are evolving from text generators into reasoning\nagents. This transition makes their ability to use external tools a critical\ncapability. However, evaluating this skill presents a significant challenge.\nExisting benchmarks are often limited by their reliance on synthetic tools and\nseverely constrained action spaces. To address these limitations, we introduce\nMCPVerse, an expansive, real-world benchmark for evaluating agentic tool use.\nMCPVerse integrates more than 550 real-world, executable tools to create an\nunprecedented action space exceeding 140k tokens, and employs outcome-based\nevaluation with real-time ground truth for time-sensitive tasks. We benchmarked\nthe state-of-the-art LLMs across three modes (Oracle, Standard, and Max-Scale),\nrevealing that while most models suffer performance degradation when confronted\nwith larger tool sets, the agentic models, such as Claude-4-Sonnet, can\neffectively leverage expanded exploration spaces to improve accuracy. This\nfinding not only exposes the limitations of state-of-the-art models in complex,\nreal-world scenarios but also establishes MCPVerse as a critical benchmark for\nmeasuring and advancing agentic tool use capabilities.",
        "url": "http://arxiv.org/abs/2508.16260v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16260v1",
        "arxiv_id": "2508.16260v1",
        "authors": [
            "Fei Lei",
            "Yibo Yang",
            "Wenxiu Sun",
            "Dahua Lin"
        ],
        "submitted": "2025-08-22 09:47:53",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on evaluating Large Language Models' ability to use external tools, which is not directly related to Information Retrieval, Search technologies, or query understanding. Although it mentions real-time relevance optimization, the context is different from the user's primary research interests."
    },
    {
        "title": "LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence",
        "abstract": "In this paper, we describe and benchmark a competitor-discovery component\nused within an agentic AI system for fast drug asset due diligence. A\ncompetitor-discovery AI agent, given an indication, retrieves all drugs\ncomprising the competitive landscape of that indication and extracts canonical\nattributes for these drugs. The competitor definition is investor-specific, and\ndata is paywalled/licensed, fragmented across registries, ontology-mismatched\nby indication, alias-heavy for drug names, multimodal, and rapidly changing.\nAlthough considered the best tool for this problem, the current LLM-based AI\nsystems aren't capable of reliably retrieving all competing drug names, and\nthere is no accepted public benchmark for this task. To address the lack of\nevaluation, we use LLM-based agents to transform five years of multi-modal,\nunstructured diligence memos from a private biotech VC fund into a structured\nevaluation corpus mapping indications to competitor drugs with normalized\nattributes. We also introduce a competitor validating LLM-as-a-judge agent that\nfilters out false positives from the list of predicted competitors to maximize\nprecision and suppress hallucinations. On this benchmark, our\ncompetitor-discovery agent achieves 83% recall, exceeding OpenAI Deep Research\n(65%) and Perplexity Labs (60%). The system is deployed in production with\nenterprise users; in a case study with a biotech VC investment fund, analyst\nturnaround time dropped from 2.5 days to $\\sim$3 hours ($\\sim$20x) for the\ncompetitive analysis.",
        "url": "http://arxiv.org/abs/2508.16571v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16571v1",
        "arxiv_id": "2508.16571v1",
        "authors": [
            "Alisa Vinogradova",
            "Vlad Vinogradov",
            "Dmitrii Radkevich",
            "Ilya Yasny",
            "Dmitry Kobyzev",
            "Ivan Izmailov",
            "Katsiaryna Yanchanka",
            "Andrey Doronichev"
        ],
        "submitted": "2025-08-22 17:50:00",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on a specific domain (drug asset due diligence) and uses Large Language Models (LLMs) for competitor discovery, which is not directly related to your areas of interest."
    },
    {
        "title": "A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering",
        "abstract": "In the realm of collaborative filtering recommendation systems, Graph Neural\nNetworks (GNNs) have demonstrated remarkable performance but face significant\nchallenges in deployment on resource-constrained edge devices due to their high\nembedding parameter requirements and computational costs. Using common\nquantization method directly on node embeddings may overlooks their graph based\nstructure, causing error accumulation during message passing and degrading the\nquality of quantized embeddings.To address this, we propose Graph based\nNode-Aware Dynamic Quantization training for collaborative filtering (GNAQ), a\nnovel quantization approach that leverages graph structural information to\nenhance the balance between efficiency and accuracy of GNNs for Top-K\nrecommendation. GNAQ introduces a node-aware dynamic quantization strategy that\nadapts quantization scales to individual node embeddings by incorporating graph\ninteraction relationships. Specifically, it initializes quantization intervals\nbased on node-wise feature distributions and dynamically refines them through\nmessage passing in GNN layers. This approach mitigates information loss caused\nby fixed quantization scales and captures hierarchical semantic features in\nuser-item interaction graphs. Additionally, GNAQ employs graph relation-aware\ngradient estimation to replace traditional straight-through estimators,\nensuring more accurate gradient propagation during training. Extensive\nexperiments on four real-world datasets demonstrate that GNAQ outperforms\nstate-of-the-art quantization methods, including BiGeaR and N2UQ, by achieving\naverage improvement in 27.8\\% Recall@10 and 17.6\\% NDCG@10 under 2-bit\nquantization. In particular, GNAQ is capable of maintaining the performance of\nfull-precision models while reducing their model sizes by 8 to 12 times; in\naddition, the training time is twice as fast compared to quantization baseline\nmethods.",
        "url": "http://arxiv.org/abs/2508.16516v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16516v1",
        "arxiv_id": "2508.16516v1",
        "authors": [
            "Lin Li",
            "Chunyang Li",
            "Yu Yin",
            "Xiaohui Tao",
            "Jianwei Zhang"
        ],
        "submitted": "2025-08-22 16:39:53",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on graph-based collaborative filtering and quantization methods, which is not directly related to information retrieval, search technologies, or query understanding. While it does involve neural networks, the application is in recommender systems, which is a secondary interest. The paper's emphasis on graph structure and node-aware dynamic quantization is not aligned with the user's primary research themes."
    },
    {
        "title": "AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions",
        "abstract": "Competitive programming has emerged as a critical benchmark for evaluating\nthe reasoning and coding capabilities of Large Language Models (LLMs). Despite\nimpressive progress on existing benchmarks, we argue that current evaluations\noverstate model proficiency, masking a substantial gap between LLMs and elite\nhuman programmers. This gap arises from two key limitations: insufficient\ndifficulty and scope of benchmark problems, and evaluation bias from\nlow-quality test cases. To address these shortcomings, we present AetherCode, a\nnew benchmark that draws problems from premier programming competitions such as\nIOI and ICPC, offering broader coverage and higher difficulty. AetherCode\nfurther incorporates comprehensive, expert-validated test suites built through\na hybrid of automated generation and human curation, ensuring rigorous and\nreliable assessment. By combining challenging problem design with robust\nevaluation, AetherCode provides a more faithful measure of LLM capabilities and\nsets a new standard for future research in code reasoning.",
        "url": "http://arxiv.org/abs/2508.16402v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16402v1",
        "arxiv_id": "2508.16402v1",
        "authors": [
            "Zihan Wang",
            "Jiaze Chen",
            "Zhicheng Liu",
            "Markus Mak",
            "Yidi Du",
            "Geonsik Moon",
            "Luoqi Xu",
            "Aaron Tua",
            "Kunshuo Peng",
            "Jiayi Lu",
            "Mingfei Xia",
            "Boqian Zou",
            "Chenyang Ran",
            "Guang Tian",
            "Shoutai Zhu",
            "Yeheng Duan",
            "Zhenghui Kang",
            "Zhenxing Lin",
            "Shangshu Li",
            "Qiang Luo",
            "Qingshen Long",
            "Zhiyong Chen",
            "Yihan Xiao",
            "Yurong Wu",
            "Daoguang Zan",
            "Yuyi Fu",
            "Mingxuan Wang",
            "Ming Ding"
        ],
        "submitted": "2025-08-22 14:04:55",
        "source": "arxiv",
        "comment": "15 pages",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, and Natural Language Processing. The topic of competitive programming and Large Language Models is not directly related to the user's areas of focus."
    },
    {
        "title": "ParamBench: A Graduate-Level Benchmark for Evaluating LLM Understanding on Indic Subjects",
        "abstract": "Large language models (LLMs) have been widely evaluated on tasks such as\ncomprehension, question answering, summarization, code generation, etc.\nHowever, their performance on graduate-level, culturally grounded questions in\nthe Indian context remains largely unexplored. Existing Indian benchmarks\nemphasise basic fact-orientated queries that offer limited assessment of a\ndeeper disciplinary understanding tailored to the Indian setting. In this\npaper, we present ParamBench, consisting of around 11.5K questions in Hindi\nlanguage comprising questionnaires from 16 diverse subjects. These questions\nare primarily derived from nation-wide graduate level entrance examination\ncovering topics such as history, music, instruments, yoga, literature,\nphilosophy, law, etc., specifically for the Indian context. Additionally, we\nassess the ability of LLMs to handle diverse question formats-such as\nlist-based matching, assertion-reason pairs, and sequence ordering-alongside\nconventional multiple-choice questions. We evaluated the performance of more\nthan 17 open source LLMs on this benchmark, observing that Llama 3.3 70B\nattains the highest overall accuracy of 48%. Furthermore, subject-wise analysis\nindicates that even for the best performing LLMs, performance remains weak on\ntopics such as music, classical instruments, politics and archaeology,\nunderscoring persistent challenges in culturally grounded reasoning.",
        "url": "http://arxiv.org/abs/2508.16185v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16185v1",
        "arxiv_id": "2508.16185v1",
        "authors": [
            "Kaushal Sharma",
            "Vivek Patel",
            "Ayush Maheshwari",
            "Aditya Maheshwari"
        ],
        "submitted": "2025-08-22 07:59:37",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on evaluating large language models' understanding on graduate-level questions in the Indian context, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on topics like question understanding and ranking models, the primary focus is on evaluating language models' comprehension rather than developing new IR or NLP techniques."
    },
    {
        "title": "EGRA:Toward Enhanced Behavior Graphs and Representation Alignment for Multimodal Recommendation",
        "abstract": "MultiModal Recommendation (MMR) systems have emerged as a promising solution\nfor improving recommendation quality by leveraging rich item-side modality\ninformation, prompting a surge of diverse methods. Despite these advances,\nexisting methods still face two critical limitations. First, they use raw\nmodality features to construct item-item links for enriching the behavior\ngraph, while giving limited attention to balancing collaborative and\nmodality-aware semantics or mitigating modality noise in the process. Second,\nthey use a uniform alignment weight across all entities and also maintain a\nfixed alignment strength throughout training, limiting the effectiveness of\nmodality-behavior alignment. To address these challenges, we propose EGRA.\nFirst, instead of relying on raw modality features, it alleviates sparsity by\nincorporating into the behavior graph an item-item graph built from\nrepresentations generated by a pretrained MMR model. This enables the graph to\ncapture both collaborative patterns and modality aware similarities with\nenhanced robustness against modality noise. Moreover, it introduces a novel\nbi-level dynamic alignment weighting mechanism to improve modality-behavior\nrepresentation alignment, which dynamically assigns alignment strength across\nentities according to their alignment degree, while gradually increasing the\noverall alignment intensity throughout training. Extensive experiments on five\ndatasets show that EGRA significantly outperforms recent methods, confirming\nits effectiveness.",
        "url": "http://arxiv.org/abs/2508.16170v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16170v1",
        "arxiv_id": "2508.16170v1",
        "authors": [
            "Xiaoxiong Zhang",
            "Xin Zhou",
            "Zhiwei Zeng",
            "Yongjie Wang",
            "Dusit Niyato",
            "Zhiqi Shen"
        ],
        "submitted": "2025-08-22 07:47:54",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Multimodal Recommendation, which is not directly related to Information Retrieval or Search technologies. While it mentions behavior graphs and representation alignment, the context is different from query understanding, ranking models, and user behavior modeling. The paper's relevance is somewhat limited, but it may still be of interest to those working on recommender systems."
    },
    {
        "title": "AgentFly: Fine-tuning LLM Agents without Fine-tuning LLMs",
        "abstract": "In this paper, we introduce a novel learning paradigm for adaptive Large\nLanguage Model (LLM) agents that eliminates the need for fine-tuning the\nunderlying LLMs. Existing approaches are often either rigid, relying on static,\nhandcrafted reflection workflows, or computationally intensive, requiring\ngradient updates of LLM model parameters. In contrast, our method enables\nlow-cost continual adaptation via memory-based online reinforcement learning.\nWe formalise this as a Memory-augmented Markov Decision Process (M-MDP),\nequipped with a neural case-selection policy to guide action decisions. Past\nexperiences are stored in an episodic memory, either differentiable or\nnon-parametric. The policy is continually updated based on environmental\nfeedback through a memory rewriting mechanism, whereas policy improvement is\nachieved through efficient memory reading (retrieval). We instantiate our agent\nmodel in the deep research setting, namely AgentFly, which attains top-1 on\nGAIA validation ($87.88\\%$ Pass@$3$) and $79.40\\%$ on the test set. It reaches\n$66.6\\%$ F1 and $80.4\\%$ PM on the DeepResearcher dataset, outperforming the\nstate-of-the-art training-based method, while case-based memory adds $4.7\\%$ to\n$9.6\\%$ absolute points on out-of-distribution tasks. Our approach offers a\nscalable and efficient pathway for developing generalist LLM agents capable of\ncontinuous, real-time learning without gradient updates, advancing machine\nlearning towards open-ended skill acquisition and deep research scenarios. The\ncode is available at https://github.com/Agent-on-the-Fly/AgentFly.",
        "url": "http://arxiv.org/abs/2508.16153v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16153v1",
        "arxiv_id": "2508.16153v1",
        "authors": [
            "Huichi Zhou",
            "Yihang Chen",
            "Siyuan Guo",
            "Xue Yan",
            "Kin Hei Lee",
            "Zihan Wang",
            "Ka Yiu Lee",
            "Guchun Zhang",
            "Kun Shao",
            "Linyi Yang",
            "Jun Wang"
        ],
        "submitted": "2025-08-22 07:25:30",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on developing a novel learning paradigm for adaptive Large Language Model (LLM) agents, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions reinforcement learning and memory-based online learning, these concepts are not typically used in IR and Search. The paper's focus on LLM agents and machine learning is more relevant to NLP and data mining, but it does not align with the user's specific interests in ranking models, user behavior modeling, or real-time relevance optimization."
    },
    {
        "title": "Extending FKG.in: Towards a Food Claim Traceability Network",
        "abstract": "The global food landscape is rife with scientific, cultural, and commercial\nclaims about what foods are, what they do, what they should not do, or should\nnot do. These range from rigorously studied health benefits (probiotics improve\ngut health) and misrepresentations (soaked almonds make one smarter) to vague\npromises (superfoods boost immunity) and culturally rooted beliefs (cold foods\ncause coughs). Despite their widespread influence, the infrastructure for\ntracing, verifying, and contextualizing these claims remains fragmented and\nunderdeveloped. In this paper, we propose a Food Claim-Traceability Network\n(FCN) as an extension of FKG.in, a knowledge graph of Indian food that we have\nbeen incrementally building. We also present the ontology design and the\nsemi-automated knowledge curation workflow that we used to develop a proof of\nconcept of FKG.in-FCN using Reddit data and Large Language Models. FCN\nintegrates curated data inputs, structured schemas, and provenance-aware\npipelines for food-related claim extraction and validation. While directly\nlinked to the Indian food knowledge graph as an application, our methodology\nremains application-agnostic and adaptable to other geographic, culinary, or\nregulatory settings. By modeling food claims and their traceability in a\nstructured, verifiable, and explainable way, we aim to contribute to more\ntransparent and accountable food knowledge ecosystems, supporting researchers,\npolicymakers, and most importantly, everyday consumers in navigating a world\nsaturated with dietary assertions.",
        "url": "http://arxiv.org/abs/2508.16117v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16117v1",
        "arxiv_id": "2508.16117v1",
        "authors": [
            "Saransh Kumar Gupta",
            "Rizwan Gulzar Mir",
            "Lipika Dey",
            "Partha Pratim Das",
            "Anirban Sen",
            "Ramesh Jain"
        ],
        "submitted": "2025-08-22 06:18:51",
        "source": "arxiv",
        "comment": "10 pages, 3 figures, 1 table, 45 references, ACM International\n  Conference on Multimedia 2025 - Multi-modal Food Computing Workshop",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topic of food claim traceability network is outside the scope of your expertise and does not involve query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Similarity-Based Supervised User Session Segmentation Method for Behavior Logs",
        "abstract": "In information recommendation, a session refers to a sequence of user actions\nwithin a specific time frame. Session-based recommender systems aim to capture\nshort-term preferences and generate relevant recommendations. However, user\ninterests may shift even within a session, making appropriate segmentation\nessential for modeling dynamic behaviors. In this study, we propose a\nsupervised session segmentation method based on similarity features derived\nfrom action embeddings and attributes. We compute the similarity scores between\nitems within a fixed-size window around each candidate segmentation point,\nusing four types of features: item co-occurrence embeddings, text embeddings of\ntitles and brands, and price. These features are used to train supervised\nclassifiers (LightGBM, XGBoost, CatBoost, support vector machine, and logistic\nregression) to predict the session boundaries. We construct a manually\nannotated dataset from real user browsing histories and evaluate the\nsegmentation performance using F1-score, area under the precision-recall curve\n(PR-AUC), and area under the receiver operating characteristic curve. The\nLightGBM model achieves the best performance, with an F1-score of 0.806 and a\nPR-AUC of 0.831. These results demonstrate the effectiveness of the proposed\nmethod for session segmentation and its potential to capture dynamic user\nbehaviors.",
        "url": "http://arxiv.org/abs/2508.16106v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16106v1",
        "arxiv_id": "2508.16106v1",
        "authors": [
            "Yongzhi Jin",
            "Kazushi Okamoto",
            "Kei Harada",
            "Atsushi Shibata",
            "Koki Karube"
        ],
        "submitted": "2025-08-22 05:47:42",
        "source": "arxiv",
        "comment": "Submitted to Journal of Advanced Computational Intelligence and\n  Intelligent Informatics",
        "score": 3,
        "keyword_reasons": [
            "Found 'user action' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper proposes a supervised session segmentation method for behavior logs, which is related to user behavior modeling and recommender systems. However, it does not directly address query understanding, ranking models, or deep semantic understanding, which are core aspects of your research interests."
    },
    {
        "title": "Less Redundancy: Boosting Practicality of Vision Language Model in Walking Assistants",
        "abstract": "Approximately 283 million people worldwide live with visual impairments,\nmotivating increasing research into leveraging Visual Language Models (VLMs) to\ndevelop effective walking assistance systems for blind and low vision\nindividuals. However, existing VLMs in walking assistant task often have\noutputs that contain considerable redundancy and extraneous details, adversely\naffecting users' ability to accurately assess their surroundings. Moreover,\nthese models typically lack the capability to proactively assess environmental\nrisks and adaptively trigger reminders based on the appropriate scene, leading\nto excessive temporal redundancy. To mitigate output and temporal redundancy,\nwe propose WalkVLM-LR, a walking assistance model with less redundancy. To\nreduce output redundancy, we introduce four human-preference-based custom\nreward functions within the GRPO-based reasoning framework to optimize the\noutput in terms of conciseness, fluency, keyword density, and accuracy, thereby\nproducing more informative and streamlined outputs. To minimize temporal\nredundancy, we incorporate an environment awareness discriminator, which shares\nthe visual encoder with the VLMs to reduce redundant computations and enhance\ndiscriminative efficiency, to make WalkVLM-LR assess scene risk levels and\nminimize unnecessary reminders. Experimental results demonstrate that our\nmethod achieves state-of-the-art performance across all evaluation metrics\ncompared with other models, particularly in output conciseness and less\ntemporal redundancy.",
        "url": "http://arxiv.org/abs/2508.16070v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16070v1",
        "arxiv_id": "2508.16070v1",
        "authors": [
            "Chongyang Li",
            "Yuan Zhiqiang",
            "Jiapei Zhang",
            "Ying Deng",
            "Hanbo Bi",
            "Zexi Jia",
            "Xiaoyue Duan",
            "Peixiang Luo",
            "Jinchao Zhang"
        ],
        "submitted": "2025-08-22 03:56:30",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on Visual Language Models for walking assistance systems, which is not related to Information Retrieval, Search technologies, or Natural Language Processing. The concepts of query understanding, ranking models, and user behavior modeling are not addressed in this paper."
    },
    {
        "title": "OpenWHO: A Document-Level Parallel Corpus for Health Translation in Low-Resource Languages",
        "abstract": "In machine translation (MT), health is a high-stakes domain characterised by\nwidespread deployment and domain-specific vocabulary. However, there is a lack\nof MT evaluation datasets for low-resource languages in this domain. To address\nthis gap, we introduce OpenWHO, a document-level parallel corpus of 2,978\ndocuments and 26,824 sentences from the World Health Organization's e-learning\nplatform. Sourced from expert-authored, professionally translated materials\nshielded from web-crawling, OpenWHO spans a diverse range of over 20 languages,\nof which nine are low-resource. Leveraging this new resource, we evaluate\nmodern large language models (LLMs) against traditional MT models. Our findings\nreveal that LLMs consistently outperform traditional MT models, with Gemini 2.5\nFlash achieving a +4.79 ChrF point improvement over NLLB-54B on our\nlow-resource test set. Further, we investigate how LLM context utilisation\naffects accuracy, finding that the benefits of document-level translation are\nmost pronounced in specialised domains like health. We release the OpenWHO\ncorpus to encourage further research into low-resource MT in the health domain.",
        "url": "http://arxiv.org/abs/2508.16048v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16048v1",
        "arxiv_id": "2508.16048v1",
        "authors": [
            "Raphaël Merx",
            "Hanna Suominen",
            "Trevor Cohn",
            "Ekaterina Vylomova"
        ],
        "submitted": "2025-08-22 02:53:56",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on machine translation in the health domain, which is related to information retrieval, but the scope is limited to translation and does not directly address query understanding, ranking models, or user behavior modeling. The paper's emphasis on low-resource languages and large language models is also not directly relevant to the user's interests in e-commerce and real-time relevance optimization."
    },
    {
        "title": "Sparse but Wrong: Incorrect L0 Leads to Incorrect Features in Sparse Autoencoders",
        "abstract": "Sparse Autoencoders (SAEs) extract features from LLM internal activations,\nmeant to correspond to single concepts. A core SAE training hyperparameter is\nL0: how many features should fire per token on average. Existing work compares\nSAE algorithms using sparsity--reconstruction tradeoff plots, implying L0 is a\nfree parameter with no single correct value. In this work we study the effect\nof L0 on BatchTopK SAEs, and show that if L0 is not set precisely, the SAE\nfails to learn the underlying features of the LLM. If L0 is too low, the SAE\nwill mix correlated features to improve reconstruction. If L0 is too high, the\nSAE finds degenerate solutions that also mix features. Further, we demonstrate\na method to determine the correct L0 value for an SAE on a given training\ndistribution, which finds the true L0 in toy models and coincides with peak\nsparse probing performance in LLMs. We find that most commonly used SAEs have\nan L0 that is too low. Our work shows that, to train SAEs with correct\nfeatures, practitioners must set L0 correctly.",
        "url": "http://arxiv.org/abs/2508.16560v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16560v1",
        "arxiv_id": "2508.16560v1",
        "authors": [
            "David Chanin",
            "Adrià Garriga-Alonso"
        ],
        "submitted": "2025-08-22 17:26:33",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on sparse autoencoders and their training hyperparameters, which is not directly related to information retrieval, search technologies, or query understanding. The topic is more relevant to natural language processing and deep learning, but the specific context and methodology are not aligned with the user's research interests."
    },
    {
        "title": "FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline",
        "abstract": "Recent works improving LLM math reasoning with synthetic data have used\nunique setups, making comparison of data synthesis strategies impractical. This\nleaves many unanswered questions about the roles of different factors in the\nsynthetic data pipeline, such as the impact of filtering low-quality problems.\nTo address this gap, we introduce FLAMES, a Framework for LLM Assessment of\nMath rEasoning Data Synthesis, and perform a systematic study of 10 existing\ndata synthesis strategies and multiple other factors impacting the performance\nof synthetic math reasoning data. Our FLAMES experiments provide several\nvaluable insights about the optimal balance of difficulty and diversity of\nsynthetic data. First, data agents designed to increase problem complexity lead\nto best improvements on most math metrics. Second, with a fixed data generation\nbudget, keeping higher problem coverage is more important than keeping only\nproblems with reliable solutions. Third, GSM8K- and MATH-based synthetic data\ncan lead to improvements on competition-level benchmarks, showcasing\neasy-to-hard generalization. Leveraging insights from our FLAMES experiments,\nwe design two novel data synthesis strategies for improving out-of-domain\ngeneralization and robustness. Further, we develop the FLAMES dataset, an\neffective blend of our novel and existing data synthesis strategies,\noutperforming public datasets on OlympiadBench (+15.7), CollegeMath (+4.5),\nGSMPlus (+6.5), and MATH (+3.1). Fine-tuning Qwen2.5-Math-7B on the FLAMES\ndataset achieves 81.4% on MATH, surpassing larger Llama3 405B, GPT-4o and\nClaude 3.5 Sonnet.",
        "url": "http://arxiv.org/abs/2508.16514v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16514v1",
        "arxiv_id": "2508.16514v1",
        "authors": [
            "Parker Seegmiller",
            "Kartik Mehta",
            "Soumya Saha",
            "Chenyang Tao",
            "Shereen Oraby",
            "Arpit Gupta",
            "Tagyoung Chung",
            "Mohit Bansal",
            "Nanyun Peng"
        ],
        "submitted": "2025-08-22 16:37:40",
        "source": "arxiv",
        "comment": "To appear at EMNLP 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on improving Large Language Model (LLM) math reasoning using synthetic data, which is outside your primary research areas. While it mentions some data synthesis strategies, the paper's scope and methodology are not aligned with your interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "LLM-as-classifier: Semi-Supervised, Iterative Framework for Hierarchical Text Classification using Large Language Models",
        "abstract": "The advent of Large Language Models (LLMs) has provided unprecedented\ncapabilities for analyzing unstructured text data. However, deploying these\nmodels as reliable, robust, and scalable classifiers in production environments\npresents significant methodological challenges. Standard fine-tuning approaches\ncan be resource-intensive and often struggle with the dynamic nature of\nreal-world data distributions, which is common in the industry. In this paper,\nwe propose a comprehensive, semi-supervised framework that leverages the zero-\nand few-shot capabilities of LLMs for building hierarchical text classifiers as\na framework for a solution to these industry-wide challenges. Our methodology\nemphasizes an iterative, human-in-the-loop process that begins with domain\nknowledge elicitation and progresses through prompt refinement, hierarchical\nexpansion, and multi-faceted validation. We introduce techniques for assessing\nand mitigating sequence-based biases and outline a protocol for continuous\nmonitoring and adaptation. This framework is designed to bridge the gap between\nthe raw power of LLMs and the practical need for accurate, interpretable, and\nmaintainable classification systems in industry applications.",
        "url": "http://arxiv.org/abs/2508.16478v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16478v1",
        "arxiv_id": "2508.16478v1",
        "authors": [
            "Doohee You",
            "Andy Parisi",
            "Zach Vander Velden",
            "Lara Dantas Inojosa"
        ],
        "submitted": "2025-08-22 15:47:17",
        "source": "arxiv",
        "comment": "20 pages excluding reference list, 2 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on leveraging Large Language Models for hierarchical text classification, which is a relevant topic in Natural Language Processing. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core aspects of Information Retrieval. The paper's emphasis on practical applications and industry challenges is somewhat related to the e-commerce domain, but the connection is loose."
    },
    {
        "title": "What makes an entity salient in discourse?",
        "abstract": "Entities in discourse vary broadly in salience: main participants, objects\nand locations are noticeable and memorable, while tangential ones are less\nimportant and quickly forgotten, raising questions about how humans signal and\ninfer relative salience. Using a graded operationalization of salience based on\nsummary-worthiness in multiple summaries of a discourse, this paper explores\ndata from 24 spoken and written genres of English to extract a multifactorial\ncomplex of overt and implicit linguistic cues, such as recurring subjecthood or\ndefiniteness, discourse relations and hierarchy across utterances, as well as\npragmatic functional inferences based on genre and communicative intent.\nTackling the question 'how is the degree of salience expressed for each and\nevery entity mentioned?' our results show that while previous approaches to\nsalience all correlate with our salience scores to some extent, no single\ngeneralization is without exceptions, and the phenomenon cuts across all levels\nof linguistic representation.",
        "url": "http://arxiv.org/abs/2508.16464v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16464v1",
        "arxiv_id": "2508.16464v1",
        "authors": [
            "Amir Zeldes",
            "Jessica Lin"
        ],
        "submitted": "2025-08-22 15:30:40",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it touches on linguistic cues and inferences, the focus is on discourse analysis and entity salience, which is outside the scope of the user's primary research interests."
    },
    {
        "title": "LLMSymGuard: A Symbolic Safety Guardrail Framework Leveraging Interpretable Jailbreak Concepts",
        "abstract": "Large Language Models have found success in a variety of applications;\nhowever, their safety remains a matter of concern due to the existence of\nvarious types of jailbreaking methods. Despite significant efforts, alignment\nand safety fine-tuning only provide a certain degree of robustness against\njailbreak attacks that covertly mislead LLMs towards the generation of harmful\ncontent. This leaves them prone to a number of vulnerabilities, ranging from\ntargeted misuse to accidental profiling of users. This work introduces\n\\textbf{LLMSymGuard}, a novel framework that leverages Sparse Autoencoders\n(SAEs) to identify interpretable concepts within LLM internals associated with\ndifferent jailbreak themes. By extracting semantically meaningful internal\nrepresentations, LLMSymGuard enables building symbolic, logical safety\nguardrails -- offering transparent and robust defenses without sacrificing\nmodel capabilities or requiring further fine-tuning. Leveraging advances in\nmechanistic interpretability of LLMs, our approach demonstrates that LLMs learn\nhuman-interpretable concepts from jailbreaks, and provides a foundation for\ndesigning more interpretable and logical safeguard measures against attackers.\nCode will be released upon publication.",
        "url": "http://arxiv.org/abs/2508.16325v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16325v1",
        "arxiv_id": "2508.16325v1",
        "authors": [
            "Darpan Aswal",
            "Céline Hudelot"
        ],
        "submitted": "2025-08-22 12:13:38",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on the safety of Large Language Models and introduces a framework to identify interpretable concepts within LLM internals associated with different jailbreak themes. While it mentions advances in mechanistic interpretability of LLMs, it does not directly relate to query understanding, ranking models, or user behavior modeling in the context of Information Retrieval and Search technologies, which are the user's primary research interests."
    },
    {
        "title": "From Confidence to Collapse in LLM Factual Robustness",
        "abstract": "Ensuring the robustness of factual knowledge in LLMs is critical for reliable\napplications in tasks such as question answering and reasoning. However,\nexisting evaluation methods predominantly focus on performance-based metrics,\noften investigating from the perspective of prompt perturbations, which\ncaptures only the externally triggered side of knowledge robustness. To bridge\nthis gap, we introduce a principled approach to measure factual robustness from\nthe perspective of the generation process by analyzing token distribution\nentropy in combination with temperature scaling sensitivity. These two factors\nbuild the Factual Robustness Score (FRS), a novel metric which quantifies the\nstability of a fact against perturbations in decoding conditions, given its\ninitial uncertainty. To validate our approach, we conduct extensive experiments\non 5 LLMs across 3 closed-book QA datasets (SQuAD, TriviaQA, and HotpotQA). We\nshow that factual robustness varies significantly -- smaller models report an\nFRS of $0.76$, larger ones $0.93$ -- with accuracy degrading by ~$60\\%$ under\nincreased uncertainty. These insights demonstrate how entropy and temperature\nscaling impact factual accuracy, and lay a foundation for developing more\nrobust knowledge retention and retrieval in future models.",
        "url": "http://arxiv.org/abs/2508.16267v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16267v1",
        "arxiv_id": "2508.16267v1",
        "authors": [
            "Alina Fastowski",
            "Bardh Prenkaj",
            "Gjergji Kasneci"
        ],
        "submitted": "2025-08-22 09:59:23",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on the robustness of factual knowledge in Large Language Models (LLMs) for tasks like question answering and reasoning, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on the concept of uncertainty, it does not explore ranking models, user behavior modeling, or real-time relevance optimization, making it only loosely relevant to the user's research interests."
    },
    {
        "title": "Hierarchical Vision-Language Reasoning for Multimodal Multiple-Choice Question Answering",
        "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\nmultimodal understanding capabilities in Visual Question Answering (VQA) tasks\nby integrating visual and textual features. However, under the challenging\nten-choice question evaluation paradigm, existing methods still exhibit\nsignificant limitations when processing PDF documents with complex layouts and\nlengthy content. Notably, current mainstream models suffer from a strong bias\ntoward English training data, resulting in suboptimal performance for Japanese\nand other language scenarios. To address these challenges, this paper proposes\na novel Japanese PDF document understanding framework that combines multimodal\nhierarchical reasoning mechanisms with Colqwen-optimized retrieval methods,\nwhile innovatively introducing a semantic verification strategy through\nsub-question decomposition. Experimental results demonstrate that our framework\nnot only significantly enhances the model's deep semantic parsing capability\nfor complex documents, but also exhibits superior robustness in practical\napplication scenarios.",
        "url": "http://arxiv.org/abs/2508.16148v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16148v1",
        "arxiv_id": "2508.16148v1",
        "authors": [
            "Ao Zhou",
            "Zebo Gu",
            "Tenghao Sun",
            "Jiawen Chen",
            "Mingsheng Tu",
            "Zifeng Cheng",
            "Yafeng Yin",
            "Zhiwei Jiang",
            "Qing Gu"
        ],
        "submitted": "2025-08-22 07:17:16",
        "source": "arxiv",
        "comment": "This paper has been accepted by ACM MM 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on multimodal understanding in Visual Question Answering, which is not directly related to Information Retrieval, Search technologies, or query understanding. Although it mentions multimodal hierarchical reasoning, the context is not applicable to the user's research interests in IR and NLP."
    },
    {
        "title": "Integrating Time Series into LLMs via Multi-layer Steerable Embedding Fusion for Enhanced Forecasting",
        "abstract": "Time series (TS) data are ubiquitous across various application areas,\nrendering time series forecasting (TSF) a fundamental task. With the astounding\nadvances in large language models (LLMs), a variety of methods have been\ndeveloped to adapt LLMs for time series forecasting. Despite unlocking the\npotential of LLMs in comprehending TS data, existing methods are inherently\nconstrained by their shallow integration of TS information, wherein LLMs\ntypically access TS representations at shallow layers, primarily at the input\nlayer. This causes the influence of TS representations to progressively fade in\ndeeper layers and eventually leads to ineffective adaptation between textual\nembeddings and TS representations. In this paper, we propose the Multi-layer\nSteerable Embedding Fusion (MSEF), a novel framework that enables LLMs to\ndirectly access time series patterns at all depths, thereby mitigating the\nprogressive loss of TS information in deeper layers. Specifically, MSEF\nleverages off-the-shelf time series foundation models to extract semantically\nrich embeddings, which are fused with intermediate text representations across\nLLM layers via layer-specific steering vectors. These steering vectors are\ndesigned to continuously optimize the alignment between time series and textual\nmodalities and facilitate a layer-specific adaptation mechanism that ensures\nefficient few-shot learning capabilities. Experimental results on seven\nbenchmarks demonstrate significant performance improvements by MSEF compared\nwith baselines, with an average reduction of 31.8% in terms of MSE. The code is\navailable at https://github.com/One1sAll/MSEF.",
        "url": "http://arxiv.org/abs/2508.16059v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16059v1",
        "arxiv_id": "2508.16059v1",
        "authors": [
            "Zhuomin Chen",
            "Dan Li",
            "Jiahui Zhou",
            "Shunyu Wu",
            "Haozheng Ye",
            "Jian Lou",
            "See-Kiong Ng"
        ],
        "submitted": "2025-08-22 03:22:10",
        "source": "arxiv",
        "comment": "To be published in CIKM 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on integrating time series data into large language models for forecasting, which is not directly related to information retrieval, search technologies, or query understanding. While it involves embedding fusion, the context is different from the user's research interests in IR and NLP."
    },
    {
        "title": "Generative Foundation Model for Structured and Unstructured Electronic Health Records",
        "abstract": "Electronic health records (EHRs) are rich clinical data sources but complex\nrepositories of patient data, spanning structured elements (demographics,\nvitals, lab results, codes), unstructured clinical notes and other modalities\nof data. Harnessing this heterogeneity is critical for improving patient\noutcomes. Recent advances in large language models (LLMs) have enabled\nfoundation models that can learn from multiple data modalities and support\nclinical tasks. However, most current approaches simply serialize numeric EHR\ndata into text, which risks losing temporal and quantitative detail. We\nintroduce Generative Deep Patient (GDP), a multimodal foundation model that\nnatively encodes structured EHR time-series via a CNN-Transformer encoder and\nfuses it with unstructured EHRs through cross-modal attention into a\nLLaMA-based decoder. GDP is trained in two stages: (1) generative pretraining,\nwhere it learns to produce clinical narratives from raw patient timelines while\nalso performing masked feature prediction (MFP) and next time-step prediction\n(NTP) to capture temporal dynamics; and (2) multi-task fine-tuning for\nclinically meaningful predictions (e.g., heart failure, type 2 diabetes, 30-day\nreadmission). In clinical prediction, GDP demonstrated superior performance on\nMIMIC-IV: heart failure AUROC = 0.923, type 2 diabetes AUROC = 0.817, and\n30-day readmission AUROC = 0.627. For narrative generation, GDP achieved\nROUGE-L = 0.135 and BERTScore-F1 = 0.545. In a blinded human evaluation,\nGDP-Instruct scored highest on faithfulness, fluency, and overall clinical\nutility, suggesting reduced hospital documentation workload without sacrificing\naccuracy. Our results demonstrate that a single multimodal foundation model can\nboth predict clinically actionable events and generate high-quality clinical\nnarratives. Furthermore, GDP's flexible architecture can be extended to\nadditional modalities.",
        "url": "http://arxiv.org/abs/2508.16054v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16054v1",
        "arxiv_id": "2508.16054v1",
        "authors": [
            "Sonish Sivarajkumar",
            "Hang Zhang",
            "Yuelyu Ji",
            "Maneesh Bilalpur",
            "Xizhi Wu",
            "Chenyu Li",
            "Min Gu Kwak",
            "Shyam Visweswaran",
            "Yanshan Wang"
        ],
        "submitted": "2025-08-22 03:05:09",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on developing a foundation model for structured and unstructured electronic health records, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing and multimodal fusion, the application is specific to the healthcare domain and does not align with the user's broader research interests."
    },
    {
        "title": "Political Ideology Shifts in Large Language Models",
        "abstract": "Large language models (LLMs) are increasingly deployed in politically\nsensitive settings, raising concerns about their potential to encode, amplify,\nor be steered toward specific ideologies. We investigate how adopting synthetic\npersonas influences ideological expression in LLMs across seven models (7B-70B+\nparameters) from multiple families, using the Political Compass Test as a\nstandardized probe. Our analysis reveals four consistent patterns: (i) larger\nmodels display broader and more polarized implicit ideological coverage; (ii)\nsusceptibility to explicit ideological cues grows with scale; (iii) models\nrespond more strongly to right-authoritarian than to left-libertarian priming;\nand (iv) thematic content in persona descriptions induces systematic and\npredictable ideological shifts, which amplify with size. These findings\nindicate that both scale and persona content shape LLM political behavior. As\nsuch systems enter decision-making, educational, and policy contexts, their\nlatent ideological malleability demands attention to safeguard fairness,\ntransparency, and safety.",
        "url": "http://arxiv.org/abs/2508.16013v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16013v1",
        "arxiv_id": "2508.16013v1",
        "authors": [
            "Pietro Bernardelle",
            "Stefano Civelli",
            "Leon Fröhling",
            "Riccardo Lunardi",
            "Kevin Roitero",
            "Gianluca Demartini"
        ],
        "submitted": "2025-08-22 00:16:38",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The focus on large language models and political ideology shifts is outside your primary areas of interest, and the paper does not address topics like e-commerce, recommender systems, or deep semantic understanding."
    },
    {
        "title": "Dancing with Deer: A Constructional Perspective on MWEs in the Era of LLMs",
        "abstract": "In this chapter, we argue for the benefits of understanding multiword\nexpressions from the perspective of usage-based, construction grammar\napproaches. We begin with a historical overview of how construction grammar was\ndeveloped in order to account for idiomatic expressions using the same\ngrammatical machinery as the non-idiomatic structures of language. We cover a\ncomprehensive description of constructions, which are pairings of meaning with\nform of any size (morpheme, word, phrase), as well as how constructional\napproaches treat the acquisition and generalization of constructions. We\ndescribe a successful case study leveraging constructional templates for\nrepresenting multiword expressions in English PropBank. Because constructions\ncan be at any level or unit of form, we then illustrate the benefit of a\nconstructional representation of multi-meaningful morphosyntactic unit\nconstructions in Arapaho, a highly polysynthetic and agglutinating language. We\ninclude a second case study leveraging constructional templates for\nrepresenting these multi-morphemic expressions in Uniform Meaning\nRepresentation. Finally, we demonstrate the similarities and differences\nbetween a usage-based explanation of a speaker learning a novel multiword\nexpression, such as \"dancing with deer,\" and that of a large language model. We\npresent experiments showing that both models and speakers can generalize the\nmeaning of novel multiword expressions based on a single exposure of usage.\nHowever, only speakers can reason over the combination of two such expressions,\nas this requires comparison of the novel forms to a speaker's lifetime of\nstored constructional exemplars, which are rich with cross-modal details.",
        "url": "http://arxiv.org/abs/2508.15977v1",
        "pdf_url": "http://arxiv.org/pdf/2508.15977v1",
        "arxiv_id": "2508.15977v1",
        "authors": [
            "Claire Bonial",
            "Julia Bonn",
            "Harish Tayyar Madabushi"
        ],
        "submitted": "2025-08-21 21:42:50",
        "source": "arxiv",
        "comment": "Chapter in Phraseology and Multiword Expressions, Language Science\n  Press (to appear)",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on constructional grammar and multiword expressions, which is unrelated to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's abstract does not mention query understanding, ranking models, or user behavior modeling, and its topics are not relevant to the user's background in e-commerce or real-time relevance optimization."
    },
    {
        "title": "ASIC-Agent: An Autonomous Multi-Agent System for ASIC Design with Benchmark Evaluation",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nRegister Transfer Level (RTL) design, enabling high-quality code generation\nfrom natural language descriptions. However, LLMs alone face significant\nlimitations in real-world hardware design workflows, including the inability to\nexecute code, lack of debugging capabilities, and absence of long-term memory.\nTo address these challenges, we present ASIC-Agent, an autonomous system\ndesigned specifically for digital ASIC design tasks. ASIC-Agent enhances base\nLLMs with a multi-agent architecture incorporating specialized sub-agents for\nRTL generation, verification, OpenLane hardening, and Caravel chip integration,\nall operating within a comprehensive sandbox environment with access to\nessential hardware design tools. The system leverages a vector database\ncontaining documentation, API references, error knowledge, and curated insights\nfrom the open-source silicon community. To evaluate ASIC-Agent's performance,\nwe introduce ASIC-Agent-Bench, the first benchmark specifically designed to\nassess agentic systems in hardware design tasks. We evaluate ASIC-Agent with\nvarious base LLMs, providing quantitative comparisons and qualitative insights\ninto agent behavior across different design scenarios. Our results demonstrate\nthat ASIC-Agent, when powered by Claude 4 Sonnet, successfully automates a\nbroad range of ASIC design tasks spanning varying levels of complexity, showing\nthe potential of significantly accelerating the ASIC design workflow.",
        "url": "http://arxiv.org/abs/2508.15940v1",
        "pdf_url": "http://arxiv.org/pdf/2508.15940v1",
        "arxiv_id": "2508.15940v1",
        "authors": [
            "Ahmed Allam",
            "Youssef Mansour",
            "Mohamed Shalan"
        ],
        "submitted": "2025-08-21 20:21:34",
        "source": "arxiv",
        "comment": "2025 IEEE International Conference on LLM-Aided Design (ICLAD)",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on ASIC design and multi-agent systems, which is outside your primary areas of interest."
    },
    {
        "title": "HAMSA: Hijacking Aligned Compact Models via Stealthy Automation",
        "abstract": "Large Language Models (LLMs), especially their compact efficiency-oriented\nvariants, remain susceptible to jailbreak attacks that can elicit harmful\noutputs despite extensive alignment efforts. Existing adversarial prompt\ngeneration techniques often rely on manual engineering or rudimentary\nobfuscation, producing low-quality or incoherent text that is easily flagged by\nperplexity-based filters. We present an automated red-teaming framework that\nevolves semantically meaningful and stealthy jailbreak prompts for aligned\ncompact LLMs. The approach employs a multi-stage evolutionary search, where\ncandidate prompts are iteratively refined using a population-based strategy\naugmented with temperature-controlled variability to balance exploration and\ncoherence preservation. This enables the systematic discovery of prompts\ncapable of bypassing alignment safeguards while maintaining natural language\nfluency. We evaluate our method on benchmarks in English (In-The-Wild Jailbreak\nPrompts on LLMs), and a newly curated Arabic one derived from In-The-Wild\nJailbreak Prompts on LLMs and annotated by native Arabic linguists, enabling\nmultilingual assessment.",
        "url": "http://arxiv.org/abs/2508.16484v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16484v1",
        "arxiv_id": "2508.16484v1",
        "authors": [
            "Alexey Krylov",
            "Iskander Vagizov",
            "Dmitrii Korzh",
            "Maryam Douiba",
            "Azidine Guezzaz",
            "Vladimir Kokh",
            "Sergey D. Erokhin",
            "Elena V. Tutubalina",
            "Oleg Y. Rogov"
        ],
        "submitted": "2025-08-22 15:57:57",
        "source": "arxiv",
        "comment": "9 pages, 1 figure; article under review",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on a specific topic in NLP, namely, adversarial attacks on large language models, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and query understanding. The paper's abstract does not mention any relevance to ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest for the user."
    },
    {
        "title": "PediatricsMQA: a Multi-modal Pediatrics Question Answering Benchmark",
        "abstract": "Large language models (LLMs) and vision-augmented LLMs (VLMs) have\nsignificantly advanced medical informatics, diagnostics, and decision support.\nHowever, these models exhibit systematic biases, particularly age bias,\ncompromising their reliability and equity. This is evident in their poorer\nperformance on pediatric-focused text and visual question-answering tasks. This\nbias reflects a broader imbalance in medical research, where pediatric studies\nreceive less funding and representation despite the significant disease burden\nin children. To address these issues, a new comprehensive multi-modal pediatric\nquestion-answering benchmark, PediatricsMQA, has been introduced. It consists\nof 3,417 text-based multiple-choice questions (MCQs) covering 131 pediatric\ntopics across seven developmental stages (prenatal to adolescent) and 2,067\nvision-based MCQs using 634 pediatric images from 67 imaging modalities and 256\nanatomical regions. The dataset was developed using a hybrid manual-automatic\npipeline, incorporating peer-reviewed pediatric literature, validated question\nbanks, existing benchmarks, and existing QA resources. Evaluating\nstate-of-the-art open models, we find dramatic performance drops in younger\ncohorts, highlighting the need for age-aware methods to ensure equitable AI\nsupport in pediatric care.",
        "url": "http://arxiv.org/abs/2508.16439v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16439v1",
        "arxiv_id": "2508.16439v1",
        "authors": [
            "Adil Bahaj",
            "Mounir Ghogho"
        ],
        "submitted": "2025-08-22 14:50:55",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on a specific domain (pediatrics) and a particular application (question answering) that is not directly related to my research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it mentions large language models, which is a related topic, the paper's primary focus is on medical informatics and decision support, which is not a central match for my interests."
    },
    {
        "title": "M3TQA: Massively Multilingual Multitask Table Question Answering",
        "abstract": "Tabular data is a fundamental component of real-world information systems,\nyet most research in table understanding remains confined to English, leaving\nmultilingual comprehension significantly underexplored. Existing multilingual\ntable benchmarks suffer from geolinguistic imbalance - overrepresenting certain\nlanguages and lacking sufficient scale for rigorous cross-lingual analysis. To\naddress these limitations, we introduce a comprehensive framework for massively\nmultilingual multitask table question answering, featuring m3TQA-Instruct, a\nlarge-scale benchmark spanning 97 languages across diverse language families,\nincluding underrepresented and low-resource languages. We construct m3TQA by\ncurating 50 real-world tables in Chinese and English, then applying a robust\nsix-step LLM-based translation pipeline powered by DeepSeek and GPT-4o,\nachieving high translation fidelity with a median BLEU score of 60.19 as\nvalidated through back-translation. The benchmark includes 2,916 professionally\nannotated question-answering pairs across four tasks designed to evaluate\nnuanced table reasoning capabilities. Experiments on state-of-the-art LLMs\nreveal critical insights into cross-lingual generalization, demonstrating that\nsynthetically generated, unannotated QA data can significantly boost\nperformance, particularly for low-resource languages. M3T-Bench establishes a\nnew standard for multilingual table understanding, providing both a challenging\nevaluation platform and a scalable methodology for future research.",
        "url": "http://arxiv.org/abs/2508.16265v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16265v1",
        "arxiv_id": "2508.16265v1",
        "authors": [
            "Daixin Shu",
            "Jian Yang",
            "Zhenhe Wu",
            "Xianjie Wu",
            "Xianfu Cheng",
            "Xiangyuan Guan",
            "Yanghai Wang",
            "Pengfei Wu",
            "Tingyang Yang",
            "Hualei Zhu",
            "Wei Zhang",
            "Ge Zhang",
            "Jiaheng Liu",
            "Zhoujun Li"
        ],
        "submitted": "2025-08-22 09:57:40",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on multilingual table question answering, which is not directly related to my primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on topics like query understanding and ranking models, the context is different and not as relevant to my core research themes."
    },
    {
        "title": "Attribute Filtering in Approximate Nearest Neighbor Search: An In-depth Experimental Study",
        "abstract": "With the growing integration of structured and unstructured data, new methods\nhave emerged for performing similarity searches on vectors while honoring\nstructured attribute constraints, i.e., a process known as Filtering\nApproximate Nearest Neighbor (Filtering ANN) search. Since many of these\nalgorithms have only appeared in recent years and are designed to work with a\nvariety of base indexing methods and filtering strategies, there is a pressing\nneed for a unified analysis that identifies their core techniques and enables\nmeaningful comparisons.\n  In this work, we present a unified Filtering ANN search interface that\nencompasses the latest algorithms and evaluate them extensively from multiple\nperspectives. First, we propose a comprehensive taxonomy of existing Filtering\nANN algorithms based on attribute types and filtering strategies. Next, we\nanalyze their key components, i.e., index structures, pruning strategies, and\nentry point selection, to elucidate design differences and tradeoffs. We then\nconduct a broad experimental evaluation on 10 algorithms and 12 methods across\n4 datasets (each with up to 10 million items), incorporating both synthetic and\nreal attributes and covering selectivity levels from 0.1% to 100%. Finally, an\nin-depth component analysis reveals the influence of pruning, entry point\nselection, and edge filtering costs on overall performance. Based on our\nfindings, we summarize the strengths and limitations of each approach, provide\npractical guidelines for selecting appropriate methods, and suggest promising\ndirections for future research. Our code is available at:\nhttps://github.com/lmccccc/FANNBench.",
        "url": "http://arxiv.org/abs/2508.16263v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16263v1",
        "arxiv_id": "2508.16263v1",
        "authors": [
            "Mocheng Li",
            "Xiao Yan",
            "Baotong Lu",
            "Yue Zhang",
            "James Cheng",
            "Chenhao Ma"
        ],
        "submitted": "2025-08-22 09:54:57",
        "source": "arxiv",
        "comment": "15 pages, 15 figures, Accepted at SIGMOD 2026",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on Attribute Filtering in Approximate Nearest Neighbor Search, which is not directly related to Information Retrieval, query understanding, ranking models, or user behavior modeling. While it involves indexing methods and filtering strategies, the context is different from the user's research interests in IR and NLP."
    },
    {
        "title": "Modeling User Preferences as Distributions for Optimal Transport-based Cross-domain Recommendation under Non-overlapping Settings",
        "abstract": "Cross-Domain Recommender (CDR) systems aim to transfer knowledge from dense\nto sparse domains, alleviating data sparsity and cold-start issues in\nsingle-domain recommendation. While many methods assume overlapping users or\nitems to connect domains, this is often unrealistic in real-world settings.\nThus, non-overlapping CDR systems, which require no shared users or items, are\nneeded.\n  However, non-overlapping CDR is challenging due to: (1) the absence of\noverlap preventing direct bridges between domains, and (2) large distributional\ndiscrepancies degrading transfer performance. Moreover, most recommenders\nrepresent user preferences as discrete vectors, failing to capture their\nfine-grained, multi-faceted nature.\n  We propose DUP-OT (Distributional User Preferences with Optimal Transport), a\nframework for non-overlapping CDR. DUP-OT has three stages: (1) Shared\nPreprocessing, where review-based embeddings and an autoencoder encode users\nand items from both domains; (2) User GMM Weight Learning, which models user\npreferences as Gaussian mixtures with learned weights; and (3) Cross-domain\nRating Prediction, where optimal transport aligns Gaussian components across\ndomains, enabling preference transfer from source to target.\n  Experiments on Amazon review datasets show that DUP-OT effectively mitigates\ndomain discrepancy and outperforms state-of-the-art baselines under the\nnon-overlapping CDR setting.",
        "url": "http://arxiv.org/abs/2508.16210v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16210v1",
        "arxiv_id": "2508.16210v1",
        "authors": [
            "Ziyin Xiao",
            "Toyotaro Suzumura"
        ],
        "submitted": "2025-08-22 08:32:13",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Cross-Domain Recommender systems, which is a related topic to Information Retrieval. However, the emphasis on user preferences and Gaussian mixtures is not directly aligned with my interests in query understanding, ranking models, and user behavior modeling. The paper's abstract does not mention search technologies or real-time relevance optimization, which are key aspects of my research."
    },
    {
        "title": "ComicScene154: A Scene Dataset for Comic Analysis",
        "abstract": "Comics offer a compelling yet under-explored domain for computational\nnarrative analysis, combining text and imagery in ways distinct from purely\ntextual or audiovisual media. We introduce ComicScene154, a manually annotated\ndataset of scene-level narrative arcs derived from public-domain comic books\nspanning diverse genres. By conceptualizing comics as an abstraction for\nnarrative-driven, multimodal data, we highlight their potential to inform\nbroader research on multi-modal storytelling. To demonstrate the utility of\nComicScene154, we present a baseline scene segmentation pipeline, providing an\ninitial benchmark that future studies can build upon. Our results indicate that\nComicScene154 constitutes a valuable resource for advancing computational\nmethods in multimodal narrative understanding and expanding the scope of comic\nanalysis within the Natural Language Processing community.",
        "url": "http://arxiv.org/abs/2508.16190v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16190v1",
        "arxiv_id": "2508.16190v1",
        "authors": [
            "Sandro Paval",
            "Ivan P. Yamshchikov",
            "Pascal Meißner"
        ],
        "submitted": "2025-08-22 08:11:58",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on a specific domain (comics) and dataset creation, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions Natural Language Processing, the scope is limited to multimodal narrative understanding and comic analysis, which is not a primary focus of the user's research interests."
    },
    {
        "title": "From Indirect Object Identification to Syllogisms: Exploring Binary Mechanisms in Transformer Circuits",
        "abstract": "Transformer-based language models (LMs) can perform a wide range of tasks,\nand mechanistic interpretability (MI) aims to reverse engineer the components\nresponsible for task completion to understand their behavior. Previous MI\nresearch has focused on linguistic tasks such as Indirect Object Identification\n(IOI). In this paper, we investigate the ability of GPT-2 small to handle\nbinary truth values by analyzing its behavior with syllogistic prompts, e.g.,\n\"Statement A is true. Statement B matches statement A. Statement B is\", which\nrequires more complex logical reasoning compared to IOI. Through our analysis\nof several syllogism tasks of varying difficulty, we identify multiple circuits\nthat mechanistically explain GPT-2's logical-reasoning capabilities and uncover\nbinary mechanisms that facilitate task completion, including the ability to\nproduce a negated token not present in the input prompt through negative heads.\nOur evaluation using a faithfulness metric shows that a circuit comprising five\nattention heads achieves over 90% of the original model's performance. By\nrelating our findings to IOI analysis, we provide new insights into the roles\nof specific attention heads and MLPs in LMs. These insights contribute to a\nbroader understanding of model reasoning and support future research in\nmechanistic interpretability.",
        "url": "http://arxiv.org/abs/2508.16109v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16109v1",
        "arxiv_id": "2508.16109v1",
        "authors": [
            "Karim Saraipour",
            "Shichang Zhang"
        ],
        "submitted": "2025-08-22 05:54:11",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on mechanistic interpretability of transformer-based language models, exploring binary mechanisms in transformer circuits. While it touches on attention heads, which are relevant to ranking models, the paper's primary focus is on linguistic tasks and logical reasoning, which is not directly related to information retrieval, search technologies, or user behavior modeling."
    },
    {
        "title": "CEQuest: Benchmarking Large Language Models for Construction Estimation",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\na wide range of general-domain tasks. However, their effectiveness in\nspecialized fields, such as construction, remains underexplored. In this paper,\nwe introduce CEQuest, a novel benchmark dataset specifically designed to\nevaluate the performance of LLMs in answering construction-related questions,\nparticularly in the areas of construction drawing interpretation and\nestimation. We conduct comprehensive experiments using five state-of-the-art\nLLMs, including Gemma 3, Phi4, LLaVA, Llama 3.3, and GPT-4.1, and evaluate\ntheir performance in terms of accuracy, execution time, and model size. Our\nexperimental results demonstrate that current LLMs exhibit considerable room\nfor improvement, highlighting the importance of integrating domain-specific\nknowledge into these models. To facilitate further research, we will\nopen-source the proposed CEQuest dataset, aiming to foster the development of\nspecialized large language models (LLMs) tailored to the construction domain.",
        "url": "http://arxiv.org/abs/2508.16081v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16081v1",
        "arxiv_id": "2508.16081v1",
        "authors": [
            "Yanzhao Wu",
            "Lufan Wang",
            "Rui Liu"
        ],
        "submitted": "2025-08-22 04:14:20",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on applying Large Language Models to construction estimation, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions LLMs, it does not address query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user."
    },
    {
        "title": "Ethical Considerations of Large Language Models in Game Playing",
        "abstract": "Large language models (LLMs) have demonstrated tremendous potential in game\nplaying, while little attention has been paid to their ethical implications in\nthose contexts. This work investigates and analyses the ethical considerations\nof applying LLMs in game playing, using Werewolf, also known as Mafia, as a\ncase study. Gender bias, which affects game fairness and player experience, has\nbeen observed from the behaviour of LLMs. Some roles, such as the Guard and\nWerewolf, are more sensitive than others to gender information, presented as a\nhigher degree of behavioural change. We further examine scenarios in which\ngender information is implicitly conveyed through names, revealing that LLMs\nstill exhibit discriminatory tendencies even in the absence of explicit gender\nlabels. This research showcases the importance of developing fair and ethical\nLLMs. Beyond our research findings, we discuss the challenges and opportunities\nthat lie ahead in this field, emphasising the need for diving deeper into the\nethical implications of LLMs in gaming and other interactive domains.",
        "url": "http://arxiv.org/abs/2508.16065v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16065v1",
        "arxiv_id": "2508.16065v1",
        "authors": [
            "Qingquan Zhang",
            "Yuchen Li",
            "Bo Yuan",
            "Julian Togelius",
            "Georgios N. Yannakakis",
            "Jialin Liu"
        ],
        "submitted": "2025-08-22 03:32:35",
        "source": "arxiv",
        "comment": "19 pages",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the ethical implications of large language models in game playing, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on topics like language models and behavioral analysis, the context is game playing, which is not a primary area of interest for the user."
    },
    {
        "title": "Estimating the Effective Topics of Articles and journals Abstract Using LDA And K-Means Clustering Algorithm",
        "abstract": "Analyzing journals and articles abstract text or documents using topic\nmodelling and text clustering has become a modern solution for the increasing\nnumber of text documents. Topic modelling and text clustering are both\nintensely involved tasks that can benefit one another. Text clustering and\ntopic modelling algorithms are used to maintain massive amounts of text\ndocuments. In this study, we have used LDA, K-Means cluster and also lexical\ndatabase WordNet for keyphrases extraction in our text documents. K-Means\ncluster and LDA algorithms achieve the most reliable performance for keyphrase\nextraction in our text documents. This study will help the researcher to make a\nsearch string based on journals and articles by avoiding misunderstandings.",
        "url": "http://arxiv.org/abs/2508.16046v1",
        "pdf_url": "http://arxiv.org/pdf/2508.16046v1",
        "arxiv_id": "2508.16046v1",
        "authors": [
            "Shadikur Rahman",
            "Umme Ayman Koana",
            "Aras M. Ismael",
            "Karmand Hussein Abdalla"
        ],
        "submitted": "2025-08-22 02:51:33",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on topic modeling and text clustering, which is not directly related to information retrieval, search technologies, or query understanding. Although it mentions keyphrase extraction, the context is not relevant to the user's interests in ranking models, user behavior modeling, or deep semantic understanding."
    }
]