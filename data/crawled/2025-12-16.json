[
    {
        "title": "Beyond surface form: A pipeline for semantic analysis in Alzheimer's Disease detection from spontaneous speech",
        "abstract": "Alzheimer's Disease (AD) is a progressive neurodegenerative condition that adversely affects cognitive abilities. Language-related changes can be automatically identified through the analysis of outputs from linguistic assessment tasks, such as picture description. Language models show promise as a basis for screening tools for AD, but their limited interpretability poses a challenge in distinguishing true linguistic markers of cognitive decline from surface-level textual patterns. To address this issue, we examine how surface form variation affects classification performance, with the goal of assessing the ability of language models to represent underlying semantic indicators. We introduce a novel approach where texts surface forms are transformed by altering syntax and vocabulary while preserving semantic content. The transformations significantly modify the structure and lexical content, as indicated by low BLEU and chrF scores, yet retain the underlying semantics, as reflected in high semantic similarity scores, isolating the effect of semantic information, and finding models perform similarly to if they were using the original text, with only small deviations in macro-F1. We also investigate whether language from picture descriptions retains enough detail to reconstruct the original image using generative models. We found that image-based transformations add substantial noise reducing classification accuracy. Our methodology provides a novel way of looking at what features influence model predictions, and allows the removal of possible spurious correlations. We find that just using semantic information, language model based classifiers can still detect AD. This work shows that difficult to detect semantic impairment can be identified, addressing an overlooked feature of linguistic deterioration, and opening new pathways for early detection systems.",
        "url": "http://arxiv.org/abs/2512.13685v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13685v1",
        "arxiv_id": "2512.13685v1",
        "authors": [
            "Dylan Phelps",
            "Rodrigo Wilkens",
            "Edward Gow-Smith",
            "Lilian Hubner",
            "Bárbara Malcorra",
            "César Rennó-Costa",
            "Marco Idiart",
            "Maria-Cruz Villa-Uriol",
            "Aline Villavicencio"
        ],
        "submitted": "2025-12-15 18:59:49",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Towards Effective Model Editing for LLM Personalization",
        "abstract": "Personalization is becoming indispensable for LLMs to align with individual user preferences and needs. Yet current approaches are often computationally expensive, data-intensive, susceptible to catastrophic forgetting, and prone to performance degradation in multi-turn interactions or when handling implicit queries. To address these challenges, we conceptualize personalization as a model editing task and introduce Personalization Editing, a framework that applies localized edits guided by clustered preference representations. This design enables precise preference-aligned updates while preserving overall model capabilities. In addition, existing personalization benchmarks frequently rely on persona-based dialogs between LLMs rather than user-LLM interactions, or focus primarily on stylistic imitation while neglecting information-seeking tasks that require accurate recall of user-specific preferences. We introduce User Preference Question Answering (UPQA), a short-answer QA dataset constructed from in-situ user queries with varying levels of difficulty. Unlike prior benchmarks, UPQA directly evaluates a model's ability to recall and apply specific user preferences. Across experimental settings, Personalization Editing achieves higher editing accuracy and greater computational efficiency than fine-tuning, while outperforming prompting-based baselines in multi-turn conversations and implicit preference questions settings.",
        "url": "http://arxiv.org/abs/2512.13676v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13676v1",
        "arxiv_id": "2512.13676v1",
        "authors": [
            "Baixiang Huang",
            "Limeng Cui",
            "Jiapeng Liu",
            "Haoran Wang",
            "Jiawei Xu",
            "Zhuiyue Tan",
            "Yutong Chen",
            "Chen Luo",
            "Yi Liu",
            "Kai Shu"
        ],
        "submitted": "2025-12-15 18:58:15",
        "source": "arxiv",
        "comment": "15 pages (including appendix), 7 figures. Code, data, results, and additional resources are available at: https://model-editing.github.io"
    },
    {
        "title": "Towards Interactive Intelligence for Digital Humans",
        "abstract": "We introduce Interactive Intelligence, a novel paradigm of digital human that is capable of personality-aligned expression, adaptive interaction, and self-evolution. To realize this, we present Mio (Multimodal Interactive Omni-Avatar), an end-to-end framework composed of five specialized modules: Thinker, Talker, Face Animator, Body Animator, and Renderer. This unified architecture integrates cognitive reasoning with real-time multimodal embodiment to enable fluid, consistent interaction. Furthermore, we establish a new benchmark to rigorously evaluate the capabilities of interactive intelligence. Extensive experiments demonstrate that our framework achieves superior performance compared to state-of-the-art methods across all evaluated dimensions. Together, these contributions move digital humans beyond superficial imitation toward intelligent interaction.",
        "url": "http://arxiv.org/abs/2512.13674v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13674v1",
        "arxiv_id": "2512.13674v1",
        "authors": [
            "Yiyi Cai",
            "Xuangeng Chu",
            "Xiwei Gao",
            "Sitong Gong",
            "Yifei Huang",
            "Caixin Kang",
            "Kunhang Li",
            "Haiyang Liu",
            "Ruicong Liu",
            "Yun Liu",
            "Dianwen Ng",
            "Zixiong Su",
            "Erwin Wu",
            "Yuhan Wu",
            "Dingkun Yan",
            "Tianyu Yan",
            "Chang Zeng",
            "Bo Zheng",
            "You Zhou"
        ],
        "submitted": "2025-12-15 18:57:35",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "A stylometric analysis of speaker attribution from speech transcripts",
        "abstract": "Forensic scientists often need to identify an unknown speaker or writer in cases such as ransom calls, covert recordings, alleged suicide notes, or anonymous online communications, among many others. Speaker recognition in the speech domain usually examines phonetic or acoustic properties of a voice, and these methods can be accurate and robust under certain conditions. However, if a speaker disguises their voice or employs text-to-speech software, vocal properties may no longer be reliable, leaving only their linguistic content available for analysis. Authorship attribution methods traditionally use syntactic, semantic, and related linguistic information to identify writers of written text (authorship attribution). In this paper, we apply a content-based authorship approach to speech that has been transcribed into text, using what a speaker says to attribute speech to individuals (speaker attribution). We introduce a stylometric method, StyloSpeaker, which incorporates character, word, token, sentence, and style features from the stylometric literature on authorship, to assess whether two transcripts were produced by the same speaker. We evaluate this method on two types of transcript formatting: one approximating prescriptive written text with capitalization and punctuation and another normalized style that removes these conventions. The transcripts' conversation topics are also controlled to varying degrees. We find generally higher attribution performance on normalized transcripts, except under the strongest topic control condition, in which overall performance is highest. Finally, we compare this more explainable stylometric model to black-box neural approaches on the same data and investigate which stylistic features most effectively distinguish speakers.",
        "url": "http://arxiv.org/abs/2512.13667v2",
        "pdf_url": "https://arxiv.org/pdf/2512.13667v2",
        "arxiv_id": "2512.13667v2",
        "authors": [
            "Cristina Aggazzotti",
            "Elizabeth Allyn Smith"
        ],
        "submitted": "2025-12-15 18:55:25",
        "source": "arxiv",
        "comment": "added acknowledgments"
    },
    {
        "title": "Comparative Analysis of LLM Abliteration Methods: A Cross-Architecture Evaluation",
        "abstract": "Safety alignment mechanisms in large language models prevent responses to harmful queries through learned refusal behavior, yet these same mechanisms impede legitimate research applications including cognitive modeling, adversarial testing, and security analysis. While abliteration techniques enable surgical removal of refusal representations through directional orthogonalization, the relative effectiveness of available implementations remains uncharacterized. This study evaluates four abliteration tools (Heretic, DECCP, ErisForge, FailSpy) across sixteen instruction-tuned models (7B-14B parameters), reporting tool compatibility on all 16 models and quantitative metrics on subsets dictated by tool support. Single-pass methods demonstrated superior capability preservation on the benchmarked subset (avg GSM8K change across three models: ErisForge -0.28 pp; DECCP -0.13 pp), while Bayesian-optimized abliteration produced variable distribution shift (KL divergence: 0.043-1.646) with model-dependent capability impact. These findings provide researchers with evidence-based selection criteria for abliteration tool deployment across diverse model architectures. The principal finding indicates that mathematical reasoning capabilities exhibit the highest sensitivity to abliteration interventions, with GSM8K change ranging from +1.51 pp to -18.81 pp (-26.5% relative) depending on tool selection and model architecture.",
        "url": "http://arxiv.org/abs/2512.13655v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13655v1",
        "arxiv_id": "2512.13655v1",
        "authors": [
            "Richard J. Young"
        ],
        "submitted": "2025-12-15 18:48:42",
        "source": "arxiv",
        "comment": "25 pages, 6 figures, 8 tables"
    },
    {
        "title": "Large-Language Memorization During the Classification of United States Supreme Court Cases",
        "abstract": "Large-language models (LLMs) have been shown to respond in a variety of ways for classification tasks outside of question-answering. LLM responses are sometimes called \"hallucinations\" since the output is not what is ex pected. Memorization strategies in LLMs are being studied in detail, with the goal of understanding how LLMs respond. We perform a deep dive into a classification task based on United States Supreme Court (SCOTUS) decisions. The SCOTUS corpus is an ideal classification task to study for LLM memory accuracy because it presents significant challenges due to extensive sentence length, complex legal terminology, non-standard structure, and domain-specific vocabulary. Experimentation is performed with the latest LLM fine tuning and retrieval-based approaches, such as parameter-efficient fine-tuning, auto-modeling, and others, on two traditional category-based SCOTUS classification tasks: one with 15 labeled topics and another with 279. We show that prompt-based models with memories, such as DeepSeek, can be more robust than previous BERT-based models on both tasks scoring about 2 points better than previous models not based on prompting.",
        "url": "http://arxiv.org/abs/2512.13654v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13654v1",
        "arxiv_id": "2512.13654v1",
        "authors": [
            "John E. Ortega",
            "Dhruv D. Joshi",
            "Matt P. Borkowski"
        ],
        "submitted": "2025-12-15 18:47:48",
        "source": "arxiv",
        "comment": "7 pages, 1 figure, Appendix of Prompts"
    },
    {
        "title": "Temporal Tokenization Strategies for Event Sequence Modeling with Large Language Models",
        "abstract": "Representing continuous time is a critical and under-explored challenge in modeling temporal event sequences with large language models (LLMs). Various strategies like byte-level representations or calendar tokens have been proposed. However, the optimal approach remains unclear, especially given the diverse statistical distributions of real-world event data, which range from smooth log-normal to discrete, spiky patterns. This paper presents the first empirical study of temporal tokenization for event sequences, comparing distinct encoding strategies: naive numeric strings, high-precision byte-level representations, human-semantic calendar tokens, classic uniform binning, and adaptive residual scalar quantization. We evaluate these strategies by fine-tuning LLMs on real-world datasets that exemplify these diverse distributions. Our analysis reveals that no single strategy is universally superior; instead, prediction performance depends heavily on aligning the tokenizer with the data's statistical properties, with log-based strategies excelling on skewed distributions and human-centric formats proving robust for mixed modalities.",
        "url": "http://arxiv.org/abs/2512.13618v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13618v1",
        "arxiv_id": "2512.13618v1",
        "authors": [
            "Zefang Liu",
            "Nam Nguyen",
            "Yinzhu Quan",
            "Austin Zhang"
        ],
        "submitted": "2025-12-15 18:10:51",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Nemotron-Cascade: Scaling Cascaded Reinforcement Learning for General-Purpose Reasoning Models",
        "abstract": "Building general-purpose reasoning models with reinforcement learning (RL) entails substantial cross-domain heterogeneity, including large variation in inference-time response lengths and verification latency. Such variability complicates the RL infrastructure, slows training, and makes training curriculum (e.g., response length extension) and hyperparameter selection challenging. In this work, we propose cascaded domain-wise reinforcement learning (Cascade RL) to develop general-purpose reasoning models, Nemotron-Cascade, capable of operating in both instruct and deep thinking modes. Departing from conventional approaches that blend heterogeneous prompts from different domains, Cascade RL orchestrates sequential, domain-wise RL, reducing engineering complexity and delivering state-of-the-art performance across a wide range of benchmarks. Notably, RLHF for alignment, when used as a pre-step, boosts the model's reasoning ability far beyond mere preference optimization, and subsequent domain-wise RLVR stages rarely degrade the benchmark performance attained in earlier domains and may even improve it (see an illustration in Figure 1). Our 14B model, after RL, outperforms its SFT teacher, DeepSeek-R1-0528, on LiveCodeBench v5/v6/Pro and achieves silver-medal performance in the 2025 International Olympiad in Informatics (IOI). We transparently share our training and data recipes.",
        "url": "http://arxiv.org/abs/2512.13607v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13607v1",
        "arxiv_id": "2512.13607v1",
        "authors": [
            "Boxin Wang",
            "Chankyu Lee",
            "Nayeon Lee",
            "Sheng-Chieh Lin",
            "Wenliang Dai",
            "Yang Chen",
            "Yangyi Chen",
            "Zhuolin Yang",
            "Zihan Liu",
            "Mohammad Shoeybi",
            "Bryan Catanzaro",
            "Wei Ping"
        ],
        "submitted": "2025-12-15 18:02:35",
        "source": "arxiv",
        "comment": "We publicly release the Nemotron-Cascade models and the full collection of training data at: https://huggingface.co/collections/nvidia/nemotron-cascade"
    },
    {
        "title": "Textual Gradients are a Flawed Metaphor for Automatic Prompt Optimization",
        "abstract": "A well-engineered prompt can increase the performance of large language models; automatic prompt optimization techniques aim to increase performance without requiring human effort to tune the prompts. One leading class of prompt optimization techniques introduces the analogy of textual gradients. We investigate the behavior of these textual gradient methods through a series of experiments and case studies. While such methods often result in a performance improvement, our experiments suggest that the gradient analogy does not accurately explain their behavior. Our insights may inform the selection of prompt optimization strategies, and development of new approaches.",
        "url": "http://arxiv.org/abs/2512.13598v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13598v1",
        "arxiv_id": "2512.13598v1",
        "authors": [
            "Daniel Melcer",
            "Qi Chen",
            "Wen-Hao Chiang",
            "Shweta Garg",
            "Pranav Garg",
            "Christian Bock"
        ],
        "submitted": "2025-12-15 17:52:16",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "ReFusion: A Diffusion Large Language Model with Parallel Autoregressive Decoding",
        "abstract": "Autoregressive models (ARMs) are hindered by slow sequential inference. While masked diffusion models (MDMs) offer a parallel alternative, they suffer from critical drawbacks: high computational overhead from precluding Key-Value (KV) caching, and incoherent generation arising from learning dependencies over an intractable space of token combinations. To address these limitations, we introduce ReFusion, a novel masked diffusion model that achieves superior performance and efficiency by elevating parallel decoding from the token level to a higher slot level, where each slot is a fixed-length, contiguous sub-sequence. This is achieved through an iterative ``plan-and-infill'' decoding process: a diffusion-based planning step first identifies a set of weakly dependent slots, and an autoregressive infilling step then decodes these selected slots in parallel. The slot-based design simultaneously unlocks full KV cache reuse with a unified causal framework and reduces the learning complexity from the token combination space to a manageable slot-level permutation space. Extensive experiments on seven diverse benchmarks show that ReFusion not only overwhelmingly surpasses prior MDMs with 34% performance gains and an over 18$\\times$ speedup on average, but also bridges the performance gap to strong ARMs while maintaining a 2.33$\\times$ average speedup.",
        "url": "http://arxiv.org/abs/2512.13586v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13586v1",
        "arxiv_id": "2512.13586v1",
        "authors": [
            "Jia-Nan Li",
            "Jian Guan",
            "Wei Wu",
            "Chongxuan Li"
        ],
        "submitted": "2025-12-15 17:41:19",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Memory in the Age of AI Agents",
        "abstract": "Memory has emerged, and will continue to remain, a core capability of foundation model-based agents. As research on agent memory rapidly expands and attracts unprecedented attention, the field has also become increasingly fragmented. Existing works that fall under the umbrella of agent memory often differ substantially in their motivations, implementations, and evaluation protocols, while the proliferation of loosely defined memory terminologies has further obscured conceptual clarity. Traditional taxonomies such as long/short-term memory have proven insufficient to capture the diversity of contemporary agent memory systems. This work aims to provide an up-to-date landscape of current agent memory research. We begin by clearly delineating the scope of agent memory and distinguishing it from related concepts such as LLM memory, retrieval augmented generation (RAG), and context engineering. We then examine agent memory through the unified lenses of forms, functions, and dynamics. From the perspective of forms, we identify three dominant realizations of agent memory, namely token-level, parametric, and latent memory. From the perspective of functions, we propose a finer-grained taxonomy that distinguishes factual, experiential, and working memory. From the perspective of dynamics, we analyze how memory is formed, evolved, and retrieved over time. To support practical development, we compile a comprehensive summary of memory benchmarks and open-source frameworks. Beyond consolidation, we articulate a forward-looking perspective on emerging research frontiers, including memory automation, reinforcement learning integration, multimodal memory, multi-agent memory, and trustworthiness issues. We hope this survey serves not only as a reference for existing work, but also as a conceptual foundation for rethinking memory as a first-class primitive in the design of future agentic intelligence.",
        "url": "http://arxiv.org/abs/2512.13564v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13564v1",
        "arxiv_id": "2512.13564v1",
        "authors": [
            "Yuyang Hu",
            "Shichun Liu",
            "Yanwei Yue",
            "Guibin Zhang",
            "Boyang Liu",
            "Fangyi Zhu",
            "Jiahang Lin",
            "Honglin Guo",
            "Shihan Dou",
            "Zhiheng Xi",
            "Senjie Jin",
            "Jiejun Tan",
            "Yanbin Yin",
            "Jiongnan Liu",
            "Zeyu Zhang",
            "Zhongxiang Sun",
            "Yutao Zhu",
            "Hao Sun",
            "Boci Peng",
            "Zhenrong Cheng",
            "Xuanbo Fan",
            "Jiaxin Guo",
            "Xinlei Yu",
            "Zhenhong Zhou",
            "Zewen Hu",
            "Jiahao Huo",
            "Junhao Wang",
            "Yuwei Niu",
            "Yu Wang",
            "Zhenfei Yin",
            "Xiaobin Hu",
            "Yue Liao",
            "Qiankun Li",
            "Kun Wang",
            "Wangchunshu Zhou",
            "Yixin Liu",
            "Dawei Cheng",
            "Qi Zhang",
            "Tao Gui",
            "Shirui Pan",
            "Yan Zhang",
            "Philip Torr",
            "Zhicheng Dou",
            "Ji-Rong Wen",
            "Xuanjing Huang",
            "Yu-Gang Jiang",
            "Shuicheng Yan"
        ],
        "submitted": "2025-12-15 17:22:34",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Verifying Rumors via Stance-Aware Structural Modeling",
        "abstract": "Verifying rumors on social media is critical for mitigating the spread of false information. The stances of conversation replies often provide important cues to determine a rumor's veracity. However, existing models struggle to jointly capture semantic content, stance information, and conversation strructure, especially under the sequence length constraints of transformer-based encoders. In this work, we propose a stance-aware structural modeling that encodes each post in a discourse with its stance signal and aggregates reply embedddings by stance category enabling a scalable and semantically enriched representation of the entire thread. To enhance structural awareness, we introduce stance distribution and hierarchical depth as covariates, capturing stance imbalance and the influence of reply depth. Extensive experiments on benchmark datasets demonstrate that our approach significantly outperforms prior methods in the ability to predict truthfulness of a rumor. We also demonstrate that our model is versatile for early detection and cross-platfrom generalization.",
        "url": "http://arxiv.org/abs/2512.13559v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13559v1",
        "arxiv_id": "2512.13559v1",
        "authors": [
            "Gibson Nkhata",
            "Uttamasha Anjally Oyshi",
            "Quan Mai",
            "Susan Gauch"
        ],
        "submitted": "2025-12-15 17:16:56",
        "source": "arxiv",
        "comment": "8 pages, 2 figures, published in The 24th IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT 2025), London, UK, 2025"
    },
    {
        "title": "PrahokBART: A Pre-trained Sequence-to-Sequence Model for Khmer Natural Language Generation",
        "abstract": "This work introduces {\\it PrahokBART}, a compact pre-trained sequence-to-sequence model trained from scratch for Khmer using carefully curated Khmer and English corpora. We focus on improving the pre-training corpus quality and addressing the linguistic issues of Khmer, which are ignored in existing multilingual models, by incorporating linguistic components such as word segmentation and normalization. We evaluate PrahokBART on three generative tasks: machine translation, text summarization, and headline generation, where our results demonstrate that it outperforms mBART50, a strong multilingual pre-trained model. Additionally, our analysis provides insights into the impact of each linguistic module and evaluates how effectively our model handles space during text generation, which is crucial for the naturalness of texts in Khmer.",
        "url": "http://arxiv.org/abs/2512.13552v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13552v1",
        "arxiv_id": "2512.13552v1",
        "authors": [
            "Hour Kaing",
            "Raj Dabre",
            "Haiyue Song",
            "Van-Hien Tran",
            "Hideki Tanaka",
            "Masao Utiyama"
        ],
        "submitted": "2025-12-15 17:11:31",
        "source": "arxiv",
        "comment": "Published at COLING 2025, 14 pages"
    },
    {
        "title": "Fine-tuned LLM-based Code Migration Framework",
        "abstract": "The study presents the outcomes of research and experimental validation in the domain of automated codebase migration, with a focus on addressing challenges in transitioning SQL-based systems. The proposed method for migration essentially appears as a framework that leverages the best aspects of traditional software engineering techniques and provides an iterative, scalable, precise and efficient solution for modern database transformations. The central piece of the approach is the integration of a fine-tuned Large Language Model to address critical issues in SQL code conversion, such as syntax mapping, resolving discrepancies between Oracle PL/SQL and PostgreSQL, and optimising database elements such as stored procedures, triggers, views, and overall database logic. Thus, the method involves a trade-off between fine-tuning and prompt engineering. Special attention is given to a fine-tuning approach, which enhances the adaptability and compatibility with migration requirements across the entire database. According to the achieved results, fine-tuning plays a very important role. The study employs targeted evaluation methodologies along with computational metrics to measure the success of iterative conversion cycles. Core innovations include automated SQL feature detection, semi-supervised error analysis and integration of Subject Matter Experts feedback within a systematic migration workflow. The methodology achieves significant reductions in Syntax Error Rates, enhances feature alignment throughout migration iterations, and leverages dataset sampling to ensure continual improvement. By embedding GAI into the migration process, the framework facilitates precise feature mapping, semi-automated error resolution, and data-driven optimisation loops, improving workflow efficiency.",
        "url": "http://arxiv.org/abs/2512.13515v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13515v1",
        "arxiv_id": "2512.13515v1",
        "authors": [
            "Oleg Grynets",
            "Vasyl Lyashkevych",
            "Dmytro Baran",
            "Maksym Orliansky",
            "Taras Zelenyy",
            "Markiian Leshchyshyn"
        ],
        "submitted": "2025-12-15 16:42:51",
        "source": "arxiv",
        "comment": "16 pages, 27 figures, 7 references"
    },
    {
        "title": "TARA: Simple and Efficient Time Aware Retrieval Adaptation of MLLMs for Video Understanding",
        "abstract": "Our objective is to build a general time-aware video-text embedding model for retrieval. To that end, we propose a simple and efficient recipe, dubbed TARA (Time Aware Retrieval Adaptation), to adapt Multimodal LLMs (MLLMs) to a time-aware video-text embedding model without using any video data at all. For evaluating time-awareness in retrieval, we propose a new benchmark with temporally opposite (chiral) actions as hard negatives and curated splits for chiral and non-chiral actions. We show that TARA outperforms all existing video-text models on this chiral benchmark while also achieving strong results on standard benchmarks. Furthermore, we discover additional benefits of TARA beyond time-awareness: (i) TARA embeddings are negation-aware as shown in NegBench benchmark that evaluates negation in video retrieval, (ii) TARA achieves state of the art performance on verb and adverb understanding in videos. Overall, TARA yields a strong, versatile, time-aware video-text embedding model with state of the art zero-shot performance.",
        "url": "http://arxiv.org/abs/2512.13511v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13511v1",
        "arxiv_id": "2512.13511v1",
        "authors": [
            "Piyush Bagad",
            "Andrew Zisserman"
        ],
        "submitted": "2025-12-15 16:38:59",
        "source": "arxiv",
        "comment": "18 Pages. Project page at http://bpiyush.github.io/tara-website"
    },
    {
        "title": "SkipCat: Rank-Maximized Low-Rank Compression of Large Language Models via Shared Projection and Block Skipping",
        "abstract": "Large language models (LLM) have achieved remarkable performance across a wide range of tasks. However, their substantial parameter sizes pose significant challenges for deployment on edge devices with limited computational and memory resources. Low-rank compression is a promising approach to address this issue, as it reduces both computational and memory costs, making LLM more suitable for resource-constrained environments. Nonetheless, naïve low-rank compression methods require a significant reduction in the retained rank to achieve meaningful memory and computation savings. For a low-rank model, the ranks need to be reduced by more than half to yield efficiency gains. Such aggressive truncation, however, typically results in substantial performance degradation. To address this trade-off, we propose SkipCat, a novel low-rank compression framework that enables the use of higher ranks while achieving the same compression rates. First, we introduce an intra-layer shared low-rank projection method, where multiple matrices that share the same input use a common projection. This reduces redundancy and improves compression efficiency. Second, we propose a block skipping technique that omits computations and memory transfers for selected sub-blocks within the low-rank decomposition. These two techniques jointly enable our compressed model to retain more effective ranks under the same compression budget. Experimental results show that, without any additional fine-tuning, our method outperforms previous low-rank compression approaches by 7% accuracy improvement on zero-shot tasks under the same compression rate. These results highlight the effectiveness of our rank-maximized compression strategy in preserving model performance under tight resource constraints.",
        "url": "http://arxiv.org/abs/2512.13494v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13494v1",
        "arxiv_id": "2512.13494v1",
        "authors": [
            "Yu-Chen Lu",
            "Sheng-Feng Yu",
            "Hui-Hsien Weng",
            "Pei-Shuo Wang",
            "Yu-Fang Hu",
            "Liang Hung-Chun",
            "Hung-Yueh Chiang",
            "Kai-Chiang Wu"
        ],
        "submitted": "2025-12-15 16:25:55",
        "source": "arxiv",
        "comment": "Accepted by AAAI 2026"
    },
    {
        "title": "SIGMA: An AI-Empowered Training Stack on Early-Life Hardware",
        "abstract": "An increasing variety of AI accelerators is being considered for large-scale training. However, enabling large-scale training on early-life AI accelerators faces three core challenges: frequent system disruptions and undefined failure modes that undermine reliability; numerical errors and training instabilities that threaten correctness and convergence; and the complexity of parallelism optimization combined with unpredictable local noise that degrades efficiency. To address these challenges, SIGMA is an open-source training stack designed to improve the reliability, stability, and efficiency of large-scale distributed training on early-life AI hardware. The core of this initiative is the LUCIA TRAINING PLATFORM (LTP), the system optimized for clusters with early-life AI accelerators. Since its launch in March 2025, LTP has significantly enhanced training reliability and operational productivity. Over the past five months, it has achieved an impressive 94.45% effective cluster accelerator utilization, while also substantially reducing node recycling and job-recovery times. Building on the foundation of LTP, the LUCIA TRAINING FRAMEWORK (LTF) successfully trained SIGMA-MOE, a 200B MoE model, using 2,048 AI accelerators. This effort delivered remarkable stability and efficiency outcomes, achieving 21.08% MFU, state-of-the-art downstream accuracy, and encountering only one stability incident over a 75-day period. Together, these advances establish SIGMA, which not only tackles the critical challenges of large-scale training but also establishes a new benchmark for AI infrastructure and platform innovation, offering a robust, cost-effective alternative to prevailing established accelerator stacks and significantly advancing AI capabilities and scalability. The source code of SIGMA is available at https://github.com/microsoft/LuciaTrainingPlatform.",
        "url": "http://arxiv.org/abs/2512.13488v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13488v1",
        "arxiv_id": "2512.13488v1",
        "authors": [
            "Lei Qu",
            "Lianhai Ren",
            "Peng Cheng",
            "Rui Gao",
            "Ruizhe Wang",
            "Tianyu Chen",
            "Xiao Liu",
            "Xingjian Zhang",
            "Yeyun Gong",
            "Yifan Xiong",
            "Yucheng Ding",
            "Yuting Jiang",
            "Zhenghao Lin",
            "Zhongxin Guo",
            "Ziyue Yang"
        ],
        "submitted": "2025-12-15 16:24:32",
        "source": "arxiv",
        "comment": "22 pages, 7 figures"
    },
    {
        "title": "Advancing Bangla Machine Translation Through Informal Datasets",
        "abstract": "Bangla is the sixth most widely spoken language globally, with approximately 234 million native speakers. However, progress in open-source Bangla machine translation remains limited. Most online resources are in English and often remain untranslated into Bangla, excluding millions from accessing essential information. Existing research in Bangla translation primarily focuses on formal language, neglecting the more commonly used informal language. This is largely due to the lack of pairwise Bangla-English data and advanced translation models. If datasets and models can be enhanced to better handle natural, informal Bangla, millions of people will benefit from improved online information access. In this research, we explore current state-of-the-art models and propose improvements to Bangla translation by developing a dataset from informal sources like social media and conversational texts. This work aims to advance Bangla machine translation by focusing on informal language translation and improving accessibility for Bangla speakers in the digital world.",
        "url": "http://arxiv.org/abs/2512.13487v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13487v1",
        "arxiv_id": "2512.13487v1",
        "authors": [
            "Ayon Roy",
            "Risat Rahaman",
            "Sadat Shibly",
            "Udoy Saha Joy",
            "Abdulla Al Kafi",
            "Farig Yousuf Sadeque"
        ],
        "submitted": "2025-12-15 16:22:45",
        "source": "arxiv",
        "comment": "33 pages, 13 figures"
    },
    {
        "title": "neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-Agent Settings",
        "abstract": "Envy is a common human behavior that shapes competitiveness and can alter outcomes in team settings. As large language models (LLMs) increasingly act on behalf of humans in collaborative and competitive workflows, there is a pressing need to evaluate whether and under what conditions they exhibit envy-like preferences. In this paper, we test whether LLMs show envy-like behavior toward each other. We considered two scenarios: (1) A point allocation game that tests whether a model tries to win over its peer. (2) A workplace setting observing behaviour when recognition is unfair. Our findings reveal consistent evidence of envy-like patterns in certain LLMs, with large variation across models and contexts. For instance, GPT-5-mini and Claude-3.7-Sonnet show a clear tendency to pull down the peer model to equalize outcomes, whereas Mistral-Small-3.2-24B instead focuses on maximizing its own individual gains. These results highlight the need to consider competitive dispositions as a safety and design factor in LLM-based multi-agent systems.",
        "url": "http://arxiv.org/abs/2512.13481v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13481v1",
        "arxiv_id": "2512.13481v1",
        "authors": [
            "Ojas Pungalia",
            "Rashi Upadhyay",
            "Abhishek Mishra",
            "Abhiram H",
            "Tejasvi Alladi",
            "Sujan Yenuganti",
            "Dhruv Kumar"
        ],
        "submitted": "2025-12-15 16:17:12",
        "source": "arxiv",
        "comment": "Under Review"
    },
    {
        "title": "Non-Resolution Reasoning (NRR): A Computational Framework for Contextual Identity and Ambiguity Preservation",
        "abstract": "Current artificial intelligence systems, despite remarkable capabilities in text generation and pattern recognition, exhibit a fundamental architectural limitation: they resolve ambiguity prematurely. This premature semantic collapse -- the tendency to collapse multiple valid interpretations into a single output -- stems from classical identity assumptions embedded in standard neural architectures. We propose Non-Resolution Reasoning (NRR), a computational framework that treats ambiguity retention as a valid reasoning mode rather than a defect to be eliminated. NRR introduces three core principles: (1) Non-Identity (A $ e$ A) -- the same symbol refers to different entities across contexts; (2) Approximate Identity (A $\\approx$ A) -- entities share partial structural overlap without being identical; and (3) Non-Resolution -- conflicting interpretations can coexist without forced convergence. We formalize these principles through three architectural components: Multi-Vector Embeddings for context-dependent representation, Non-Collapsing Attention for parallel interpretation retention, and Contextual Identity Tracking (CIT) for maintaining A $ e$ A across inference. We demonstrate NRR's advantages through case studies in paradox handling, creative generation, and context-dependent reasoning. Crucially, we provide a minimal empirical validation on a synthetic context-shift task where an NRR-lite model achieves 90.9% out-of-distribution accuracy compared to 9.1% for standard architectures, demonstrating that ambiguity preservation enables structural generalization. NRR challenges the assumption that meaning must collapse to be useful, offering a foundation for AI systems capable of sophisticated ambiguity handling and creative reasoning. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.",
        "url": "http://arxiv.org/abs/2512.13478v2",
        "pdf_url": "https://arxiv.org/pdf/2512.13478v2",
        "arxiv_id": "2512.13478v2",
        "authors": [
            "Kei Saito"
        ],
        "submitted": "2025-12-15 16:14:32",
        "source": "arxiv",
        "comment": "7 pages, 2 figures, ORCID: 0009-0006-4715-9176"
    },
    {
        "title": "Scaling Laws for Code: Every Programming Language Matters",
        "abstract": "Code large language models (Code LLMs) are powerful but costly to train, with scaling laws predicting performance from model size, data, and compute. However, different programming languages (PLs) have varying impacts during pre-training that significantly affect base model performance, leading to inaccurate performance prediction. Besides, existing works focus on language-agnostic settings, neglecting the inherently multilingual nature of modern software development. Therefore, it is first necessary to investigate the scaling laws of different PLs, and then consider their mutual influences to arrive at the final multilingual scaling law. In this paper, we present the first systematic exploration of scaling laws for multilingual code pre-training, conducting over 1000+ experiments (Equivalent to 336,000+ H800 hours) across multiple PLs, model sizes (0.2B to 14B parameters), and dataset sizes (1T tokens). We establish comprehensive scaling laws for code LLMs across multiple PLs, revealing that interpreted languages (e.g., Python) benefit more from increased model size and data than compiled languages (e.g., Rust). The study demonstrates that multilingual pre-training provides synergistic benefits, particularly between syntactically similar PLs. Further, the pre-training strategy of the parallel pairing (concatenating code snippets with their translations) significantly enhances cross-lingual abilities with favorable scaling properties. Finally, a proportion-dependent multilingual scaling law is proposed to optimally allocate training tokens by prioritizing high-utility PLs (e.g., Python), balancing high-synergy pairs (e.g., JavaScript-TypeScript), and reducing allocation to fast-saturating languages (Rust), achieving superior average performance across all PLs compared to uniform distribution under the same compute budget.",
        "url": "http://arxiv.org/abs/2512.13472v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13472v1",
        "arxiv_id": "2512.13472v1",
        "authors": [
            "Jian Yang",
            "Shawn Guo",
            "Lin Jing",
            "Wei Zhang",
            "Aishan Liu",
            "Chuan Hao",
            "Zhoujun Li",
            "Wayne Xin Zhao",
            "Xianglong Liu",
            "Weifeng Lv",
            "Bryan Dai"
        ],
        "submitted": "2025-12-15 16:07:34",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Large language models are not about language",
        "abstract": "Large Language Models are useless for linguistics, as they are probabilistic models that require a vast amount of data to analyse externalized strings of words. In contrast, human language is underpinned by a mind-internal computational system that recursively generates hierarchical thought structures. The language system grows with minimal external input and can readily distinguish between real language and impossible languages.",
        "url": "http://arxiv.org/abs/2512.13441v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13441v1",
        "arxiv_id": "2512.13441v1",
        "authors": [
            "Johan J. Bolhuis",
            "Andrea Moro",
            "Stephen Crain",
            "Sandiway Fong"
        ],
        "submitted": "2025-12-15 15:36:42",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Differentiable Evolutionary Reinforcement Learning",
        "abstract": "The design of effective reward functions presents a central and often arduous challenge in reinforcement learning (RL), particularly when developing autonomous agents for complex reasoning tasks. While automated reward optimization approaches exist, they typically rely on derivative-free evolutionary heuristics that treat the reward function as a black box, failing to capture the causal relationship between reward structure and task performance. To bridge this gap, we propose Differentiable Evolutionary Reinforcement Learning (DERL), a bilevel framework that enables the autonomous discovery of optimal reward signals. In DERL, a Meta-Optimizer evolves a reward function (i.e., Meta-Reward) by composing structured atomic primitives, guiding the training of an inner-loop policy. Crucially, unlike previous evolution, DERL is differentiable in its metaoptimization: it treats the inner-loop validation performance as a signal to update the Meta-Optimizer via reinforcement learning. This allows DERL to approximate the \"meta-gradient\" of task success, progressively learning to generate denser and more actionable feedback. We validate DERL across three distinct domains: robotic agent (ALFWorld), scientific simulation (ScienceWorld), and mathematical reasoning (GSM8k, MATH). Experimental results show that DERL achieves state-of-the-art performance on ALFWorld and ScienceWorld, significantly outperforming methods relying on heuristic rewards, especially in out-of-distribution scenarios. Analysis of the evolutionary trajectory demonstrates that DERL successfully captures the intrinsic structure of tasks, enabling selfimproving agent alignment without human intervention.",
        "url": "http://arxiv.org/abs/2512.13399v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13399v1",
        "arxiv_id": "2512.13399v1",
        "authors": [
            "Sitao Cheng",
            "Tianle Li",
            "Xuhan Huang",
            "Xunjian Yin",
            "Difan Zou"
        ],
        "submitted": "2025-12-15 14:50:08",
        "source": "arxiv",
        "comment": "Work in Progress. We release our code and model at https://github.com/sitaocheng/DERL"
    },
    {
        "title": "Automated Information Flow Selection for Multi-scenario Multi-task Recommendation",
        "abstract": "Multi-scenario multi-task recommendation (MSMTR) systems must address recommendation demands across diverse scenarios while simultaneously optimizing multiple objectives, such as click-through rate and conversion rate. Existing MSMTR models typically consist of four information units: scenario-shared, scenario-specific, task-shared, and task-specific networks. These units interact to generate four types of relationship information flows, directed from scenario-shared or scenario-specific networks to task-shared or task-specific networks. However, these models face two main limitations: 1) They often rely on complex architectures, such as mixture-of-experts (MoE) networks, which increase the complexity of information fusion, model size, and training cost. 2) They extract all available information flows without filtering out irrelevant or even harmful content, introducing potential noise. Regarding these challenges, we propose a lightweight Automated Information Flow Selection (AutoIFS) framework for MSMTR. To tackle the first issue, AutoIFS incorporates low-rank adaptation (LoRA) to decouple the four information units, enabling more flexible and efficient information fusion with minimal parameter overhead. To address the second issue, AutoIFS introduces an information flow selection network that automatically filters out invalid scenario-task information flows based on model performance feedback. It employs a simple yet effective pruning function to eliminate useless information flows, thereby enhancing the impact of key relationships and improving model performance. Finally, we evaluate AutoIFS and confirm its effectiveness through extensive experiments on two public benchmark datasets and an online A/B test.",
        "url": "http://arxiv.org/abs/2512.13396v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13396v1",
        "arxiv_id": "2512.13396v1",
        "authors": [
            "Chaohua Yang",
            "Dugang Liu",
            "Shiwei Li",
            "Yuwen Fu",
            "Xing Tang",
            "Weihong Luo",
            "Xiangyu Zhao",
            "Xiuqiang He",
            "Zhong Ming"
        ],
        "submitted": "2025-12-15 14:48:59",
        "source": "arxiv",
        "comment": "10 Pages, 6 Figures, WSDM 2026 Accepted"
    },
    {
        "title": "BlossomRec: Block-level Fused Sparse Attention Mechanism for Sequential Recommendations",
        "abstract": "Transformer structures have been widely used in sequential recommender systems (SRS). However, as user interaction histories increase, computational time and memory requirements also grow. This is mainly caused by the standard attention mechanism. Although there exist many methods employing efficient attention and SSM-based models, these approaches struggle to effectively model long sequences and may exhibit unstable performance on short sequences. To address these challenges, we design a sparse attention mechanism, BlossomRec, which models both long-term and short-term user interests through attention computation to achieve stable performance across sequences of varying lengths. Specifically, we categorize user interests in recommendation systems into long-term and short-term interests, and compute them using two distinct sparse attention patterns, with the results combined through a learnable gated output. Theoretically, it significantly reduces the number of interactions participating in attention computation. Extensive experiments on four public datasets demonstrate that BlossomRec, when integrated with state-of-the-art Transformer-based models, achieves comparable or even superior performance while significantly reducing memory usage, providing strong evidence of BlossomRec's efficiency and effectiveness.The code is available at https://github.com/ronineume/BlossomRec.",
        "url": "http://arxiv.org/abs/2512.13368v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13368v1",
        "arxiv_id": "2512.13368v1",
        "authors": [
            "Mengyang Ma",
            "Xiaopeng Li",
            "Wanyu Wang",
            "Zhaocheng Du",
            "Jingtong Gao",
            "Pengyue Jia",
            "Yuyang Ye",
            "Yiqi Wang",
            "Yunpeng Weng",
            "Weihong Luo",
            "Xiao Han",
            "Xiangyu Zhao"
        ],
        "submitted": "2025-12-15 14:23:57",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Detecting Emotion Drift in Mental Health Text Using Pre-Trained Transformers",
        "abstract": "This study investigates emotion drift: the change in emotional state across a single text, within mental health-related messages. While sentiment analysis typically classifies an entire message as positive, negative, or neutral, the nuanced shift of emotions over the course of a message is often overlooked. This study detects sentence-level emotions and measures emotion drift scores using pre-trained transformer models such as DistilBERT and RoBERTa. The results provide insights into patterns of emotional escalation or relief in mental health conversations. This methodology can be applied to better understand emotional dynamics in content.",
        "url": "http://arxiv.org/abs/2512.13363v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13363v1",
        "arxiv_id": "2512.13363v1",
        "authors": [
            "Shibani Sankpal"
        ],
        "submitted": "2025-12-15 14:18:12",
        "source": "arxiv",
        "comment": "14 pages, 12 figures"
    },
    {
        "title": "On the Effectiveness of Membership Inference in Targeted Data Extraction from Large Language Models",
        "abstract": "Large Language Models (LLMs) are prone to memorizing training data, which poses serious privacy risks. Two of the most prominent concerns are training data extraction and Membership Inference Attacks (MIAs). Prior research has shown that these threats are interconnected: adversaries can extract training data from an LLM by querying the model to generate a large volume of text and subsequently applying MIAs to verify whether a particular data point was included in the training set. In this study, we integrate multiple MIA techniques into the data extraction pipeline to systematically benchmark their effectiveness. We then compare their performance in this integrated setting against results from conventional MIA benchmarks, allowing us to evaluate their practical utility in real-world extraction scenarios.",
        "url": "http://arxiv.org/abs/2512.13352v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13352v1",
        "arxiv_id": "2512.13352v1",
        "authors": [
            "Ali Al Sahili",
            "Ali Chehab",
            "Razane Tajeddine"
        ],
        "submitted": "2025-12-15 14:05:49",
        "source": "arxiv",
        "comment": "Accepted to IEEE Conference on Secure and Trustworthy Machine Learning (SaTML) 2026"
    },
    {
        "title": "FIN-bench-v2: A Unified and Robust Benchmark Suite for Evaluating Finnish Large Language Models",
        "abstract": "We introduce FIN-bench-v2, a unified benchmark suite for evaluating large language models in Finnish. FIN-bench-v2 consolidates Finnish versions of widely used benchmarks together with an updated and expanded version of the original FIN-bench into a single, consistently formatted collection, covering multiple-choice and generative tasks across reading comprehension, commonsense reasoning, sentiment analysis, world knowledge, and alignment. All datasets are converted to HuggingFace Datasets, which include both cloze and multiple-choice prompt formulations with five variants per task, and we incorporate human annotation or review for machine-translated resources such as GoldenSwag and XED. To select robust tasks, we pretrain a set of 2.15B-parameter decoder-only models and use their learning curves to compute monotonicity, signal-to-noise, non-random performance, and model ordering consistency, retaining only tasks that satisfy all criteria. We further evaluate a set of larger instruction-tuned models to characterize performance across tasks and prompt formulations. All datasets, prompts, and evaluation configurations are publicly available via our fork of the Language Model Evaluation Harness at https://github.com/LumiOpen/lm-evaluation-harness. Supplementary resources are released in a separate repository at https://github.com/TurkuNLP/FIN-bench-v2.",
        "url": "http://arxiv.org/abs/2512.13330v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13330v1",
        "arxiv_id": "2512.13330v1",
        "authors": [
            "Joona Kytöniemi",
            "Jousia Piha",
            "Akseli Reunamo",
            "Fedor Vitiugin",
            "Farrokh Mehryary",
            "Sampo Pyysalo"
        ],
        "submitted": "2025-12-15 13:41:41",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "No One Left Behind: How to Exploit the Incomplete and Skewed Multi-Label Data for Conversion Rate Prediction",
        "abstract": "In most real-world online advertising systems, advertisers typically have diverse customer acquisition goals. A common solution is to use multi-task learning (MTL) to train a unified model on post-click data to estimate the conversion rate (CVR) for these diverse targets. In practice, CVR prediction often encounters missing conversion data as many advertisers submit only a subset of user conversion actions due to privacy or other constraints, making the labels of multi-task data incomplete. If the model is trained on all available samples where advertisers submit user conversion actions, it may struggle when deployed to serve a subset of advertisers targeting specific conversion actions, as the training and deployment data distributions are mismatched. While considerable MTL efforts have been made, a long-standing challenge is how to effectively train a unified model with the incomplete and skewed multi-label data. In this paper, we propose a fine-grained Knowledge transfer framework for Asymmetric Multi-Label data (KAML). We introduce an attribution-driven masking strategy (ADM) to better utilize data with asymmetric multi-label data in training. However, the more relaxed masking in ADM is a double-edged sword: it provides additional training signals but also introduces noise due to skewed data. To address this, we propose a hierarchical knowledge extraction mechanism (HKE) to model the sample discrepancy within the target task tower. Finally, to maximize the utility of unlabeled samples, we incorporate ranking loss strategy to further enhance our model. The effectiveness of KAML has been demonstrated through comprehensive evaluations on offline industry datasets and online A/B tests, which show significant performance improvements over existing MTL baselines.",
        "url": "http://arxiv.org/abs/2512.13300v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13300v1",
        "arxiv_id": "2512.13300v1",
        "authors": [
            "Qinglin Jia",
            "Zhaocheng Du",
            "Chuhan Wu",
            "Huifeng Guo",
            "Ruiming Tang",
            "Shuting Shi",
            "Muyu Zhang"
        ],
        "submitted": "2025-12-15 13:14:20",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "MiniLingua: A Small Open-Source LLM for European Languages",
        "abstract": "Large language models are powerful but often limited by high computational cost, privacy concerns, and English-centric training. Recent progress demonstrates that small, efficient models with around one billion parameters can deliver strong results and enable on-device use. This paper introduces MiniLingua, a multilingual open-source LLM of one billion parameters trained from scratch for 13 European languages, designed to balance coverage and instruction-following capabilities. Based on evaluation results, the instruction-tuned version of MiniLingua outperforms EuroLLM, a model with a similar training approach but a larger training budget, on summarization, classification and both open- and closed-book question answering. Moreover, it remains competitive with more advanced state-of-the-art models on open-ended generation tasks. We release model weights, tokenizer and source code used for data processing and model training.",
        "url": "http://arxiv.org/abs/2512.13298v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13298v1",
        "arxiv_id": "2512.13298v1",
        "authors": [
            "Anna Aksenova",
            "Boris Zverkov",
            "Nicola Dainese",
            "Alexander Nikitin",
            "Pekka Marttinen"
        ],
        "submitted": "2025-12-15 13:12:42",
        "source": "arxiv",
        "comment": "9+6 pages, 6 figures and 3 tables in the main text. Code at https://github.com/MiniLingua-ai/training_artifacts"
    },
    {
        "title": "Integrating Causal Reasoning into Automated Fact-Checking",
        "abstract": "In fact-checking applications, a common reason to reject a claim is to detect the presence of erroneous cause-effect relationships between the events at play. However, current automated fact-checking methods lack dedicated causal-based reasoning, potentially missing a valuable opportunity for semantically rich explainability. To address this gap, we propose a methodology that combines event relation extraction, semantic similarity computation, and rule-based reasoning to detect logical inconsistencies between chains of events mentioned in a claim and in an evidence. Evaluated on two fact-checking datasets, this method establishes the first baseline for integrating fine-grained causal event relationships into fact-checking and enhance explainability of verdict prediction.",
        "url": "http://arxiv.org/abs/2512.13286v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13286v1",
        "arxiv_id": "2512.13286v1",
        "authors": [
            "Youssra Rebboud",
            "Pasquale Lisena",
            "Raphael Troncy"
        ],
        "submitted": "2025-12-15 12:56:00",
        "source": "arxiv",
        "comment": "Extended version of the accepted ACM SAC paper"
    },
    {
        "title": "AIR: Post-training Data Selection for Reasoning via Attention Head Influence",
        "abstract": "LLMs achieve remarkable multi-step reasoning capabilities, yet effectively transferring these skills via post-training distillation remains challenging. Existing data selection methods, ranging from manual curation to heuristics based on length, entropy, or overall loss, fail to capture the causal importance of individual reasoning steps, limiting distillation efficiency. To address this, we propose Attention Influence for Reasoning (AIR), a principled, unsupervised and training-free framework that leverages mechanistic insights of the retrieval head to select high-value post-training data. AIR first identifies reasoning-critical attention heads of an off-the-shelf model, then constructs a weakened reference model with disabled head influence, and finally quantifies the resulting loss divergence as the Attention Influence Score. This score enables fine-grained assessment at both the step and sample levels, supporting step-level weighted fine-tuning and global sample selection. Experiments across multiple reasoning benchmarks show that AIR consistently improves reasoning accuracy, surpassing heuristic baselines and effectively isolating the most critical steps and samples. Our work establishes a mechanism-driven, data-efficient approach for reasoning distillation in LLMs.",
        "url": "http://arxiv.org/abs/2512.13279v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13279v1",
        "arxiv_id": "2512.13279v1",
        "authors": [
            "Jinrui Liu",
            "Jeff Wu",
            "Xuanguang Pan",
            "Gavin Cheung",
            "Shuai Ma",
            "Chongyang Tao"
        ],
        "submitted": "2025-12-15 12:38:24",
        "source": "arxiv",
        "comment": "19 pages"
    },
    {
        "title": "AutoTool: Dynamic Tool Selection and Integration for Agentic Reasoning",
        "abstract": "Agentic reinforcement learning has advanced large language models (LLMs) to reason through long chain-of-thought trajectories while interleaving external tool use. Existing approaches assume a fixed inventory of tools, limiting LLM agents' adaptability to new or evolving toolsets. We present AutoTool, a framework that equips LLM agents with dynamic tool-selection capabilities throughout their reasoning trajectories. We first construct a 200k dataset with explicit tool-selection rationales across 1,000+ tools and 100+ tasks spanning mathematics, science, code generation, and multimodal reasoning. Building on this data foundation, AutoTool employs a dual-phase optimization pipeline: (i) supervised and RL-based trajectory stabilization for coherent reasoning, and (ii) KL-regularized Plackett-Luce ranking to refine consistent multi-step tool selection. Across ten diverse benchmarks, we train two base models, Qwen3-8B and Qwen2.5-VL-7B, with AutoTool. With fewer parameters, AutoTool consistently outperforms advanced LLM agents and tool-integration methods, yielding average gains of 6.4% in math & science reasoning, 4.5% in search-based QA, 7.7% in code generation, and 6.9% in multimodal understanding. In addition, AutoTool exhibits stronger generalization by dynamically leveraging unseen tools from evolving toolsets during inference.",
        "url": "http://arxiv.org/abs/2512.13278v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13278v1",
        "arxiv_id": "2512.13278v1",
        "authors": [
            "Jiaru Zou",
            "Ling Yang",
            "Yunzhe Qi",
            "Sirui Chen",
            "Mengting Ai",
            "Ke Shen",
            "Jingrui He",
            "Mengdi Wang"
        ],
        "submitted": "2025-12-15 12:38:04",
        "source": "arxiv",
        "comment": "Best Paper Award at ICCV 2025 Workshop on Multi-Modal Reasoning for Agentic Intelligence"
    },
    {
        "title": "Learning to Retrieve with Weakened Labels: Robust Training under Label Noise",
        "abstract": "Neural Encoders are frequently used in the NLP domain to perform dense retrieval tasks, for instance, to generate the candidate documents for a given query in question-answering tasks. However, sparse annotation and label noise in the training data make it challenging to train or fine-tune such retrieval models. Although existing works have attempted to mitigate these problems by incorporating modified loss functions or data cleaning, these approaches either require some hyperparameters to tune during training or add substantial complexity to the training setup. In this work, we consider a label weakening approach to generate robust retrieval models in the presence of label noise. Instead of enforcing a single, potentially erroneous label for each query document pair, we allow for a set of plausible labels derived from both the observed supervision and the model's confidence scores. We perform an extensive evaluation considering two retrieval models, one re-ranking model, considering four diverse ranking datasets. To this end, we also consider a realistic noisy setting by using a semantic-aware noise generation technique to generate different ratios of noise. Our initial results show that label weakening can improve the performance of the retrieval tasks in comparison to 10 different state-of-the-art loss functions.",
        "url": "http://arxiv.org/abs/2512.13237v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13237v1",
        "arxiv_id": "2512.13237v1",
        "authors": [
            "Arnab Sharma"
        ],
        "submitted": "2025-12-15 11:52:13",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Efficient Adaptive Rejection Sampling for Accelerating Speculative Decoding in Large Language Models",
        "abstract": "Speculative Decoding is a prominent technique for accelerating the autoregressive inference of large language models (LLMs) by employing a fast draft model to propose candidate token sequences and a large target model to verify them in parallel. However, its core component -- the rejection sampling mechanism -- relies on a fixed, context-independent random threshold. This leads to a significant \"random rejection\" problem in high-uncertainty generation scenarios, where plausible candidate tokens are frequently rejected due to random chance, undermining inference efficiency. This paper introduces Efficient Adaptive Rejection Sampling (EARS), a novel method that dynamically adjusts the acceptance threshold by incorporating the target model's own predictive uncertainty, measured as 1 - max(P_target). By introducing a tolerance term proportional to this uncertainty, EARS intelligently relaxes the acceptance criterion when the model is uncertain, effectively reducing random rejections while maintaining strict standards when the model is confident. Experiments on creative writing and open-domain QA tasks demonstrate that EARS significantly enhances the efficiency of speculative decoding, achieving up to an 18.12% increase in throughput with a negligible 0.84% accuracy drop on the GSM8K benchmark. The method requires no modifications to model architectures and can be seamlessly integrated into existing speculative decoding frameworks.",
        "url": "http://arxiv.org/abs/2512.13194v2",
        "pdf_url": "https://arxiv.org/pdf/2512.13194v2",
        "arxiv_id": "2512.13194v2",
        "authors": [
            "Chendong Sun",
            "mingmin Chen",
            "Lei Xu"
        ],
        "submitted": "2025-12-15 11:08:56",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Know Your Users! Estimating User Domain Knowledge in Conversational Recommenders",
        "abstract": "The ideal conversational recommender system (CRS) acts like a savvy salesperson, adapting its language and suggestions to each user's level of expertise. However, most current systems treat all users as experts, leading to frustrating and inefficient interactions when users are unfamiliar with a domain. Systems that can adapt their conversational strategies to a user's knowledge level stand to offer a much more natural and effective experience. To make a step toward such adaptive systems, we introduce a new task: estimating user domain knowledge from conversations, enabling a CRS to better understand user needs and personalize interactions. A key obstacle to developing such adaptive systems is the lack of suitable data; to our knowledge, no existing dataset captures the conversational behaviors of users with varying levels of domain knowledge. Furthermore, in most dialogue collection protocols, users are free to express their own preferences, which tends to concentrate on popular items and well-known features, offering little insight into how novices explore or learn about unfamiliar features. To address this, we design a game-based data collection protocol that elicits varied expressions of knowledge, release the resulting dataset, and provide an initial analysis to highlight its potential for future work on user-knowledge-aware CRS.",
        "url": "http://arxiv.org/abs/2512.13173v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13173v1",
        "arxiv_id": "2512.13173v1",
        "authors": [
            "Ivica Kostric",
            "Ujwal Gadiraju",
            "Krisztian Balog"
        ],
        "submitted": "2025-12-15 10:35:05",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Finch: Benchmarking Finance & Accounting across Spreadsheet-Centric Enterprise Workflows",
        "abstract": "We introduce a finance & accounting benchmark (Finch) for evaluating AI agents on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management.\n  We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain-expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work.\n  We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 48 hours in total yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI agents.",
        "url": "http://arxiv.org/abs/2512.13168v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13168v1",
        "arxiv_id": "2512.13168v1",
        "authors": [
            "Haoyu Dong",
            "Pengkun Zhang",
            "Yan Gao",
            "Xuanyu Dong",
            "Yilin Cheng",
            "Mingzhe Lu",
            "Adina Yakefu",
            "Shuxin Zheng"
        ],
        "submitted": "2025-12-15 10:28:45",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning",
        "abstract": "Effective human-agent collaboration is increasingly prevalent in real-world applications. Current trends in such collaborations are predominantly unidirectional, with users providing instructions or posing questions to agents, where agents respond directly without seeking necessary clarifications or confirmations. However, the evolving capabilities of these agents require more proactive engagement, where agents should dynamically participate in conversations to clarify user intents, resolve ambiguities, and adapt to changing circumstances. Existing prior work under-utilize the conversational capabilities of language models (LMs), thereby optimizing agents as better followers rather than effective speakers. In this work, we introduce SpeakRL, a reinforcement learning (RL) method that enhances agents' conversational capabilities by rewarding proactive interactions with users, such as asking right clarification questions when necessary. To support this, we curate SpeakER, a synthetic dataset that includes diverse scenarios from task-oriented dialogues, where tasks are resolved through interactive clarification questions. We present a systematic analysis of reward design for conversational proactivity and propose a principled reward formulation for teaching agents to balance asking with acting. Empirical evaluations demonstrate that our approach achieves a 20.14% absolute improvement in task completion over base models without increasing conversation turns even surpassing even much larger proprietary models, demonstrating the promise of clarification-centric user-agent interactions.",
        "url": "http://arxiv.org/abs/2512.13159v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13159v1",
        "arxiv_id": "2512.13159v1",
        "authors": [
            "Emre Can Acikgoz",
            "Jinoh Oh",
            "Jie Hao",
            "Joo Hyuk Jeon",
            "Heng Ji",
            "Dilek Hakkani-Tür",
            "Gokhan Tur",
            "Xiang Li",
            "Chengyuan Ma",
            "Xing Fan"
        ],
        "submitted": "2025-12-15 10:08:53",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "MAC: A Multi-Agent Framework for Interactive User Clarification in Multi-turn Conversations",
        "abstract": "Conversational agents often encounter ambiguous user requests, requiring an effective clarification to successfully complete tasks. While recent advancements in real-world applications favor multi-agent architectures to manage complex conversational scenarios efficiently, ambiguity resolution remains a critical and underexplored challenge--particularly due to the difficulty of determining which agent should initiate a clarification and how agents should coordinate their actions when faced with uncertain or incomplete user input. The fundamental questions of when to interrupt a user and how to formulate the optimal clarification query within the most optimal multi-agent settings remain open. In this paper, we propose MAC (Multi-Agent Clarification), an interactive multi-agent framework specifically optimized to resolve user ambiguities by strategically managing clarification dialogues. We first introduce a novel taxonomy categorizing user ambiguities to systematically guide clarification strategies. Then, we present MAC that autonomously coordinates multiple agents to interact synergistically with users. Empirical evaluations on MultiWOZ 2.4 demonstrate that enabling clarification at both levels increases task success rate 7.8\\% (54.5 to 62.3) and reduces the average number of dialogue turns (6.53 to 4.86) by eliciting all required user information up front and minimizing repetition. Our findings highlight the importance of active user interaction and role-aware clarification for more reliable human-agent communication.",
        "url": "http://arxiv.org/abs/2512.13154v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13154v1",
        "arxiv_id": "2512.13154v1",
        "authors": [
            "Emre Can Acikgoz",
            "Jinoh Oh",
            "Joo Hyuk Jeon",
            "Jie Hao",
            "Heng Ji",
            "Dilek Hakkani-Tür",
            "Gokhan Tur",
            "Xiang Li",
            "Chengyuan Ma",
            "Xing Fan"
        ],
        "submitted": "2025-12-15 10:02:50",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Towards Practical Large-scale Dynamical Heterogeneous Graph Embedding: Cold-start Resilient Recommendation",
        "abstract": "Deploying dynamic heterogeneous graph embeddings in production faces key challenges of scalability, data freshness, and cold-start. This paper introduces a practical, two-stage solution that balances deep graph representation with low-latency incremental updates. Our framework combines HetSGFormer, a scalable graph transformer for static learning, with Incremental Locally Linear Embedding (ILLE), a lightweight, CPU-based algorithm for real-time updates. HetSGFormer captures global structure with linear scalability, while ILLE provides rapid, targeted updates to incorporate new data, thus avoiding costly full retraining. This dual approach is cold-start resilient, leveraging the graph to create meaningful embeddings from sparse data. On billion-scale graphs, A/B tests show HetSGFormer achieved up to a 6.11% lift in Advertiser Value over previous methods, while the ILLE module added another 3.22% lift and improved embedding refresh timeliness by 83.2%. Our work provides a validated framework for deploying dynamic graph learning in production environments.",
        "url": "http://arxiv.org/abs/2512.13120v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13120v1",
        "arxiv_id": "2512.13120v1",
        "authors": [
            "Mabiao Long",
            "Jiaxi Liu",
            "Yufeng Li",
            "Hao Xiong",
            "Junchi Yan",
            "Kefan Wang",
            "Yi Cao",
            "Jiandong Ding"
        ],
        "submitted": "2025-12-15 09:19:23",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Uncovering the Role of Initial Saliency in U-Shaped Attention Bias: Scaling Initial Token Weight for Enhanced Long-Text Processing",
        "abstract": "Large language models (LLMs) have demonstrated strong performance on a variety of natural language processing (NLP) tasks. However, they often struggle with long-text sequences due to the ``lost in the middle'' phenomenon. This issue has been shown to arise from a U-shaped attention bias, where attention is disproportionately focused on the beginning and end of a text, leaving the middle section underrepresented. While previous studies have attributed this bias to position encoding, our research first identifies an additional factor: initial saliency. It means that in the attention computation for each token, tokens with higher attention weights relative to the initial token tend to receive more attention in the prediction of the next token. We further find that utilizing this property by scaling attention weight between the initial token and others improves the model's ability to process long contexts, achieving a maximum improvement of 3.6\\% in MDQA dataset. Moreover, combining this approach with existing methods to reduce position encoding bias further enhances performance, achieving a maximum improvement of 3.4\\% in KV-Retrieval tasks.",
        "url": "http://arxiv.org/abs/2512.13109v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13109v1",
        "arxiv_id": "2512.13109v1",
        "authors": [
            "Zewen Qiang",
            "Sendong Zhao",
            "Haochun Wang",
            "Bing Qin",
            "Ting Liu"
        ],
        "submitted": "2025-12-15 09:04:06",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Heart Disease Prediction using Case Based Reasoning (CBR)",
        "abstract": "This study provides an overview of heart disease prediction using an intelligent system. Predicting disease accurately is crucial in the medical field, but traditional methods relying solely on a doctor's experience often lack precision. To address this limitation, intelligent systems are applied as an alternative to traditional approaches. While various intelligent system methods exist, this study focuses on three: Fuzzy Logic, Neural Networks, and Case-Based Reasoning (CBR). A comparison of these techniques in terms of accuracy was conducted, and ultimately, Case-Based Reasoning (CBR) was selected for heart disease prediction. In the prediction phase, the heart disease dataset underwent data pre-processing to clean the data and data splitting to separate it into training and testing sets. The chosen intelligent system was then employed to predict heart disease outcomes based on the processed data. The experiment concluded with Case-Based Reasoning (CBR) achieving a notable accuracy rate of 97.95% in predicting heart disease. The findings also revealed that the probability of heart disease was 57.76% for males and 42.24% for females. Further analysis from related studies suggests that factors such as smoking and alcohol consumption are significant contributors to heart disease, particularly among males.",
        "url": "http://arxiv.org/abs/2512.13078v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13078v1",
        "arxiv_id": "2512.13078v1",
        "authors": [
            "Mohaiminul Islam Bhuiyan",
            "Chan Hue Wah",
            "Nur Shazwani Kamarudin",
            "Nur Hafieza Ismail",
            "Ahmad Fakhri Ab Nasir"
        ],
        "submitted": "2025-12-15 08:20:47",
        "source": "arxiv",
        "comment": "Published in Journal of Theoretical and Applied Information Technology on 31st October 2024. Vol.102. No. 20"
    },
    {
        "title": "A Simple and Effective Framework for Symmetric Consistent Indexing in Large-Scale Dense Retrieval",
        "abstract": "Dense retrieval has become the industry standard in large-scale information retrieval systems due to its high efficiency and competitive accuracy. Its core relies on a coarse-to-fine hierarchical architecture that enables rapid candidate selection and precise semantic matching, achieving millisecond-level response over billion-scale corpora. This capability makes it essential not only in traditional search and recommendation scenarios but also in the emerging paradigm of generative recommendation driven by large language models, where semantic IDs-themselves a form of coarse-to-fine representation-play a foundational role. However, the widely adopted dual-tower encoding architecture introduces inherent challenges, primarily representational space misalignment and retrieval index inconsistency, which degrade matching accuracy, retrieval stability, and performance on long-tail queries. These issues are further magnified in semantic ID generation, ultimately limiting the performance ceiling of downstream generative models.\n  To address these challenges, this paper proposes a simple and effective framework named SCI comprising two synergistic modules: a symmetric representation alignment module that employs an innovative input-swapping mechanism to unify the dual-tower representation space without adding parameters, and an consistent indexing with dual-tower synergy module that redesigns retrieval paths using a dual-view indexing strategy to maintain consistency from training to inference. The framework is systematic, lightweight, and engineering-friendly, requiring minimal overhead while fully supporting billion-scale deployment. We provide theoretical guarantees for our approach, with its effectiveness validated by results across public datasets and real-world e-commerce datasets.",
        "url": "http://arxiv.org/abs/2512.13074v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13074v1",
        "arxiv_id": "2512.13074v1",
        "authors": [
            "Huimu Wang",
            "Yiming Qiu",
            "Xingzhi Yao",
            "Zhiguo Chen",
            "Guoyu Tang",
            "Songlin Wang",
            "Sulong Xu",
            "Mingming Li"
        ],
        "submitted": "2025-12-15 08:11:24",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization",
        "abstract": "Self-supervised reinforcement learning (RL) presents a promising approach for enhancing the reasoning capabilities of Large Language Models (LLMs) without reliance on expensive human-annotated data. However, we find that existing methods suffer from a critical failure mode under long-horizon training: a \"policy collapse\" where performance precipitously degrades. We diagnose this instability and demonstrate that simply scaling the number of rollouts -- a common strategy to improve performance -- only delays, but does not prevent, this collapse. To counteract this instability, we first introduce M-GRPO (Momentum-Anchored Group Relative Policy Optimization), a framework that leverages a slowly evolving momentum model to provide a stable training target. In addition, we identify that this process is often accompanied by a rapid collapse in policy entropy, resulting in a prematurely confident and suboptimal policy. To specifically address this issue, we propose a second contribution: an adaptive filtering method based on the interquartile range (IQR) that dynamically prunes low-entropy trajectories, preserving essential policy diversity. Our extensive experiments on multiple reasoning benchmarks demonstrate that M-GRPO stabilizes the training process while the IQR filter prevents premature convergence. The combination of these two innovations leads to superior training stability and state-of-the-art performance.",
        "url": "http://arxiv.org/abs/2512.13070v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13070v1",
        "arxiv_id": "2512.13070v1",
        "authors": [
            "Bizhe Bai",
            "Hongming Wu",
            "Peng Ye",
            "Tao Chen"
        ],
        "submitted": "2025-12-15 08:07:23",
        "source": "arxiv",
        "comment": "7 pages, 5 figures,Accepted NeurIPS 2025 Workshop on Efficient Reasoning"
    },
    {
        "title": "LLM Rationalis? Measuring Bargaining Capabilities of AI Negotiators",
        "abstract": "Bilateral negotiation is a complex, context-sensitive task in which human negotiators dynamically adjust anchors, pacing, and flexibility to exploit power asymmetries and informal cues. We introduce a unified mathematical framework for modeling concession dynamics based on a hyperbolic tangent curve, and propose two metrics burstiness tau and the Concession-Rigidity Index (CRI) to quantify the timing and rigidity of offer trajectories. We conduct a large-scale empirical comparison between human negotiators and four state-of-the-art large language models (LLMs) across natural-language and numeric-offers settings, with and without rich market context, as well as six controlled power-asymmetry scenarios. Our results reveal that, unlike humans who smoothly adapt to situations and infer the opponents position and strategies, LLMs systematically anchor at extremes of the possible agreement zone for negotiations and optimize for fixed points irrespective of leverage or context. Qualitative analysis further shows limited strategy diversity and occasional deceptive tactics used by LLMs. Moreover the ability of LLMs to negotiate does not improve with better models. These findings highlight fundamental limitations in current LLM negotiation capabilities and point to the need for models that better internalize opponent reasoning and context-dependent strategy.",
        "url": "http://arxiv.org/abs/2512.13063v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13063v1",
        "arxiv_id": "2512.13063v1",
        "authors": [
            "Cheril Shah",
            "Akshit Agarwal",
            "Kanak Garg",
            "Mourad Heddaya"
        ],
        "submitted": "2025-12-15 07:50:09",
        "source": "arxiv",
        "comment": "Published in the First Workshop on Multi-Turn Interactions in Large Language Models at Neurips 2025"
    },
    {
        "title": "An Open and Reproducible Deep Research Agent for Long-Form Question Answering",
        "abstract": "We present an open deep research system for long-form question answering, selected as a winning system in the text-to-text track of the MMU-RAG competition at NeurIPS 2025. The system combines an open-source large language model (LLM) with an open web search API to perform iterative retrieval, reasoning, and synthesis in real-world open-domain settings. To enhance reasoning quality, we apply preference tuning based on LLM-as-a-judge feedback that evaluates multiple aspects, including clarity, insightfulness, and factuality. Our experimental results show that the proposed method consistently improves answer quality across all three aspects. Our source code is publicly available at https://github.com/efficient-deep-research/efficient-deep-research.",
        "url": "http://arxiv.org/abs/2512.13059v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13059v1",
        "arxiv_id": "2512.13059v1",
        "authors": [
            "Ikuya Yamada",
            "Wataru Ikeda",
            "Ko Yoshida",
            "Mengyu Ye",
            "Hinata Sugimoto",
            "Masatoshi Suzuki",
            "Hisanori Ozaki",
            "Jun Suzuki"
        ],
        "submitted": "2025-12-15 07:37:53",
        "source": "arxiv",
        "comment": "Technical report of a winning system in the NeurIPS MMU-RAG competition"
    },
    {
        "title": "Understanding Structured Financial Data with LLMs: A Case Study on Fraud Detection",
        "abstract": "Detecting fraud in financial transactions typically relies on tabular models that demand heavy feature engineering to handle high-dimensional data and offer limited interpretability, making it difficult for humans to understand predictions. Large Language Models (LLMs), in contrast, can produce human-readable explanations and facilitate feature analysis, potentially reducing the manual workload of fraud analysts and informing system refinements. However, they perform poorly when applied directly to tabular fraud detection due to the difficulty of reasoning over many features, the extreme class imbalance, and the absence of contextual information. To bridge this gap, we introduce FinFRE-RAG, a two-stage approach that applies importance-guided feature reduction to serialize a compact subset of numeric/categorical attributes into natural language and performs retrieval-augmented in-context learning over label-aware, instance-level exemplars. Across four public fraud datasets and three families of open-weight LLMs, FinFRE-RAG substantially improves F1/MCC over direct prompting and is competitive with strong tabular baselines in several settings. Although these LLMs still lag behind specialized classifiers, they narrow the performance gap and provide interpretable rationales, highlighting their value as assistive tools in fraud analysis.",
        "url": "http://arxiv.org/abs/2512.13040v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13040v1",
        "arxiv_id": "2512.13040v1",
        "authors": [
            "Xuwei Tan",
            "Yao Ma",
            "Xueru Zhang"
        ],
        "submitted": "2025-12-15 07:09:11",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Progressive Refinement of E-commerce Search Ranking Based on Short-Term Activities of the Buyer",
        "abstract": "In e-commerce shopping, aligning search results with a buyer's immediate needs and preferences presents a significant challenge, particularly in adapting search results throughout the buyer's shopping journey as they move from the initial stages of browsing to making a purchase decision or shift from one intent to another. This study presents a systematic approach to adapting e-commerce search results based on the current context. We start with basic methods and incrementally incorporate more contextual information and state-of-the-art techniques to improve the search outcomes. By applying this evolving contextual framework to items displayed on the search engine results page (SERP), we progressively align search outcomes more closely with the buyer's interests and current search intentions. Our findings demonstrate that this incremental enhancement, from simple heuristic autoregressive features to advanced sequence models, significantly improves ranker performance. The integration of contextual techniques enhances the performance of our production ranker, leading to improved search results in both offline and online A/B testing in terms of Mean Reciprocal Rank (MRR). Overall, the paper details iterative methodologies and their substantial contributions to search result contextualization on e-commerce platforms.",
        "url": "http://arxiv.org/abs/2512.13037v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13037v1",
        "arxiv_id": "2512.13037v1",
        "authors": [
            "Taoran Sheng",
            "Sathappan Muthiah",
            "Atiq Islam",
            "Jinming Feng"
        ],
        "submitted": "2025-12-15 07:07:32",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Scaling Bidirectional Spans and Span Violations in Attention Mechanism",
        "abstract": "The canonical $O(N^2)$ Transformer remains the empirical performance frontier in sequence modeling, and its training can be further optimized by addressing geometric inefficiency. We propose an optimization framework that leverages an asymmetric projection to decompose the backward-pass gradients into parallel spans and orthogonal violations, while keeping the canonical forward-pass $QKV$ structure intact. Through consistent experimental validation across various decomposition and projection setups, we provide strong theoretical evidence: the standard attention gradient is suboptimal. We demonstrated that selectively scaling these components, focusing primarily on $0^{th}$ order bidirectional parallel spans, yields the most effective learning signal. On the limited WikiText-2 dataset, and using a crude configuration, this method achieved a $0.56\\%$ reduction in validation loss, confirming the framework's fundamental validity and suggesting significant potential gains on larger datasets and deeper training regimes",
        "url": "http://arxiv.org/abs/2512.13033v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13033v1",
        "arxiv_id": "2512.13033v1",
        "authors": [
            "Jongwook Kim",
            "Sangheon Yun",
            "Sukjin Yoon"
        ],
        "submitted": "2025-12-15 07:03:24",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Are Large Language Models Really Effective for Training-Free Cold-Start Recommendation?",
        "abstract": "Recommender systems usually rely on large-scale interaction data to learn from users' past behaviors and make accurate predictions. However, real-world applications often face situations where no training data is available, such as when launching new services or handling entirely new users. In such cases, conventional approaches cannot be applied. This study focuses on training-free recommendation, where no task-specific training is performed, and particularly on \\textit{training-free cold-start recommendation} (TFCSR), the more challenging case where the target user has no interactions. Large language models (LLMs) have recently been explored as a promising solution, and numerous studies have been proposed. As the ability of text embedding models (TEMs) increases, they are increasingly recognized as applicable to training-free recommendation, but no prior work has directly compared LLMs and TEMs under identical conditions. We present the first controlled experiments that systematically evaluate these two approaches in the same setting. The results show that TEMs outperform LLM rerankers, and this trend holds not only in cold-start settings but also in warm-start settings with rich interactions. These findings indicate that direct LLM ranking is not the only viable option, contrary to the commonly shared belief, and TEM-based approaches provide a stronger and more scalable basis for training-free recommendation.",
        "url": "http://arxiv.org/abs/2512.13001v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13001v1",
        "arxiv_id": "2512.13001v1",
        "authors": [
            "Genki Kusano",
            "Kenya Abe",
            "Kunihiro Takeoka"
        ],
        "submitted": "2025-12-15 05:47:07",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Reveal Hidden Pitfalls and Navigate Next Generation of Vector Similarity Search from Task-Centric Views",
        "abstract": "Vector Similarity Search (VSS) in high-dimensional spaces is rapidly emerging as core functionality in next-generation database systems for numerous data-intensive services -- from embedding lookups in large language models (LLMs), to semantic information retrieval and recommendation engines. Current benchmarks, however, evaluate VSS primarily on the recall-latency trade-off against a ground truth defined solely by distance metrics, neglecting how retrieval quality ultimately impacts downstream tasks. This disconnect can mislead both academic research and industrial practice.\n  We present Iceberg, a holistic benchmark suite for end-to-end evaluation of VSS methods in realistic application contexts. From a task-centric view, Iceberg uncovers the Information Loss Funnel, which identifies three principal sources of end-to-end performance degradation: (1) Embedding Loss during feature extraction; (2) Metric Misuse, where distances poorly reflect task relevance; (3) Data Distribution Sensitivity, highlighting index robustness across skews and modalities. For a more comprehensive assessment, Iceberg spans eight diverse datasets across key domains such as image classification, face recognition, text retrieval, and recommendation systems. Each dataset, ranging from 1M to 100M vectors, includes rich, task-specific labels and evaluation metrics, enabling assessment of retrieval algorithms within the full application pipeline rather than in isolation. Iceberg benchmarks 13 state-of-the-art VSS methods and re-ranks them based on application-level metrics, revealing substantial deviations from traditional rankings derived purely from recall-latency evaluations. Building on these insights, we define a set of task-centric meta-features and derive an interpretable decision tree to guide practitioners in selecting and tuning VSS methods for their specific workloads.",
        "url": "http://arxiv.org/abs/2512.12980v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12980v1",
        "arxiv_id": "2512.12980v1",
        "authors": [
            "Tingyang Chen",
            "Cong Fu",
            "Jiahua Wu",
            "Haotian Wu",
            "Hua Fan",
            "Xiangyu Ke",
            "Yunjun Gao",
            "Yabo Ni",
            "Anxiang Zeng"
        ],
        "submitted": "2025-12-15 04:49:33",
        "source": "arxiv",
        "comment": "SIGMOD2026"
    },
    {
        "title": "Do Reviews Matter for Recommendations in the Era of Large Language Models?",
        "abstract": "With the advent of large language models (LLMs), the landscape of recommender systems is undergoing a significant transformation. Traditionally, user reviews have served as a critical source of rich, contextual information for enhancing recommendation quality. However, as LLMs demonstrate an unprecedented ability to understand and generate human-like text, this raises the question of whether explicit user reviews remain essential in the era of LLMs. In this paper, we provide a systematic investigation of the evolving role of text reviews in recommendation by comparing deep learning methods and LLM approaches. Particularly, we conduct extensive experiments on eight public datasets with LLMs and evaluate their performance in zero-shot, few-shot, and fine-tuning scenarios. We further introduce a benchmarking evaluation framework for review-aware recommender systems, RAREval, to comprehensively assess the contribution of textual reviews to the recommendation performance of review-aware recommender systems. Our framework examines various scenarios, including the removal of some or all textual reviews, random distortion, as well as recommendation performance in data sparsity and cold-start user settings. Our findings demonstrate that LLMs are capable of functioning as effective review-aware recommendation engines, generally outperforming traditional deep learning approaches, particularly in scenarios characterized by data sparsity and cold-start conditions. In addition, the removal of some or all textual reviews and random distortion does not necessarily lead to declines in recommendation accuracy. These findings motivate a rethinking of how user preference from text reviews can be more effectively leveraged. All code and supplementary materials are available at: https://github.com/zhytk/RAREval-data-processing.",
        "url": "http://arxiv.org/abs/2512.12978v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12978v1",
        "arxiv_id": "2512.12978v1",
        "authors": [
            "Chee Heng Tan",
            "Huiying Zheng",
            "Jing Wang",
            "Zhuoyi Lin",
            "Shaodi Feng",
            "Huijing Zhan",
            "Xiaoli Li",
            "J. Senthilnath"
        ],
        "submitted": "2025-12-15 04:46:48",
        "source": "arxiv",
        "comment": "11 pages, 9 figures, 3 tables"
    },
    {
        "title": "Authors Should Annotate",
        "abstract": "The status quo for labeling text is third-party annotation, but there are many cases where information directly from the document's source would be preferable over a third-person proxy, especially for egocentric features like sentiment and belief. We introduce author labeling, an annotation technique where the writer of the document itself annotates the data at the moment of creation. We collaborate with a commercial chatbot with over 10,000 users to deploy an author labeling annotation system for subjective features related to product recommendation. This system identifies task-relevant queries, generates on-the-fly labeling questions, and records authors' answers in real time. We train and deploy an online-learning model architecture for product recommendation that continuously improves from author labeling and find it achieved a 534% increase in click-through rate compared to an industry advertising baseline running concurrently. We then compare the quality and practicality of author labeling to three traditional annotation approaches for sentiment analysis and find author labeling to be higher quality, faster to acquire, and cheaper. These findings reinforce existing literature that annotations, especially for egocentric and subjective beliefs, are significantly higher quality when labeled by the author rather than a third party. To facilitate broader scientific adoption, we release an author labeling service for the research community at academic.echollm.io.",
        "url": "http://arxiv.org/abs/2512.12976v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12976v1",
        "arxiv_id": "2512.12976v1",
        "authors": [
            "Marcus Ma",
            "Cole Johnson",
            "Nolan Bridges",
            "Jackson Trager",
            "Georgios Chochlakis",
            "Shrikanth Narayanan"
        ],
        "submitted": "2025-12-15 04:45:09",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management",
        "abstract": "We introduce QwenLong-L1.5, a model that achieves superior long-context reasoning capabilities through systematic post-training innovations. The key technical breakthroughs of QwenLong-L1.5 are as follows: (1) Long-Context Data Synthesis Pipeline: We develop a systematic synthesis framework that generates challenging reasoning tasks requiring multi-hop grounding over globally distributed evidence. By deconstructing documents into atomic facts and their underlying relationships, and then programmatically composing verifiable reasoning questions, our approach creates high-quality training data at scale, moving substantially beyond simple retrieval tasks to enable genuine long-range reasoning capabilities. (2) Stabilized Reinforcement Learning for Long-Context Training: To overcome the critical instability in long-context RL, we introduce task-balanced sampling with task-specific advantage estimation to mitigate reward bias, and propose Adaptive Entropy-Controlled Policy Optimization (AEPO) that dynamically regulates exploration-exploitation trade-offs. (3) Memory-Augmented Architecture for Ultra-Long Contexts: Recognizing that even extended context windows cannot accommodate arbitrarily long sequences, we develop a memory management framework with multi-stage fusion RL training that seamlessly integrates single-pass reasoning with iterative memory-based processing for tasks exceeding 4M tokens. Based on Qwen3-30B-A3B-Thinking, QwenLong-L1.5 achieves performance comparable to GPT-5 and Gemini-2.5-Pro on long-context reasoning benchmarks, surpassing its baseline by 9.90 points on average. On ultra-long tasks (1M~4M tokens), QwenLong-L1.5's memory-agent framework yields a 9.48-point gain over the agent baseline. Additionally, the acquired long-context reasoning ability translates to enhanced performance in general domains like scientific reasoning, memory tool using, and extended dialogue.",
        "url": "http://arxiv.org/abs/2512.12967v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12967v1",
        "arxiv_id": "2512.12967v1",
        "authors": [
            "Weizhou Shen",
            "Ziyi Yang",
            "Chenliang Li",
            "Zhiyuan Lu",
            "Miao Peng",
            "Huashan Sun",
            "Yingcheng Shi",
            "Shengyi Liao",
            "Shaopeng Lai",
            "Bo Zhang",
            "Dayiheng Liu",
            "Fei Huang",
            "Jingren Zhou",
            "Ming Yan"
        ],
        "submitted": "2025-12-15 04:11:11",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "BLADE: A Behavior-Level Data Augmentation Framework with Dual Fusion Modeling for Multi-Behavior Sequential Recommendation",
        "abstract": "Multi-behavior sequential recommendation aims to capture users' dynamic interests by modeling diverse types of user interactions over time. Although several studies have explored this setting, the recommendation performance remains suboptimal, mainly due to two fundamental challenges: the heterogeneity of user behaviors and data sparsity. To address these challenges, we propose BLADE, a framework that enhances multi-behavior modeling while mitigating data sparsity. Specifically, to handle behavior heterogeneity, we introduce a dual item-behavior fusion architecture that incorporates behavior information at both the input and intermediate levels, enabling preference modeling from multiple perspectives. To mitigate data sparsity, we design three behavior-level data augmentation methods that operate directly on behavior sequences rather than core item sequences. These methods generate diverse augmented views while preserving the semantic consistency of item sequences. These augmented views further enhance representation learning and generalization via contrastive learning. Experiments on three real-world datasets demonstrate the effectiveness of our approach.",
        "url": "http://arxiv.org/abs/2512.12964v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12964v1",
        "arxiv_id": "2512.12964v1",
        "authors": [
            "Yupeng Li",
            "Mingyue Cheng",
            "Yucong Luo",
            "Yitong Zhou",
            "Qingyang Mao",
            "Shijin Wang"
        ],
        "submitted": "2025-12-15 04:02:53",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Building from Scratch: A Multi-Agent Framework with Human-in-the-Loop for Multilingual Legal Terminology Mapping",
        "abstract": "Accurately mapping legal terminology across languages remains a significant challenge, especially for language pairs like Chinese and Japanese, which share a large number of homographs with different meanings. Existing resources and standardized tools for these languages are limited. To address this, we propose a human-AI collaborative approach for building a multilingual legal terminology database, based on a multi-agent framework. This approach integrates advanced large language models and legal domain experts throughout the entire process-from raw document preprocessing, article-level alignment, to terminology extraction, mapping, and quality assurance. Unlike a single automated pipeline, our approach places greater emphasis on how human experts participate in this multi-agent system. Humans and AI agents take on different roles: AI agents handle specific, repetitive tasks, such as OCR, text segmentation, semantic alignment, and initial terminology extraction, while human experts provide crucial oversight, review, and supervise the outputs with contextual knowledge and legal judgment. We tested the effectiveness of this framework using a trilingual parallel corpus comprising 35 key Chinese statutes, along with their English and Japanese translations. The experimental results show that this human-in-the-loop, multi-agent workflow not only improves the precision and consistency of multilingual legal terminology mapping but also offers greater scalability compared to traditional manual methods.",
        "url": "http://arxiv.org/abs/2512.12950v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12950v1",
        "arxiv_id": "2512.12950v1",
        "authors": [
            "Lingyi Meng",
            "Maolin Liu",
            "Hao Wang",
            "Yilan Cheng",
            "Qi Yang",
            "Idlkaid Mohanmmed"
        ],
        "submitted": "2025-12-15 03:29:21",
        "source": "arxiv",
        "comment": "43 pages, 6 fingures, accepted in Artificial Intelligence and Law (2025)"
    },
    {
        "title": "SPAR: Session-based Pipeline for Adaptive Retrieval on Legacy File Systems",
        "abstract": "The ability to extract value from historical data is essential for enterprise decision-making. However, much of this information remains inaccessible within large legacy file systems that lack structured organization and semantic indexing, making retrieval and analysis inefficient and error-prone. We introduce SPAR (Session-based Pipeline for Adaptive Retrieval), a conceptual framework that integrates Large Language Models (LLMs) into a Retrieval-Augmented Generation (RAG) architecture specifically designed for legacy enterprise environments. Unlike conventional RAG pipelines, which require costly construction and maintenance of full-scale vector databases that mirror the entire file system, SPAR employs a lightweight two-stage process: a semantic Metadata Index is first created, after which session-specific vector databases are dynamically generated on demand. This design reduces computational overhead while improving transparency, controllability, and relevance in retrieval. We provide a theoretical complexity analysis comparing SPAR with standard LLM-based RAG pipelines, demonstrating its computational advantages. To validate the framework, we apply SPAR to a synthesized enterprise-scale file system containing a large corpus of biomedical literature, showing improvements in both retrieval effectiveness and downstream model accuracy. Finally, we discuss design trade-offs and outline open challenges for deploying SPAR across diverse enterprise settings.",
        "url": "http://arxiv.org/abs/2512.12938v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12938v1",
        "arxiv_id": "2512.12938v1",
        "authors": [
            "Duy A. Nguyen",
            "Hai H. Do",
            "Minh Doan",
            "Minh N. Do"
        ],
        "submitted": "2025-12-15 02:54:10",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Unified Interactive Multimodal Moment Retrieval via Cascaded Embedding-Reranking and Temporal-Aware Score Fusion",
        "abstract": "The exponential growth of video content has created an urgent need for efficient multimodal moment retrieval systems. However, existing approaches face three critical challenges: (1) fixed-weight fusion strategies fail across cross modal noise and ambiguous queries, (2) temporal modeling struggles to capture coherent event sequences while penalizing unrealistic gaps, and (3) systems require manual modality selection, reducing usability. We propose a unified multimodal moment retrieval system with three key innovations. First, a cascaded dual-embedding pipeline combines BEIT-3 and SigLIP for broad retrieval, refined by BLIP-2 based reranking to balance recall and precision. Second, a temporal-aware scoring mechanism applies exponential decay penalties to large temporal gaps via beam search, constructing coherent event sequences rather than isolated frames. Third, Agent-guided query decomposition (GPT-4o) automatically interprets ambiguous queries, decomposes them into modality specific sub-queries (visual/OCR/ASR), and performs adaptive score fusion eliminating manual modality selection. Qualitative analysis demonstrates that our system effectively handles ambiguous queries, retrieves temporally coherent sequences, and dynamically adapts fusion strategies, advancing interactive moment search capabilities.",
        "url": "http://arxiv.org/abs/2512.12935v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12935v1",
        "arxiv_id": "2512.12935v1",
        "authors": [
            "Toan Le Ngo Thanh",
            "Phat Ha Huu",
            "Tan Nguyen Dang Duy",
            "Thong Nguyen Le Minh",
            "Anh Nguyen Nhu Tinh"
        ],
        "submitted": "2025-12-15 02:50:43",
        "source": "arxiv",
        "comment": "Accepted at AAAI Workshop 2026"
    },
    {
        "title": "Meta-GPT: Decoding the Metasurface Genome with Generative Artificial Intelligence",
        "abstract": "Advancing artificial intelligence for physical sciences requires representations that are both interpretable and compatible with the underlying laws of nature. We introduce METASTRINGS, a symbolic language for photonics that expresses nanostructures as textual sequences encoding materials, geometries, and lattice configurations. Analogous to molecular textual representations in chemistry, METASTRINGS provides a framework connecting human interpretability with computational design by capturing the structural hierarchy of photonic metasurfaces. Building on this representation, we develop Meta-GPT, a foundation transformer model trained on METASTRINGS and finetuned with physics-informed supervised, reinforcement, and chain-of-thought learning. Across various design tasks, the model achieves <3% mean-squared spectral error and maintains >98% syntactic validity, generating diverse metasurface prototypes whose experimentally measured optical responses match their target spectra. These results demonstrate that Meta-GPT can learn the compositional rules of light-matter interactions through METASTRINGS, laying a rigorous foundation for AI-driven photonics and representing an important step toward a metasurface genome project.",
        "url": "http://arxiv.org/abs/2512.12888v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12888v1",
        "arxiv_id": "2512.12888v1",
        "authors": [
            "David Dang",
            "Stuart Love",
            "Meena Salib",
            "Quynh Dang",
            "Samuel Rothfarb",
            "Mysk Alnatour",
            "Andrew Salij",
            "Hou-Tong Chen",
            "Ho Wai",
            "Lee",
            "Wilton J. M. Kort-Kamp"
        ],
        "submitted": "2025-12-15 00:09:14",
        "source": "arxiv",
        "comment": "Keywords: Physics-informed machine learning; Transformer models; Reinforcement learning; Chain-of-thought reasoning; Metasurfaces; Nanophotonics; Inverse design"
    },
    {
        "title": "SignRAG: A Retrieval-Augmented System for Scalable Zero-Shot Road Sign Recognition",
        "abstract": "Automated road sign recognition is a critical task for intelligent transportation systems, but traditional deep learning methods struggle with the sheer number of sign classes and the impracticality of creating exhaustive labeled datasets. This paper introduces a novel zero-shot recognition framework that adapts the Retrieval-Augmented Generation (RAG) paradigm to address this challenge. Our method first uses a Vision Language Model (VLM) to generate a textual description of a sign from an input image. This description is used to retrieve a small set of the most relevant sign candidates from a vector database of reference designs. Subsequently, a Large Language Model (LLM) reasons over the retrieved candidates to make a final, fine-grained recognition. We validate this approach on a comprehensive set of 303 regulatory signs from the Ohio MUTCD. Experimental results demonstrate the framework's effectiveness, achieving 95.58% accuracy on ideal reference images and 82.45% on challenging real-world road data. This work demonstrates the viability of RAG-based architectures for creating scalable and accurate systems for road sign recognition without task-specific training.",
        "url": "http://arxiv.org/abs/2512.12885v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12885v1",
        "arxiv_id": "2512.12885v1",
        "authors": [
            "Minghao Zhu",
            "Zhihao Zhang",
            "Anmol Sidhu",
            "Keith Redmill"
        ],
        "submitted": "2025-12-14 23:56:34",
        "source": "arxiv",
        "comment": "Submitted to IV 2026"
    },
    {
        "title": "ERA-IT: Aligning Semantic Models with Revealed Economic Preference for Real-Time and Explainable Patent Valuation",
        "abstract": "Valuing intangible assets under uncertainty remains a critical challenge in the strategic management of technological innovation due to the information asymmetry inherent in high-dimensional technical specifications. Traditional bibliometric indicators, such as citation counts, fail to address this friction in a timely manner due to the systemic latency inherent in data accumulation. To bridge this gap, this study proposes the Economic Reasoning Alignment via Instruction Tuning (ERA-IT) framework. We theoretically conceptualize patent renewal history as a revealed economic preference and leverage it as an objective supervisory signal to align the generative reasoning of Large Language Models (LLMs) with market realities, a process we term Eco-Semantic Alignment. Using a randomly sampled dataset of 10,000 European Patent Office patents across diverse technological domains, we trained the model not only to predict value tiers but also to reverse-engineer the Economic Chain-of-Thought from unstructured text. Empirical results demonstrate that ERA-IT significantly outperforms both conventional econometric models and zero-shot LLMs in predictive accuracy. More importantly, by generating explicit, logically grounded rationales for valuation, the framework serves as a transparent cognitive scaffold for decision-makers, reducing the opacity of black-box AI in high-stakes intellectual property management.",
        "url": "http://arxiv.org/abs/2512.12869v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12869v1",
        "arxiv_id": "2512.12869v1",
        "authors": [
            "Yoo Yongmin",
            "Kim Seungwoo",
            "Liu Jingjiang"
        ],
        "submitted": "2025-12-14 23:04:07",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Counting Clues: A Lightweight Probabilistic Baseline Can Match an LLM",
        "abstract": "Large language models (LLMs) excel on multiple-choice clinical diagnosis benchmarks, yet it is unclear how much of this performance reflects underlying probabilistic reasoning. We study this through questions from MedQA, where the task is to select the most likely diagnosis. We introduce the Frequency-Based Probabilistic Ranker (FBPR), a lightweight method that scores options with a smoothed Naive Bayes over concept-diagnosis co-occurrence statistics from a large corpus. When co-occurrence statistics were sourced from the pretraining corpora for OLMo and Llama, FBPR achieves comparable performance to the corresponding LLMs pretrained on that same corpus. Direct LLM inference and FBPR largely get different questions correct, with an overlap only slightly above random chance, indicating complementary strengths of each method. These findings highlight the continued value of explicit probabilistic baselines: they provide a meaningful performance reference point and a complementary signal for potential hybridization. While the performance of LLMs seems to be driven by a mechanism other than simple frequency aggregation, we show that an approach similar to the historically grounded, low-complexity expert systems still accounts for a substantial portion of benchmark performance.",
        "url": "http://arxiv.org/abs/2512.12868v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12868v1",
        "arxiv_id": "2512.12868v1",
        "authors": [
            "Furong Jia",
            "Yuan Pu",
            "Finn Guo",
            "Monica Agrawal"
        ],
        "submitted": "2025-12-14 23:00:10",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "What Matters in Evaluating Book-Length Stories? A Systematic Study of Long Story Evaluation",
        "abstract": "In this work, we conduct systematic research in a challenging area: the automatic evaluation of book-length stories (>100K tokens). Our study focuses on two key questions: (1) understanding which evaluation aspects matter most to readers, and (2) exploring effective methods for evaluating lengthy stories. We introduce the first large-scale benchmark, LongStoryEval, comprising 600 newly published books with an average length of 121K tokens (maximum 397K). Each book includes its average rating and multiple reader reviews, presented as critiques organized by evaluation aspects. By analyzing all user-mentioned aspects, we propose an evaluation criteria structure and conduct experiments to identify the most significant aspects among the 8 top-level criteria. For evaluation methods, we compare the effectiveness of three types: aggregation-based, incremental-updated, and summary-based evaluations. Our findings reveal that aggregation- and summary-based evaluations perform better, with the former excelling in detail assessment and the latter offering greater efficiency. Building on these insights, we further propose NovelCritique, an 8B model that leverages the efficient summary-based framework to review and score stories across specified aspects. NovelCritique outperforms commercial models like GPT-4o in aligning with human evaluations. Our datasets and codes are available at https://github.com/DingyiYang/LongStoryEval.",
        "url": "http://arxiv.org/abs/2512.12839v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12839v1",
        "arxiv_id": "2512.12839v1",
        "authors": [
            "Dingyi Yang",
            "Qin Jin"
        ],
        "submitted": "2025-12-14 20:53:29",
        "source": "arxiv",
        "comment": "24 pages, 7 figures, Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics"
    },
    {
        "title": "Hindsight is 20/20: Building Agent Memory that Retains, Recalls, and Reflects",
        "abstract": "Agent memory has been touted as a dimension of growth for LLM-based applications, enabling agents that can accumulate experience, adapt across sessions, and move beyond single-shot question answering. The current generation of agent memory systems treats memory as an external layer that extracts salient snippets from conversations, stores them in vector or graph-based stores, and retrieves top-k items into the prompt of an otherwise stateless model. While these systems improve personalization and context carry-over, they still blur the line between evidence and inference, struggle to organize information over long horizons, and offer limited support for agents that must explain their reasoning. We present Hindsight, a memory architecture that treats agent memory as a structured, first-class substrate for reasoning by organizing it into four logical networks that distinguish world facts, agent experiences, synthesized entity summaries, and evolving beliefs. This framework supports three core operations -- retain, recall, and reflect -- that govern how information is added, accessed, and updated. Under this abstraction, a temporal, entity aware memory layer incrementally turns conversational streams into a structured, queryable memory bank, while a reflection layer reasons over this bank to produce answers and to update information in a traceable way. On key long-horizon conversational memory benchmarks like LongMemEval and LoCoMo, Hindsight with an open-source 20B model lifts overall accuracy from 39% to 83.6% over a full-context baseline with the same backbone and outperforms full context GPT-4o. Scaling the backbone further pushes Hindsight to 91.4% on LongMemEval and up to 89.61% on LoCoMo (vs. 75.78% for the strongest prior open system), consistently outperforming existing memory architectures on multi-session and open-domain questions.",
        "url": "http://arxiv.org/abs/2512.12818v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12818v1",
        "arxiv_id": "2512.12818v1",
        "authors": [
            "Chris Latimer",
            "Nicoló Boschi",
            "Andrew Neeser",
            "Chris Bartholomew",
            "Gaurav Srivastava",
            "Xuan Wang",
            "Naren Ramakrishnan"
        ],
        "submitted": "2025-12-14 19:47:23",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Does Tone Change the Answer? Evaluating Prompt Politeness Effects on Modern LLMs: GPT, Gemini, LLaMA",
        "abstract": "Prompt engineering has emerged as a critical factor influencing large language model (LLM) performance, yet the impact of pragmatic elements such as linguistic tone and politeness remains underexplored, particularly across different model families. In this work, we propose a systematic evaluation framework to examine how interaction tone affects model accuracy and apply it to three recently released and widely available LLMs: GPT-4o mini (OpenAI), Gemini 2.0 Flash (Google DeepMind), and Llama 4 Scout (Meta). Using the MMMLU benchmark, we evaluate model performance under Very Friendly, Neutral, and Very Rude prompt variants across six tasks spanning STEM and Humanities domains, and analyze pairwise accuracy differences with statistical significance testing.\n  Our results show that tone sensitivity is both model-dependent and domain-specific. Neutral or Very Friendly prompts generally yield higher accuracy than Very Rude prompts, but statistically significant effects appear only in a subset of Humanities tasks, where rude tone reduces accuracy for GPT and Llama, while Gemini remains comparatively tone-insensitive. When performance is aggregated across tasks within each domain, tone effects diminish and largely lose statistical significance. Compared with earlier researches, these findings suggest that dataset scale and coverage materially influence the detection of tone effects. Overall, our study indicates that while interaction tone can matter in specific interpretive settings, modern LLMs are broadly robust to tonal variation in typical mixed-domain use, providing practical guidance for prompt design and model selection in real-world deployments.",
        "url": "http://arxiv.org/abs/2512.12812v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12812v1",
        "arxiv_id": "2512.12812v1",
        "authors": [
            "Hanyu Cai",
            "Binqi Shen",
            "Lier Jin",
            "Lan Hu",
            "Xiaojing Fan"
        ],
        "submitted": "2025-12-14 19:25:20",
        "source": "arxiv",
        "comment": null
    }
]