# Daily Papers Report - 2025-08-27

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. REALM: Recursive Relevance Modeling for LLM-based Document Re-Ranking

- **LLM Score**: 8
- **Keyword Score**: 15
- **Authors**: Pinhuan Wang, Zhiqiu Xia, Chunhua Liao, Feiyi Wang, Hang Liu
- **URL**: <http://arxiv.org/abs/2508.18379v1>
- **Submitted**: 2025-08-25 18:13:50
- **Comment**: Accepted to EMNLP 2025 (Main Conference). 13 pages, 2 figures
- **Topic Keywords**: information retrieval, queries, ranking, relevance, retrieval, rank
- **Reason**: The paper REALM: Recursive Relevance Modeling for LLM-based Document Re-Ranking is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The paper proposes a novel approach to re-ranking documents using Large Language Models, which aligns with your focus on query understanding and ranking models. The paper's emphasis on uncertainty-aware re-ranking and efficient token usage also resonates with your interest in real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Uncertainty-aware re-ranking framework for Large Language Model-based document re-ranking
- **Aim**: To address limitations of Large Language Model-based document re-ranking, including ranking uncertainty, unstable top-k recovery, and high token costs
- **Rationale**: REALM models LLM-derived relevance as Gaussian distributions and refines them through recursive Bayesian updates, explicitly capturing uncertainty and minimizing redundant queries
- **Ground**: Combines relevance estimation with a recursive refinement process, consisting of Uncertainty-Aware Relevance Modeling, Recursive Refinement Framework, and Pivot-Centric Optimizations
- **Experiment**: Evaluates REALM on two widely used benchmarks, TREC Deep Learning 2019 and 2020, and compares it to other LLM-based re-ranking methods
- **Takeaway**: REALM achieves consistent improvements in both ranking quality and inference efficiency, outperforming state-of-the-art re-ranking methods while significantly reducing token usage and latency

#### Abstract
> Large Language Models (LLMs) have shown strong capabilities in document
re-ranking, a key component in modern Information Retrieval (IR) systems.
However, existing LLM-based approaches face notable limitations, including
ranking uncertainty, unstable top-k recovery, and high token cost due to
token-intensive prompting. To effectively address these limitations, we propose
REALM, an uncertainty-aware re-ranking framework that models LLM-derived
relevance as Gaussian distributions and refines them through recursive Bayesian
updates. By explicitly capturing uncertainty and minimizing redundant queries,
REALM achieves better rankings more efficiently. Experimental results
demonstrate that our REALM surpasses state-of-the-art re-rankers while
significantly reducing token usage and latency, promoting it as the
next-generation re-ranker for modern IR systems.

---

### 2. Optimization of Latent-Space Compression using Game-Theoretic Techniques for Transformer-Based Vector Search

- **LLM Score**: 6
- **Keyword Score**: 11
- **Authors**: Kushagra Agrawal, Nisharg Nargund, Oishani Banerjee
- **URL**: <http://arxiv.org/abs/2508.18877v1>
- **Submitted**: 2025-08-26 09:51:02
- **Topic Keywords**: information retrieval, query, rag, retrieval, search
- **Reason**: The paper is somewhat related to information retrieval, specifically vector similarity search, which is a relevant topic. However, the focus on transformer-based embeddings and latent-space compression is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling. While the paper's game-theoretic framework for optimization is interesting, it does not seem to address the user's primary research themes.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Optimizing Latent-Space Compression in Transformer-Based Vector Search
- **Aim**: Derive a latent transformation that preserves semantic similarity while reducing redundancy
- **Rationale**: Balancing the trade-off between retrieval speed and semantic accuracy in large-scale vector search systems
- **Ground**: Game-theoretic optimization framework, hybrid search architectures, and transformer-based embeddings
- **Experiment**: Benchmark comparison with FAISS library across query time, average cosine similarity, and semantic utility score
- **Takeaway**: Game-theoretic optimization enables near-lossless semantic retrieval in compressed spaces with substantial improvement in average similarity and overall utility

#### Abstract
> Vector similarity search plays a pivotal role in modern information retrieval
systems, especially when powered by transformer-based embeddings. However, the
scalability and efficiency of such systems are often hindered by the high
dimensionality of latent representations. In this paper, we propose a novel
game-theoretic framework for optimizing latent-space compression to enhance
both the efficiency and semantic utility of vector search. By modeling the
compression strategy as a zero-sum game between retrieval accuracy and storage
efficiency, we derive a latent transformation that preserves semantic
similarity while reducing redundancy. We benchmark our method against FAISS, a
widely-used vector search library, and demonstrate that our approach achieves a
significantly higher average similarity (0.9981 vs. 0.5517) and utility (0.8873
vs. 0.5194), albeit with a modest increase in query time. This trade-off
highlights the practical value of game-theoretic latent compression in
high-utility, transformer-based search applications. The proposed system can be
seamlessly integrated into existing LLM pipelines to yield more semantically
accurate and computationally efficient retrieval.

---

### 3. How Reliable are LLMs for Reasoning on the Re-ranking task?

- **LLM Score**: 6
- **Keyword Score**: 4
- **Authors**: Nafis Tanveer Islam, Zhiming Zhao
- **URL**: <http://arxiv.org/abs/2508.18444v1>
- **Submitted**: 2025-08-25 19:48:39
- **Comment**: Accepted at FQAS Conference 2024. DOI will be provided in 3 weeks
  after the conference has published the paper
- **Topic Keywords**: ranking, rank
- **Reason**: The paper explores the reliability of Large Language Models (LLMs) for re-ranking tasks, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on LLMs and their internal workings is not directly aligned with the user's primary interest in IR and search technologies. The paper's emphasis on explainability and transparency is also relevant to NLP, but the connection to user behavior modeling and click models is limited.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Explainable Re-ranking Methodology using Large Language Models
- **Aim**: To develop a re-ranking methodology that provides transparent and trustworthy explanations for ranking decisions using Large Language Models
- **Rationale**: Understanding the internal workings of LLMs is crucial to comprehend the reasoning behind re-ranking, enabling users to make informed decisions
- **Ground**: The proposed methodology integrates various training methods for LLMs, including supervised fine-tuning, direct policy optimization, and proximal policy optimization, with a focus on explainability scores and SHAP analysis
- **Experiment**: The authors experiment with different training methods and evaluate their approach using various metrics, including NDCG@K, BERTScore, BLEU score, Rouge-L, and Cosine Similarity
- **Takeaway**: The paper contributes to the development of explainable re-ranking methodologies, providing a more transparent and trustworthy approach to re-ranking and recommendation systems

#### Abstract
> With the improving semantic understanding capability of Large Language Models
(LLMs), they exhibit a greater awareness and alignment with human values, but
this comes at the cost of transparency. Although promising results are achieved
via experimental analysis, an in-depth understanding of the LLM's internal
workings is unavoidable to comprehend the reasoning behind the re-ranking,
which provides end users with an explanation that enables them to make an
informed decision. Moreover, in newly developed systems with limited user
engagement and insufficient ranking data, accurately re-ranking content remains
a significant challenge. While various training methods affect the training of
LLMs and generate inference, our analysis has found that some training methods
exhibit better explainability than others, implying that an accurate semantic
understanding has not been learned through all training methods; instead,
abstract knowledge has been gained to optimize evaluation, which raises
questions about the true reliability of LLMs. Therefore, in this work, we
analyze how different training methods affect the semantic understanding of the
re-ranking task in LLMs and investigate whether these models can generate more
informed textual reasoning to overcome the challenges of transparency or LLMs
and limited training data. To analyze the LLMs for re-ranking tasks, we utilize
a relatively small ranking dataset from the environment and the Earth science
domain to re-rank retrieved content. Furthermore, we also analyze the
explainable information to see if the re-ranking can be reasoned using
explainability.

---

### 4. Beyond the Black Box: Integrating Lexical and Semantic Methods in Quantitative Discourse Analysis with BERTopic

- **LLM Score**: 6
- **Keyword Score**: 3
- **Authors**: Thomas Compton
- **URL**: <http://arxiv.org/abs/2508.19099v1>
- **Submitted**: 2025-08-26 15:00:04
- **Comment**: 5 pages conference paper, 4 tables
- **Topic Keywords**: rag, search
- **Reason**: The paper's focus on Quantitative Discourse Analysis and its integration of lexical and semantic methods shows some relevance to the user's interests in Natural Language Processing and Information Retrieval. However, the specific application and methodology used in the paper are not directly related to the user's core research themes, such as query understanding, ranking models, and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Hybrid Framework for Quantitative Discourse Analysis (QDA)
- **Aim**: To address the challenges of complexity, accuracy, and transparency in computational discourse studies
- **Rationale**: The complexity, accuracy, and transparency challenges in QDA arise from technical literacy requirements, varying method performance, and lack of access to preprocessing and clustering logic
- **Ground**: Combining lexical (bag-of-words frequency analysis, n-grams) and semantic (sentence embedding-based topic modeling using BERTopic) methods for triangulation and context-aware clustering
- **Experiment**: Example analysis of lexical and semantic methods on a dataset, demonstrating the effectiveness of the hybrid approach
- **Takeaway**: The hybrid framework demonstrates the complementary nature of lexical and semantic methods, emphasizing the importance of triangulation and interdisciplinary training for effective QDA

#### Abstract
> Quantitative Discourse Analysis has seen growing adoption with the rise of
Large Language Models and computational tools. However, reliance on black box
software such as MAXQDA and NVivo risks undermining methodological transparency
and alignment with research goals. This paper presents a hybrid, transparent
framework for QDA that combines lexical and semantic methods to enable
triangulation, reproducibility, and interpretability. Drawing from a case study
in historical political discourse, we demonstrate how custom Python pipelines
using NLTK, spaCy, and Sentence Transformers allow fine-grained control over
preprocessing, lemmatisation, and embedding generation. We further detail our
iterative BERTopic modelling process, incorporating UMAP dimensionality
reduction, HDBSCAN clustering, and c-TF-IDF keyword extraction, optimised
through parameter tuning and multiple runs to enhance topic coherence and
coverage. By juxtaposing precise lexical searches with context-aware semantic
clustering, we argue for a multi-layered approach that mitigates the
limitations of either method in isolation. Our workflow underscores the
importance of code-level transparency, researcher agency, and methodological
triangulation in computational discourse studies. Code and supplementary
materials are available via GitHub.

---

### 5. Bias Mitigation Agent: Optimizing Source Selection for Fair and Balanced Knowledge Retrieval

- **LLM Score**: 6
- **Keyword Score**: 2
- **Authors**: Karanbir Singh, Deepak Muppiri, William Ngu
- **URL**: <http://arxiv.org/abs/2508.18724v1>
- **Submitted**: 2025-08-26 06:44:04
- **Comment**: Accepted at KDD'2025 Agent4IR workshop
- **Topic Keywords**: retrieval
- **Reason**: The paper explores the concept of bias mitigation in knowledge retrieval, which is related to my interests in Information Retrieval and Search technologies. The use of multi-agent systems and optimization techniques is also relevant to my background in query understanding and ranking models. However, the focus on large language models and generative AI applications is not directly aligned with my primary interests in traditional IR and NLP.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Bias Mitigation in Artificial Intelligence Systems
- **Aim**: To develop a novel multi-agent system for optimizing source selection and reducing bias in Large Language Models (LLMs)
- **Rationale**: Traditional prompting techniques in LLMs are limited, and Retrieval-Augmented Generation (RAG) is an effective extension that combines retrieval systems with generative language models to access external knowledge sources dynamically
- **Ground**: The paper draws on existing research in natural language processing, fairness, and bias in large language models, citing 26 references from various sources
- **Experiment**: The Bias Mitigation Agent is evaluated using BE datasets and OpenAI's GPT series models, demonstrating an 81.82% reduction in bias compared to a baseline naive retrieval strategy
- **Takeaway**: The proposed multi-agent system has the potential to enhance fairness and transparency in knowledge-retrieval tasks by orchestrating a set of specialized agents through a centralized control mechanism

#### Abstract
> Large Language Models (LLMs) have transformed the field of artificial
intelligence by unlocking the era of generative applications. Built on top of
generative AI capabilities, Agentic AI represents a major shift toward
autonomous, goal-driven systems that can reason, retrieve, and act. However,
they also inherit the bias present in both internal and external information
sources. This significantly affects the fairness and balance of retrieved
information, and hence reduces user trust. To address this critical challenge,
we introduce a novel Bias Mitigation Agent, a multi-agent system designed to
orchestrate the workflow of bias mitigation through specialized agents that
optimize the selection of sources to ensure that the retrieved content is both
highly relevant and minimally biased to promote fair and balanced knowledge
dissemination. The experimental results demonstrate an 81.82\% reduction in
bias compared to a baseline naive retrieval strategy.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Generative Interfaces for Language Models

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Jiaqi Chen, Yanzhe Zhang, Yutong Zhang, Yijia Shao, Diyi Yang
- **URL**: <http://arxiv.org/abs/2508.19227v1>
- **Submitted**: 2025-08-26 17:43:20
- **Comment**: Preprint
- **Topic Keywords**: query, queries, rag
- **Reason**: The paper explores the concept of generative interfaces for language models, which is related to information retrieval and search technologies. However, the focus is on the user interface and human-AI interaction, rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest for you.

#### Abstract
> Large language models (LLMs) are increasingly seen as assistants, copilots,
and consultants, capable of supporting a wide range of tasks through natural
conversation. However, most systems remain constrained by a linear
request-response format that often makes interactions inefficient in
multi-turn, information-dense, and exploratory tasks. To address these
limitations, we propose Generative Interfaces for Language Models, a paradigm
in which LLMs respond to user queries by proactively generating user interfaces
(UIs) that enable more adaptive and interactive engagement. Our framework
leverages structured interface-specific representations and iterative
refinements to translate user queries into task-specific UIs. For systematic
evaluation, we introduce a multidimensional assessment framework that compares
generative interfaces with traditional chat-based ones across diverse tasks,
interaction patterns, and query types, capturing functional, interactive, and
emotional aspects of user experience. Results show that generative interfaces
consistently outperform conversational ones, with humans preferring them in
over 70% of cases. These findings clarify when and why users favor generative
interfaces, paving the way for future advancements in human-AI interaction.

### 7. Text to Query Plans for Question Answering on Large Tables

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Yipeng Zhang, Chen Wang, Yuzhe Zhang, Jacky Jiang
- **URL**: <http://arxiv.org/abs/2508.18758v1>
- **Submitted**: 2025-08-26 07:35:26
- **Topic Keywords**: query, queries, rag
- **Reason**: The paper explores a novel framework for transforming natural language queries into query plans, which is related to query understanding and ranking models in Information Retrieval. However, the focus on large tabular datasets and SQL commands is not directly aligned with the user's interests in e-commerce and real-time relevance optimization. The paper's relevance is somewhat limited to the user's background in NLP and data mining, but it does not address the user's primary focus on information retrieval and deep semantic understanding.

#### Abstract
> Efficient querying and analysis of large tabular datasets remain significant
challenges, especially for users without expertise in programming languages
like SQL. Text-to-SQL approaches have shown promising performance on benchmark
data; however, they inherit SQL's drawbacks, including inefficiency with large
datasets and limited support for complex data analyses beyond basic querying.
We propose a novel framework that transforms natural language queries into
query plans. Our solution is implemented outside traditional databases,
allowing us to support classical SQL commands while avoiding SQL's inherent
limitations. Additionally, we enable complex analytical functions, such as
principal component analysis and anomaly detection, providing greater
flexibility and extensibility than traditional SQL capabilities. We leverage
LLMs to iteratively interpret queries and construct operation sequences,
addressing computational complexity by incrementally building solutions. By
executing operations directly on the data, we overcome context length
limitations without requiring the entire dataset to be processed by the model.
We validate our framework through experiments on both standard databases and
large scientific tables, demonstrating its effectiveness in handling extensive
datasets and performing sophisticated data analyses.

### 8. UniC-RAG: Universal Knowledge Corruption Attacks to Retrieval-Augmented Generation

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Runpeng Geng, Yanting Wang, Ying Chen, Jinyuan Jia
- **URL**: <http://arxiv.org/abs/2508.18652v1>
- **Submitted**: 2025-08-26 03:50:52
- **Comment**: 21 pages, 4 figures
- **Topic Keywords**: queries, rag, retrieval
- **Reason**: The paper is somewhat related to information retrieval, specifically in the context of retrieval-augmented generation (RAG) systems. However, the focus on knowledge corruption attacks and malicious objectives is not directly aligned with the user's research interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is limited to the broader area of information retrieval, but it does not address the user's specific areas of interest.

#### Abstract
> Retrieval-augmented generation (RAG) systems are widely deployed in
real-world applications in diverse domains such as finance, healthcare, and
cybersecurity. However, many studies showed that they are vulnerable to
knowledge corruption attacks, where an attacker can inject adversarial texts
into the knowledge database of a RAG system to induce the LLM to generate
attacker-desired outputs. Existing studies mainly focus on attacking specific
queries or queries with similar topics (or keywords). In this work, we propose
UniC-RAG, a universal knowledge corruption attack against RAG systems. Unlike
prior work, UniC-RAG jointly optimizes a small number of adversarial texts that
can simultaneously attack a large number of user queries with diverse topics
and domains, enabling an attacker to achieve various malicious objectives, such
as directing users to malicious websites, triggering harmful command execution,
or launching denial-of-service attacks. We formulate UniC-RAG as an
optimization problem and further design an effective solution to solve it,
including a balanced similarity-based clustering method to enhance the attack's
effectiveness. Our extensive evaluations demonstrate that UniC-RAG is highly
effective and significantly outperforms baselines. For instance, UniC-RAG could
achieve over 90% attack success rate by injecting 100 adversarial texts into a
knowledge database with millions of texts to simultaneously attack a large set
of user queries (e.g., 2,000). Additionally, we evaluate existing defenses and
show that they are insufficient to defend against UniC-RAG, highlighting the
need for new defense mechanisms in RAG systems.

### 9. Breaking the Trade-Off Between Faithfulness and Expressiveness for Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Chenxu Yang, Qingyi Si, Zheng Lin
- **URL**: <http://arxiv.org/abs/2508.18651v1>
- **Submitted**: 2025-08-26 03:48:05
- **Topic Keywords**: ranking, rerank, rank
- **Reason**: The paper focuses on Large Language Models, which is not directly related to Information Retrieval or Search technologies. While it touches on the idea of integrating external knowledge, the primary concern is faithfulness and expressiveness, which is more relevant to Natural Language Processing. The paper does not seem to address query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's research interests.

#### Abstract
> Grounding responses in external knowledge represents an effective strategy
for mitigating hallucinations in Large Language Models (LLMs). However, current
LLMs struggle to seamlessly integrate knowledge while simultaneously
maintaining faithfulness (or fidelity) and expressiveness, capabilities that
humans naturally possess. This limitation results in outputs that either lack
support from external knowledge, thereby compromising faithfulness, or appear
overly verbose and unnatural, thus sacrificing expressiveness. In this work, to
break the trade-off between faithfulness and expressiveness, we propose
Collaborative Decoding (CoDe), a novel approach that dynamically integrates
output probabilities generated with and without external knowledge. This
integration is guided by distribution divergence and model confidence, enabling
the selective activation of relevant and reliable expressions from the model's
internal parameters. Furthermore, we introduce a knowledge-aware reranking
mechanism that prevents over-reliance on prior parametric knowledge while
ensuring proper utilization of provided external information. Through
comprehensive experiments, our plug-and-play CoDe framework demonstrates
superior performance in enhancing faithfulness without compromising
expressiveness across diverse LLMs and evaluation metrics, validating both its
effectiveness and generalizability.

### 10. Beyond Quality: Unlocking Diversity in Ad Headline Generation with Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Chang Wang, Siyu Yan, Depeng Yuan, Yuqi Chen, Yanhua Huang, Yuanhang Zheng, Shuhao Li, Yinqi Zhang, Kedi Chen, Mingrui Zhu, Ruiwen Xu
- **URL**: <http://arxiv.org/abs/2508.18739v1>
- **Submitted**: 2025-08-26 07:11:44
- **Topic Keywords**: click, ctr, click-through rate
- **Reason**: The paper focuses on ad headline generation using large language models, optimizing for both quality and diversity. While it touches on relevance and click-through rates, the primary focus is on ad headline generation, which is not directly related to information retrieval, search technologies, or user behavior modeling. The paper's relevance to the user's interests is somewhat limited.

#### Abstract
> The generation of ad headlines plays a vital role in modern advertising,
where both quality and diversity are essential to engage a broad range of
audience segments. Current approaches primarily optimize language models for
headline quality or click-through rates (CTR), often overlooking the need for
diversity and resulting in homogeneous outputs. To address this limitation, we
propose DIVER, a novel framework based on large language models (LLMs) that are
jointly optimized for both diversity and quality. We first design a semantic-
and stylistic-aware data generation pipeline that automatically produces
high-quality training pairs with ad content and multiple diverse headlines. To
achieve the goal of generating high-quality and diversified ad headlines within
a single forward pass, we propose a multi-stage multi-objective optimization
framework with supervised fine-tuning (SFT) and reinforcement learning (RL).
Experiments on real-world industrial datasets demonstrate that DIVER
effectively balances quality and diversity. Deployed on a large-scale
content-sharing platform serving hundreds of millions of users, our framework
improves advertiser value (ADVV) and CTR by 4.0% and 1.4%.

### 11. Retrieval-Augmented Generation for Natural Language Art Provenance Searches in the Getty Provenance Index

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Mathew Henrickson
- **URL**: <http://arxiv.org/abs/2508.19093v1>
- **Submitted**: 2025-08-26 14:58:09
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper focuses on Retrieval-Augmented Generation for natural language art provenance searches, which is related to information retrieval and search technologies. However, the specific domain of art provenance and the use of the Getty Provenance Index are not directly aligned with the user's interests in e-commerce and general information retrieval. The paper's emphasis on semantic retrieval and contextual summarization is somewhat relevant to the user's interests in query understanding and ranking models, but the application is limited to a specific domain.

#### Abstract
> This research presents a Retrieval-Augmented Generation (RAG) framework for
art provenance studies, focusing on the Getty Provenance Index. Provenance
research establishes the ownership history of artworks, which is essential for
verifying authenticity, supporting restitution and legal claims, and
understanding the cultural and historical context of art objects. The process
is complicated by fragmented, multilingual archival data that hinders efficient
retrieval. Current search portals require precise metadata, limiting
exploratory searches. Our method enables natural-language and multilingual
searches through semantic retrieval and contextual summarization, reducing
dependence on metadata structures. We assess RAG's capability to retrieve and
summarize auction records using a 10,000-record sample from the Getty
Provenance Index - German Sales. The results show this approach provides a
scalable solution for navigating art market archives, offering a practical tool
for historians and cultural heritage professionals conducting historically
sensitive research.

### 12. Diverse And Private Synthetic Datasets Generation for RAG evaluation: A multi-agent framework

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Ilias Driouich, Hongliu Cao, Eoin Thomas
- **URL**: <http://arxiv.org/abs/2508.18929v1>
- **Submitted**: 2025-08-26 11:16:14
- **Comment**: ECAI 2025 TRUST AI workshop
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on the evaluation of Retrieval-Augmented Generation (RAG) systems, which is a related topic to Information Retrieval. However, the specific focus on synthetic dataset generation and privacy preservation is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Retrieval-augmented generation (RAG) systems improve large language model
outputs by incorporating external knowledge, enabling more informed and
context-aware responses. However, the effectiveness and trustworthiness of
these systems critically depends on how they are evaluated, particularly on
whether the evaluation process captures real-world constraints like protecting
sensitive information. While current evaluation efforts for RAG systems have
primarily focused on the development of performance metrics, far less attention
has been given to the design and quality of the underlying evaluation datasets,
despite their pivotal role in enabling meaningful, reliable assessments. In
this work, we introduce a novel multi-agent framework for generating synthetic
QA datasets for RAG evaluation that prioritize semantic diversity and privacy
preservation. Our approach involves: (1) a Diversity agent leveraging
clustering techniques to maximize topical coverage and semantic variability,
(2) a Privacy Agent that detects and mask sensitive information across multiple
domains and (3) a QA curation agent that synthesizes private and diverse QA
pairs suitable as ground truth for RAG evaluation. Extensive experiments
demonstrate that our evaluation sets outperform baseline methods in diversity
and achieve robust privacy masking on domain-specific datasets. This work
offers a practical and ethically aligned pathway toward safer, more
comprehensive RAG system evaluation, laying the foundation for future
enhancements aligned with evolving AI regulations and compliance standards.

### 13. Chronological Passage Assembling in RAG framework for Temporal Question Answering

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Byeongjeong Kim, Jeonghyun Park, Joonho Yang, Hwanhee Lee
- **URL**: <http://arxiv.org/abs/2508.18748v1>
- **Submitted**: 2025-08-26 07:23:23
- **Comment**: 7 pages, 3 figures
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper proposes a novel framework for temporal question answering, focusing on narrative texts. While it uses retrieval-augmented generation (RAG) indexing methods, the primary focus is on reconstructing a coherent timeline of events, which is not directly related to my research interests in query understanding, ranking models, and user behavior modeling in Information Retrieval. The paper's emphasis on temporal order and sequential relationships is somewhat relevant, but it does not align with my core research themes.

#### Abstract
> Long-context question answering over narrative tasks is challenging because
correct answers often hinge on reconstructing a coherent timeline of events
while preserving contextual flow in a limited context window.
Retrieval-augmented generation (RAG) indexing methods aim to address this
challenge by selectively retrieving only necessary document segments. However,
narrative texts possess unique characteristics that limit the effectiveness of
these existing approaches. Specifically, understanding narrative texts requires
more than isolated segments, as the broader context and sequential
relationships between segments are crucial for comprehension. To address these
limitations, we propose ChronoRAG, a novel RAG framework specialized for
narrative texts. This approach focuses on two essential aspects: refining
dispersed document information into coherent and structured passages, and
preserving narrative flow by explicitly capturing and maintaining the temporal
order among retrieved passages. We empirically demonstrate the effectiveness of
ChronoRAG through experiments on the NarrativeQA dataset, showing substantial
improvements in tasks requiring both factual identification and comprehension
of complex sequential relationships, underscoring that reasoning over temporal
order is crucial in resolving narrative QA.

### 14. Automatic Prompt Optimization with Prompt Distillation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Viktor N. Zhuravlev, Artur R. Khairullin, Ernest A. Dyagin, Alena N. Sitkina, Nikita I. Kulin
- **URL**: <http://arxiv.org/abs/2508.18992v1>
- **Submitted**: 2025-08-26 12:46:58
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on prompt optimization for language models, which is related to information retrieval and search technologies. However, the specific application and methodology are not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is somewhat limited to the user's background in e-commerce and NLP, but it does not address the user's primary focus on information retrieval and real-time relevance optimization.

#### Abstract
> Autoprompting is the process of automatically selecting optimized prompts for
language models, which is gaining popularity due to the rapid development of
prompt engineering driven by extensive research in the field of large language
models (LLMs). This paper presents DistillPrompt -- a novel autoprompting
method based on large language models that employs a multi-stage integration of
task-specific information into prompts using training data. DistillPrompt
utilizes distillation, compression, and aggregation operations to explore the
prompt space more thoroughly. The method was tested on different datasets for
text classification and generation tasks using the t-lite-instruct-0.1 language
model. The results demonstrate a significant average improvement (e.g., 20.12%
across the entire dataset compared to Grips) in key metrics over existing
methods in the field, establishing DistillPrompt as one of the most effective
non-gradient approaches in autoprompting.

### 15. COMET-poly: Machine Translation Metric Grounded in Other Candidates

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Maike Z√ºfle, Vil√©m Zouhar, Tu Anh Dinh, Felipe Maia Polo, Jan Niehues, Mrinmaya Sachan
- **URL**: <http://arxiv.org/abs/2508.18549v1>
- **Submitted**: 2025-08-25 22:55:22
- **Comment**: Maike Z\"ufle, Vil\'em Zouhar, and Tu Anh Dinh contributed equally
- **Topic Keywords**: retrieval
- **Reason**: The paper proposes machine translation metrics that incorporate additional information, such as alternative translations or retrieved examples, to improve their performance. While it touches on the idea of comparing multiple translations, it does not directly relate to query understanding, ranking models, or user behavior modeling in the context of information retrieval. The paper's focus on machine translation and NLP is somewhat relevant to the user's interests, but it does not align with their primary focus on information retrieval and real-time relevance optimization.

#### Abstract
> Automated metrics for machine translation attempt to replicate human
judgment. Unlike humans, who often assess a translation in the context of
multiple alternatives, these metrics typically consider only the source
sentence and a single translation. This discrepancy in the evaluation setup may
negatively impact the performance of automated metrics. We propose two
automated metrics that incorporate additional information beyond the single
translation. COMET-polycand uses alternative translations of the same source
sentence to compare and contrast with the translation at hand, thereby
providing a more informed assessment of its quality. COMET-polyic, inspired by
retrieval-based in-context learning, takes in translations of similar source
texts along with their human-labeled quality scores to guide the evaluation. We
find that including a single additional translation in COMET-polycand improves
the segment-level metric performance (0.079 to 0.118 Kendall's tau-b
correlation), with further gains when more translations are added.
Incorporating retrieved examples in COMET-polyic yields similar improvements
(0.079 to 0.116 Kendall's tau-b correlation). We release our models publicly.

### 16. Evaluating the Evaluators: Are readability metrics good measures of readability?

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Isabel Cachola, Daniel Khashabi, Mark Dredze
- **URL**: <http://arxiv.org/abs/2508.19221v1>
- **Submitted**: 2025-08-26 17:38:42
- **Topic Keywords**: recommend
- **Reason**: The paper evaluates readability metrics and language models for plain language summarization, which is a topic in Natural Language Processing (NLP). While it touches on the idea of summarization, which is related to information retrieval, the focus is on readability rather than query understanding, ranking models, or user behavior modeling, making it only loosely relevant to your research interests.

#### Abstract
> Plain Language Summarization (PLS) aims to distill complex documents into
accessible summaries for non-expert audiences. In this paper, we conduct a
thorough survey of PLS literature, and identify that the current standard
practice for readability evaluation is to use traditional readability metrics,
such as Flesch-Kincaid Grade Level (FKGL). However, despite proven utility in
other fields, these metrics have not been compared to human readability
judgments in PLS. We evaluate 8 readability metrics and show that most
correlate poorly with human judgments, including the most popular metric, FKGL.
We then show that Language Models (LMs) are better judges of readability, with
the best-performing model achieving a Pearson correlation of 0.56 with human
judgments. Extending our analysis to PLS datasets, which contain summaries
aimed at non-expert audiences, we find that LMs better capture deeper measures
of readability, such as required background knowledge, and lead to different
conclusions than the traditional metrics. Based on these findings, we offer
recommendations for best practices in the evaluation of plain language
summaries. We release our analysis code and survey data.

### 17. DenseRec: Revisiting Dense Content Embeddings for Sequential Transformer-based Recommendation

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Jan Malte Lichtenberg, Antonio De Candia, Matteo Ruffini
- **URL**: <http://arxiv.org/abs/2508.18442v1>
- **Submitted**: 2025-08-25 19:47:20
- **Comment**: EARL workshop @RecSys'25, Prague, Czech Republic
- **Topic Keywords**: recommend
- **Reason**: The paper focuses on recommender systems, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the specific topic of sequential recommendation and dense content embeddings is not directly aligned with your core research themes, such as query understanding, ranking models, and user behavior modeling.

#### Abstract
> Transformer-based sequential recommenders, such as SASRec or BERT4Rec,
typically rely solely on learned item ID embeddings, making them vulnerable to
the item cold-start problem, particularly in environments with dynamic item
catalogs. While dense content embeddings from pre-trained models offer
potential solutions, direct integration into transformer-based recommenders has
consistently underperformed compared to ID-only approaches. We revisit this
integration challenge and propose DenseRec, a simple yet effective method that
introduces a dual-path embedding approach. DenseRec learns a linear projection
from the dense embedding space into the ID embedding space during training,
enabling seamless generalization to previously unseen items without requiring
specialized embedding models or complex infrastructure. In experiments on three
real-world datasets, we find DenseRec to consistently outperform an ID-only
SASRec baseline, even without additional hyperparameter tuning and while using
compact embedding models. Our analysis suggests improvements primarily arise
from better sequence representations in the presence of unseen items,
positioning DenseRec as a practical and robust solution for cold-start
sequential recommendation.

### 18. Integral Transformer: Denoising Attention, Not Too Much Not Too Little

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Ivan Kobyzev, Abbas Ghaddar, Dingtao Hu, Boxing Chen
- **URL**: <http://arxiv.org/abs/2508.18387v1>
- **Submitted**: 2025-08-25 18:19:21
- **Comment**: EMNLP 2025 Main
- **Topic Keywords**: rank
- **Reason**: The paper proposes a novel self-attention mechanism, the Integral Transformer, which addresses attention noise in Transformer models. While it's related to NLP and Transformer architectures, it doesn't directly address query understanding, ranking models, or user behavior modeling, which are core interests in Information Retrieval and Search technologies.

#### Abstract
> Softmax self-attention often assigns disproportionate weight to semantically
uninformative tokens such as special tokens and punctuation, a phenomenon known
as attention noise. While recent methods like Cog Attention and the
Differential Transformer have addressed this by introducing negative attention
scores, they risk discarding useful information. In this paper, we propose the
Integral Transformer, a novel self-attention mechanism that denoises attention
by integrating signals sampled from the logit distribution. Our approach
mitigates noise while preserving the contributions of special tokens critical
for model performance. Extensive experiments demonstrate that our model
outperforms vanilla, Cog, and Differential attention variants on
well-established knowledge and reasoning language benchmarks. Moreover, our
analysis reveals that employing vanilla self-attention in the lower Transformer
layers enhances performance and that the Integral Transformer effectively
balances attention distributions and reduces rank collapse in upper layers.

### 19. An Investigation on Group Query Hallucination Attacks

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Kehao Miao, Xiaolong Jin
- **URL**: <http://arxiv.org/abs/2508.19321v1>
- **Submitted**: 2025-08-26 14:30:59
- **Topic Keywords**: query, queries
- **Reason**: The paper focuses on investigating potential failure modes of large language models, which is not directly related to information retrieval, search technologies, or query understanding. The topic of group query hallucination attacks is not relevant to the user's research interests in ranking models, user behavior modeling, or deep semantic understanding.

#### Abstract
> With the widespread use of large language models (LLMs), understanding their
potential failure modes during user interactions is essential. In practice,
users often pose multiple questions in a single conversation with LLMs.
Therefore, in this study, we propose Group Query Attack, a technique that
simulates this scenario by presenting groups of queries to LLMs simultaneously.
We investigate how the accumulated context from consecutive prompts influences
the outputs of LLMs. Specifically, we observe that Group Query Attack
significantly degrades the performance of models fine-tuned on specific tasks.
Moreover, we demonstrate that Group Query Attack induces a risk of triggering
potential backdoors of LLMs. Besides, Group Query Attack is also effective in
tasks involving reasoning, such as mathematical reasoning and code generation
for pre-trained and aligned models.

### 20. Attention2Probability: Attention-Driven Terminology Probability Estimation for Robust Speech-to-Text System

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Yanfan Du, Jun Zhang, Bin Wang, Jin Qiu, Lu Huang, Yuan Ge, Xiaoqian Liu, Tong Xiao, Jingbo Zhu
- **URL**: <http://arxiv.org/abs/2508.18701v1>
- **Submitted**: 2025-08-26 06:08:17
- **Comment**: 9 pages, 4 figures, 5 tables
- **Topic Keywords**: query, retrieval, search
- **Reason**: The paper focuses on speech-to-text systems and terminology probability estimation, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions attention mechanisms, it is not applied to ranking models or user behavior modeling, and the paper's scope is limited to speech recognition and translation tasks.

#### Abstract
> Recent advances in speech large language models (SLMs) have improved speech
recognition and translation in general domains, but accurately generating
domain-specific terms or neologisms remains challenging. To address this, we
propose Attention2Probability: attention-driven terminology probability
estimation for robust speech-to-text system, which is lightweight, flexible,
and accurate. Attention2Probability converts cross-attention weights between
speech and terminology into presence probabilities, and it further employs
curriculum learning to enhance retrieval accuracy. Furthermore, to tackle the
lack of data for speech-to-text tasks with terminology intervention, we create
and release a new speech dataset with terminology to support future research in
this area. Experimental results show that Attention2Probability significantly
outperforms the VectorDB method on our test set. Specifically, its maximum
recall rates reach 92.57% for Chinese and 86.83% for English. This high recall
is achieved with a latency of only 8.71ms per query. Intervening in SLMs'
recognition and translation tasks using Attention2Probability-retrieved terms
improves terminology accuracy by 6-17%, while revealing that the current
utilization of terminology by SLMs has limitations.

### 21. Beyond the Textual: Generating Coherent Visual Options for MCQs

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Wanqiang Wang, Longzhu He, Wei Zheng
- **URL**: <http://arxiv.org/abs/2508.18772v1>
- **Submitted**: 2025-08-26 07:55:46
- **Comment**: EMNLP 2025
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper focuses on generating educational MCQs with visual options, which is outside the scope of information retrieval and search technologies. While it involves some aspects of multimodal processing, the primary focus is on education and not on query understanding, ranking models, or user behavior modeling.

#### Abstract
> Multiple-choice questions (MCQs) play a crucial role in fostering deep
thinking and knowledge integration in education. However, previous research has
primarily focused on generating MCQs with textual options, but it largely
overlooks the visual options. Moreover, generating high-quality distractors
remains a major challenge due to the high cost and limited scalability of
manual authoring. To tackle these problems, we propose a Cross-modal Options
Synthesis (CmOS), a novel framework for generating educational MCQs with visual
options. Our framework integrates Multimodal Chain-of-Thought (MCoT) reasoning
process and Retrieval-Augmented Generation (RAG) to produce semantically
plausible and visually similar answer and distractors. It also includes a
discrimination module to identify content suitable for visual options.
Experimental results on test tasks demonstrate the superiority of CmOS in
content discrimination, question generation and visual option generation over
existing methods across various subjects and educational levels.

### 22. Taming the One-Epoch Phenomenon in Online Recommendation System by Two-stage Contrastive ID Pre-training

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Yi-Ping Hsu, Po-Wei Wang, Chantat Eksombatchai, Jiajing Xu
- **URL**: <http://arxiv.org/abs/2508.18700v1>
- **Submitted**: 2025-08-26 06:06:21
- **Comment**: Published at RecSys'24, see
  https://dl.acm.org/doi/10.1145/3640457.3688053
- **Topic Keywords**: rag, recommend, search
- **Reason**: The paper focuses on online recommendation systems, which is related to the recommender systems you occasionally explore. However, the paper's emphasis on ID-based embeddings, contrastive loss, and pre-training for recommendation tasks is not directly aligned with your primary interests in information retrieval, query understanding, ranking models, and user behavior modeling.

#### Abstract
> ID-based embeddings are widely used in web-scale online recommendation
systems. However, their susceptibility to overfitting, particularly due to the
long-tail nature of data distributions, often limits training to a single
epoch, a phenomenon known as the "one-epoch problem." This challenge has driven
research efforts to optimize performance within the first epoch by enhancing
convergence speed or feature sparsity. In this study, we introduce a novel
two-stage training strategy that incorporates a pre-training phase using a
minimal model with contrastive loss, enabling broader data coverage for the
embedding system. Our offline experiments demonstrate that multi-epoch training
during the pre-training phase does not lead to overfitting, and the resulting
embeddings improve online generalization when fine-tuned for more complex
downstream recommendation tasks. We deployed the proposed system in live
traffic at Pinterest, achieving significant site-wide engagement gains.

### 23. Membership Inference Attacks on LLM-based Recommender Systems

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Jiajie He, Yuechun Gu, Min-Chun Chen, Keke Chen
- **URL**: <http://arxiv.org/abs/2508.18665v1>
- **Submitted**: 2025-08-26 04:14:39
- **Topic Keywords**: click, recommend, recsys
- **Reason**: The paper focuses on recommender systems and membership inference attacks, which is not directly related to the user's primary research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. While the paper touches on the use of language models, it does not explore the deep semantic understanding and real-time relevance optimization that the user is interested in.

#### Abstract
> Large language models (LLMs) based Recommender Systems (RecSys) can flexibly
adapt recommendation systems to different domains. It utilizes in-context
learning (ICL), i.e., the prompts, to customize the recommendation functions,
which include sensitive historical user-specific item interactions, e.g.,
implicit feedback like clicked items or explicit product reviews. Such private
information may be exposed to novel privacy attack. However, no study has been
done on this important issue. We design four membership inference attacks
(MIAs), aiming to reveal whether victims' historical interactions have been
used by system prompts. They are \emph{direct inquiry, hallucination,
similarity, and poisoning attacks}, each of which utilizes the unique features
of LLMs or RecSys. We have carefully evaluated them on three LLMs that have
been used to develop ICL-LLM RecSys and two well-known RecSys benchmark
datasets. The results confirm that the MIA threat on LLM RecSys is realistic:
direct inquiry and poisoning attacks showing significantly high attack
advantages. We have also analyzed the factors affecting these attacks, such as
the number of shots in system prompts and the position of the victim in the
shots.

### 24. StepWiser: Stepwise Generative Judges for Wiser Reasoning

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Wei Xiong, Wenting Zhao, Weizhe Yuan, Olga Golovneva, Tong Zhang, Jason Weston, Sainbayar Sukhbaatar
- **URL**: <http://arxiv.org/abs/2508.19229v2>
- **Submitted**: 2025-08-26 17:45:05
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on stepwise generative judges for wiser reasoning, which is unrelated to information retrieval, search technologies, or query understanding. The topic is more relevant to artificial intelligence, machine learning, and reasoning, which are outside the user's primary research interests.

#### Abstract
> As models increasingly leverage multi-step reasoning strategies to solve
complex problems, supervising the logical validity of these intermediate steps
has become a critical research challenge. Process reward models address this by
providing step-by-step feedback, but current approaches have two major
drawbacks: they typically function as classifiers without providing
explanations, and their reliance on supervised fine-tuning with static datasets
limits generalization. Inspired by recent advances, we reframe stepwise reward
modeling from a classification task to a reasoning task itself. We thus propose
a generative judge that reasons about the policy model's reasoning steps (i.e.,
meta-reasons), outputting thinking tokens before delivering a final verdict.
Our model, StepWiser, is trained by reinforcement learning using relative
outcomes of rollouts. We show it provides (i) better judgment accuracy on
intermediate steps than existing methods; (ii) can be used to improve the
policy model at training time; and (iii) improves inference-time search.

### 25. The Double-edged Sword of LLM-based Data Reconstruction: Understanding and Mitigating Contextual Vulnerability in Word-level Differential Privacy Text Sanitization

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Stephen Meisenbacher, Alexandra Klymenko, Andreea-Elena Bodea, Florian Matthes
- **URL**: <http://arxiv.org/abs/2508.18976v1>
- **Submitted**: 2025-08-26 12:22:45
- **Comment**: 15 pages, 4 figures, 8 tables. Accepted to WPES @ CCS 2025
- **Topic Keywords**: rag, recommend
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The topic of differential privacy text sanitization and LLM-based data reconstruction attacks is outside the scope of your primary focus.

#### Abstract
> Differentially private text sanitization refers to the process of privatizing
texts under the framework of Differential Privacy (DP), providing provable
privacy guarantees while also empirically defending against adversaries seeking
to harm privacy. Despite their simplicity, DP text sanitization methods
operating at the word level exhibit a number of shortcomings, among them the
tendency to leave contextual clues from the original texts due to randomization
during sanitization $\unicode{x2013}$ this we refer to as $\textit{contextual
vulnerability}$. Given the powerful contextual understanding and inference
capabilities of Large Language Models (LLMs), we explore to what extent LLMs
can be leveraged to exploit the contextual vulnerability of DP-sanitized texts.
We expand on previous work not only in the use of advanced LLMs, but also in
testing a broader range of sanitization mechanisms at various privacy levels.
Our experiments uncover a double-edged sword effect of LLM-based data
reconstruction attacks on privacy and utility: while LLMs can indeed infer
original semantics and sometimes degrade empirical privacy protections, they
can also be used for good, to improve the quality and privacy of DP-sanitized
texts. Based on our findings, we propose recommendations for using LLM data
reconstruction as a post-processing step, serving to increase privacy
protection by thinking adversarially.

### 26. ReflectivePrompt: Reflective evolution in autoprompting algorithms

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Viktor N. Zhuravlev, Artur R. Khairullin, Ernest A. Dyagin, Alena N. Sitkina, Nikita I. Kulin
- **URL**: <http://arxiv.org/abs/2508.18870v1>
- **Submitted**: 2025-08-26 09:46:20
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on autoprompting algorithms for language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on evolutionary algorithms, the context is not relevant to the user's primary research interests.

#### Abstract
> Autoprompting is the process of automatically selecting optimized prompts for
language models, which has been gaining popularity with the rapid advancement
of prompt engineering, driven by extensive research in the field of large
language models (LLMs). This paper presents ReflectivePrompt - a novel
autoprompting method based on evolutionary algorithms that employs a reflective
evolution approach for more precise and comprehensive search of optimal
prompts. ReflectivePrompt utilizes short-term and long-term reflection
operations before crossover and elitist mutation to enhance the quality of the
modifications they introduce. This method allows for the accumulation of
knowledge obtained throughout the evolution process and updates it at each
epoch based on the current population. ReflectivePrompt was tested on 33
datasets for classification and text generation tasks using open-access large
language models: t-lite-instruct-0.1 and gemma3-27b-it. The method
demonstrates, on average, a significant improvement (e.g., 28% on BBH compared
to EvoPrompt) in metrics relative to current state-of-the-art approaches,
thereby establishing itself as one of the most effective solutions in
evolutionary algorithm-based autoprompting.

### 27. Emotion Omni: Enabling Empathetic Speech Response Generation through Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Haoyu Wang, Guangyan Zhang, Jiale Chen, Jingyu Li, Yuehai Wang, Yiwen Guo
- **URL**: <http://arxiv.org/abs/2508.18655v1>
- **Submitted**: 2025-08-26 03:54:39
- **Comment**: 5 pages, 1 figure, submitted to ICASSP 2026
- **Topic Keywords**: query
- **Reason**: The paper focuses on developing a speech language model that can understand emotional cues in user queries, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on the topic of user behavior modeling, it is not specifically related to click models or ranking models. The paper's focus on empathetic speech response generation and emotional understanding is more aligned with natural language processing and human-computer interaction.

#### Abstract
> With the development of speech large language models (speech LLMs), users can
now interact directly with assistants via speech. However, most existing models
simply convert the response content into speech without fully understanding the
rich emotional and paralinguistic cues embedded in the user's query. In many
cases, the same sentence can have different meanings depending on the emotional
expression. Furthermore, emotional understanding is essential for improving
user experience in human-machine interaction. Currently, most speech LLMs with
empathetic capabilities are trained on massive datasets. This approach requires
vast amounts of data and significant computational resources. Therefore, a key
challenge lies in how to develop a speech LLM capable of generating empathetic
responses with limited data and without the need for large-scale training. To
address this challenge, we propose Emotion Omni, a novel model architecture
designed to understand the emotional content of user speech input and generate
empathetic speech responses. Additionally, we developed a data generation
pipeline based on an open-source TTS framework to construct a 200k emotional
dialogue dataset, which supports the construction of an empathetic speech
assistant. The demos are available at https://w311411.github.io/omni_demo/

### 28. RLMR: Reinforcement Learning with Mixed Rewards for Creative Writing

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jianxing Liao, Tian Zhang, Xiao Feng, Yusong Zhang, Rui Yang, Haorui Wang, Bosi Wen, Ziying Wang, Runzhi Shi
- **URL**: <http://arxiv.org/abs/2508.18642v1>
- **Submitted**: 2025-08-26 03:40:06
- **Topic Keywords**: pairwise
- **Reason**: The paper focuses on creative writing and reinforcement learning, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves language models, the context is creative writing, which is not a primary area of focus for the user.

#### Abstract
> Large language models are extensively utilized in creative writing
applications. Creative writing requires a balance between subjective writing
quality (e.g., literariness and emotional expression) and objective constraint
following (e.g., format requirements and word limits). Existing reinforcement
learning methods struggle to balance these two aspects: single reward
strategies fail to improve both abilities simultaneously, while fixed-weight
mixed-reward methods lack the ability to adapt to different writing scenarios.
To address this problem, we propose Reinforcement Learning with Mixed Rewards
(RLMR), utilizing a dynamically mixed reward system from a writing reward model
evaluating subjective writing quality and a constraint verification model
assessing objective constraint following. The constraint following reward
weight is adjusted dynamically according to the writing quality within sampled
groups, ensuring that samples violating constraints get negative advantage in
GRPO and thus penalized during training, which is the key innovation of this
proposed method. We conduct automated and manual evaluations across diverse
model families from 8B to 72B parameters. Additionally, we construct a
real-world writing benchmark named WriteEval for comprehensive evaluation.
Results illustrate that our method achieves consistent improvements in both
instruction following (IFEval from 83.36\% to 86.65\%) and writing quality
(72.75\% win rate in manual expert pairwise evaluations on WriteEval). To the
best of our knowledge, RLMR is the first work to combine subjective preferences
with objective verification in online RL training, providing an effective
solution for multi-dimensional creative writing optimization.

### 29. CAC-CoT: Connector-Aware Compact Chain-of-Thought for Efficient Reasoning Data Synthesis Across Dual-System Cognitive Tasks

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sunguk Choi, Yonghoon Kwon, Heondeuk Lee
- **URL**: <http://arxiv.org/abs/2508.18743v1>
- **Submitted**: 2025-08-26 07:17:21
- **Comment**: Accepted at EMNLP 2025 findings
- **Topic Keywords**: rag
- **Reason**: The paper focuses on developing a method for efficient reasoning data synthesis in cognitive tasks, using Large Language Models. While it mentions 'reasoning traces' and 'explanations', the context is unrelated to information retrieval, search technologies, or user behavior modeling, which are the core areas of your research interests.

#### Abstract
> Long chain-of-thought (CoT) prompting helps Large Language Models (LLMs)
solve difficult problems, but very long traces often slow or even degrade
performance on fast, intuitive "System-1" tasks. We introduce Connector-Aware
Compact CoT (CAC-CoT) -- a method that deliberately restricts reasoning to a
small, fixed set of connector phrases, steering the model toward concise and
well -- structured explanations. Despite its simplicity, our synthetic method
with Gemini-2.0-Flash yields a high-quality training quality. CAC-CoT achieves
approximately 85% on GSM8K and approximately 40% on GPQA (System-2) while
retaining approximately 90% on S1-Bench (System-1). Its reasoning traces
average approximately 300 tokens(ART), about one-third the length of baseline
traces, delivering higher efficiency without loss of accuracy.

### 30. Knowing or Guessing? Robust Medical Visual Question Answering via Joint Consistency and Contrastive Learning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Songtao Jiang, Yuxi Chen, Sibo Song, Yan Zhang, Yeying Jin, Yang Feng, Jian Wu, Zuozhu Liu
- **URL**: <http://arxiv.org/abs/2508.18687v1>
- **Submitted**: 2025-08-26 05:21:19
- **Topic Keywords**: rag
- **Reason**: The paper focuses on medical visual question answering, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The techniques and datasets used in the paper, such as Consistency and Contrastive Learning, are not applicable to the user's areas of interest.

#### Abstract
> In high-stakes medical applications, consistent answering across diverse
question phrasings is essential for reliable diagnosis. However, we reveal that
current Medical Vision-Language Models (Med-VLMs) exhibit concerning fragility
in Medical Visual Question Answering, as their answers fluctuate significantly
when faced with semantically equivalent rephrasings of medical questions. We
attribute this to two limitations: (1) insufficient alignment of medical
concepts, leading to divergent reasoning patterns, and (2) hidden biases in
training data that prioritize syntactic shortcuts over semantic understanding.
To address these challenges, we construct RoMed, a dataset built upon original
VQA datasets containing 144k questions with variations spanning word-level,
sentence-level, and semantic-level perturbations. When evaluating
state-of-the-art (SOTA) models like LLaVA-Med on RoMed, we observe alarming
performance drops (e.g., a 40\% decline in Recall) compared to original VQA
benchmarks, exposing critical robustness gaps. To bridge this gap, we propose
Consistency and Contrastive Learning (CCL), which integrates two key
components: (1) knowledge-anchored consistency learning, aligning Med-VLMs with
medical knowledge rather than shallow feature patterns, and (2) bias-aware
contrastive learning, mitigating data-specific priors through discriminative
representation refinement. CCL achieves SOTA performance on three popular VQA
benchmarks and notably improves answer consistency by 50\% on the challenging
RoMed test set, demonstrating significantly enhanced robustness. Code will be
released.

### 31. FALCON: Autonomous Cyber Threat Intelligence Mining with LLMs for IDS Rule Generation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Shaswata Mitra, Azim Bazarov, Martin Duclos, Sudip Mittal, Aritran Piplai, Md Rayhanur Rahman, Edward Zieglar, Shahram Rahimi
- **URL**: <http://arxiv.org/abs/2508.18684v1>
- **Submitted**: 2025-08-26 05:08:53
- **Comment**: 11 pages, 5 figures, 4 tables
- **Topic Keywords**: rag
- **Reason**: The paper focuses on cyber threat intelligence mining and intrusion detection systems, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions data mining, the context is different from the user's background in e-commerce and focus on deep semantic understanding and real-time relevance optimization.

#### Abstract
> Signature-based Intrusion Detection Systems (IDS) detect malicious activities
by matching network or host activity against predefined rules. These rules are
derived from extensive Cyber Threat Intelligence (CTI), which includes attack
signatures and behavioral patterns obtained through automated tools and manual
threat analysis, such as sandboxing. The CTI is then transformed into
actionable rules for the IDS engine, enabling real-time detection and
prevention. However, the constant evolution of cyber threats necessitates
frequent rule updates, which delay deployment time and weaken overall security
readiness. Recent advancements in agentic systems powered by Large Language
Models (LLMs) offer the potential for autonomous IDS rule generation with
internal evaluation. We introduce FALCON, an autonomous agentic framework that
generates deployable IDS rules from CTI data in real-time and evaluates them
using built-in multi-phased validators. To demonstrate versatility, we target
both network (Snort) and host-based (YARA) mediums and construct a
comprehensive dataset of IDS rules with their corresponding CTIs. Our
evaluations indicate FALCON excels in automatic rule generation, with an
average of 95% accuracy validated by qualitative evaluation with 84%
inter-rater agreement among multiple cybersecurity analysts across all metrics.
These results underscore the feasibility and effectiveness of LLM-driven data
mining for real-time cyber threat mitigation.

### 32. Beyond Benchmark: LLMs Evaluation with an Anthropomorphic and Value-oriented Roadmap

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jun Wang, Ninglun Gu, Kailai Zhang, Zijiao Zhang, Yelun Bao, Jin Yang, Xu Yin, Liwei Liu, Yihuan Liu, Pengyong Li, Gary G. Yen, Junchi Yan
- **URL**: <http://arxiv.org/abs/2508.18646v1>
- **Submitted**: 2025-08-26 03:43:05
- **Comment**: Preprint. Under review
- **Topic Keywords**: rag
- **Reason**: The paper focuses on evaluating Large Language Models (LLMs) using an anthropomorphic and value-oriented approach, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on the importance of real-world utility, the paper's primary concern is on the evaluation of LLMs, which is outside the scope of the user's research interests.

#### Abstract
> For Large Language Models (LLMs), a disconnect persists between benchmark
performance and real-world utility. Current evaluation frameworks remain
fragmented, prioritizing technical metrics while neglecting holistic assessment
for deployment. This survey introduces an anthropomorphic evaluation paradigm
through the lens of human intelligence, proposing a novel three-dimensional
taxonomy: Intelligence Quotient (IQ)-General Intelligence for foundational
capacity, Emotional Quotient (EQ)-Alignment Ability for value-based
interactions, and Professional Quotient (PQ)-Professional Expertise for
specialized proficiency. For practical value, we pioneer a Value-oriented
Evaluation (VQ) framework assessing economic viability, social impact, ethical
alignment, and environmental sustainability. Our modular architecture
integrates six components with an implementation roadmap. Through analysis of
200+ benchmarks, we identify key challenges including dynamic assessment needs
and interpretability gaps. It provides actionable guidance for developing LLMs
that are technically proficient, contextually relevant, and ethically sound. We
maintain a curated repository of open-source evaluation resources at:
https://github.com/onejune2018/Awesome-LLM-Eval.

### 33. A New NMT Model for Translating Clinical Texts from English to Spanish

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Rumeng Li, Xun Wang, Hong Yu
- **URL**: <http://arxiv.org/abs/2508.18607v1>
- **Submitted**: 2025-08-26 02:24:38
- **Comment**: This work was accepted by the Machine Learning for Health (ML4H)
  Workshop at NeurIPS 2018
- **Topic Keywords**: ctr
- **Reason**: The paper focuses on Neural Machine Translation (NMT) for clinical texts, which is not directly related to Information Retrieval, Search technologies, or query understanding. Although it involves Natural Language Processing (NLP), the topic is more specific to machine translation and does not align with the user's primary research interests.

#### Abstract
> Translating electronic health record (EHR) narratives from English to Spanish
is a clinically important yet challenging task due to the lack of a
parallel-aligned corpus and the abundant unknown words contained. To address
such challenges, we propose \textbf{NOOV} (for No OOV), a new neural machine
translation (NMT) system that requires little in-domain parallel-aligned corpus
for training. NOOV integrates a bilingual lexicon automatically learned from
parallel-aligned corpora and a phrase look-up table extracted from a large
biomedical knowledge resource, to alleviate both the unknown word problem and
the word-repeat challenge in NMT, enhancing better phrase generation of NMT
systems. Evaluation shows that NOOV is able to generate better translation of
EHR with improvement in both accuracy and fluency.

### 34. Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer Reasoning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jeong-seok Oh, Jay-yoon Lee
- **URL**: <http://arxiv.org/abs/2508.18395v1>
- **Submitted**: 2025-08-25 18:36:28
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer Reasoning, which is not directly related to Information Retrieval, Search technologies, or query understanding. Although it involves Natural Language Processing, the topic is more specific to question answering and does not align with the user's primary research interests.

#### Abstract
> Probabilistic decoding in Large Language Models (LLMs) often yields
inconsistent outputs, particularly on complex or long-form questions.
Self-Consistency (SC) mitigates this for short-form QA by majority voting over
exact strings, whereas Universal Self-Consistency (USC) and Weighted Unigram
Consistency Score (WUCS) extend to long-form responses but lose accuracy on
short-form benchmarks.
  We introduce Latent Self-Consistency (LSC), which selects the most
semantically consistent response using learnable token embeddings. A
lightweight forward generation of summary tokens increases inference time by
less than 1% and requires no changes to the model architecture.
  Across 6 short-form and 5 long-form reasoning benchmarks (e.g., MATH, MMLU,
TruthfulQA), LSC surpasses SC, USC and WUCS on all short-form and long-form
ones on average, while maintaining negligible computational overhead. These
results position LSC as a practical consistency-selection method that works
reliably across answer formats. Additionally, LSC provides well-calibrated
confidence estimates, maintaining low Expected Calibration Error across both
answer formats.

### 35. Backprompting: Leveraging Synthetic Production Data for Health Advice Guardrails

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Kellen Tan Cheng, Anna Lisa Gentile, Chad DeLuca, Guang-Jie Ren
- **URL**: <http://arxiv.org/abs/2508.18384v1>
- **Submitted**: 2025-08-25 18:17:00
- **Topic Keywords**: rag
- **Reason**: The paper focuses on developing a method to generate labeled data for health advice guardrails, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions large language models, the context is different from the user's interests in NLP and IR.

#### Abstract
> The pervasiveness of large language models (LLMs) in enterprise settings has
also brought forth a significant amount of risks associated with their usage.
Guardrails technologies aim to mitigate this risk by filtering LLMs'
input/output text through various detectors. However, developing and
maintaining robust detectors faces many challenges, one of which is the
difficulty in acquiring production-quality labeled data on real LLM outputs
prior to deployment. In this work, we propose backprompting, a simple yet
intuitive solution to generate production-like labeled data for health advice
guardrails development. Furthermore, we pair our backprompting method with a
sparse human-in-the-loop clustering technique to label the generated data. Our
aim is to construct a parallel corpus roughly representative of the original
dataset yet resembling real LLM output. We then infuse existing datasets with
our synthetic examples to produce robust training data for our detector. We
test our technique in one of the most difficult and nuanced guardrails: the
identification of health advice in LLM output, and demonstrate improvement
versus other solutions. Our detector is able to outperform GPT-4o by up to
3.73%, despite having 400x less parameters.

### 36. The Ramon Llull's Thinking Machine for Automated Ideation

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Xinran Zhao, Boyuan Zheng, Chenglei Si, Haofei Yu, Ken Liu, Runlong Zhou, Ruochen Li, Tong Chen, Xiang Li, Yiming Zhang, Tongshuang Wu
- **URL**: <http://arxiv.org/abs/2508.19200v1>
- **Submitted**: 2025-08-26 17:03:43
- **Comment**: 21 pages, 3 figures
- **Topic Keywords**: search
- **Reason**: The paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it touches on AI-driven exploration, it is focused on a specific domain (research ideation) and does not align with the user's primary research interests.

#### Abstract
> This paper revisits Ramon Llull's Ars combinatoria - a medieval framework for
generating knowledge through symbolic recombination - as a conceptual
foundation for building a modern Llull's thinking machine for research
ideation. Our approach defines three compositional axes: Theme (e.g.,
efficiency, adaptivity), Domain (e.g., question answering, machine
translation), and Method (e.g., adversarial training, linear attention). These
elements represent high-level abstractions common in scientific work -
motivations, problem settings, and technical approaches - and serve as building
blocks for LLM-driven exploration. We mine elements from human experts or
conference papers and show that prompting LLMs with curated combinations
produces research ideas that are diverse, relevant, and grounded in current
literature. This modern thinking machine offers a lightweight, interpretable
tool for augmenting scientific creativity and suggests a path toward
collaborative ideation between humans and AI.

### 37. Empowering Computing Education Researchers Through LLM-Assisted Content Analysis

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Laurie Gale, Sebastian Mateos Nicolajsen
- **URL**: <http://arxiv.org/abs/2508.18872v1>
- **Submitted**: 2025-08-26 09:46:59
- **Comment**: 7 pages, 2 figures
- **Topic Keywords**: search
- **Reason**: The paper's focus on computing education research and content analysis using large language models is not directly related to the user's interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's methodology and application are also not relevant to the user's areas of interest, such as query understanding, ranking models, and user behavior modeling.

#### Abstract
> Computing education research (CER) is often instigated by practitioners
wanting to improve both their own and the wider discipline's teaching practice.
However, the latter is often difficult as many researchers lack the colleagues,
resources, or capacity to conduct research that is generalisable or rigorous
enough to advance the discipline. As a result, research methods that enable
sense-making with larger volumes of qualitative data, while not increasing the
burden on the researcher, have significant potential within CER.
  In this discussion paper, we propose such a method for conducting rigorous
analysis on large volumes of textual data, namely a variation of LLM-assisted
content analysis (LACA). This method combines content analysis with the use of
large language models, empowering researchers to conduct larger-scale research
which they would otherwise not be able to perform. Using a computing education
dataset, we illustrate how LACA could be applied in a reproducible and rigorous
manner. We believe this method has potential in CER, enabling more
generalisable findings from a wider range of research. This, together with the
development of similar methods, can help to advance both the practice and
research quality of the CER discipline.

### 38. Harnessing Rule-Based Reinforcement Learning for Enhanced Grammatical Error Correction

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yilin Li, Xunjian Yin, Yilin Chen, Xiaojun Wan
- **URL**: <http://arxiv.org/abs/2508.18780v1>
- **Submitted**: 2025-08-26 08:04:04
- **Comment**: Code will be released upon publication
- **Topic Keywords**: search
- **Reason**: The paper focuses on grammatical error correction in NLP, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and query understanding. While the paper mentions Reinforcement Learning, it is not applied to query understanding or ranking models, and the user's background in e-commerce is not relevant to this topic.

#### Abstract
> Grammatical error correction is a significant task in NLP. Traditional
methods based on encoder-decoder models have achieved certain success, but the
application of LLMs in this field is still underexplored. Current research
predominantly relies on supervised fine-tuning to train LLMs to directly
generate the corrected sentence, which limits the model's powerful reasoning
ability. To address this limitation, we propose a novel framework based on
Rule-Based RL. Through experiments on the Chinese datasets, our Rule-Based RL
framework achieves \textbf{state-of-the-art }performance, with a notable
increase in \textbf{recall}. This result clearly highlights the advantages of
using RL to steer LLMs, offering a more controllable and reliable paradigm for
future development in GEC.

### 39. Designing across domains with declarative thinking: Insights from the 96-Eyes ptychographic imager project

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Antony C Chan
- **URL**: <http://arxiv.org/abs/2508.18512v1>
- **Submitted**: 2025-08-25 21:32:15
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper discusses declarative problem formulation language and its application in a specific domain, which is unrelated to your areas of focus.

#### Abstract
> This article presents a practitioner's reflection on applying declarative,
5th generation, problem formulation language (5GL) to de novo imaging system
design, informed by experiences across the interdisciplinary research in
academia and cross-functional product development within the private sector.
Using the 96-Eyes project: 96-camera parallel multi-modal imager for
high-throughput drug discovery as a representative case, I illustrate how
project requirements, ranging from hardware constraints to life sciences needs,
can be formalized into machine-readable problem statements to preserve
mission-critical input from diverse domain stakeholders. This declarative
approach enhances transparency, ensures design traceability, and minimizes
costly misalignment across optical, algorithmic, hardware-accelerated compute,
and life sciences teams.
  Alongside the technical discussion of 5GL with real-world code examples, I
reflect on the practical barriers to adopting 5GL in environments where
imperative, 3rd-generation languages (3GL) remain the default medium for
inter-team collaboration. Rather than offering an one-size-fits-all solution,
these learned lessons highlight how programming paradigms implicitly shapes
research workflows through existing domain hierarchies. The discussion aims to
invite further explorations into how declarative problem formulations can
facilitate innovation in settings where concurrent R\&{}D workflows are gaining
traction, as opposed to environments where sequential, phase-driven workflows
remain the norm.

### 40. Can Out-of-Distribution Evaluations Uncover Reliance on Shortcuts? A Case Study in Question Answering

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Michal ≈†tef√°nik, Timothee Mickus, Marek Kadlƒç√≠k, Michal Spiegel, Josef Kucha≈ô
- **URL**: <http://arxiv.org/abs/2508.18407v1>
- **Submitted**: 2025-08-25 18:49:50
- **Comment**: To appear in Findings of EMNLP 2025
- **Topic Keywords**: recommend
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on question answering and evaluating generalization capabilities of AI models, which is a topic in Natural Language Processing, but not closely aligned with the user's primary research interests.

#### Abstract
> A majority of recent work in AI assesses models' generalization capabilities
through the lens of performance on out-of-distribution (OOD) datasets. Despite
their practicality, such evaluations build upon a strong assumption: that OOD
evaluations can capture and reflect upon possible failures in a real-world
deployment.
  In this work, we challenge this assumption and confront the results obtained
from OOD evaluations with a set of specific failure modes documented in
existing question-answering (QA) models, referred to as a reliance on spurious
features or prediction shortcuts.
  We find that different datasets used for OOD evaluations in QA provide an
estimate of models' robustness to shortcuts that have a vastly different
quality, some largely under-performing even a simple, in-distribution
evaluation. We partially attribute this to the observation that spurious
shortcuts are shared across ID+OOD datasets, but also find cases where a
dataset's quality for training and evaluation is largely disconnected. Our work
underlines limitations of commonly-used OOD-based evaluations of
generalization, and provides methodology and recommendations for evaluating
generalization within and beyond QA more robustly.

---

