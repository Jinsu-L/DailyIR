[
    {
        "title": "The Ranking Blind Spot: Decision Hijacking in LLM-based Text Ranking",
        "abstract": "Large Language Models (LLMs) have demonstrated strong performance in\ninformation retrieval tasks like passage ranking. Our research examines how\ninstruction-following capabilities in LLMs interact with multi-document\ncomparison tasks, identifying what we term the \"Ranking Blind Spot\", a\ncharacteristic of LLM decision processes during comparative evaluation. We\nanalyze how this ranking blind spot affects LLM evaluation systems through two\napproaches: Decision Objective Hijacking, which alters the evaluation goal in\npairwise ranking systems, and Decision Criteria Hijacking, which modifies\nrelevance standards across ranking schemes. These approaches demonstrate how\ncontent providers could potentially influence LLM-based ranking systems to\naffect document positioning. These attacks aim to force the LLM ranker to\nprefer a specific passage and rank it at the top. Malicious content providers\ncan exploit this weakness, which helps them gain additional exposure by\nattacking the ranker. In our experiment, We empirically show that the proposed\nattacks are effective in various LLMs and can be generalized to multiple\nranking schemes. We apply these attack to realistic examples to show their\neffectiveness. We also found stronger LLMs are more vulnerable to these\nattacks. Our code is available at:\nhttps://github.com/blindspotorg/RankingBlindSpot",
        "url": "http://arxiv.org/abs/2509.18575v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18575v1",
        "arxiv_id": "2509.18575v1",
        "authors": [
            "Yaoyao Qian",
            "Yifan Zeng",
            "Yuchao Jiang",
            "Chelsi Jain",
            "Huazheng Wang"
        ],
        "submitted": "2025-09-23 02:56:38",
        "source": "arxiv",
        "comment": "Accepted by EMNLP 2025",
        "score": 16,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'pairwise' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 9,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of ranking models and their vulnerabilities. The study focuses on the 'Ranking Blind Spot' in Large Language Models (LLMs) and its potential exploitation by malicious content providers. The paper's emphasis on LLM-based text ranking and its implications for real-time relevance optimization aligns closely with your research themes."
    },
    {
        "title": "A Knowledge Graph and a Tripartite Evaluation Framework Make Retrieval-Augmented Generation Scalable and Transparent",
        "abstract": "Large Language Models (LLMs) have significantly enhanced conversational\nArtificial Intelligence(AI) chatbots; however, domain-specific accuracy and the\navoidance of factual inconsistencies remain pressing challenges, particularly\nfor large datasets. Designing an effective chatbot with appropriate methods and\nevaluating its effectiveness is among the challenges in this domain. This study\npresents a Retrieval Augmented Generation (RAG) chatbot that harnesses a\nknowledge graph and vector search retrieval to deliver precise, context-rich\nresponses in an exemplary use case from over high-volume engineering\nproject-related emails, thereby minimising the need for document chunking. A\ncentral innovation of this work is the introduction of RAG Evaluation\n(RAG-Eval), a novel chain-of-thought LLM-based tripartite evaluation framework\nspecifically developed to assess RAG applications. This framework operates in\nparallel with the chatbot, jointly assessing the user's query, the retrieved\ndocument, and the generated response, enabling a holistic evaluation across\nmultiple quality metrics like query relevance, factual accuracy, coverage,\ncoherence and fluency. The resulting scoring system is provided directly to\nusers as a confidence score (1 to 100%), enabling quick identification of\npossible misaligned or incomplete answers. This proposed approach promotes\ntransparency and rapid verification by incorporating metadata email IDs,\ntimestamps into responses. Experimental comparisons against BERTScore and\nG-EVAL for summarisation evaluation tasks confirm its effectiveness, and\nempirical analysis also shows RAG-Eval reliably detects factual gaps and query\nmismatches, thereby fostering trust in high demand, data centric environments.\nThese findings highlight a scalable path for developing accurate,\nuser-verifiable chatbots that bridge the gap between high-level conversational\nfluency and factual accuracy.",
        "url": "http://arxiv.org/abs/2509.19209v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19209v1",
        "arxiv_id": "2509.19209v1",
        "authors": [
            "Olalekan K. Akindele",
            "Bhupesh Kumar Mishra",
            "Kenneth Y. Wertheim"
        ],
        "submitted": "2025-09-23 16:29:22",
        "source": "arxiv",
        "comment": "25 Pages",
        "score": 13,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval augmented generation' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper presents a Retrieval-Augmented Generation (RAG) chatbot that leverages a knowledge graph and vector search retrieval. While it touches on information retrieval and natural language processing, its primary focus is on conversational AI and chatbots, which is somewhat related to your interests in search technologies and query understanding, but not a central match."
    },
    {
        "title": "Robust Denoising Neural Reranker for Recommender Systems",
        "abstract": "For multi-stage recommenders in industry, a user request would first trigger\na simple and efficient retriever module that selects and ranks a list of\nrelevant items, then calls a slower but more sophisticated deep reranking model\nthat refines the item arrangement before exposure to the user. The latter model\ntypically reranks the item list conditioned on the user's history content and\nthe initial ranking from retrievers. Although this two-stage retrieval-ranking\nframework demonstrates practical effectiveness, the significance of retriever\nscores from the previous stage has been limitedly explored, which is\ninformative. In this work, we first theoretically analyze the limitations of\nusing retriever scores as the rerankers' input directly and argue that the\nreranking task is essentially a noise reduction problem from the retriever\nscores. Following this notion, we derive an adversarial framework, DNR, that\nassociates the denoising reranker with a carefully designed noise generation\nmodule. We extend the conventional score error minimization term with three\naugmented objectives, including: 1) a denoising objective that aims to denoise\nthe noisy retriever scores to align with the user feedback; 2) an adversarial\nretriever score generation objective that improves the exploration in the\nretriever score space; and 3) a distribution regularization term that aims to\nalign the distribution of generated noisy retriever scores with the real ones.\nExtensive experiments are conducted on three public datasets, together with\nanalytical support, validating the effectiveness of the proposed DNR.",
        "url": "http://arxiv.org/abs/2509.18736v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18736v1",
        "arxiv_id": "2509.18736v1",
        "authors": [
            "Wenyu Mao",
            "Shuchang Liu",
            "Hailan Yang",
            "Xiaobei Wang",
            "Xiaoyu Yang",
            "Xu Gao",
            "Xiang Li",
            "Lantao Hu",
            "Han Li",
            "Kun Gai",
            "An Zhang",
            "Xiang Wang"
        ],
        "submitted": "2025-09-23 07:29:52",
        "source": "arxiv",
        "comment": null,
        "score": 13,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a two-stage retrieval-ranking framework, which is somewhat related to information retrieval and search technologies. However, the focus is on recommender systems and denoising neural rerankers, which is not a central match to the user's core research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "RELATE: Relation Extraction in Biomedical Abstracts with LLMs and Ontology Constraints",
        "abstract": "Biomedical knowledge graphs (KGs) are vital for drug discovery and clinical\ndecision support but remain incomplete. Large language models (LLMs) excel at\nextracting biomedical relations, yet their outputs lack standardization and\nalignment with ontologies, limiting KG integration. We introduce RELATE, a\nthree-stage pipeline that maps LLM-extracted relations to standardized ontology\npredicates using ChemProt and the Biolink Model. The pipeline includes: (1)\nontology preprocessing with predicate embeddings, (2) similarity-based\nretrieval enhanced with SapBERT, and (3) LLM-based reranking with explicit\nnegation handling. This approach transforms relation extraction from free-text\noutputs to structured, ontology-constrained representations. On the ChemProt\nbenchmark, RELATE achieves 52% exact match and 94% accuracy@10, and in 2,400\nHEAL Project abstracts, it effectively rejects irrelevant associations (0.4%)\nand identifies negated assertions. RELATE captures nuanced biomedical\nrelationships while ensuring quality for KG augmentation. By combining vector\nsearch with contextual LLM reasoning, RELATE provides a scalable, semantically\naccurate framework for converting unstructured biomedical literature into\nstandardized KGs.",
        "url": "http://arxiv.org/abs/2509.19057v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19057v1",
        "arxiv_id": "2509.19057v1",
        "authors": [
            "Olawumi Olasunkanmi",
            "Mathew Satursky",
            "Hong Yi",
            "Chris Bizon",
            "Harlin Lee",
            "Stanley Ahalt"
        ],
        "submitted": "2025-09-23 14:21:46",
        "source": "arxiv",
        "comment": null,
        "score": 10,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on relation extraction in biomedical abstracts using LLMs and ontology constraints, which is somewhat related to information retrieval and NLP. However, the specific domain (biomedical) and application (relation extraction) are not directly aligned with the user's core research interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Investigating Test-Time Scaling with Reranking for Machine Translation",
        "abstract": "Scaling model parameters has become the de facto strategy for improving NLP\nsystems, but it comes with substantial computational costs. Test-Time Scaling\n(TTS) offers an alternative by allocating more computation at inference:\ngenerating multiple candidates and selecting the best. While effective in tasks\nsuch as mathematical reasoning, TTS has not been systematically explored for\nmachine translation (MT). In this paper, we present the first systematic study\nof TTS for MT, investigating a simple but practical best-of-N framework on\nWMT24 benchmarks. Our experiments cover six high-resource and one low-resource\nlanguage pairs, five model sizes (3B-72B), and various TTS compute budget (N up\nto 1024). Our results show that a) For high-resource languages, TTS generally\nimproves translation quality according to multiple neural MT evaluation\nmetrics, and our human evaluation confirms these gains; b) Augmenting smaller\nmodels with large $N$ can match or surpass larger models at $N{=}1$ with more\ncompute cost; c) Under fixed compute budgets, larger models are typically more\nefficient, and TTS can degrade quality due to metric blind spots in\nlow-resource cases.",
        "url": "http://arxiv.org/abs/2509.19020v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19020v1",
        "arxiv_id": "2509.19020v1",
        "authors": [
            "Shaomu Tan",
            "Ryosuke Mitani",
            "Ritvik Choudhary",
            "Toshiyuki Sekiya"
        ],
        "submitted": "2025-09-23 13:58:16",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on machine translation and test-time scaling, which are not directly related to information retrieval, search technologies, or natural language processing in the context of query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "BloomIntent: Automating Search Evaluation with LLM-Generated Fine-Grained User Intents",
        "abstract": "If 100 people issue the same search query, they may have 100 different goals.\nWhile existing work on user-centric AI evaluation highlights the importance of\naligning systems with fine-grained user intents, current search evaluation\nmethods struggle to represent and assess this diversity. We introduce\nBloomIntent, a user-centric search evaluation method that uses user intents as\nthe evaluation unit. BloomIntent first generates a set of plausible,\nfine-grained search intents grounded on taxonomies of user attributes and\ninformation-seeking intent types. Then, BloomIntent provides an automated\nevaluation of search results against each intent powered by large language\nmodels. To support practical analysis, BloomIntent clusters semantically\nsimilar intents and summarizes evaluation outcomes in a structured interface.\nWith three technical evaluations, we showed that BloomIntent generated\nfine-grained, evaluable, and realistic intents and produced scalable\nassessments of intent-level satisfaction that achieved 72% agreement with\nexpert evaluators. In a case study (N=4), we showed that BloomIntent supported\nsearch specialists in identifying intents for ambiguous queries, uncovering\nunderserved user needs, and discovering actionable insights for improving\nsearch experiences. By shifting from query-level to intent-level evaluation,\nBloomIntent reimagines how search systems can be assessed -- not only for\nperformance but for their ability to serve a multitude of user goals.",
        "url": "http://arxiv.org/abs/2509.18641v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18641v1",
        "arxiv_id": "2509.18641v1",
        "authors": [
            "Yoonseo Choi",
            "Eunhye Kim",
            "Hyunwoo Kim",
            "Donghyun Park",
            "Honggu Lee",
            "Jinyoung Kim",
            "Juho Kim"
        ],
        "submitted": "2025-09-23 04:56:06",
        "source": "arxiv",
        "comment": "Accepted to UIST 2025; 34 pages (including 18 pages of Appendix)",
        "score": 7,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper aligns well with your research interests in Information Retrieval, particularly in query understanding and user behavior modeling. The focus on fine-grained user intents and large language models is also relevant to your work in NLP and search technologies. However, the primary focus on search evaluation and user-centric AI evaluation is somewhat tangential to your core research themes."
    },
    {
        "title": "Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning",
        "abstract": "Large language models (LLMs) show promise for diagnostic reasoning but often\nlack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as\nthe Unified Medical Language System (UMLS), offer structured biomedical\nknowledge that can support trustworthy reasoning. Prior approaches typically\nintegrate KGs via retrieval augmented generation or fine tuning, inserting KG\ncontent into prompts rather than enabling structured reasoning. We explore an\nalternative paradigm: treating the LLM as a reward model of KG reasoning paths,\nwhere the model learns to judge whether a candidate path leads to correct\ndiagnosis for a given patient input. This approach is inspired by recent work\nthat leverages reward training to enhance model reasoning abilities, and\ngrounded in computational theory, which suggests that verifying a solution is\noften easier than generating one from scratch. It also parallels physicians'\ndiagnostic assessment, where they judge which sequences of findings and\nintermediate conditions most plausibly support a diagnosis. We first\nsystematically evaluate five task formulation for knowledge path judging and\neight training paradigm. Second, we test whether the path judging abilities\ngeneralize to downstream diagnostic tasks, including diagnosis summarization\nand medical question answering. Experiments with three open source\ninstruct-tuned LLMs reveal both promise and brittleness: while specific reward\noptimization and distillation lead to strong path-judging performance, the\ntransferability to downstream tasks remain weak. Our finding provides the first\nsystematic assessment of \"reward model style\" reasoning over clinical KGs,\noffering insights into how structured, reward-based supervision influences\ndiagnostic reasoning in GenAI systems for healthcare.",
        "url": "http://arxiv.org/abs/2509.18316v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18316v1",
        "arxiv_id": "2509.18316v1",
        "authors": [
            "Saksham Khatwani",
            "He Cheng",
            "Majid Afshar",
            "Dmitriy Dligach",
            "Yanjun Gao"
        ],
        "submitted": "2025-09-22 18:39:09",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval augmented generation' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the application of knowledge graphs in diagnostic reasoning, leveraging large language models as reward models. While it touches on aspects of query understanding and ranking models, its primary focus is on knowledge graph-based reward modeling, which is somewhat related to the user's interests in information retrieval and NLP, but not directly aligned with their core research themes."
    },
    {
        "title": "AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field",
        "abstract": "Large language models (LLMs), as a novel information technology, are seeing\nincreasing adoption in the Architecture, Engineering, and Construction (AEC)\nfield. They have shown their potential to streamline processes throughout the\nbuilding lifecycle. However, the robustness and reliability of LLMs in such a\nspecialized and safety-critical domain remain to be evaluated. To address this\nchallenge, this paper establishes AECBench, a comprehensive benchmark designed\nto quantify the strengths and limitations of current LLMs in the AEC domain.\nThe benchmark defines 23 representative tasks within a five-level\ncognition-oriented evaluation framework encompassing Knowledge Memorization,\nUnderstanding, Reasoning, Calculation, and Application. These tasks were\nderived from authentic AEC practice, with scope ranging from codes retrieval to\nspecialized documents generation. Subsequently, a 4,800-question dataset\nencompassing diverse formats, including open-ended questions, was crafted\nprimarily by engineers and validated through a two-round expert review.\nFurthermore, an LLM-as-a-Judge approach was introduced to provide a scalable\nand consistent methodology for evaluating complex, long-form responses\nleveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear\nperformance decline across five cognitive levels was revealed. Despite\ndemonstrating proficiency in foundational tasks at the Knowledge Memorization\nand Understanding levels, the models showed significant performance deficits,\nparticularly in interpreting knowledge from tables in building codes, executing\ncomplex reasoning and calculation, and generating domain-specific documents.\nConsequently, this study lays the groundwork for future research and\ndevelopment aimed at the robust and reliable integration of LLMs into\nsafety-critical engineering practices.",
        "url": "http://arxiv.org/abs/2509.18776v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18776v1",
        "arxiv_id": "2509.18776v1",
        "authors": [
            "Chen Liang",
            "Zhaoqi Huang",
            "Haofen Wang",
            "Fu Chai",
            "Chunying Yu",
            "Huanhuan Wei",
            "Zhengjie Liu",
            "Yanpeng Li",
            "Hongjun Wang",
            "Ruifeng Luo",
            "Xianzhong Zhao"
        ],
        "submitted": "2025-09-23 08:09:58",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, particularly in the context of evaluating large language models. However, the focus on the Architecture, Engineering, and Construction (AEC) field and the specific tasks defined in the benchmark are not directly aligned with your core research themes."
    },
    {
        "title": "Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference",
        "abstract": "Large language models (LLMs) are increasingly used for text-rich graph\nmachine learning tasks such as node classification in high-impact domains like\nfraud detection and recommendation systems. Yet, despite a surge of interest,\nthe field lacks a principled understanding of the capabilities of LLMs in their\ninteraction with graph data. In this work, we conduct a large-scale, controlled\nevaluation across several key axes of variability to systematically assess the\nstrengths and weaknesses of LLM-based graph reasoning methods in text-based\napplications. The axes include the LLM-graph interaction mode, comparing\nprompting, tool-use, and code generation; dataset domains, spanning citation,\nweb-link, e-commerce, and social networks; structural regimes contrasting\nhomophilic and heterophilic graphs; feature characteristics involving both\nshort- and long-text node attributes; and model configurations with varying LLM\nsizes and reasoning capabilities. We further analyze dependencies by\nmethodically truncating features, deleting edges, and removing labels to\nquantify reliance on input types. Our findings provide practical and actionable\nguidance. (1) LLMs as code generators achieve the strongest overall performance\non graph data, with especially large gains on long-text or high-degree graphs\nwhere prompting quickly exceeds the token budget. (2) All interaction\nstrategies remain effective on heterophilic graphs, challenging the assumption\nthat LLM-based methods collapse under low homophily. (3) Code generation is\nable to flexibly adapt its reliance between structure, features, or labels to\nleverage the most informative input type. Together, these findings provide a\ncomprehensive view of the strengths and limitations of current LLM-graph\ninteraction modes and highlight key design principles for future approaches.",
        "url": "http://arxiv.org/abs/2509.18487v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18487v1",
        "arxiv_id": "2509.18487v1",
        "authors": [
            "Ben Finkelshtein",
            "Silviu Cucerzan",
            "Sujay Kumar Jauhar",
            "Ryen White"
        ],
        "submitted": "2025-09-23 00:46:21",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the capabilities of Large Language Models (LLMs) in graph inference tasks, which is somewhat related to information retrieval, but primarily focuses on NLP and graph machine learning. While it touches on recommender systems, which is a tangential interest, it does not directly address query understanding, ranking models, or user behavior modeling, making it only loosely relevant to your core research themes."
    },
    {
        "title": "Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models",
        "abstract": "Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph\ninteractions and associated text attributes, are prevalent in real-world\napplications. Existing methods, such as Graph Neural Networks (GNNs) and Large\nLanguage Models (LLMs), mostly focus on static TAGs. Extending these existing\nmethods to DyTAGs is challenging as they largely neglect the recent-global\ntemporal semantics: the recent semantic dependencies among interaction texts\nand the global semantic evolution of nodes over time. Furthermore, applying\nLLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To\ntackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic\nProcessing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to\nefficiently and effectively reason on DyTAGs. Specifically, we first design a\nnode-centric implicit reasoning method together with a sliding window mechanism\nto efficiently capture recent temporal semantics. In addition, to capture\nglobal semantic dynamics of nodes, we leverage explicit reasoning with tailored\nprompts and an RNN-like chain structure to infer long-term semantics. Lastly,\nwe intricately integrate the recent and global temporal semantics as well as\nthe dynamic graph structural information using updating and merging layers.\nExtensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,\nachieving up to 34% improvement in Hit@10 for destination node retrieval task.\nBesides, DyGRASP exhibits strong generalization across different temporal GNNs\nand LLMs.",
        "url": "http://arxiv.org/abs/2509.18742v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18742v1",
        "arxiv_id": "2509.18742v1",
        "authors": [
            "Yunan Wang",
            "Jianxin Li",
            "Ziwei Zhang"
        ],
        "submitted": "2025-09-23 07:35:42",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on reasoning on dynamic text-attributed graphs using Large Language Models, which is somewhat related to information retrieval and search technologies. However, the primary focus is on graph reasoning and temporal semantics, which is not a central match to the user's core research themes in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture",
        "abstract": "We introduce DRISHTIKON, a first-of-its-kind multimodal and multilingual\nbenchmark centered exclusively on Indian culture, designed to evaluate the\ncultural understanding of generative AI systems. Unlike existing benchmarks\nwith a generic or global scope, DRISHTIKON offers deep, fine-grained coverage\nacross India's diverse regions, spanning 15 languages, covering all states and\nunion territories, and incorporating over 64,000 aligned text-image pairs. The\ndataset captures rich cultural themes including festivals, attire, cuisines,\nart forms, and historical heritage amongst many more. We evaluate a wide range\nof vision-language models (VLMs), including open-source small and large models,\nproprietary systems, reasoning-specialized VLMs, and Indic-focused models,\nacross zero-shot and chain-of-thought settings. Our results expose key\nlimitations in current models' ability to reason over culturally grounded,\nmultimodal inputs, particularly for low-resource languages and less-documented\ntraditions. DRISHTIKON fills a vital gap in inclusive AI research, offering a\nrobust testbed to advance culturally aware, multimodally competent language\ntechnologies.",
        "url": "http://arxiv.org/abs/2509.19274v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19274v1",
        "arxiv_id": "2509.19274v1",
        "authors": [
            "Arijit Maji",
            "Raghvendra Kumar",
            "Akash Ghosh",
            "Anushka",
            "Nemil Shah",
            "Abhilekh Borah",
            "Vanshika Shah",
            "Nishant Mishra",
            "Sriparna Saha"
        ],
        "submitted": "2025-09-23 17:40:43",
        "source": "arxiv",
        "comment": "EMNLP MAINS 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on evaluating language models' understanding of Indian culture, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve language models, the specific application and scope are quite different from the user's areas of focus."
    },
    {
        "title": "CompLLM: Compression for Long Context Q&A",
        "abstract": "Large Language Models (LLMs) face significant computational challenges when\nprocessing long contexts due to the quadratic complexity of self-attention.\nWhile soft context compression methods, which map input text to smaller latent\nrepresentations, have shown promise, their real-world adoption is limited.\nExisting techniques typically compress the context as a single unit, which\nleads to quadratic compression complexity and an inability to reuse\ncomputations across queries with overlapping contexts. In this work, we\nintroduce CompLLM, a soft compression technique designed for practical\ndeployment. Instead of processing the context holistically, CompLLM divides it\ninto segments and compresses each one independently. This simple design choice\nyields three critical properties: efficiency, as the compression step scales\nlinearly with the context length; scalability, enabling models trained on short\nsequences (e.g., 1k tokens) to generalize to contexts of 100k tokens; and\nreusability, allowing compressed segments to be cached and reused across\ndifferent queries. Our experiments show that with a 2x compression rate, at\nhigh context lengths CompLLM speeds up Time To First Token (TTFT) by up to 4x\nand reduces the KV cache size by 50%. Furthermore, CompLLM achieves performance\ncomparable to that obtained with the uncompressed context, and even surpasses\nit on very long sequences, demonstrating its effectiveness and practical\nutility.",
        "url": "http://arxiv.org/abs/2509.19228v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19228v1",
        "arxiv_id": "2509.19228v1",
        "authors": [
            "Gabriele Berton",
            "Jayakrishnan Unnikrishnan",
            "Son Tran",
            "Mubarak Shah"
        ],
        "submitted": "2025-09-23 16:49:43",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it deals with Large Language Models and context compression. However, the focus on query understanding, ranking models, and user behavior modeling is not directly addressed. The paper's emphasis on efficiency and scalability in processing long contexts may be of interest, but it does not align with your primary research themes."
    },
    {
        "title": "Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction",
        "abstract": "Attention-based models have become the leading approach in modeling medical\nlanguage for Natural Language Processing (NLP) in clinical notes. These models\noutperform traditional techniques by effectively capturing contextual rep-\nresentations of language. In this research a comparative analysis is done\namongst pre- trained attention based models namely Bert Base, BioBert, two\nvariations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task\nrelated to Electronic Health Record (EHR) information extraction. The tasks\nfrom Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges\n(n2c2) are considered for this comparison, with the Contextualized Medication\nEvent Dataset (CMED) given for these task. CMED is a dataset of unstructured\nEHRs and annotated notes that contain task relevant information about the EHRs.\nThe goal of the challenge is to develop effective solutions for extracting\ncontextual information related to patient medication events from EHRs using\ndata driven methods. Each pre-trained model is fine-tuned and applied on CMED\nto perform medication extraction, medical event detection, and\nmulti-dimensional medication event context classification. Pro- cessing methods\nare also detailed for breaking down EHRs for compatibility with the applied\nmodels. Performance analysis has been carried out using a script based on\nconstructing medical terms from the evaluation portion of CMED with metrics\nincluding recall, precision, and F1-Score. The results demonstrate that models\npre-trained on clinical data are more effective in detecting medication and\nmedication events, but Bert Base, pre- trained on general domain data showed to\nbe the most effective for classifying the context of events related to\nmedications.",
        "url": "http://arxiv.org/abs/2509.19224v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19224v1",
        "arxiv_id": "2509.19224v1",
        "authors": [
            "Tariq Abdul-Quddoos",
            "Xishuang Dong",
            "Lijun Qian"
        ],
        "submitted": "2025-09-23 16:48:28",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to your research interests in Natural Language Processing (NLP) and data mining, but it focuses on a specific application in the medical domain, which is not a central match for your interests in Information Retrieval and Search technologies. Although it involves deep semantic understanding, the context is not directly related to your primary focus on real-time relevance optimization and query understanding."
    },
    {
        "title": "Steering Multimodal Large Language Models Decoding for Context-Aware Safety",
        "abstract": "Multimodal Large Language Models (MLLMs) are increasingly deployed in\nreal-world applications, yet their ability to make context-aware safety\ndecisions remains limited. Existing methods often fail to balance\noversensitivity (unjustified refusals of benign queries) and undersensitivity\n(missed detection of visually grounded risks), leaving a persistent gap in\nsafety alignment. To address this issue, we introduce Safety-aware Contrastive\nDecoding (SafeCoDe), a lightweight and model-agnostic decoding framework that\ndynamically adjusts token generation based on multimodal context. SafeCoDe\noperates in two stages: (1) a contrastive decoding mechanism that highlights\ntokens sensitive to visual context by contrasting real and Gaussian-noised\nimages, and (2) a global-aware token modulation strategy that integrates\nscene-level reasoning with token-level adjustment to adapt refusals according\nto the predicted safety verdict. Extensive experiments across diverse MLLM\narchitectures and safety benchmarks, covering undersensitivity,\noversensitivity, and general safety evaluations, show that SafeCoDe\nconsistently improves context-sensitive refusal behaviors while preserving\nmodel helpfulness.",
        "url": "http://arxiv.org/abs/2509.19212v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19212v1",
        "arxiv_id": "2509.19212v1",
        "authors": [
            "Zheyuan Liu",
            "Zhangchen Xu",
            "Guangyao Dou",
            "Xiangchi Yuan",
            "Zhaoxuan Tan",
            "Radha Poovendran",
            "Meng Jiang"
        ],
        "submitted": "2025-09-23 16:32:25",
        "source": "arxiv",
        "comment": "A lightweight and model-agnostic decoding framework that dynamically\n  adjusts token generation based on multimodal context",
        "score": 3,
        "keyword_reasons": [
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses multimodal large language models and their safety alignment, which is somewhat related to information retrieval and search technologies. However, the focus on safety and multimodal context is not directly aligned with the user's primary research interests in query understanding, ranking models, and user behavior modeling. The connection to natural language processing is more relevant, but still not a central match."
    },
    {
        "title": "Measuring AI \"Slop\" in Text",
        "abstract": "AI \"slop\" is an increasingly popular term used to describe low-quality\nAI-generated text, but there is currently no agreed upon definition of this\nterm nor a means to measure its occurrence. In this work, we develop a taxonomy\nof \"slop\" through interviews with experts in NLP, writing, and philosophy, and\npropose a set of interpretable dimensions for its assessment in text. Through\nspan-level annotation, we find that binary \"slop\" judgments are (somewhat)\nsubjective, but such determinations nonetheless correlate with latent\ndimensions such as coherence and relevance. Our framework can be used to\nevaluate AI-generated text in both detection and binary preference tasks,\npotentially offering new insights into the linguistic and stylistic factors\nthat contribute to quality judgments.",
        "url": "http://arxiv.org/abs/2509.19163v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19163v1",
        "arxiv_id": "2509.19163v1",
        "authors": [
            "Chantal Shaib",
            "Tuhin Chakrabarty",
            "Diego Garcia-Olano",
            "Byron C. Wallace"
        ],
        "submitted": "2025-09-23 15:41:19",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the concept of 'slop' in AI-generated text, which is related to NLP, but its focus on text quality and coherence doesn't directly align with your primary interests in IR, query understanding, and ranking models. However, it may offer some insights into linguistic and stylistic factors that could be relevant to your work in IR, particularly in areas requiring deep semantic understanding."
    },
    {
        "title": "Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering",
        "abstract": "The rapid growth of scientific literature demands efficient methods to\norganize and synthesize research findings. Existing taxonomy construction\nmethods, leveraging unsupervised clustering or direct prompting of large\nlanguage models (LLMs), often lack coherence and granularity. We propose a\nnovel context-aware hierarchical taxonomy generation framework that integrates\nLLM-guided multi-aspect encoding with dynamic clustering. Our method leverages\nLLMs to identify key aspects of each paper (e.g., methodology, dataset,\nevaluation) and generates aspect-specific paper summaries, which are then\nencoded and clustered along each aspect to form a coherent hierarchy. In\naddition, we introduce a new evaluation benchmark of 156 expert-crafted\ntaxonomies encompassing 11.6k papers, providing the first naturally annotated\ndataset for this task. Experimental results demonstrate that our method\nsignificantly outperforms prior approaches, achieving state-of-the-art\nperformance in taxonomy coherence, granularity, and interpretability.",
        "url": "http://arxiv.org/abs/2509.19125v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19125v1",
        "arxiv_id": "2509.19125v1",
        "authors": [
            "Kun Zhu",
            "Lizi Liao",
            "Yuxuan Gu",
            "Lei Huang",
            "Xiaocheng Feng",
            "Bing Qin"
        ],
        "submitted": "2025-09-23 15:12:58",
        "source": "arxiv",
        "comment": "Accepted to EMNLP 2025 Main",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it involves taxonomy generation and clustering. However, the focus on scientific papers and the use of large language models (LLMs) for multi-aspect encoding is not directly aligned with your primary interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction",
        "abstract": "Recent advances in multimodal large language models (MLLMs) have\nsignificantly enhanced video understanding capabilities, opening new\npossibilities for practical applications. Yet current video benchmarks focus\nlargely on indoor scenes or short-range outdoor activities, leaving the\nchallenges associated with long-distance travel largely unexplored. Mastering\nextended geospatial-temporal trajectories is critical for next-generation\nMLLMs, underpinning real-world tasks such as embodied-AI planning and\nnavigation. To bridge this gap, we present VIR-Bench, a novel benchmark\nconsisting of 200 travel videos that frames itinerary reconstruction as a\nchallenging task designed to evaluate and push forward MLLMs'\ngeospatial-temporal intelligence. Experimental results reveal that\nstate-of-the-art MLLMs, including proprietary ones, struggle to achieve high\nscores, underscoring the difficulty of handling videos that span extended\nspatial and temporal scales. Moreover, we conduct an in-depth case study in\nwhich we develop a prototype travel-planning agent that leverages the insights\ngained from VIR-Bench. The agent's markedly improved itinerary recommendations\nverify that our evaluation protocol not only benchmarks models effectively but\nalso translates into concrete performance gains in user-facing applications.",
        "url": "http://arxiv.org/abs/2509.19002v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19002v1",
        "arxiv_id": "2509.19002v1",
        "authors": [
            "Hao Wang",
            "Eiki Murata",
            "Lingfang Zhang",
            "Ayako Sato",
            "So Fukuda",
            "Ziqi Yin",
            "Wentao Hu",
            "Keisuke Nakao",
            "Yusuke Nakamura",
            "Sebastian Zwirner",
            "Yi-Chia Chen",
            "Hiroyuki Otomo",
            "Hiroki Ouchi",
            "Daisuke Kawahara"
        ],
        "submitted": "2025-09-23 13:46:31",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on evaluating the geospatial and temporal understanding of multimodal large language models (MLLMs) using travel video itinerary reconstruction. While it involves video understanding and real-world applications, it does not directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "Agentic AutoSurvey: Let LLMs Survey LLMs",
        "abstract": "The exponential growth of scientific literature poses unprecedented\nchallenges for researchers attempting to synthesize knowledge across rapidly\nevolving fields. We present \\textbf{Agentic AutoSurvey}, a multi-agent\nframework for automated survey generation that addresses fundamental\nlimitations in existing approaches. Our system employs four specialized agents\n(Paper Search Specialist, Topic Mining \\& Clustering, Academic Survey Writer,\nand Quality Evaluator) working in concert to generate comprehensive literature\nsurveys with superior synthesis quality. Through experiments on six\nrepresentative LLM research topics from COLM 2024 categories, we demonstrate\nthat our multi-agent approach achieves significant improvements over existing\nbaselines, scoring 8.18/10 compared to AutoSurvey's 4.77/10. The multi-agent\narchitecture processes 75--443 papers per topic (847 total across six topics)\nwhile targeting high citation coverage (often $\\geq$80\\% on 75--100-paper sets;\nlower on very large sets such as RLHF) through specialized agent orchestration.\nOur 12-dimension evaluation captures organization, synthesis integration, and\ncritical analysis beyond basic metrics. These findings demonstrate that\nmulti-agent architectures represent a meaningful advancement for automated\nliterature survey generation in rapidly evolving scientific domains.",
        "url": "http://arxiv.org/abs/2509.18661v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18661v1",
        "arxiv_id": "2509.18661v1",
        "authors": [
            "Yixin Liu",
            "Yonghui Wu",
            "Denghui Zhang",
            "Lichao Sun"
        ],
        "submitted": "2025-09-23 05:28:43",
        "source": "arxiv",
        "comment": "29 pages, 7 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a novel framework for automated literature survey generation, which is somewhat related to information retrieval and NLP. However, the focus is on survey generation rather than query understanding, ranking models, or user behavior modeling, making it less central to the user's core research themes."
    },
    {
        "title": "Individualized non-uniform quantization for vector search",
        "abstract": "Embedding vectors are widely used for representing unstructured data and\nsearching through it for semantically similar items. However, the large size of\nthese vectors, due to their high-dimensionality, creates problems for modern\nvector search techniques: retrieving large vectors from memory/storage is\nexpensive and their footprint is costly. In this work, we present NVQ\n(non-uniform vector quantization), a new vector compression technique that is\ncomputationally and spatially efficient in the high-fidelity regime. The core\nin NVQ is to use novel parsimonious and computationally efficient\nnonlinearities for building non-uniform vector quantizers. Critically, these\nquantizers are \\emph{individually} learned for each indexed vector. Our\nexperimental results show that NVQ exhibits improved accuracy compared to the\nstate of the art with a minimal computational cost.",
        "url": "http://arxiv.org/abs/2509.18471v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18471v1",
        "arxiv_id": "2509.18471v1",
        "authors": [
            "Mariano Tepper",
            "Ted Willke"
        ],
        "submitted": "2025-09-22 23:20:07",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, specifically in the area of vector search techniques. However, it focuses on vector compression and quantization, which, while relevant to search, is not a central match to your interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Evaluating the Creativity of LLMs in Persian Literary Text Generation",
        "abstract": "Large language models (LLMs) have demonstrated notable creative abilities in\ngenerating literary texts, including poetry and short stories. However, prior\nresearch has primarily centered on English, with limited exploration of\nnon-English literary traditions and without standardized methods for assessing\ncreativity. In this paper, we evaluate the capacity of LLMs to generate Persian\nliterary text enriched with culturally relevant expressions. We build a dataset\nof user-generated Persian literary spanning 20 diverse topics and assess model\noutputs along four creativity dimensions-originality, fluency, flexibility, and\nelaboration-by adapting the Torrance Tests of Creative Thinking. To reduce\nevaluation costs, we adopt an LLM as a judge for automated scoring and validate\nits reliability against human judgments using intraclass correlation\ncoefficients, observing strong agreement. In addition, we analyze the models'\nability to understand and employ four core literary devices: simile, metaphor,\nhyperbole, and antithesis. Our results highlight both the strengths and\nlimitations of LLMs in Persian literary text generation, underscoring the need\nfor further refinement.",
        "url": "http://arxiv.org/abs/2509.18401v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18401v1",
        "arxiv_id": "2509.18401v1",
        "authors": [
            "Armin Tourajmehr",
            "Mohammad Reza Modarres",
            "Yadollah Yaghoobzadeh"
        ],
        "submitted": "2025-09-22 20:32:56",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'search' (score: +1)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the creativity of Large Language Models (LLMs) in generating Persian literary text, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific application and scope are quite different from your areas of focus."
    },
    {
        "title": "NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery",
        "abstract": "Social norms govern culturally appropriate behavior in communication,\nenabling dialogue systems to produce responses that are not only coherent but\nalso socially acceptable. We present NormGenesis, a multicultural framework for\ngenerating and annotating socially grounded dialogues across English, Chinese,\nand Korean. To model the dynamics of social interaction beyond static norm\nclassification, we propose a novel dialogue type, Violation-to-Resolution\n(V2R), which models the progression of conversations following norm violations\nthrough recognition and socially appropriate repair. To improve pragmatic\nconsistency in underrepresented languages, we implement an exemplar-based\niterative refinement early in the dialogue synthesis process. This design\nintroduces alignment with linguistic, emotional, and sociocultural expectations\nbefore full dialogue generation begins. Using this framework, we construct a\ndataset of 10,800 multi-turn dialogues annotated at the turn level for norm\nadherence, speaker intent, and emotional response. Human and LLM-based\nevaluations demonstrate that NormGenesis significantly outperforms existing\ndatasets in refinement quality, dialogue naturalness, and generalization\nperformance. We show that models trained on our V2R-augmented data exhibit\nimproved pragmatic competence in ethically sensitive contexts. Our work\nestablishes a new benchmark for culturally adaptive dialogue modeling and\nprovides a scalable methodology for norm-aware generation across linguistically\nand culturally diverse languages.",
        "url": "http://arxiv.org/abs/2509.18395v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18395v1",
        "arxiv_id": "2509.18395v1",
        "authors": [
            "Minki Hong",
            "Jangho Choi",
            "Jihie Kim"
        ],
        "submitted": "2025-09-22 20:29:25",
        "source": "arxiv",
        "comment": "39 pages, 17 figures, EMNLP 2025 Main Conference",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'korea' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on dialogue generation and social norm modeling, which is outside the primary scope of your research interests in Information Retrieval and Search technologies. While it touches on aspects of language understanding, the context is more aligned with Natural Language Processing and dialogue systems rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World",
        "abstract": "Large language models (LLMs) often reflect Western-centric biases, limiting\ntheir effectiveness in diverse cultural contexts. Although some work has\nexplored cultural alignment, the potential for cross-cultural transfer, using\nalignment in one culture to improve performance in others, remains\nunderexplored. This paper investigates cross-cultural transfer of commonsense\nreasoning in the Arab world, where linguistic and historical similarities\ncoexist with local cultural differences. Using a culturally grounded\ncommonsense reasoning dataset covering 13 Arab countries, we evaluate\nlightweight alignment methods such as in-context learning and\ndemonstration-based reinforcement (DITTO), alongside baselines like supervised\nfine-tuning and direct preference optimization. Our results show that merely 12\nculture-specific examples from one country can improve performance in others by\n10\\% on average, within multilingual models. In addition, we demonstrate that\nout-of-culture demonstrations from Indonesia and US contexts can match or\nsurpass in-culture alignment for MCQ reasoning, highlighting cultural\ncommonsense transferability beyond the Arab world. These findings demonstrate\nthat efficient cross-cultural alignment is possible and offer a promising\napproach to adapt LLMs to low-resource cultural settings.",
        "url": "http://arxiv.org/abs/2509.19265v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19265v1",
        "arxiv_id": "2509.19265v1",
        "authors": [
            "Saeed Almheiri",
            "Rania Hossam",
            "Mena Attia",
            "Chenxi Wang",
            "Preslav Nakov",
            "Timothy Baldwin",
            "Fajri Koto"
        ],
        "submitted": "2025-09-23 17:24:14",
        "source": "arxiv",
        "comment": "EMNLP 2025 - Findings",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on cross-cultural transfer of commonsense reasoning in LLMs, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves LLMs and NLP, the context and application are quite different from your areas of focus."
    },
    {
        "title": "Reinforcement Learning on Pre-Training Data",
        "abstract": "The growing disparity between the exponential scaling of computational\nresources and the finite growth of high-quality text data now constrains\nconventional scaling approaches for large language models (LLMs). To address\nthis challenge, we introduce Reinforcement Learning on Pre-Training data\n(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast\nto prior approaches that scale training primarily through supervised learning,\nRLPT enables the policy to autonomously explore meaningful trajectories to\nlearn from pre-training data and improve its capability through reinforcement\nlearning (RL). While existing RL strategies such as reinforcement learning from\nhuman feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)\nrely on human annotation for reward construction, RLPT eliminates this\ndependency by deriving reward signals directly from pre-training data.\nSpecifically, it adopts a next-segment reasoning objective, rewarding the\npolicy for accurately predicting subsequent text segments conditioned on the\npreceding context. This formulation allows RL to be scaled on pre-training\ndata, encouraging the exploration of richer trajectories across broader\ncontexts and thereby fostering more generalizable reasoning skills. Extensive\nexperiments on both general-domain and mathematical reasoning benchmarks across\nmultiple models validate the effectiveness of RLPT. For example, when applied\nto Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,\n$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and\nAIME25, respectively. The results further demonstrate favorable scaling\nbehavior, suggesting strong potential for continued gains with more compute. In\naddition, RLPT provides a solid foundation, extending the reasoning boundaries\nof LLMs and enhancing RLVR performance.",
        "url": "http://arxiv.org/abs/2509.19249v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19249v1",
        "arxiv_id": "2509.19249v1",
        "authors": [
            "Siheng Li",
            "Kejiao Li",
            "Zenan Xu",
            "Guanhua Huang",
            "Evander Yang",
            "Kun Li",
            "Haoyuan Wu",
            "Jiajia Wu",
            "Zihao Zheng",
            "Chenchen Zhang",
            "Kun Shi",
            "Kyrierl Deng",
            "Qi Yi",
            "Ruibin Xiong",
            "Tingqiang Xu",
            "Yuhao Jiang",
            "Jianfeng Yan",
            "Yuyuan Zeng",
            "Guanghui Xu",
            "Jinbao Xue",
            "Zhijiang Xu",
            "Zheng Fang",
            "Shuai Li",
            "Qibin Liu",
            "Xiaoxue Li",
            "Zhuoyu Li",
            "Yangyu Tao",
            "Fei Gao",
            "Cheng Jiang",
            "Bo Chao Wang",
            "Kai Liu",
            "Jianchen Zhu",
            "Wai Lam",
            "Wayyt Wang",
            "Bo Zhou",
            "Di Wang"
        ],
        "submitted": "2025-09-23 17:10:40",
        "source": "arxiv",
        "comment": "Work in progress",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a novel training paradigm for large language models, which is related to my interests in Natural Language Processing (NLP) and related topics. However, the focus on reinforcement learning and pre-training data does not directly align with my primary research themes in Information Retrieval (IR), query understanding, and ranking models."
    },
    {
        "title": "Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions",
        "abstract": "Tool-augmented large language models (LLMs) are usually trained with\nsupervised imitation or coarse-grained reinforcement learning that optimizes\nsingle tool calls. Current self-reflection practices rely on heuristic prompts\nor one-way reasoning: the model is urged to 'think more' instead of learning\nerror diagnosis and repair. This is fragile in multi-turn interactions; after a\nfailure the model often repeats the same mistake. We propose structured\nreflection, which turns the path from error to repair into an explicit,\ncontrollable, and trainable action. The agent produces a short yet precise\nreflection: it diagnoses the failure using evidence from the previous step and\nthen proposes a correct, executable follow-up call. For training we combine\nDAPO and GSPO objectives with a reward scheme tailored to tool use, optimizing\nthe stepwise strategy Reflect, then Call, then Final. To evaluate, we introduce\nTool-Reflection-Bench, a lightweight benchmark that programmatically checks\nstructural validity, executability, parameter correctness, and result\nconsistency. Tasks are built as mini trajectories of erroneous call,\nreflection, and corrected call, with disjoint train and test splits.\nExperiments on BFCL v3 and Tool-Reflection-Bench show large gains in multi-turn\ntool-call success and error recovery, and a reduction of redundant calls. These\nresults indicate that making reflection explicit and optimizing it directly\nimproves the reliability of tool interaction and offers a reproducible path for\nagents to learn from failure.",
        "url": "http://arxiv.org/abs/2509.18847v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18847v1",
        "arxiv_id": "2509.18847v1",
        "authors": [
            "Junhao Su",
            "Yuanliang Wan",
            "Junwei Yang",
            "Hengyu Shi",
            "Tianyang Han",
            "Junfeng Luo",
            "Yurui Qiu"
        ],
        "submitted": "2025-09-23 09:35:49",
        "source": "arxiv",
        "comment": "9pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on enhancing the reliability of tool interactions for large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it involves a form of model improvement, the context and objectives are quite different from the user's core research themes."
    },
    {
        "title": "Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?",
        "abstract": "Open-weight versions of large language models (LLMs) are rapidly advancing,\nwith state-of-the-art models like DeepSeek-V3 now performing comparably to\nproprietary LLMs. This progression raises the question of whether small\nopen-weight LLMs are capable of effectively replacing larger closed-source\nmodels. We are particularly interested in the context of biomedical\nquestion-answering, a domain we explored by participating in Task 13B Phase B\nof the BioASQ challenge. In this work, we compare several open-weight models\nagainst top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and\nClaude 3.7 Sonnet. To enhance question answering capabilities, we use various\ntechniques including retrieving the most relevant snippets based on embedding\ndistance, in-context learning, and structured outputs. For certain submissions,\nwe utilize ensemble approaches to leverage the diverse outputs generated by\ndifferent models for exact-answer questions. Our results demonstrate that\nopen-weight LLMs are comparable to proprietary ones. In some instances,\nopen-weight LLMs even surpassed their closed counterparts, particularly when\nensembling strategies were applied. All code is publicly available at\nhttps://github.com/evidenceprime/BioASQ-13b.",
        "url": "http://arxiv.org/abs/2509.18843v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18843v1",
        "arxiv_id": "2509.18843v1",
        "authors": [
            "Damian Stachura",
            "Joanna Konieczna",
            "Artur Nowak"
        ],
        "submitted": "2025-09-23 09:27:57",
        "source": "arxiv",
        "comment": "CLEF 2025 Working Notes, 9-12 September 2025, Madrid, Spain",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the comparison of open-weight and proprietary language models for biomedical question answering, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language models, the context and application are specific to the biomedical domain and question answering, which does not align with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction",
        "abstract": "Keyphrase extraction is a fundamental task in natural language processing.\nHowever, existing unsupervised prompt-based methods for Large Language Models\n(LLMs) often rely on single-stage inference pipelines with uniform prompting,\nregardless of document length or LLM backbone. Such one-size-fits-all designs\nhinder the full exploitation of LLMs' reasoning and generation capabilities,\nespecially given the complexity of keyphrase extraction across diverse\nscenarios. To address these challenges, we propose MAPEX, the first framework\nthat introduces multi-agent collaboration into keyphrase extraction. MAPEX\ncoordinates LLM-based agents through modules for expert recruitment, candidate\nextraction, topic guidance, knowledge augmentation, and post-processing. A\ndual-path strategy dynamically adapts to document length: knowledge-driven\nextraction for short texts and topic-guided extraction for long texts.\nExtensive experiments on six benchmark datasets across three different LLMs\ndemonstrate its strong generalization and universality, outperforming the\nstate-of-the-art unsupervised method by 2.44% and standard LLM baselines by\n4.01% in F1@5 on average. Code is available at\nhttps://github.com/NKU-LITI/MAPEX.",
        "url": "http://arxiv.org/abs/2509.18813v2",
        "pdf_url": "http://arxiv.org/pdf/2509.18813v2",
        "arxiv_id": "2509.18813v2",
        "authors": [
            "Liting Zhang",
            "Shiwan Zhao",
            "Aobo Kong",
            "Qicheng Li"
        ],
        "submitted": "2025-09-23 09:00:43",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper MAPEX focuses on keyphrase extraction, a task related to Natural Language Processing (NLP), which is within your research interests. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of focus for you. While it involves deep semantic understanding, the context is not specifically related to information retrieval or search technologies."
    },
    {
        "title": "Financial Risk Relation Identification through Dual-view Adaptation",
        "abstract": "A multitude of interconnected risk events -- ranging from regulatory changes\nto geopolitical tensions -- can trigger ripple effects across firms.\nIdentifying inter-firm risk relations is thus crucial for applications like\nportfolio management and investment strategy. Traditionally, such assessments\nrely on expert judgment and manual analysis, which are, however, subjective,\nlabor-intensive, and difficult to scale. To address this, we propose a\nsystematic method for extracting inter-firm risk relations using Form 10-K\nfilings -- authoritative, standardized financial documents -- as our data\nsource. Leveraging recent advances in natural language processing, our approach\ncaptures implicit and abstract risk connections through unsupervised\nfine-tuning based on chronological and lexical patterns in the filings. This\nenables the development of a domain-specific financial encoder with a deeper\ncontextual understanding and introduces a quantitative risk relation score for\ntransparency, interpretable analysis. Extensive experiments demonstrate that\nour method outperforms strong baselines across multiple evaluation settings.",
        "url": "http://arxiv.org/abs/2509.18775v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18775v1",
        "arxiv_id": "2509.18775v1",
        "authors": [
            "Wei-Ning Chiu",
            "Yu-Hsiang Wang",
            "Andy Hsiao",
            "Yu-Shiang Huang",
            "Chuan-Ju Wang"
        ],
        "submitted": "2025-09-23 08:09:30",
        "source": "arxiv",
        "comment": "11 pages, 3 figures, EMNLP 2025 Main Conference",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on financial risk relation identification using natural language processing, which is somewhat related to the user's interests in NLP. However, the topic is not directly related to information retrieval, search technologies, or query understanding, which are the user's core research themes."
    },
    {
        "title": "MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service",
        "abstract": "Large Language Model-based agents(LLM-based agents) are increasingly deployed\nin customer service, yet they often forget across sessions, repeat errors, and\nlack mechanisms for continual self-improvement. This makes them unreliable in\ndynamic settings where stability and consistency are critical. To better\nevaluate these properties, we emphasize two indicators: task success rate as a\nmeasure of overall effectiveness, and consistency metrics such as Pass$^k$ to\ncapture reliability across multiple trials. To address the limitations of\nexisting approaches, we propose MemOrb, a lightweight and plug-and-play verbal\nreinforcement memory layer that distills multi-turn interactions into compact\nstrategy reflections. These reflections are stored in a shared memory bank and\nretrieved to guide decision-making, without requiring any fine-tuning.\nExperiments show that MemOrb significantly improves both success rate and\nstability, achieving up to a 63 percentage-point gain in multi-turn success\nrate and delivering more consistent performance across repeated trials. Our\nresults demonstrate that structured reflection is a powerful mechanism for\nenhancing long-term reliability of frozen LLM agents in customer service\nscenarios.",
        "url": "http://arxiv.org/abs/2509.18713v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18713v1",
        "arxiv_id": "2509.18713v1",
        "authors": [
            "Yizhe Huang",
            "Yang Liu",
            "Ruiyu Zhao",
            "Xiaolong Zhong",
            "Xingming Yue",
            "Ling Jiang"
        ],
        "submitted": "2025-09-23 06:57:07",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving the reliability of Large Language Model-based agents in customer service, which is a specific application in the e-commerce domain. While it involves natural language processing, it does not directly relate to information retrieval, query understanding, or ranking models, which are core areas of your research interests."
    },
    {
        "title": "Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction",
        "abstract": "LLM-as-a-judge has become a promising paradigm for using large language\nmodels (LLMs) to evaluate natural language generation (NLG), but the\nuncertainty of its evaluation remains underexplored. This lack of reliability\nmay limit its deployment in many applications. This work presents the first\nframework to analyze the uncertainty by offering a prediction interval of\nLLM-based scoring via conformal prediction. Conformal prediction constructs\ncontinuous prediction intervals from a single evaluation run, and we design an\nordinal boundary adjustment for discrete rating tasks. We also suggest a\nmidpoint-based score within the interval as a low-bias alternative to raw model\nscore and weighted average. We perform extensive experiments and analysis,\nwhich show that conformal prediction can provide valid prediction interval with\ncoverage guarantees. We also explore the usefulness of interval midpoint and\njudge reprompting for better judgment.",
        "url": "http://arxiv.org/abs/2509.18658v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18658v1",
        "arxiv_id": "2509.18658v1",
        "authors": [
            "Huanxin Sheng",
            "Xinyi Liu",
            "Hangfeng He",
            "Jieyu Zhao",
            "Jian Kang"
        ],
        "submitted": "2025-09-23 05:26:28",
        "source": "arxiv",
        "comment": "To appear in EMNLP 2025. Our code and data are available at\n  \\url{https://github.com/BruceSheng1202/Analyzing_Uncertainty_of_LLM-as-a-Judge",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the uncertainty of LLM-based evaluation, which is related to query understanding and ranking models in Information Retrieval. However, the focus on natural language generation and evaluation rather than search technologies limits its relevance to your core research themes."
    },
    {
        "title": "Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering",
        "abstract": "Parameter-Preserving Knowledge Editing (PPKE) enables updating models with\nnew or corrected information without retraining or parameter adjustment. Recent\nPPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)\ncapabilities to multi-hop question answering (MHQA). However, these methods\noften lack consistency, leading to knowledge contamination, unstable updates,\nand retrieval behaviors that fail to reflect the intended edits. Such\ninconsistencies undermine the reliability of PPKE in multi- hop reasoning. We\npresent CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge\nGraphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures\nKG construction, update, and retrieval are always aligned with the requirements\nof the MHQA task, maintaining coherent reasoning over both unedited and edited\nknowledge. Extensive experiments on the MQuAKE benchmark show accuracy\nimprovements in PPKE performance for MHQA, demonstrating the effectiveness of\naddressing consistency in PPKE.",
        "url": "http://arxiv.org/abs/2509.18655v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18655v1",
        "arxiv_id": "2509.18655v1",
        "authors": [
            "Lingwen Deng",
            "Yifei Han",
            "Long Zhang",
            "Yue Du",
            "Bin Li"
        ],
        "submitted": "2025-09-23 05:17:39",
        "source": "arxiv",
        "comment": "Submitted to ICASSP 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on a knowledge editing framework for multi-hop question answering, which is related to information retrieval and NLP. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The connection to IR is indirect, as it involves knowledge retrieval and question answering."
    },
    {
        "title": "Scalable Evaluation for Audio Identification via Synthetic Latent Fingerprint Generation",
        "abstract": "The evaluation of audio fingerprinting at a realistic scale is limited by the\nscarcity of large public music databases. We present an audio-free approach\nthat synthesises latent fingerprints which approximate the distribution of real\nfingerprints. Our method trains a Rectified Flow model on embeddings extracted\nby pre-trained neural audio fingerprinting systems. The synthetic fingerprints\ngenerated using our system act as realistic distractors and enable the\nsimulation of retrieval performance at a large scale without requiring\nadditional audio. We assess the fidelity of synthetic fingerprints by comparing\nthe distributions to real data. We further benchmark the retrieval performances\nacross multiple state-of-the-art audio fingerprinting frameworks by augmenting\nreal reference databases with synthetic distractors, and show that the scaling\ntrends obtained with synthetic distractors closely track those obtained with\nreal distractors. Finally, we scale the synthetic distractor database to model\nretrieval performance for very large databases, providing a practical metric of\nsystem scalability that does not depend on access to audio corpora.",
        "url": "http://arxiv.org/abs/2509.18620v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18620v1",
        "arxiv_id": "2509.18620v1",
        "authors": [
            "Aditya Bhattacharjee",
            "Marco Pasini",
            "Emmanouil Benetos"
        ],
        "submitted": "2025-09-23 04:11:15",
        "source": "arxiv",
        "comment": "Under review for International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP), Barcelona, 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your core research themes in Information Retrieval, Search technologies, or Natural Language Processing. The focus on audio fingerprinting and scalability in the audio domain does not align with your interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation",
        "abstract": "Radiology report generation (RRG) aims to automatically produce clinically\nfaithful reports from chest X-ray images. Prevailing work typically follows a\nscale-driven paradigm, by multi-stage training over large paired corpora and\noversized backbones, making pipelines highly data- and compute-intensive. In\nthis paper, we propose Oracle-educated GRPO {OraPO) with a FactScore-based\nreward (FactS) to tackle the RRG task under constrained budgets. OraPO enables\nsingle-stage, RL-only training by converting failed GRPO explorations on rare\nor difficult studies into direct preference supervision via a lightweight\noracle step. FactS grounds learning in diagnostic evidence by extracting atomic\nclinical facts and checking entailment against ground-truth labels, yielding\ndense, interpretable sentence-level rewards. Together, OraPO and FactS create a\ncompact and powerful framework that significantly improves learning efficiency\non clinically challenging cases, setting the new SOTA performance on the\nCheXpert Plus dataset (0.341 in F1) with 2--3 orders of magnitude less training\ndata using a small base VLM on modest hardware.",
        "url": "http://arxiv.org/abs/2509.18600v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18600v1",
        "arxiv_id": "2509.18600v1",
        "authors": [
            "Zhuoxiao Chen",
            "Hongyang Yu",
            "Ying Xu",
            "Yadan Luo",
            "Long Duong",
            "Yuan-Fang Li"
        ],
        "submitted": "2025-09-23 03:42:26",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on radiology report generation, which is not a core area of information retrieval. While it involves some NLP aspects, the primary goal is not query understanding or ranking models, making it less relevant to your research interests."
    },
    {
        "title": "UniECG: Understanding and Generating ECG in One Unified Model",
        "abstract": "Recent unified models such as GPT-5 have achieved encouraging progress on\nvision-language tasks. However, these unified models typically fail to\ncorrectly understand ECG signals and provide accurate medical diagnoses, nor\ncan they correctly generate ECG signals. To address these limitations, we\npropose UniECG, the first unified model for ECG capable of concurrently\nperforming evidence-based ECG interpretation and text-conditioned ECG\ngeneration tasks. Through a decoupled two-stage training approach, the model\nfirst learns evidence-based interpretation skills (ECG-to-Text), and then\ninjects ECG generation capabilities (Text-to-ECG) via latent space alignment.\nUniECG can autonomously choose to interpret or generate an ECG based on user\ninput, significantly extending the capability boundaries of current ECG models.\nOur code and checkpoints will be made publicly available at\nhttps://github.com/PKUDigitalHealth/UniECG upon acceptance.",
        "url": "http://arxiv.org/abs/2509.18588v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18588v1",
        "arxiv_id": "2509.18588v1",
        "authors": [
            "Jiarui Jin",
            "Haoyu Wang",
            "Xiang Lan",
            "Jun Li",
            "Gaofeng Cheng",
            "Hongyan Li",
            "Shenda Hong"
        ],
        "submitted": "2025-09-23 03:15:53",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on a unified model for ECG interpretation and generation, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "Teaching Audio Models to Reason: A Unified Framework for Source- and Layer-wise Distillation",
        "abstract": "While large audio language models excel at tasks like ASR and emotion\nrecognition, they still struggle with complex reasoning due to the modality gap\nbetween audio and text as well as the lack of structured intermediate\nsupervision. To address this, we propose a unified knowledge distillation\nframework to transfer reasoning capabilities from a high-capacity textual\nteacher model to a student audio models while preserving its acoustic\ncompetence. Our method introduces two key dimensions: source-wise distillation,\nwhich leverages both textual and acoustic teachers to provide complementary\nmodality-specific supervision; and layer-wise distillation, which aligns\nteacher signals with appropriate student layers to improve transfer efficiency.\nThis dual-dimensional strategy enables fine-grained control over the\ndistillation process, effectively bridging the gap between symbolic reasoning\nand speech representations. Experimental results show significant improvements\nin audio reasoning performance, demonstrating the effectiveness of our\nframework as a reasoning transfer solution for audio modeling.",
        "url": "http://arxiv.org/abs/2509.18579v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18579v1",
        "arxiv_id": "2509.18579v1",
        "authors": [
            "Runyan Yang",
            "Yuke Si",
            "Yingying Gao",
            "Junlan Feng",
            "Chao Deng",
            "Shilei Zhang"
        ],
        "submitted": "2025-09-23 02:58:16",
        "source": "arxiv",
        "comment": "5 pages; submitted to ICASSP 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on audio language models and knowledge distillation, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some form of model transfer, the context and application are quite different from your areas of focus."
    },
    {
        "title": "Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity",
        "abstract": "As large language models (LLMs) are pretrained on massive web corpora,\ncareful selection of data becomes essential to ensure effective and efficient\nlearning. While perplexity (PPL)-based filtering has shown strong performance,\nit suffers from drawbacks: substantial time costs and inherent unreliability of\nthe model when handling noisy or out-of-distribution samples. In this work, we\npropose a simple yet powerful alternative: a prior-based data filtering method\nthat estimates token priors using corpus-level term frequency statistics,\ninspired by linguistic insights on word roles and lexical density. Our approach\nfilters documents based on the mean and standard deviation of token priors,\nserving as a fast proxy to PPL while requiring no model inference. Despite its\nsimplicity, the prior-based filter achieves the highest average performance\nacross 20 downstream benchmarks, while reducing time cost by over 1000x\ncompared to PPL-based filtering. We further demonstrate its applicability to\nsymbolic languages such as code and math, and its dynamic adaptability to\nmultilingual corpora without supervision",
        "url": "http://arxiv.org/abs/2509.18577v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18577v1",
        "arxiv_id": "2509.18577v1",
        "authors": [
            "Yeongbin Seo",
            "Gayoung Kim",
            "Jaehyung Kim",
            "Jinyoung Yeo"
        ],
        "submitted": "2025-09-23 02:57:29",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on data filtering for large language models, proposing a prior-based method that estimates token priors using corpus-level term frequency statistics. While it touches on the topic of model performance, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's relevance to information retrieval is somewhat tangential, as it primarily deals with data preprocessing."
    },
    {
        "title": "HarmoniFuse: A Component-Selective and Prompt-Adaptive Framework for Multi-Task Speech Language Modeling",
        "abstract": "Recent advances in large language models have facilitated the development of\nunified speech language models (SLMs) capable of supporting multiple speech\ntasks within a shared architecture. However, tasks such as automatic speech\nrecognition (ASR) and speech emotion recognition (SER) rely on distinct types\nof information: ASR primarily depends on linguistic content, whereas SER\nrequires the integration of both linguistic and paralinguistic cues. Existing\nmultitask SLMs typically adopt naive parameter sharing or prompt-based\nconditioning without explicitly modeling the differences in information\ncomposition required by each task. Such designs risk task interference and\nperformance degradation, especially under limited data conditions. To address\nthese limitations, we propose HarmoniFuse, a component-selective and\nprompt-adaptive framework for multi-task speech language modeling. HarmoniFuse\nis designed to harmonize heterogeneous task demands by selecting and fusing\ntask-relevant components of speech representations. Specifically, it integrates\na gated speech encoder to extract task-specific acoustic features and a\nprompt-adaptive dynamic fusion module to aggregate transformer layers based on\ntask characteristics. In addition, a batch-interleaved training strategy\nenables leveraging separate ASR and SER datasets without requiring joint\nannotation. Experimental results demonstrate that HarmoniFuse improves both ASR\nand SER performance, offering a scalable and robust solution for multitask\nspeech understanding under realistic data constraints.",
        "url": "http://arxiv.org/abs/2509.18570v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18570v1",
        "arxiv_id": "2509.18570v1",
        "authors": [
            "Yuke Si",
            "Runyan Yang",
            "Yingying Gao",
            "Junlan Feng",
            "Chao Deng",
            "Shilei Zhang"
        ],
        "submitted": "2025-09-23 02:53:38",
        "source": "arxiv",
        "comment": "5 pages; submitted to ICASSP 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on speech language modeling and multi-task learning, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves deep learning and model adaptation, the context and application are quite different from the user's areas of expertise."
    },
    {
        "title": "LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling",
        "abstract": "Although transformer architectures have achieved state-of-the-art performance\nacross diverse domains, their quadratic computational complexity with respect\nto sequence length remains a significant bottleneck, particularly for\nlatency-sensitive long-context applications. While recent linear-complexity\nalternatives are increasingly powerful, effectively training them from scratch\nis still resource-intensive. To overcome these limitations, we propose LAWCAT\n(Linear Attention with Convolution Across Time), a novel linearization\nframework designed to efficiently transfer the capabilities of pre-trained\ntransformers into a performant linear attention architecture. LAWCAT integrates\ncausal Conv1D layers to enhance local dependency modeling and employs\nnormalized gated linear attention to improve generalization across varying\ncontext lengths. Our comprehensive evaluations demonstrate that, distilling\nMistral-7B with only 1K-length sequences yields over 90\\% passkey retrieval\naccuracy up to 22K tokens, significantly extending its effective context\nwindow. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance\non S-NIAH 1\\&2\\&3 tasks (1K-8K context length) and BABILong benchmark\n(QA2\\&QA3, 0K-16K context length), requiring less than 0.1\\% pre-training\ntokens compared with pre-training models. Furthermore, LAWCAT exhibits faster\nprefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT\nthus provides an efficient pathway to high-performance, long-context linear\nmodels suitable for edge deployment, reducing reliance on extensive\nlong-sequence training data and computational resources.",
        "url": "http://arxiv.org/abs/2509.18467v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18467v1",
        "arxiv_id": "2509.18467v1",
        "authors": [
            "Zeyu Liu",
            "Souvik Kundu",
            "Lianghao Jiang",
            "Anni Li",
            "Srikanth Ronanki",
            "Sravan Bodapati",
            "Gourav Datta",
            "Peter A. Beerel"
        ],
        "submitted": "2025-09-22 22:43:44",
        "source": "arxiv",
        "comment": "17 pages, 8 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving the efficiency of transformer architectures for long-context applications, which is not directly related to your core research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. While it does involve attention mechanisms, the primary goal is to reduce computational complexity, which is not a central theme in your research."
    },
    {
        "title": "Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations",
        "abstract": "Shared decision-making (SDM) is necessary to achieve patient-centred care.\nCurrently no methodology exists to automatically measure SDM at scale. This\nstudy aimed to develop an automated approach to measure SDM by using language\nmodelling and the conversational alignment (CA) score. A total of 157\nvideo-recorded patient-doctor conversations from a randomized multi-centre\ntrial evaluating SDM decision aids for anticoagulation in atrial fibrillations\nwere transcribed and segmented into 42,559 sentences. Context-response pairs\nand negative sampling were employed to train deep learning (DL) models and\nfine-tuned BERT models via the next sentence prediction (NSP) task. Each\ntop-performing model was used to calculate four types of CA scores. A\nrandom-effects analysis by clinician, adjusting for age, sex, race, and trial\narm, assessed the association between CA scores and SDM outcomes: the\nDecisional Conflict Scale (DCS) and the Observing Patient Involvement in\nDecision-Making 12 (OPTION12) scores. p-values were corrected for multiple\ncomparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,\nmean age 70 SD 10.8), clinicians on average spoke more words than patients\n(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1\nof 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1\nwith 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)\nscores generated with the DL without stylebook were associated with OPTION12.\nThe Max CA score generated with the fine-tuned BERTbase (110M) was associated\nwith the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an\nimpact the association between CA scores and SDM. This study introduces an\nautomated, scalable methodology to measure SDM in patient-doctor conversations\nthrough explainable CA scores, with potential to evaluate SDM strategies at\nscale.",
        "url": "http://arxiv.org/abs/2509.18439v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18439v1",
        "arxiv_id": "2509.18439v1",
        "authors": [
            "Oscar J. Ponce-Ponte",
            "David Toro-Tobon",
            "Luis F. Figueroa",
            "Michael Gionfriddo",
            "Megan Branda",
            "Victor M. Montori",
            "Saturnino Luz",
            "Juan P. Brito"
        ],
        "submitted": "2025-09-22 21:50:13",
        "source": "arxiv",
        "comment": "53 pages, 1 figure, 4 tables, 5 supplementary figures, 13\n  supplementary tables",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. The paper focuses on developing an AI framework for detecting shared decision-making in patient-doctor conversations, which is a topic in the healthcare domain and does not align with your core research themes."
    },
    {
        "title": "Memory-QA: Answering Recall Questions Based on Multimodal Memories",
        "abstract": "We introduce Memory-QA, a novel real-world task that involves answering\nrecall questions about visual content from previously stored multimodal\nmemories. This task poses unique challenges, including the creation of\ntask-oriented memories, the effective utilization of temporal and location\ninformation within memories, and the ability to draw upon multiple memories to\nanswer a recall question. To address these challenges, we propose a\ncomprehensive pipeline, Pensieve, integrating memory-specific augmentation,\ntime- and location-aware multi-signal retrieval, and multi-memory QA\nfine-tuning. We created a multimodal benchmark to illustrate various real\nchallenges in this task, and show the superior performance of Pensieve over\nstate-of-the-art solutions (up to 14% on QA accuracy).",
        "url": "http://arxiv.org/abs/2509.18436v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18436v1",
        "arxiv_id": "2509.18436v1",
        "authors": [
            "Hongda Jiang",
            "Xinyuan Zhang",
            "Siddhant Garg",
            "Rishab Arora",
            "Shiun-Zu Kuo",
            "Jiayang Xu",
            "Christopher Brossman",
            "Yue Liu",
            "Aaron Colak",
            "Ahmed Aly",
            "Anuj Kumar",
            "Xin Luna Dong"
        ],
        "submitted": "2025-09-22 21:41:35",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "While the paper touches on multimodal memories and retrieval, it primarily focuses on question answering and multimodal benchmark creation, which is not directly aligned with the user's core research themes in Information Retrieval and Search technologies, particularly query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding",
        "abstract": "The immense model sizes of large language models (LLMs) challenge deployment\non memory-limited consumer GPUs. Although model compression and parameter\noffloading are common strategies to address memory limitations, compression can\ndegrade quality, and offloading maintains quality but suffers from slow\ninference. Speculative decoding presents a promising avenue to accelerate\nparameter offloading, utilizing a fast draft model to propose multiple draft\ntokens, which are then verified by the target LLM in parallel with a single\nforward pass. This method reduces the time-consuming data transfers in forward\npasses that involve offloaded weight transfers. Existing methods often rely on\npretrained weights of the same family, but require additional training to align\nwith custom-trained models. Moreover, approaches that involve draft model\ntraining usually yield only modest speedups. This limitation arises from\ninsufficient alignment with the target model, preventing higher token\nacceptance lengths. To address these challenges and achieve greater speedups,\nwe propose SubSpec, a plug-and-play method to accelerate parameter offloading\nthat is lossless and training-free. SubSpec constructs a highly aligned draft\nmodel by generating low-bit quantized substitute layers from offloaded target\nLLM portions. Additionally, our method shares the remaining GPU-resident layers\nand the KV-Cache, further reducing memory overhead and enhance alignment.\nSubSpec achieves a high average acceptance length, delivering 9.1x speedup for\nQwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for\nQwen2.5 32B on popular generation benchmarks (24GB VRAM limit).",
        "url": "http://arxiv.org/abs/2509.18344v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18344v1",
        "arxiv_id": "2509.18344v1",
        "authors": [
            "Pei-Shuo Wang",
            "Jian-Jia Chen",
            "Chun-Che Yang",
            "Chi-Chih Chang",
            "Ning-Chi Huang",
            "Mohamed S. Abdelfattah",
            "Kai-Chiang Wu"
        ],
        "submitted": "2025-09-22 19:08:57",
        "source": "arxiv",
        "comment": "Accepted by NeurIPS 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on accelerating large language models through speculative decoding, which is outside your areas of expertise in Information Retrieval and Search technologies."
    },
    {
        "title": "Evaluating Large Language Models for Detecting Antisemitism",
        "abstract": "Detecting hateful content is a challenging and important problem. Automated\ntools, like machine-learning models, can help, but they require continuous\ntraining to adapt to the ever-changing landscape of social media. In this work,\nwe evaluate eight open-source LLMs' capability to detect antisemitic content,\nspecifically leveraging in-context definition as a policy guideline. We explore\nvarious prompting techniques and design a new CoT-like prompt, Guided-CoT.\nGuided-CoT handles the in-context policy well, increasing performance across\nall evaluated models, regardless of decoding configuration, model sizes, or\nreasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.\nAdditionally, we examine LLM errors and introduce metrics to quantify semantic\ndivergence in model-generated rationales, revealing notable differences and\nparadoxical behaviors among LLMs. Our experiments highlight the differences\nobserved across LLMs' utility, explainability, and reliability.",
        "url": "http://arxiv.org/abs/2509.18293v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18293v1",
        "arxiv_id": "2509.18293v1",
        "authors": [
            "Jay Patel",
            "Hrudayangam Mehta",
            "Jeremy Blackburn"
        ],
        "submitted": "2025-09-22 18:23:21",
        "source": "arxiv",
        "comment": "Accepted to EMNLP 2025 Main Conference",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on evaluating large language models for detecting antisemitism, which is a topic outside of the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific application and context are not directly related to the user's core themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "WolBanking77: Wolof Banking Speech Intent Classification Dataset",
        "abstract": "Intent classification models have made a lot of progress in recent years.\nHowever, previous studies primarily focus on high-resource languages datasets,\nwhich results in a gap for low-resource languages and for regions with a high\nrate of illiterate people where languages are more spoken than read or written.\nThis is the case in Senegal, for example, where Wolof is spoken by around 90\\%\nof the population, with an illiteracy rate of 42\\% for the country. Wolof is\nactually spoken by more than 10 million people in West African region. To\ntackle such limitations, we release a Wolof Intent Classification Dataset\n(WolBanking77), for academic research in intent classification. WolBanking77\ncurrently contains 9,791 text sentences in the banking domain and more than 4\nhours of spoken sentences. Experiments on various baselines are conducted in\nthis work, including text and voice state-of-the-art models. The results are\nvery promising on this current dataset. This paper also provides detailed\nanalyses of the contents of the data. We report baseline f1-score and word\nerror rate metrics respectively on NLP and ASR models trained on WolBanking77\ndataset and also comparisons between models. We plan to share and conduct\ndataset maintenance, updates and to release open-source code.",
        "url": "http://arxiv.org/abs/2509.19271v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19271v1",
        "arxiv_id": "2509.19271v1",
        "authors": [
            "Abdou Karim Kandji",
            "Frdric Precioso",
            "Cheikh Ba",
            "Samba Ndiaye",
            "Augustin Ndione"
        ],
        "submitted": "2025-09-23 17:34:10",
        "source": "arxiv",
        "comment": "10 pages, 7 figures",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on intent classification in the Wolof language, which is a low-resource language. While it involves NLP and has some relation to information retrieval, it does not directly align with the user's core research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data",
        "abstract": "Automatic Speech Recognition (ASR) for low-resource languages like Slovak is\nhindered by the scarcity of training data. To address this, we introduce\nSloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of\nspeech from parliamentary proceedings. We developed a robust processing\npipeline to align and segment long-form recordings into clean, 30-second\naudio-transcript pairs suitable for model training. We use this dataset to\nfine-tune several OpenAI Whisper models (small, medium, large-v3, and\nlarge-v3-turbo), achieving significant Word Error Rate (WER) reductions on\nstandard Slovak benchmarks like Common Voice and FLEURS. For instance, the\nfine-tuned Whisper-small model's WER dropped by up to 70\\%, approaching the\nbaseline performance of the much larger Whisper-large-v3 model. To foster\nfuture research in low-resource speech recognition, we publicly release the\ncomplete SloPalSpeech dataset, the fully segmented transcripts (60 million\nwords), and all our fine-tuned models.",
        "url": "http://arxiv.org/abs/2509.19270v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19270v1",
        "arxiv_id": "2509.19270v1",
        "authors": [
            "Erik Bok",
            "Marek uppa"
        ],
        "submitted": "2025-09-23 17:33:57",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 1,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. The focus is on Automatic Speech Recognition for low-resource languages, which is outside your primary areas of interest."
    },
    {
        "title": "Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering",
        "abstract": "Personalization is essential for adapting question answering (QA) systems to\nuser-specific information needs, thereby improving both accuracy and user\nsatisfaction. However, personalized QA remains relatively underexplored due to\nchallenges such as inferring preferences from long, noisy, and implicit\ncontexts, and generating responses that are simultaneously correct,\ncontextually appropriate, and aligned with user expectations and background\nknowledge. To address these challenges, we propose Pathways of Thoughts (PoT),\nan inference-stage method that applies to any large language model (LLM)\nwithout requiring task-specific fine-tuning. The approach models the reasoning\nof an LLM as an iterative decision process, where the model dynamically selects\namong cognitive operations such as reasoning, revision, personalization, and\nclarification. This enables exploration of multiple reasoning trajectories,\nproducing diverse candidate responses that capture different perspectives. PoT\nthen aggregates and reweights these candidates according to inferred user\npreferences, yielding a final personalized response that benefits from the\ncomplementary strengths of diverse reasoning paths. Experiments on the LaMP-QA\nbenchmark for personalized QA show that PoT consistently outperforms\ncompetitive baselines, achieving up to a 13.1% relative improvement. Human\nevaluation corroborates these results, with annotators preferring outputs from\nPoT in 66% of cases and reporting ties in only 15% of cases.",
        "url": "http://arxiv.org/abs/2509.19094v1",
        "pdf_url": "http://arxiv.org/pdf/2509.19094v1",
        "arxiv_id": "2509.19094v1",
        "authors": [
            "Alireza Salemi",
            "Cheng Li",
            "Mingyang Zhang",
            "Qiaozhu Mei",
            "Zhuowan Li",
            "Spurthi Amba Hombaiah",
            "Weize Kong",
            "Tao Chen",
            "Hamed Zamani",
            "Michael Bendersky"
        ],
        "submitted": "2025-09-23 14:44:46",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper on 'Pathways of Thoughts' for long-form personalized question answering aligns with your interests in Information Retrieval, particularly in query understanding and ranking models. The focus on user behavior modeling and personalized responses is also relevant to your background in e-commerce and NLP. However, the specific application to question answering and the use of large language models might not be a central match to your primary focus on search technologies and real-time relevance optimization."
    },
    {
        "title": "Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus",
        "abstract": "Over the past decade, Computational Linguistics (CL) and Natural Language\nProcessing (NLP) have evolved rapidly, especially with the advent of\nTransformer-based Large Language Models (LLMs). This shift has transformed\nresearch goals and priorities, from Lexical and Semantic Resources to Language\nModelling and Multimodality. In this study, we track the research trends of the\nItalian CL and NLP community through an analysis of the contributions to\nCLiC-it, arguably the leading Italian conference in the field. We compile the\nproceedings from the first 10 editions of the CLiC-it conference (from 2014 to\n2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its\nmetadata, including author provenance, gender, affiliations, and more, as well\nas the content of the papers themselves, which address various topics. Our goal\nis to provide the Italian and international research communities with valuable\ninsights into emerging trends and key developments over time, supporting\ninformed decisions and future directions in the field.",
        "url": "http://arxiv.org/abs/2509.19033v2",
        "pdf_url": "http://arxiv.org/pdf/2509.19033v2",
        "arxiv_id": "2509.19033v2",
        "authors": [
            "Chiara Alzetta",
            "Serena Auriemma",
            "Alessandro Bondielli",
            "Luca Dini",
            "Chiara Fazzone",
            "Alessio Miaschi",
            "Martina Miliani",
            "Marta Sartor"
        ],
        "submitted": "2025-09-23 14:06:09",
        "source": "arxiv",
        "comment": "Submitted to IJCoL",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on tracking research trends in Italian Computational Linguistics and NLP, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and query understanding. While it touches on NLP, it does not seem to address the user's specific areas of focus, such as ranking models or user behavior modeling."
    },
    {
        "title": "DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment",
        "abstract": "End-to-End Speech Translation (E2E-ST) is the task of translating source\nspeech directly into target text bypassing the intermediate transcription step.\nThe representation discrepancy between the speech and text modalities has\nmotivated research on what is known as bridging the modality gap.\nState-of-the-art methods addressed this by aligning speech and text\nrepresentations on the word or token level. Unfortunately, this requires an\nalignment tool that is not available for all languages. Although this issue has\nbeen addressed by aligning speech and text embeddings using nearest-neighbor\nsimilarity search, it does not lead to accurate alignments. In this work, we\nadapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during\ntraining. Our experiments demonstrate the effectiveness of our method in\nbridging the modality gap in E2E-ST. Compared to previous work, our method\nproduces more accurate alignments and achieves comparable E2E-ST results while\nbeing significantly faster. Furthermore, our method outperforms previous work\nin low resource settings on 5 out of 6 language directions.",
        "url": "http://arxiv.org/abs/2509.18987v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18987v1",
        "arxiv_id": "2509.18987v1",
        "authors": [
            "Abderrahmane Issam",
            "Yusuf Can Semerci",
            "Jan Scholtes",
            "Gerasimos Spanakis"
        ],
        "submitted": "2025-09-23 13:37:15",
        "source": "arxiv",
        "comment": "Accepted at WMT2025",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on speech translation and bridging the modality gap, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves text and speech embeddings, the context and application are quite different from your areas of focus."
    },
    {
        "title": "From latent factors to language: a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system",
        "abstract": "We investigate whether large language models (LLMs) can generate effective,\nuser-facing explanations from a mathematically interpretable recommendation\nmodel. The model is based on constrained matrix factorization, where user types\nare explicitly represented and predicted item scores share the same scale as\nobserved ratings, making the model's internal representations and predicted\nscores directly interpretable. This structure is translated into natural\nlanguage explanations using carefully designed LLM prompts. Many works in\nexplainable AI rely on automatic evaluation metrics, which often fail to\ncapture users' actual needs and perceptions. In contrast, we adopt a\nuser-centered approach: we conduct a study with 326 participants who assessed\nthe quality of the explanations across five key dimensions-transparency,\neffectiveness, persuasion, trust, and satisfaction-as well as the\nrecommendations themselves.To evaluate how different explanation strategies are\nperceived, we generate multiple explanation types from the same underlying\nmodel, varying the input information provided to the LLM. Our analysis reveals\nthat all explanation types are generally well received, with moderate\nstatistical differences between strategies. User comments further underscore\nhow participants react to each type of explanation, offering complementary\ninsights beyond the quantitative results.",
        "url": "http://arxiv.org/abs/2509.18980v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18980v1",
        "arxiv_id": "2509.18980v1",
        "authors": [
            "Maxime Manderlier",
            "Fabian Lecron",
            "Olivier Vu Thanh",
            "Nicolas Gillis"
        ],
        "submitted": "2025-09-23 13:30:03",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores explainable AI in recommender systems, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the focus on recommender systems and user-facing explanations is not a central match to your primary research themes, which include query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Pay More Attention To Audio: Mitigating Imbalance of Cross-Modal Attention in Large Audio Language Models",
        "abstract": "Large Audio-Language Models (LALMs) often suffer from audio-textual attention\nimbalance, prioritizing text over acoustic information, particularly in the\nmulti-modal fusion layers of the Transformer architecture. This bias hinders\ntheir ability to fully utilize acoustic cues, causing suboptimal performance on\naudio reasoning tasks. To mitigate this, we propose \\textbf{MATA}, a novel\ntraining-free method that dynamically pushes LALMs to pay \\textbf{M}ore\n\\textbf{A}ttention \\textbf{T}o \\textbf{A}udio tokens within the self-attention\nmechanism. Specifically, MATA intervenes post raw attention scoring, targeting\nonly the last token in intermediate layers without introducing additional\nparameters or computational overhead. Experiments on the MMAU and MMAR\nbenchmarks confirm MATA's effectiveness, with consistent performance gains.\nNotably, on MMAR, MATA enables an open-source model to surpass the proprietary\nGemini 2.0 Flash for the first time. Our work provides an efficient solution to\nmitigate attention bias and opens a new research direction for enhancing the\naudio-processing capabilities of multi-modal models.",
        "url": "http://arxiv.org/abs/2509.18816v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18816v1",
        "arxiv_id": "2509.18816v1",
        "authors": [
            "Junyu Wang",
            "Ziyang Ma",
            "Zhengding Luo",
            "Tianrui Wang",
            "Meng Ge",
            "Xiaobao Wang",
            "Longbiao Wang"
        ],
        "submitted": "2025-09-23 09:02:15",
        "source": "arxiv",
        "comment": "Submitted to ICASSP 2026",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on mitigating attention imbalance in large audio-language models, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves deep semantic understanding, the context is specific to audio processing and multi-modal models, making it somewhat tangential to the user's core research interests."
    },
    {
        "title": "Single-Branch Network Architectures to Close the Modality Gap in Multimodal Recommendation",
        "abstract": "Traditional recommender systems rely on collaborative filtering, using past\nuser-item interactions to help users discover new items in a vast collection.\nIn cold start, i.e., when interaction histories of users or items are not\navailable, content-based recommender systems use side information instead.\nHybrid recommender systems (HRSs) often employ multimodal learning to combine\ncollaborative and side information, which we jointly refer to as modalities.\nThough HRSs can provide recommendations when some modalities are missing, their\nquality degrades. In this work, we utilize single-branch neural networks\nequipped with weight sharing, modality sampling, and contrastive loss to\nprovide accurate recommendations even in missing modality scenarios by\nnarrowing the modality gap. We compare these networks with multi-branch\nalternatives and conduct extensive experiments on three datasets. Six\naccuracy-based and four beyond-accuracy-based metrics help assess the\nrecommendation quality for the different training paradigms and their\nhyperparameters in warm-start and missing modality scenarios. We quantitatively\nand qualitatively study the effects of these different aspects on bridging the\nmodality gap. Our results show that single-branch networks achieve competitive\nperformance in warm-start scenarios and are significantly better in missing\nmodality settings. Moreover, our approach leads to closer proximity of an\nitem's modalities in the embedding space. Our full experimental setup is\navailable at https://github.com/hcai-mms/single-branch-networks.",
        "url": "http://arxiv.org/abs/2509.18807v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18807v1",
        "arxiv_id": "2509.18807v1",
        "authors": [
            "Christian Ganhr",
            "Marta Moscati",
            "Anna Hausberger",
            "Shah Nawaz",
            "Markus Schedl"
        ],
        "submitted": "2025-09-23 08:58:53",
        "source": "arxiv",
        "comment": "Accepted by ACM Transactions on Recommender Systems (TORS)",
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on multimodal recommendation systems, which is somewhat related to information retrieval and search technologies. However, the primary focus on recommender systems and the use of neural networks for bridging the modality gap in recommendation scenarios does not directly align with the user's core research themes in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR",
        "abstract": "We present LOTUSDIS, a publicly available Thai meeting corpus designed to\nadvance far-field conversational ASR. The dataset comprises 114 hours of\nspontaneous, unscripted dialogue collected in 15-20 minute sessions with three\nparticipants, where overlapping speech is frequent and natural. Speech was\nrecorded simultaneously by nine independent single-channel devices spanning six\nmicrophone types at distances from 0.12 m to 10 m, preserving the authentic\neffects of reverberation, noise, and device coloration without relying on\nmicrophone arrays. We provide standard train, dev, test splits and release a\nreproducible baseline system. We benchmarked several Whisper variants under\nzero-shot and fine-tuned conditions. Off-the-shelf models showed strong\ndegradation with distance, confirming a mismatch between pre-training data and\nThai far-field speech. Fine-tuning on LOTUSDIS dramatically improved\nrobustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and\nfar-field WER from 81.6 to 49.5, with especially large gains on the most\ndistant microphones. These results underscore the importance of\ndistance-diverse training data for robust ASR. The corpus is available under\nCC-BY-SA 4.0. We also release training and evaluation scripts as a baseline\nsystem to promote reproducible research in this field.",
        "url": "http://arxiv.org/abs/2509.18722v1",
        "pdf_url": "http://arxiv.org/pdf/2509.18722v1",
        "arxiv_id": "2509.18722v1",
        "authors": [
            "Pattara Tipaksorn",
            "Sumonmas Thatphithakkul",
            "Vataya Chunwijitra",
            "Kwanchiva Thangthai"
        ],
        "submitted": "2025-09-23 07:11:06",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on conversational ASR and speech recognition in the Thai language, which does not align with your primary focus on Information Retrieval, Search technologies, and Natural Language Processing."
    }
]