# Daily Papers Report - 2025-11-17

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. ComLQ: Benchmarking Complex Logical Queries in Information Retrieval

- **LLM Score**: 9
- **Keyword Score**: 19
- **Authors**: Ganlin Xu, Zhitao Yin, Linghao Zhang, Jiaqing Liang, Weijia Lu, Xiaodong Zhang, Zhifei Yang, Sihang Jiang, Deqing Yang
- **URL**: <http://arxiv.org/abs/2511.12004v1>
- **Submitted**: 2025-11-15 02:58:21
- **Comment**: Accepted by AAAI 2026
- **Topic Keywords**: information retrieval, retriever, query, queries, relevance, rag, retrieval
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The proposed ComLQ dataset and evaluation metric address complex logical queries, which is a key area of focus for you. The use of large language models and expert annotation also aligns with your interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> Information retrieval (IR) systems play a critical role in navigating information overload across various applications. Existing IR benchmarks primarily focus on simple queries that are semantically analogous to single- and multi-hop relations, overlooking \emph{complex logical queries} involving first-order logic operations such as conjunction ($\land$), disjunction ($\lor$), and negation ($\lnot$). Thus, these benchmarks can not be used to sufficiently evaluate the performance of IR models on complex queries in real-world scenarios. To address this problem, we propose a novel method leveraging large language models (LLMs) to construct a new IR dataset \textbf{ComLQ} for \textbf{Com}plex \textbf{L}ogical \textbf{Q}ueries, which comprises 2,909 queries and 11,251 candidate passages. A key challenge in constructing the dataset lies in capturing the underlying logical structures within unstructured text. Therefore, by designing the subgraph-guided prompt with the subgraph indicator, an LLM (such as GPT-4o) is guided to generate queries with specific logical structures based on selected passages. All query-passage pairs in ComLQ are ensured \emph{structure conformity} and \emph{evidence distribution} through expert annotation. To better evaluate whether retrievers can handle queries with negation, we further propose a new evaluation metric, \textbf{Log-Scaled Negation Consistency} (\textbf{LSNC@$K$}). As a supplement to standard relevance-based metrics (such as nDCG and mAP), LSNC@$K$ measures whether top-$K$ retrieved passages violate negation conditions in queries. Our experimental results under zero-shot settings demonstrate existing retrieval models' limited performance on complex logical queries, especially on queries with negation, exposing their inferior capabilities of modeling exclusion.

---

### 2. Probing Preference Representations: A Multi-Dimensional Evaluation and Analysis Method for Reward Models

- **LLM Score**: 8
- **Keyword Score**: 9
- **Authors**: Chenglong Wang, Yifu Huo, Yang Gan, Yongyu Mu, Qiaozhi He, Murun Yang, Bei Li, Chunliang Zhang, Tongran Liu, Anxiang Ma, Zhengtao Yu, Jingbo Zhu, Tong Xiao
- **URL**: <http://arxiv.org/abs/2511.12464v1>
- **Submitted**: 2025-11-16 05:29:29
- **Comment**: Accepted by AAAI 2026
- **Topic Keywords**: ranking, pairwise, rag, rank
- **Reason**: This paper focuses on reward models, which is somewhat related to ranking models in Information Retrieval. The evaluation method and benchmark proposed in the paper can be applied to various domains, including e-commerce, and the analysis of preference representations aligns with query understanding and user behavior modeling. However, the primary focus on reward models and large language models limits its direct relevance to my core research themes.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Reward Model Evaluation and Multi-Dimensional Preference Benchmarking
- **Aim**: Develop a benchmark (MRMBench) and inference-time probing method to enable fine-grained evaluation of reward models across distinct preference dimensions and improve interpretability and alignment performance.
- **Rationale**: Existing evaluation relies on fixed pairwise ranking test sets that lack granularity; a multi-dimensional approach is needed to capture nuanced preferences and to identify which dimensions a reward model consults during inference.
- **Ground**: MRMBench consists of six probing tasks, each targeting a specific preference dimension; inference-time probing identifies the consulted dimensions and provides a confidence metric for reward predictions.
- **Experiment**: Extensive experiments show MRMBench scores strongly correlate with large-language-model alignment performance; analysis reveals many reward models fail to represent multiple preference dimensions simultaneously; inference-time probing reliably assesses prediction confidence and improves alignment.
- **Takeaway**: MRMBench serves as a valuable development reference; multi-objective optimization could enhance reward modeling; inference-time probing offers a reliable confidence metric that improves LLM alignment.

#### Abstract
> Previous methods evaluate reward models by testing them on a fixed pairwise ranking test set, but they typically do not provide performance information on each preference dimension. In this work, we address the evaluation challenge of reward models by probing preference representations. To confirm the effectiveness of this evaluation method, we construct a Multi-dimensional Reward Model Benchmark (MRMBench), a collection of six probing tasks for different preference dimensions. We design it to favor and encourage reward models that better capture preferences across different dimensions. Furthermore, we introduce an analysis method, inference-time probing, which identifies the dimensions used during the reward prediction and enhances its interpretability. Through extensive experiments, we find that MRMBench strongly correlates with the alignment performance of large language models (LLMs), making it a reliable reference for developing advanced reward models. Our analysis of MRMBench evaluation results reveals that reward models often struggle to capture preferences across multiple dimensions, highlighting the potential of multi-objective optimization in reward modeling. Additionally, our findings show that the proposed inference-time probing method offers a reliable metric for assessing the confidence of reward predictions, which ultimately improves the alignment of LLMs.

---

### 3. From Scaling to Structured Expressivity: Rethinking Transformers for CTR Prediction

- **LLM Score**: 8
- **Keyword Score**: 7
- **Authors**: Bencheng Yan, Yuejie Lei, Zhiyuan Zeng, Di Wang, Kaiyi Lin, Pengjie Wang, Jian Xu, Bo Zheng
- **URL**: <http://arxiv.org/abs/2511.12081v1>
- **Submitted**: 2025-11-15 07:55:50
- **Topic Keywords**: click, ctr, click-through rate, recommend
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, specifically click-through rate (CTR) prediction and ranking models. The authors propose a novel Field-Aware Transformer (FAT) architecture that addresses the structural misalignment in existing deep models, leading to improved performance and scalability. While the focus is on recommender systems, the work contributes to the broader area of query understanding and ranking models.

#### Abstract
> Despite massive investments in scale, deep models for click-through rate (CTR) prediction often exhibit rapidly diminishing returns - a stark contrast to the smooth, predictable gains seen in large language models. We identify the root cause as a structural misalignment: Transformers assume sequential compositionality, while CTR data demand combinatorial reasoning over high-cardinality semantic fields. Unstructured attention spreads capacity indiscriminately, amplifying noise under extreme sparsity and breaking scalable learning. To restore alignment, we introduce the Field-Aware Transformer (FAT), which embeds field-based interaction priors into attention through decomposed content alignment and cross-field modulation. This design ensures model complexity scales with the number of fields F, not the total vocabulary size n >> F, leading to tighter generalization and, critically, observed power-law scaling in AUC as model width increases. We present the first formal scaling law for CTR models, grounded in Rademacher complexity, that explains and predicts this behavior. On large-scale benchmarks, FAT improves AUC by up to +0.51% over state-of-the-art methods. Deployed online, it delivers +2.33% CTR and +0.66% RPM. Our work establishes that effective scaling in recommendation arises not from size, but from structured expressivity-architectural coherence with data semantics.

---

### 4. DualGR: Generative Retrieval with Long and Short-Term Interests Modeling

- **LLM Score**: 8
- **Keyword Score**: 6
- **Authors**: Zhongchao Yi, Kai Feng, Xiaojian Ma, Yalong Wang, Yongqi Liu, Han Li, Zhengyang Zhou, Yang Wang
- **URL**: <http://arxiv.org/abs/2511.12518v1>
- **Submitted**: 2025-11-16 09:20:54
- **Topic Keywords**: click, retrieval, recommend, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of Generative Retrieval and query understanding. The proposed DualGR framework addresses challenges in modeling user interests and handling negative feedback, which aligns with your focus on real-time relevance optimization and deep semantic understanding.

#### Abstract
> In large-scale industrial recommendation systems, retrieval must produce high-quality candidates from massive corpora under strict latency. Recently, Generative Retrieval (GR) has emerged as a viable alternative to Embedding-Based Retrieval (EBR), which quantizes items into a finite token space and decodes candidates autoregressively, providing a scalable path that explicitly models target-history interactions via cross-attention. However, three challenges persist: 1) how to balance users' long-term and short-term interests , 2) noise interference when generating hierarchical semantic IDs (SIDs), 3) the absence of explicit modeling for negative feedback such as exposed items without clicks. To address these challenges, we propose DualGR, a generative retrieval framework that explicitly models dual horizons of user interests with selective activation. Specifically, DualGR utilizes Dual-Branch Long/Short-Term Router (DBR) to cover both stable preferences and transient intents by explicitly modeling users' long- and short-term behaviors. Meanwhile, Search-based SID Decoding (S2D) is presented to control context-induced noise and enhance computational efficiency by constraining candidate interactions to the current coarse (level-1) bucket during fine-grained (level-2/3) SID prediction. % also reinforcing intra-class consistency. Finally, we propose an Exposure-aware Next-Token Prediction Loss (ENTP-Loss) that treats "exposed-but-unclicked" items as hard negatives at level-1, enabling timely interest fade-out. On the large-scale Kuaishou short-video recommendation system, DualGR has achieved outstanding performance. Online A/B testing shows +0.527% video views and +0.432% watch time lifts, validating DualGR as a practical and effective paradigm for industrial generative retrieval.

---

### 5. TAdaRAG: Task Adaptive Retrieval-Augmented Generation via On-the-Fly Knowledge Graph Construction

- **LLM Score**: 8
- **Keyword Score**: 4
- **Authors**: Jie Zhang, Bo Tang, Wanzi Shao, Wenqiang Wei, Jihao Zhao, Jianqing Zhu, Zhiyu li, Wen Xi, Zehao Lin, Feiyu Xiong, Yanchao Tan
- **URL**: <http://arxiv.org/abs/2511.12520v1>
- **Submitted**: 2025-11-16 09:23:09
- **Comment**: Accepted by AAAI 2026
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of query understanding and ranking models. The proposed framework, TAdaRAG, addresses issues in Retrieval-Augmented Generation, which is a key area of interest in IR. While the focus is on NLP, the paper's emphasis on knowledge graph construction and relevance optimization aligns with your broader interests.

#### Abstract
> Retrieval-Augmented Generation (RAG) improves large language models by retrieving external knowledge, often truncated into smaller chunks due to the input context window, which leads to information loss, resulting in response hallucinations and broken reasoning chains. Moreover, traditional RAG retrieves unstructured knowledge, introducing irrelevant details that hinder accurate reasoning. To address these issues, we propose TAdaRAG, a novel RAG framework for on-the-fly task-adaptive knowledge graph construction from external sources. Specifically, we design an intent-driven routing mechanism to a domain-specific extraction template, followed by supervised fine-tuning and a reinforcement learning-based implicit extraction mechanism, ensuring concise, coherent, and non-redundant knowledge integration. Evaluations on six public benchmarks and a real-world business benchmark (NowNewsQA) across three backbone models demonstrate that TAdaRAG outperforms existing methods across diverse domains and long-text tasks, highlighting its strong generalization and practical effectiveness.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. QA-Noun: Representing Nominal Semantics via Natural Language Question-Answer Pairs

- **LLM Score**: 8
- **Keyword Score**: 2
- **Authors**: Maria Tseytlin, Paul Roit, Omri Abend, Ido Dagan, Ayal Klein
- **URL**: <http://arxiv.org/abs/2511.12504v1>
- **Submitted**: 2025-11-16 08:32:38
- **Topic Keywords**: rag
- **Reason**: This paper aligns with your interests in Natural Language Processing (NLP) and query understanding, as it introduces a framework for capturing noun-centered semantic relations using question-answer pairs. While it's not directly related to search technologies or ranking models, it contributes to the broader field of semantic understanding, which is relevant to your research. The paper's focus on fine-grained semantic decomposition and cross-text alignment is also of interest.

#### Abstract
> Decomposing sentences into fine-grained meaning units is increasingly used to model semantic alignment. While QA-based semantic approaches have shown effectiveness for representing predicate-argument relations, they have so far left noun-centered semantics largely unaddressed. We introduce QA-Noun, a QA-based framework for capturing noun-centered semantic relations. QA-Noun defines nine question templates that cover both explicit syntactical and implicit contextual roles for nouns, producing interpretable QA pairs that complement verbal QA-SRL. We release detailed guidelines, a dataset of over 2,000 annotated noun mentions, and a trained model integrated with QA-SRL to yield a unified decomposition of sentence meaning into individual, highly fine-grained, facts. Evaluation shows that QA-Noun achieves near-complete coverage of AMR's noun arguments while surfacing additional contextually implied relations, and that combining QA-Noun with QA-SRL yields over 130\% higher granularity than recent fact-based decomposition methods such as FactScore and DecompScore. QA-Noun thus complements the broader QA-based semantic framework, forming a comprehensive and scalable approach to fine-grained semantic decomposition for cross-text alignment.

### 7. Assessing LLMs for Serendipity Discovery in Knowledge Graphs: A Case for Drug Repurposing

- **LLM Score**: 6
- **Keyword Score**: 5
- **Authors**: Mengying Wang, Chenhui Ma, Ao Jiao, Tuo Liang, Pengjun Lu, Shrinidhi Hegde, Yu Yin, Evren Gurkan-Cavusoglu, Yinghui Wu
- **URL**: <http://arxiv.org/abs/2511.12472v1>
- **Submitted**: 2025-11-16 06:19:53
- **Comment**: The 40th AAAI Conference on Artificial Intelligence (AAAI-26)
- **Topic Keywords**: relevance, retrieval
- **Reason**: This paper explores the application of Large Language Models (LLMs) in knowledge graph question answering (KGQA) with a focus on serendipity discovery. While it touches on aspects of query understanding and ranking models, the primary focus is on a specific domain (drug repurposing) and a novel task (serendipity-aware KGQA). The connection to information retrieval and real-time relevance optimization is indirect, but the paper's emphasis on LLMs and KGQA suggests some relevance to broader IR themes.

#### Abstract
> Large Language Models (LLMs) have greatly advanced knowledge graph question answering (KGQA), yet existing systems are typically optimized for returning highly relevant but predictable answers. A missing yet desired capacity is to exploit LLMs to suggest surprise and novel ("serendipitious") answers. In this paper, we formally define the serendipity-aware KGQA task and propose the SerenQA framework to evaluate LLMs' ability to uncover unexpected insights in scientific KGQA tasks. SerenQA includes a rigorous serendipity metric based on relevance, novelty, and surprise, along with an expert-annotated benchmark derived from the Clinical Knowledge Graph, focused on drug repurposing. Additionally, it features a structured evaluation pipeline encompassing three subtasks: knowledge retrieval, subgraph reasoning, and serendipity exploration. Our experiments reveal that while state-of-the-art LLMs perform well on retrieval, they still struggle to identify genuinely surprising and valuable discoveries, underscoring a significant room for future improvements. Our curated resources and extended version are released at: https://cwru-db-group.github.io/serenQA.

### 8. MOON2.0: Dynamic Modality-balanced Multimodal Representation Learning for E-commerce Product Understanding

- **LLM Score**: 6
- **Keyword Score**: 4
- **Authors**: Zhanheng Nie, Chenghan Fu, Daoze Zhang, Junxian Wu, Wanxian Guan, Pengjie Wang, Jian Xu, Bo Zheng
- **URL**: <http://arxiv.org/abs/2511.12449v1>
- **Submitted**: 2025-11-16 04:29:35
- **Comment**: 11 pages, 7 figures
- **Topic Keywords**: rag, commerce, e-commerce
- **Reason**: The paper focuses on multimodal representation learning for e-commerce product understanding, which is somewhat related to your interests in Information Retrieval and Search technologies, particularly in the e-commerce domain. However, the paper's emphasis on multimodal models and product understanding is not a central match for your primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> The rapid growth of e-commerce calls for multimodal models that comprehend rich visual and textual product information. Although recent multimodal large language models (MLLMs) for product understanding exhibit strong capability in representation learning for e-commerce, they still face three challenges: (i) the modality imbalance induced by modality mixed training; (ii) underutilization of the intrinsic alignment relationships among visual and textual information within a product; and (iii) limited handling of noise in e-commerce multimodal data. To address these, we propose MOON2.0, a dynamic modality-balanced multimodal representation learning framework for e-commerce product understanding. MOON2.0 comprises: (1) a Modality-driven Mixture-of-Experts (MoE) module that adaptively processes input samples by their modality composition, enabling Multimodal Joint Learning to mitigate the modality imbalance; (2) a Dual-level Alignment method to better leverage semantic alignment properties inside individual products; and (3) an MLLM-based Image-text Co-augmentation strategy that integrates textual enrichment with visual expansion, coupled with Dynamic Sample Filtering to improve training data quality. We further introduce MBE2.0, a co-augmented multimodal representation benchmark for e-commerce representation learning and evaluation. Experiments show that MOON2.0 delivers state-of-the-art zero-shot performance on MBE2.0 and multiple public datasets. Furthermore, attention-based heatmap visualization provides qualitative evidence of improved multimodal alignment of MOON2.0.

### 9. Task-Aware Retrieval Augmentation for Dynamic Recommendation

- **LLM Score**: 4
- **Keyword Score**: 11
- **Authors**: Zhen Tao, Xinke Jiang, Qingshuai Feng, Haoyu Zhang, Lun Du, Yuchen Fang, Hao Miao, Bangquan Xie, Qingqiang Sun
- **URL**: <http://arxiv.org/abs/2511.12495v1>
- **Submitted**: 2025-11-16 08:14:52
- **Comment**: AAAI 2026
- **Topic Keywords**: query, relevance, rag, retrieval, recommend
- **Reason**: The paper focuses on dynamic recommendation systems, leveraging graph neural networks and task-aware retrieval augmentation. While it touches on user behavior modeling, it's primarily concerned with recommender systems, which is a related but secondary interest of yours. The paper's emphasis on deep semantic understanding and real-time relevance optimization is somewhat relevant to your IR interests, but the context is different.

#### Abstract
> Dynamic recommendation systems aim to provide personalized suggestions by modeling temporal user-item interactions across time-series behavioral data. Recent studies have leveraged pre-trained dynamic graph neural networks (GNNs) to learn user-item representations over temporal snapshot graphs. However, fine-tuning GNNs on these graphs often results in generalization issues due to temporal discrepancies between pre-training and fine-tuning stages, limiting the model's ability to capture evolving user preferences. To address this, we propose TarDGR, a task-aware retrieval-augmented framework designed to enhance generalization capability by incorporating task-aware model and retrieval-augmentation. Specifically, TarDGR introduces a Task-Aware Evaluation Mechanism to identify semantically relevant historical subgraphs, enabling the construction of task-specific datasets without manual labeling. It also presents a Graph Transformer-based Task-Aware Model that integrates semantic and structural encodings to assess subgraph relevance. During inference, TarDGR retrieves and fuses task-aware subgraphs with the query subgraph, enriching its representation and mitigating temporal generalization issues. Experiments on multiple large-scale dynamic graph datasets demonstrate that TarDGR consistently outperforms state-of-the-art methods, with extensive empirical evidence underscoring its superior accuracy and generalization capabilities.

### 10. MME-RAG: Multi-Manager-Expert Retrieval-Augmented Generation for Fine-Grained Entity Recognition in Task-Oriented Dialogues

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Liang Xue, Haoyu Liu, Yajun Tian, Xinyu Zhong, Yang Liu
- **URL**: <http://arxiv.org/abs/2511.12213v1>
- **Submitted**: 2025-11-15 13:35:55
- **Topic Keywords**: retriever, rag, retrieval
- **Reason**: The paper focuses on fine-grained entity recognition in task-oriented dialogues, which is somewhat related to information retrieval and NLP. However, the primary focus on dialogue understanding and entity recognition in a specific domain (task-oriented dialogues) is not directly aligned with the user's core research themes in IR and search technologies.

#### Abstract
> Fine-grained entity recognition is crucial for reasoning and decision-making in task-oriented dialogues, yet current large language models (LLMs) continue to face challenges in domain adaptation and retrieval controllability. We introduce MME-RAG, a Multi-Manager-Expert Retrieval-Augmented Generation framework that decomposes entity recognition into two coordinated stages: type-level judgment by lightweight managers and span-level extraction by specialized experts. Each expert is supported by a KeyInfo retriever that injects semantically aligned, few-shot exemplars during inference, enabling precise and domain-adaptive extraction without additional training. Experiments on CrossNER, MIT-Movie, MIT-Restaurant, and our newly constructed multi-domain customer-service dataset demonstrate that MME-RAG performs better than recent baselines in most domains. Ablation studies further show that both the hierarchical decomposition and KeyInfo-guided retrieval are key drivers of robustness and cross-domain generalization, establishing MME-RAG as a scalable and interpretable solution for adaptive dialogue understanding.

### 11. Evolving Prompts for Toxicity Search in Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Onkar Shelar, Travis Desell
- **URL**: <http://arxiv.org/abs/2511.12487v1>
- **Submitted**: 2025-11-16 07:47:31
- **Comment**: pre-print
- **Topic Keywords**: search, acl
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of query understanding and ranking models. However, its focus on Large Language Models and toxicity search is more aligned with NLP and related topics, rather than your primary focus on IR and real-time relevance optimization.

#### Abstract
> Large Language Models remain vulnerable to adversarial prompts that elicit toxic content even after safety alignment. We present ToxSearch, a black-box evolutionary framework that tests model safety by evolving prompts in a synchronous steady-state loop. The system employs a diverse set of operators, including lexical substitutions, negation, back-translation, paraphrasing, and two semantic crossover operators, while a moderation oracle provides fitness guidance. Operator-level analysis shows heterogeneous behavior: lexical substitutions offer the best yield-variance trade-off, semantic-similarity crossover acts as a precise low-throughput inserter, and global rewrites exhibit high variance with elevated refusal costs. Using elite prompts evolved on LLaMA 3.1 8B, we observe practically meaningful but attenuated cross-model transfer, with toxicity roughly halving on most targets, smaller LLaMA 3.2 variants showing the strongest resistance, and some cross-architecture models retaining higher toxicity. These results suggest that small, controllable perturbations are effective vehicles for systematic red-teaming and that defenses should anticipate cross-model reuse of adversarial prompts rather than focusing only on single-model hardening.

### 12. PRISM of Opinions: A Persona-Reasoned Multimodal Framework for User-centric Conversational Stance Detection

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Bingbing Wang, Zhixin Bai, Zhengda Jin, Zihan Wang, Xintong Song, Jingjie Lin, Sixuan Li, Jing Li, Ruifeng Xu
- **URL**: <http://arxiv.org/abs/2511.12130v1>
- **Submitted**: 2025-11-15 09:35:58
- **Topic Keywords**: rag, search
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and multimodal interactions, but it does not directly address your core focus on Information Retrieval (IR), query understanding, or ranking models. The paper's emphasis on user-centric conversational stance detection and multimodal reasoning is not a central match for your research themes.

#### Abstract
> The rapid proliferation of multimodal social media content has driven research in Multimodal Conversational Stance Detection (MCSD), which aims to interpret users' attitudes toward specific targets within complex discussions. However, existing studies remain limited by: **1) pseudo-multimodality**, where visual cues appear only in source posts while comments are treated as text-only, misaligning with real-world multimodal interactions; and **2) user homogeneity**, where diverse users are treated uniformly, neglecting personal traits that shape stance expression. To address these issues, we introduce **U-MStance**, the first user-centric MCSD dataset, containing over 40k annotated comments across six real-world targets. We further propose **PRISM**, a **P**ersona-**R**easoned mult**I**modal **S**tance **M**odel for MCSD. PRISM first derives longitudinal user personas from historical posts and comments to capture individual traits, then aligns textual and visual cues within conversational context via Chain-of-Thought to bridge semantic and pragmatic gaps across modalities. Finally, a mutual task reinforcement mechanism is employed to jointly optimize stance detection and stance-aware response generation for bidirectional knowledge transfer. Experiments on U-MStance demonstrate that PRISM yields significant gains over strong baselines, underscoring the effectiveness of user-centric and context-grounded multimodal reasoning for realistic stance understanding.

### 13. LLMLagBench: Identifying Temporal Training Boundaries in Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Piotr Pƒôzik, Konrad Kaczy≈Ñski, Maria Szyma≈Ñska, Filip ≈ªarnecki, Zuzanna Deckert, Jakub Kwiatkowski, Wojciech Janowski
- **URL**: <http://arxiv.org/abs/2511.12116v1>
- **Submitted**: 2025-11-15 09:08:10
- **Topic Keywords**: query
- **Reason**: This paper is loosely relevant to your research interests in Information Retrieval and Natural Language Processing, as it deals with Large Language Models and their limitations in providing accurate information. However, the focus on temporal training boundaries and model freshness is not directly related to your core areas of interest in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large Language Models (LLMs) are pretrained on textual data up to a specific temporal cutoff. This creates a strict knowledge boundary beyond which models cannot provide accurate information without querying external sources. More subtly, when this limitation is unknown or ignored, LLMs may inadvertently blend outdated time-sensitive information with general knowledge during reasoning tasks, potentially compromising response accuracy. We introduce LLMLagBench, an LLM freshness benchmark, as a systematic approach for identifying the earliest probable temporal boundaries of an LLM's training data by evaluating its knowledge of recent events. We then apply this benchmark to evaluate a large set of LLMs, including models with both explicitly declared and undeclared training cutoffs. The reliability of the benchmark is assessed by manual validation and comparison with publicly released information about LLM pretraining.

### 14. Continuous-time Discrete-space Diffusion Model for Recommendation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Chengyi Liu, Xiao Chen, Shijie Wang, Wenqi Fan, Qing Li
- **URL**: <http://arxiv.org/abs/2511.12114v1>
- **Submitted**: 2025-11-15 09:06:57
- **Comment**: Accepted by WSDM 2026
- **Topic Keywords**: user behavior, recommend
- **Reason**: The paper focuses on recommender systems, which is a related area to information retrieval, but it does not directly address query understanding, ranking models, or user behavior modeling in the context of search technologies. The proposed CDRec framework is designed for recommendation accuracy and efficiency, but it does not explicitly incorporate deep semantic understanding or real-time relevance optimization, which are key aspects of your research interests.

#### Abstract
> In the era of information explosion, Recommender Systems (RS) are essential for alleviating information overload and providing personalized user experiences. Recent advances in diffusion-based generative recommenders have shown promise in capturing the dynamic nature of user preferences. These approaches explore a broader range of user interests by progressively perturbing the distribution of user-item interactions and recovering potential preferences from noise, enabling nuanced behavioral understanding. However, existing diffusion-based approaches predominantly operate in continuous space through encoded graph-based historical interactions, which may compromise potential information loss and suffer from computational inefficiency. As such, we propose CDRec, a novel Continuous-time Discrete-space Diffusion Recommendation framework, which models user behavior patterns through discrete diffusion on historical interactions over continuous time. The discrete diffusion algorithm operates via discrete element operations (e.g., masking) while incorporating domain knowledge through transition matrices, producing more meaningful diffusion trajectories. Furthermore, the continuous-time formulation enables flexible adaptive sampling. To better adapt discrete diffusion models to recommendations, CDRec introduces: (1) a novel popularity-aware noise schedule that generates semantically meaningful diffusion trajectories, and (2) an efficient training framework combining consistency parameterization for fast sampling and a contrastive learning objective guided by multi-hop collaborative signals for personalized recommendation. Extensive experiments on real-world datasets demonstrate CDRec's superior performance in both recommendation accuracy and computational efficiency.

### 15. MedPT: A Massive Medical Question Answering Dataset for Brazilian-Portuguese Speakers

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Fernanda Bufon F√§rber, Iago Alves Brito, Julia Soares Dollis, Pedro Schindler Freire Brasil Ribeiro, Rafael Teixeira Sousa, Arlindo Rodrigues Galv√£o Filho
- **URL**: <http://arxiv.org/abs/2511.11878v1>
- **Submitted**: 2025-11-14 21:13:28
- **Comment**: 11 pages, 3 tables, 2 figures
- **Topic Keywords**: queries
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, particularly in the context of query understanding and deep semantic understanding. However, the focus on a specific language (Brazilian-Portuguese) and a medical domain limits its direct relevance to your core research themes in e-commerce and general search technologies.

#### Abstract
> While large language models (LLMs) show transformative potential in healthcare, their development remains focused on high-resource languages, creating a critical barrier for others as simple translation fails to capture unique clinical and cultural nuances, such as endemic diseases. To address this, we introduce MedPT, the first large-scale, real-world corpus for Brazilian Portuguese, comprising 384,095 authentic question-answer pairs from patient-doctor interactions. The dataset underwent a meticulous multi-stage curation protocol, using a hybrid quantitative-qualitative analysis to filter noise and contextually enrich thousands of ambiguous queries. We further augmented the corpus via LLM-driven annotation, classifying questions into seven semantic types to capture user intent. Our analysis reveals its thematic breadth (3,200 topics) and unique linguistic properties, like the natural asymmetry in patient-doctor communication. To validate its utility, we benchmark a medical specialty routing task: fine-tuning a 1.7B parameter model achieves an outstanding 94\% F1-score on a 20-class setup. Furthermore, our qualitative error analysis shows misclassifications are not random but reflect genuine clinical ambiguities (e.g., between comorbid conditions), proving the dataset's deep semantic richness. We publicly release MedPT to foster the development of more equitable, accurate, and culturally-aware medical technologies for the Portuguese-speaking world.

### 16. Consistency Is the Key: Detecting Hallucinations in LLM Generated Text By Checking Inconsistencies About Key Facts

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Raavi Gupta, Pranav Hari Panicker, Sumit Bhatia, Ganesh Ramakrishnan
- **URL**: <http://arxiv.org/abs/2511.12236v1>
- **Submitted**: 2025-11-15 14:33:02
- **Comment**: To appear at International Joint Conference on Natural Language Processing & Asia-Pacific Chapter of the Association for Computational Linguistics (IJCNLP-AACL), 2025
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to your interests in Natural Language Processing (NLP) and Large Language Models (LLMs), but it does not directly address your core research themes in Information Retrieval (IR), query understanding, ranking models, or user behavior modeling. The paper's focus on hallucination detection in LLMs is an interesting application, but it does not seem to be a central match for your research interests.

#### Abstract
> Large language models (LLMs), despite their remarkable text generation capabilities, often hallucinate and generate text that is factually incorrect and not grounded in real-world knowledge. This poses serious risks in domains like healthcare, finance, and customer support. A typical way to use LLMs is via the APIs provided by LLM vendors where there is no access to model weights or options to fine-tune the model. Existing methods to detect hallucinations in such settings where the model access is restricted or constrained by resources typically require making multiple LLM API calls, increasing latency and API cost. We introduce CONFACTCHECK, an efficient hallucination detection approach that does not leverage any external knowledge base and works on the simple intuition that responses to factual probes within the generated text should be consistent within a single LLM and across different LLMs. Rigorous empirical evaluation on multiple datasets that cover both the generation of factual texts and the open generation shows that CONFACTCHECK can detect hallucinated facts efficiently using fewer resources and achieves higher accuracy scores compared to existing baselines that operate under similar conditions. Our code is available here.

### 17. AI-Salesman: Towards Reliable Large Language Model Driven Telemarketing

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Qingyu Zhang, Chunlei Xin, Xuanang Chen, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun, Qing Ye, Qianlong Xie, Xingxing Wang
- **URL**: <http://arxiv.org/abs/2511.12133v1>
- **Submitted**: 2025-11-15 09:44:42
- **Topic Keywords**: rag
- **Reason**: The paper explores the application of Large Language Models in telemarketing, which is a specific domain. While it involves some aspects of query understanding and ranking models, the primary focus is on dialogue generation and persuasive strategies, which is somewhat related to information retrieval but not directly aligned with your core research themes.

#### Abstract
> Goal-driven persuasive dialogue, exemplified by applications like telemarketing, requires sophisticated multi-turn planning and strict factual faithfulness, which remains a significant challenge for even state-of-the-art Large Language Models (LLMs). A lack of task-specific data often limits previous works, and direct LLM application suffers from strategic brittleness and factual hallucination. In this paper, we first construct and release TeleSalesCorpus, the first real-world-grounded dialogue dataset for this domain. We then propose AI-Salesman, a novel framework featuring a dual-stage architecture. For the training stage, we design a Bayesian-supervised reinforcement learning algorithm that learns robust sales strategies from noisy dialogues. For the inference stage, we introduce the Dynamic Outline-Guided Agent (DOGA), which leverages a pre-built script library to provide dynamic, turn-by-turn strategic guidance. Moreover, we design a comprehensive evaluation framework that combines fine-grained metrics for key sales skills with the LLM-as-a-Judge paradigm. Experimental results demonstrate that our proposed AI-Salesman significantly outperforms baseline models in both automatic metrics and comprehensive human evaluations, showcasing its effectiveness in complex persuasive scenarios.

### 18. CURE: Cultural Understanding and Reasoning Evaluation - A Framework for "Thick" Culture Alignment Evaluation in LLMs

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Truong Vo, Sanmi Koyejo
- **URL**: <http://arxiv.org/abs/2511.12014v1>
- **Submitted**: 2025-11-15 03:39:13
- **Comment**: 7 pages, 5 figures
- **Topic Keywords**: rag
- **Reason**: The paper explores cultural understanding and evaluation in Large Language Models (LLMs), which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on cultural competence and evaluation metrics is not directly aligned with the user's primary research interests in IR and NLP. While the paper touches on deep semantic understanding, it is more focused on cultural understanding rather than real-time relevance optimization.

#### Abstract
> Large language models (LLMs) are increasingly deployed in culturally diverse environments, yet existing evaluations of cultural competence remain limited. Existing methods focus on de-contextualized correctness or forced-choice judgments, overlooking the need for cultural understanding and reasoning required for appropriate responses. To address this gap, we introduce a set of benchmarks that, instead of directly probing abstract norms or isolated statements, present models with realistic situational contexts that require culturally grounded reasoning. In addition to the standard Exact Match metric, we introduce four complementary metrics (Coverage, Specificity, Connotation, and Coherence) to capture different dimensions of model's response quality. Empirical analysis across frontier models reveals that thin evaluation systematically overestimates cultural competence and produces unstable assessments with high variance. In contrast, thick evaluation exposes differences in reasoning depth, reduces variance, and provides more stable, interpretable signals of cultural understanding.

### 19. Improving LLM's Attachment to External Knowledge In Dialogue Generation Tasks Through Entity Anonymization

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Hadi Sheikhi, Chenyang Huang, Osmar R. Za√Øane
- **URL**: <http://arxiv.org/abs/2511.11946v1>
- **Submitted**: 2025-11-14 23:37:35
- **Topic Keywords**: rag
- **Reason**: The paper explores the use of large language models in dialogue generation tasks, focusing on knowledge attachment and entity anonymization. While it touches on NLP, it doesn't directly relate to information retrieval, query understanding, or ranking models, which are core areas of interest. The paper's focus on dialogue generation and knowledge graphs is somewhat relevant to the broader NLP domain, but not a central match for the user's research interests.

#### Abstract
> Knowledge graph-based dialogue generation (KG-DG) is a challenging task requiring models to effectively incorporate external knowledge into conversational responses. While large language models (LLMs) have achieved impressive results across various NLP tasks, their ability to utilize external knowledge in KG-DG remains under-explored. We observe that LLMs often rely on internal knowledge, leading to detachment from provided knowledge graphs, even when they are given a flawlessly retrieved knowledge graph. First, we introduce LLM-KAT, an evaluation procedure for measuring knowledge attachment in generated responses. Second, we propose a simple yet effective entity anonymization technique to encourage LLMs to better leverage external knowledge. Experiments on the OpenDialKG dataset demonstrate that our approach improves LLMs' attachment on external knowledge.

### 20. ClinStructor: AI-Powered Structuring of Unstructured Clinical Texts

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Karthikeyan K, Raghuveer Thirukovalluru, David Carlson
- **URL**: <http://arxiv.org/abs/2511.11883v1>
- **Submitted**: 2025-11-14 21:21:16
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it involves text structuring and question-answer pairs. However, the focus on clinical text and predictive modeling is not directly aligned with your core interests in search technologies, ranking models, and user behavior modeling.

#### Abstract
> Clinical notes contain valuable, context-rich information, but their unstructured format introduces several challenges, including unintended biases (e.g., gender or racial bias), and poor generalization across clinical settings (e.g., models trained on one EHR system may perform poorly on another due to format differences) and poor interpretability. To address these issues, we present ClinStructor, a pipeline that leverages large language models (LLMs) to convert clinical free-text into structured, task-specific question-answer pairs prior to predictive modeling. Our method substantially enhances transparency and controllability and only leads to a modest reduction in predictive performance (a 2-3% drop in AUC), compared to direct fine-tuning, on the ICU mortality prediction task. ClinStructor lays a strong foundation for building reliable, interpretable, and generalizable machine learning models in clinical environments.

### 21. CriticSearch: Fine-Grained Credit Assignment for Search Agents via a Retrospective Critic

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Yaocheng Zhang, Haohuan Huang, Zijun Song, Yuanheng Zhu, Qichao Zhang, Zijie Zhao, Dongbin Zhao
- **URL**: <http://arxiv.org/abs/2511.12159v1>
- **Submitted**: 2025-11-15 11:06:57
- **Comment**: 17 pages, 10 figures
- **Topic Keywords**: search
- **Reason**: The paper explores a novel approach to search agent optimization, introducing a fine-grained credit-assignment framework. While it touches on search technologies, its primary focus is on improving the training process of search agents, which is somewhat related to your interests in query understanding and ranking models. However, the paper's emphasis on large language models and question-answering tasks is not directly aligned with your core research themes in Information Retrieval and Search technologies.

#### Abstract
> Tool-Integrated Reasoning (TIR) with search engines enables large language models to iteratively retrieve up-to-date external knowledge, enhancing adaptability and generalization in complex question-answering tasks. However, existing search agent pipelines typically depend on reinforcement learning based optimization, which often suffers from sparse outcome rewards, leading to inefficient exploration and unstable training. We introduce CriticSearch, a fine-grained credit-assignment framework that supplies dense, turn-level feedback via a retrospective critic mechanism. During training, a frozen, asymmetric critique LLM retrospectively evaluates each turn using privileged information from the full trajectory and gold answers, converting these assessments into stable, dense rewards that guide policy improvement. Experimental results across diverse multi-hop reasoning benchmarks demonstrate that CriticSearch consistently outperforms existing baselines, achieving faster convergence, improved training stability, and higher performance.

### 22. Additive Large Language Models for Semi-Structured Text

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Karthikeyan K, Raghuveer Thirukovalluru, David Carlson
- **URL**: <http://arxiv.org/abs/2511.11922v1>
- **Submitted**: 2025-11-14 23:06:16
- **Topic Keywords**: search
- **Reason**: This paper introduces a new framework for semi-structured text classification using additive large language models, which provides interpretable predictions. While it relates to NLP and deep semantic understanding, it does not directly focus on information retrieval, query understanding, or ranking models, which are core areas of your research interests.

#### Abstract
> Large Language Models have advanced clinical text classification, but their opaque predictions remain a critical barrier to practical adoption in research and clinical settings where investigators and physicians need to understand which parts of a patient's record drive risk signals. To address this challenge, we introduce \textbf{CALM}, short for \textbf{Classification with Additive Large Language Models}, an interpretable framework for semi-structured text where inputs are composed of semantically meaningful components, such as sections of an admission note or question-answer fields from an intake form. CALM predicts outcomes as the additive sum of each component's contribution, making these contributions part of the forward computation itself and enabling faithful explanations at both the patient and population level. The additive structure also enables clear visualizations, such as component-level risk curves similar to those used in generalized additive models, making the learned relationships easier to inspect and communicate. Although CALM expects semi-structured inputs, many clinical documents already have this form, and similar structure can often be automatically extracted from free-text notes. CALM achieves performance comparable to conventional LLM classifiers while improving trust, supporting quality-assurance checks, and revealing clinically meaningful patterns during model development and auditing.

### 23. On the Notion that Language Models Reason

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Bertram H√∏jer
- **URL**: <http://arxiv.org/abs/2511.11810v1>
- **Submitted**: 2025-11-14 19:04:24
- **Comment**: Accepted at the 1st Workshop on Epistemic Intelligence in Machine Learning, EurIPS 2025
- **Topic Keywords**: search
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP), but it focuses on the notion of language models 'reasoning' and does not directly address query understanding, ranking models, or user behavior modeling. While it touches on the computational processes of NLP systems, it does not seem to be directly applicable to your core research themes in Information Retrieval and Search technologies.

#### Abstract
> Language models (LMs) are said to be exhibiting reasoning, but what does this entail? We assess definitions of reasoning and how key papers in the field of natural language processing (NLP) use the notion and argue that the definitions provided are not consistent with how LMs are trained, process information, and generate new tokens. To illustrate this incommensurability we assume the view that transformer-based LMs implement an \textit{implicit} finite-order Markov kernel mapping contexts to conditional token distributions. In this view, reasoning-like outputs correspond to statistical regularities and approximate statistical invariances in the learned kernel rather than the implementation of explicit logical mechanisms. This view is illustrative of the claim that LMs are "statistical pattern matchers"" and not genuine reasoners and provides a perspective that clarifies why reasoning-like outputs arise in LMs without any guarantees of logical consistency. This distinction is fundamental to how epistemic uncertainty is evaluated in LMs. We invite a discussion on the importance of how the computational processes of the systems we build and analyze in NLP research are described.

### 24. A Multimodal Manufacturing Safety Chatbot: Knowledge Base Design, Benchmark Development, and Evaluation of Multiple RAG Approaches

- **LLM Score**: 2
- **Keyword Score**: 8
- **Authors**: Ryan Singh, Austin Hamilton, Amanda White, Michael Wise, Ibrahim Yousif, Arthur Carvalho, Zhe Shan, Reza Abrisham Baf, Mohammad Mayyas, Lora A. Cavuoto, Fadel M. Megahed
- **URL**: <http://arxiv.org/abs/2511.11847v1>
- **Submitted**: 2025-11-14 20:10:23
- **Comment**: 25 pages, 5 figures
- **Topic Keywords**: query, rag, retrieval, search
- **Reason**: This paper focuses on a multimodal manufacturing safety chatbot, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve large language models and retrieval-augmented generation, the context and application are quite different from the user's areas of interest.

#### Abstract
> Ensuring worker safety remains a critical challenge in modern manufacturing environments. Industry 5.0 reorients the prevailing manufacturing paradigm toward more human-centric operations. Using a design science research methodology, we identify three essential requirements for next-generation safety training systems: high accuracy, low latency, and low cost. We introduce a multimodal chatbot powered by large language models that meets these design requirements. The chatbot uses retrieval-augmented generation to ground its responses in curated regulatory and technical documentation. To evaluate our solution, we developed a domain-specific benchmark of expert-validated question and answer pairs for three representative machines: a Bridgeport manual mill, a Haas TL-1 CNC lathe, and a Universal Robots UR5e collaborative robot. We tested 24 RAG configurations using a full-factorial design and assessed them with automated evaluations of correctness, latency, and cost. Our top 2 configurations were then evaluated by ten industry experts and academic researchers. Our results show that retrieval strategy and model configuration have a significant impact on performance. The top configuration (selected for chatbot deployment) achieved an accuracy of 86.66%, an average latency of 10.04 seconds, and an average cost of $0.005 per query. Overall, our work provides three contributions: an open-source, domain-grounded safety training chatbot; a validated benchmark for evaluating AI-assisted safety instruction; and a systematic methodology for designing and assessing AI-enabled instructional and immersive safety training systems for Industry 5.0 environments.

### 25. Mobile-Agent-RAG: Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Yuxiang Zhou, Jichang Li, Yanhao Zhang, Haonan Lu, Guanbin Li
- **URL**: <http://arxiv.org/abs/2511.12254v1>
- **Submitted**: 2025-11-15 15:22:42
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper focuses on multi-agent coordination and knowledge empowerment for mobile automation, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Mobile agents show immense potential, yet current state-of-the-art (SoTA) agents exhibit inadequate success rates on real-world, long-horizon, cross-application tasks. We attribute this bottleneck to the agents' excessive reliance on static, internal knowledge within MLLMs, which leads to two critical failure points: 1) strategic hallucinations in high-level planning and 2) operational errors during low-level execution on user interfaces (UI). The core insight of this paper is that high-level planning and low-level UI operations require fundamentally distinct types of knowledge. Planning demands high-level, strategy-oriented experiences, whereas operations necessitate low-level, precise instructions closely tied to specific app UIs. Motivated by these insights, we propose Mobile-Agent-RAG, a novel hierarchical multi-agent framework that innovatively integrates dual-level retrieval augmentation. At the planning stage, we introduce Manager-RAG to reduce strategic hallucinations by retrieving human-validated comprehensive task plans that provide high-level guidance. At the execution stage, we develop Operator-RAG to improve execution accuracy by retrieving the most precise low-level guidance for accurate atomic actions, aligned with the current app and subtask. To accurately deliver these knowledge types, we construct two specialized retrieval-oriented knowledge bases. Furthermore, we introduce Mobile-Eval-RAG, a challenging benchmark for evaluating such agents on realistic multi-app, long-horizon tasks. Extensive experiments demonstrate that Mobile-Agent-RAG significantly outperforms SoTA baselines, improving task completion rate by 11.0% and step efficiency by 10.2%, establishing a robust paradigm for context-aware, reliable multi-agent mobile automation.

### 26. AugAbEx : Way Forward for Extractive Case Summarization

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Purnima Bindal, Vikas Kumar, Sagar Rathore, Vasudha Bhatnagar
- **URL**: <http://arxiv.org/abs/2511.12290v1>
- **Submitted**: 2025-11-15 16:49:42
- **Comment**: 30 pages, under review in a Journal
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on extractive case summarization in the legal domain, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific application and goals are quite different from your areas of focus.

#### Abstract
> Summarization of legal judgments poses a heavy cognitive burden on law practitioners due to the complexity of the language, context-sensitive legal jargon, and the length of the document. Therefore, the automatic summarization of legal documents has attracted serious attention from natural language processing researchers. Since the abstractive summaries of legal documents generated by deep neural methods remain prone to the risk of misrepresenting nuanced legal jargon or overlooking key contextual details, we envisage a rising trend toward the use of extractive case summarizers.
  Given the high cost of human annotation for gold standard extractive summaries, we engineer a light and transparent pipeline that leverages existing abstractive gold standard summaries to create the corresponding extractive gold standard versions. The approach ensures that the experts` opinions ensconced in the original gold standard abstractive summaries are carried over to the transformed extractive summaries. We aim to augment seven existing case summarization datasets, which include abstractive summaries, by incorporating corresponding extractive summaries and create an enriched data resource for case summarization research community. To ensure the quality of the augmented extractive summaries, we perform an extensive comparative evaluation with the original abstractive gold standard summaries covering structural, lexical, and semantic dimensions. We also compare the domain-level information of the two summaries. We commit to release the augmented datasets in the public domain for use by the research community and believe that the resource will offer opportunities to advance the field of automatic summarization of legal documents.

### 27. Leveraging Large Language Models for Career Mobility Analysis: A Study of Gender, Race, and Job Change Using U.S. Online Resume Profiles

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Palakorn Achananuparp, Connie Xu, Yao Lu, Xavier Jayaraj Siddarth Ashok, Ee-Peng Lim
- **URL**: <http://arxiv.org/abs/2511.12010v1>
- **Submitted**: 2025-11-15 03:26:57
- **Comment**: Submitted to EPJ Data Science
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves large language models, the application is in career mobility analysis and occupation classification, which is unrelated to your primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> We present a large-scale analysis of career mobility of college-educated U.S. workers using online resume profiles to investigate how gender, race, and job change options are associated with upward mobility. This study addresses key research questions of how the job changes affect their upward career mobility, and how the outcomes of upward career mobility differ by gender and race. We address data challenges -- such as missing demographic attributes, missing wage data, and noisy occupation labels -- through various data processing and Artificial Intelligence (AI) methods. In particular, we develop a large language models (LLMs) based occupation classification method known as FewSOC that achieves accuracy significantly higher than the original occupation labels in the resume dataset. Analysis of 228,710 career trajectories reveals that intra-firm occupation change has been found to facilitate upward mobility most strongly, followed by inter-firm occupation change and inter-firm lateral move. Women and Black college graduates experience significantly lower returns from job changes than men and White peers. Multilevel sensitivity analyses confirm that these disparities are robust to cluster-level heterogeneity and reveal additional intersectional patterns.

### 28. Context-Emotion Aware Therapeutic Dialogue Generation: A Multi-component Reinforcement Learning Approach to Language Models for Mental Health Support

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Eric Hua Qing Zhang, Julia Ive
- **URL**: <http://arxiv.org/abs/2511.11884v1>
- **Submitted**: 2025-11-14 21:32:10
- **Topic Keywords**: relevance
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing, as it focuses on therapeutic dialogue generation for mental health support using reinforcement learning. While it involves language models, the context and application are quite different from your areas of interest.

#### Abstract
> Mental health illness represents a substantial global socioeconomic burden, with COVID-19 further exacerbating accessibility challenges and driving increased demand for telehealth mental health support. While large language models (LLMs) offer promising solutions through 24/7 availability and non-judgmental interactions, pre-trained models often lack the contextual and emotional awareness necessary for appropriate therapeutic responses. This paper investigated the application of supervised fine-tuning (SFT) and reinforcement learning (RL) techniques to enhance GPT-2's capacity for therapeutic dialogue generation. The methodology restructured input formats to enable simultaneous processing of contextual information and emotional states alongside user input, employing a multi-component reward function that aligned model outputs with professional therapist responses and annotated emotions. Results demonstrated improvements through reinforcement learning over baseline GPT-2 across multiple evaluation metrics: BLEU (0.0111), ROUGE-1 (0.1397), ROUGE-2 (0.0213), ROUGE-L (0.1317), and METEOR (0.0581). LLM evaluation confirmed high contextual relevance and professionalism, while reinforcement learning achieved 99.34% emotion accuracy compared to 66.96% for baseline GPT-2. These findings demonstrate reinforcement learning's effectiveness in developing therapeutic dialogue systems that can serve as valuable assistive tools for therapists while maintaining essential human clinical oversight.

### 29. Accepted with Minor Revisions: Value of AI-Assisted Scientific Writing

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sanchaita Hazra, Doeun Lee, Bodhisattwa Prasad Majumder, Sachin Kumar
- **URL**: <http://arxiv.org/abs/2511.12529v1>
- **Submitted**: 2025-11-16 09:49:01
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves Large Language Models, the focus is on their application in scientific writing, which is not a core area of your research.

#### Abstract
> Large Language Models have seen expanding application across domains, yet their effectiveness as assistive tools for scientific writing -- an endeavor requiring precision, multimodal synthesis, and domain expertise -- remains insufficiently understood. We examine the potential of LLMs to support domain experts in scientific writing, with a focus on abstract composition. We design an incentivized randomized controlled trial with a hypothetical conference setup where participants with relevant expertise are split into an author and reviewer pool. Inspired by methods in behavioral science, our novel incentive structure encourages authors to edit the provided abstracts to an acceptable quality for a peer-reviewed submission. Our 2x2 between-subject design expands into two dimensions: the implicit source of the provided abstract and the disclosure of it. We find authors make most edits when editing human-written abstracts compared to AI-generated abstracts without source attribution, often guided by higher perceived readability in AI generation. Upon disclosure of source information, the volume of edits converges in both source treatments. Reviewer decisions remain unaffected by the source of the abstract, but bear a significant correlation with the number of edits made. Careful stylistic edits, especially in the case of AI-generated abstracts, in the presence of source information, improve the chance of acceptance. We find that AI-generated abstracts hold potential to reach comparable levels of acceptability to human-written ones with minimal revision, and that perceptions of AI authorship, rather than objective quality, drive much of the observed editing behavior. Our findings reverberate the significance of source disclosure in collaborative scientific writing.

### 30. From Phonemes to Meaning: Evaluating Large Language Models on Tamil

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jeyarajalingam Varsha, Menan Velayuthan, Sumirtha Karunakaran, Rasan Nivethiga, Kengatharaiyer Sarveswaran
- **URL**: <http://arxiv.org/abs/2511.12387v1>
- **Submitted**: 2025-11-15 23:41:16
- **Comment**: 11 pages
- **Topic Keywords**: rag
- **Reason**: This paper focuses on evaluating Large Language Models on the Tamil language, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. While it involves Natural Language Processing, the specific application and scope are quite different from the user's core research interests.

#### Abstract
> Large Language Models (LLMs) have shown strong generalization across tasks in high-resource languages; however, their linguistic competence in low-resource and morphologically rich languages such as Tamil remains largely unexplored. Existing multilingual benchmarks often rely on translated English datasets, failing to capture the linguistic and cultural nuances of the target language. To address this gap, we introduce ILAKKANAM, the first Tamil-specific linguistic evaluation benchmark manually curated using 820 questions from Sri Lankan school-level Tamil subject examination papers. Each question is annotated by trained linguists under five linguistic categories and a factual knowledge category, spanning Grades 1--13 to ensure broad linguistic coverage. We evaluate both closed-source and open-source LLMs using a standardized evaluation framework. Our results show that Gemini 2.5 achieves the highest overall performance, while open-source models lag behind, highlighting the gap in linguistic grounding. Category- and grade-wise analyses reveal that all models perform well on lower-grade questions but show a clear decline as linguistic complexity increases. Further, no strong correlation is observed between a model's overall performance and its ability to identify linguistic categories, suggesting that performance may be driven by exposure rather than genuine understanding.

### 31. Seeing is Believing: Rich-Context Hallucination Detection for MLLMs via Backward Visual Grounding

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Pinxue Guo, Chongruo Wu, Xinyu Zhou, Lingyi Hong, Zhaoyu Chen, Jinglun Li, Kaixun Jiang, Sen-ching Samson Cheung, Wei Zhang, Wenqiang Zhang
- **URL**: <http://arxiv.org/abs/2511.12140v1>
- **Submitted**: 2025-11-15 10:11:13
- **Topic Keywords**: rag
- **Reason**: This paper focuses on hallucination detection in Multimodal Large Language Models (MLLMs), which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves deep semantic understanding, the context is specific to visual inputs and MLLMs, making it somewhat tangential to your primary focus.

#### Abstract
> Multimodal Large Language Models (MLLMs) have unlocked powerful cross-modal capabilities, but still significantly suffer from hallucinations. As such, accurate detection of hallucinations in MLLMs is imperative for ensuring their reliability in practical applications. To this end, guided by the principle of "Seeing is Believing", we introduce VBackChecker, a novel reference-free hallucination detection framework that verifies the consistency of MLLMgenerated responses with visual inputs, by leveraging a pixellevel Grounding LLM equipped with reasoning and referring segmentation capabilities. This reference-free framework not only effectively handles rich-context scenarios, but also offers interpretability. To facilitate this, an innovative pipeline is accordingly designed for generating instruction-tuning data (R-Instruct), featuring rich-context descriptions, grounding masks, and hard negative samples. We further establish R^2 -HalBench, a new hallucination benchmark for MLLMs, which, unlike previous benchmarks, encompasses real-world, rich-context descriptions from 18 MLLMs with high-quality annotations, spanning diverse object-, attribute, and relationship-level details. VBackChecker outperforms prior complex frameworks and achieves state-of-the-art performance on R^2 -HalBench, even rivaling GPT-4o's capabilities in hallucination detection. It also surpasses prior methods in the pixel-level grounding task, achieving over a 10% improvement. All codes, data, and models are available at https://github.com/PinxueGuo/VBackChecker.

### 32. Critical or Compliant? The Double-Edged Sword of Reasoning in Chain-of-Thought Explanations

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Eunkyu Park, Wesley Hanwen Deng, Vasudha Varadarajan, Mingxi Yan, Gunhee Kim, Maarten Sap, Motahhare Eslami
- **URL**: <http://arxiv.org/abs/2511.12001v1>
- **Submitted**: 2025-11-15 02:38:49
- **Comment**: Under review; 16 pages, 15 figures
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests as it focuses on Chain-of-Thought explanations in multimodal moral scenarios, specifically in vision language models, and their impact on user trust and error detection. The paper's topics, such as NLP systems and explanations, are related but not central to your core research themes in Information Retrieval and Search technologies. The paper's findings and recommendations are also not directly applicable to your areas of interest.

#### Abstract
> Explanations are often promoted as tools for transparency, but they can also foster confirmation bias; users may assume reasoning is correct whenever outputs appear acceptable. We study this double-edged role of Chain-of-Thought (CoT) explanations in multimodal moral scenarios by systematically perturbing reasoning chains and manipulating delivery tones. Specifically, we analyze reasoning errors in vision language models (VLMs) and how they impact user trust and the ability to detect errors. Our findings reveal two key effects: (1) users often equate trust with outcome agreement, sustaining reliance even when reasoning is flawed, and (2) the confident tone suppresses error detection while maintaining reliance, showing that delivery styles can override correctness. These results highlight how CoT explanations can simultaneously clarify and mislead, underscoring the need for NLP systems to provide explanations that encourage scrutiny and critical thinking rather than blind trust. All code will be released publicly.

### 33. SGuard-v1: Safety Guardrail for Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: JoonHo Lee, HyeonMin Cho, Jaewoong Yun, Hyunjae Lee, JunKyu Lee, Juree Seok
- **URL**: <http://arxiv.org/abs/2511.12497v1>
- **Submitted**: 2025-11-16 08:15:54
- **Comment**: Technical Report
- **Topic Keywords**: search
- **Reason**: This paper focuses on safety guardrails for Large Language Models, which is a topic related to NLP but not directly aligned with the user's primary research interests in Information Retrieval, query understanding, and ranking models. While it touches on conversational settings, it does not address the user's core areas of focus.

#### Abstract
> We present SGuard-v1, a lightweight safety guardrail for Large Language Models (LLMs), which comprises two specialized models to detect harmful content and screen adversarial prompts in human-AI conversational settings. The first component, ContentFilter, is trained to identify safety risks in LLM prompts and responses in accordance with the MLCommons hazard taxonomy, a comprehensive framework for trust and safety assessment of AI. The second component, JailbreakFilter, is trained with a carefully designed curriculum over integrated datasets and findings from prior work on adversarial prompting, covering 60 major attack types while mitigating false-unsafe classification. SGuard-v1 is built on the 2B-parameter Granite-3.3-2B-Instruct model that supports 12 languages. We curate approximately 1.4 million training instances from both collected and synthesized data and perform instruction tuning on the base model, distributing the curated data across the two component according to their designated functions. Through extensive evaluation on public and proprietary safety benchmarks, SGuard-v1 achieves state-of-the-art safety performance while remaining lightweight, thereby reducing deployment overhead. SGuard-v1 also improves interpretability for downstream use by providing multi-class safety predictions and their binary confidence scores. We release the SGuard-v1 under the Apache-2.0 License to enable further research and practical deployment in AI safety.

### 34. DenseAnnotate: Enabling Scalable Dense Caption Collection for Images and 3D Scenes via Spoken Descriptions

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Xiaoyu Lin, Aniket Ghorpade, Hansheng Zhu, Justin Qiu, Dea Rrozhani, Monica Lama, Mick Yang, Zixuan Bian, Ruohan Ren, Alan B. Hong, Jiatao Gu, Chris Callison-Burch
- **URL**: <http://arxiv.org/abs/2511.12452v1>
- **Submitted**: 2025-11-16 04:46:06
- **Topic Keywords**: search
- **Reason**: This paper focuses on multimodal large language models and dense annotation for images and 3D scenes, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context is more focused on multimodal data and annotation, rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> With the rapid adoption of multimodal large language models (MLLMs) across diverse applications, there is a pressing need for task-centered, high-quality training data. A key limitation of current training datasets is their reliance on sparse annotations mined from the Internet or entered via manual typing that capture only a fraction of an image's visual content. Dense annotations are more valuable but remain scarce. Traditional text-based annotation pipelines are poorly suited for creating dense annotations: typing limits expressiveness, slows annotation speed, and underrepresents nuanced visual features, especially in specialized areas such as multicultural imagery and 3D asset annotation. In this paper, we present DenseAnnotate, an audio-driven online annotation platform that enables efficient creation of dense, fine-grained annotations for images and 3D assets. Annotators narrate observations aloud while synchronously linking spoken phrases to image regions or 3D scene parts. Our platform incorporates speech-to-text transcription and region-of-attention marking. To demonstrate the effectiveness of DenseAnnotate, we conducted case studies involving over 1,000 annotators across two domains: culturally diverse images and 3D scenes. We curate a human-annotated multi-modal dataset of 3,531 images, 898 3D scenes, and 7,460 3D objects, with audio-aligned dense annotations in 20 languages, including 8,746 image captions, 2,000 scene captions, and 19,000 object captions. Models trained on this dataset exhibit improvements of 5% in multilingual, 47% in cultural alignment, and 54% in 3D spatial capabilities. Our results show that our platform offers a feasible approach for future vision-language research and can be applied to various tasks and diverse types of data.

### 35. VoiceCraft-X: Unifying Multilingual, Voice-Cloning Speech Synthesis and Speech Editing

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Zhisheng Zheng, Puyuan Peng, Anuj Diwan, Cong Phuoc Huynh, Xiaohang Sun, Zhu Liu, Vimal Bhat, David Harwath
- **URL**: <http://arxiv.org/abs/2511.12347v1>
- **Submitted**: 2025-11-15 20:27:25
- **Comment**: EMNLP 2025. Demo and code are available at https://zhishengzheng.com/voicecraft-x/
- **Topic Keywords**: korea
- **Reason**: This paper focuses on speech synthesis and editing, which is outside the primary scope of information retrieval and search technologies. While it involves some NLP aspects, the core topic is not directly related to query understanding, ranking models, or user behavior modeling, which are key areas of interest.

#### Abstract
> We introduce VoiceCraft-X, an autoregressive neural codec language model which unifies multilingual speech editing and zero-shot Text-to-Speech (TTS) synthesis across 11 languages: English, Mandarin, Korean, Japanese, Spanish, French, German, Dutch, Italian, Portuguese, and Polish. VoiceCraft-X utilizes the Qwen3 large language model for phoneme-free cross-lingual text processing and a novel token reordering mechanism with time-aligned text and speech tokens to handle both tasks as a single sequence generation problem. The model generates high-quality, natural-sounding speech, seamlessly creating new audio or editing existing recordings within one framework. VoiceCraft-X shows robust performance in diverse linguistic settings, even with limited per-language data, underscoring the power of unified autoregressive approaches for advancing complex, real-world multilingual speech applications. Audio samples are available at https://zhishengzheng.com/voicecraft-x/.

### 36. A Reasoning Paradigm for Named Entity Recognition

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Hui Huang, Yanping Chen, Ruizhang Huang, Chuan Lin, Yongbin Qin
- **URL**: <http://arxiv.org/abs/2511.11978v1>
- **Submitted**: 2025-11-15 01:31:43
- **Comment**: Accepted at AAAI 2026
- **Topic Keywords**: search
- **Reason**: This paper focuses on Named Entity Recognition (NER) using a reasoning framework, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific application and methodology are not aligned with the user's primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Generative LLMs typically improve Named Entity Recognition (NER) performance through instruction tuning. They excel at generating entities by semantic pattern matching but lack an explicit, verifiable reasoning mechanism. This "cognitive shortcutting" leads to suboptimal performance and brittle generalization, especially in zero-shot and lowresource scenarios where reasoning from limited contextual cues is crucial. To address this issue, a reasoning framework is proposed for NER, which shifts the extraction paradigm from implicit pattern matching to explicit reasoning. This framework consists of three stages: Chain of Thought (CoT) generation, CoT tuning, and reasoning enhancement. First, a dataset annotated with NER-oriented CoTs is generated, which contain task-relevant reasoning chains. Then, they are used to tune the NER model to generate coherent rationales before deriving the final answer. Finally, a reasoning enhancement stage is implemented to optimize the reasoning process using a comprehensive reward signal. This stage ensures explicit and verifiable extractions. Experiments show that ReasoningNER demonstrates impressive cognitive ability in the NER task, achieving competitive performance. In zero-shot settings, it achieves state-of-the-art (SOTA) performance, outperforming GPT-4 by 12.3 percentage points on the F1 score. Analytical results also demonstrate its great potential to advance research in reasoningoriented information extraction. Our codes are available at https://github.com/HuiResearch/ReasoningIE.

### 37. Identifying Imaging Follow-Up in Radiology Reports: A Comparative Analysis of Traditional ML and LLM Approaches

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Namu Park, Giridhar Kaushik Ramachandran, Kevin Lybarger, Fei Xia, Ozlem Uzuner, Meliha Yetisgen, Martin Gunn
- **URL**: <http://arxiv.org/abs/2511.11867v1>
- **Submitted**: 2025-11-14 20:55:44
- **Comment**: Submitted to LREC 2026
- **Topic Keywords**: recommend
- **Reason**: This paper focuses on clinical natural language processing and radiology reports, which is outside the user's primary research interests in Information Retrieval and Search technologies. While it involves machine learning and large language models, the application domain and task are not directly related to the user's core themes.

#### Abstract
> Large language models (LLMs) have shown considerable promise in clinical natural language processing, yet few domain-specific datasets exist to rigorously evaluate their performance on radiology tasks. In this work, we introduce an annotated corpus of 6,393 radiology reports from 586 patients, each labeled for follow-up imaging status, to support the development and benchmarking of follow-up adherence detection systems. Using this corpus, we systematically compared traditional machine-learning classifiers, including logistic regression (LR), support vector machines (SVM), Longformer, and a fully fine-tuned Llama3-8B-Instruct, with recent generative LLMs. To evaluate generative LLMs, we tested GPT-4o and the open-source GPT-OSS-20B under two configurations: a baseline (Base) and a task-optimized (Advanced) setting that focused inputs on metadata, recommendation sentences, and their surrounding context. A refined prompt for GPT-OSS-20B further improved reasoning accuracy. Performance was assessed using precision, recall, and F1 scores with 95% confidence intervals estimated via non-parametric bootstrapping. Inter-annotator agreement was high (F1 = 0.846). GPT-4o (Advanced) achieved the best performance (F1 = 0.832), followed closely by GPT-OSS-20B (Advanced; F1 = 0.828). LR and SVM also performed strongly (F1 = 0.776 and 0.775), underscoring that while LLMs approach human-level agreement through prompt optimization, interpretable and resource-efficient models remain valuable baselines.

---

