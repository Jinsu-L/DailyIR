# Daily Papers Report - 2025-07-29

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Industry Insights from Comparing Deep Learning and GBDT Models for E-Commerce Learning-to-Rank

- **LLM Score**: 7
- **Keyword Score**: 10
- **Authors**: Yunus Lutz, Timo Wilm, Philipp Duwe
- **URL**: <http://arxiv.org/abs/2507.20753v1>
- **Submitted**: 2025-07-28 12:02:02
- **Comment**: This work was accepted for publication in the 19th ACM Conference on
  Recommender Systems (RecSys 2025). The final published version will be
  available at the ACM Digital Library
- **Topic Keywords**: ltr, click, recommend, commerce, e-commerce, rank, search
- **Reason**: The paper is relevant to your research interests in Information Retrieval, specifically Learning-to-Rank, as it compares deep learning and GBDT models for LTR tasks in e-commerce. The focus on query understanding and ranking models aligns with your interests. However, the paper's scope is limited to e-commerce and does not explore user behavior modeling or deep semantic understanding, which are important aspects of your research.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Deep Neural Networks for E-commerce Learning-to-Rank Tasks
- **Aim**: To evaluate the performance of deep neural networks (DNNs) in e-commerce Learning-to-Rank (LTR) tasks and compare them to traditional tree-based models
- **Rationale**: Existing Large-scale Transactional Recommendation (LTR) datasets lack representation of real-world e-commerce applications, and DNNs have not been systematically evaluated for large-scale e-commerce LTR tasks
- **Ground**: The study uses a large-scale proprietary dataset from OTTO and validates the findings through an 8-week online A/B test
- **Experiment**: The study evaluates multiple DNN architectures and loss functions, including Two-Tower, Cross-Encoder, Transformer, RankNet, and Softmax Cross-Entropy, and proposes a novel loss function, LCE
- **Takeaway**: Deep learning approaches can serve as a viable alternative to GBDT-based models in industrial ranking systems, outperforming traditional tree-based models in terms of engagement metrics while maintaining parity in units sold

#### Abstract
> In e-commerce recommender and search systems, tree-based models, such as
LambdaMART, have set a strong baseline for Learning-to-Rank (LTR) tasks.
Despite their effectiveness and widespread adoption in industry, the debate
continues whether deep neural networks (DNNs) can outperform traditional
tree-based models in this domain. To contribute to this discussion, we
systematically benchmark DNNs against our production-grade LambdaMART model. We
evaluate multiple DNN architectures and loss functions on a proprietary dataset
from OTTO and validate our findings through an 8-week online A/B test. The
results show that a simple DNN architecture outperforms a strong tree-based
baseline in terms of total clicks and revenue, while achieving parity in total
units sold.

---

### 2. When Scale Meets Diversity: Evaluating Language Models on Fine-Grained Multilingual Claim Verification

- **LLM Score**: 6
- **Keyword Score**: 2
- **Authors**: Hanna Shcharbakova, Tatiana Anikina, Natalia Skachkova, Josef van Genabith
- **URL**: <http://arxiv.org/abs/2507.20700v1>
- **Submitted**: 2025-07-28 10:49:04
- **Comment**: Published at the FEVER Workshop, ACL 2025
- **Topic Keywords**: rag
- **Reason**: The paper evaluates language models for multilingual claim verification, which is related to information retrieval and natural language processing. While it doesn't directly focus on query understanding, ranking models, or user behavior modeling, it explores the effectiveness of different language models, which is relevant to the broader field of information retrieval. However, the paper's focus on fine-grained multilingual claim verification is somewhat niche and not directly aligned with the user's primary research interests.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Fine-grained Multilingual Claim Verification
- **Aim**: Evaluating the performance of various language models on fine-grained multilingual claim verification
- **Rationale**: Assessing the veracity of claims across diverse languages and nuanced classification schemes is a challenging task, and existing language models have limitations in effectively utilizing evidence and handling nuanced veracity categories
- **Ground**: The X-Fact dataset, a comprehensive collection of fact-checking claims from various sources, is used to evaluate the performance of five state-of-the-art language models
- **Experiment**: The models are fine-tuned and evaluated under two conditions: using claims alone and using claims with accompanying evidence text, with results showing a substantial performance gap between encoder-based and decoder-only architectures
- **Takeaway**: Smaller, specialized models may be more effective than general-purpose large models for fine-grained multilingual fact verification, with important implications for practical deployment of fact-checking systems

#### Abstract
> The rapid spread of multilingual misinformation requires robust automated
fact verification systems capable of handling fine-grained veracity assessments
across diverse languages. While large language models have shown remarkable
capabilities across many NLP tasks, their effectiveness for multilingual claim
verification with nuanced classification schemes remains understudied. We
conduct a comprehensive evaluation of five state-of-the-art language models on
the X-Fact dataset, which spans 25 languages with seven distinct veracity
categories. Our experiments compare small language models (encoder-based XLM-R
and mT5) with recent decoder-only LLMs (Llama 3.1, Qwen 2.5, Mistral Nemo)
using both prompting and fine-tuning approaches. Surprisingly, we find that
XLM-R (270M parameters) substantially outperforms all tested LLMs (7-12B
parameters), achieving 57.7% macro-F1 compared to the best LLM performance of
16.9%. This represents a 15.8% improvement over the previous state-of-the-art
(41.9%), establishing new performance benchmarks for multilingual fact
verification. Our analysis reveals problematic patterns in LLM behavior,
including systematic difficulties in leveraging evidence and pronounced biases
toward frequent categories in imbalanced data settings. These findings suggest
that for fine-grained multilingual fact verification, smaller specialized
models may be more effective than general-purpose large models, with important
implications for practical deployment of fact-checking systems.

---

### 3. Speaking in Words, Thinking in Logic: A Dual-Process Framework in QA Systems

- **LLM Score**: 6
- **Keyword Score**: 2
- **Authors**: Tuan Bui, Trong Le, Phat Thai, Sang Nguyen, Minh Hua, Ngan Pham, Thang Bui, Tho Quan
- **URL**: <http://arxiv.org/abs/2507.20491v1>
- **Submitted**: 2025-07-28 03:00:35
- **Comment**: 8 pages, 3 figures. Accepted at the International Joint Conference on
  Neural Networks (IJCNN) 2025, Workshop on Trustworthiness and Reliability in
  Neuro-Symbolic AI. https://2025.ijcnn.org
- **Topic Keywords**: rag
- **Reason**: The paper explores a novel framework for converting natural language into first-order logic, which is relevant to information retrieval and query understanding. However, the focus on question-answering systems and the lack of direct connection to search technologies and ranking models limit its alignment with the user's primary research interests.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Natural Language to First-Order Logic (NL2FOL) Conversion in Question-Answering Systems
- **Aim**: To develop a novel framework for converting natural language into first-order logic (NL2FOL) in question-answering (QA) systems
- **Rationale**: To address the limitations of existing neural-symbolic (NeSy) approaches and enable robust logical inference using the Z3 solver
- **Ground**: Dual-system cognitive theory, emulating System 1 and System 2 to achieve accurate and interpretable reasoning
- **Experiment**: Extensive empirical evaluations on domain-specific datasets, demonstrating competitive performance with significantly lower computational overhead compared to larger LLM-based systems
- **Takeaway**: The Text-JEPA framework offers a lightweight yet effective architecture for converting NL to FOL, outperforming larger LLM-based baselines in conversion accuracy and generalization

#### Abstract
> Recent advances in large language models (LLMs) have significantly enhanced
question-answering (QA) capabilities, particularly in open-domain contexts.
However, in closed-domain scenarios such as education, healthcare, and law,
users demand not only accurate answers but also transparent reasoning and
explainable decision-making processes. While neural-symbolic (NeSy) frameworks
have emerged as a promising solution, leveraging LLMs for natural language
understanding and symbolic systems for formal reasoning, existing approaches
often rely on large-scale models and exhibit inefficiencies in translating
natural language into formal logic representations.
  To address these limitations, we introduce Text-JEPA (Text-based
Joint-Embedding Predictive Architecture), a lightweight yet effective framework
for converting natural language into first-order logic (NL2FOL). Drawing
inspiration from dual-system cognitive theory, Text-JEPA emulates System 1 by
efficiently generating logic representations, while the Z3 solver operates as
System 2, enabling robust logical inference. To rigorously evaluate the
NL2FOL-to-reasoning pipeline, we propose a comprehensive evaluation framework
comprising three custom metrics: conversion score, reasoning score, and
Spearman rho score, which collectively capture the quality of logical
translation and its downstream impact on reasoning accuracy.
  Empirical results on domain-specific datasets demonstrate that Text-JEPA
achieves competitive performance with significantly lower computational
overhead compared to larger LLM-based systems. Our findings highlight the
potential of structured, interpretable reasoning frameworks for building
efficient and explainable QA systems in specialized domains.

---

### 4. On The Role of Pretrained Language Models in General-Purpose Text Embeddings: A Survey

- **LLM Score**: 4
- **Keyword Score**: 12
- **Authors**: Meishan Zhang, Xin Zhang, Xinping Zhao, Shouzheng Huang, Baotian Hu, Min Zhang
- **URL**: <http://arxiv.org/abs/2507.20783v1>
- **Submitted**: 2025-07-28 12:52:24
- **Comment**: 45 pages, 2 figures, 9 tables
- **Topic Keywords**: ranking, pairwise, rag, retrieval, rank, search
- **Reason**: The paper discusses the role of pretrained language models in general-purpose text embeddings, which is a topic in Natural Language Processing (NLP). While it touches on the concept of embeddings, it does not specifically focus on query understanding, ranking models, or user behavior modeling, which are key areas of interest in Information Retrieval (IR). The paper's scope is broader and more general, making it only loosely relevant to the user's research interests.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: General-purpose Text Embeddings (GPTE) leveraging Pretrained Language Models (PLMs)
- **Aim**: Provide a comprehensive overview of GPTE in the era of PLMs
- **Rationale**: GPTE architecture involves using PLMs to derive dense text representations, optimized through contrastive learning on large-scale pairwise datasets
- **Ground**: PLMs play fundamental and advanced roles in GPTE, including embedding extraction, expressivity enhancement, training strategies, learning objectives, data construction, multilingual support, multimodal integration, code understanding, and scenario-specific adaptation
- **Experiment**: Not applicable (survey paper)
- **Takeaway**: Future research directions include ranking integration, safety considerations, bias mitigation, structural information incorporation, and the cognitive extension of embeddings

#### Abstract
> Text embeddings have attracted growing interest due to their effectiveness
across a wide range of natural language processing (NLP) tasks, such as
retrieval, classification, clustering, bitext mining, and summarization. With
the emergence of pretrained language models (PLMs), general-purpose text
embeddings (GPTE) have gained significant traction for their ability to produce
rich, transferable representations. The general architecture of GPTE typically
leverages PLMs to derive dense text representations, which are then optimized
through contrastive learning on large-scale pairwise datasets. In this survey,
we provide a comprehensive overview of GPTE in the era of PLMs, focusing on the
roles PLMs play in driving its development. We first examine the fundamental
architecture and describe the basic roles of PLMs in GPTE, i.e., embedding
extraction, expressivity enhancement, training strategies, learning objectives,
and data construction. Then, we describe advanced roles enabled by PLMs, such
as multilingual support, multimodal integration, code understanding, and
scenario-specific adaptation. Finally, we highlight potential future research
directions that move beyond traditional improvement goals, including ranking
integration, safety considerations, bias mitigation, structural information
incorporation, and the cognitive extension of embeddings. This survey aims to
serve as a valuable reference for both newcomers and established researchers
seeking to understand the current state and future potential of GPTE.

---

### 5. CONCAP: Seeing Beyond English with Concepts Retrieval-Augmented Captioning

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: George Ibrahim, Rita Ramos, Yova Kementchedjhieva
- **URL**: <http://arxiv.org/abs/2507.20411v1>
- **Submitted**: 2025-07-27 21:00:02
- **Comment**: Published as a conference paper at COLM 2025
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on multilingual image captioning, which is not directly related to my primary research interests in Information Retrieval and Search technologies. While it touches on retrieval-augmented generation, the context is different from my usual focus on query understanding, ranking models, and user behavior modeling. The paper's emphasis on multilingual vision-language models and concept-aware retrieval augmentation is interesting, but not directly applicable to my research areas.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Multilingual Image Captioning
- **Aim**: To alleviate the need for extensive multilingual training data and costly large-scale model parameterization in image captioning
- **Rationale**: Integrating retrieved captions with image-specific concepts to enhance contextualization and grounding across different languages
- **Ground**: XM3600 dataset, a human-annotated multilingual benchmark featuring captions in 36 languages
- **Experiment**: Evaluating CONCAP on XM3600 dataset, comparing with baselines, and analyzing individual contribution of CONCAP's components
- **Takeaway**: CONCAP outperforms all baselines by a large margin, and concept-aware retrieval augmentation is key to its impressive performance

#### Abstract
> Multilingual vision-language models have made significant strides in image
captioning, yet they still lag behind their English counterparts due to limited
multilingual training data and costly large-scale model parameterization.
Retrieval-augmented generation (RAG) offers a promising alternative by
conditioning caption generation on retrieved examples in the target language,
reducing the need for extensive multilingual training. However, multilingual
RAG captioning models often depend on retrieved captions translated from
English, which can introduce mismatches and linguistic biases relative to the
source language. We introduce CONCAP, a multilingual image captioning model
that integrates retrieved captions with image-specific concepts, enhancing the
contextualization of the input image and grounding the captioning process
across different languages. Experiments on the XM3600 dataset indicate that
CONCAP enables strong performance on low- and mid-resource languages, with
highly reduced data requirements. Our findings highlight the effectiveness of
concept-aware retrieval augmentation in bridging multilingual performance gaps.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Multi-Agent-as-Judge: Aligning LLM-Agent-Based Automated Evaluation with Multi-Dimensional Human Evaluation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Jiaju Chen, Yuxuan Lu, Xiaojie Wang, Huimin Zeng, Jing Huang, Jiri Gesi, Ying Xu, Bingsheng Yao, Dakuo Wang
- **URL**: <http://arxiv.org/abs/2507.21028v1>
- **Submitted**: 2025-07-28 17:48:40
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on leveraging Large Language Model (LLM) agents to simulate human evaluators, which is not directly related to Information Retrieval or Search technologies. While it touches on NLP, the primary focus is on evaluation frameworks and multi-dimensional human perspectives, which is not a central match for your research interests.

#### Abstract
> Nearly all human work is collaborative; thus, the evaluation of real-world
NLP applications often requires multiple dimensions that align with diverse
human perspectives. As real human evaluator resources are often scarce and
costly, the emerging "LLM-as-a-judge" paradigm sheds light on a promising
approach to leverage LLM agents to believably simulate human evaluators. Yet,
to date, existing LLM-as-a-judge approaches face two limitations: persona
descriptions of agents are often arbitrarily designed, and the frameworks are
not generalizable to other tasks. To address these challenges, we propose
MAJ-EVAL, a Multi-Agent-as-Judge evaluation framework that can automatically
construct multiple evaluator personas with distinct dimensions from relevant
text documents (e.g., research papers), instantiate LLM agents with the
personas, and engage in-group debates with multi-agents to Generate
multi-dimensional feedback. Our evaluation experiments in both the educational
and medical domains demonstrate that MAJ-EVAL can generate evaluation results
that better align with human experts' ratings compared with conventional
automated evaluation metrics and existing LLM-as-a-judge methods.

### 7. Modeling User Behavior from Adaptive Surveys with Supplemental Context

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Aman Shukla, Daniel Patrick Scantlebury, Rishabh Kumar
- **URL**: <http://arxiv.org/abs/2507.20919v1>
- **Submitted**: 2025-07-28 15:19:54
- **Comment**: Best Paper, NewInML @ ICML 2025
- **Topic Keywords**: user behavior, personalization
- **Reason**: The paper focuses on modeling user behavior from adaptive surveys, which is related to user behavior modeling in search technologies. However, the paper's primary focus is on survey-based data collection and modeling, which is not directly aligned with my interests in query understanding, ranking models, and real-time relevance optimization in information retrieval.

#### Abstract
> Modeling user behavior is critical across many industries where understanding
preferences, intent, or decisions informs personalization, targeting, and
strategic outcomes. Surveys have long served as a classical mechanism for
collecting such behavioral data due to their interpretability, structure, and
ease of deployment. However, surveys alone are inherently limited by user
fatigue, incomplete responses, and practical constraints on their length making
them insufficient for capturing user behavior. In this work, we present LANTERN
(Late-Attentive Network for Enriched Response Modeling), a modular architecture
for modeling user behavior by fusing adaptive survey responses with
supplemental contextual signals. We demonstrate the architectural value of
maintaining survey primacy through selective gating, residual connections and
late fusion via cross-attention, treating survey data as the primary signal
while incorporating external modalities only when relevant. LANTERN outperforms
strong survey-only baselines in multi-label prediction of survey responses. We
further investigate threshold sensitivity and the benefits of selective
modality reliance through ablation and rare/frequent attribute analysis.
LANTERN's modularity supports scalable integration of new encoders and evolving
datasets. This work provides a practical and extensible blueprint for behavior
modeling in survey-centric applications.

### 8. Latent Inter-User Difference Modeling for LLM Personalization

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Yilun Qiu, Tianhao Shi, Xiaoyan Zhao, Fengbin Zhu, Yang Zhang, Fuli Feng
- **URL**: <http://arxiv.org/abs/2507.20849v1>
- **Submitted**: 2025-07-28 14:00:57
- **Topic Keywords**: rag, personalization
- **Reason**: The paper focuses on personalization in large language models, which is related to search technologies and user behavior modeling. However, the specific approach of modeling inter-user differences in the latent space is not directly aligned with my research interests in query understanding, ranking models, and click models. While the paper touches on user behavior, it does not explore the topics of query understanding, ranking, or click models.

#### Abstract
> Large language models (LLMs) are increasingly integrated into users' daily
lives, leading to a growing demand for personalized outputs. Previous work
focuses on leveraging a user's own history, overlooking inter-user differences
that are crucial for effective personalization. While recent work has attempted
to model such differences, the reliance on language-based prompts often hampers
the effective extraction of meaningful distinctions. To address these issues,
we propose Difference-aware Embedding-based Personalization (DEP), a framework
that models inter-user differences in the latent space instead of relying on
language prompts. DEP constructs soft prompts by contrasting a user's embedding
with those of peers who engaged with similar content, highlighting relative
behavioral signals. A sparse autoencoder then filters and compresses both
user-specific and difference-aware embeddings, preserving only task-relevant
features before injecting them into a frozen LLM. Experiments on personalized
review generation show that DEP consistently outperforms baseline methods
across multiple metrics. Our code is available at
https://github.com/SnowCharmQ/DEP.

### 9. Ontology-Enhanced Knowledge Graph Completion using Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Wenbin Guo, Xin Wang, Jiaoyan Chen, Zhao Li, Zirui Chen
- **URL**: <http://arxiv.org/abs/2507.20643v1>
- **Submitted**: 2025-07-28 09:00:48
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on Knowledge Graph Completion using Large Language Models, which is not directly related to Information Retrieval or Search technologies. While it mentions neural-perceptual structural information, it does not address query understanding, ranking models, or user behavior modeling, which are core aspects of my research interests. The paper's relevance is limited to the intersection of NLP and data mining, but it does not explore real-time relevance optimization or deep semantic understanding.

#### Abstract
> Large Language Models (LLMs) have been extensively adopted in Knowledge Graph
Completion (KGC), showcasing significant research advancements. However, as
black-box models driven by deep neural architectures, current LLM-based KGC
methods rely on implicit knowledge representation with parallel propagation of
erroneous knowledge, thereby hindering their ability to produce conclusive and
decisive reasoning outcomes. We aim to integrate neural-perceptual structural
information with ontological knowledge, leveraging the powerful capabilities of
LLMs to achieve a deeper understanding of the intrinsic logic of the knowledge.
We propose an ontology enhanced KGC method using LLMs -- OL-KGC. It first
leverages neural perceptual mechanisms to effectively embed structural
information into the textual space, and then uses an automated extraction
algorithm to retrieve ontological knowledge from the knowledge graphs (KGs)
that needs to be completed, which is further transformed into a textual format
comprehensible to LLMs for providing logic guidance. We conducted extensive
experiments on three widely-used benchmarks -- FB15K-237, UMLS and WN18RR. The
experimental results demonstrate that OL-KGC significantly outperforms existing
mainstream KGC methods across multiple evaluation metrics, achieving
state-of-the-art performance.

### 10. Soft Injection of Task Embeddings Outperforms Prompt-Based In-Context Learning

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Jungwon Park, Wonjong Rhee
- **URL**: <http://arxiv.org/abs/2507.20906v2>
- **Submitted**: 2025-07-28 14:59:17
- **Comment**: Preprint
- **Topic Keywords**: rag
- **Reason**: The paper explores a novel approach to task embeddings and in-context learning, which is related to Natural Language Processing (NLP) and Large Language Models (LLMs). However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core aspects of Information Retrieval (IR) and Search technologies. The paper's focus on task embeddings and attention heads is somewhat relevant to IR, but the connection is not strong enough to warrant a higher score.

#### Abstract
> In-Context Learning (ICL) enables Large Language Models (LLMs) to perform
tasks by conditioning on input-output examples in the prompt, without requiring
any update in model parameters. While widely adopted, it remains unclear
whether prompting with multiple examples is the most effective and efficient
way to convey task information. In this work, we propose Soft Injection of task
embeddings. The task embeddings are constructed only once using few-shot ICL
prompts and repeatedly used during inference. Soft injection is performed by
softly mixing task embeddings with attention head activations using
pre-optimized mixing parameters, referred to as soft head-selection parameters.
This method not only allows a desired task to be performed without in-prompt
demonstrations but also significantly outperforms existing ICL approaches while
reducing memory usage and compute cost at inference time. An extensive
evaluation is performed across 57 tasks and 12 LLMs, spanning four model
families of sizes from 4B to 70B. Averaged across 57 tasks, our method
outperforms 10-shot ICL by 10.2%-14.3% across 12 LLMs. Additional analyses show
that our method also serves as an insightful tool for analyzing task-relevant
roles of attention heads, revealing that task-relevant head positions selected
by our method transfer across similar tasks but not across dissimilar ones --
underscoring the task-specific nature of head functionality. Our soft injection
method opens a new paradigm for reducing prompt length and improving task
performance by shifting task conditioning from the prompt space to the
activation space.

### 11. A survey of diversity quantification in natural language processing: The why, what, where and how

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Louis Est√®ve, Marie-Catherine de Marneffe, Nurit Melnik, Agata Savary, Olha Kanishcheva
- **URL**: <http://arxiv.org/abs/2507.20858v1>
- **Submitted**: 2025-07-28 14:12:34
- **Topic Keywords**: acl
- **Reason**: The paper is somewhat related to your research interests in Natural Language Processing (NLP), but it focuses on diversity quantification in NLP, which is a specific topic that doesn't directly align with your primary focus on Information Retrieval and Search technologies. While the paper's unified taxonomy and framework might be of interest, it doesn't address query understanding, ranking models, or user behavior modeling, which are key areas of your research.

#### Abstract
> The concept of diversity has received increased consideration in Natural
Language Processing (NLP) in recent years. This is due to various motivations
like promoting and inclusion, approximating human linguistic behavior, and
increasing systems' performance. Diversity has however often been addressed in
an ad hoc manner in NLP, and with few explicit links to other domains where
this notion is better theorized. We survey articles in the ACL Anthology from
the past 6 years, with "diversity" or "diverse" in their title. We find a wide
range of settings in which diversity is quantified, often highly specialized
and using inconsistent terminology. We put forward a unified taxonomy of why,
what on, where, and how diversity is measured in NLP. Diversity measures are
cast upon a unified framework from ecology and economy (Stirling, 2007) with 3
dimensions of diversity: variety, balance and disparity. We discuss the trends
which emerge due to this systematized approach. We believe that this study
paves the way towards a better formalization of diversity in NLP, which should
bring a better understanding of this notion and a better comparability between
various approaches.

### 12. Multilingual Self-Taught Faithfulness Evaluators

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Carlo Alfano, Aymen Al Marjani, Zeno Jonke, Amin Mantrach, Saab Mansour, Marcello Federico
- **URL**: <http://arxiv.org/abs/2507.20752v1>
- **Submitted**: 2025-07-28 12:01:59
- **Topic Keywords**: rag
- **Reason**: The paper focuses on multilingual faithfulness evaluators, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on language models, it does not explore ranking models or user behavior modeling. The paper's relevance is limited to the NLP domain, but it does not specifically address deep semantic understanding or real-time relevance optimization.

#### Abstract
> The growing use of large language models (LLMs) has increased the need for
automatic evaluation systems, particularly to address the challenge of
information hallucination. Although existing faithfulness evaluation approaches
have shown promise, they are predominantly English-focused and often require
expensive human-labeled training data for fine-tuning specialized models. As
LLMs see increased adoption in multilingual contexts, there is a need for
accurate faithfulness evaluators that can operate across languages without
extensive labeled data. This paper presents Self-Taught Evaluators for
Multilingual Faithfulness, a framework that learns exclusively from synthetic
multilingual summarization data while leveraging cross-lingual transfer
learning. Through experiments comparing language-specific and mixed-language
fine-tuning approaches, we demonstrate a consistent relationship between an
LLM's general language capabilities and its performance in language-specific
evaluation tasks. Our framework shows improvements over existing baselines,
including state-of-the-art English evaluators and machine translation-based
approaches.

### 13. Survey of NLU Benchmarks Diagnosing Linguistic Phenomena: Why not Standardize Diagnostics Benchmarks?

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Khloud AL Jallad, Nada Ghneim, Ghaida Rebdawi
- **URL**: <http://arxiv.org/abs/2507.20419v1>
- **Submitted**: 2025-07-27 21:30:50
- **Topic Keywords**: search
- **Reason**: The paper is somewhat related to your research interests in NLP and IR, as it discusses NLU benchmarks and diagnostics datasets. However, the focus is more on the evaluation of NLU capabilities and the development of benchmarks, rather than query understanding, ranking models, or user behavior modeling, which are your primary areas of interest.

#### Abstract
> Natural Language Understanding (NLU) is a basic task in Natural Language
Processing (NLP). The evaluation of NLU capabilities has become a trending
research topic that attracts researchers in the last few years, resulting in
the development of numerous benchmarks. These benchmarks include various tasks
and datasets in order to evaluate the results of pretrained models via public
leaderboards. Notably, several benchmarks contain diagnostics datasets designed
for investigation and fine-grained error analysis across a wide range of
linguistic phenomena. This survey provides a comprehensive review of available
English, Arabic, and Multilingual NLU benchmarks, with a particular emphasis on
their diagnostics datasets and the linguistic phenomena they covered. We
present a detailed comparison and analysis of these benchmarks, highlighting
their strengths and limitations in evaluating NLU tasks and providing in-depth
error analysis. When highlighting the gaps in the state-of-the-art, we noted
that there is no naming convention for macro and micro categories or even a
standard set of linguistic phenomena that should be covered. Consequently, we
formulated a research question regarding the evaluation metrics of the
evaluation diagnostics benchmarks: "Why do not we have an evaluation standard
for the NLU evaluation diagnostics benchmarks?" similar to ISO standard in
industry. We conducted a deep analysis and comparisons of the covered
linguistic phenomena in order to support experts in building a global hierarchy
for linguistic phenomena in future. We think that having evaluation metrics for
diagnostics evaluation could be valuable to gain more insights when comparing
the results of the studied models on different diagnostics benchmarks.

### 14. Memorization in Fine-Tuned Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Danil Savine, Muni Sreenivas Pydi, Jamal Atif, Olivier Capp√©
- **URL**: <http://arxiv.org/abs/2507.21009v1>
- **Submitted**: 2025-07-28 17:22:10
- **Topic Keywords**: query, rank, search
- **Reason**: This paper focuses on the memorization of fine-tuned large language models in the medical domain, which is not directly related to information retrieval, search technologies, or query understanding. The paper's emphasis on language models, transformer architecture, and data privacy concerns is outside the scope of the user's primary research interests.

#### Abstract
> This study investigates the mechanisms and factors influencing memorization
in fine-tuned large language models (LLMs), with a focus on the medical domain
due to its privacy-sensitive nature. We examine how different aspects of the
fine-tuning process affect a model's propensity to memorize training data,
using the PHEE dataset of pharmacovigilance events.
  Our research employs two main approaches: a membership inference attack to
detect memorized data, and a generation task with prompted prefixes to assess
verbatim reproduction. We analyze the impact of adapting different weight
matrices in the transformer architecture, the relationship between perplexity
and memorization, and the effect of increasing the rank in low-rank adaptation
(LoRA) fine-tuning.
  Key findings include: (1) Value and Output matrices contribute more
significantly to memorization compared to Query and Key matrices; (2) Lower
perplexity in the fine-tuned model correlates with increased memorization; (3)
Higher LoRA ranks lead to increased memorization, but with diminishing returns
at higher ranks.
  These results provide insights into the trade-offs between model performance
and privacy risks in fine-tuned LLMs. Our findings have implications for
developing more effective and responsible strategies for adapting large
language models while managing data privacy concerns.

### 15. Enhancing Project-Specific Code Completion by Inferring Internal API Information

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Le Deng, Xiaoxue Ren, Chao Ni, Ming Liang, David Lo, Zhongxin Liu
- **URL**: <http://arxiv.org/abs/2507.20888v1>
- **Submitted**: 2025-07-28 14:39:46
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on code completion, which is not directly related to information retrieval, search technologies, or query understanding. Although it uses large language models, the context is different from the user's interests in NLP and data mining.

#### Abstract
> Project-specific code completion is a critical task that leverages context
from a project to generate accurate code. State-of-the-art methods use
retrieval-augmented generation (RAG) with large language models (LLMs) and
project information for code completion. However, they often struggle to
incorporate internal API information, which is crucial for accuracy, especially
when APIs are not explicitly imported in the file.
  To address this, we propose a method to infer internal API information
without relying on imports. Our method extends the representation of APIs by
constructing usage examples and semantic descriptions, building a knowledge
base for LLMs to generate relevant completions. We also introduce ProjBench, a
benchmark that avoids leaked imports and consists of large-scale real-world
projects.
  Experiments on ProjBench and CrossCodeEval show that our approach
significantly outperforms existing methods, improving code exact match by
22.72% and identifier exact match by 18.31%. Additionally, integrating our
method with existing baselines boosts code match by 47.80% and identifier match
by 35.55%.

### 16. ZSE-Cap: A Zero-Shot Ensemble for Image Retrieval and Prompt-Guided Captioning

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Duc-Tai Dinh, Duc Anh Khoa Dinh
- **URL**: <http://arxiv.org/abs/2507.20564v1>
- **Submitted**: 2025-07-28 06:58:35
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on image retrieval and captioning, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and query understanding. Although it mentions ensembling and prompting, which are relevant to the user's background in NLP, the context is specific to image retrieval and captioning, making it only loosely relevant.

#### Abstract
> We present ZSE-Cap (Zero-Shot Ensemble for Captioning), our 4th place system
in Event-Enriched Image Analysis (EVENTA) shared task on article-grounded image
retrieval and captioning. Our zero-shot approach requires no finetuning on the
competition's data. For retrieval, we ensemble similarity scores from CLIP,
SigLIP, and DINOv2. For captioning, we leverage a carefully engineered prompt
to guide the Gemma 3 model, enabling it to link high-level events from the
article to the visual content in the image. Our system achieved a final score
of 0.42002, securing a top-4 position on the private test set, demonstrating
the effectiveness of combining foundation models through ensembling and
prompting. Our code is available at https://github.com/ductai05/ZSE-Cap.

### 17. FHSTP@EXIST 2025 Benchmark: Sexism Detection with Transparent Speech Concept Bottleneck Models

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Roberto Labadie-Tamayo, Adrian Jaques B√∂ck, Djordje Slijepƒçeviƒá, Xihui Chen, Andreas Babic, Matthias Zeppelzauer
- **URL**: <http://arxiv.org/abs/2507.20924v1>
- **Submitted**: 2025-07-28 15:30:17
- **Comment**: 12 pages
- **Topic Keywords**: rag, rank
- **Reason**: The paper focuses on sexism detection in social media, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The techniques and models described in the paper, such as Speech Concept Bottleneck Models, are not relevant to the user's areas of focus.

#### Abstract
> Sexism has become widespread on social media and in online conversation. To
help address this issue, the fifth Sexism Identification in Social Networks
(EXIST) challenge is initiated at CLEF 2025. Among this year's international
benchmarks, we concentrate on solving the first task aiming to identify and
classify sexism in social media textual posts. In this paper, we describe our
solutions and report results for three subtasks: Subtask 1.1 - Sexism
Identification in Tweets, Subtask 1.2 - Source Intention in Tweets, and Subtask
1.3 - Sexism Categorization in Tweets. We implement three models to address
each subtask which constitute three individual runs: Speech Concept Bottleneck
Model (SCBM), Speech Concept Bottleneck Model with Transformer (SCBMT), and a
fine-tuned XLM-RoBERTa transformer model. SCBM uses descriptive adjectives as
human-interpretable bottleneck concepts. SCBM leverages large language models
(LLMs) to encode input texts into a human-interpretable representation of
adjectives, then used to train a lightweight classifier for downstream tasks.
SCBMT extends SCBM by fusing adjective-based representation with contextual
embeddings from transformers to balance interpretability and classification
performance. Beyond competitive results, these two models offer fine-grained
explanations at both instance (local) and class (global) levels. We also
investigate how additional metadata, e.g., annotators' demographic profiles,
can be leveraged. For Subtask 1.1, XLM-RoBERTa, fine-tuned on provided data
augmented with prior datasets, ranks 6th for English and Spanish and 4th for
English in the Soft-Soft evaluation. Our SCBMT achieves 7th for English and
Spanish and 6th for Spanish.

### 18. Before the Outrage: Challenges and Advances in Predicting Online Antisocial Behavior

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Ana√Øs Ollagnier
- **URL**: <http://arxiv.org/abs/2507.20614v1>
- **Submitted**: 2025-07-28 08:27:58
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on predicting online antisocial behavior, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions machine learning and language models, the context is different from the user's primary research interests.

#### Abstract
> Antisocial behavior (ASB) on social media-including hate speech, harassment,
and trolling-poses growing challenges for platform safety and societal
wellbeing. While prior work has primarily focused on detecting harmful content
after it appears, predictive approaches aim to forecast future harmful
behaviors-such as hate speech propagation, conversation derailment, or user
recidivism-before they fully unfold. Despite increasing interest, the field
remains fragmented, lacking a unified taxonomy or clear synthesis of existing
methods. This paper presents a systematic review of over 49 studies on ASB
prediction, offering a structured taxonomy of five core task types: early harm
detection, harm emergence prediction, harm propagation prediction, behavioral
risk prediction, and proactive moderation support. We analyze how these tasks
differ by temporal framing, prediction granularity, and operational goals. In
addition, we examine trends in modeling techniques-from classical machine
learning to pre-trained language models-and assess the influence of dataset
characteristics on task feasibility and generalization. Our review highlights
methodological challenges, such as dataset scarcity, temporal drift, and
limited benchmarks, while outlining emerging research directions including
multilingual modeling, cross-platform generalization, and human-in-the-loop
systems. By organizing the field around a coherent framework, this survey aims
to guide future work toward more robust and socially responsible ASB
prediction.

### 19. Beyond Interactions: Node-Level Graph Generation for Knowledge-Free Augmentation in Recommender Systems

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Zhaoyan Wang, Hyunjun Ahn, In-Young Ko
- **URL**: <http://arxiv.org/abs/2507.20578v1>
- **Submitted**: 2025-07-28 07:22:06
- **Topic Keywords**: rag, recommend
- **Reason**: The paper focuses on recommender systems, which is a related topic, but it does not address information retrieval, query understanding, ranking models, or user behavior modeling, which are the core areas of interest. The paper's emphasis on knowledge-free augmentation and node-level graph generation is not directly relevant to the user's research themes.

#### Abstract
> Recent advances in recommender systems rely on external resources such as
knowledge graphs or large language models to enhance recommendations, which
limit applicability in real-world settings due to data dependency and
computational overhead. Although knowledge-free models are able to bolster
recommendations by direct edge operations as well, the absence of augmentation
primitives drives them to fall short in bridging semantic and structural gaps
as high-quality paradigm substitutes. Unlike existing diffusion-based works
that remodel user-item interactions, this work proposes NodeDiffRec, a
pioneering knowledge-free augmentation framework that enables fine-grained
node-level graph generation for recommendations and expands the scope of
restricted augmentation primitives via diffusion. By synthesizing pseudo-items
and corresponding interactions that align with the underlying distribution for
injection, and further refining user preferences through a denoising preference
modeling process, NodeDiffRec dramatically enhances both semantic diversity and
structural connectivity without external knowledge. Extensive experiments
across diverse datasets and recommendation algorithms demonstrate the
superiority of NodeDiffRec, achieving State-of-the-Art (SOTA) performance, with
maximum average performance improvement 98.6% in Recall@5 and 84.0% in NDCG@5
over selected baselines.

### 20. Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Andy Zou, Maxwell Lin, Eliot Jones, Micha Nowak, Mateusz Dziemian, Nick Winter, Alexander Grattan, Valent Nathanael, Ayla Croft, Xander Davies, Jai Patel, Robert Kirk, Nate Burnikell, Yarin Gal, Dan Hendrycks, J. Zico Kolter, Matt Fredrikson
- **URL**: <http://arxiv.org/abs/2507.20526v1>
- **Submitted**: 2025-07-28 05:13:04
- **Topic Keywords**: queries
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus is on AI agent deployment and security challenges, which is a distinct area of study. While the paper mentions 'language model reasoning', it is not related to query understanding, ranking models, or user behavior modeling, which are your primary areas of interest.

#### Abstract
> Recent advances have enabled LLM-powered AI agents to autonomously execute
complex tasks by combining language model reasoning with tools, memory, and web
access. But can these systems be trusted to follow deployment policies in
realistic environments, especially under attack? To investigate, we ran the
largest public red-teaming competition to date, targeting 22 frontier AI agents
across 44 realistic deployment scenarios. Participants submitted 1.8 million
prompt-injection attacks, with over 60,000 successfully eliciting policy
violations such as unauthorized data access, illicit financial actions, and
regulatory noncompliance. We use these results to build the Agent Red Teaming
(ART) benchmark - a curated set of high-impact attacks - and evaluate it across
19 state-of-the-art models. Nearly all agents exhibit policy violations for
most behaviors within 10-100 queries, with high attack transferability across
models and tasks. Importantly, we find limited correlation between agent
robustness and model size, capability, or inference-time compute, suggesting
that additional defenses are needed against adversarial misuse. Our findings
highlight critical and persistent vulnerabilities in today's AI agents. By
releasing the ART benchmark and accompanying evaluation framework, we aim to
support more rigorous security assessment and drive progress toward safer agent
deployment.

### 21. Your AI, Not Your View: The Bias of LLMs in Investment Analysis

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Hoyoung Lee, Junhyuk Seo, Suhwan Park, Junhyeong Lee, Wonbin Ahn, Chanyeol Choi, Alejandro Lopez-Lira, Yongjae Lee
- **URL**: <http://arxiv.org/abs/2507.20957v1>
- **Submitted**: 2025-07-28 16:09:38
- **Topic Keywords**: recommend, search
- **Reason**: The paper focuses on Large Language Models (LLMs) in investment analysis, exploring their biases and preferences. While it touches on the topic of 'real-time relevance optimization', it is not directly related to Information Retrieval (IR) or Search technologies, which are the primary areas of interest. The paper's focus on finance and investment analysis is outside the scope of the user's research interests.

#### Abstract
> In finance, Large Language Models (LLMs) face frequent knowledge conflicts
due to discrepancies between pre-trained parametric knowledge and real-time
market data. These conflicts become particularly problematic when LLMs are
deployed in real-world investment services, where misalignment between a
model's embedded preferences and those of the financial institution can lead to
unreliable recommendations. Yet little research has examined what investment
views LLMs actually hold. We propose an experimental framework to investigate
such conflicts, offering the first quantitative analysis of confirmation bias
in LLM-based investment analysis. Using hypothetical scenarios with balanced
and imbalanced arguments, we extract models' latent preferences and measure
their persistence. Focusing on sector, size, and momentum, our analysis reveals
distinct, model-specific tendencies. In particular, we observe a consistent
preference for large-cap stocks and contrarian strategies across most models.
These preferences often harden into confirmation bias, with models clinging to
initial judgments despite counter-evidence.

### 22. FRED: Financial Retrieval-Enhanced Detection and Editing of Hallucinations in Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Likun Tan, Kuan-Wei Huang, Kevin Wu
- **URL**: <http://arxiv.org/abs/2507.20930v1>
- **Submitted**: 2025-07-28 15:41:53
- **Topic Keywords**: retrieval
- **Reason**: The paper focuses on detecting and editing hallucinations in language models, which is not directly related to information retrieval, search technologies, or query understanding. Although it mentions fine-tuning language models, the context is financial text generation, which is not a primary focus of the user's research interests.

#### Abstract
> Hallucinations in large language models pose a critical challenge for
applications requiring factual reliability, particularly in high-stakes domains
such as finance. This work presents an effective approach for detecting and
editing factually incorrect content in model-generated responses based on the
provided context. Given a user-defined domain-specific error taxonomy, we
construct a synthetic dataset by inserting tagged errors into financial
question-answering corpora and then fine-tune four language models, Phi-4,
Phi-4-mini, Qwen3-4B, and Qwen3-14B, to detect and edit these factual
inaccuracies. Our best-performing model, fine-tuned Phi-4, achieves an 8%
improvement in binary F1 score and a 30% gain in overall detection performance
compared to OpenAI-o3. Notably, our fine-tuned Phi-4-mini model, despite having
only 4 billion parameters, maintains competitive performance with just a 2%
drop in binary detection and a 0.1% decline in overall detection compared to
OpenAI-o3. Our work provides a practical solution for detecting and editing
factual inconsistencies in financial text generation while introducing a
generalizable framework that can enhance the trustworthiness and alignment of
large language models across diverse applications beyond finance. Our code and
data are available at https://github.com/pegasi-ai/fine-grained-editting.

### 23. Leveraging Open-Source Large Language Models for Clinical Information Extraction in Resource-Constrained Settings

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Luc Builtjes, Joeran Bosma, Mathias Prokop, Bram van Ginneken, Alessa Hering
- **URL**: <http://arxiv.org/abs/2507.20859v1>
- **Submitted**: 2025-07-28 14:12:37
- **Comment**: 34 pages, 5 figures
- **Topic Keywords**: rag
- **Reason**: The paper focuses on leveraging open-source large language models for clinical information extraction, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions generative LLMs, the context is clinical natural language processing, which is a different domain from the user's interests.

#### Abstract
> Medical reports contain rich clinical information but are often unstructured
and written in domain-specific language, posing challenges for information
extraction. While proprietary large language models (LLMs) have shown promise
in clinical natural language processing, their lack of transparency and data
privacy concerns limit their utility in healthcare. This study therefore
evaluates nine open-source generative LLMs on the DRAGON benchmark, which
includes 28 clinical information extraction tasks in Dutch. We developed
\texttt{llm\_extractinator}, a publicly available framework for information
extraction using open-source generative LLMs, and used it to assess model
performance in a zero-shot setting. Several 14 billion parameter models,
Phi-4-14B, Qwen-2.5-14B, and DeepSeek-R1-14B, achieved competitive results,
while the bigger Llama-3.3-70B model achieved slightly higher performance at
greater computational cost. Translation to English prior to inference
consistently degraded performance, highlighting the need of native-language
processing. These findings demonstrate that open-source LLMs, when used with
our framework, offer effective, scalable, and privacy-conscious solutions for
clinical information extraction in low-resource settings.

### 24. Watermarking Large Language Model-based Time Series Forecasting

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Wei Yuan, Chaoqun Yang, Yu Xing, Tong Chen, Nguyen Quoc Viet Hung, Hongzhi Yin
- **URL**: <http://arxiv.org/abs/2507.20762v1>
- **Submitted**: 2025-07-28 12:16:52
- **Topic Keywords**: rag
- **Reason**: The paper focuses on watermarking large language model-based time series forecasting, which is not directly related to information retrieval, search technologies, or query understanding. The topic is more aligned with natural language processing and data mining, but the specific application and methodology are not relevant to the user's interests.

#### Abstract
> Large Language Model-based Time Series Forecasting (LLMTS) has shown
remarkable promise in handling complex and diverse temporal data, representing
a significant step toward foundation models for time series analysis. However,
this emerging paradigm introduces two critical challenges. First, the
substantial commercial potential and resource-intensive development raise
urgent concerns about intellectual property (IP) protection. Second, their
powerful time series forecasting capabilities may be misused to produce
misleading or fabricated deepfake time series data. To address these concerns,
we explore watermarking the outputs of LLMTS models, that is, embedding
imperceptible signals into the generated time series data that remain
detectable by specialized algorithms. We propose a novel post-hoc watermarking
framework, Waltz, which is broadly compatible with existing LLMTS models. Waltz
is inspired by the empirical observation that time series patch embeddings are
rarely aligned with a specific set of LLM tokens, which we term ``cold
tokens''. Leveraging this insight, Waltz embeds watermarks by rewiring the
similarity statistics between patch embeddings and cold token embeddings, and
detects watermarks using similarity z-scores. To minimize potential side
effects, we introduce a similarity-based embedding position identification
strategy and employ projected gradient descent to constrain the watermark noise
within a defined boundary. Extensive experiments using two popular LLMTS models
across seven benchmark datasets demonstrate that Waltz achieves high watermark
detection accuracy with minimal impact on the quality of the generated time
series.

### 25. Geometric-Mean Policy Optimization

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yuzhong Zhao, Yue Liu, Junpeng Liu, Jingye Chen, Xun Wu, Yaru Hao, Tengchao Lv, Shaohan Huang, Lei Cui, Qixiang Ye, Fang Wan, Furu Wei
- **URL**: <http://arxiv.org/abs/2507.20673v1>
- **Submitted**: 2025-07-28 09:54:05
- **Comment**: Code is available at https://github.com/callsys/GMPO
- **Topic Keywords**: rag
- **Reason**: The paper focuses on optimizing policy updates for large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions rewards and importance sampling, the context is different from the user's interests in ranking models and user behavior modeling.

#### Abstract
> Recent advancements, such as Group Relative Policy Optimization (GRPO), have
enhanced the reasoning capabilities of large language models by optimizing the
arithmetic mean of token-level rewards. However, GRPO suffers from unstable
policy updates when processing tokens with outlier importance-weighted rewards,
which manifests as extreme importance sampling ratios during training, i.e.,
the ratio between the sampling probabilities assigned to a token by the current
and old policies. In this work, we propose Geometric-Mean Policy Optimization
(GMPO), a stabilized variant of GRPO. Instead of optimizing the arithmetic
mean, GMPO maximizes the geometric mean of token-level rewards, which is
inherently less sensitive to outliers and maintains a more stable range of
importance sampling ratio. In addition, we provide comprehensive theoretical
and experimental analysis to justify the design and stability benefits of GMPO.
Beyond improved stability, GMPO-7B outperforms GRPO by an average of 4.1% on
multiple mathematical benchmarks and 1.4% on multimodal reasoning benchmark,
including AIME24, AMC, MATH500, OlympiadBench, Minerva, and Geometry3K. Code is
available at https://github.com/callsys/GMPO.

### 26. SAND-Math: Using LLMs to Generate Novel, Difficult and Useful Mathematics Questions and Answers

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Chaitanya Manem, Pratik Prabhanjan Brahma, Prakamya Mishra, Zicheng Liu, Emad Barsoum
- **URL**: <http://arxiv.org/abs/2507.20527v2>
- **Submitted**: 2025-07-28 05:17:48
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on generating mathematical questions and answers using Large Language Models, which is outside your primary focus area.

#### Abstract
> The demand for Large Language Models (LLMs) capable of sophisticated
mathematical reasoning is growing across industries. However, the development
of performant mathematical LLMs is critically bottlenecked by the scarcity of
difficult, novel training data. We introduce \textbf{SAND-Math} (Synthetic
Augmented Novel and Difficult Mathematics problems and solutions), a pipeline
that addresses this by first generating high-quality problems from scratch and
then systematically elevating their complexity via a new \textbf{Difficulty
Hiking} step. We demonstrate the effectiveness of our approach through two key
findings. First, augmenting a strong baseline with SAND-Math data significantly
boosts performance, outperforming the next-best synthetic dataset by
\textbf{$\uparrow$ 17.85 absolute points} on the AIME25 benchmark. Second, in a
dedicated ablation study, we show our Difficulty Hiking process is highly
effective: by increasing average problem difficulty from 5.02 to 5.98, this
step lifts AIME25 performance from 46.38\% to 49.23\%. The full generation
pipeline, final dataset, and a fine-tuned model form a practical and scalable
toolkit for building more capable and efficient mathematical reasoning LLMs.
SAND-Math dataset is released here:
\href{https://huggingface.co/datasets/amd/SAND-MATH}{https://huggingface.co/datasets/amd/SAND-MATH}

### 27. Customize Multi-modal RAI Guardrails with Precedent-based predictions

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Cheng-Fu Yang, Thanh Tran, Christos Christodoulopoulos, Weitong Ruan, Rahul Gupta, Kai-Wei Chang
- **URL**: <http://arxiv.org/abs/2507.20503v1>
- **Submitted**: 2025-07-28 03:45:34
- **Comment**: Accepted to COLM 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on multi-modal guardrails for filtering image content based on user-defined policies, which is not directly related to information retrieval, search technologies, or query understanding. The topic is more aligned with computer vision and multimedia processing, and the approach is not relevant to ranking models or user behavior modeling.

#### Abstract
> A multi-modal guardrail must effectively filter image content based on
user-defined policies, identifying material that may be hateful, reinforce
harmful stereotypes, contain explicit material, or spread misinformation.
Deploying such guardrails in real-world applications, however, poses
significant challenges. Users often require varied and highly customizable
policies and typically cannot provide abundant examples for each custom policy.
Consequently, an ideal guardrail should be scalable to the multiple policies
and adaptable to evolving user standards with minimal retraining. Existing
fine-tuning methods typically condition predictions on pre-defined policies,
restricting their generalizability to new policies or necessitating extensive
retraining to adapt. Conversely, training-free methods struggle with limited
context lengths, making it difficult to incorporate all the policies
comprehensively. To overcome these limitations, we propose to condition model's
judgment on "precedents", which are the reasoning processes of prior data
points similar to the given input. By leveraging precedents instead of fixed
policies, our approach greatly enhances the flexibility and adaptability of the
guardrail. In this paper, we introduce a critique-revise mechanism for
collecting high-quality precedents and two strategies that utilize precedents
for robust prediction. Experimental results demonstrate that our approach
outperforms previous methods across both few-shot and full-dataset scenarios
and exhibits superior generalization to novel policies.

### 28. Improving Community Detection in Academic Networks by Handling Publication Bias

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Md Asaduzzaman Noor, John Sheppard, Jason Clark
- **URL**: <http://arxiv.org/abs/2507.20449v1>
- **Submitted**: 2025-07-28 00:48:33
- **Comment**: This paper is an extended version of a work accepted at ASONAM 2025
- **Topic Keywords**: recommend, search
- **Reason**: The paper focuses on community detection in academic networks, using publication content and BERTopic with SciBERT, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on topic-based research networks, the primary focus is on community detection and collaboration opportunities, which is not a central match for the user's research interests.

#### Abstract
> Finding potential research collaborators is a challenging task, especially in
today's fast-growing and interdisciplinary research landscape. While
traditional methods often rely on observable relationships such as
co-authorships and citations to construct the research network, in this work,
we focus solely on publication content to build a topic-based research network
using BERTopic with a fine-tuned SciBERT model that connects and recommends
researchers across disciplines based on shared topical interests. A major
challenge we address is publication imbalance, where some researchers publish
much more than others, often across several topics. Without careful handling,
their less frequent interests are hidden under dominant topics, limiting the
network's ability to detect their full research scope. To tackle this, we
introduce a cloning strategy that clusters a researcher's publications and
treats each cluster as a separate node. This allows researchers to be part of
multiple communities, improving the detection of interdisciplinary links.
Evaluation on the proposed method shows that the cloned network structure leads
to more meaningful communities and uncovers a broader set of collaboration
opportunities.

### 29. TIMEST: Temporal Information Motif Estimator Using Sampling Trees

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yunjie Pan, Omkar Bhalerao, C. Seshadhri, Nishil Talati
- **URL**: <http://arxiv.org/abs/2507.20441v1>
- **Submitted**: 2025-07-27 23:31:55
- **Topic Keywords**: rag
- **Reason**: The paper focuses on temporal motif mining in graph mining, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions graph mining, which is a related field, the specific problem and solution presented are not aligned with the user's research interests.

#### Abstract
> The mining of pattern subgraphs, known as motifs, is a core task in the field
of graph mining. Edges in real-world networks often have timestamps, so there
is a need for temporal motif mining. A temporal motif is a richer structure
that imposes timing constraints on the edges of the motif. Temporal motifs have
been used to analyze social networks, financial transactions, and biological
networks.
  Motif counting in temporal graphs is particularly challenging. A graph with
millions of edges can have trillions of temporal motifs, since the same edge
can occur with multiple timestamps. There is a combinatorial explosion of
possibilities, and state-of-the-art algorithms cannot manage motifs with more
than four vertices.
  In this work, we present TIMEST: a general, fast, and accurate estimation
algorithm to count temporal motifs of arbitrary sizes in temporal networks. Our
approach introduces a temporal spanning tree sampler that leverages weighted
sampling to generate substructures of target temporal motifs. This method
carefully takes a subset of temporal constraints of the motif that can be
jointly and efficiently sampled. TIMEST uses randomized estimation techniques
to obtain accurate estimates of motif counts.
  We give theoretical guarantees on the running time and approximation
guarantees of TIMEST. We perform an extensive experimental evaluation and show
that TIMEST is both faster and more accurate than previous algorithms. Our CPU
implementation exhibits an average speedup of 28x over state-of-the-art GPU
implementation of the exact algorithm, and 6x speedup over SOTA approximate
algorithms while consistently showcasing less than 5% error in most cases. For
example, TIMEST can count the number of instances of a financial fraud temporal
motif in four minutes with 0.6% error, while exact methods take more than two
days.

### 30. CodeNER: Code Prompting for Named Entity Recognition

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sungwoo Han, Hyeyeon Kim, Jingun Kwon, Hidetaka Kamigaito, Manabu Okumura
- **URL**: <http://arxiv.org/abs/2507.20423v1>
- **Submitted**: 2025-07-27 21:49:36
- **Comment**: 18 pages, 6 figures
- **Topic Keywords**: rag
- **Reason**: The paper focuses on named entity recognition (NER) and code-based prompting, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and query understanding. Although it mentions large language models, it does not explore ranking models or user behavior modeling, making it only loosely relevant to the user's interests.

#### Abstract
> Recent studies have explored various approaches for treating candidate named
entity spans as both source and target sequences in named entity recognition
(NER) by leveraging large language models (LLMs). Although previous approaches
have successfully generated candidate named entity spans with suitable labels,
they rely solely on input context information when using LLMs, particularly,
ChatGPT. However, NER inherently requires capturing detailed labeling
requirements with input context information. To address this issue, we propose
a novel method that leverages code-based prompting to improve the capabilities
of LLMs in understanding and performing NER. By embedding code within prompts,
we provide detailed BIO schema instructions for labeling, thereby exploiting
the ability of LLMs to comprehend long-range scopes in programming languages.
Experimental results demonstrate that the proposed code-based prompting method
outperforms conventional text-based prompting on ten benchmarks across English,
Arabic, Finnish, Danish, and German datasets, indicating the effectiveness of
explicitly structuring NER instructions. We also verify that combining the
proposed code-based prompting method with the chain-of-thought prompting
further improves performance.

### 31. Cognitive Chain-of-Thought: Structured Multimodal Reasoning about Social Situations

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Eunkyu Park, Wesley Hanwen Deng, Gunhee Kim, Motahhare Eslami, Maarten Sap
- **URL**: <http://arxiv.org/abs/2507.20409v1>
- **Submitted**: 2025-07-27 20:40:30
- **Comment**: Under review; 17 pages
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on multimodal reasoning and cognitive chain-of-thought prompting, which is more relevant to Natural Language Processing and computer vision.

#### Abstract
> Chain-of-Thought (CoT) prompting helps models think step by step. But what
happens when they must see, understand, and judge-all at once? In visual tasks
grounded in social context, where bridging perception with norm-grounded
judgments is essential, flat CoT often breaks down. We introduce Cognitive
Chain-of-Thought (CoCoT), a prompting strategy that scaffolds VLM reasoning
through three cognitively inspired stages: perception, situation, and norm. Our
experiments show that, across multiple multimodal benchmarks (including intent
disambiguation, commonsense reasoning, and safety), CoCoT consistently
outperforms CoT and direct prompting (+8\% on average). Our findings
demonstrate that cognitively grounded reasoning stages enhance interpretability
and social awareness in VLMs, paving the way for safer and more reliable
multimodal systems.

### 32. Automating Thematic Review of Prevention of Future Deaths Reports: Replicating the ONS Child Suicide Study using Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Sam Osian, Arpan Dutta, Sahil Bhandari, Iain E. Buchan, Dan W. Joyce
- **URL**: <http://arxiv.org/abs/2507.20786v1>
- **Submitted**: 2025-07-28 12:56:31
- **Comment**: 8 pages, 1 figure
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on applying large language models to automate thematic review of coronial data, which is outside the scope of your research areas.

#### Abstract
> Prevention of Future Deaths (PFD) reports, issued by coroners in England and
Wales, flag systemic hazards that may lead to further loss of life. Analysis of
these reports has previously been constrained by the manual effort required to
identify and code relevant cases. In 2025, the Office for National Statistics
(ONS) published a national thematic review of child-suicide PFD reports ($\leq$
18 years), identifying 37 cases from January 2015 to November 2023 - a process
based entirely on manual curation and coding. We evaluated whether a fully
automated, open source "text-to-table" language-model pipeline (PFD Toolkit)
could reproduce the ONS's identification and thematic analysis of child-suicide
PFD reports, and assessed gains in efficiency and reliability. All 4,249 PFD
reports published from July 2013 to November 2023 were processed via PFD
Toolkit's large language model pipelines. Automated screening identified cases
where the coroner attributed death to suicide in individuals aged 18 or
younger, and eligible reports were coded for recipient category and 23 concern
sub-themes, replicating the ONS coding frame. PFD Toolkit identified 72
child-suicide PFD reports - almost twice the ONS count. Three blinded
clinicians adjudicated a stratified sample of 144 reports to validate the
child-suicide screening. Against the post-consensus clinical annotations, the
LLM-based workflow showed substantial to almost-perfect agreement (Cohen's
$\kappa$ = 0.82, 95% CI: 0.66-0.98, raw agreement = 91%). The end-to-end script
runtime was 8m 16s, transforming a process that previously took months into one
that can be completed in minutes. This demonstrates that automated LLM analysis
can reliably and efficiently replicate manual thematic reviews of coronial
data, enabling scalable, reproducible, and timely insights for public health
and safety. The PFD Toolkit is openly available for future research.

### 33. Kimi K2: Open Agentic Intelligence

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Kimi Team, Yifan Bai, Yiping Bao, Guanduo Chen, Jiahao Chen, Ningxin Chen, Ruijue Chen, Yanru Chen, Yuankun Chen, Yutian Chen, Zhuofu Chen, Jialei Cui, Hao Ding, Mengnan Dong, Angang Du, Chenzhuang Du, Dikang Du, Yulun Du, Yu Fan, Yichen Feng, Kelin Fu, Bofei Gao, Hongcheng Gao, Peizhong Gao, Tong Gao, Xinran Gu, Longyu Guan, Haiqing Guo, Jianhang Guo, Hao Hu, Xiaoru Hao, Tianhong He, Weiran He, Wenyang He, Chao Hong, Yangyang Hu, Zhenxing Hu, Weixiao Huang, Zhiqi Huang, Zihao Huang, Tao Jiang, Zhejun Jiang, Xinyi Jin, Yongsheng Kang, Guokun Lai, Cheng Li, Fang Li, Haoyang Li, Ming Li, Wentao Li, Yanhao Li, Yiwei Li, Zhaowei Li, Zheming Li, Hongzhan Lin, Xiaohan Lin, Zongyu Lin, Chengyin Liu, Chenyu Liu, Hongzhang Liu, Jingyuan Liu, Junqi Liu, Liang Liu, Shaowei Liu, T. Y. Liu, Tianwei Liu, Weizhou Liu, Yangyang Liu, Yibo Liu, Yiping Liu, Yue Liu, Zhengying Liu, Enzhe Lu, Lijun Lu, Shengling Ma, Xinyu Ma, Yingwei Ma, Shaoguang Mao, Jie Mei, Xin Men, Yibo Miao, Siyuan Pan, Yebo Peng, Ruoyu Qin, Bowen Qu, Zeyu Shang, Lidong Shi, Shengyuan Shi, Feifan Song, Jianlin Su, Zhengyuan Su, Xinjie Sun, Flood Sung, Heyi Tang, Jiawen Tao, Qifeng Teng, Chensi Wang, Dinglu Wang, Feng Wang, Haiming Wang, Jianzhou Wang, Jiaxing Wang, Jinhong Wang, Shengjie Wang, Shuyi Wang, Yao Wang, Yejie Wang, Yiqin Wang, Yuxin Wang, Yuzhi Wang, Zhaoji Wang, Zhengtao Wang, Zhexu Wang, Chu Wei, Qianqian Wei, Wenhao Wu, Xingzhe Wu, Yuxin Wu, Chenjun Xiao, Xiaotong Xie, Weimin Xiong, Boyu Xu, Jing Xu, Jinjing Xu, L. H. Xu, Lin Xu, Suting Xu, Weixin Xu, Xinran Xu, Yangchuan Xu, Ziyao Xu, Junjie Yan, Yuzi Yan, Xiaofei Yang, Ying Yang, Zhen Yang, Zhilin Yang, Zonghan Yang, Haotian Yao, Xingcheng Yao, Wenjie Ye, Zhuorui Ye, Bohong Yin, Longhui Yu, Enming Yuan, Hongbang Yuan, Mengjie Yuan, Haobing Zhan, Dehao Zhang, Hao Zhang, Wanlu Zhang, Xiaobin Zhang, Yangkun Zhang, Yizhi Zhang, Yongting Zhang, Yu Zhang, Yutao Zhang, Yutong Zhang, Zheng Zhang, Haotian Zhao, Yikai Zhao, Huabin Zheng, Shaojie Zheng, Jianren Zhou, Xinyu Zhou, Zaida Zhou, Zhen Zhu, Weiyu Zhuang, Xinxing Zu
- **URL**: <http://arxiv.org/abs/2507.20534v1>
- **Submitted**: 2025-07-28 05:35:43
- **Comment**: tech report of Kimi K2
- **Topic Keywords**: search
- **Reason**: The paper introduces a large language model, Kimi K2, with a focus on agentic intelligence and capabilities. While it mentions the model's performance on various benchmarks, there is no clear connection to information retrieval, search technologies, or query understanding, which are the user's primary research interests.

#### Abstract
> We introduce Kimi K2, a Mixture-of-Experts (MoE) large language model with 32
billion activated parameters and 1 trillion total parameters. We propose the
MuonClip optimizer, which improves upon Muon with a novel QK-clip technique to
address training instability while enjoying the advanced token efficiency of
Muon. Based on MuonClip, K2 was pre-trained on 15.5 trillion tokens with zero
loss spike. During post-training, K2 undergoes a multi-stage post-training
process, highlighted by a large-scale agentic data synthesis pipeline and a
joint reinforcement learning (RL) stage, where the model improves its
capabilities through interactions with real and synthetic environments.
  Kimi K2 achieves state-of-the-art performance among open-source non-thinking
models, with strengths in agentic capabilities. Notably, K2 obtains 66.1 on
Tau2-Bench, 76.5 on ACEBench (En), 65.8 on SWE-Bench Verified, and 47.3 on
SWE-Bench Multilingual -- surpassing most open and closed-sourced baselines in
non-thinking settings. It also exhibits strong capabilities in coding,
mathematics, and reasoning tasks, with a score of 53.7 on LiveCodeBench v6,
49.5 on AIME 2025, 75.1 on GPQA-Diamond, and 27.1 on OJBench, all without
extended thinking. These results position Kimi K2 as one of the most capable
open-source large language models to date, particularly in software engineering
and agentic tasks. We release our base and post-trained model checkpoints to
facilitate future research and applications of agentic intelligence.

### 34. AQUA: A Large Language Model for Aquaculture & Fisheries

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Praneeth Narisetty, Uday Kumar Reddy Kattamanchi, Lohit Akshant Nimma, Sri Ram Kaushik Karnati, Shiva Nagendra Babu Kore, Mounika Golamari, Tejashree Nageshreddy
- **URL**: <http://arxiv.org/abs/2507.20520v1>
- **Submitted**: 2025-07-28 05:06:07
- **Topic Keywords**: search
- **Reason**: The paper focuses on applying AI to the aquaculture industry, introducing a large language model tailored for this domain. While it mentions machine learning, it does not relate to information retrieval, search technologies, or query understanding, which are the user's primary research interests.

#### Abstract
> Aquaculture plays a vital role in global food security and coastal economies
by providing sustainable protein sources. As the industry expands to meet
rising demand, it faces growing challenges such as disease outbreaks,
inefficient feeding practices, rising labor costs, logistical inefficiencies,
and critical hatchery issues, including high mortality rates and poor water
quality control. Although artificial intelligence has made significant
progress, existing machine learning methods fall short of addressing the
domain-specific complexities of aquaculture. To bridge this gap, we introduce
AQUA, the first large language model (LLM) tailored for aquaculture, designed
to support farmers, researchers, and industry practitioners. Central to this
effort is AQUADAPT (Data Acquisition, Processing and Tuning), an Agentic
Framework for generating and refining high-quality synthetic data using a
combination of expert knowledge, largescale language models, and automated
evaluation techniques. Our work lays the foundation for LLM-driven innovations
in aquaculture research, advisory systems, and decision-making tools.

---

