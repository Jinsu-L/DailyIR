[
    {
        "title": "Query-Document Dense Vectors for LLM Relevance Judgment Bias Analysis",
        "abstract": "Large Language Models (LLMs) have been used as relevance assessors for Information Retrieval (IR) evaluation collection creation due to reduced cost and increased scalability as compared to human assessors. While previous research has looked at the reliability of LLMs as compared to human assessors, in this work, we aim to understand if LLMs make systematic mistakes when judging relevance, rather than just understanding how good they are on average. To this aim, we propose a novel representational method for queries and documents that allows us to analyze relevance label distributions and compare LLM and human labels to identify patterns of disagreement and localize systematic areas of disagreement. We introduce a clustering-based framework that embeds query-document (Q-D) pairs into a joint semantic space, treating relevance as a relational property. Experiments on TREC Deep Learning 2019 and 2020 show that systematic disagreement between humans and LLMs is concentrated in specific semantic clusters rather than distributed randomly. Query-level analyses reveal recurring failures, most often in definition-seeking, policy-related, or ambiguous contexts. Queries with large variation in agreement across their clusters emerge as disagreement hotspots, where LLMs tend to under-recall relevant content or over-include irrelevant material. This framework links global diagnostics with localized clustering to uncover hidden weaknesses in LLM judgments, enabling bias-aware and more reliable IR evaluation.",
        "url": "http://arxiv.org/abs/2601.01751v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01751v1",
        "arxiv_id": "2601.01751v1",
        "authors": [
            "Samaneh Mohtadi",
            "Gianluca Demartini"
        ],
        "submitted": "2026-01-05 03:02:33",
        "source": "arxiv",
        "comment": "Accepted for presentation at the ECIR 2026 Full Papers track",
        "score": 19,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)",
            "Found 'trec' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of Large Language Models (LLMs) and their potential biases in relevance judgment. The paper's focus on understanding LLMs' systematic mistakes and proposing a novel representational method for queries and documents aligns with your interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "LACONIC: Dense-Level Effectiveness for Scalable Sparse Retrieval via a Two-Phase Training Curriculum",
        "abstract": "While dense retrieval models have become the standard for state-of-the-art information retrieval, their deployment is often constrained by high memory requirements and reliance on GPU accelerators for vector similarity search. Learned sparse retrieval offers a compelling alternative by enabling efficient search via inverted indices, yet it has historically received less attention than dense approaches. In this report, we introduce LACONIC, a family of learned sparse retrievers based on the Llama-3 architecture (1B, 3B, and 8B). We propose a streamlined two-phase training curriculum consisting of (1) weakly supervised pre-finetuning to adapt causal LLMs for bidirectional contextualization and (2) high-signal finetuning using curated hard negatives. Our results demonstrate that LACONIC effectively bridges the performance gap with dense models: the 8B variant achieves a state-of-the-art 60.2 nDCG on the MTEB Retrieval benchmark, ranking 15th on the leaderboard as of January 1, 2026, while utilizing 71\\% less index memory than an equivalent dense model. By delivering high retrieval effectiveness on commodity CPU hardware with a fraction of the compute budget required by competing models, LACONIC provides a scalable and efficient solution for real-world search applications.",
        "url": "http://arxiv.org/abs/2601.01684v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01684v1",
        "arxiv_id": "2601.01684v1",
        "authors": [
            "Zhichao Xu",
            "Shengyao Zhuang",
            "Crystina Zhang",
            "Xueguang Ma",
            "Yijun Tian",
            "Maitrey Mehta",
            "Jimmy Lin",
            "Vivek Srikumar"
        ],
        "submitted": "2026-01-04 22:42:20",
        "source": "arxiv",
        "comment": null,
        "score": 19,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retriever' (score: +3)",
            "Found 'sparse retrieval' (score: +3)",
            "Found 'dense retrieval' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to the field of Information Retrieval, particularly in the area of scalable and efficient search technologies. The focus on learned sparse retrieval and its comparison to dense models aligns with the user's interests in query understanding and ranking models. However, the specific application to search applications and the emphasis on scalability and efficiency, while related, do not perfectly match the user's core research themes."
    },
    {
        "title": "Judging with Personality and Confidence: A Study on Personality-Conditioned LLM Relevance Assessment",
        "abstract": "Recent studies have shown that prompting can enable large language models (LLMs) to simulate specific personality traits and produce behaviors that align with those traits. However, there is limited understanding of how these simulated personalities influence critical web search decisions, specifically relevance assessment. Moreover, few studies have examined how simulated personalities impact confidence calibration, specifically the tendencies toward overconfidence or underconfidence. This gap exists even though psychological literature suggests these biases are trait-specific, often linking high extraversion to overconfidence and high neuroticism to underconfidence. To address this gap, we conducted a comprehensive study evaluating multiple LLMs, including commercial models and open-source models, prompted to simulate Big Five personality traits. We tested these models across three test collections (TREC DL 2019, TREC DL 2020, and LLMJudge), collecting two key outputs for each query-document pair: a relevance judgment and a self-reported confidence score.\n  The findings show that personalities such as low agreeableness consistently align more closely with human labels than the unprompted condition. Additionally, low conscientiousness performs well in balancing the suppression of both overconfidence and underconfidence. We also observe that relevance scores and confidence distributions vary systematically across different personalities. Based on the above findings, we incorporate personality-conditioned scores and confidence as features in a random forest classifier. This approach achieves performance that surpasses the best single-personality condition on a new dataset (TREC DL 2021), even with limited training data. These findings highlight that personality-derived confidence offers a complementary predictive signal, paving the way for more reliable and human-aligned LLM evaluators.",
        "url": "http://arxiv.org/abs/2601.01862v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01862v1",
        "arxiv_id": "2601.01862v1",
        "authors": [
            "Nuo Chen",
            "Hanpei Fang",
            "Piaohong Wang",
            "Jiqun Liu",
            "Tetsuya Sakai",
            "Xiao-Ming Wu"
        ],
        "submitted": "2026-01-05 07:46:29",
        "source": "arxiv",
        "comment": null,
        "score": 10,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'web search' (score: +1)",
            "Found 'search' (score: +1)",
            "Found 'trec' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your interests in Information Retrieval, particularly in the area of query understanding and ranking models. The study explores how simulated personalities influence relevance assessment and confidence calibration in large language models, which aligns with your focus on deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines",
        "abstract": "Retrieval-Augmented Generation (RAG) systems often rely on fixed top-k document selection mechanisms that ignore downstream generation quality and impose computational overheads. We propose SRAS (Sparse Reward-Aware Selector), a lightweight document selector trained via reinforcement learning (RL) for edge-native RAG deployment. Unlike prior RL-based retrievers that assume large memory and latency budgets, SRAS learns a compact (~0.76MB) policy using Proximal Policy Optimization (PPO), guided by a hybrid reward signal combining Relaxed F1 and BERTScore. Our method operates under tight token and compute constraints, maintaining <1s latency on CPU. SRAS outperforms supervised and random selectors on a synthetic QA benchmark, and generalizes to real-world data, achieving BERTScore F1 of 0.8546 on SQuAD v2 without domain-specific tuning. This work is the first to demonstrate that RL-based document selection can be made ultra-lightweight, latency-aware, and effective for on-device RAG pipelines.",
        "url": "http://arxiv.org/abs/2601.01785v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01785v1",
        "arxiv_id": "2601.01785v1",
        "authors": [
            "Rajiv Chaitanya Muttur"
        ],
        "submitted": "2026-01-05 04:39:31",
        "source": "arxiv",
        "comment": "Presented at ICEdge 2025; nominated for Best Paper Award",
        "score": 10,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'ltr' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a reinforcement learning-based document selector for edge-native RAG pipelines, which is somewhat related to information retrieval and search technologies. However, the focus on edge-native deployment and latency-awareness is not a central match with the user's primary interests in query understanding, ranking models, and user behavior modeling. The connection to natural language processing is also indirect, as the paper primarily deals with retrieval-augmented generation systems."
    },
    {
        "title": "Beyond Homophily: Community Search on Heterophilic Graphs",
        "abstract": "Community search aims to identify a refined set of nodes that are most relevant to a given query, supporting tasks ranging from fraud detection to recommendation. Unlike homophilic graphs, many real-world networks are heterophilic, where edges predominantly connect dissimilar nodes. Therefore, structural signals that once reflected smooth, low-frequency similarity now appear as sharp, high-frequency contrasts. However, both classical algorithms (e.g., k-core, k-truss) and recent ML-based models struggle to achieve effective community search on heterophilic graphs, where edge signs or semantics are generally unknown. Algorithm-based methods often return communities with mixed class labels, while GNNs, built on homophily, smooth away meaningful signals and blur community boundaries. Therefore, we propose Adaptive Community Search (AdaptCS), a unified framework featuring three key designs: (i) an AdaptCS Encoder that disentangles multi-hop and multi-frequency signals, enabling the model to capture both smooth (homophilic) and contrastive (heterophilic) relations; (ii) a memory-efficient low-rank optimization that removes the main computational bottleneck and ensures model scalability; and (iii) an Adaptive Community Score (ACS) that guides online search by balancing embedding similarity and topological relations. Extensive experiments on both heterophilic and homophilic benchmarks demonstrate that AdaptCS outperforms the best-performing baseline by an average of 11% in F1-score, retains robustness across heterophily levels, and achieves up to 2 orders of magnitude speedup.",
        "url": "http://arxiv.org/abs/2601.01703v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01703v1",
        "arxiv_id": "2601.01703v1",
        "authors": [
            "Qing Sima",
            "Xiaoyang Wang",
            "Wenjie Zhang"
        ],
        "submitted": "2026-01-05 00:44:17",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on community search on heterophilic graphs, proposing a unified framework called AdaptCS. While it involves graph neural networks and optimization techniques, its primary application is in recommendation and fraud detection, which is somewhat related to information retrieval. However, the paper's emphasis on community search and graph structures does not directly align with the user's core research themes in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "A Dynamic Retrieval-Augmented Generation System with Selective Memory and Remembrance",
        "abstract": "We introduce \\emph{Adaptive RAG Memory} (ARM), a retrieval-augmented generation (RAG) framework that replaces a static vector index with a \\emph{dynamic} memory substrate governed by selective remembrance and decay. Frequently retrieved items are consolidated and protected from forgetting, while rarely used items gradually decay, inspired by cognitive consolidation and forgetting principles. On a lightweight retrieval benchmark, ARM reaches near state-of-the-art performance (e.g., NDCG@5 $\\approx$ 0.940, Recall@5 $=1.000$) with only $\\sim$22M parameters in the embedding layer, achieving the best efficiency among ultra-efficient models ($<$25M parameters). In addition, we compare static vs. dynamic RAG combinations across Llama 3.1 and GPT-4o. Llama 3.1 with static RAG achieves the highest key-term coverage (67.2\\%) at moderate latency, while GPT-4o with a dynamic selective retrieval policy attains the fastest responses (8.2s on average) with competitive coverage (58.7\\%). We further present an engineering optimization of the DynamicRAG implementation, making embedding weights configurable, adjustable at runtime, and robust to invalid settings.\n  ARM yields competitive accuracy, self-regularizing memory growth, and interpretable retention dynamics without retraining the generator\\color{black} and provides practical trade-off between quality, latency and memory efficiency for production and research RAG system.",
        "url": "http://arxiv.org/abs/2601.02428v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02428v1",
        "arxiv_id": "2601.02428v1",
        "authors": [
            "Okan Bursa"
        ],
        "submitted": "2026-01-04 21:51:41",
        "source": "arxiv",
        "comment": "6 Pages, 2 figures",
        "score": 8,
        "keyword_reasons": [
            "Found 'ltr' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper introduces a retrieval-augmented generation framework with a dynamic memory substrate, which shows promise for improving information retrieval efficiency. While it doesn't directly focus on query understanding, ranking models, or user behavior modeling, it does explore the intersection of retrieval and generation, which is relevant to information retrieval. However, the paper's primary focus on efficiency and scalability, rather than deep semantic understanding, limits its alignment with your core research themes."
    },
    {
        "title": "Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory",
        "abstract": "Access to reliable agricultural advisory remains limited in many developing regions due to a persistent language barrier: authoritative agricultural manuals are predominantly written in English, while farmers primarily communicate in low-resource local languages such as Bengali. Although recent advances in Large Language Models (LLMs) enable natural language interaction, direct generation in low-resource languages often exhibits poor fluency and factual inconsistency, while cloud-based solutions remain cost-prohibitive. This paper presents a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory that emphasizes factual grounding and practical deployability. The proposed system adopts a translation-centric architecture in which Bengali user queries are translated into English, enriched through domain-specific keyword injection to align colloquial farmer terminology with scientific nomenclature, and answered via dense vector retrieval over a curated corpus of English agricultural manuals (FAO, IRRI). The generated English response is subsequently translated back into Bengali to ensure accessibility. The system is implemented entirely using open-source models and operates on consumer-grade hardware without reliance on paid APIs. Experimental evaluation demonstrates reliable source-grounded responses, robust rejection of out-of-domain queries, and an average end-to-end latency below 20 seconds. The results indicate that cross-lingual retrieval combined with controlled translation offers a practical and scalable solution for agricultural knowledge access in low-resource language settings",
        "url": "http://arxiv.org/abs/2601.02065v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02065v1",
        "arxiv_id": "2601.02065v1",
        "authors": [
            "Md. Asif Hossain",
            "Nabil Subhan",
            "Mantasha Rahman Mahi",
            "Jannatul Ferdous Nabila"
        ],
        "submitted": "2026-01-05 12:41:44",
        "source": "arxiv",
        "comment": "5 pages, 3 figures, 1 table",
        "score": 7,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it involves a Retrieval-Augmented Generation framework for cross-lingual retrieval. However, the focus on low-resource languages and agricultural advisory is not a central match to your core research themes, which are more focused on general query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Tackling the Inherent Difficulty of Noise Filtering in RAG",
        "abstract": "Retrieval-Augmented Generation (RAG) has become a widely adopted approach to enhance Large Language Models (LLMs) by incorporating external knowledge and reducing hallucinations. However, noisy or irrelevant documents are often introduced during RAG, potentially degrading performance and even causing hallucinated outputs. While various methods have been proposed to filter out such noise, we argue that identifying irrelevant information from retrieved content is inherently difficult and limited number of transformer layers can hardly solve this. Consequently, retrievers fail to filter out irrelevant documents entirely. Therefore, LLMs must be robust against such noise, but we demonstrate that standard fine-tuning approaches are often ineffective in enabling the model to selectively utilize relevant information while ignoring irrelevant content due to the structural constraints of attention patterns. To address this, we propose a novel fine-tuning method designed to enhance the model's ability to distinguish between relevant and irrelevant information within retrieved documents. Extensive experiments across multiple benchmarks show that our approach significantly improves the robustness and performance of LLMs.",
        "url": "http://arxiv.org/abs/2601.01896v2",
        "pdf_url": "https://arxiv.org/pdf/2601.01896v2",
        "arxiv_id": "2601.01896v2",
        "authors": [
            "Jingyu Liu",
            "Jiaen Lin",
            "Yong Liu"
        ],
        "submitted": "2026-01-05 08:40:37",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper discusses Retrieval-Augmented Generation (RAG) and its challenges with noise filtering, which is related to information retrieval. However, the focus is on robustness and performance of Large Language Models rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest. The connection to IR is somewhat indirect, but the paper's emphasis on relevance and optimization is relevant to the field."
    },
    {
        "title": "MCGI: Manifold-Consistent Graph Indexing for Billion-Scale Disk-Resident Vector Search",
        "abstract": "Graph-based Approximate Nearest Neighbor (ANN) search often suffers from performance degradation in high-dimensional spaces due to the ``Euclidean-Geodesic mismatch,'' where greedy routing diverges from the underlying data manifold. To address this, we propose Manifold-Consistent Graph Indexing (MCGI), a geometry-aware and disk-resident indexing method that leverages Local Intrinsic Dimensionality (LID) to dynamically adapt search strategies to the data's intrinsic geometry. Unlike standard algorithms that treat dimensions uniformly, MCGI modulates its beam search budget based on in situ geometric analysis, eliminating dependency on static hyperparameters. Theoretical analysis confirms that MCGI enables improved approximation guarantees by preserving manifold-consistent topological connectivity. Empirically, MCGI achieves 5.8$\\times$ higher throughput at 95\\% recall on high-dimensional GIST1M compared to state-of-the-art DiskANN. On the billion-scale SIFT1B dataset, MCGI further validates its scalability by reducing high-recall query latency by 3$\\times$, while maintaining performance parity on standard lower-dimensional datasets.",
        "url": "http://arxiv.org/abs/2601.01930v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01930v1",
        "arxiv_id": "2601.01930v1",
        "authors": [
            "Dongfang Zhao"
        ],
        "submitted": "2026-01-05 09:23:48",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on vector search and graph indexing, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves data mining and scalability, the context is more aligned with computer vision and machine learning, rather than the user's primary interests."
    },
    {
        "title": "ARIES: A Scalable Multi-Agent Orchestration Framework for Real-Time Epidemiological Surveillance and Outbreak Monitoring",
        "abstract": "Global health surveillance is currently facing a challenge of Knowledge Gaps. While general-purpose AI has proliferated, it remains fundamentally unsuited for the high-stakes epidemiological domain due to chronic hallucinations and an inability to navigate specialized data silos. This paper introduces ARIES (Agentic Retrieval Intelligence for Epidemiological Surveillance), a specialized, autonomous multi-agent framework designed to move beyond static, disease-specific dashboards toward a dynamic intelligence ecosystem. Built on a hierarchical command structure, ARIES utilizes GPTs to orchestrate a scalable swarm of sub-agents capable of autonomously querying World Health Organization (WHO), Center for Disease Control and Prevention (CDC), and peer-reviewed research papers. By automating the extraction and logical synthesis of surveillance data, ARIES provides a specialized reasoning that identifies emergent threats and signal divergence in near real-time. This modular architecture proves that a task-specific agentic swarm can outperform generic models, offering a robust, extensible for next-generation outbreak response and global health intelligence.",
        "url": "http://arxiv.org/abs/2601.01831v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01831v1",
        "arxiv_id": "2601.01831v1",
        "authors": [
            "Aniket Wattamwar",
            "Sampson Akwafuo"
        ],
        "submitted": "2026-01-05 06:50:40",
        "source": "arxiv",
        "comment": "6 pages, 14 figures, 1 table",
        "score": 6,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves querying and data synthesis, the context is epidemiological surveillance, which is not a primary focus of the user's interests."
    },
    {
        "title": "Cold-Starting Podcast Ads and Promotions with Multi-Task Learning on Spotify",
        "abstract": "We present a unified multi-objective model for targeting both advertisements and promotions within the Spotify podcast ecosystem. Our approach addresses key challenges in personalization and cold-start initialization, particularly for new advertising objectives. By leveraging transfer learning from large-scale ad and content interactions within a multi-task learning (MTL) framework, a single joint model can be fine-tuned or directly applied to new or low-data targeting tasks, including in-app promotions. This multi-objective design jointly optimizes podcast outcomes such as streams, clicks, and follows for both ads and promotions using a shared representation over user, content, context, and creative features, effectively supporting diverse business goals while improving user experience. Online A/B tests show up to a 22% reduction in effective Cost-Per-Stream (eCPS), particularly for less-streamed podcasts, and an 18-24% increase in podcast stream rates. Offline experiments and ablations highlight the contribution of ancillary objectives and feature groups to cold-start performance. Our experience shows that a unified modeling strategy improves maintainability, cold-start performance, and coverage, while breaking down historically siloed targeting pipelines. We discuss practical trade-offs of such joint models in a real-world advertising system.",
        "url": "http://arxiv.org/abs/2601.02306v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02306v1",
        "arxiv_id": "2601.02306v1",
        "authors": [
            "Shivam Verma",
            "Hannes Karlbom",
            "Yu Zhao",
            "Nick Topping",
            "Vivian Chen",
            "Kieran Stanley",
            "Bharath Rengarajan"
        ],
        "submitted": "2026-01-05 17:48:15",
        "source": "arxiv",
        "comment": "Accepted at WSDM 2026",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'click' (score: +2)",
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to Information Retrieval, particularly in the context of advertising and personalization, but it does not directly address query understanding, ranking models, or user behavior modeling. The focus on recommender systems and multi-objective modeling is relevant, but the e-commerce domain and podcast ecosystem are not directly aligned with the user's primary research interests."
    },
    {
        "title": "pdfQA: Diverse, Challenging, and Realistic Question Answering over PDFs",
        "abstract": "PDFs are the second-most used document type on the internet (after HTML). Yet, existing QA datasets commonly start from text sources or only address specific domains. In this paper, we present pdfQA, a multi-domain 2K human-annotated (real-pdfQA) and 2K synthetic dataset (syn-pdfQA) differentiating QA pairs in ten complexity dimensions (e.g., file type, source modality, source position, answer type). We apply and evaluate quality and difficulty filters on both datasets, obtaining valid and challenging QA pairs. We answer the questions with open-source LLMs, revealing existing challenges that correlate with our complexity dimensions. pdfQA presents a basis for end-to-end QA pipeline evaluation, testing diverse skill sets and local optimizations (e.g., in information retrieval or parsing).",
        "url": "http://arxiv.org/abs/2601.02285v2",
        "pdf_url": "https://arxiv.org/pdf/2601.02285v2",
        "arxiv_id": "2601.02285v2",
        "authors": [
            "Tobias Schimanski",
            "Imene Kolli",
            "Yu Fan",
            "Ario Saeid Vaghefi",
            "Jingwei Ni",
            "Elliott Ash",
            "Markus Leippold"
        ],
        "submitted": "2026-01-05 17:15:26",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper presents a question answering dataset over PDFs, which is related to information retrieval and query understanding. However, the focus is on question answering rather than search technologies or ranking models, limiting its direct relevance to your core research themes. The connection to IR is through the end-to-end QA pipeline evaluation, which touches on information retrieval and parsing."
    },
    {
        "title": "Not All Needles Are Found: How Fact Distribution and Don't Make It Up Prompts Shape Literal Extraction, Logical Inference, and Hallucination Risks in Long-Context LLMs",
        "abstract": "Large language models (LLMs) increasingly support very long input contexts. Yet it remains unclear how reliably they extract and infer information at scale. Performance varies with context length and strongly interacts with how information is distributed in real-world corpora. Motivated by these observations, we study how fact placement, corpus-level fact distributions, and Don't Make It Up prompts influence model behavior. We introduce an extended needle-in-a-haystack benchmark across four production-scale models: Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, and Deepseek-v3.2-chat. Unlike prior work, we separately evaluate literal extraction, logical inference, and hallucination risk. Our study considers both positional effects and realistic distributions of evidence across long contexts, as well as prompts that explicitly discourage fabrication. We find that longer contexts alone do not guarantee better performance and can be detrimental when relevant evidence is diluted or widely dispersed. Performance varies substantially across models: some show severe degradation under realistic conditions, while others remain more robust at longer context lengths. Anti-hallucination (AH) instructions can make some models overly conservative, sharply reducing accuracy in literal extraction and logical inference. While we do not directly compare retrieval-augmented generation (RAG) and cache-augmented generation (CAG), our results suggest many failures stem from ineffective context utilization. Models often struggle to identify and prioritize relevant information even when it is present. These findings have direct practical implications, as enterprise workflows increasingly involve pasting large volumes of unfiltered documents into LLM prompts. Effective context length and model-specific robustness to long contexts are therefore critical for reliable LLM deployment in research and business.",
        "url": "http://arxiv.org/abs/2601.02023v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02023v1",
        "arxiv_id": "2601.02023v1",
        "authors": [
            "Amirali Ebrahimzadeh",
            "Seyyed M. Salili"
        ],
        "submitted": "2026-01-05 11:30:56",
        "source": "arxiv",
        "comment": "25 pages, 8 figures, 3 tables",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the behavior of large language models (LLMs) in long-context scenarios, focusing on literal extraction, logical inference, and hallucination risks. While it touches on aspects of information retrieval and model behavior, its primary focus is on NLP and LLMs, which aligns with your interests but is not a central match. The study's findings have implications for the deployment of LLMs in research and business, but the paper's relevance to your core research themes in IR and search technologies is limited."
    },
    {
        "title": "Hidden State Poisoning Attacks against Mamba-based Language Models",
        "abstract": "State space models (SSMs) like Mamba offer efficient alternatives to Transformer-based language models, with linear time complexity. Yet, their adversarial robustness remains critically unexplored. This paper studies the phenomenon whereby specific short input phrases induce a partial amnesia effect in such models, by irreversibly overwriting information in their hidden states, referred to as a Hidden State Poisoning Attack (HiSPA). Our benchmark RoBench25 allows evaluating a model's information retrieval capabilities when subject to HiSPAs, and confirms the vulnerability of SSMs against such attacks. Even a recent 52B hybrid SSM-Transformer model from the Jamba family collapses on RoBench25 under optimized HiSPA triggers, whereas pure Transformers do not. We also observe that HiSPA triggers significantly weaken the Jamba model on the popular Open-Prompt-Injections benchmark, unlike pure Transformers. Finally, our interpretability study reveals patterns in Mamba's hidden layers during HiSPAs that could be used to build a HiSPA mitigation system. The full code and data to reproduce the experiments can be found at https://anonymous.4open.science/r/hispa_anonymous-5DB0.",
        "url": "http://arxiv.org/abs/2601.01972v2",
        "pdf_url": "https://arxiv.org/pdf/2601.01972v2",
        "arxiv_id": "2601.01972v2",
        "authors": [
            "Alexandre Le Mercier",
            "Chris Develder",
            "Thomas Demeester"
        ],
        "submitted": "2026-01-05 10:27:19",
        "source": "arxiv",
        "comment": "17 pages, 4 figures",
        "score": 5,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the security aspect of language models, specifically the vulnerability of state space models to hidden state poisoning attacks. While it touches on information retrieval capabilities, the primary focus is on the robustness of language models, which is not a central match to your research interests in IR and related topics."
    },
    {
        "title": "When Attention Becomes Exposure in Generative Search",
        "abstract": "Generative search engines are reshaping information access by replacing traditional ranked lists with synthesized answers and references. In parallel, with the growth of Web3 platforms, incentive-driven creator ecosystems have become an essential part of how enterprises build visibility and community by rewarding creators for contributing to shared narratives. However, the extent to which exposure in generative search engine citations is shaped by external attention markets remains uncertain. In this study, we audit the exposure for 44 Web3 enterprises. First, we show that the creator community around each enterprise is persistent over time. Second, enterprise-specific queries reveal that more popular voices systematically receive greater citation exposure than others. Third, we find that larger follower bases and enterprises with more concentrated creator cores are associated with higher-ranked exposure. Together, these results show that generative search engine citations exhibit exposure bias toward already prominent voices, which risks entrenching incumbents and narrowing viewpoint diversity.",
        "url": "http://arxiv.org/abs/2601.01750v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01750v1",
        "arxiv_id": "2601.01750v1",
        "authors": [
            "Shayan Alipour",
            "Mehdi Kargar",
            "Morteza Zihayat"
        ],
        "submitted": "2026-01-05 03:01:46",
        "source": "arxiv",
        "comment": "8 pages, 2 figures",
        "score": 5,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the dynamics of generative search engines, specifically the exposure bias in citations towards prominent voices. While it touches on search technologies, its primary focus on Web3 platforms and creator ecosystems makes it somewhat related to your interests in Information Retrieval, but not directly aligned with your core research themes."
    },
    {
        "title": "EHRSummarizer: A Privacy-Aware, FHIR-Native Architecture for Structured Clinical Summarization of Electronic Health Records",
        "abstract": "Clinicians routinely navigate fragmented electronic health record (EHR) interfaces to assemble a coherent picture of a patient's problems, medications, recent encounters, and longitudinal trends. This work describes EHRSummarizer, a privacy-aware, FHIR-native reference architecture that retrieves a targeted set of high-yield FHIR R4 resources, normalizes them into a consistent clinical context package, and produces structured summaries intended to support structured chart review. The system can be configured for data minimization, stateless processing, and flexible deployment, including local inference within an organization's trust boundary. To mitigate the risk of unsupported or unsafe behavior, the summarization stage is constrained to evidence present in the retrieved context package, is intended to indicate missing or unavailable domains where feasible, and avoids diagnostic or treatment recommendations. Prototype demonstrations on synthetic and test FHIR environments illustrate end-to-end behavior and output formats; however, this manuscript does not report clinical outcomes or controlled workflow studies. We outline an evaluation plan centered on faithfulness, omission risk, temporal correctness, usability, and operational monitoring to guide future institutional assessments.",
        "url": "http://arxiv.org/abs/2601.01668v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01668v1",
        "arxiv_id": "2601.01668v1",
        "authors": [
            "Houman Kazemzadeh",
            "Nima Minaifar",
            "Kamyar Naderi",
            "Sho Tabibzadeh"
        ],
        "submitted": "2026-01-04 21:10:42",
        "source": "arxiv",
        "comment": "19 pages",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on electronic health record summarization and privacy-aware architecture, which does not align with your primary focus on Information Retrieval, Search technologies, and Natural Language Processing. Although it involves data processing and retrieval, the context and application are specific to the healthcare domain and do not overlap with your areas of interest."
    },
    {
        "title": "EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning",
        "abstract": "Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.",
        "url": "http://arxiv.org/abs/2601.02163v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02163v1",
        "arxiv_id": "2601.02163v1",
        "authors": [
            "Chuanrui Hu",
            "Xingze Gao",
            "Zuyi Zhou",
            "Dannong Xu",
            "Yi Bai",
            "Xintong Li",
            "Hui Zhang",
            "Tong Li",
            "Chong Zhang",
            "Lidong Bing",
            "Yafeng Deng"
        ],
        "submitted": "2026-01-05 14:39:43",
        "source": "arxiv",
        "comment": "16 pages, 6 figures, 12 tables. Code available at https://github.com/EverMind-AI/EverMemOS",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning is somewhat related to the user's interests in Natural Language Processing (NLP) and related topics. However, it does not directly align with the user's primary focus on Information Retrieval (IR), query understanding, ranking models, and user behavior modeling. The paper's focus on memory systems for long-term interactive agents and episodic trace formation is tangentially related to user behavior modeling, but it is not a central match."
    },
    {
        "title": "Exploring Approaches for Detecting Memorization of Recommender System Data in Large Language Models",
        "abstract": "Large Language Models (LLMs) are increasingly applied in recommendation scenarios due to their strong natural language understanding and generation capabilities. However, they are trained on vast corpora whose contents are not publicly disclosed, raising concerns about data leakage. Recent work has shown that the MovieLens-1M dataset is memorized by both the LLaMA and OpenAI model families, but the extraction of such memorized data has so far relied exclusively on manual prompt engineering. In this paper, we pose three main questions: Is it possible to enhance manual prompting? Can LLM memorization be detected through methods beyond manual prompting? And can the detection of data leakage be automated? To address these questions, we evaluate three approaches: (i) jailbreak prompt engineering; (ii) unsupervised latent knowledge discovery, probing internal activations via Contrast-Consistent Search (CCS) and Cluster-Norm; and (iii) Automatic Prompt Engineering (APE), which frames prompt discovery as a meta-learning process that iteratively refines candidate instructions. Experiments on MovieLens-1M using LLaMA models show that jailbreak prompting does not improve the retrieval of memorized items and remains inconsistent; CCS reliably distinguishes genuine from fabricated movie titles but fails on numerical user and rating data; and APE retrieves item-level information with moderate success yet struggles to recover numerical interactions. These findings suggest that automatically optimizing prompts is the most promising strategy for extracting memorized samples.",
        "url": "http://arxiv.org/abs/2601.02002v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02002v1",
        "arxiv_id": "2601.02002v1",
        "authors": [
            "Antonio Colacicco",
            "Vito Guida",
            "Dario Di Palma",
            "Fedelucio Narducci",
            "Tommaso Di Noia"
        ],
        "submitted": "2026-01-05 11:03:56",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves Large Language Models and Natural Language Understanding, its focus on recommender systems and data leakage detection is outside your primary areas of interest."
    },
    {
        "title": "A Hybrid Architecture for Multi-Stage Claim Document Understanding: Combining Vision-Language Models and Machine Learning for Real-Time Processing",
        "abstract": "Claims documents are fundamental to healthcare and insurance operations, serving as the basis for reimbursement, auditing, and compliance. However, these documents are typically not born digital; they often exist as scanned PDFs or photographs captured under uncontrolled conditions. Consequently, they exhibit significant content heterogeneity, ranging from typed invoices to handwritten medical reports, as well as linguistic diversity. This challenge is exemplified by operations at Fullerton Health, which handles tens of millions of claims annually across nine markets, including Singapore, the Philippines, Indonesia, Malaysia, Mainland China, Hong Kong, Vietnam, Papua New Guinea, and Cambodia. Such variability, coupled with inconsistent image quality and diverse layouts, poses a significant obstacle to automated parsing and structured information extraction.\n  This paper presents a robust multi-stage pipeline that integrates the multilingual optical character recognition (OCR) engine PaddleOCR, a traditional Logistic Regression classifier, and a compact Vision-Language Model (VLM), Qwen 2.5-VL-7B, to achieve efficient and accurate field extraction from large-scale claims data. The proposed system achieves a document-type classification accuracy of over 95 percent and a field-level extraction accuracy of approximately 87 percent, while maintaining an average processing latency of under 2 seconds per document. Compared to manual processing, which typically requires around 10 minutes per claim, our system delivers a 300x improvement in efficiency. These results demonstrate that combining traditional machine learning models with modern VLMs enables production-grade accuracy and speed for real-world automation. The solution has been successfully deployed in our mobile application and is currently processing tens of thousands of claims weekly from Vietnam and Singapore.",
        "url": "http://arxiv.org/abs/2601.01897v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01897v1",
        "arxiv_id": "2601.01897v1",
        "authors": [
            "Lilu Cheng",
            "Jingjun Lu",
            "Yi Xuan Chan",
            "Quoc Khai Nguyen",
            "John Bi",
            "Sean Ho"
        ],
        "submitted": "2026-01-05 08:40:44",
        "source": "arxiv",
        "comment": "19 pages, 3 figures, 3 tables",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, particularly in the context of document understanding and field extraction. However, the focus on healthcare and insurance claims documents, as well as the use of specific technologies like PaddleOCR and Qwen 2.5-VL-7B, limits its relevance to your broader interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "MergeRec: Model Merging for Data-Isolated Cross-Domain Sequential Recommendation",
        "abstract": "Modern recommender systems trained on domain-specific data often struggle to generalize across multiple domains. Cross-domain sequential recommendation has emerged as a promising research direction to address this challenge; however, existing approaches face fundamental limitations, such as reliance on overlapping users or items across domains, or unrealistic assumptions that ignore privacy constraints. In this work, we propose a new framework, MergeRec, based on model merging under a new and realistic problem setting termed data-isolated cross-domain sequential recommendation, where raw user interaction data cannot be shared across domains. MergeRec consists of three key components: (1) merging initialization, (2) pseudo-user data construction, and (3) collaborative merging optimization. First, we initialize a merged model using training-free merging techniques. Next, we construct pseudo-user data by treating each item as a virtual sequence in each domain, enabling the synthesis of meaningful training samples without relying on real user interactions. Finally, we optimize domain-specific merging weights through a joint objective that combines a recommendation loss, which encourages the merged model to identify relevant items, and a distillation loss, which transfers collaborative filtering signals from the fine-tuned source models. Extensive experiments demonstrate that MergeRec not only preserves the strengths of the original models but also significantly enhances generalizability to unseen domains. Compared to conventional model merging methods, MergeRec consistently achieves superior performance, with average improvements of up to 17.21% in Recall@10, highlighting the potential of model merging as a scalable and effective approach for building universal recommender systems. The source code is available at https://github.com/DIALLab-SKKU/MergeRec.",
        "url": "http://arxiv.org/abs/2601.01753v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01753v1",
        "arxiv_id": "2601.01753v1",
        "authors": [
            "Hyunsoo Kim",
            "Jaewan Moon",
            "Seongmin Park",
            "Jongwuk Lee"
        ],
        "submitted": "2026-01-05 03:14:23",
        "source": "arxiv",
        "comment": "Accepted by KDD 2026",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on recommender systems, specifically proposing a framework for cross-domain sequential recommendation. While it touches on model merging and optimization, it doesn't directly relate to information retrieval, query understanding, or ranking models, which are core areas of your research interests."
    },
    {
        "title": "DeCode: Decoupling Content and Delivery for Medical QA",
        "abstract": "Large language models (LLMs) exhibit strong medical knowledge and can generate factually accurate responses. However, existing models often fail to account for individual patient contexts, producing answers that are clinically correct yet poorly aligned with patients' needs. In this work, we introduce DeCode, a training-free, model-agnostic framework that adapts existing LLMs to produce contextualized answers in clinical settings. We evaluate DeCode on OpenAI HealthBench, a comprehensive and challenging benchmark designed to assess clinical relevance and validity of LLM responses. DeCode improves the previous state of the art from $28.4\\%$ to $49.8\\%$, corresponding to a $75\\%$ relative improvement. Experimental results suggest the effectiveness of DeCode in improving clinical question answering of LLMs.",
        "url": "http://arxiv.org/abs/2601.02123v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02123v1",
        "arxiv_id": "2601.02123v1",
        "authors": [
            "Po-Jen Ko",
            "Chen-Han Tsai",
            "Yu-Shao Peng"
        ],
        "submitted": "2026-01-05 13:54:38",
        "source": "arxiv",
        "comment": "Preprint",
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and query understanding, as it involves adapting large language models for clinical question answering. However, the focus on medical QA and clinical relevance is not directly aligned with your primary interest in information retrieval and search technologies. The paper's relevance is also limited by its lack of connection to ranking models and user behavior modeling."
    },
    {
        "title": "Simulated Reasoning is Reasoning",
        "abstract": "Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., \"symbolic reasoning\". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can \"reason\" by way of imitating the process of \"thinking out loud\", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the \"stochastic parrot\" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.",
        "url": "http://arxiv.org/abs/2601.02043v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02043v1",
        "arxiv_id": "2601.02043v1",
        "authors": [
            "Hendrik Kempt",
            "Alon Lavie"
        ],
        "submitted": "2026-01-05 12:00:04",
        "source": "arxiv",
        "comment": "21 pages",
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. It discusses the concept of reasoning in the context of artificial intelligence and foundational models, which is unrelated to your areas of focus."
    },
    {
        "title": "Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations",
        "abstract": "ChatGPT has emerged as a versatile tool, demonstrating capabilities across diverse domains. Given these successes, the Recommender Systems (RSs) community has begun investigating its applications within recommendation scenarios primarily focusing on accuracy. While the integration of ChatGPT into RSs has garnered significant attention, a comprehensive analysis of its performance across various dimensions remains largely unexplored. Specifically, the capabilities of providing diverse and novel recommendations or exploring potential biases such as popularity bias have not been thoroughly examined. As the use of these models continues to expand, understanding these aspects is crucial for enhancing user satisfaction and achieving long-term personalization.\n  This study investigates the recommendations provided by ChatGPT-3.5 and ChatGPT-4 by assessing ChatGPT's capabilities in terms of diversity, novelty, and popularity bias. We evaluate these models on three distinct datasets and assess their performance in Top-N recommendation and cold-start scenarios. The findings reveal that ChatGPT-4 matches or surpasses traditional recommenders, demonstrating the ability to balance novelty and diversity in recommendations. Furthermore, in the cold-start scenario, ChatGPT models exhibit superior performance in both accuracy and novelty, suggesting they can be particularly beneficial for new users. This research highlights the strengths and limitations of ChatGPT's recommendations, offering new perspectives on the capacity of these models to provide recommendations beyond accuracy-focused metrics.",
        "url": "http://arxiv.org/abs/2601.01997v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01997v1",
        "arxiv_id": "2601.01997v1",
        "authors": [
            "Dario Di Palma",
            "Giovanni Maria Biancofiore",
            "Vito Walter Anelli",
            "Fedelucio Narducci",
            "Tommaso Di Noia"
        ],
        "submitted": "2026-01-05 10:56:01",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'personalization' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the capabilities of ChatGPT in recommendation systems, specifically focusing on diversity, novelty, and popularity bias. While it touches on aspects related to information retrieval, such as ranking models and user behavior modeling, the primary focus is on recommender systems, which is a related but secondary interest. The paper's emphasis on ChatGPT's strengths and limitations in recommendation scenarios is somewhat relevant to the user's interests in search technologies and query understanding."
    },
    {
        "title": "CSF: Contrastive Semantic Features for Direct Multilingual Sign Language Generation",
        "abstract": "Sign language translation systems typically require English as an intermediary language, creating barriers for non-English speakers in the global deaf community. We present Canonical Semantic Form (CSF), a language-agnostic semantic representation framework that enables direct translation from any source language to sign language without English mediation. CSF decomposes utterances into nine universal semantic slots: event, intent, time, condition, agent, object, location, purpose, and modifier. A key contribution is our comprehensive condition taxonomy comprising 35 condition types across eight semantic categories, enabling nuanced representation of conditional expressions common in everyday communication. We train a lightweight transformer-based extractor (0.74 MB) that achieves 99.03% average slot extraction accuracy across four typologically diverse languages: English, Vietnamese, Japanese, and French. The model demonstrates particularly strong performance on condition classification (99.4% accuracy) despite the 35-class complexity. With inference latency of 3.02ms on CPU, our approach enables real-time sign language generation in browser-based applications. We release our code, trained models, and multilingual dataset to support further research in accessible sign language technology.",
        "url": "http://arxiv.org/abs/2601.01964v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01964v1",
        "arxiv_id": "2601.01964v1",
        "authors": [
            "Tran Sy Bao"
        ],
        "submitted": "2026-01-05 10:15:35",
        "source": "arxiv",
        "comment": "9 pages, 8 tables, code available at https://github.com/transybao1393/csf-sign-language",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on sign language generation and translation, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language understanding and generation, the context and application are quite different from the user's areas of focus."
    },
    {
        "title": "The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities",
        "abstract": "In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.\n  We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.",
        "url": "http://arxiv.org/abs/2601.01944v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01944v1",
        "arxiv_id": "2601.01944v1",
        "authors": [
            "Matteo Esposito",
            "Andrea Janes",
            "Valentina Lenarduzzi",
            "Davide Taibi"
        ],
        "submitted": "2026-01-05 09:50:37",
        "source": "arxiv",
        "comment": "ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026",
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be unrelated to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on AI, its focus is on the adoption and impact of AI libraries in Open Source Software projects, which is outside your primary areas of interest."
    },
    {
        "title": "CD4LM: Consistency Distillation and aDaptive Decoding for Diffusion Language Models",
        "abstract": "Autoregressive large language models achieve strong results on many benchmarks, but decoding remains fundamentally latency-limited by sequential dependence on previously generated tokens. Diffusion language models (DLMs) promise parallel generation but suffer from a fundamental static-to-dynamic misalignment: Training optimizes local transitions under fixed schedules, whereas efficient inference requires adaptive \"long-jump\" refinements through unseen states. Our goal is to enable highly parallel decoding for DLMs with low number of function evaluations while preserving generation quality. To achieve this, we propose CD4LM, a framework that decouples training from inference via Discrete-Space Consistency Distillation (DSCD) and Confidence-Adaptive Decoding (CAD). Unlike standard objectives, DSCD trains a student to be trajectory-invariant, mapping diverse noisy states directly to the clean distribution. This intrinsic robustness enables CAD to dynamically allocate compute resources based on token confidence, aggressively skipping steps without the quality collapse typical of heuristic acceleration. On GSM8K, CD4LM matches the LLaDA baseline with a 5.18x wall-clock speedup; across code and math benchmarks, it strictly dominates the accuracy-efficiency Pareto frontier, achieving a 3.62x mean speedup while improving average accuracy. Code is available at https://github.com/yihao-liang/CDLM",
        "url": "http://arxiv.org/abs/2601.02236v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02236v1",
        "arxiv_id": "2601.02236v1",
        "authors": [
            "Yihao Liang",
            "Ze Wang",
            "Hao Chen",
            "Ximeng Sun",
            "Jialian Wu",
            "Xiaodong Yu",
            "Jiang Liu",
            "Emad Barsoum",
            "Zicheng Liu",
            "Niraj K. Jha"
        ],
        "submitted": "2026-01-05 16:09:22",
        "source": "arxiv",
        "comment": "33 pages, 7 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving the efficiency of diffusion language models through a novel framework called CD4LM. While it involves language models, which are related to NLP, the primary focus is on improving the efficiency of the model rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest for your research."
    },
    {
        "title": "Toward Global Large Language Models in Medicine",
        "abstract": "Despite continuous advances in medical technology, the global distribution of health care resources remains uneven. The development of large language models (LLMs) has transformed the landscape of medicine and holds promise for improving health care quality and expanding access to medical information globally. However, existing LLMs are primarily trained on high-resource languages, limiting their applicability in global medical scenarios. To address this gap, we constructed GlobMed, a large multilingual medical dataset, containing over 500,000 entries spanning 12 languages, including four low-resource languages. Building on this, we established GlobMed-Bench, which systematically assesses 56 state-of-the-art proprietary and open-weight LLMs across multiple multilingual medical tasks, revealing significant performance disparities across languages, particularly for low-resource languages. Additionally, we introduced GlobMed-LLMs, a suite of multilingual medical LLMs trained on GlobMed, with parameters ranging from 1.7B to 8B. GlobMed-LLMs achieved an average performance improvement of over 40% relative to baseline models, with a more than threefold increase in performance on low-resource languages. Together, these resources provide an important foundation for advancing the equitable development and application of LLMs globally, enabling broader language communities to benefit from technological advances.",
        "url": "http://arxiv.org/abs/2601.02186v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02186v1",
        "arxiv_id": "2601.02186v1",
        "authors": [
            "Rui Yang",
            "Huitao Li",
            "Weihao Xuan",
            "Heli Qi",
            "Xin Li",
            "Kunyu Yu",
            "Yingjian Chen",
            "Rongrong Wang",
            "Jacques Behmoaras",
            "Tianxi Cai",
            "Bibhas Chakraborty",
            "Qingyu Chen",
            "Lionel Tim-Ee Cheng",
            "Marie-Louise Damwanza",
            "Chido Dzinotyiwei",
            "Aosong Feng",
            "Chuan Hong",
            "Yusuke Iwasawa",
            "Yuhe Ke",
            "Linah Kitala",
            "Taehoon Ko",
            "Jisan Lee",
            "Irene Li",
            "Jonathan Chong Kai Liew",
            "Hongfang Liu",
            "Lian Leng Low",
            "Edison Marrese-Taylor",
            "Yutaka Matsuo",
            "Isheanesu Misi",
            "Yilin Ning",
            "Jasmine Chiat Ling Ong",
            "Marcus Eng Hock Ong",
            "Enrico Petretto",
            "Hossein Rouhizadeh",
            "Abiram Sandralegar",
            "Oren Schreier",
            "Iain Bee Huat Tan",
            "Patrick Tan",
            "Daniel Shu Wei Ting",
            "Junjue Wang",
            "Chunhua Weng",
            "Matthew Yu Heng Wong",
            "Fang Wu",
            "Yunze Xiao",
            "Xuhai Xu",
            "Qingcheng Zeng",
            "Zhuo Zheng",
            "Yifan Peng",
            "Douglas Teodoro",
            "Nan Liu"
        ],
        "submitted": "2026-01-05 15:05:49",
        "source": "arxiv",
        "comment": "182 pages, 65 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on large language models in medicine, which is outside your primary research interests in Information Retrieval and Search technologies. While it touches on multilingual tasks, the context is medical and not directly related to your areas of expertise."
    },
    {
        "title": "Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts",
        "abstract": "Mixture-of-Experts (MoE) architectures scale large language models efficiently by employing a parametric \"router\" to dispatch tokens to a sparse subset of experts. Typically, this router is trained once and then frozen, rendering routing decisions brittle under distribution shifts. We address this limitation by introducing kNN-MoE, a retrieval-augmented routing framework that reuses optimal expert assignments from a memory of similar past cases. This memory is constructed offline by directly optimizing token-wise routing logits to maximize the likelihood on a reference set. Crucially, we use the aggregate similarity of retrieved neighbors as a confidence-driven mixing coefficient, thus allowing the method to fall back to the frozen router when no relevant cases are found. Experiments show kNN-MoE outperforms zero-shot baselines and rivals computationally expensive supervised fine-tuning.",
        "url": "http://arxiv.org/abs/2601.02144v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02144v1",
        "arxiv_id": "2601.02144v1",
        "authors": [
            "Boxuan Lyu",
            "Soichiro Murakami",
            "Hidetaka Kamigaito",
            "Peinan Zhang"
        ],
        "submitted": "2026-01-05 14:16:11",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper explores a novel approach to routing in Mixture-of-Experts architectures, leveraging retrieval-augmented routing to improve performance under distribution shifts. While it touches on search and retrieval, its primary focus is on improving the efficiency of large language models, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the paper's emphasis on routing and mixture-of-experts architectures is not a central match for your research themes."
    },
    {
        "title": "Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows",
        "abstract": "Diffusion language models (DLMs) have recently emerged as a strong alternative to autoregressive models by enabling parallel text generation. To improve inference efficiency and KV-cache compatibility, prior work commonly adopts block-based diffusion, decoding tokens block by block. However, this paradigm suffers from a structural limitation that we term Boundary-Induced Context Truncation (BICT): undecoded tokens near block boundaries are forced to commit without access to nearby future context, even when such context could substantially reduce uncertainty. This limitation degrades decoding confidence and generation quality, especially for tasks requiring precise reasoning, such as mathematical problem solving and code generation. We propose Deferred Commitment Decoding (DCD), a novel, training-free decoding strategy that mitigates this issue. DCD maintains a confidence-aware sliding window over masked tokens, resolving low-uncertainty tokens early while deferring high-uncertainty tokens until sufficient contextual evidence becomes available. This design enables effective bidirectional information flow within the decoding window without sacrificing efficiency. Extensive experiments across multiple diffusion language models, benchmarks, and caching configurations show that DCD improves generation accuracy by 1.39% with comparable time on average compared to fixed block-based diffusion methods, with the most significant improvement reaching 9.0%. These results demonstrate that deferring token commitment based on uncertainty is a simple yet effective principle for improving both the quality and efficiency of diffusion language model decoding.",
        "url": "http://arxiv.org/abs/2601.02076v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02076v1",
        "arxiv_id": "2601.02076v1",
        "authors": [
            "Yingte Shu",
            "Yuchuan Tian",
            "Chao Xu",
            "Yunhe Wang",
            "Hanting Chen"
        ],
        "submitted": "2026-01-05 12:57:33",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is about improving the efficiency and accuracy of diffusion language models, which is a topic in Natural Language Processing (NLP). However, it does not appear to be directly related to your core research interests in Information Retrieval (IR), query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "DermoGPT: Open Weights and Open Data for Morphology-Grounded Dermatological Reasoning MLLMs",
        "abstract": "Multimodal Large Language Models (MLLMs) show promise for medical applications, yet progress in dermatology lags due to limited training data, narrow task coverage, and lack of clinically-grounded supervision that mirrors expert diagnostic workflows. We present a comprehensive framework to address these gaps. First, we introduce DermoInstruct, a large-scale morphology-anchored instruction corpus comprising 211,243 images and 772,675 trajectories across five task formats, capturing the complete diagnostic pipeline from morphological observation and clinical reasoning to final diagnosis. Second, we establish DermoBench, a rigorous benchmark evaluating 11 tasks across four clinical axes: Morphology, Diagnosis, Reasoning, and Fairness, including a challenging subset of 3,600 expert-verified open-ended instances and human performance baselines. Third, we develop DermoGPT, a dermatology reasoning MLLM trained via supervised fine-tuning followed by our Morphologically-Anchored Visual-Inference-Consistent (MAVIC) reinforcement learning objective, which enforces consistency between visual observations and diagnostic conclusions. At inference, we deploy Confidence-Consistency Test-time adaptation (CCT) for robust predictions. Experiments show DermoGPT significantly outperforms 16 representative baselines across all axes, achieving state-of-the-art performance while substantially narrowing the human-AI gap. DermoInstruct, DermoBench and DermoGPT will be made publicly available at https://github.com/mendicant04/DermoGPT upon acceptance.",
        "url": "http://arxiv.org/abs/2601.01868v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01868v1",
        "arxiv_id": "2601.01868v1",
        "authors": [
            "Jinghan Ru",
            "Siyuan Yan",
            "Yuguo Yin",
            "Yuexian Zou",
            "Zongyuan Ge"
        ],
        "submitted": "2026-01-05 07:55:36",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on dermatology and multimodal large language models, which is not directly related to the user's core research themes in Information Retrieval and Search technologies. Although it involves a form of reasoning, it's grounded in a specific medical domain and doesn't align with the user's interests in query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Aspect Extraction from E-Commerce Product and Service Reviews",
        "abstract": "Aspect Extraction (AE) is a key task in Aspect-Based Sentiment Analysis (ABSA), yet it remains difficult to apply in low-resource and code-switched contexts like Taglish, a mix of Tagalog and English commonly used in Filipino e-commerce reviews. This paper introduces a comprehensive AE pipeline designed for Taglish, combining rule-based, large language model (LLM)-based, and fine-tuning techniques to address both aspect identification and extraction. A Hierarchical Aspect Framework (HAF) is developed through multi-method topic modeling, along with a dual-mode tagging scheme for explicit and implicit aspects. For aspect identification, four distinct models are evaluated: a Rule-Based system, a Generative LLM (Gemini 2.0 Flash), and two Fine-Tuned Gemma-3 1B models trained on different datasets (Rule-Based vs. LLM-Annotated). Results indicate that the Generative LLM achieved the highest performance across all tasks (Macro F1 0.91), demonstrating superior capability in handling implicit aspects. In contrast, the fine-tuned models exhibited limited performance due to dataset imbalance and architectural capacity constraints. This work contributes a scalable and linguistically adaptive framework for enhancing ABSA in diverse, code-switched environments.",
        "url": "http://arxiv.org/abs/2601.01827v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01827v1",
        "arxiv_id": "2601.01827v1",
        "authors": [
            "Valiant Lance D. Dionela",
            "Fatima Kriselle S. Dy",
            "Robin James M. Hombrebueno",
            "Aaron Rae M. Nicolas",
            "Charibeth K. Cheng",
            "Raphael W. Gonda"
        ],
        "submitted": "2026-01-05 06:45:51",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on Aspect Extraction, a task in Aspect-Based Sentiment Analysis, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the paper's primary focus on NLP and ABSA, while relevant to your broader interests, does not directly align with your core research themes in IR and search technologies."
    },
    {
        "title": "CSCBench: A PVC Diagnostic Benchmark for Commodity Supply Chain Reasoning",
        "abstract": "Large Language Models (LLMs) have achieved remarkable success in general benchmarks, yet their competence in commodity supply chains (CSCs) -- a domain governed by institutional rule systems and feasibility constraints -- remains under-explored. CSC decisions are shaped jointly by process stages (e.g., planning, procurement, delivery), variety-specific rules (e.g., contract specifications and delivery grades), and reasoning depth (from retrieval to multi-step analysis and decision selection). We introduce CSCBench, a 2.3K+ single-choice benchmark for CSC reasoning, instantiated through our PVC 3D Evaluation Framework (Process, Variety, and Cognition). The Process axis aligns tasks with SCOR+Enable; the Variety axis operationalizes commodity-specific rule systems under coupled material-information-financial constraints, grounded in authoritative exchange guidebooks/rulebooks and industry reports; and the Cognition axis follows Bloom's revised taxonomy. Evaluating representative LLMs under a direct prompting setting, we observe strong performance on the Process and Cognition axes but substantial degradation on the Variety axis, especially on Freight Agreements. CSCBench provides a diagnostic yardstick for measuring and improving LLM capabilities in this high-stakes domain.",
        "url": "http://arxiv.org/abs/2601.01825v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01825v1",
        "arxiv_id": "2601.01825v1",
        "authors": [
            "Yaxin Cui",
            "Yuanqiang Zeng",
            "Jiapeng Yan",
            "Keling Lin",
            "Kai Ji",
            "Jianhui Zeng",
            "Sheng Zhang",
            "Xin Luo",
            "Binzhu Su",
            "Chaolai Shen",
            "Jiahao Yu"
        ],
        "submitted": "2026-01-05 06:44:29",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on a commodity supply chain reasoning benchmark, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves Large Language Models, the context is specific to supply chain reasoning and does not align with the user's core themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "HyperCLOVA X 8B Omni",
        "abstract": "In this report, we present HyperCLOVA X 8B Omni, the first any-to-any omnimodal model in the HyperCLOVA X family that supports text, audio, and vision as both inputs and outputs. By consolidating multimodal understanding and generation into a single model rather than separate modality-specific pipelines, HyperCLOVA X 8B Omni serves as an 8B-scale omni-pathfinding point toward practical any-to-any omni assistants. At a high level, the model unifies modalities through a shared next-token prediction interface over an interleaved multimodal sequence, while vision and audio encoders inject continuous embeddings for fine-grained understanding and grounding. Empirical evaluations demonstrate competitive performance against comparably sized models across diverse input-output combinations spanning text, audio, and vision, in both Korean and English. We anticipate that the open-weight release of HyperCLOVA X 8B Omni will support a wide range of research and deployment scenarios.",
        "url": "http://arxiv.org/abs/2601.01792v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01792v1",
        "arxiv_id": "2601.01792v1",
        "authors": [
            "NAVER Cloud HyperCLOVA X Team"
        ],
        "submitted": "2026-01-05 05:06:11",
        "source": "arxiv",
        "comment": "Technical Report",
        "score": 2,
        "keyword_reasons": [
            "Found 'search' (score: +1)",
            "Found 'korea' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a multimodal model that supports text, audio, and vision inputs and outputs, which is somewhat related to information retrieval and NLP. However, the focus on multimodal understanding and generation is not directly aligned with the user's primary research interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is mostly limited to the broader NLP domain."
    },
    {
        "title": "BanglaIPA: Towards Robust Text-to-IPA Transcription with Contextual Rewriting in Bengali",
        "abstract": "Despite its widespread use, Bengali lacks a robust automated International Phonetic Alphabet (IPA) transcription system that effectively supports both standard language and regional dialectal texts. Existing approaches struggle to handle regional variations, numerical expressions, and generalize poorly to previously unseen words. To address these limitations, we propose BanglaIPA, a novel IPA generation system that integrates a character-based vocabulary with word-level alignment. The proposed system accurately handles Bengali numerals and demonstrates strong performance across regional dialects. BanglaIPA improves inference efficiency by leveraging a precomputed word-to-IPA mapping dictionary for previously observed words. The system is evaluated on the standard Bengali and six regional variations of the DUAL-IPA dataset. Experimental results show that BanglaIPA outperforms baseline IPA transcription models by 58.4-78.7% and achieves an overall mean word error rate of 11.4%, highlighting its robustness in phonetic transcription generation for the Bengali language.",
        "url": "http://arxiv.org/abs/2601.01778v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01778v1",
        "arxiv_id": "2601.01778v1",
        "authors": [
            "Jakir Hasan",
            "Shrestha Datta",
            "Md Saiful Islam",
            "Shubhashis Roy Dipta",
            "Ameya Debnath"
        ],
        "submitted": "2026-01-05 04:17:31",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing, as it focuses on text-to-IPA transcription in Bengali and does not address query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Multi-granularity Interactive Attention Framework for Residual Hierarchical Pronunciation Assessment",
        "abstract": "Automatic pronunciation assessment plays a crucial role in computer-assisted pronunciation training systems. Due to the ability to perform multiple pronunciation tasks simultaneously, multi-aspect multi-granularity pronunciation assessment methods are gradually receiving more attention and achieving better performance than single-level modeling tasks. However, existing methods only consider unidirectional dependencies between adjacent granularity levels, lacking bidirectional interaction among phoneme, word, and utterance levels and thus insufficiently capturing the acoustic structural correlations. To address this issue, we propose a novel residual hierarchical interactive method, HIA for short, that enables bidirectional modeling across granularities. As the core of HIA, the Interactive Attention Module leverages an attention mechanism to achieve dynamic bidirectional interaction, effectively capturing linguistic features at each granularity while integrating correlations between different granularity levels. We also propose a residual hierarchical structure to alleviate the feature forgetting problem when modeling acoustic hierarchies. In addition, we use 1-D convolutional layers to enhance the extraction of local contextual cues at each granularity. Extensive experiments on the speechocean762 dataset show that our model is comprehensively ahead of the existing state-of-the-art methods.",
        "url": "http://arxiv.org/abs/2601.01745v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01745v1",
        "arxiv_id": "2601.01745v1",
        "authors": [
            "Hong Han",
            "Hao-Chen Pei",
            "Zhao-Zheng Nie",
            "Xin Luo",
            "Xin-Shun Xu"
        ],
        "submitted": "2026-01-05 02:43:04",
        "source": "arxiv",
        "comment": "9 pages, 4 figures, 5 tables, accepted by AAAI 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. The focus is on automatic pronunciation assessment and speech processing, which is outside your primary areas of interest."
    },
    {
        "title": "K-EXAONE Technical Report",
        "abstract": "This technical report presents K-EXAONE, a large-scale multilingual language model developed by LG AI Research. K-EXAONE is built on a Mixture-of-Experts architecture with 236B total parameters, activating 23B parameters during inference. It supports a 256K-token context window and covers six languages: Korean, English, Spanish, German, Japanese, and Vietnamese. We evaluate K-EXAONE on a comprehensive benchmark suite spanning reasoning, agentic, general, Korean, and multilingual abilities. Across these evaluations, K-EXAONE demonstrates performance comparable to open-weight models of similar size. K-EXAONE, designed to advance AI for a better life, is positioned as a powerful proprietary AI foundation model for a wide range of industrial and research applications.",
        "url": "http://arxiv.org/abs/2601.01739v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01739v1",
        "arxiv_id": "2601.01739v1",
        "authors": [
            "Eunbi Choi",
            "Kibong Choi",
            "Seokhee Hong",
            "Junwon Hwang",
            "Hyojin Jeon",
            "Hyunjik Jo",
            "Joonkee Kim",
            "Seonghwan Kim",
            "Soyeon Kim",
            "Sunkyoung Kim",
            "Yireun Kim",
            "Yongil Kim",
            "Haeju Lee",
            "Jinsik Lee",
            "Kyungmin Lee",
            "Sangha Park",
            "Heuiyeen Yeen",
            "Hwan Chang",
            "Stanley Jungkyu Choi",
            "Yejin Choi",
            "Jiwon Ham",
            "Kijeong Jeon",
            "Geunyeong Jeong",
            "Gerrard Jeongwon Jo",
            "Yonghwan Jo",
            "Jiyeon Jung",
            "Naeun Kang",
            "Dohoon Kim",
            "Euisoon Kim",
            "Hayeon Kim",
            "Hyosang Kim",
            "Hyunseo Kim",
            "Jieun Kim",
            "Minu Kim",
            "Myoungshin Kim",
            "Unsol Kim",
            "Youchul Kim",
            "YoungJin Kim",
            "Chaeeun Lee",
            "Chaeyoon Lee",
            "Changhun Lee",
            "Dahm Lee",
            "Edward Hwayoung Lee",
            "Honglak Lee",
            "Jinsang Lee",
            "Jiyoung Lee",
            "Sangeun Lee",
            "Seungwon Lim",
            "Solji Lim",
            "Woohyung Lim",
            "Chanwoo Moon",
            "Jaewoo Park",
            "Jinho Park",
            "Yongmin Park",
            "Hyerin Seo",
            "Wooseok Seo",
            "Yongwoo Song",
            "Sejong Yang",
            "Sihoon Yang",
            "Chang En Yea",
            "Sihyuk Yi",
            "Chansik Yoon",
            "Dongkeun Yoon",
            "Sangyeon Yoon",
            "Hyeongu Yun"
        ],
        "submitted": "2026-01-05 02:30:59",
        "source": "arxiv",
        "comment": "29 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'search' (score: +1)",
            "Found 'korea' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be about a large-scale multilingual language model, which is related to Natural Language Processing (NLP), but it does not seem to focus on information retrieval, query understanding, or ranking models, which are the core areas of your research interests."
    },
    {
        "title": "Lying with Truths: Open-Channel Multi-Agent Collusion for Belief Manipulation via Generative Montage",
        "abstract": "As large language models (LLMs) transition to autonomous agents synthesizing real-time information, their reasoning capabilities introduce an unexpected attack surface. This paper introduces a novel threat where colluding agents steer victim beliefs using only truthful evidence fragments distributed through public channels, without relying on covert communications, backdoors, or falsified documents. By exploiting LLMs' overthinking tendency, we formalize the first cognitive collusion attack and propose Generative Montage: a Writer-Editor-Director framework that constructs deceptive narratives through adversarial debate and coordinated posting of evidence fragments, causing victims to internalize and propagate fabricated conclusions. To study this risk, we develop CoPHEME, a dataset derived from real-world rumor events, and simulate attacks across diverse LLM families. Our results show pervasive vulnerability across 14 LLM families: attack success rates reach 74.4% for proprietary models and 70.6% for open-weights models. Counterintuitively, stronger reasoning capabilities increase susceptibility, with reasoning-specialized models showing higher attack success than base models or prompts. Furthermore, these false beliefs then cascade to downstream judges, achieving over 60% deception rates, highlighting a socio-technical vulnerability in how LLM-based agents interact with dynamic information environments. Our implementation and data are available at: https://github.com/CharlesJW222/Lying_with_Truth/tree/main.",
        "url": "http://arxiv.org/abs/2601.01685v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01685v1",
        "arxiv_id": "2601.01685v1",
        "authors": [
            "Jinwei Hu",
            "Xinmiao Huang",
            "Youcheng Sun",
            "Yi Dong",
            "Xiaowei Huang"
        ],
        "submitted": "2026-01-04 22:50:23",
        "source": "arxiv",
        "comment": "Under Review",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be unrelated to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on Generative Montage and cognitive collusion attacks in large language models does not align with your areas of expertise."
    },
    {
        "title": "Classifying several dialectal Nawatl varieties",
        "abstract": "Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.",
        "url": "http://arxiv.org/abs/2601.02303v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02303v1",
        "arxiv_id": "2601.02303v1",
        "authors": [
            "Juan-Jos Guzmn-Landa",
            "Juan-Manuel Torres-Moreno",
            "Miguel Figueroa-Saavedra",
            "Carlos-Emiliano Gonzlez-Gallardo",
            "Graham Ranger",
            "Martha Lorena-Avendao-Garrido"
        ],
        "submitted": "2026-01-05 17:38:55",
        "source": "arxiv",
        "comment": "9 pages, 5 figures, 4 tables",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on language classification using Machine Learning and Neural Networks, which is related to Natural Language Processing (NLP), but it does not align with the user's primary research interests in Information Retrieval, query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Confidence Estimation for LLMs in Multi-turn Interactions",
        "abstract": "While confidence estimation is a promising direction for mitigating hallucinations in Large Language Models (LLMs), current research dominantly focuses on single-turn settings. The dynamics of model confidence in multi-turn conversations, where context accumulates and ambiguity is progressively resolved, remain largely unexplored. Reliable confidence estimation in multi-turn settings is critical for many downstream applications, such as autonomous agents and human-in-the-loop systems. This work presents the first systematic study of confidence estimation in multi-turn interactions, establishing a formal evaluation framework grounded in two key desiderata: per-turn calibration and monotonicity of confidence as more information becomes available. To facilitate this, we introduce novel metrics, including a length-normalized Expected Calibration Error (InfoECE), and a new \"Hinter-Guesser\" paradigm for generating controlled evaluation datasets. Our experiments reveal that widely-used confidence techniques struggle with calibration and monotonicity in multi-turn dialogues. We propose P(Sufficient), a logit-based probe that achieves comparatively better performance, although the task remains far from solved. Our work provides a foundational methodology for developing more reliable and trustworthy conversational agents.",
        "url": "http://arxiv.org/abs/2601.02179v1",
        "pdf_url": "https://arxiv.org/pdf/2601.02179v1",
        "arxiv_id": "2601.02179v1",
        "authors": [
            "Caiqi Zhang",
            "Ruihan Yang",
            "Xiaochen Zhu",
            "Chengzu Li",
            "Tiancheng Hu",
            "Yijiang River Dong",
            "Deqing Yang",
            "Nigel Collier"
        ],
        "submitted": "2026-01-05 14:58:04",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper is somewhat related to the user's interests in Information Retrieval, particularly in the context of query understanding and ranking models. Although it focuses on Large Language Models and conversational agents, it explores confidence estimation and calibration, which are relevant to the user's background in e-commerce and NLP. However, the paper's primary focus on multi-turn interactions and conversational agents makes it less central to the user's core research themes."
    },
    {
        "title": "A Defect is Being Born: How Close Are We? A Time Sensitive Forecasting Approach",
        "abstract": "Background. Defect prediction has been a highly active topic among researchers in the Empirical Software Engineering field. Previous literature has successfully achieved the most accurate prediction of an incoming fault and identified the features and anomalies that precede it through just-in-time prediction. As software systems evolve continuously, there is a growing need for time-sensitive methods capable of forecasting defects before they manifest.\n  Aim. Our study seeks to explore the effectiveness of time-sensitive techniques for defect forecasting. Moreover, we aim to investigate the early indicators that precede the occurrence of a defect.\n  Method. We will train multiple time-sensitive forecasting techniques to forecast the future bug density of a software project, as well as identify the early symptoms preceding the occurrence of a defect.\n  Expected results. Our expected results are translated into empirical evidence on the effectiveness of our approach for early estimation of bug proneness.",
        "url": "http://arxiv.org/abs/2601.01921v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01921v1",
        "arxiv_id": "2601.01921v1",
        "authors": [
            "Mikel Robredo",
            "Matteo Esposito",
            "Fabio Palomba",
            "Rafael Pealoza",
            "Valentina Lenarduzzi"
        ],
        "submitted": "2026-01-05 09:11:29",
        "source": "arxiv",
        "comment": "ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. It focuses on defect prediction in software engineering, which is outside your primary areas of interest."
    },
    {
        "title": "A Training-Free Large Reasoning Model-based Knowledge Tracing Framework for Unified Prediction and Prescription",
        "abstract": "Knowledge Tracing (KT) aims to estimate a learner's evolving mastery based on interaction histories. Recent studies have explored Large Language Models (LLMs) for KT via autoregressive nature, but such approaches typically require fine-tuning and exhibit unstable or near-random performance. Moreover, prior KT systems primarily focus on prediction and rely on multi-stage pipelines for feedback and recommendation, resulting in increased system complexity and resources. To address this gap, we propose Thinking-KT, a training-free KT framework that incorporates Test-Time Scaling (TTS), enabling even small LLMs to achieve competitive KT performance. Moreover, in this framework, a small LLM can jointly perform KT prediction, personalized feedback generation, and learning recommendation in a unified output without degrading prediction accuracy. Beyond performance, we present the systematic analysis of reasoning traces in KT. Our results demonstrate that TTS is a critical yet underexplored factor in LLM-based KT, and that small LLMs can serve as unified ITS engines.",
        "url": "http://arxiv.org/abs/2601.01708v1",
        "pdf_url": "https://arxiv.org/pdf/2601.01708v1",
        "arxiv_id": "2601.01708v1",
        "authors": [
            "Unggi Lee",
            "Joo Young Kim",
            "Ran Ju",
            "Minyoung Jung",
            "Jeyeon Eo"
        ],
        "submitted": "2026-01-05 01:02:21",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Knowledge Tracing, a field not directly related to the user's core research themes in Information Retrieval and Search technologies. While it involves Large Language Models, the application is in a different domain and does not align with the user's interests in query understanding, ranking models, or user behavior modeling."
    }
]