# Daily Papers Report - 2025-07-16

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Aligned Query Expansion: Efficient Query Expansion for Information Retrieval through LLM Alignment

- **LLM Score**: 8
- **Keyword Score**: 19
- **Authors**: Adam Yang, Gustavo Penha, Enrico Palumbo, Hugues Bouchard
- **URL**: <http://arxiv.org/abs/2507.11042v1>
- **Submitted**: 2025-07-15 07:11:29
- **Topic Keywords**: information retrieval, passage retrieval, query, queries, relevance, rag, retrieval
- **Reason**: The paper focuses on query expansion techniques in information retrieval, leveraging large language models (LLMs) for alignment, which aligns with your interest in query understanding and ranking models. The approach also addresses the vocabulary mismatch problem, a common issue in IR, and demonstrates improvements in retrieval effectiveness, making it a relevant contribution to the field.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Aligned Query Expansion (AQE) for Passage Retrieval in Open-Domain Question Answering
- **Aim**: To develop a novel approach to enhance query expansion for passage retrieval in open-domain question answering
- **Rationale**: Traditional query expansion techniques are costly and do not optimize query generation, leading to reduced retrieval effectiveness
- **Ground**: Recent techniques in Large Language Model (LLM) alignment and document expansion
- **Experiment**: Empirical evaluations on four public datasets (Natural Questions, TriviaQA, WebQA, and Entity Questions) comparing AQE with baseline models
- **Takeaway**: AQE surpasses baseline models in retrieval effectiveness, reduces computational overhead, and is a promising solution for real-world systems

#### Abstract
> With the breakthroughs in large language models (LLMs), query generation
techniques that expand documents and queries with related terms are becoming
increasingly popular in the information retrieval field. Such techniques have
been shown to improve the effectiveness of traditional lexical retrieval
methods by dealing with the vocabulary mismatch problem. Recent work has found
that generating queries with a greedy decoding strategy can produce sub-optimal
queries, including hallucinations, and proposed to filter out queries before
expansion. This `generate-then-filter' approach is costly, as it requires
generating multiple queries and applying a relevance model to all of them and
does not teach the LLM which of the generated queries is more effective for
expansion. To overcome such limitations, we propose Aligned Query Expansion
(AQE), a novel approach to enhance query expansion for passage retrieval in
open-domain question answering. AQE leverages recent techniques in LLM
alignment to fine-tune models for generating query expansions that directly
optimize the effectiveness of the retrieval task, eliminating the need for
additional filtering steps. This alignment ensures that queries are more
relevant, reducing computational costs while improving retrieval effectiveness.
Empirical evaluations show that AQE outperforms baseline models for query
expansion in both in-domain and out-of-domain settings, demonstrating
significant improvements in retrieval effectiveness.

---

### 2. Extracting Document Relations from Search Corpus by Marginalizing over User Queries

- **LLM Score**: 8
- **Keyword Score**: 11
- **Authors**: Yuki Iwamoto, Kaoru Tsunoda, Ken Kaneiwa
- **URL**: <http://arxiv.org/abs/2507.10726v1>
- **Submitted**: 2025-07-14 18:47:13
- **Comment**: 9 pages, 6 figures
- **Topic Keywords**: query, queries, rag, retrieval, search
- **Reason**: The paper's focus on extracting document relations from a search corpus, using query marginalization, aligns with your interest in Information Retrieval and Search technologies. The approach also involves ranking models and user behavior modeling, which are relevant to your research themes. While the paper's scope is broader than your specific focus on e-commerce, the concepts and techniques discussed are relevant to your broader interests in IR and NLP.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Document Relationship Extraction
- **Aim**: Propose a novel framework, EDR-MQ, to discover document relationships in large-scale corpora without relying on manual annotation or predefined relationship taxonomies
- **Rationale**: EDR-MQ is based on the idea that strongly related documents often co-occur in results across diverse user queries, enabling the estimation of joint probabilities between document pairs by marginalizing over a collection of queries
- **Ground**: The authors develop Multiply Conditioned Retrieval-Augmented Generation (MC-RAG) which employs conditional retrieval and uses ColBERT as the retrieval backbone
- **Experiment**: The authors demonstrate the effectiveness of EDR-MQ through experiments on scientific literature, showing that the approach can extract meaningful document relationships, reveal topical clusters, evidence chains, and cross-domain connections
- **Takeaway**: EDR-MQ offers a practical and effective way to discover document relationships in large-scale corpora, facilitating better understanding of corpus structure and enabling more effective navigation of document collections

#### Abstract
> Understanding relationships between documents in large-scale corpora is
essential for knowledge discovery and information organization. However,
existing approaches rely heavily on manual annotation or predefined
relationship taxonomies. We propose EDR-MQ (Extracting Document Relations by
Marginalizing over User Queries), a novel framework that discovers document
relationships through query marginalization. EDR-MQ is based on the insight
that strongly related documents often co-occur in results across diverse user
queries, enabling us to estimate joint probabilities between document pairs by
marginalizing over a collection of queries. To enable this query
marginalization approach, we develop Multiply Conditioned Retrieval-Augmented
Generation (MC-RAG), which employs conditional retrieval where subsequent
document retrievals depend on previously retrieved content. By observing
co-occurrence patterns across diverse queries, EDR-MQ estimates joint
probabilities between document pairs without requiring labeled training data or
predefined taxonomies. Experimental results show that our query marginalization
approach successfully identifies meaningful document relationships, revealing
topical clusters, evidence chains, and cross-domain connections that are not
apparent through traditional similarity-based methods. Our query-driven
framework offers a practical approach to document organization that adapts to
different user perspectives and information needs.

---

### 3. An Empirical Study of Multi-Agent RAG for Real-World University Admissions Counseling

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Anh Nguyen-Duc, Chien Vu Manh, Bao Anh Tran, Viet Phuong Ngo, Luan Le Chi, Anh Quang Nguyen
- **URL**: <http://arxiv.org/abs/2507.11272v1>
- **Submitted**: 2025-07-15 12:49:42
- **Topic Keywords**: queries, rag, retrieval
- **Reason**: The paper's focus on conversational AI and university admissions counseling is somewhat related to information retrieval, but it does not directly align with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's use of large language models and retrieval-augmented systems is also not directly applicable to the user's background in e-commerce and NLP.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Conversational AI for Higher Education Admissions Counseling
- **Aim**: Design and evaluate MARAUS, a conversational AI platform for higher education admissions counseling in Vietnam
- **Rationale**: Address limitations of existing solutions by combining hybrid retrieval, multi-agent orchestration, and Large Language Model (LLM)-based generation
- **Ground**: Empirical study involving technical development and real-world evaluation, processing over 6,000 actual user interactions
- **Experiment**: Two-phase study with a Q&A system running for two weeks, collecting 6,079 pairs of questions and answers, and comparing MARAUS with LLM-only baselines
- **Takeaway**: MARAUS offers a cost-effective and scalable solution for real-world adoption, achieving significant improvements over LLM-only baselines with an average accuracy of 92%, reduced hallucination rates, and average response times below 4 seconds

#### Abstract
> This paper presents MARAUS (Multi-Agent and Retrieval-Augmented University
Admission System), a real-world deployment of a conversational AI platform for
higher education admissions counseling in Vietnam. While large language models
(LLMs) offer potential for automating advisory tasks, most existing solutions
remain limited to prototypes or synthetic benchmarks. MARAUS addresses this gap
by combining hybrid retrieval, multi-agent orchestration, and LLM-based
generation into a system tailored for real-world university admissions. In
collaboration with the University of Transport Technology (UTT) in Hanoi, we
conducted a two-phase study involving technical development and real-world
evaluation. MARAUS processed over 6,000 actual user interactions, spanning six
categories of queries. Results show substantial improvements over LLM-only
baselines: on average 92 percent accuracy, hallucination rates reduced from 15
precent to 1.45 percent, and average response times below 4 seconds. The system
operated cost-effectively, with a two-week deployment cost of 11.58 USD using
GPT-4o mini. This work provides actionable insights for the deployment of
agentic RAG systems in low-resource educational settings.

---

### 4. Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Wenqing Wu, Chengzhi Zhang, Yi Zhao
- **URL**: <http://arxiv.org/abs/2507.11330v2>
- **Submitted**: 2025-07-15 14:03:55
- **Comment**: Journal of the Association for Information Science and Technology,
  2025
- **Topic Keywords**: rag, search
- **Reason**: The paper's focus on novelty evaluation in academic papers and the use of large language models is somewhat related to my interests in Information Retrieval and Natural Language Processing. However, the specific application and methodology are not directly aligned with my core research themes, such as query understanding, ranking models, and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Evaluating novelty in academic papers using large language models and human experts
- **Aim**: To develop a method that integrates human knowledge and large language models to assess novelty in academic papers
- **Rationale**: Traditional methods of assessing novelty have limitations, and large language models lack human judgment abilities
- **Ground**: Peer review process for evaluating academic papers
- **Experiment**: Comparing the proposed method to several baselines using extensive experiments
- **Takeaway**: The proposed method demonstrates superior performance in predicting method novelty of papers

#### Abstract
> Novelty is a crucial criterion in the peer review process for evaluating
academic papers. Traditionally, it's judged by experts or measure by unique
reference combinations. Both methods have limitations: experts have limited
knowledge, and the effectiveness of the combination method is uncertain.
Moreover, it's unclear if unique citations truly measure novelty. The large
language model (LLM) possesses a wealth of knowledge, while human experts
possess judgment abilities that the LLM does not possess. Therefore, our
research integrates the knowledge and abilities of LLM and human experts to
address the limitations of novelty assessment. One of the most common types of
novelty in academic papers is the introduction of new methods. In this paper,
we propose leveraging human knowledge and LLM to assist pretrained language
models (PLMs, e.g. BERT etc.) in predicting the method novelty of papers.
Specifically, we extract sentences related to the novelty of the academic paper
from peer review reports and use LLM to summarize the methodology section of
the academic paper, which are then used to fine-tune PLMs. In addition, we have
designed a text-guided fusion module with novel Sparse-Attention to better
integrate human and LLM knowledge. We compared the method we proposed with a
large number of baselines. Extensive experiments demonstrate that our method
achieves superior performance.

---

### 5. Journalism-Guided Agentic In-Context Learning for News Stance Detection

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Dahyun Lee, Jonghyeon Choi, Jiyoung Han, Kunwoo Park
- **URL**: <http://arxiv.org/abs/2507.11049v2>
- **Submitted**: 2025-07-15 07:22:04
- **Comment**: Preprint. 24 pages
- **Topic Keywords**: recommend, search, korea
- **Reason**: The paper focuses on stance detection in news articles, which is a specific application of Natural Language Processing (NLP). While it touches on the topic of personalized recommendation systems, it does not directly relate to query understanding, ranking models, or user behavior modeling in Information Retrieval (IR). The paper's emphasis on journalism and media bias is also not directly aligned with the user's research interests.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Stance Detection in News Articles
- **Aim**: Address the limitations of existing stance detection research by introducing a new dataset and framework
- **Rationale**: Existing research primarily focuses on short texts and high-resource languages, neglecting long-form news articles and low-resource languages
- **Ground**: The authors introduce the Korean dataset 'K-News-Stance' and propose the 'JoA-ICL' framework, which employs a language model agent to predict stances of key structural segments in news articles
- **Experiment**: Experimental results show that JoA-ICL outperforms existing stance detection methods, highlighting the benefits of segment-level agency in capturing the overall position of long-form news articles
- **Takeaway**: The proposed framework promotes viewpoint diversity in news recommendations and uncovers patterns of media bias

#### Abstract
> As online news consumption grows, personalized recommendation systems have
become integral to digital journalism. However, these systems risk reinforcing
filter bubbles and political polarization by failing to incorporate diverse
perspectives. Stance detection -- identifying a text's position on a target --
can help mitigate this by enabling viewpoint-aware recommendations and
data-driven analyses of media bias. Yet, existing stance detection research
remains largely limited to short texts and high-resource languages. To address
these gaps, we introduce \textsc{K-News-Stance}, the first Korean dataset for
article-level stance detection, comprising 2,000 news articles with
article-level and 19,650 segment-level stance annotations across 47 societal
issues. We also propose \textsc{JoA-ICL}, a \textbf{Jo}urnalism-guided
\textbf{A}gentic \textbf{I}n-\textbf{C}ontext \textbf{L}earning framework that
employs a language model agent to predict the stances of key structural
segments (e.g., leads, quotes), which are then aggregated to infer the overall
article stance. Experiments show that \textsc{JoA-ICL} outperforms existing
stance detection methods, highlighting the benefits of segment-level agency in
capturing the overall position of long-form news articles. Two case studies
further demonstrate its broader utility in promoting viewpoint diversity in
news recommendations and uncovering patterns of media bias.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Seungho Choi
- **URL**: <http://arxiv.org/abs/2507.10920v1>
- **Submitted**: 2025-07-15 02:26:47
- **Topic Keywords**: rag, korea
- **Reason**: The paper proposes a novel technique to address semantic ambiguity in Korean language models, which is a specific problem in NLP. While it's not directly related to information retrieval or search technologies, it's a relevant topic in NLP and could potentially be applied to IR tasks. However, the focus on Korean language and Hanja characters limits its broader applicability to the user's research interests.

#### Abstract
> Large language models (LLMs) often show poor performance in low-resource
languages like Korean, partly due to unique linguistic challenges such as
homophonous Sino-Korean words that are indistinguishable in Hangul script. To
address this semantic ambiguity, we propose HanjaBridge, a novel
meaning-injection technique integrated into a continual pre-training (CPT)
framework. Instead of deterministically mapping a word to a single Hanja
(Chinese character), HanjaBridge presents the model with all possible Hanja
candidates for a given homograph, encouraging the model to learn contextual
disambiguation. This process is paired with token-level knowledge distillation
to prevent catastrophic forgetting. Experimental results show that HanjaBridge
significantly improves Korean language understanding, achieving a 21\% relative
improvement on the KoBALT benchmark. Notably, by reinforcing semantic alignment
between Korean and Chinese through shared Hanja, we observe a strong positive
cross-lingual transfer. Furthermore, these gains persist even when Hanja
augmentation is omitted at inference time, ensuring practical efficiency with
no additional run-time cost.

### 7. Seq vs Seq: An Open Suite of Paired Encoders and Decoders

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Orion Weller, Kathryn Ricci, Marc Marone, Antoine Chaffin, Dawn Lawrie, Benjamin Van Durme
- **URL**: <http://arxiv.org/abs/2507.11412v1>
- **Submitted**: 2025-07-15 15:31:51
- **Topic Keywords**: retrieval
- **Reason**: The paper focuses on comparing encoder-only and decoder-only language models, which is related to query understanding and ranking models in Information Retrieval. However, the paper's primary focus is on language models and their applications, rather than specifically on search technologies or user behavior modeling, which are key areas of interest for your research.

#### Abstract
> The large language model (LLM) community focuses almost exclusively on
decoder-only language models, since they are easier to use for text generation.
However, a large subset of the community still uses encoder-only models for
tasks such as classification or retrieval. Previous work has attempted to
compare these architectures, but is forced to make comparisons with models that
have different numbers of parameters, training techniques, and datasets. We
introduce the SOTA open-data Ettin suite of models: paired encoder-only and
decoder-only models ranging from 17 million parameters to 1 billion, trained on
up to 2 trillion tokens. Using the same recipe for both encoder-only and
decoder-only models produces SOTA recipes in both categories for their
respective sizes, beating ModernBERT as an encoder and Llama 3.2 and SmolLM2 as
decoders. Like previous work, we find that encoder-only models excel at
classification and retrieval tasks while decoders excel at generative tasks.
However, we show that adapting a decoder model to encoder tasks (and vice
versa) through continued training is subpar compared to using only the reverse
objective (i.e. a 400M encoder outperforms a 1B decoder on MNLI, and vice versa
for generative tasks). We open-source all artifacts of this study including
training data, training order segmented by checkpoint, and 200+ checkpoints to
allow future work to analyze or extend all aspects of training.

### 8. LRCTI: A Large Language Model-Based Framework for Multi-Step Evidence Retrieval and Reasoning in Cyber Threat Intelligence Credibility Verification

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Fengxiao Tang, Huan Li, Ming Zhao, Zongzong Wu, Shisong Peng, Tao Yin
- **URL**: <http://arxiv.org/abs/2507.11310v1>
- **Submitted**: 2025-07-15 13:42:32
- **Topic Keywords**: retrieval
- **Reason**: The paper proposes a framework for credibility verification in Cyber Threat Intelligence, leveraging large language models and natural language inference. While it touches on some relevant topics like text summarization and evidence retrieval, the focus is on a specific domain (cybersecurity) and does not directly align with the user's primary interests in Information Retrieval, Search technologies, and query understanding.

#### Abstract
> Verifying the credibility of Cyber Threat Intelligence (CTI) is essential for
reliable cybersecurity defense. However, traditional approaches typically treat
this task as a static classification problem, relying on handcrafted features
or isolated deep learning models. These methods often lack the robustness
needed to handle incomplete, heterogeneous, or noisy intelligence, and they
provide limited transparency in decision-making-factors that reduce their
effectiveness in real-world threat environments. To address these limitations,
we propose LRCTI, a Large Language Model (LLM)-based framework designed for
multi-step CTI credibility verification. The framework first employs a text
summarization module to distill complex intelligence reports into concise and
actionable threat claims. It then uses an adaptive multi-step evidence
retrieval mechanism that iteratively identifies and refines supporting
information from a CTI-specific corpus, guided by LLM feedback. Finally, a
prompt-based Natural Language Inference (NLI) module is applied to evaluate the
credibility of each claim while generating interpretable justifications for the
classification outcome. Experiments conducted on two benchmark datasets,
CTI-200 and PolitiFact show that LRCTI improves F1-Macro and F1-Micro scores by
over 5%, reaching 90.9% and 93.6%, respectively, compared to state-of-the-art
baselines. These results demonstrate that LRCTI effectively addresses the core
limitations of prior methods, offering a scalable, accurate, and explainable
solution for automated CTI credibility verification

### 9. Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Andres Azqueta-Gavald√≥n, Joaquin Ramos Cosgrove
- **URL**: <http://arxiv.org/abs/2507.11086v1>
- **Submitted**: 2025-07-15 08:28:24
- **Topic Keywords**: rag
- **Reason**: The paper explores the application of Large Language Models (LLMs) for cross-border entity identification, which is not directly related to the user's primary focus on Information Retrieval, Search technologies, and query understanding. While the paper touches on the limitations of traditional algorithms, it does not address the user's specific interests in ranking models, user behavior modeling, or deep semantic understanding.

#### Abstract
> The growing prevalence of cross-border financial activities in global markets
has underscored the necessity of accurately identifying and classifying foreign
entities. This practice is essential within the Spanish financial system for
ensuring robust risk management, regulatory adherence, and the prevention of
financial misconduct. This process involves a labor-intensive entity-matching
task, where entities need to be validated against available reference sources.
Challenges arise from linguistic variations, special characters, outdated
names, and changes in legal forms, complicating traditional matching algorithms
like Jaccard, cosine, and Levenshtein distances. These methods struggle with
contextual nuances and semantic relationships, leading to mismatches. To
address these limitations, we explore Large Language Models (LLMs) as a
flexible alternative. LLMs leverage extensive training to interpret context,
handle abbreviations, and adapt to legal transitions. We evaluate traditional
methods, Hugging Face-based LLMs, and interface-based LLMs (e.g., Microsoft
Copilot, Alibaba's Qwen 2.5) using a dataset of 65 Portuguese company cases.
Results show traditional methods achieve accuracies over 92% but suffer high
false positive rates (20-40%). Interface-based LLMs outperform, achieving
accuracies above 93%, F1 scores exceeding 96%, and lower false positives
(40-80%).

### 10. Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Michal Podstawski
- **URL**: <http://arxiv.org/abs/2507.10772v1>
- **Submitted**: 2025-07-14 19:53:56
- **Topic Keywords**: rag
- **Reason**: The paper explores the application of text embedding models in property graphs, which is related to information retrieval and NLP. However, the focus is on graph analysis and node classification, which is not directly aligned with the user's primary interest in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Labeled property graphs often contain rich textual attributes that can
enhance analytical tasks when properly leveraged. This work explores the use of
pretrained text embedding models to enable efficient semantic analysis in such
graphs. By embedding textual node and edge properties, we support downstream
tasks including node classification and relation prediction with improved
contextual understanding. Our approach integrates language model embeddings
into the graph pipeline without altering its structure, demonstrating that
textual semantics can significantly enhance the accuracy and interpretability
of property graph analysis.

### 11. LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Ziyan Wang, Yingpeng Du, Zhu Sun, Jieyi Bi, Haoyan Chua, Tianjun Wei, Jie Zhang
- **URL**: <http://arxiv.org/abs/2507.10917v1>
- **Submitted**: 2025-07-15 02:13:54
- **Comment**: 10 pages, 5 figures
- **Topic Keywords**: recommend
- **Reason**: The paper proposes a framework for multi-interest modeling using large language models, which is related to query understanding and user behavior modeling in the context of information retrieval. However, the focus on recommendation systems and the use of LLMs for item clustering and representation learning are not directly aligned with the user's primary research interests in search technologies and ranking models.

#### Abstract
> Recently, much effort has been devoted to modeling users' multi-interests
based on their behaviors or auxiliary signals. However, existing methods often
rely on heuristic assumptions, e.g., co-occurring items indicate the same
interest of users, failing to capture user multi-interests aligning with
real-world scenarios. While large language models (LLMs) show significant
potential for multi-interest analysis due to their extensive knowledge and
powerful reasoning capabilities, two key challenges remain. First, the
granularity of LLM-driven multi-interests is agnostic, possibly leading to
overly fine or coarse interest grouping. Second, individual user analysis
provides limited insights due to the data sparsity issue. In this paper, we
propose an LLM-driven dual-level multi-interest modeling framework for more
effective recommendation. At the user-individual level, we exploit LLMs to
flexibly allocate items engaged by users into different semantic clusters,
indicating their diverse and distinct interests. To alleviate the agnostic
generation of LLMs, we adaptively assign these semantic clusters to users'
collaborative multi-interests learned from global user-item interactions,
allowing the granularity to be automatically adjusted according to the user's
behaviors using an alignment module. To alleviate the limited insights derived
from individual users' behaviors, at the user-crowd level, we propose
aggregating user cliques into synthesized users with rich behaviors for more
comprehensive LLM-driven multi-interest analysis. We formulate a max covering
problem to ensure the compactness and representativeness of synthesized users'
behaviors, and then conduct contrastive learning based on their LLM-driven
multi-interests to disentangle item representations among different interests.
Experiments on real-world datasets show the superiority of our approach against
state-of-the-art methods.

### 12. NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Zongtao He, Liuyi Wang, Lu Chen, Chengju Liu, Qijun Chen
- **URL**: <http://arxiv.org/abs/2507.10894v1>
- **Submitted**: 2025-07-15 01:20:22
- **Topic Keywords**: search
- **Reason**: The paper proposes a framework for generating navigation instructions, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing, the focus is on language-guided navigation rather than search or retrieval. The paper's relevance to the user's interests is limited, but it may be of interest to those working on embodied AI or natural language processing.

#### Abstract
> Language-guided navigation is a cornerstone of embodied AI, enabling agents
to interpret language instructions and navigate complex environments. However,
expert-provided instructions are limited in quantity, while synthesized
annotations often lack quality, making them insufficient for large-scale
research. To address this, we propose NavComposer, a novel framework for
automatically generating high-quality navigation instructions. NavComposer
explicitly decomposes semantic entities such as actions, scenes, and objects,
and recomposes them into natural language instructions. Its modular
architecture allows flexible integration of state-of-the-art techniques, while
the explicit use of semantic entities enhances both the richness and accuracy
of instructions. Moreover, it operates in a data-agnostic manner, supporting
adaptation to diverse navigation trajectories without domain-specific training.
Complementing NavComposer, we introduce NavInstrCritic, a comprehensive
annotation-free evaluation system that assesses navigation instructions on
three dimensions: contrastive matching, semantic consistency, and linguistic
diversity. NavInstrCritic provides a holistic evaluation of instruction
quality, addressing limitations of traditional metrics that rely heavily on
expert annotations. By decoupling instruction generation and evaluation from
specific navigation agents, our method enables more scalable and generalizable
research. Extensive experiments provide direct and practical evidence for the
effectiveness of our method.

### 13. Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: JaMor Hairston, Ritvik Ranjan, Sahithi Lakamana, Anthony Spadaro, Selen Bozkurt, Jeanmarie Perrone, Abeed Sarker
- **URL**: <http://arxiv.org/abs/2507.10803v1>
- **Submitted**: 2025-07-14 20:57:52
- **Comment**: Pages: 19, Abstract word count: 151 words, Manuscript word count:
  2185 words, References: 14, Figures: 3, Tables: 2
- **Topic Keywords**: search
- **Reason**: The paper explores the application of large language models (LLMs) in thematic analysis, which is related to natural language processing (NLP) and information retrieval (IR). However, the focus on social media data and public health is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling, making it only loosely relevant.

#### Abstract
> Background Large language models (LLMs) face challenges in inductive thematic
analysis, a task requiring deep interpretive and domain-specific expertise. We
evaluated the feasibility of using LLMs to replicate expert-driven thematic
analysis of social media data. Methods Using two temporally non-intersecting
Reddit datasets on xylazine (n=286 and n=686, for model optimization and
validation, respectively) with twelve expert-derived themes, we evaluated five
LLMs against expert coding. We modeled the task as a series of binary
classifications, rather than a single, multi-label classification, employing
zero-, single-, and few-shot prompting strategies and measuring performance via
accuracy, precision, recall, and F1-score. Results On the validation set,
GPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:
0.71). For high-prevalence themes, model-derived thematic distributions closely
mirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:
16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based
approaches can automate thematic analyses, offering a scalable supplement for
qualitative research. Keywords: thematic analysis, large language models,
natural language processing, qualitative analysis, social media, prompt
engineering, public health

### 14. Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Yilun Zhao, Chengye Wang, Chuhan Li, Arman Cohan
- **URL**: <http://arxiv.org/abs/2507.10787v1>
- **Submitted**: 2025-07-14 20:35:25
- **Comment**: ACL 2025 Findings
- **Topic Keywords**: search
- **Reason**: The paper explores multimodal foundation models' ability to understand schematic diagrams in scientific papers, which is related to information retrieval and query understanding. However, the focus on multimodal foundation models and scientific papers is not directly aligned with the user's interests in e-commerce and real-time relevance optimization.

#### Abstract
> This paper introduces MISS-QA, the first benchmark specifically designed to
evaluate the ability of models to interpret schematic diagrams within
scientific literature. MISS-QA comprises 1,500 expert-annotated examples over
465 scientific papers. In this benchmark, models are tasked with interpreting
schematic diagrams that illustrate research overviews and answering
corresponding information-seeking questions based on the broader context of the
paper. We assess the performance of 18 frontier multimodal foundation models,
including o4-mini, Gemini-2.5-Flash, and Qwen2.5-VL. We reveal a significant
performance gap between these models and human experts on MISS-QA. Our analysis
of model performance on unanswerable questions and our detailed error analysis
further highlight the strengths and limitations of current models, offering key
insights to enhance models in comprehending multimodal scientific literature.

### 15. LiLM-RDB-SFC: Lightweight Language Model with Relational Database-Guided DRL for Optimized SFC Provisioning

- **LLM Score**: 2
- **Keyword Score**: 8
- **Authors**: Parisa Fard Moshiri, Xinyu Zhu, Poonam Lohan, Burak Kantarci, Emil Janulewicz
- **URL**: <http://arxiv.org/abs/2507.10903v1>
- **Submitted**: 2025-07-15 01:42:44
- **Comment**: 9 pages, 6 figures, Accepted to IEEE 16th International Conference on
  Network of the Future (NoF) 2025
- **Topic Keywords**: query, queries, rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on Service Function Chains, Virtual Network Functions, and Deep Reinforcement Learning in the context of Software-Defined Networking and Network Function Virtualization, which is outside your primary research areas.

#### Abstract
> Effective management of Service Function Chains (SFCs) and optimal Virtual
Network Function (VNF) placement are critical challenges in modern
Software-Defined Networking (SDN) and Network Function Virtualization (NFV)
environments. Although Deep Reinforcement Learning (DRL) is widely adopted for
dynamic network decision-making, its inherent dependency on structured data and
fixed action rules often limits adaptability and responsiveness, particularly
under unpredictable network conditions. This paper introduces LiLM-RDB-SFC, a
novel approach combining Lightweight Language Model (LiLM) with Relational
Database (RDB) to answer network state queries to guide DRL model for efficient
SFC provisioning. Our proposed approach leverages two LiLMs, Bidirectional and
Auto-Regressive Transformers (BART) and the Fine-tuned Language Net T5
(FLAN-T5), to interpret network data and support diverse query types related to
SFC demands, data center resources, and VNF availability. Results demonstrate
that FLAN-T5 outperforms BART with a lower test loss (0.00161 compared to
0.00734), higher accuracy (94.79% compared to 80.2%), and less processing time
(2h 2min compared to 2h 38min). Moreover, when compared to the large language
model SQLCoder, FLAN-T5 matches the accuracy of SQLCoder while cutting
processing time by 96% (SQLCoder: 54 h 43 min; FLAN-T5: 2 h 2 min).

### 16. Language Models for Adult Service Website Text Analysis

- **LLM Score**: 2
- **Keyword Score**: 8
- **Authors**: Nickolas Freeman, Thanh Nguyen, Gregory Bott, Jason Parton, Collin Francel
- **URL**: <http://arxiv.org/abs/2507.10743v1>
- **Submitted**: 2025-07-14 19:08:07
- **Comment**: 32 pages, 12 figures, 1 table
- **Topic Keywords**: information retrieval, rag, retrieval, search
- **Reason**: This paper is not relevant to your research interests as it focuses on language models for adult service website text analysis, which is a specific domain and application area. The topics of query understanding, ranking models, and user behavior modeling are not addressed, and the paper's focus on text analysis and language models is not aligned with your interests in information retrieval and search technologies.

#### Abstract
> Sex trafficking refers to the use of force, fraud, or coercion to compel an
individual to perform in commercial sex acts against their will. Adult service
websites (ASWs) have and continue to be linked to sex trafficking, offering a
platform for traffickers to advertise their victims. Thus, organizations
involved in the fight against sex trafficking often use ASW data when
attempting to identify potential sex trafficking victims. A critical challenge
in transforming ASW data into actionable insight is text analysis. Previous
research using ASW data has shown that ASW ad text is important for linking
ads. However, working with this text is challenging due to its extensive use of
emojis, poor grammar, and deliberate obfuscation to evade law enforcement
scrutiny. We conduct a comprehensive study of language modeling approaches for
this application area, including simple information retrieval methods,
pre-trained transformers, and custom transformer models. We demonstrate that
characteristics of ASW text data allow efficient custom transformer models to
be trained with relatively small GPU resources and used efficiently for
inference on consumer hardware. Our custom models outperform fine-tuned
variants of well-known encoder-only transformer models, including BERT-base,
RoBERTa, and ModernBERT, on accuracy, recall, F1 score, and ROC AUC. We
demonstrate the use of our best-performing custom configuration on three tasks
related to ASW data analysis: (i) decomposing the giant component in a graph
representation of ASW data, (ii) clustering ASW ad text, and (iii) using the
learned token embeddings to understand the use of emojis in the illicit context
we study. The models we develop represent a significant advancement in ASW text
analysis, which can be leveraged in a variety of downstream applications and
research.

### 17. From Chaos to Automation: Enabling the Use of Unstructured Data for Robotic Process Automation

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Kelly Kurowski, Xixi Lu, Hajo A. Reijers
- **URL**: <http://arxiv.org/abs/2507.11364v1>
- **Submitted**: 2025-07-15 14:32:49
- **Comment**: Accepted at AUTOMATE 2025
- **Topic Keywords**: information retrieval, retrieval, search
- **Reason**: This paper focuses on Robotic Process Automation (RPA) and unstructured data, which is not directly related to Information Retrieval (IR) or Search technologies, the user's primary research interests. While it mentions natural language processing (NLP) techniques, the context is different from the user's background in e-commerce and NLP for IR applications.

#### Abstract
> The growing volume of unstructured data within organizations poses
significant challenges for data analysis and process automation. Unstructured
data, which lacks a predefined format, encompasses various forms such as
emails, reports, and scans. It is estimated to constitute approximately 80% of
enterprise data. Despite the valuable insights it can offer, extracting
meaningful information from unstructured data is more complex compared to
structured data. Robotic Process Automation (RPA) has gained popularity for
automating repetitive tasks, improving efficiency, and reducing errors.
However, RPA is traditionally reliant on structured data, limiting its
application to processes involving unstructured documents. This study addresses
this limitation by developing the UNstructured Document REtrieval SyStem
(UNDRESS), a system that uses fuzzy regular expressions, techniques for natural
language processing, and large language models to enable RPA platforms to
effectively retrieve information from unstructured documents. The research
involved the design and development of a prototype system, and its subsequent
evaluation based on text extraction and information retrieval performance. The
results demonstrate the effectiveness of UNDRESS in enhancing RPA capabilities
for unstructured data, providing a significant advancement in the field. The
findings suggest that this system could facilitate broader RPA adoption across
processes traditionally hindered by unstructured data, thereby improving
overall business process efficiency.

### 18. LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Haowei Yang, Ziyu Shen, Junli Shao, Luyao Men, Xinyue Han, Jing Dong
- **URL**: <http://arxiv.org/abs/2507.11052v1>
- **Submitted**: 2025-07-15 07:32:16
- **Topic Keywords**: relevance, rag
- **Reason**: This paper is not relevant to your research interests as it focuses on clinical NLP and cardiovascular disease risk prediction, which is outside your primary area of interest in Information Retrieval, Search technologies, and Natural Language Processing. The paper's application in clinical decision support systems is also not directly related to your research themes.

#### Abstract
> Timely identification and accurate risk stratification of cardiovascular
disease (CVD) remain essential for reducing global mortality. While existing
prediction models primarily leverage structured data, unstructured clinical
notes contain valuable early indicators. This study introduces a novel
LLM-augmented clinical NLP pipeline that employs domain-adapted large language
models for symptom extraction, contextual reasoning, and correlation from
free-text reports. Our approach integrates cardiovascular-specific fine-tuning,
prompt-based inference, and entity-aware reasoning. Evaluations on MIMIC-III
and CARDIO-NLP datasets demonstrate improved performance in precision, recall,
F1-score, and AUROC, with high clinical relevance (kappa = 0.82) assessed by
cardiologists. Challenges such as contextual hallucination, which occurs when
plausible information contracts with provided source, and temporal ambiguity,
which is related with models struggling with chronological ordering of events
are addressed using prompt engineering and hybrid rule-based verification. This
work underscores the potential of LLMs in clinical decision support systems
(CDSS), advancing early warning systems and enhancing the translation of
patient narratives into actionable risk assessments.

### 19. Access Control for Information-Theoretically Secure Key-Document Stores

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Yin Li, Sharad Mehrota, Shantanu Sharma, Komal Kumari
- **URL**: <http://arxiv.org/abs/2507.10730v1>
- **Submitted**: 2025-07-14 18:51:20
- **Comment**: An extended abstract of this version has been accepted in VLDB 2025
- **Topic Keywords**: query, retrieval
- **Reason**: This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on access control and secret-sharing techniques for secure key-value stores, which is outside the user's primary focus areas.

#### Abstract
> This paper presents a novel key-based access control technique for secure
outsourcing key-value stores where values correspond to documents that are
indexed and accessed using keys. The proposed approach adopts Shamir's
secret-sharing that offers unconditional or information-theoretic security. It
supports keyword-based document retrieval while preventing leakage of the data,
access rights of users, or the size (\textit{i}.\textit{e}., volume of the
output that satisfies a query). The proposed approach allows servers to detect
(and abort) malicious clients from gaining unauthorized access to data, and
prevents malicious servers from altering data undetected while ensuring
efficient access -- it takes 231.5ms over 5,000 keywords across 500,000 files.

### 20. KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Luohe Shi, Zuchao Li, Lefei Zhang, Guoming Liu, Baoyuan Qi, Hai Zhao
- **URL**: <http://arxiv.org/abs/2507.11273v1>
- **Submitted**: 2025-07-15 12:52:12
- **Comment**: To be published in The 63rd Annual Meeting of the Association for
  Computational Linguistics (ACL 2025)
- **Topic Keywords**: query
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on language models, KV cache reduction, and positional embedding, which are not directly related to your areas of interest.

#### Abstract
> Large language models (LLMs) based on Transformer Decoders have become the
preferred choice for conversational generative AI. Despite the overall
superiority of the Decoder architecture, the gradually increasing Key-Value
(KV) cache during inference has emerged as a primary efficiency bottleneck,
both in aspects of memory consumption and data transfer bandwidth limitations.
To address these challenges, we propose a paradigm called KV-Latent. By
down-sampling the Key-Value vector dimensions into a latent space, we can
significantly reduce the KV Cache footprint and improve inference speed, only
with a small amount of extra training, less than 1\% of pre-training takes.
Besides, we enhanced the stability of Rotary Positional Embedding applied on
lower-dimensional vectors by modifying its frequency sampling mechanism,
avoiding noise introduced by higher frequencies while retaining position
attenuation. Our experiments, including both models with Grouped Query
Attention and those without, have yielded satisfactory results. Finally, we
conducted comparative experiments to study the impact of separately reducing
Key and Value components on model's performance. Our approach allows for the
construction of more efficient language model systems, and opens the new
possibility on KV Cache saving and efficient LLMs. Our code is available at
https://github.com/ShiLuohe/KV-Latent.

### 21. Mario at EXIST 2025: A Simple Gateway to Effective Multilingual Sexism Detection

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Lin Tian, Johanne R. Trippas, Marian-Andrei Rizoiu
- **URL**: <http://arxiv.org/abs/2507.10996v1>
- **Submitted**: 2025-07-15 05:30:32
- **Comment**: 12 pages, 5 tables, CLEF 2025
- **Topic Keywords**: rag, rank
- **Reason**: The paper focuses on multilingual sexism detection in tweets, which is not related to the user's interests in Information Retrieval, Search technologies, and Natural Language Processing. The techniques and applications described in the paper are not relevant to the user's areas of focus, such as query understanding, ranking models, and user behavior modeling.

#### Abstract
> This paper presents our approach to EXIST 2025 Task 1, addressing text-based
sexism detection in English and Spanish tweets through hierarchical Low-Rank
Adaptation (LoRA) of Llama 3.1 8B. Our method introduces conditional adapter
routing that explicitly models label dependencies across three hierarchically
structured subtasks: binary sexism identification, source intention detection,
and multilabel sexism categorization. Unlike conventional LoRA applications
that target only attention layers, we apply adaptation to all linear
transformations, enhancing the model's capacity to capture task-specific
patterns. In contrast to complex data processing and ensemble approaches, we
show that straightforward parameter-efficient fine-tuning achieves strong
performance. We train separate LoRA adapters (rank=16, QLoRA 4-bit) for each
subtask using unified multilingual training that leverages Llama 3.1's native
bilingual capabilities. The method requires minimal preprocessing and uses
standard supervised learning. Our multilingual training strategy eliminates the
need for separate language-specific models, achieving 1.7-2.4\% F1 improvements
through cross-lingual transfer. With only 1.67\% trainable parameters compared
to full fine-tuning, our approach reduces training time by 75\% and model
storage by 98\%, while achieving competitive performance across all subtasks
(ICM-Hard: 0.6774 for binary classification, 0.4991 for intention detection,
0.6519 for multilabel categorization).

### 22. EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: LG AI Research, :, Kyunghoon Bae, Eunbi Choi, Kibong Choi, Stanley Jungkyu Choi, Yemuk Choi, Kyubeen Han, Seokhee Hong, Junwon Hwang, Taewan Hwang, Joonwon Jang, Hyojin Jeon, Kijeong Jeon, Gerrard Jeongwon Jo, Hyunjik Jo, Jiyeon Jung, Euisoon Kim, Hyosang Kim, Jihoon Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Yongil Kim, Youchul Kim, Edward Hwayoung Lee, Gwangho Lee, Haeju Lee, Honglak Lee, Jinsik Lee, Kyungmin Lee, Sangha Park, Young Min Paik, Yongmin Park, Youngyong Park, Sanghyun Seo, Sihoon Yang, Heuiyeen Yeen, Sihyuk Yi, Hyeongu Yun
- **URL**: <http://arxiv.org/abs/2507.11407v1>
- **Submitted**: 2025-07-15 15:24:51
- **Comment**: Technical Report, 30 Pages
- **Topic Keywords**: search, korea
- **Reason**: The paper focuses on large language models, integrating non-reasoning and reasoning modes, which is not directly related to information retrieval, search technologies, or user behavior modeling. The topic is more aligned with natural language processing and deep learning, but lacks specific relevance to query understanding, ranking models, or real-time relevance optimization.

#### Abstract
> This technical report introduces EXAONE 4.0, which integrates a Non-reasoning
mode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5
and the advanced reasoning abilities of EXAONE Deep. To pave the way for the
agentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool
use, and its multilingual capabilities are extended to support Spanish in
addition to English and Korean. The EXAONE 4.0 model series consists of two
sizes: a mid-size 32B model optimized for high performance, and a small-size
1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates
superior performance compared to open-weight models in its class and remains
competitive even against frontier-class models. The models are publicly
available for research purposes and can be easily downloaded via
https://huggingface.co/LGAI-EXAONE.

### 23. DCR: Quantifying Data Contamination in LLMs Evaluation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Cheng Xu, Nan Yan, Shuhao Guan, Changhong Jin, Yuke Mei, Yibing Guo, M-Tahar Kechadi
- **URL**: <http://arxiv.org/abs/2507.11405v1>
- **Submitted**: 2025-07-15 15:23:53
- **Topic Keywords**: rag
- **Reason**: This paper focuses on large language models (LLMs) and benchmark data contamination, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on evaluation metrics, the topic is more relevant to NLP and model assessment, rather than IR or search technologies.

#### Abstract
> The rapid advancement of large language models (LLMs) has heightened concerns
about benchmark data contamination (BDC), where models inadvertently memorize
evaluation data, inflating performance metrics and undermining genuine
generalization assessment. This paper introduces the Data Contamination Risk
(DCR) framework, a lightweight, interpretable pipeline designed to detect and
quantify BDC across four granular levels: semantic, informational, data, and
label. By synthesizing contamination scores via a fuzzy inference system, DCR
produces a unified DCR Factor that adjusts raw accuracy to reflect
contamination-aware performance. Validated on 9 LLMs (0.5B-72B) across
sentiment analysis, fake news detection, and arithmetic reasoning tasks, the
DCR framework reliably diagnoses contamination severity and with accuracy
adjusted using the DCR Factor to within 4% average error across the three
benchmarks compared to the uncontaminated baseline. Emphasizing computational
efficiency and transparency, DCR provides a practical tool for integrating
contamination assessment into routine evaluations, fostering fairer comparisons
and enhancing the credibility of LLM benchmarking practices.

### 24. FMC: Formalization of Natural Language Mathematical Competition Problems

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jiaxuan Xie, Chengwu Liu, Ye Yuan, Siqi Li, Zhiping Xiao, Ming Zhang
- **URL**: <http://arxiv.org/abs/2507.11275v1>
- **Submitted**: 2025-07-15 12:52:47
- **Comment**: Accepted in ICML 2025 AI4MATH Workshop
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it involves natural language processing, the focus is on formalizing mathematical problems, which is not a primary interest of yours.

#### Abstract
> Efficient and accurate autoformalization methods, which leverage large-scale
datasets of extensive natural language mathematical problems to construct
formal language datasets, are key to advancing formal mathematical reasoning.
In this paper, we propose an autoformalization pipeline based on large language
models with error feedback, achieving a fully automatic and training-free
formalization approach. Using this pipeline, we curate an Olympiad-level
dataset aligning natural language problems with Lean formalizations. The
dataset comprises $3,922$ mathematical problems in natural language and $9,787$
in Lean, of which $64.46\%$ were assessed as at least above-average quality,
making it suitable as a benchmark for automated theorem provers. Additionally,
we investigate the formalization and reasoning capabilities of various LLMs and
empirically demonstrate that few-shot learning, error feedback, and increasing
sampling numbers enhance the autoformalization process. Experiments of three
automated theorem provers on the \dataset\ dataset also highlight its
challenging nature and its value as a benchmark for formal reasoning tasks.

### 25. An Agentic Flow for Finite State Machine Extraction using Prompt Chaining

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Fares Wael, Youssef Maklad, Ali Hamdi, Wael Elsersy
- **URL**: <http://arxiv.org/abs/2507.11222v1>
- **Submitted**: 2025-07-15 11:50:25
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on Finite-State Machines, protocol analysis, and cybersecurity, which are outside your primary research areas.

#### Abstract
> Finite-State Machines (FSMs) are critical for modeling the operational logic
of network protocols, enabling verification, analysis, and vulnerability
discovery. However, existing FSM extraction techniques face limitations such as
scalability, incomplete coverage, and ambiguity in natural language
specifications. In this paper, we propose FlowFSM, a novel agentic framework
that leverages Large Language Models (LLMs) combined with prompt chaining and
chain-of-thought reasoning to extract accurate FSMs from raw RFC documents.
FlowFSM systematically processes protocol specifications, identifies state
transitions, and constructs structured rule-books by chaining agent outputs.
Experimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM
achieves high extraction precision while minimizing hallucinated transitions,
showing promising results. Our findings highlight the potential of agent-based
LLM systems in the advancement of protocol analysis and FSM inference for
cybersecurity and reverse engineering applications.

### 26. First-Order Error Matters: Accurate Compensation for Quantized Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xingyu Zheng, Haotong Qin, Yuye Li, Jiakai Wang, Jinyang Guo, Michele Magno, Xianglong Liu
- **URL**: <http://arxiv.org/abs/2507.11017v1>
- **Submitted**: 2025-07-15 06:18:46
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on post-training quantization of large language models, which is a topic in Natural Language Processing, but not directly related to your core interests.

#### Abstract
> Post-training quantization (PTQ) offers an efficient approach to compressing
large language models (LLMs), significantly reducing memory access and
computational costs. Existing compensation-based weight calibration methods
often rely on a second-order Taylor expansion to model quantization error,
under the assumption that the first-order term is negligible in well-trained
full-precision models. However, we reveal that the progressive compensation
process introduces accumulated first-order deviations between latent weights
and their full-precision counterparts, making this assumption fundamentally
flawed. To address this, we propose FOEM, a novel PTQ method that explicitly
incorporates first-order gradient terms to improve quantization error
compensation. FOEM approximates gradients by directly computing the difference
between latent and full-precision weights, avoiding the high cost and limited
generalization of backpropagation-based gradient computation. This approach
introduces minimal additional computational overhead. Moreover, FOEM leverages
precomputed Cholesky factors to efficiently recover the inverse of Hessian
submatrices in real time. Extensive experiments across a wide range of models
and benchmarks demonstrate that FOEM consistently outperforms the classical
GPTQ method. In 3-bit weight-only quantization, FOEM reduces the perplexity of
Llama3-8B by 89.6%, and improves the 5-shot MMLU accuracy of Llama3-70B from
51.7% to 74.9%, approaching the full-precision performance of 78.6%.
Furthermore, FOEM can be seamlessly integrated with advanced techniques such as
GPTAQ and SpinQuant, yielding additional improvements under the challenging
W4A4KV4 setting, and further narrowing the accuracy gap with full-precision
baselines beyond what current state-of-the-art methods achieve. The code is
available at https://github.com/Xingyu-Zheng/FOEM.

### 27. Teach Me Sign: Stepwise Prompting LLM for Sign Language Production

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zhaoyi An, Rei Kawakami
- **URL**: <http://arxiv.org/abs/2507.10972v1>
- **Submitted**: 2025-07-15 04:31:52
- **Comment**: Accepted by IEEE ICIP 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on sign language generation using large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it employs a stepwise prompting strategy, the paper's primary concern is sign language production, which is outside the user's core research themes.

#### Abstract
> Large language models, with their strong reasoning ability and rich
knowledge, have brought revolution to many tasks of AI, but their impact on
sign language generation remains limited due to its complexity and unique
rules. In this paper, we propose TEAch Me Sign (TEAM-Sign), treating sign
language as another natural language. By fine-tuning an LLM, we enable it to
learn the correspondence between text and sign language, and facilitate
generation. Considering the differences between sign and spoken language, we
employ a stepwise prompting strategy to extract the inherent sign language
knowledge within the LLM, thereby supporting the learning and generation
process. Experimental results on How2Sign and Phoenix14T datasets demonstrate
that our approach effectively leverages both the sign language knowledge and
reasoning capabilities of LLM to align the different distribution and
grammatical rules between sign and spoken language.

### 28. Supporting SENƒÜOTEN Language Documentation Efforts with Automatic Speech Recognition

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Mengzhe Geng, Patrick Littell, Aidan Pine, PEN√ÅƒÜ, Marc Tessier, Roland Kuhn
- **URL**: <http://arxiv.org/abs/2507.10827v1>
- **Submitted**: 2025-07-14 21:44:35
- **Comment**: Accepted by ComputEL-8
- **Topic Keywords**: rag
- **Reason**: The paper focuses on developing an Automatic Speech Recognition system for the SENƒÜOTEN language, which is not related to Information Retrieval, Search technologies, or Natural Language Processing. The paper's primary concern is language documentation and revitalization, which is outside the scope of the user's research interests.

#### Abstract
> The SEN\'{C}OTEN language, spoken on the Saanich peninsula of southern
Vancouver Island, is in the midst of vigorous language revitalization efforts
to turn the tide of language loss as a result of colonial language policies. To
support these on-the-ground efforts, the community is turning to digital
technology. Automatic Speech Recognition (ASR) technology holds great promise
for accelerating language documentation and the creation of educational
resources. However, developing ASR systems for SEN\'{C}OTEN is challenging due
to limited data and significant vocabulary variation from its polysynthetic
structure and stress-driven metathesis. To address these challenges, we propose
an ASR-driven documentation pipeline that leverages augmented speech data from
a text-to-speech (TTS) system and cross-lingual transfer learning with Speech
Foundation Models (SFMs). An n-gram language model is also incorporated via
shallow fusion or n-best restoring to maximize the use of available data.
Experiments on the SEN\'{C}OTEN dataset show a word error rate (WER) of 19.34%
and a character error rate (CER) of 5.09% on the test set with a 57.02%
out-of-vocabulary (OOV) rate. After filtering minor cedilla-related errors, WER
improves to 14.32% (26.48% on unseen words) and CER to 3.45%, demonstrating the
potential of our ASR-driven pipeline to support SEN\'{C}OTEN language
documentation.

### 29. Testing Hypotheses from the Social Approval Theory of Online Hate: An Analysis of 110 Million Posts from Parler

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: David M. Markowitz, Samuel Hardman Taylor
- **URL**: <http://arxiv.org/abs/2507.10810v1>
- **Submitted**: 2025-07-14 21:10:39
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper's focus on social approval theory of online hate and its analysis of hate speech posts on Parler is outside the user's primary research areas.

#### Abstract
> In this paper, we explored how online hate is motivated by receiving social
approval from others. We specifically examined two central tenets of Walther's
(2024) social approval theory of online hate: (H1a) more signals of social
approval on hate messages predicts more subsequent hate messages, and (H1b) as
social approval increases, hate speech messages become more extreme. Using over
110 million posts from Parler (2018-2021), we observed that the number of
upvotes a person received on a hate speech post was unassociated with the
amount of hate speech in their next post and posts during the next week, month,
three months, and six months. Between-person effects revealed an average
negative relationship between social approval and hate speech production at the
post level, but this relationship was mixed at other time intervals. Social
approval reinforcement mechanisms of online hate may operate differently on
niche social media platforms.

### 30. Theory of Mind and Self-Disclosure to CUIs

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Samuel Rhys Cox
- **URL**: <http://arxiv.org/abs/2507.10773v1>
- **Submitted**: 2025-07-14 19:57:18
- **Comment**: Workshop paper presented at ToMinHAI at CUI'2025: Theory of Mind in
  Human-CUI Interaction, held in conjunction with the 2025 ACM conference on
  Conversational User Interfaces, July 8th, 2025. 4 pages. 3 figures
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The topic of self-disclosure to conversational user interfaces is outside the scope of the user's primary focus on information retrieval and deep semantic understanding.

#### Abstract
> Self-disclosure is important to help us feel better, yet is often difficult.
This difficulty can arise from how we think people are going to react to our
self-disclosure. In this workshop paper, we briefly discuss self-disclosure to
conversational user interfaces (CUIs) in relation to various social cues. We
then, discuss how expressions of uncertainty or representation of a CUI's
reasoning could help encourage self-disclosure, by making a CUI's intended
"theory of mind" more transparent to users.

### 31. AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Shiyi Yang, Xiaoxue Yu, Rongpeng Li, Jianhang Zhu, Zhifeng Zhao, Honggang Zhang
- **URL**: <http://arxiv.org/abs/2507.11515v1>
- **Submitted**: 2025-07-15 17:36:37
- **Comment**: 11 pages, 8 figures
- **Topic Keywords**: rank
- **Reason**: The paper focuses on remote fine-tuning of Large Language Models over the air, using a hierarchical diffusion policy framework. While it mentions 'rank configuration' and 'projections', the context is unclear and seems unrelated to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval and Search technologies.

#### Abstract
> Operating Large Language Models (LLMs) on edge devices is increasingly
challenged by limited communication bandwidth and strained computational and
memory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable.
Nevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ
fixed or heuristic rank configurations, and the subsequent over-the-air
transmission of all LoRA parameters could be rather inefficient. To address
this limitation, we develop AirLLM, a hierarchical diffusion policy framework
for communication-aware LoRA adaptation. Specifically, AirLLM models the rank
configuration as a structured action vector that spans all LoRA-inserted
projections. To solve the underlying high-dimensional sequential
decision-making problem, a Proximal Policy Optimization (PPO) agent generates
coarse-grained decisions by jointly observing wireless states and linguistic
complexity, which are then refined via Denoising Diffusion Implicit Models
(DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The
two modules are optimized alternatively, with the DDIM trained under the
Classifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards.
Experiments under varying signal-to-noise ratios demonstrate that AirLLM
consistently enhances fine-tuning performance while significantly reducing
transmission costs, highlighting the effectiveness of reinforcement-driven,
diffusion-refined rank adaptation for scalable and efficient remote fine-tuning
over the air.

### 32. Real-World Summarization: When Evaluation Reaches Its Limits

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Patr√≠cia Schmidtov√°, Ond≈ôej Du≈°ek, Saad Mahamood
- **URL**: <http://arxiv.org/abs/2507.11508v1>
- **Submitted**: 2025-07-15 17:23:56
- **Topic Keywords**: rank
- **Reason**: The paper focuses on summarization and evaluation metrics, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on natural language processing, the context is different from the user's primary interests in IR and search technologies.

#### Abstract
> We examine evaluation of faithfulness to input data in the context of hotel
highlights: brief LLM-generated summaries that capture unique features of
accommodations. Through human evaluation campaigns involving categorical error
assessment and span-level annotation, we compare traditional metrics, trainable
methods, and LLM-as-a-judge approaches. Our findings reveal that simpler
metrics like word overlap correlate surprisingly well with human judgments
(Spearman correlation rank of 0.63), often outperforming more complex methods
when applied to out-of-domain data. We further demonstrate that while LLMs can
generate high-quality highlights, they prove unreliable for evaluation as they
tend to severely under- or over-annotate. Our analysis of real-world business
impacts shows incorrect and non-checkable information pose the greatest risks.
We also highlight challenges in crowdsourced evaluations.

### 33. What is the Best Process Model Representation? A Comparative Analysis for Process Modeling with Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Alexis Brissard, Fr√©d√©ric Cuppens, Amal Zouaq
- **URL**: <http://arxiv.org/abs/2507.11356v1>
- **Submitted**: 2025-07-15 14:26:50
- **Comment**: 12 pages, 7 figures, to be published in AI4BPM 2025 Proceedings
- **Topic Keywords**: search
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on Process Modeling and Large Language Models, which is outside the user's primary research interests.

#### Abstract
> Large Language Models (LLMs) are increasingly applied for Process Modeling
(PMo) tasks such as Process Model Generation (PMG). To support these tasks,
researchers have introduced a variety of Process Model Representations (PMRs)
that serve as model abstractions or generation targets. However, these PMRs
differ widely in structure, complexity, and usability, and have never been
systematically compared. Moreover, recent PMG approaches rely on distinct
evaluation strategies and generation techniques, making comparison difficult.
This paper presents the first empirical study that evaluates multiple PMRs in
the context of PMo with LLMs. We introduce the PMo Dataset, a new dataset
containing 55 process descriptions paired with models in nine different PMRs.
We evaluate PMRs along two dimensions: suitability for LLM-based PMo and
performance on PMG. \textit{Mermaid} achieves the highest overall score across
six PMo criteria, whereas \textit{BPMN text} delivers the best PMG results in
terms of process element similarity.

### 34. Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded Term Lexicon, and Enhanced Detection Frameworks

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Zewen Bai, Liang Yang, Shengdi Yin, Yuanyuan Sun, Hongfei Lin
- **URL**: <http://arxiv.org/abs/2507.11292v1>
- **Submitted**: 2025-07-15 13:19:18
- **Topic Keywords**: search
- **Reason**: The paper focuses on hate speech detection in Chinese, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on interpretability and semantic understanding is not specific to the user's areas of interest, and the recommender systems aspect is not explored.

#### Abstract
> The proliferation of hate speech has inflicted significant societal harm,
with its intensity and directionality closely tied to specific targets and
arguments. In recent years, numerous machine learning-based methods have been
developed to detect hateful comments on online platforms automatically.
However, research on Chinese hate speech detection lags behind, and
interpretability studies face two major challenges: first, the scarcity of
span-level fine-grained annotated datasets limits models' deep semantic
understanding of hate speech; second, insufficient research on identifying and
interpreting coded hate speech restricts model explainability in complex
real-world scenarios. To address these, we make the following contributions:
(1) We introduce the Span-level Target-Aware Toxicity Extraction dataset (STATE
ToxiCN), the first span-level Chinese hate speech dataset, and evaluate the
hate semantic understanding of existing models using it. (2) We conduct the
first comprehensive study on Chinese coded hate terms, LLMs' ability to
interpret hate semantics. (3) We propose a method to integrate an annotated
lexicon into models, significantly enhancing hate speech detection performance.
Our work provides valuable resources and insights to advance the
interpretability of Chinese hate speech detection research.

### 35. Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Conrad Borchers, Bahar Shahrokhian, Francesco Balzan, Elham Tajik, Sreecharan Sankaranarayanan, Sebastian Simon
- **URL**: <http://arxiv.org/abs/2507.11198v1>
- **Submitted**: 2025-07-15 11:06:32
- **Comment**: Manuscript submitted for review
- **Topic Keywords**: search
- **Reason**: The paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on Large Language Models, multi-agent systems, and qualitative coding, which is outside the user's primary research interests.

#### Abstract
> Large Language Models (LLMs) enable new possibilities for qualitative
research at scale, including coding and data annotation. While multi-agent
systems (MAS) can emulate human coding workflows, their benefits over
single-agent coding remain poorly understood. We conducted an experimental
study of how agent persona and temperature shape consensus-building and coding
accuracy of dialog segments based on a codebook with 8 codes. Our open-source
MAS mirrors deductive human coding through structured agent discussion and
consensus arbitration. Using six open-source LLMs (with 3 to 32 billion
parameters) and 18 experimental configurations, we analyze over 77,000 coding
decisions against a gold-standard dataset of human-annotated transcripts from
online math tutoring sessions. Temperature significantly impacted whether and
when consensus was reached across all six LLMs. MAS with multiple personas
(including neutral, assertive, or empathetic), significantly delayed consensus
in four out of six LLMs compared to uniform personas. In three of those LLMs,
higher temperatures significantly diminished the effects of multiple personas
on consensus. However, neither temperature nor persona pairing lead to robust
improvements in coding accuracy. Single agents matched or outperformed MAS
consensus in most conditions. Only one model (OpenHermesV2:7B) and code
category showed above-chance gains from MAS deliberation when temperature was
0.5 or lower and especially when the agents included at least one assertive
persona. Qualitative analysis of MAS collaboration for these configurations
suggests that MAS may nonetheless aid in narrowing ambiguous code applications
that could improve codebooks and human-AI coding. We contribute new insight
into the limits of LLM-based qualitative methods, challenging the notion that
diverse MAS personas lead to better outcomes. We open-source our MAS and
experimentation code.

### 36. What Should LLMs Forget? Quantifying Personal Data in LLMs for Right-to-Be-Forgotten Requests

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Dimitri Staufer
- **URL**: <http://arxiv.org/abs/2507.11128v1>
- **Submitted**: 2025-07-15 09:28:44
- **Comment**: 16 pages, 3 figures. Accepted at the 7th Workshop on eXplainable
  Knowledge Discovery in Data Mining (XKDD 2025), ECML PKDD 2025, Porto,
  Portugal
- **Topic Keywords**: rank
- **Reason**: The paper focuses on the topic of privacy and data protection in Large Language Models (LLMs), which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on machine unlearning and Right-to-Be-Forgotten requests is also outside the user's primary focus.

#### Abstract
> Large Language Models (LLMs) can memorize and reveal personal information,
raising concerns regarding compliance with the EU's GDPR, particularly the
Right to Be Forgotten (RTBF). Existing machine unlearning methods assume the
data to forget is already known but do not address how to identify which
individual-fact associations are stored in the model. Privacy auditing
techniques typically operate at the population level or target a small set of
identifiers, limiting applicability to individual-level data inquiries. We
introduce WikiMem, a dataset of over 5,000 natural language canaries covering
243 human-related properties from Wikidata, and a model-agnostic metric to
quantify human-fact associations in LLMs. Our approach ranks ground-truth
values against counterfactuals using calibrated negative log-likelihood across
paraphrased prompts. We evaluate 200 individuals across 15 LLMs (410M-70B
parameters), showing that memorization correlates with subject web presence and
model scale. We provide a foundation for identifying memorized personal data in
LLMs at the individual level, enabling the dynamic construction of forget sets
for machine unlearning and RTBF requests.

### 37. Team HUMANE at AVeriTeC 2025: HerO 2 for Efficient Fact Verification

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yejun Yoon, Jaeyoon Jung, Seunghyun Yoon, Kunwoo Park
- **URL**: <http://arxiv.org/abs/2507.11004v1>
- **Submitted**: 2025-07-15 05:42:50
- **Comment**: ACL 2025 Workshop (FEVER)
- **Topic Keywords**: rank
- **Reason**: The paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. Although it mentions language models, it focuses on fact verification, which is a different area of research.

#### Abstract
> This paper presents HerO 2, Team HUMANE's system for the AVeriTeC shared task
at the FEVER-25 workshop. HerO 2 is an enhanced version of HerO, the
best-performing open-source model from the previous year's challenge. It
improves evidence quality through document summarization and answer
reformulation, optimizes veracity prediction via post-training quantization
under computational constraints, and enhances overall system performance by
integrating updated language model (LM) backbones. HerO 2 ranked second on the
leaderboard while achieving the shortest runtime among the top three systems,
demonstrating both high efficiency and strong potential for real-world fact
verification. The code is available at https://github.com/ssu-humane/HerO2.

### 38. Modeling Understanding of Story-Based Analogies Using Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Kalit Inani, Keshav Kabra, Vijay Marupudi, Sashank Varma
- **URL**: <http://arxiv.org/abs/2507.10957v1>
- **Submitted**: 2025-07-15 03:40:21
- **Comment**: To appear at CogSci 2025
- **Topic Keywords**: search
- **Reason**: This paper focuses on the understanding of story-based analogies using Large Language Models, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on the topic of semantic representation and model performance, it does not address ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest for your research.

#### Abstract
> Recent advancements in Large Language Models (LLMs) have brought them closer
to matching human cognition across a variety of tasks. How well do these models
align with human performance in detecting and mapping analogies? Prior research
has shown that LLMs can extract similarities from analogy problems but lack
robust human-like reasoning. Building on Webb, Holyoak, and Lu (2023), the
current study focused on a story-based analogical mapping task and conducted a
fine-grained evaluation of LLM reasoning abilities compared to human
performance. First, it explored the semantic representation of analogies in
LLMs, using sentence embeddings to assess whether they capture the similarity
between the source and target texts of an analogy, and the dissimilarity
between the source and distractor texts. Second, it investigated the
effectiveness of explicitly prompting LLMs to explain analogies. Throughout, we
examine whether LLMs exhibit similar performance profiles to those observed in
humans by evaluating their reasoning at the level of individual analogies, and
not just at the level of overall accuracy (as prior studies have done). Our
experiments include evaluating the impact of model size (8B vs. 70B parameters)
and performance variation across state-of-the-art model architectures such as
GPT-4 and LLaMA3. This work advances our understanding of the analogical
reasoning abilities of LLMs and their potential as models of human reasoning.

### 39. Unraveling the Biomarker Prospects of High-Altitude Diseases: Insights from Biomolecular Event Network Constructed using Text Mining

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Balu Bhasuran, Sabenabanu Abdulkadhar, Jeyakumar Natarajan
- **URL**: <http://arxiv.org/abs/2507.10953v1>
- **Submitted**: 2025-07-15 03:34:00
- **Topic Keywords**: rank
- **Reason**: This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on biomolecular event extraction and network analysis in the context of high-altitude diseases, which is outside the user's primary research areas.

#### Abstract
> High-altitude diseases (HAD), encompassing acute mountain sickness (AMS),
high-altitude cerebral edema (HACE), and high-altitude pulmonary edema (HAPE),
are triggered by hypobaric hypoxia at elevations above 2,500 meters. These
conditions pose significant health risks, yet the molecular mechanisms remain
insufficiently understood. In this study, we developed a biomolecular event
extraction pipeline integrating supervised machine learning with feature-based
and multiscale Laplacian graph kernels to analyze 7,847 curated HAD-related
abstracts from PubMed. We extracted over 150 unique biomolecular events
including gene expression, regulation, binding, and localization and
constructed a weighted, undirected biomolecular event network comprising 97
nodes and 153 edges. Using the PageRank algorithm, we prioritized key
biomolecules based on their centrality within the event network. The top-ranked
proteins included Erythropoietin (EPO) (0.0163), Vascular endothelial growth
factor (VEGF) (0.0148), Hypoxia-inducible factor 1 (HIF-1) alpha (0.0136),
Endothelial PAS Domain Protein 1 (EPAS1) and Angiotensin-Converting Enzyme
(ACE) (0.0119), Egl nine homolog 1 (EGLN1), Endothelin 1 (ET-1), and 70
kilodalton heat shock protein (Hsp70)(0.0118), all of which play crucial roles
in oxygen sensing, vascular remodeling, erythropoiesis, and blood pressure
regulation. Subnetwork analysis revealed three major functional clusters
centered on hypoxia response, inflammation, and stress adaptation pathways. Our
integrative approach demonstrates the utility of large-scale text mining and
graph-based analysis to uncover mechanistic insights and prioritize potential
biomarkers for high-altitude disease.

### 40. Domain-Adaptive Small Language Models for Structured Tax Code Prediction

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Souvik Nath, Sumit Wadhwa, Luiz Perez
- **URL**: <http://arxiv.org/abs/2507.10880v1>
- **Submitted**: 2025-07-15 00:46:01
- **Comment**: 10 pages, 3 figures
- **Topic Keywords**: search
- **Reason**: The paper focuses on structured tax code prediction using small language models, which is not directly related to information retrieval, search technologies, or query understanding. While it involves NLP, the domain is specific to tax compliance and does not align with the user's broader interests in e-commerce, data mining, or real-time relevance optimization.

#### Abstract
> Every day, multinational firms process thousands of transactions, each of
which must adhere to tax regulations that vary by jurisdiction and are often
nuanced. The determination of product and service tax codes, such as HSN or SAC
is a major use case in Tax compliance. An accurate determination of such codes
is imperative to avoid any tax penalties. This paper proposes a domain-adaptive
small language model (SLM) with an encoder-decoder architecture for the
enhanced prediction of product and service tax codes. In this approach, we
address the problem of predicting hierarchical tax code sequences using
unstructured product and services data. We employ an SLM based upon
encoder-decoder architecture as this enables sequential generation of tax codes
to capture the hierarchical dependencies present within the tax codes. Our
experiments demonstrate that encoder-decoder SLMs can be successfully applied
to the sequential prediction of structured tax codes, a domain that remains
comparatively unexplored in current NLP research. In this paper, we demonstrate
the superior performance of the domain-adaptive encoder-decoder SLMs over flat
classifiers when applied to the Harmonized System of Nomenclature (HSN), and
achieve superior results compared to decoder-only and encoder-only
architectures for structured sequence generation tasks. This approach can also
be scaled to other government-mandated tax commodity codes, such as United
Nations Standard Products and Services Codes (UNSPSC), or Brazil's Nomenclatura
Comum do Mercosul (NCM).

### 41. LLMs on Trial: Evaluating Judicial Fairness for Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yiran Hu, Zongyue Xue, Haitao Li, Siyuan Zheng, Qingjing Chen, Shaochun Wang, Xihan Zhang, Ning Zheng, Yun Liu, Qingyao Ai, Yiqun Liu, Charles L. A. Clarke, Weixing Shen
- **URL**: <http://arxiv.org/abs/2507.10852v1>
- **Submitted**: 2025-07-14 22:56:58
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus is on evaluating the fairness of Large Language Models in a judicial context, which is outside your primary areas of interest.

#### Abstract
> Large Language Models (LLMs) are increasingly used in high-stakes fields
where their decisions impact rights and equity. However, LLMs' judicial
fairness and implications for social justice remain underexplored. When LLMs
act as judges, the ability to fairly resolve judicial issues is a prerequisite
to ensure their trustworthiness. Based on theories of judicial fairness, we
construct a comprehensive framework to measure LLM fairness, leading to a
selection of 65 labels and 161 corresponding values. Applying this framework to
the judicial system, we compile an extensive dataset, JudiFair, comprising
177,100 unique case facts. To achieve robust statistical inference, we develop
three evaluation metrics, inconsistency, bias, and imbalanced inaccuracy, and
introduce a method to assess the overall fairness of multiple LLMs across
various labels. Through experiments with 16 LLMs, we uncover pervasive
inconsistency, bias, and imbalanced inaccuracy across models, underscoring
severe LLM judicial unfairness. Particularly, LLMs display notably more
pronounced biases on demographic labels, with slightly less bias on substance
labels compared to procedure ones. Interestingly, increased inconsistency
correlates with reduced biases, but more accurate predictions exacerbate
biases. While we find that adjusting the temperature parameter can influence
LLM fairness, model size, release date, and country of origin do not exhibit
significant effects on judicial fairness. Accordingly, we introduce a publicly
available toolkit containing all datasets and code, designed to support future
research in evaluating and improving LLM fairness.

---

