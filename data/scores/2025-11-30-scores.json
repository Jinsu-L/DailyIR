[
    {
        "title": "MegaChat: A Synthetic Persian Q&A Dataset for High-Quality Sales Chatbot Evaluation",
        "abstract": "Small and medium-sized enterprises (SMEs) in Iran increasingly leverage Telegram for sales, where real-time engagement is essential for conversion. However, developing AI-driven chatbots for this purpose requires large, high-quality question-and-answer (Q&A) datasets, which are typically expensive and resource-intensive to produce, especially for low-resource languages like Persian. In this paper, we introduce MegaChat, the first fully synthetic Persian Q&A dataset designed to evaluate intelligent sales chatbots in Telegram-based e-commerce. We propose a novel, automated multi-agent architecture that generates persona-aware Q&A pairs by collecting data from active Telegram shopping channels. The system employs specialized agents for question generation, validation, and refinement, ensuring the production of realistic and diverse conversational data. To evaluate answer generation, we compare three classic retrieval-augmented generation (RAG) models with our advanced agentic system, which features multi-query retrieval, reranking, and persona-aligned response synthesis. Using GPT-5.1 for evaluation across six quality dimensions, our results show that the agentic architecture outperformed traditional RAG models in 4 out of 5 diverse channels, demonstrating its ability to generate scalable, high-quality datasets without relying on expensive human annotation or complex fine-tuning. MegaChat provides SMEs with an efficient, cost-effective solution for building intelligent customer engagement systems in specialized commercial domains, enabling advancements in multilingual conversational AI for low-resource languages. Download: https://github.com/MegaChat-Tech/MegaChat-DataSet",
        "url": "http://arxiv.org/abs/2511.23397v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23397v1",
        "arxiv_id": "2511.23397v1",
        "authors": [
            "Mahdi Rahmani",
            "AmirHossein Saffari",
            "Reyhane Rahmani"
        ],
        "submitted": "2025-11-28 17:44:20",
        "source": "arxiv",
        "comment": "6 pages, 11 figures, 2 tables",
        "score": 17,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'shopping' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of conversational AI and chatbots. The use of retrieval-augmented generation (RAG) models and multi-query retrieval is relevant to your focus on query understanding and ranking models. However, the specific application to Persian Q&A datasets and sales chatbots in the e-commerce domain is somewhat niche and not directly aligned with your primary research themes."
    },
    {
        "title": "MCP vs RAG vs NLWeb vs HTML: A Comparison of the Effectiveness and Efficiency of Different Agent Interfaces to the Web (Technical Report)",
        "abstract": "Large language model agents are increasingly used to automate web tasks such as product search, offer comparison, and checkout. Current research explores different interfaces through which these agents interact with websites, including traditional HTML browsing, retrieval-augmented generation (RAG) over pre-crawled content, communication via Web APIs using the Model Context Protocol (MCP), and natural-language querying through the NLWeb interface. However, no prior work has compared these four architectures within a single controlled environment using identical tasks.\n  To address this gap, we introduce a testbed consisting of four simulated e-shops, each offering its products via HTML, MCP, and NLWeb interfaces. For each interface (HTML, RAG, MCP, and NLWeb) we develop specialized agents that perform the same sets of tasks, ranging from simple product searches and price comparisons to complex queries for complementary or substitute products and checkout processes. We evaluate the agents using GPT 4.1, GPT 5, GPT 5 mini, and Claude Sonnet 4 as underlying LLM. Our evaluation shows that the RAG, MCP and NLWeb agents outperform HTML on both effectiveness and efficiency. Averaged over all tasks, F1 rises from 0.67 for HTML to between 0.75 and 0.77 for the other agents. Token usage falls from about 241k for HTML to between 47k and 140k per task. The runtime per task drops from 291 seconds to between 50 and 62 seconds. The best overall configuration is RAG with GPT 5 achieving an F1 score of 0.87 and a completion rate of 0.79. Also taking cost into consideration, RAG with GPT 5 mini offers a good compromise between API usage fees and performance. Our experiments show the choice of the interaction interface has a substantial impact on both the effectiveness and efficiency of LLM-based web agents.",
        "url": "http://arxiv.org/abs/2511.23281v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23281v1",
        "arxiv_id": "2511.23281v1",
        "authors": [
            "Aaron Steiner",
            "Ralph Peeters",
            "Christian Bizer"
        ],
        "submitted": "2025-11-28 15:32:15",
        "source": "arxiv",
        "comment": null,
        "score": 11,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of query understanding and ranking models. The comparison of different agent interfaces to the web, including retrieval-augmented generation (RAG) and Model Context Protocol (MCP), is closely related to your focus on deep semantic understanding and real-time relevance optimization. However, the paper's primary focus on web agents and their interaction with websites is somewhat tangential to your core research themes."
    },
    {
        "title": "Do LLM-judges Align with Human Relevance in Cranfield-style Recommender Evaluation?",
        "abstract": "Evaluating recommender systems remains a long-standing challenge, as offline methods based on historical user interactions and train-test splits often yield unstable and inconsistent results due to exposure bias, popularity bias, sampled evaluations, and missing-not-at-random patterns. In contrast, textual document retrieval benefits from robust, standardized evaluation via Cranfield-style test collections, which combine pooled relevance judgments with controlled setups. While recent work shows that adapting this methodology to recommender systems is feasible, constructing such collections remains costly due to the need for manual relevance judgments, thus limiting scalability. This paper investigates whether Large Language Models (LLMs) can serve as reliable automatic judges to address these scalability challenges. Using the ML-32M-ext Cranfield-style movie recommendation collection, we first examine the limitations of existing evaluation methodologies. Then we explore the alignment and the recommender systems ranking agreement between the LLM-judge and human provided relevance labels. We find that incorporating richer item metadata and longer user histories improves alignment, and that LLM-judge yields high agreement with human-based rankings (Kendall's tau = 0.87). Finally, an industrial case study in the podcast recommendation domain demonstrates the practical value of LLM-judge for model selection. Overall, our results show that LLM-judge is a viable and scalable approach for evaluating recommender systems.",
        "url": "http://arxiv.org/abs/2511.23312v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23312v1",
        "arxiv_id": "2511.23312v1",
        "authors": [
            "Gustavo Penha",
            "Aleksandr V. Petrov",
            "Claudia Hauff",
            "Enrico Palumbo",
            "Ali Vardasbi",
            "Edoardo D'Amico",
            "Francesco Fabbri",
            "Alice Wang",
            "Praveen Chandar",
            "Henrik Lindstrom",
            "Hugues Bouchard",
            "Mounia Lalmas"
        ],
        "submitted": "2025-11-28 16:10:39",
        "source": "arxiv",
        "comment": null,
        "score": 10,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores recommender systems, which is a related topic to information retrieval, but it focuses on evaluation methodologies rather than query understanding, ranking models, or user behavior modeling. The use of Large Language Models (LLMs) as automatic judges is an interesting application of NLP, but it is not directly aligned with the user's core research themes."
    },
    {
        "title": "Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models",
        "abstract": "This work explores the challenge of building ``Machines that Can Remember'', framing long-term memory as the problem of efficient ultra-long context modeling. We argue that this requires three key properties: \\textbf{sparsity}, \\textbf{random-access flexibility}, and \\textbf{length generalization}. To address ultra-long-context modeling, we leverage Hierarchical Sparse Attention (HSA), a novel attention mechanism that satisfies all three properties. We integrate HSA into Transformers to build HSA-UltraLong, which is an 8B-parameter MoE model trained on over 8 trillion tokens and is rigorously evaluated on different tasks with in-domain and out-of-domain context lengths to demonstrate its capability in handling ultra-long contexts. Results show that our model performs comparably to full-attention baselines on in-domain lengths while achieving over 90\\% accuracy on most in-context retrieval tasks with contexts up to 16M. This report outlines our experimental insights and open problems, contributing a foundation for future research in ultra-long context modeling.",
        "url": "http://arxiv.org/abs/2511.23319v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23319v1",
        "arxiv_id": "2511.23319v1",
        "authors": [
            "Xiang Hu",
            "Zhanchao Zhou",
            "Ruiqi Liang",
            "Zehuan Li",
            "Wei Wu",
            "Jianguo Li"
        ],
        "submitted": "2025-11-28 16:17:53",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'ltr' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores ultra-long context modeling in large language models, leveraging a novel attention mechanism called Hierarchical Sparse Attention. While it touches on the topic of information retrieval with in-context retrieval tasks, the focus is primarily on language modeling and memory, which is somewhat related to your research interests in Information Retrieval and NLP, but not directly aligned with your core themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Towards Improving Interpretability of Language Model Generation through a Structured Knowledge Discovery Approach",
        "abstract": "Knowledge-enhanced text generation aims to enhance the quality of generated text by utilizing internal or external knowledge sources. While language models have demonstrated impressive capabilities in generating coherent and fluent text, the lack of interpretability presents a substantial obstacle. The limited interpretability of generated text significantly impacts its practical usability, particularly in knowledge-enhanced text generation tasks that necessitate reliability and explainability. Existing methods often employ domain-specific knowledge retrievers that are tailored to specific data characteristics, limiting their generalizability to diverse data types and tasks. To overcome this limitation, we directly leverage the two-tier architecture of structured knowledge, consisting of high-level entities and low-level knowledge triples, to design our task-agnostic structured knowledge hunter. Specifically, we employ a local-global interaction scheme for structured knowledge representation learning and a hierarchical transformer-based pointer network as the backbone for selecting relevant knowledge triples and entities. By combining the strong generative ability of language models with the high faithfulness of the knowledge hunter, our model achieves high interpretability, enabling users to comprehend the model output generation process. Furthermore, we empirically demonstrate the effectiveness of our model in both internal knowledge-enhanced table-to-text generation on the RotoWireFG dataset and external knowledge-enhanced dialogue response generation on the KdConv dataset. Our task-agnostic model outperforms state-of-the-art methods and corresponding language models, setting new standards on the benchmark.",
        "url": "http://arxiv.org/abs/2511.23335v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23335v1",
        "arxiv_id": "2511.23335v1",
        "authors": [
            "Shuqi Liu",
            "Han Wu",
            "Guanzhi Deng",
            "Jianshu Chen",
            "Xiaoyang Wang",
            "Linqi Song"
        ],
        "submitted": "2025-11-28 16:43:46",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and deep semantic understanding, but it primarily focuses on improving the interpretability of language models for text generation, which is not a central match for your interests in Information Retrieval (IR), query understanding, and ranking models."
    },
    {
        "title": "ShoppingComp: Are LLMs Really Ready for Your Shopping Cart?",
        "abstract": "We present ShoppingComp, a challenging real-world benchmark for rigorously evaluating LLM-powered shopping agents on three core capabilities: precise product retrieval, expert-level report generation, and safety critical decision making. Unlike prior e-commerce benchmarks, ShoppingComp introduces highly complex tasks under the principle of guaranteeing real products and ensuring easy verifiability, adding a novel evaluation dimension for identifying product safety hazards alongside recommendation accuracy and report quality. The benchmark comprises 120 tasks and 1,026 scenarios, curated by 35 experts to reflect authentic shopping needs. Results reveal stark limitations of current LLMs: even state-of-the-art models achieve low performance (e.g., 11.22% for GPT-5, 3.92% for Gemini-2.5-Flash). These findings highlight a substantial gap between research benchmarks and real-world deployment, where LLMs make critical errors such as failure to identify unsafe product usage or falling for promotional misinformation, leading to harmful recommendations. ShoppingComp fills the gap and thus establishes a new standard for advancing reliable and practical agents in e-commerce.",
        "url": "http://arxiv.org/abs/2511.22978v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22978v1",
        "arxiv_id": "2511.22978v1",
        "authors": [
            "Huaixiao Tou",
            "Ying Zeng",
            "Cong Ma",
            "Muzhi Li",
            "Minghao Li",
            "Weijie Yuan",
            "He Zhang",
            "Kai Jia"
        ],
        "submitted": "2025-11-28 08:32:54",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'shopping' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the e-commerce domain, as it presents a benchmark for evaluating LLM-powered shopping agents on tasks such as product retrieval and report generation. The focus on real-world deployment and safety critical decision making aligns with your interests in query understanding, ranking models, and user behavior modeling. However, the primary focus on LLMs and their limitations might not be a central match with your interests in deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Modeling Romanized Hindi and Bengali: Dataset Creation and Multilingual LLM Integration",
        "abstract": "The development of robust transliteration techniques to enhance the effectiveness of transforming Romanized scripts into native scripts is crucial for Natural Language Processing tasks, including sentiment analysis, speech recognition, information retrieval, and intelligent personal assistants. Despite significant advancements, state-of-the-art multilingual models still face challenges in handling Romanized script, where the Roman alphabet is adopted to represent the phonetic structure of diverse languages. Within the South Asian context, where the use of Romanized script for Indo-Aryan languages is widespread across social media and digital communication platforms, such usage continues to pose significant challenges for cutting-edge multilingual models. While a limited number of transliteration datasets and models are available for Indo-Aryan languages, they generally lack sufficient diversity in pronunciation and spelling variations, adequate code-mixed data for large language model (LLM) training, and low-resource adaptation. To address this research gap, we introduce a novel transliteration dataset for two popular Indo-Aryan languages, Hindi and Bengali, which are ranked as the 3rd and 7th most spoken languages worldwide. Our dataset comprises nearly 1.8 million Hindi and 1 million Bengali transliteration pairs. In addition to that, we pre-train a custom multilingual seq2seq LLM based on Marian architecture using the developed dataset. Experimental results demonstrate significant improvements compared to existing relevant models in terms of BLEU and CER metrics.",
        "url": "http://arxiv.org/abs/2511.22769v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22769v1",
        "arxiv_id": "2511.22769v1",
        "authors": [
            "Kanchon Gharami",
            "Quazi Sarwar Muhtaseem",
            "Deepti Gupta",
            "Lavanya Elluri",
            "Shafika Showkat Moni"
        ],
        "submitted": "2025-11-27 21:39:48",
        "source": "arxiv",
        "comment": "Proceedings of the 8th Workshop on Big Data for Cybersecurity (BigCyber)",
        "score": 7,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on developing a transliteration dataset and a multilingual seq2seq model for Romanized Hindi and Bengali, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does touch on NLP, it is more focused on language translation and model development rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "ReAG: Reasoning-Augmented Generation for Knowledge-based Visual Question Answering",
        "abstract": "Multimodal Large Language Models (MLLMs) have shown impressive capabilities in jointly understanding text, images, and videos, often evaluated via Visual Question Answering (VQA). However, even state-of-the-art MLLMs struggle with domain-specific or knowledge-intensive queries, where relevant information is underrepresented in pre-training data. Knowledge-based VQA (KB-VQA) addresses this by retrieving external documents to condition answer generation, but current retrieval-augmented approaches suffer from low precision, noisy passages, and limited reasoning. To address this, we propose ReAG, a novel Reasoning-Augmented Multimodal RAG approach that combines coarse- and fine-grained retrieval with a critic model that filters irrelevant passages, ensuring high-quality additional context. The model follows a multi-stage training strategy leveraging reinforcement learning to enhance reasoning over retrieved content, while supervised fine-tuning serves only as a cold start. Extensive experiments on Encyclopedic-VQA and InfoSeek demonstrate that ReAG significantly outperforms prior methods, improving answer accuracy and providing interpretable reasoning grounded in retrieved evidence. Our source code is publicly available at: https://github.com/aimagelab/ReAG.",
        "url": "http://arxiv.org/abs/2511.22715v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22715v1",
        "arxiv_id": "2511.22715v1",
        "authors": [
            "Alberto Compagnoni",
            "Marco Morini",
            "Sara Sarto",
            "Federico Cocchi",
            "Davide Caffagni",
            "Marcella Cornia",
            "Lorenzo Baraldi",
            "Rita Cucchiara"
        ],
        "submitted": "2025-11-27 19:01:02",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores multimodal large language models and knowledge-based visual question answering, which is somewhat related to information retrieval and query understanding. However, the focus on visual question answering and multimodal understanding is not directly aligned with the user's primary research interests in text-based information retrieval and search technologies."
    },
    {
        "title": "Listwise Preference Optimization with Element-wise Confusions for Aspect Sentiment Quad Prediction",
        "abstract": "Aspect sentiment quad prediction (ASQP) is inherently challenging to predict a structured quadruple with four core sentiment elements, including aspect term (a), aspect category (c), opinion term (o), and sentiment polarity (s). Prior methods relying on marker-based prediction struggle with modeling the intricate relationships among elements and experience sharp performance declines when predicting higher-order elements (e.g., c and s) under standard supervised fine-tuning. To address these limitations, we employ reasoning-based generation to output both the quadruple and a natural language rationale under element prefixes within a unified template, encouraging explicit relational reasoning and interpretability. To further enhance element-wise alignment, we introduce a listwise preference optimization framework for improving structural validity and relational coherence. Specifically, we generate element-wise confusable candidates via syntactic and semantic proximity, then train the model with listwise objectives to prefer the gold candidates over closely competing alternatives. Extensive experiments on four benchmark datasets demonstrate that our framework effectively improves quadruple prediction accuracy and explanation consistency.",
        "url": "http://arxiv.org/abs/2511.23184v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23184v1",
        "arxiv_id": "2511.23184v1",
        "authors": [
            "Wenna Lai",
            "Haoran Xie",
            "Guandong Xu",
            "Qing Li",
            "S. Joe Qin"
        ],
        "submitted": "2025-11-28 13:52:01",
        "source": "arxiv",
        "comment": "11 pages, 7 figures, and 6 tables",
        "score": 5,
        "keyword_reasons": [
            "Found 'listwise' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to Information Retrieval, as it involves aspect sentiment quad prediction, which can be seen as a form of query understanding. However, the focus is more on Natural Language Processing and sentiment analysis, rather than search technologies or ranking models. The paper's use of listwise preference optimization and element-wise confusions is an interesting approach, but it does not directly align with the user's core research themes."
    },
    {
        "title": "Decoding the Past: Explainable Machine Learning Models for Dating Historical Texts",
        "abstract": "Accurately dating historical texts is essential for organizing and interpreting cultural heritage collections. This article addresses temporal text classification using interpretable, feature-engineered tree-based machine learning models. We integrate five feature categories - compression-based, lexical structure, readability, neologism detection, and distance features - to predict the temporal origin of English texts spanning five centuries. Comparative analysis shows that these feature domains provide complementary temporal signals, with combined models outperforming any individual feature set. On a large-scale corpus, we achieve 76.7% accuracy for century-scale prediction and 26.1% for decade-scale classification, substantially above random baselines (20% and 2.3%). Under relaxed temporal precision, performance increases to 96.0% top-2 accuracy for centuries and 85.8% top-10 accuracy for decades. The final model exhibits strong ranking capabilities with AUCROC up to 94.8% and AUPRC up to 83.3%, and maintains controlled errors with mean absolute deviations of 27 years and 30 years, respectively. For authentication-style tasks, binary models around key thresholds (e.g., 1850-1900) reach 85-98% accuracy. Feature importance analysis identifies distance features and lexical structure as most informative, with compression-based features providing complementary signals. SHAP explainability reveals systematic linguistic evolution patterns, with the 19th century emerging as a pivot point across feature domains. Cross-dataset evaluation on Project Gutenberg highlights domain adaptation challenges, with accuracy dropping by 26.4 percentage points, yet the computational efficiency and interpretability of tree-based models still offer a scalable, explainable alternative to neural architectures.",
        "url": "http://arxiv.org/abs/2511.23056v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23056v1",
        "arxiv_id": "2511.23056v1",
        "authors": [
            "Paulo J. N. Pinto",
            "Armando J. Pinho",
            "Diogo Pratas"
        ],
        "submitted": "2025-11-28 10:27:48",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on temporal text classification and explainable machine learning models for dating historical texts, which is outside the user's core research themes in Information Retrieval and Search technologies. While it involves some machine learning concepts, the application domain and specific problem are not relevant to the user's interests."
    },
    {
        "title": "RAG System for Supporting Japanese Litigation Procedures: Faithful Response Generation Complying with Legal Norms",
        "abstract": "This study discusses the essential components that a Retrieval-Augmented Generation (RAG)-based LLM system should possess in order to support Japanese medical litigation procedures complying with legal norms. In litigation, expert commissioners, such as physicians, architects, accountants, and engineers, provide specialized knowledge to help judges clarify points of dispute. When considering the substitution of these expert roles with a RAG-based LLM system, the constraint of strict adherence to legal norms is imposed. Specifically, three requirements arise: (1) the retrieval module must retrieve appropriate external knowledge relevant to the disputed issues in accordance with the principle prohibiting the use of private knowledge, (2) the responses generated must originate from the context provided by the RAG and remain faithful to that context, and (3) the retrieval module must reference external knowledge with appropriate timestamps corresponding to the issues at hand. This paper discusses the design of a RAG-based LLM system that satisfies these requirements.",
        "url": "http://arxiv.org/abs/2511.22858v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22858v1",
        "arxiv_id": "2511.22858v1",
        "authors": [
            "Yuya Ishihara",
            "Atsushi Keyaki",
            "Hiroaki Yamada",
            "Ryutaro Ohara",
            "Mihoko Sumida"
        ],
        "submitted": "2025-11-28 03:28:27",
        "source": "arxiv",
        "comment": "This is a preprint version of a paper reviewed and accepted at BREV-RAG 2025: Beyond Relevance-based EValuation of RAG Systems, a SIGIR-AP 2025 workshop",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves Retrieval-Augmented Generation (RAG), it is focused on a specific application in Japanese litigation procedures, which does not align with the user's interests in e-commerce or general deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Scaling HuBERT for African Languages: From Base to Large and XL",
        "abstract": "Despite recent progress in multilingual speech processing, African languages remain under-represented in both research and deployed systems, particularly when it comes to strong, open-weight encoders that transfer well under low-resource supervision. Self-supervised learning has proven especially promising in such settings, yet most publicly released models targeting African speech remain at BASE scale, leaving unanswered whether larger encoders, trained exclusively on Africa-centric audio, offer tangible benefits and how model capacity interacts with data composition. This work addresses that gap by introducing SSA-HuBERT-Large (317M parameters) and SSA-HuBERT-XL (964M parameters), the first large models trained solely on African speech, alongside a BASE size counterpart. We release these models as open weights: see https://huggingface.co/collections/Orange/african-speech-foundation-models. By conducting a carefully controlled experimental study focused exclusively on Sub-Saharan languages, covering automatic speech recognition (ASR) and language identification (LID) tasks, we demonstrate that larger architectures significantly improve performance by effectively leveraging large audio datasets.",
        "url": "http://arxiv.org/abs/2511.23370v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23370v1",
        "arxiv_id": "2511.23370v1",
        "authors": [
            "Antoine Caubrière",
            "Elodie Gauthier"
        ],
        "submitted": "2025-11-28 17:17:40",
        "source": "arxiv",
        "comment": "Journée d'études AFIA-ATALA 2025 : Technologies linguistiques pour les langues peu dotées",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multilingual speech processing and self-supervised learning for African languages, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "Transformer-Driven Triple Fusion Framework for Enhanced Multimodal Author Intent Classification in Low-Resource Bangla",
        "abstract": "The expansion of the Internet and social networks has led to an explosion of user-generated content. Author intent understanding plays a crucial role in interpreting social media content. This paper addresses author intent classification in Bangla social media posts by leveraging both textual and visual data. Recognizing limitations in previous unimodal approaches, we systematically benchmark transformer-based language models (mBERT, DistilBERT, XLM-RoBERTa) and vision architectures (ViT, Swin, SwiftFormer, ResNet, DenseNet, MobileNet), utilizing the Uddessho dataset of 3,048 posts spanning six practical intent categories. We introduce a novel intermediate fusion strategy that significantly outperforms early and late fusion on this task. Experimental results show that intermediate fusion, particularly with mBERT and Swin Transformer, achieves 84.11% macro-F1 score, establishing a new state-of-the-art with an 8.4 percentage-point improvement over prior Bangla multimodal approaches. Our analysis demonstrates that integrating visual context substantially enhances intent classification. Cross-modal feature integration at intermediate levels provides optimal balance between modality-specific representation and cross-modal learning. This research establishes new benchmarks and methodological standards for Bangla and other low-resource languages. We call our proposed framework BangACMM (Bangla Author Content MultiModal).",
        "url": "http://arxiv.org/abs/2511.23287v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23287v1",
        "arxiv_id": "2511.23287v1",
        "authors": [
            "Ariful Islam",
            "Tanvir Mahmud",
            "Md Rifat Hossen"
        ],
        "submitted": "2025-11-28 15:44:42",
        "source": "arxiv",
        "comment": "Accepted at the 28th International Conference on Computer and Information Technology (ICCIT 2025). To be published in IEEE proceedings",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on author intent classification in Bangla social media posts using multimodal data, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP and deep learning techniques, the specific application and language (Bangla) are not aligned with your primary focus."
    },
    {
        "title": "BanglaSentNet: An Explainable Hybrid Deep Learning Framework for Multi-Aspect Sentiment Analysis with Cross-Domain Transfer Learning",
        "abstract": "Multi-aspect sentiment analysis of Bangla e-commerce reviews remains challenging due to limited annotated datasets, morphological complexity, code-mixing phenomena, and domain shift issues, affecting 300 million Bangla-speaking users. Existing approaches lack explainability and cross-domain generalization capabilities crucial for practical deployment. We present BanglaSentNet, an explainable hybrid deep learning framework integrating LSTM, BiLSTM, GRU, and BanglaBERT through dynamic weighted ensemble learning for multi-aspect sentiment classification. We introduce a dataset of 8,755 manually annotated Bangla product reviews across four aspects (Quality, Service, Price, Decoration) from major Bangladeshi e-commerce platforms. Our framework incorporates SHAP-based feature attribution and attention visualization for transparent insights. BanglaSentNet achieves 85% accuracy and 0.88 F1-score, outperforming standalone deep learning models by 3-7% and traditional approaches substantially. The explainability suite achieves 9.4/10 interpretability score with 87.6% human agreement. Cross-domain transfer learning experiments reveal robust generalization: zero-shot performance retains 67-76% effectiveness across diverse domains (BanglaBook reviews, social media, general e-commerce, news headlines); few-shot learning with 500-1000 samples achieves 90-95% of full fine-tuning performance, significantly reducing annotation costs. Real-world deployment demonstrates practical utility for Bangladeshi e-commerce platforms, enabling data-driven decision-making for pricing optimization, service improvement, and customer experience enhancement. This research establishes a new state-of-the-art benchmark for Bangla sentiment analysis, advances ensemble learning methodologies for low-resource languages, and provides actionable solutions for commercial applications.",
        "url": "http://arxiv.org/abs/2511.23264v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23264v1",
        "arxiv_id": "2511.23264v1",
        "authors": [
            "Ariful Islam",
            "Md Rifat Hossen",
            "Tanvir Mahmud"
        ],
        "submitted": "2025-11-28 15:17:22",
        "source": "arxiv",
        "comment": "Submitted to Springer Nature Computer Science (SNCS) as an extended version of our ICDSAIA 2025 conference paper",
        "score": 3,
        "keyword_reasons": [
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on multi-aspect sentiment analysis for Bangla e-commerce reviews, which is somewhat related to information retrieval and search technologies. However, the primary focus on NLP and deep learning for sentiment analysis, although relevant to user behavior modeling, does not directly align with the user's core research themes in query understanding, ranking models, and click models."
    },
    {
        "title": "Tourism Question Answer System in Indian Language using Domain-Adapted Foundation Models",
        "abstract": "This article presents the first comprehensive study on designing a baseline extractive question-answering (QA) system for the Hindi tourism domain, with a specialized focus on the Varanasi-a cultural and spiritual hub renowned for its Bhakti-Bhaav (devotional ethos). Targeting ten tourism-centric subdomains-Ganga Aarti, Cruise, Food Court, Public Toilet, Kund, Museum, General, Ashram, Temple and Travel, the work addresses the absence of language-specific QA resources in Hindi for culturally nuanced applications. In this paper, a dataset comprising 7,715 Hindi QA pairs pertaining to Varanasi tourism was constructed and subsequently augmented with 27,455 pairs generated via Llama zero-shot prompting. We propose a framework leveraging foundation models-BERT and RoBERTa, fine-tuned using Supervised Fine-Tuning (SFT) and Low-Rank Adaptation (LoRA), to optimize parameter efficiency and task performance. Multiple variants of BERT, including pre-trained languages (e.g., Hindi-BERT), are evaluated to assess their suitability for low-resource domain-specific QA. Evaluation metrics - F1, BLEU, and ROUGE-L - highlight trade-offs between answer precision and linguistic fluency. Experiments demonstrate that LoRA-based fine-tuning achieves competitive performance (85.3\\% F1) while reducing trainable parameters by 98\\% compared to SFT, striking a balance between efficiency and accuracy. Comparative analysis across models reveals that RoBERTa with SFT outperforms BERT variants in capturing contextual nuances, particularly for culturally embedded terms (e.g., Aarti, Kund). This work establishes a foundational baseline for Hindi tourism QA systems, emphasizing the role of LORA in low-resource settings and underscoring the need for culturally contextualized NLP frameworks in the tourism domain.",
        "url": "http://arxiv.org/abs/2511.23235v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23235v1",
        "arxiv_id": "2511.23235v1",
        "authors": [
            "Praveen Gatla",
            "Anushka",
            "Nikita Kanwar",
            "Gouri Sahoo",
            "Rajesh Kumar Mundotiya"
        ],
        "submitted": "2025-11-28 14:44:16",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and query understanding, as it involves question-answering systems and fine-tuning foundation models. However, the focus on the tourism domain and Indian languages is not a central match to your e-commerce background and interests in information retrieval, especially in areas requiring deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Multi-chain Graph Refinement and Selection for Reliable Reasoning in Large Language Models",
        "abstract": "The complex reasoning ability of Large Language Models (LLMs) poses a critical bottleneck for their practical applications. Test-time expansion methods such as Tree-of-Thought (ToT) and Graph-of-Thought (GoT) enhance reasoning by introducing intermediate reasoning structures, tree search, or graph-based exploration mechanisms. However, their reasoning strategies suffer from limited diversity, redundant search branches, and inadequate integration and error correction across heterogeneous reasoning paths. To address these limitations, we propose a novel reasoning framework called Multi-chain Graph Refinement & Selection (MGRS), which first generates multiple diverse reasoning trajectories for a given problem, refines candidate responses using a composite self- and cross-verification strategy, then constructs a reasoning relation graph and estimates the success rate of intermediate nodes, and finally computes cumulative success rates to select the most reliable answer and corresponding reasoning trajectory. Experimental results demonstrate that MGRS significantly advances both the reasoning capability and computational efficiency of reasoning enhancement methods. Across six benchmark datasets spanning four distinct tasks, MGRS achieves an average accuracy of 82.9%, outperforming state-of-the-art baselines by a clear margin of 2.1%. Remarkably, on the 24-point game, MGRS attains 100% accuracy for the first time, while delivering a 13.6x speed-up compared to the leading Forest of Thoughts framework.",
        "url": "http://arxiv.org/abs/2511.23136v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23136v1",
        "arxiv_id": "2511.23136v1",
        "authors": [
            "Yujiao Yang",
            "Jing Lian",
            "Linhui Li"
        ],
        "submitted": "2025-11-28 12:35:16",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Large Language Models and their reasoning capabilities, proposing a novel framework for reliable reasoning. While it involves graph-based exploration mechanisms, it does not directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "Bharat Scene Text: A Novel Comprehensive Dataset and Benchmark for Indian Language Scene Text Understanding",
        "abstract": "Reading scene text, that is, text appearing in images, has numerous application areas, including assistive technology, search, and e-commerce. Although scene text recognition in English has advanced significantly and is often considered nearly a solved problem, Indian language scene text recognition remains an open challenge. This is due to script diversity, non-standard fonts, and varying writing styles, and, more importantly, the lack of high-quality datasets and open-source models. To address these gaps, we introduce the Bharat Scene Text Dataset (BSTD) - a large-scale and comprehensive benchmark for studying Indian Language Scene Text Recognition. It comprises more than 100K words that span 11 Indian languages and English, sourced from over 6,500 scene images captured across various linguistic regions of India. The dataset is meticulously annotated and supports multiple scene text tasks, including: (i) Scene Text Detection, (ii) Script Identification, (iii) Cropped Word Recognition, and (iv) End-to-End Scene Text Recognition. We evaluated state-of-the-art models originally developed for English by adapting (fine-tuning) them for Indian languages. Our results highlight the challenges and opportunities in Indian language scene text recognition. We believe that this dataset represents a significant step toward advancing research in this domain. All our models and data are open source.",
        "url": "http://arxiv.org/abs/2511.23071v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23071v1",
        "arxiv_id": "2511.23071v1",
        "authors": [
            "Anik De",
            "Abhirama Subramanyam Penamakuri",
            "Rajeev Yadav",
            "Aditya Rathore",
            "Harshiv Shah",
            "Devesh Sharma",
            "Sagar Agarwal",
            "Pravin Kumar",
            "Anand Mishra"
        ],
        "submitted": "2025-11-28 10:58:37",
        "source": "arxiv",
        "comment": "Under Peer Review",
        "score": 3,
        "keyword_reasons": [
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 3,
        "llm_reason": "The paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, but it focuses on scene text recognition and Indian language understanding, which is not a central match to your core themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Masked Diffusion for Generative Recommendation",
        "abstract": "Generative recommendation (GR) with semantic IDs (SIDs) has emerged as a promising alternative to traditional recommendation approaches due to its performance gains, capitalization on semantic information provided through language model embeddings, and inference and storage efficiency. Existing GR with SIDs works frame the probability of a sequence of SIDs corresponding to a user's interaction history using autoregressive modeling. While this has led to impressive next item prediction performances in certain settings, these autoregressive GR with SIDs models suffer from expensive inference due to sequential token-wise decoding, potentially inefficient use of training data and bias towards learning short-context relationships among tokens. Inspired by recent breakthroughs in NLP, we propose to instead model and learn the probability of a user's sequence of SIDs using masked diffusion. Masked diffusion employs discrete masking noise to facilitate learning the sequence distribution, and models the probability of masked tokens as conditionally independent given the unmasked tokens, allowing for parallel decoding of the masked tokens. We demonstrate through thorough experiments that our proposed method consistently outperforms autoregressive modeling. This performance gap is especially pronounced in data-constrained settings and in terms of coarse-grained recall, consistent with our intuitions. Moreover, our approach allows the flexibility of predicting multiple SIDs in parallel during inference while maintaining superior performance to autoregressive modeling.",
        "url": "http://arxiv.org/abs/2511.23021v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23021v1",
        "arxiv_id": "2511.23021v1",
        "authors": [
            "Kulin Shah",
            "Bhuvesh Kumar",
            "Neil Shah",
            "Liam Collins"
        ],
        "submitted": "2025-11-28 09:36:26",
        "source": "arxiv",
        "comment": "25 pages",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Generative Recommendation, which is somewhat related to Information Retrieval, but it's more aligned with Recommender Systems. Although it involves NLP and semantic understanding, the primary goal is to improve recommendation models, which is not the core focus of the user's research interests."
    },
    {
        "title": "Language-conditioned world model improves policy generalization by reading environmental descriptions",
        "abstract": "To interact effectively with humans in the real world, it is important for agents to understand language that describes the dynamics of the environment--that is, how the environment behaves--rather than just task instructions specifying \"what to do\". Understanding this dynamics-descriptive language is important for human-agent interaction and agent behavior. Recent work address this problem using a model-based approach: language is incorporated into a world model, which is then used to learn a behavior policy. However, these existing methods either do not demonstrate policy generalization to unseen games or rely on limiting assumptions. For instance, assuming that the latency induced by inference-time planning is tolerable for the target task or expert demonstrations are available. Expanding on this line of research, we focus on improving policy generalization from a language-conditioned world model while dropping these assumptions. We propose a model-based reinforcement learning approach, where a language-conditioned world model is trained through interaction with the environment, and a policy is learned from this model--without planning or expert demonstrations. Our method proposes Language-aware Encoder for Dreamer World Model (LED-WM) built on top of DreamerV3. LED-WM features an observation encoder that uses an attention mechanism to explicitly ground language descriptions to entities in the observation. We show that policies trained with LED-WM generalize more effectively to unseen games described by novel dynamics and language compared to other baselines in several settings in two environments: MESSENGER and MESSENGER-WM.To highlight how the policy can leverage the trained world model before real-world deployment, we demonstrate the policy can be improved through fine-tuning on synthetic test trajectories generated by the world model.",
        "url": "http://arxiv.org/abs/2511.22904v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22904v1",
        "arxiv_id": "2511.22904v1",
        "authors": [
            "Anh Nguyen",
            "Stefan Lee"
        ],
        "submitted": "2025-11-28 06:13:27",
        "source": "arxiv",
        "comment": "NeuRIPS 2025. Workshop: LAW 2025: Bridging Language, Agent, and World Models",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving policy generalization in a model-based reinforcement learning approach, using a language-conditioned world model. While it involves understanding language and its application in a real-world environment, it does not directly relate to information retrieval, search technologies, or user behavior modeling, which are the core areas of your research interests."
    },
    {
        "title": "ORION: Teaching Language Models to Reason Efficiently in the Language of Thought",
        "abstract": "Large Reasoning Models (LRMs) achieve strong performance in mathematics, code generation, and task planning, but their reliance on long chains of verbose \"thinking\" tokens leads to high latency, redundancy, and incoherent reasoning paths. Inspired by the Language of Thought Hypothesis, which posits that human reasoning operates over a symbolic, compositional mental language called Mentalese, we introduce a framework that trains models to reason in a similarly compact style. Mentalese encodes abstract reasoning as ultra-compressed, structured tokens, enabling models to solve complex problems with far fewer steps. To improve both efficiency and accuracy, we propose SHORTER LENGTH PREFERENCE OPTIMIZATION (SLPO), a reinforcement learning method that rewards concise solutions that stay correct, while still allowing longer reasoning when needed. Applied to Mentalese-aligned models, SLPO yields significantly higher compression rates by enabling concise reasoning that preserves the benefits of detailed thinking without the computational overhead. Across benchmarks including AIME 2024 and 2025, MinervaMath, OlympiadBench, Math500, and AMC, our ORION models produce reasoning traces with 4-16x fewer tokens, achieve up to 5x lower inference latency, and reduce training costs by 7-9x relative to the DeepSeek R1 Distilled model, while maintaining 90-98% of its accuracy. ORION also surpasses Claude and ChatGPT-4o by up to 5% in accuracy while maintaining 2x compression. These results show that Mentalese-style compressed reasoning offers a step toward human-like cognitive efficiency, enabling real-time, cost-effective reasoning without sacrificing accuracy.",
        "url": "http://arxiv.org/abs/2511.22891v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22891v1",
        "arxiv_id": "2511.22891v1",
        "authors": [
            "Kumar Tanmay",
            "Kriti Aggarwal",
            "Paul Pu Liang",
            "Subhabrata Mukherjee"
        ],
        "submitted": "2025-11-28 05:41:55",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'ltr' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on improving the efficiency of large reasoning models, which is somewhat related to information retrieval and search technologies. However, the primary focus on reasoning and cognitive efficiency, rather than query understanding, ranking models, or user behavior modeling, limits its relevance to your core research themes."
    },
    {
        "title": "FedAU2: Attribute Unlearning for User-Level Federated Recommender Systems with Adaptive and Robust Adversarial Training",
        "abstract": "Federated Recommender Systems (FedRecs) leverage federated learning to protect user privacy by retaining data locally. However, user embeddings in FedRecs often encode sensitive attribute information, rendering them vulnerable to attribute inference attacks. Attribute unlearning has emerged as a promising approach to mitigate this issue. In this paper, we focus on user-level FedRecs, which is a more practical yet challenging setting compared to group-level FedRecs. Adversarial training emerges as the most feasible approach within this context. We identify two key challenges in implementing adversarial training-based attribute unlearning for user-level FedRecs: i) mitigating training instability caused by user data heterogeneity, and ii) preventing attribute information leakage through gradients. To address these challenges, we propose FedAU2, an attribute unlearning method for user-level FedRecs. For CH1, we propose an adaptive adversarial training strategy, where the training dynamics are adjusted in response to local optimization behavior. For CH2, we propose a dual-stochastic variational autoencoder to perturb the adversarial model, effectively preventing gradient-based information leakage. Extensive experiments on three real-world datasets demonstrate that our proposed FedAU2 achieves superior performance in unlearning effectiveness and recommendation performance compared to existing baselines.",
        "url": "http://arxiv.org/abs/2511.22872v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22872v1",
        "arxiv_id": "2511.22872v1",
        "authors": [
            "Yuyuan Li",
            "Junjie Fang",
            "Fengyuan Yu",
            "Xichun Sheng",
            "Tianyu Du",
            "Xuyang Teng",
            "Shaowei Jiang",
            "Linbo Jiang",
            "Jianan Lin",
            "Chaochao Chen"
        ],
        "submitted": "2025-11-28 04:22:27",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on federated recommender systems, attribute unlearning, and adversarial training, which are not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "ThetaEvolve: Test-time Learning on Open Problems",
        "abstract": "Recent advances in large language models (LLMs) have enabled breakthroughs in mathematical discovery, exemplified by AlphaEvolve, a closed-source system that evolves programs to improve bounds on open problems. However, it relies on ensembles of frontier LLMs to achieve new bounds and is a pure inference system that models cannot internalize the evolving strategies. We introduce ThetaEvolve, an open-source framework that simplifies and extends AlphaEvolve to efficiently scale both in-context learning and Reinforcement Learning (RL) at test time, allowing models to continually learn from their experiences in improving open optimization problems. ThetaEvolve features a single LLM, a large program database for enhanced exploration, batch sampling for higher throughput, lazy penalties to discourage stagnant outputs, and optional reward shaping for stable training signals, etc. ThetaEvolve is the first evolving framework that enable a small open-source model, like DeepSeek-R1-0528-Qwen3-8B, to achieve new best-known bounds on open problems (circle packing and first auto-correlation inequality) mentioned in AlphaEvolve. Besides, across two models and four open tasks, we find that ThetaEvolve with RL at test-time consistently outperforms inference-only baselines, and the model indeed learns evolving capabilities, as the RL-trained checkpoints demonstrate faster progress and better final performance on both trained target task and other unseen tasks. We release our code publicly: https://github.com/ypwang61/ThetaEvolve",
        "url": "http://arxiv.org/abs/2511.23473v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23473v1",
        "arxiv_id": "2511.23473v1",
        "authors": [
            "Yiping Wang",
            "Shao-Rong Su",
            "Zhiyuan Zeng",
            "Eva Xu",
            "Liliang Ren",
            "Xinyu Yang",
            "Zeyi Huang",
            "Xuehai He",
            "Luyao Ma",
            "Baolin Peng",
            "Hao Cheng",
            "Pengcheng He",
            "Weizhu Chen",
            "Shuohang Wang",
            "Simon Shaolei Du",
            "Yelong Shen"
        ],
        "submitted": "2025-11-28 18:58:14",
        "source": "arxiv",
        "comment": "30 pages, link: https://github.com/ypwang61/ThetaEvolve",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is about a framework for mathematical discovery using large language models, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves deep learning and optimization, the focus is on mathematical problem-solving rather than semantic understanding or real-time relevance optimization."
    },
    {
        "title": "Pooling Attention: Evaluating Pretrained Transformer Embeddings for Deception Classification",
        "abstract": "This paper investigates fake news detection as a downstream evaluation of Transformer representations, benchmarking encoder-only and decoder-only pre-trained models (BERT, GPT-2, Transformer-XL) as frozen embedders paired with lightweight classifiers. Through controlled preprocessing comparing pooling versus padding and neural versus linear heads, results demonstrate that contextual self-attention encodings consistently transfer effectively. BERT embeddings combined with logistic regression outperform neural baselines on LIAR dataset splits, while analyses of sequence length and aggregation reveal robustness to truncation and advantages from simple max or average pooling. This work positions attention-based token encoders as robust, architecture-centric foundations for veracity tasks, isolating Transformer contributions from classifier complexity.",
        "url": "http://arxiv.org/abs/2511.22977v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22977v1",
        "arxiv_id": "2511.22977v1",
        "authors": [
            "Sumit Mamtani",
            "Abhijeet Bhure"
        ],
        "submitted": "2025-11-28 08:32:49",
        "source": "arxiv",
        "comment": "Accepted at the IEEE 7th Computing, Communications and IoT Applications Conference (ComComAp 2025), Madrid, Spain, December 2025. 6 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 3,
        "llm_reason": "This paper is loosely relevant to your research interests as it involves Natural Language Processing (NLP) and deep semantic understanding, but it focuses on deception classification and fake news detection, which is not directly related to your primary focus on Information Retrieval and Search technologies."
    },
    {
        "title": "Training-Free Loosely Speculative Decoding: Accepting Semantically Correct Drafts Beyond Exact Match",
        "abstract": "Large language models (LLMs) achieve strong performance across diverse tasks but suffer from high inference latency due to their autoregressive generation. Speculative Decoding (SPD) mitigates this issue by verifying candidate tokens in parallel from a smaller draft model, yet its strict exact-match verification discards many semantically valid continuations. Moreover, existing training-based SPD methods often suffer from performance degradation on out-of-distribution (OOD) tasks. To this end, we propose Training-Free Loosely Speculative Decoding (FLy), a novel method that loosens the rigid verification criterion by leveraging the target model's self-corrective behavior to judge whether a draft-target mismatch remains semantically valid. FLy introduces a two-tier mechanism: an entropy-level gate that identifies whether the current token allows multiple plausible alternatives or is nearly deterministic, and a token-level deferred window that distinguishes genuine errors from differently worded yet semantically correct variants. To further reduce latency, we design a multi-level acceleration strategy that accelerates not only the target model but also the drafter itself. Owing to its training-free design, FLy composes seamlessly with arbitrary draft-target pairs and generalizes across models and domains without hyperparameter re-tuning. Experiments show that FLy preserves more than 99% of the target model's accuracy while achieving an average 2.81x speedup on Llama-3.1-70B-Instruct and 5.07x speedup on the 405B variant. Notably, on out-of-domain datasets, our method remains highly effective and outperforms the training-based method EAGLE-3 by 1.62x.",
        "url": "http://arxiv.org/abs/2511.22972v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22972v1",
        "arxiv_id": "2511.22972v1",
        "authors": [
            "Jinze Li",
            "Yixing Xu",
            "Guanchen Li",
            "Shuo Yang",
            "Jinfeng Xu",
            "Xuanwu Yin",
            "Dong Li",
            "Edith C. H. Ngai",
            "Emad Barsoum"
        ],
        "submitted": "2025-11-28 08:23:30",
        "source": "arxiv",
        "comment": "Under review",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on improving the efficiency of large language models through speculative decoding, but it does not directly relate to information retrieval, search technologies, or user behavior modeling. While it involves deep semantic understanding, the context is different from your primary research interests in IR and NLP."
    },
    {
        "title": "Visual Puns from Idioms: An Iterative LLM-T2IM-MLLM Framework",
        "abstract": "We study idiom-based visual puns--images that align an idiom's literal and figurative meanings--and present an iterative framework that coordinates a large language model (LLM), a text-to-image model (T2IM), and a multimodal LLM (MLLM) for automatic generation and evaluation. Given an idiom, the system iteratively (i) generates detailed visual prompts, (ii) synthesizes an image, (iii) infers the idiom from the image, and (iv) refines the prompt until recognition succeeds or a step limit is reached. Using 1,000 idioms as inputs, we synthesize a corresponding dataset of visual pun images with paired prompts, enabling benchmarking of both generation and understanding. Experiments across 10 LLMs, 10 MLLMs, and one T2IM (Qwen-Image) show that MLLM choice is the primary performance driver: GPT achieves the highest accuracies, Gemini follows, and the best open-source MLLM (Gemma) is competitive with some closed models. On the LLM side, Claude attains the strongest average performance for prompt generation.",
        "url": "http://arxiv.org/abs/2511.22943v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22943v1",
        "arxiv_id": "2511.22943v1",
        "authors": [
            "Kelaiti Xiao",
            "Liang Yang",
            "Dongyu Zhang",
            "Paerhati Tulajiang",
            "Hongfei Lin"
        ],
        "submitted": "2025-11-28 07:30:58",
        "source": "arxiv",
        "comment": "Submitted to ICASSP 2026 (under review)",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on visual puns and idiom-based image generation, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves multimodal models, the context is more aligned with computer vision and creative AI applications rather than real-time relevance optimization or query understanding."
    },
    {
        "title": "Artwork Interpretation with Vision Language Models: A Case Study on Emotions and Emotion Symbols",
        "abstract": "Emotions are a fundamental aspect of artistic expression. Due to their abstract nature, there is a broad spectrum of emotion realization in artworks. These are subject to historical change and their analysis requires expertise in art history. In this article, we investigate which aspects of emotional expression can be detected by current (2025) vision language models (VLMs). We present a case study of three VLMs (Llava-Llama and two Qwen models) in which we ask these models four sets of questions of increasing complexity about artworks (general content, emotional content, expression of emotions, and emotion symbols) and carry out a qualitative expert evaluation. We find that the VLMs recognize the content of the images surprisingly well and often also which emotions they depict and how they are expressed. The models perform best for concrete images but fail for highly abstract or highly symbolic images. Reliable recognition of symbols remains fundamentally difficult. Furthermore, the models continue to exhibit the well-known LLM weakness of providing inconsistent answers to related questions.",
        "url": "http://arxiv.org/abs/2511.22929v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22929v1",
        "arxiv_id": "2511.22929v1",
        "authors": [
            "Sebastian Padó",
            "Kerstin Thomas"
        ],
        "submitted": "2025-11-28 07:04:09",
        "source": "arxiv",
        "comment": "Accepted for publication at the IJCNLP-AACL workshop on Multimodal Models for Low-Resource Contexts and Social Impact",
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves vision language models, the focus is on artwork interpretation and emotion recognition, which is outside your primary areas of interest."
    },
    {
        "title": "Two-Stage Distributionally Robust Optimization Framework for Secure Communications in Aerial-RIS Systems",
        "abstract": "This letter proposes a two-stage distributionally robust optimization (DRO) framework for secure deployment and beamforming in an aerial reconfigurable intelligent surface (A-RIS) assisted millimeter-wave system. To account for multi-timescale uncertainties arising from user mobility, imperfect channel state information (CSI), and hardware impairments, our approach decouples the long-term unmanned aerial vehicle (UAV) placement from the per-slot beamforming design. By employing the conditional value-at-risk (CVaR) as a distribution-free risk metric, a low-complexity algorithm is developed, which combines a surrogate model for efficient deployment with an alternating optimization (AO) scheme for robust real-time beamforming. Simulation results validate that the proposed DRO-CVaR framework significantly enhances the tail-end secrecy spectral efficiency and maintains a lower outage probability compared to benchmark schemes, especially under severe uncertainty conditions.",
        "url": "http://arxiv.org/abs/2511.22855v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22855v1",
        "arxiv_id": "2511.22855v1",
        "authors": [
            "Zhongming Feng",
            "Qiling Gao",
            "Zeping Sui",
            "Yun Lin",
            "Michail Matthaiou"
        ],
        "submitted": "2025-11-28 03:20:19",
        "source": "arxiv",
        "comment": "5 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on secure communications in aerial-RIS systems, which is outside the scope of information retrieval, search technologies, and related topics."
    },
    {
        "title": "Ambiguity Awareness Optimization: Towards Semantic Disambiguation for Direct Preference Optimization",
        "abstract": "Direct Preference Optimization (DPO) is a widely used reinforcement learning from human feedback (RLHF) method across various domains. Recent research has increasingly focused on the role of token importance in improving DPO effectiveness. It is observed that identical or semantically similar content (defined as ambiguous content) frequently appears within the preference pairs. We hypothesize that the presence of ambiguous content during DPO training may introduce ambiguity, thereby limiting further improvements in alignment. Through mathematical analysis and proof-of-concept experiments, we reveal that ambiguous content may potentially introduce ambiguities, thereby degrading performance. To address this issue, we introduce Ambiguity Awareness Optimization (AAO), a simple yet effective approach that automatically re-weights ambiguous content to reduce ambiguities by calculating semantic similarity from preference pairs. Through extensive experiments, we demonstrate that AAO consistently and significantly surpasses state-of-the-art approaches in performance, without markedly increasing response length, across multiple model scales and widely adopted benchmark datasets, including AlpacaEval 2, MT-Bench, and Arena-Hard. Specifically, AAO outperforms DPO by up to 8.9 points on AlpacaEval 2 and achieves an improvement of by up to 15.0 points on Arena-Hard.",
        "url": "http://arxiv.org/abs/2511.23391v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23391v1",
        "arxiv_id": "2511.23391v1",
        "authors": [
            "Jian Li",
            "Shenglin Yin",
            "Yujia Zhang",
            "Alan Zhao",
            "Xi Chen",
            "Xiaohui Zhou",
            "Pengfei Xu"
        ],
        "submitted": "2025-11-28 17:32:54",
        "source": "arxiv",
        "comment": "Accepted at EMNLP 2025 main",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper explores the concept of ambiguity awareness in Direct Preference Optimization, a topic somewhat related to information retrieval and ranking models. While it doesn't directly focus on query understanding or user behavior modeling, it does involve semantic disambiguation and real-time relevance optimization, which are relevant to your interests. However, the specific domain and application (RLHF) are not directly aligned with your e-commerce background or primary focus on IR."
    },
    {
        "title": "Is Passive Expertise-Based Personalization Enough? A Case Study in AI-Assisted Test-Taking",
        "abstract": "Novice and expert users have different systematic preferences in task-oriented dialogues. However, whether catering to these preferences actually improves user experience and task performance remains understudied. To investigate the effects of expertise-based personalization, we first built a version of an enterprise AI assistant with passive personalization. We then conducted a user study where participants completed timed exams, aided by the two versions of the AI assistant. Preliminary results indicate that passive personalization helps reduce task load and improve assistant perception, but reveal task-specific limitations that can be addressed through providing more user agency. These findings underscore the importance of combining active and passive personalization to optimize user experience and effectiveness in enterprise task-oriented environments.",
        "url": "http://arxiv.org/abs/2511.23376v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23376v1",
        "arxiv_id": "2511.23376v1",
        "authors": [
            "Li Siyan",
            "Jason Zhang",
            "Akash Maharaj",
            "Yuanming Shi",
            "Yunyao Li"
        ],
        "submitted": "2025-11-28 17:21:41",
        "source": "arxiv",
        "comment": "Accepted into Tailoring AI: Exploring Active and Passive LLM Personalization (PALS) workshop at EMNLP 2025",
        "score": 1,
        "keyword_reasons": [
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on user behavior modeling, the context is focused on AI-assisted test-taking and expertise-based personalization, which is not a central match to your research themes."
    }
]