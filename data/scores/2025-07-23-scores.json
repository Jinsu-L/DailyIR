[
    {
        "title": "Advancing Risk and Quality Assurance: A RAG Chatbot for Improved Regulatory Compliance",
        "abstract": "Risk and Quality (R&Q) assurance in highly regulated industries requires\nconstant navigation of complex regulatory frameworks, with employees handling\nnumerous daily queries demanding accurate policy interpretation. Traditional\nmethods relying on specialized experts create operational bottlenecks and limit\nscalability. We present a novel Retrieval Augmented Generation (RAG) system\nleveraging Large Language Models (LLMs), hybrid search and relevance boosting\nto enhance R&Q query processing. Evaluated on 124 expert-annotated real-world\nqueries, our actively deployed system demonstrates substantial improvements\nover traditional RAG approaches. Additionally, we perform an extensive\nhyperparameter analysis to compare and evaluate multiple configuration setups,\ndelivering valuable insights to practitioners.",
        "url": "http://arxiv.org/abs/2507.16711v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16711v1",
        "arxiv_id": "2507.16711v1",
        "authors": [
            "Lars Hillebrand",
            "Armin Berger",
            "Daniel Uedelhoven",
            "David Berghaus",
            "Ulrich Warning",
            "Tim Dilmaghani",
            "Bernd Kliem",
            "Thomas Schmid",
            "Rüdiger Loitz",
            "Rafet Sifa"
        ],
        "submitted": "2025-07-22 15:46:44",
        "source": "arxiv",
        "comment": "Accepted and published at BigData 2024, 3 pages, 3 tables, 2 figures",
        "score": 16,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval augmented generation' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on Risk and Quality assurance in regulated industries, using a chatbot to improve regulatory compliance. While it mentions retrieval and relevance, the context is quite different from the user's interests in Information Retrieval and Search technologies, particularly in query understanding, ranking models, and user behavior modeling. The paper's emphasis on regulatory compliance and policy interpretation also doesn't align with the user's background in e-commerce or broader interests in NLP, data mining, and related topics."
    },
    {
        "title": "LLM-Enhanced Reranking for Complementary Product Recommendation",
        "abstract": "Complementary product recommendation, which aims to suggest items that are\nused together to enhance customer value, is a crucial yet challenging task in\ne-commerce. While existing graph neural network (GNN) approaches have made\nsignificant progress in capturing complex product relationships, they often\nstruggle with the accuracy-diversity tradeoff, particularly for long-tail\nitems. This paper introduces a model-agnostic approach that leverages Large\nLanguage Models (LLMs) to enhance the reranking of complementary product\nrecommendations. Unlike previous works that use LLMs primarily for data\npreprocessing and graph augmentation, our method applies LLM-based prompting\nstrategies directly to rerank candidate items retrieved from existing\nrecommendation models, eliminating the need for model retraining. Through\nextensive experiments on public datasets, we demonstrate that our approach\neffectively balances accuracy and diversity in complementary product\nrecommendations, with at least 50% lift in accuracy metrics and 2% lift in\ndiversity metrics on average for the top recommended items across datasets.",
        "url": "http://arxiv.org/abs/2507.16237v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16237v1",
        "arxiv_id": "2507.16237v1",
        "authors": [
            "Zekun Xu",
            "Yudi Zhang"
        ],
        "submitted": "2025-07-22 05:15:45",
        "source": "arxiv",
        "comment": null,
        "score": 12,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on complementary product recommendation, which is a specific application in e-commerce, and leverages Large Language Models (LLMs) for reranking. While it touches on aspects of search and ranking, the primary focus is on recommendation systems, which is not a central match with the user's interests in Information Retrieval and Search technologies. The paper's emphasis on LLMs and graph neural networks is also not directly related to the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications",
        "abstract": "Conventional Retrieval-Augmented Generation (RAG) systems enhance Large\nLanguage Models (LLMs) but often fall short on complex queries, delivering\nlimited, extractive answers and struggling with multiple targeted retrievals or\nnavigating intricate entity relationships. This is a critical gap in\nknowledge-intensive domains. We introduce INRAExplorer, an agentic RAG system\nfor exploring the scientific data of INRAE (France's National Research\nInstitute for Agriculture, Food and Environment). INRAExplorer employs an\nLLM-based agent with a multi-tool architecture to dynamically engage a rich\nknowledge base, through a comprehensive knowledge graph derived from open\naccess INRAE publications. This design empowers INRAExplorer to conduct\niterative, targeted queries, retrieve exhaustive datasets (e.g., all\npublications by an author), perform multi-hop reasoning, and deliver\nstructured, comprehensive answers. INRAExplorer serves as a concrete\nillustration of enhancing knowledge interaction in specialized fields.",
        "url": "http://arxiv.org/abs/2507.16507v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16507v1",
        "arxiv_id": "2507.16507v1",
        "authors": [
            "Jean Lelong",
            "Adnane Errazine",
            "Annabelle Blangero"
        ],
        "submitted": "2025-07-22 12:03:10",
        "source": "arxiv",
        "comment": "ECAI 2025 demo track, 4 pages",
        "score": 8,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper discusses Retrieval-Augmented Generation (RAG) systems, which is related to my interest in Information Retrieval. The use of knowledge graphs and multi-hop reasoning is also relevant to my focus on query understanding and ranking models. However, the specific application domain of agriculture and food environment is not directly aligned with my interests in e-commerce and general information retrieval."
    },
    {
        "title": "Enhancing patent retrieval using automated patent summarization",
        "abstract": "Effective query formulation is a key challenge in long-document Information\nRetrieval (IR). This challenge is particularly acute in domain-specific\ncontexts like patent retrieval, where documents are lengthy, linguistically\ncomplex, and encompass multiple interrelated technical topics. In this work, we\npresent the application of recent extractive and abstractive summarization\nmethods for generating concise, purpose-specific summaries of patent documents.\nWe further assess the utility of these automatically generated summaries as\nsurrogate queries across three benchmark patent datasets and compare their\nretrieval performance against conventional approaches that use entire patent\nsections. Experimental results show that summarization-based queries\nsignificantly improve prior-art retrieval effectiveness, highlighting their\npotential as an efficient alternative to traditional query formulation\ntechniques.",
        "url": "http://arxiv.org/abs/2507.16371v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16371v1",
        "arxiv_id": "2507.16371v1",
        "authors": [
            "Eleni Kamateri",
            "Renukswamy Chikkamath",
            "Michail Salampasis",
            "Linda Andersson",
            "Markus Endres"
        ],
        "submitted": "2025-07-22 09:14:44",
        "source": "arxiv",
        "comment": "This version was submitted and accepted for publication at the 6th\n  Workshop on Patent Text Mining and Semantic Technologies (PatentSemTech\n  2025), held in conjunction with SIGIR 2025. A revised and polished version,\n  incorporating reviewers' feedback, will follow",
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper is somewhat related to the user's interests in Information Retrieval (IR) and query understanding, as it explores the application of summarization methods for generating concise summaries of patent documents. However, the focus is on patent retrieval, which is a specific domain, and the paper does not directly address ranking models or user behavior modeling, which are key areas of interest for the user."
    },
    {
        "title": "Time to Split: Exploring Data Splitting Strategies for Offline Evaluation of Sequential Recommenders",
        "abstract": "Modern sequential recommender systems, ranging from lightweight\ntransformer-based variants to large language models, have become increasingly\nprominent in academia and industry due to their strong performance in the\nnext-item prediction task. Yet common evaluation protocols for sequential\nrecommendations remain insufficiently developed: they often fail to reflect the\ncorresponding recommendation task accurately, or are not aligned with\nreal-world scenarios.\n  Although the widely used leave-one-out split matches next-item prediction, it\npermits the overlap between training and test periods, which leads to temporal\nleakage and unrealistically long test horizon, limiting real-world relevance.\nGlobal temporal splitting addresses these issues by evaluating on distinct\nfuture periods. However, its applications to sequential recommendations remain\nloosely defined, particularly in terms of selecting target interactions and\nconstructing a validation subset that provides necessary consistency between\nvalidation and test metrics.\n  In this paper, we demonstrate that evaluation outcomes can vary significantly\nacross splitting strategies, influencing model rankings and practical\ndeployment decisions. To improve reproducibility in both academic and\nindustrial settings, we systematically compare different splitting strategies\nfor sequential recommendations across multiple datasets and established\nbaselines. Our findings show that prevalent splits, such as leave-one-out, may\nbe insufficiently aligned with more realistic evaluation strategies. Code:\nhttps://github.com/monkey0head/time-to-split",
        "url": "http://arxiv.org/abs/2507.16289v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16289v1",
        "arxiv_id": "2507.16289v1",
        "authors": [
            "Danil Gusak",
            "Anna Volodkevich",
            "Anton Klenitskiy",
            "Alexey Vasilev",
            "Evgeny Frolov"
        ],
        "submitted": "2025-07-22 07:20:52",
        "source": "arxiv",
        "comment": "Accepted for ACM RecSys 2025. Author's version. The final published\n  version will be available at the ACM Digital Library",
        "score": 8,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores data splitting strategies for offline evaluation of sequential recommenders, which is a related topic to information retrieval and search technologies. However, the focus is on recommender systems, which is not the primary area of interest. The paper's relevance is somewhat limited due to the lack of direct connection to query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Reinforce Lifelong Interaction Value of User-Author Pairs for Large-Scale Recommendation Systems",
        "abstract": "Recommendation systems (RS) help users find interested content and connect\nauthors with their target audience. Most research in RS tends to focus either\non predicting users' immediate feedback (like click-through rate) accurately or\nimproving users' long-term engagement. However, they ignore the influence for\nauthors and the lifelong interaction value (LIV) of user-author pairs, which is\nparticularly crucial for improving the prosperity of social community in\nshort-video platforms. Currently, reinforcement learning (RL) can optimize\nlong-term benefits and has been widely applied in RS. In this paper, we\nintroduce RL to Reinforce Lifelong Interaction Value of User-Author pairs\n(RLIV-UA) based on each interaction of UA pairs. To address the long intervals\nbetween UA interactions and the large scale of the UA space, we propose a novel\nSparse Cross-Request Interaction Markov Decision Process (SCRI-MDP) and\nintroduce an Adjacent State Approximation (ASA) method to construct RL training\nsamples. Additionally, we introduce Multi-Task Critic Learning (MTCL) to\ncapture the progressive nature of UA interactions (click -> follow -> gift),\nwhere denser interaction signals are leveraged to compensate for the learning\nof sparse labels. Finally, an auxiliary supervised learning task is designed to\nenhance the convergence of the RLIV-UA model. In offline experiments and online\nA/B tests, the RLIV-UA model achieves both higher user satisfaction and higher\nplatform profits than compared methods.",
        "url": "http://arxiv.org/abs/2507.16253v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16253v1",
        "arxiv_id": "2507.16253v1",
        "authors": [
            "Yisha Li",
            "Lexi Gao",
            "Jingxin Liu",
            "Xiang Gao",
            "Xin Li",
            "Haiyang Lu",
            "Liyin Hong"
        ],
        "submitted": "2025-07-22 05:58:55",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'click' (score: +2)",
            "Found 'click-through rate' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on recommendation systems, which is related to information retrieval, but the emphasis is on long-term engagement and user-author pairs, which is not directly aligned with my interests in query understanding, ranking models, and user behavior modeling. While the paper mentions reinforcement learning, it is not specifically applied to search technologies or query understanding."
    },
    {
        "title": "Language Detection by Means of the Minkowski Norm: Identification Through Character Bigrams and Frequency Analysis",
        "abstract": "The debate surrounding language identification has gained renewed attention\nin recent years, especially with the rapid evolution of AI-powered language\nmodels. However, the non-AI-based approaches to language identification have\nbeen overshadowed. This research explores a mathematical implementation of an\nalgorithm for language determinism by leveraging monograms and bigrams\nfrequency rankings derived from established linguistic research. The datasets\nused comprise texts varying in length, historical period, and genre, including\nshort stories, fairy tales, and poems. Despite these variations, the method\nachieves over 80\\% accuracy on texts shorter than 150 characters and reaches\n100\\% accuracy for longer texts. These results demonstrate that classical\nfrequency-based approaches remain effective and scalable alternatives to\nAI-driven models for language detection.",
        "url": "http://arxiv.org/abs/2507.16284v2",
        "pdf_url": "http://arxiv.org/pdf/2507.16284v2",
        "arxiv_id": "2507.16284v2",
        "authors": [
            "Paul-Andrei Pogăcean",
            "Sanda-Maria Avram"
        ],
        "submitted": "2025-07-22 07:11:01",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on language detection using frequency analysis, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on natural language processing, the scope is limited to language detection and does not explore ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest."
    },
    {
        "title": "mRAKL: Multilingual Retrieval-Augmented Knowledge Graph Construction for Low-Resourced Languages",
        "abstract": "Knowledge Graphs represent real-world entities and the relationships between\nthem. Multilingual Knowledge Graph Construction (mKGC) refers to the task of\nautomatically constructing or predicting missing entities and links for\nknowledge graphs in a multilingual setting. In this work, we reformulate the\nmKGC task as a Question Answering (QA) task and introduce mRAKL: a\nRetrieval-Augmented Generation (RAG) based system to perform mKGC. We achieve\nthis by using the head entity and linking relation in a question, and having\nour model predict the tail entity as an answer. Our experiments focus primarily\non two low-resourced languages: Tigrinya and Amharic. We experiment with using\nhigher-resourced languages Arabic and English for cross-lingual transfer. With\na BM25 retriever, we find that the RAG-based approach improves performance over\na no-context setting. Further, our ablation studies show that with an idealized\nretrieval system, mRAKL improves accuracy by 4.92 and 8.79 percentage points\nfor Tigrinya and Amharic, respectively.",
        "url": "http://arxiv.org/abs/2507.16011v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16011v1",
        "arxiv_id": "2507.16011v1",
        "authors": [
            "Hellina Hailu Nigatu",
            "Min Li",
            "Maartje ter Hoeve",
            "Saloni Potdar",
            "Sarah Chasins"
        ],
        "submitted": "2025-07-21 19:11:31",
        "source": "arxiv",
        "comment": "Accepted to Findings of ACL 2025",
        "score": 7,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on multilingual knowledge graph construction, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and query understanding. While the paper mentions retrieval, it is not in the context of query understanding or ranking models. The user's background in e-commerce is also not directly applicable to this paper."
    },
    {
        "title": "RAVine: Reality-Aligned Evaluation for Agentic Search",
        "abstract": "Agentic search, as a more autonomous and adaptive paradigm of retrieval\naugmentation, is driving the evolution of intelligent search systems. However,\nexisting evaluation frameworks fail to align well with the goals of agentic\nsearch. First, the complex queries commonly used in current benchmarks often\ndeviate from realistic user search scenarios. Second, prior approaches tend to\nintroduce noise when extracting ground truth for end-to-end evaluations,\nleading to distorted assessments at a fine-grained level. Third, most current\nframeworks focus solely on the quality of final answers, neglecting the\nevaluation of the iterative process inherent to agentic search. To address\nthese limitations, we propose RAVine -- a Reality-Aligned eValuation framework\nfor agentic LLMs with search. RAVine targets multi-point queries and long-form\nanswers that better reflect user intents, and introduces an attributable ground\ntruth construction strategy to enhance the accuracy of fine-grained evaluation.\nMoreover, RAVine examines model's interaction with search tools throughout the\niterative process, and accounts for factors of efficiency. We benchmark a\nseries of models using RAVine and derive several insights, which we hope will\ncontribute to advancing the development of agentic search systems. The code and\ndatasets are available at https://github.com/SwordFaith/RAVine.",
        "url": "http://arxiv.org/abs/2507.16725v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16725v1",
        "arxiv_id": "2507.16725v1",
        "authors": [
            "Yilong Xu",
            "Xiang Long",
            "Zhi Zheng",
            "Jinhua Gao"
        ],
        "submitted": "2025-07-22 16:08:12",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper proposes a new evaluation framework for agentic search, which is a relevant topic in Information Retrieval. The framework addresses limitations in existing evaluation methods, such as noisy ground truth and focus on final answers. While the paper does not specifically focus on query understanding, ranking models, or user behavior modeling, it contributes to the development of intelligent search systems, which aligns with the user's broader interests in IR and NLP."
    },
    {
        "title": "Step-Audio 2 Technical Report",
        "abstract": "This paper presents Step-Audio~2, an end-to-end multi-modal large language\nmodel designed for industry-strength audio understanding and speech\nconversation. By integrating a latent audio encoder and reasoning-centric\nreinforcement learning (RL), Step-Audio 2 achieves promising performance in\nautomatic speech recognition (ASR) and audio understanding. To facilitate\ngenuine end-to-end speech conversation, Step-Audio 2 incorporates the\ngeneration of discrete audio tokens into language modeling, significantly\nenhancing its responsiveness to paralinguistic information such as speaking\nstyles and emotions. To effectively leverage the rich textual and acoustic\nknowledge in real-world data, Step-Audio 2 integrates retrieval-augmented\ngeneration (RAG) and is able to call external tools such as web search to\nmitigate hallucination and audio search to switch timbres. Trained on millions\nof hours of speech and audio data, Step-Audio 2 delivers intelligence and\nexpressiveness across diverse conversational scenarios. Evaluation results\ndemonstrate that Step-Audio 2 achieves state-of-the-art performance on various\naudio understanding and conversational benchmarks compared to other open-source\nand commercial solutions. Please visit\nhttps://github.com/stepfun-ai/Step-Audio2 for more information.",
        "url": "http://arxiv.org/abs/2507.16632v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16632v1",
        "arxiv_id": "2507.16632v1",
        "authors": [
            "Boyong Wu",
            "Chao Yan",
            "Chen Hu",
            "Cheng Yi",
            "Chengli Feng",
            "Fei Tian",
            "Feiyu Shen",
            "Gang Yu",
            "Haoyang Zhang",
            "Jingbei Li",
            "Mingrui Chen",
            "Peng Liu",
            "Wang You",
            "Xiangyu Tony Zhang",
            "Xingyuan Li",
            "Xuerui Yang",
            "Yayue Deng",
            "Yechang Huang",
            "Yuxin Li",
            "Yuxin Zhang",
            "Zhao You",
            "Brian Li",
            "Changyi Wan",
            "Hanpeng Hu",
            "Jiangjie Zhen",
            "Siyu Chen",
            "Song Yuan",
            "Xuelin Zhang",
            "Yimin Jiang",
            "Yu Zhou",
            "Yuxiang Yang",
            "Bingxin Li",
            "Buyun Ma",
            "Changhe Song",
            "Dongqing Pang",
            "Guoqiang Hu",
            "Haiyang Sun",
            "Kang An",
            "Na Wang",
            "Shuli Gao",
            "Wei Ji",
            "Wen Li",
            "Wen Sun",
            "Xuan Wen",
            "Yong Ren",
            "Yuankai Ma",
            "Yufan Lu",
            "Bin Wang",
            "Bo Li",
            "Changxin Miao",
            "Che Liu",
            "Chen Xu",
            "Dapeng Shi",
            "Dingyuan Hu",
            "Donghang Wu",
            "Enle Liu",
            "Guanzhe Huang",
            "Gulin Yan",
            "Han Zhang",
            "Hao Nie",
            "Haonan Jia",
            "Hongyu Zhou",
            "Jianjian Sun",
            "Jiaoren Wu",
            "Jie Wu",
            "Jie Yang",
            "Jin Yang",
            "Junzhe Lin",
            "Kaixiang Li",
            "Lei Yang",
            "Liying Shi",
            "Li Zhou",
            "Longlong Gu",
            "Ming Li",
            "Mingliang Li",
            "Mingxiao Li",
            "Nan Wu",
            "Qi Han",
            "Qinyuan Tan",
            "Shaoliang Pang",
            "Shengjie Fan",
            "Siqi Liu",
            "Tiancheng Cao",
            "Wanying Lu",
            "Wenqing He",
            "Wuxun Xie",
            "Xu Zhao",
            "Xueqi Li",
            "Yanbo Yu",
            "Yang Yang",
            "Yi Liu",
            "Yifan Lu",
            "Yilei Wang",
            "Yuanhao Ding",
            "Yuanwei Liang",
            "Yuanwei Lu",
            "Yuchu Luo",
            "Yuhe Yin",
            "Yumeng Zhan",
            "Yuxiang Zhang",
            "Zidong Yang",
            "Zixin Zhang",
            "Binxing Jiao",
            "Daxin Jiang",
            "Heung-Yeung Shum",
            "Jiansheng Chen",
            "Jing Li",
            "Xiangyu Zhang",
            "Yibo Zhu"
        ],
        "submitted": "2025-07-22 14:23:55",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'web search' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on audio understanding and speech conversation, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions retrieval-augmented generation, the context is different from the user's interests in IR and NLP."
    },
    {
        "title": "Beyond Context Limits: Subconscious Threads for Long-Horizon Reasoning",
        "abstract": "To break the context limits of large language models (LLMs) that bottleneck\nreasoning accuracy and efficiency, we propose the Thread Inference Model (TIM),\na family of LLMs trained for recursive and decompositional problem solving, and\nTIMRUN, an inference runtime enabling long-horizon structured reasoning beyond\ncontext limits. Together, TIM hosted on TIMRUN supports virtually unlimited\nworking memory and multi-hop tool calls within a single language model\ninference, overcoming output limits, positional-embedding constraints, and\nGPU-memory bottlenecks. Performance is achieved by modeling natural language as\nreasoning trees measured by both length and depth instead of linear sequences.\nThe reasoning trees consist of tasks with thoughts, recursive subtasks, and\nconclusions based on the concept we proposed in Schroeder et al, 2025. During\ngeneration, we maintain a working memory that retains only the key-value states\nof the most relevant context tokens, selected by a rule-based subtask-pruning\nmechanism, enabling reuse of positional embeddings and GPU memory pages\nthroughout reasoning. Experimental results show that our system sustains high\ninference throughput, even when manipulating up to 90% of the KV cache in GPU\nmemory. It also delivers accurate reasoning on mathematical tasks and handles\ninformation retrieval challenges that require long-horizon reasoning and\nmulti-hop tool use.",
        "url": "http://arxiv.org/abs/2507.16784v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16784v1",
        "arxiv_id": "2507.16784v1",
        "authors": [
            "Hongyin Luo",
            "Nathaniel Morgan",
            "Tina Li",
            "Derek Zhao",
            "Ai Vy Ngo",
            "Philip Schroeder",
            "Lijie Yang",
            "Assaf Ben-Kish",
            "Jack O'Brien",
            "James Glass"
        ],
        "submitted": "2025-07-22 17:30:04",
        "source": "arxiv",
        "comment": "Research preview",
        "score": 5,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a new language model architecture for long-horizon reasoning, which is somewhat related to information retrieval and search technologies. However, the focus is on large language models and reasoning trees, which is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is limited to the information retrieval challenges that require long-horizon reasoning and multi-hop tool use, but the connection is not strong enough to warrant a higher score."
    },
    {
        "title": "Beyond Isolated Dots: Benchmarking Structured Table Construction as Deep Knowledge Extraction",
        "abstract": "With the emergence of large language models (LLMs), there is an expectation\nthat LLMs can effectively extract explicit information from complex real-world\ndocuments (e.g., papers, reports). However, most LLMs generate paragraph-style\nanswers that are chaotic, disorganized, and untraceable. To bridge this gap, we\nintroduce the Arranged and Organized Extraction Benchmark (AOE), a new\nbilingual benchmark with data and documents of varying lengths designed to\nsystematically evaluate the ability of LLMs to comprehend fragmented documents\nand reconstruct isolated information into one organized table. Unlike\nconventional text-to-table tasks, which rely on fixed schema and narrow task\ndomains, AOE includes 11 carefully crafted tasks across three diverse domains,\nrequiring models to generate context-specific schema tailored to varied input\nqueries. In the experiment, we evaluated both open-source and closed-source\nstate-of-the-art LLMs. The results show that even the most advanced models\nstruggled significantly. The benchmark is available at\nhttps://huggingface.co/datasets/tianyumyum/AOE.",
        "url": "http://arxiv.org/abs/2507.16271v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16271v1",
        "arxiv_id": "2507.16271v1",
        "authors": [
            "Tianyun Zhong",
            "Guozhao Mo",
            "Yanjiang Liu",
            "Yihan Chen",
            "Lingdi Kong",
            "Xuanang Chen",
            "Yaojie Lu",
            "Hongyu Lin",
            "Ben He",
            "Le Sun"
        ],
        "submitted": "2025-07-22 06:37:51",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on evaluating the ability of language models to extract information from complex documents and reconstruct it into organized tables, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on the topic of deep semantic understanding, it is not primarily focused on real-time relevance optimization or user behavior modeling."
    },
    {
        "title": "Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory",
        "abstract": "Vision-language models (VLMs) have been widely adopted in robotics to enable\nautonomous planning. However, grounding VLMs, originally trained on internet\ndata, to diverse real-world robots remains a challenge. This paper presents\nExpTeach, a framework that grounds VLMs to physical robots by building a\nself-generated memory of real-world experiences. In ExpTeach, the VLM\nautonomously plans actions, verifies outcomes, reflects on failures, and adapts\nrobot behaviors in a closed loop. The self-generated experiences during this\nprocess are then summarized into a long-term memory, enabling retrieval of\nlearned knowledge to guide future tasks via retrieval-augmented generation\n(RAG). Additionally, ExpTeach enhances the spatial understanding of VLMs with\nan on-demand image annotation module. In experiments, we show that reflection\nimproves success rates from 36% to 84% on four challenging robotic tasks and\nobserve the emergence of intelligent object interactions, including creative\ntool use. Across extensive tests on 12 real-world scenarios (including eight\nunseen ones), we find that grounding with long-term memory boosts single-trial\nsuccess rates from 22% to 80%, demonstrating the effectiveness and\ngeneralizability of ExpTeach.",
        "url": "http://arxiv.org/abs/2507.16713v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16713v1",
        "arxiv_id": "2507.16713v1",
        "authors": [
            "Guowei Lan",
            "Kaixian Qu",
            "René Zurbrügg",
            "Changan Chen",
            "Christopher E. Mower",
            "Haitham Bou-Ammar",
            "Marco Hutter"
        ],
        "submitted": "2025-07-22 15:48:49",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on grounding vision-language models for robotics, which is not directly related to information retrieval, search technologies, or query understanding. While it involves machine learning and data processing, the context and applications are quite different from the user's primary research interests."
    },
    {
        "title": "EBaReT: Expert-guided Bag Reward Transformer for Auto Bidding",
        "abstract": "Reinforcement learning has been widely applied in automated bidding.\nTraditional approaches model bidding as a Markov Decision Process (MDP).\nRecently, some studies have explored using generative reinforcement learning\nmethods to address long-term dependency issues in bidding environments.\nAlthough effective, these methods typically rely on supervised learning\napproaches, which are vulnerable to low data quality due to the amount of\nsub-optimal bids and low probability rewards resulting from the low click and\nconversion rates. Unfortunately, few studies have addressed these challenges.\n  In this paper, we formalize the automated bidding as a sequence\ndecision-making problem and propose a novel Expert-guided Bag Reward\nTransformer (EBaReT) to address concerns related to data quality and\nuncertainty rewards. Specifically, to tackle data quality issues, we generate a\nset of expert trajectories to serve as supplementary data in the training\nprocess and employ a Positive-Unlabeled (PU) learning-based discriminator to\nidentify expert transitions. To ensure the decision also meets the expert\nlevel, we further design a novel expert-guided inference strategy. Moreover, to\nmitigate the uncertainty of rewards, we consider the transitions within a\ncertain period as a \"bag\" and carefully design a reward function that leads to\na smoother acquisition of rewards. Extensive experiments demonstrate that our\nmodel achieves superior performance compared to state-of-the-art bidding\nmethods.",
        "url": "http://arxiv.org/abs/2507.16186v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16186v1",
        "arxiv_id": "2507.16186v1",
        "authors": [
            "Kaiyuan Li",
            "Pengyu Wang",
            "Yunshan Peng",
            "Pengjia Yuan",
            "Yanxiang Zeng",
            "Rui Xiang",
            "Yanhua Cheng",
            "Xialong Liu",
            "Peng Jiang"
        ],
        "submitted": "2025-07-22 02:56:36",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'click' (score: +2)",
            "Found 'conversion rate' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on automated bidding, which is not directly related to information retrieval, search technologies, or query understanding. Although it mentions reinforcement learning, the context is different from the user's interests in ranking models and user behavior modeling."
    },
    {
        "title": "MegaScience: Pushing the Frontiers of Post-Training Datasets for Science Reasoning",
        "abstract": "Scientific reasoning is critical for developing AI scientists and supporting\nhuman researchers in advancing the frontiers of natural science discovery.\nHowever, the open-source community has primarily focused on mathematics and\ncoding while neglecting the scientific domain, largely due to the absence of\nopen, large-scale, high-quality, verifiable scientific reasoning datasets. To\nbridge this gap, we first present TextbookReasoning, an open dataset featuring\ntruthful reference answers extracted from 12k university-level scientific\ntextbooks, comprising 650k reasoning questions spanning 7 scientific\ndisciplines. We further introduce MegaScience, a large-scale mixture of\nhigh-quality open-source datasets totaling 1.25 million instances, developed\nthrough systematic ablation studies that evaluate various data selection\nmethodologies to identify the optimal subset for each publicly available\nscientific dataset. Meanwhile, we build a comprehensive evaluation system\ncovering diverse subjects and question types across 15 benchmarks,\nincorporating comprehensive answer extraction strategies to ensure accurate\nevaluation metrics. Our experiments demonstrate that our datasets achieve\nsuperior performance and training efficiency with more concise response lengths\ncompared to existing open-source scientific datasets. Furthermore, we train\nLlama3.1, Qwen2.5, and Qwen3 series base models on MegaScience, which\nsignificantly outperform the corresponding official instruct models in average\nperformance. In addition, MegaScience exhibits greater effectiveness for larger\nand stronger models, suggesting a scaling benefit for scientific tuning. We\nrelease our data curation pipeline, evaluation system, datasets, and seven\ntrained models to the community to advance scientific reasoning research.",
        "url": "http://arxiv.org/abs/2507.16812v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16812v1",
        "arxiv_id": "2507.16812v1",
        "authors": [
            "Run-Ze Fan",
            "Zengzhi Wang",
            "Pengfei Liu"
        ],
        "submitted": "2025-07-22 17:59:03",
        "source": "arxiv",
        "comment": "39 pages; Github: https://github.com/GAIR-NLP/MegaScience; HF:\n  https://huggingface.co/MegaScience",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on creating large-scale datasets for scientific reasoning, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions training models, it does not specifically address query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's interests."
    },
    {
        "title": "Interpretable Topic Extraction and Word Embedding Learning using row-stochastic DEDICOM",
        "abstract": "The DEDICOM algorithm provides a uniquely interpretable matrix factorization\nmethod for symmetric and asymmetric square matrices. We employ a new\nrow-stochastic variation of DEDICOM on the pointwise mutual information\nmatrices of text corpora to identify latent topic clusters within the\nvocabulary and simultaneously learn interpretable word embeddings. We introduce\na method to efficiently train a constrained DEDICOM algorithm and a qualitative\nevaluation of its topic modeling and word embedding performance.",
        "url": "http://arxiv.org/abs/2507.16695v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16695v1",
        "arxiv_id": "2507.16695v1",
        "authors": [
            "Lars Hillebrand",
            "David Biesner",
            "Christian Bauckhage",
            "Rafet Sifa"
        ],
        "submitted": "2025-07-22 15:30:32",
        "source": "arxiv",
        "comment": "Accepted and published at CD-MAKE 2020, 20 pages, 8 tables, 8 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'pointwise' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on matrix factorization and topic modeling, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions word embeddings, the context is not related to ranking models or user behavior modeling, and the paper does not seem to address real-time relevance optimization or deep semantic understanding."
    },
    {
        "title": "Generating Search Explanations using Large Language Models",
        "abstract": "Aspect-oriented explanations in search results are typically concise text\nsnippets placed alongside retrieved documents to serve as explanations that\nassist users in efficiently locating relevant information. While Large Language\nModels (LLMs) have demonstrated exceptional performance for a range of\nproblems, their potential to generate explanations for search results has not\nbeen explored. This study addresses that gap by leveraging both encoder-decoder\nand decoder-only LLMs to generate explanations for search results. The\nexplanations generated are consistently more accurate and plausible\nexplanations than those produced by a range of baseline models.",
        "url": "http://arxiv.org/abs/2507.16692v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16692v1",
        "arxiv_id": "2507.16692v1",
        "authors": [
            "Arif Laksito",
            "Mark Stevenson"
        ],
        "submitted": "2025-07-22 15:29:39",
        "source": "arxiv",
        "comment": "Extended Abstract - Workshop on Explainability in Information\n  Retrieval (WExIR), SIGIR 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper explores the application of Large Language Models (LLMs) in generating search explanations, which aligns with the user's interest in Information Retrieval and Search technologies. The focus on query understanding and ranking models is not directly addressed, but the study's emphasis on generating accurate and plausible explanations resonates with the user's interest in user behavior modeling and click models. While the paper's scope is not exclusively focused on the user's core research themes, it does contribute to the broader field of IR and NLP."
    },
    {
        "title": "Towards Automated Regulatory Compliance Verification in Financial Auditing with Large Language Models",
        "abstract": "The auditing of financial documents, historically a labor-intensive process,\nstands on the precipice of transformation. AI-driven solutions have made\ninroads into streamlining this process by recommending pertinent text passages\nfrom financial reports to align with the legal requirements of accounting\nstandards. However, a glaring limitation remains: these systems commonly fall\nshort in verifying if the recommended excerpts indeed comply with the specific\nlegal mandates. Hence, in this paper, we probe the efficiency of publicly\navailable Large Language Models (LLMs) in the realm of regulatory compliance\nacross different model configurations. We place particular emphasis on\ncomparing cutting-edge open-source LLMs, such as Llama-2, with their\nproprietary counterparts like OpenAI's GPT models. This comparative analysis\nleverages two custom datasets provided by our partner PricewaterhouseCoopers\n(PwC) Germany. We find that the open-source Llama-2 70 billion model\ndemonstrates outstanding performance in detecting non-compliance or true\nnegative occurrences, beating all their proprietary counterparts. Nevertheless,\nproprietary models such as GPT-4 perform the best in a broad variety of\nscenarios, particularly in non-English contexts.",
        "url": "http://arxiv.org/abs/2507.16642v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16642v1",
        "arxiv_id": "2507.16642v1",
        "authors": [
            "Armin Berger",
            "Lars Hillebrand",
            "David Leonhard",
            "Tobias Deußer",
            "Thiago Bell Felix de Oliveira",
            "Tim Dilmaghani",
            "Mohamed Khaled",
            "Bernd Kliem",
            "Rüdiger Loitz",
            "Christian Bauckhage",
            "Rafet Sifa"
        ],
        "submitted": "2025-07-22 14:39:54",
        "source": "arxiv",
        "comment": "Accepted and published at BigData 2023, 10 pages, 3 figures, 5 tables",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on applying Large Language Models to regulatory compliance verification in financial auditing, which is not directly related to the user's interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper does involve NLP, the context and application are quite different from the user's primary focus."
    },
    {
        "title": "WhatsApp Tiplines and Multilingual Claims in the 2021 Indian Assembly Elections",
        "abstract": "WhatsApp tiplines, first launched in 2019 to combat misinformation, enable\nusers to interact with fact-checkers to verify misleading content. This study\nanalyzes 580 unique claims (tips) from 451 users, covering both high-resource\nlanguages (English, Hindi) and a low-resource language (Telugu) during the 2021\nIndian assembly elections using a mixed-method approach. We categorize the\nclaims into three categories, election, COVID-19, and others, and observe\nvariations across languages. We compare content similarity through frequent\nword analysis and clustering of neural sentence embeddings. We also investigate\nuser overlap across languages and fact-checking organizations. We measure the\naverage time required to debunk claims and inform tipline users. Results reveal\nsimilarities in claims across languages, with some users submitting tips in\nmultiple languages to the same fact-checkers. Fact-checkers generally require a\ncouple of days to debunk a new claim and share the results with users. Notably,\nno user submits claims to multiple fact-checking organizations, indicating that\neach organization maintains a unique audience. We provide practical\nrecommendations for using tiplines during elections with ethical consideration\nof users' information.",
        "url": "http://arxiv.org/abs/2507.16298v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16298v1",
        "arxiv_id": "2507.16298v1",
        "authors": [
            "Gautam Kishore Shahi",
            "Scot A. Hale"
        ],
        "submitted": "2025-07-22 07:35:42",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on WhatsApp tiplines and fact-checking during the 2021 Indian assembly elections, which is unrelated to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's methodology and findings are specific to the Indian election context and do not contribute to the user's areas of focus."
    },
    {
        "title": "Deep Researcher with Test-Time Diffusion",
        "abstract": "Deep research agents, powered by Large Language Models (LLMs), are rapidly\nadvancing; yet, their performance often plateaus when generating complex,\nlong-form research reports using generic test-time scaling algorithms. Drawing\ninspiration from the iterative nature of human research, which involves cycles\nof searching, reasoning, and revision, we propose the Test-Time Diffusion Deep\nResearcher (TTD-DR). This novel framework conceptualizes research report\ngeneration as a diffusion process. TTD-DR initiates this process with a\npreliminary draft, an updatable skeleton that serves as an evolving foundation\nto guide the research direction. The draft is then iteratively refined through\na \"denoising\" process, which is dynamically informed by a retrieval mechanism\nthat incorporates external information at each step. The core process is\nfurther enhanced by a self-evolutionary algorithm applied to each component of\nthe agentic workflow, ensuring the generation of high-quality context for the\ndiffusion process. This draft-centric design makes the report writing process\nmore timely and coherent while reducing information loss during the iterative\nsearch process. We demonstrate that our TTD-DR achieves state-of-the-art\nresults on a wide array of benchmarks that require intensive search and\nmulti-hop reasoning, significantly outperforming existing deep research agents.",
        "url": "http://arxiv.org/abs/2507.16075v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16075v1",
        "arxiv_id": "2507.16075v1",
        "authors": [
            "Rujun Han",
            "Yanfei Chen",
            "Zoey CuiZhu",
            "Lesly Miculicich",
            "Guan Sun",
            "Yuanjun Bi",
            "Weiming Wen",
            "Hui Wan",
            "Chunfeng Wen",
            "Solène Maître",
            "George Lee",
            "Vishy Tirumalashetty",
            "Emily Xue",
            "Zizhao Zhang",
            "Salem Haykal",
            "Burak Gokturk",
            "Tomas Pfister",
            "Chen-Yu Lee"
        ],
        "submitted": "2025-07-21 21:23:21",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a novel framework for research report generation, leveraging Large Language Models and a diffusion process. While it touches on search and retrieval mechanisms, the focus is on report generation rather than information retrieval or ranking models. The paper's relevance to the user's interests is limited, but it may be of interest to those exploring NLP and data mining applications."
    },
    {
        "title": "LingBench++: A Linguistically-Informed Benchmark and Reasoning Framework for Multi-Step and Cross-Cultural Inference with LLMs",
        "abstract": "We propose LingBench++, a linguistically-informed benchmark and reasoning\nframework designed to evaluate large language models (LLMs) on complex\nlinguistic tasks inspired by the International Linguistics Olympiad (IOL).\nUnlike prior benchmarks that focus solely on final answer accuracy, LingBench++\nprovides structured reasoning traces, stepwise evaluation protocols, and rich\ntypological metadata across over 90 low-resource and cross-cultural languages.\nWe further develop a multi-agent architecture integrating grammatical knowledge\nretrieval, tool-augmented reasoning, and deliberate hypothesis testing. Through\nsystematic comparisons of baseline and our proposed agentic models, we\ndemonstrate that models equipped with external knowledge sources and iterative\nreasoning outperform single-pass approaches in both accuracy and\ninterpretability. LingBench++ offers a comprehensive foundation for advancing\nlinguistically grounded, culturally informed, and cognitively plausible\nreasoning in LLMs.",
        "url": "http://arxiv.org/abs/2507.16809v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16809v1",
        "arxiv_id": "2507.16809v1",
        "authors": [
            "Da-Chen Lian",
            "Ri-Sheng Huang",
            "Pin-Er Chen",
            "Chunki Lim",
            "You-Kuan Lin",
            "Guan-Yu Tseng",
            "Zi-Cheng Yang",
            "Shu-Kai Hsieh"
        ],
        "submitted": "2025-07-22 17:57:44",
        "source": "arxiv",
        "comment": "41 pages, 17 figures, 10 tables",
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on evaluating large language models on complex linguistic tasks, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions reasoning and inference, the context is more focused on linguistic tasks rather than user behavior modeling or ranking models. The paper's relevance to NLP and data mining is higher, but it does not specifically address the user's interests in real-time relevance optimization or deep semantic understanding."
    },
    {
        "title": "Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty",
        "abstract": "When language models (LMs) are trained via reinforcement learning (RL) to\ngenerate natural language \"reasoning chains\", their performance improves on a\nvariety of difficult question answering tasks. Today, almost all successful\napplications of RL for reasoning use binary reward functions that evaluate the\ncorrectness of LM outputs. Because such reward functions do not penalize\nguessing or low-confidence outputs, they often have the unintended side-effect\nof degrading calibration and increasing the rate at which LMs generate\nincorrect responses (or \"hallucinate\") in other problem domains. This paper\ndescribes RLCR (Reinforcement Learning with Calibration Rewards), an approach\nto training reasoning models that jointly improves accuracy and calibrated\nconfidence estimation. During RLCR, LMs generate both predictions and numerical\nconfidence estimates after reasoning. They are trained to optimize a reward\nfunction that augments a binary correctness score with a Brier score -- a\nscoring rule for confidence estimates that incentivizes calibrated prediction.\nWe first prove that this reward function (or any analogous reward function that\nuses a bounded, proper scoring rule) yields models whose predictions are both\naccurate and well-calibrated. We next show that across diverse datasets, RLCR\nsubstantially improves calibration with no loss in accuracy, on both in-domain\nand out-of-domain evaluations -- outperforming both ordinary RL training and\nclassifiers trained to assign post-hoc confidence scores. While ordinary RL\nhurts calibration, RLCR improves it. Finally, we demonstrate that verbalized\nconfidence can be leveraged at test time to improve accuracy and calibration\nvia confidence-weighted scaling methods. Our results show that explicitly\noptimizing for calibration can produce more generally reliable reasoning\nmodels.",
        "url": "http://arxiv.org/abs/2507.16806v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16806v1",
        "arxiv_id": "2507.16806v1",
        "authors": [
            "Mehul Damani",
            "Isha Puri",
            "Stewart Slocum",
            "Idan Shenfeld",
            "Leshem Choshen",
            "Yoon Kim",
            "Jacob Andreas"
        ],
        "submitted": "2025-07-22 17:56:01",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on training language models to reason about their uncertainty, which is related to query understanding and ranking models in Information Retrieval. However, the paper's primary focus is on Natural Language Processing and reinforcement learning, which is not directly aligned with the user's interests in Search technologies and user behavior modeling."
    },
    {
        "title": "Steering Out-of-Distribution Generalization with Concept Ablation Fine-Tuning",
        "abstract": "Fine-tuning large language models (LLMs) can lead to unintended\nout-of-distribution generalization. Standard approaches to this problem rely on\nmodifying training data, for example by adding data that better specify the\nintended generalization. However, this is not always practical. We introduce\nConcept Ablation Fine-Tuning (CAFT), a technique that leverages\ninterpretability tools to control how LLMs generalize from fine-tuning, without\nneeding to modify the training data or otherwise use data from the target\ndistribution. Given a set of directions in an LLM's latent space corresponding\nto undesired concepts, CAFT works by ablating these concepts with linear\nprojections during fine-tuning, steering the model away from unintended\ngeneralizations. We successfully apply CAFT to three fine-tuning tasks,\nincluding emergent misalignment, a phenomenon where LLMs fine-tuned on a narrow\ntask generalize to give egregiously misaligned responses to general questions.\nWithout any changes to the fine-tuning data, CAFT reduces misaligned responses\nby 10x without degrading performance on the training distribution. Overall,\nCAFT represents a novel approach for steering LLM generalization without\nmodifying training data.",
        "url": "http://arxiv.org/abs/2507.16795v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16795v1",
        "arxiv_id": "2507.16795v1",
        "authors": [
            "Helena Casademunt",
            "Caden Juang",
            "Adam Karvonen",
            "Samuel Marks",
            "Senthooran Rajamanoharan",
            "Neel Nanda"
        ],
        "submitted": "2025-07-22 17:45:04",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses fine-tuning large language models, which is related to my interests in Natural Language Processing. However, the focus on controlling out-of-distribution generalization and concept ablation fine-tuning is not directly aligned with my primary research themes in Information Retrieval, query understanding, and ranking models."
    },
    {
        "title": "Biases in LLM-Generated Musical Taste Profiles for Recommendation",
        "abstract": "One particularly promising use case of Large Language Models (LLMs) for\nrecommendation is the automatic generation of Natural Language (NL) user taste\nprofiles from consumption data. These profiles offer interpretable and editable\nalternatives to opaque collaborative filtering representations, enabling\ngreater transparency and user control. However, it remains unclear whether\nusers consider these profiles to be an accurate representation of their taste,\nwhich is crucial for trust and usability. Moreover, because LLMs inherit\nsocietal and data-driven biases, profile quality may systematically vary across\nuser and item characteristics. In this paper, we study this issue in the\ncontext of music streaming, where personalization is challenged by a large and\nculturally diverse catalog. We conduct a user study in which participants rate\nNL profiles generated from their own listening histories. We analyze whether\nidentification with the profiles is biased by user attributes (e.g.,\nmainstreamness, taste diversity) and item features (e.g., genre, country of\norigin). We also compare these patterns to those observed when using the\nprofiles in a downstream recommendation task. Our findings highlight both the\npotential and limitations of scrutable, LLM-based profiling in personalized\nsystems.",
        "url": "http://arxiv.org/abs/2507.16708v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16708v1",
        "arxiv_id": "2507.16708v1",
        "authors": [
            "Bruno Sguerra",
            "Elena V. Epure",
            "Harin Lee",
            "Manuel Moussallam"
        ],
        "submitted": "2025-07-22 15:44:10",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the use of Large Language Models (LLMs) for generating user taste profiles, which is related to information retrieval and search technologies. However, the focus on music streaming and recommendation systems is not directly aligned with the user's primary research interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is somewhat limited to the user's background in e-commerce and interest in recommender systems, but it does not address the user's core research themes."
    },
    {
        "title": "Self-Contradiction as Self-Improvement: Mitigating the Generation-Understanding Gap in MLLMs",
        "abstract": "Despite efforts to unify multimodal generation and understanding tasks in a\nsingle model, we show these MLLMs exhibit self-contradiction where generation\nproduces images deemed misaligned with input prompts based on the model's own\nunderstanding. We define a Nonunified score that quantifies such\nself-contradiction. Our empirical results reveal that the self-contradiction\nmainly arises from weak generation that fails to align with prompts, rather\nthan misunderstanding. This capability asymmetry indicates the potential of\nleveraging self-contradiction for self-improvement, where the stronger model\nunderstanding guides the weaker generation to mitigate the\ngeneration-understanding gap. Applying standard post-training methods (e.g.,\nSFT, DPO) with such internal supervision successfully improves both generation\nand unification. We discover a co-improvement effect on both generation and\nunderstanding when only fine-tuning the generation branch, a phenomenon known\nin pre-training but underexplored in post-training. Our analysis shows\nimprovements stem from better detection of false positives that are previously\nincorrectly identified as prompt-aligned. Theoretically, we show the aligned\ntraining dynamics between generation and understanding allow reduced\nprompt-misaligned generations to also improve mismatch detection in the\nunderstanding branch. Additionally, the framework reveals a potential risk of\nco-degradation under poor supervision-an overlooked phenomenon that is\nempirically validated in our experiments. Notably, we find intrinsic metrics\nlike Nonunified score cannot distinguish co-degradation from co-improvement,\nwhich highlights the necessity of data quality check. Finally, we propose a\ncurriculum-based strategy based on our findings that gradually introduces\nharder samples as the model improves, leading to better unification and\nimproved MLLM generation and understanding.",
        "url": "http://arxiv.org/abs/2507.16663v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16663v1",
        "arxiv_id": "2507.16663v1",
        "authors": [
            "Yujin Han",
            "Hao Chen",
            "Andi Han",
            "Zhiheng Wang",
            "Xinyu Lin",
            "Yingya Zhang",
            "Shiwei Zhang",
            "Difan Zou"
        ],
        "submitted": "2025-07-22 14:56:39",
        "source": "arxiv",
        "comment": "19 pages, 9 figures, 3 tables",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on multimodal language models (MLLMs) and their generation-understanding gap, which is not directly related to information retrieval, search technologies, or query understanding. Although it touches on the idea of self-improvement, the context is different from the user's primary research interests."
    },
    {
        "title": "P-CoT: A Pedagogically-motivated Participatory Chain-of-Thought Prompting for Phonological Reasoning in LLMs",
        "abstract": "This study explores the potential of phonological reasoning within text-based\nlarge language models (LLMs). Utilizing the PhonologyBench benchmark, we assess\ntasks like rhyme word generation, g2p conversion, and syllable counting. Our\nevaluations across 12 LLMs reveal that while few-shot learning offers\ninconsistent gains, the introduction of a novel Pedagogically-motivated\nParticipatory Chain-of-Thought (P-CoT) prompt, which is anchored in educational\ntheories like scaffolding and discovery learning, consistently enhances\nperformance. This method leverages structured guidance to activate latent\nphonological abilities, achieving up to 52% improvement and even surpassing\nhuman baselines in certain tasks. Future work could aim to optimize P-CoT\nprompts for specific models or explore their application across different\nlinguistic domains.",
        "url": "http://arxiv.org/abs/2507.16656v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16656v1",
        "arxiv_id": "2507.16656v1",
        "authors": [
            "Dongjun Jang",
            "Youngchae Ahn",
            "Hyopil Shin"
        ],
        "submitted": "2025-07-22 14:52:25",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on phonological reasoning in large language models, which is a topic in Natural Language Processing, but not directly related to your core interests."
    },
    {
        "title": "Scaling Linear Attention with Sparse State Expansion",
        "abstract": "The Transformer architecture, despite its widespread success, struggles with\nlong-context scenarios due to quadratic computation and linear memory growth.\nWhile various linear attention variants mitigate these efficiency constraints\nby compressing context into fixed-size states, they often degrade performance\nin tasks such as in-context retrieval and reasoning. To address this limitation\nand achieve more effective context compression, we propose two key innovations.\nFirst, we introduce a row-sparse update formulation for linear attention by\nconceptualizing state updating as information classification. This enables\nsparse state updates via softmax-based top-$k$ hard classification, thereby\nextending receptive fields and reducing inter-class interference. Second, we\npresent Sparse State Expansion (SSE) within the sparse framework, which expands\nthe contextual state into multiple partitions, effectively decoupling parameter\nsize from state capacity while maintaining the sparse classification paradigm.\nOur design, supported by efficient parallelized implementations, yields\neffective classification and discriminative state representations. We\nextensively validate SSE in both pure linear and hybrid (SSE-H) architectures\nacross language modeling, in-context retrieval, and mathematical reasoning\nbenchmarks. SSE demonstrates strong retrieval performance and scales favorably\nwith state size. Moreover, after reinforcement learning (RL) training, our 2B\nSSE-H model achieves state-of-the-art mathematical reasoning performance among\nsmall reasoning models, scoring 64.7 on AIME24 and 51.3 on AIME25,\nsignificantly outperforming similarly sized open-source Transformers. These\nresults highlight SSE as a promising and efficient architecture for\nlong-context modeling.",
        "url": "http://arxiv.org/abs/2507.16577v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16577v1",
        "arxiv_id": "2507.16577v1",
        "authors": [
            "Yuqi Pan",
            "Yongqi An",
            "Zheng Li",
            "Yuhong Chou",
            "Ruijie Zhu",
            "Xiaohui Wang",
            "Mingxuan Wang",
            "Jinqiao Wang",
            "Guoqi Li"
        ],
        "submitted": "2025-07-22 13:27:31",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on improving the Transformer architecture for long-context scenarios, which is not directly related to information retrieval, query understanding, or ranking models. While it mentions retrieval and reasoning tasks, the primary focus is on the architecture and its efficiency, rather than the underlying retrieval or ranking mechanisms."
    },
    {
        "title": "Learning Text Styles: A Study on Transfer, Attribution, and Verification",
        "abstract": "This thesis advances the computational understanding and manipulation of text\nstyles through three interconnected pillars: (1) Text Style Transfer (TST),\nwhich alters stylistic properties (e.g., sentiment, formality) while preserving\ncontent; (2)Authorship Attribution (AA), identifying the author of a text via\nstylistic fingerprints; and (3) Authorship Verification (AV), determining\nwhether two texts share the same authorship. We address critical challenges in\nthese areas by leveraging parameter-efficient adaptation of large language\nmodels (LLMs), contrastive disentanglement of stylistic features, and\ninstruction-based fine-tuning for explainable verification.",
        "url": "http://arxiv.org/abs/2507.16530v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16530v1",
        "arxiv_id": "2507.16530v1",
        "authors": [
            "Zhiqiang Hu"
        ],
        "submitted": "2025-07-22 12:38:39",
        "source": "arxiv",
        "comment": "PhD thesis",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on text style transfer, authorship attribution, and verification, which are not directly related to information retrieval, search technologies, or query understanding. While it involves language models, the application is not in the context of search or retrieval, and the topics are more aligned with NLP and data mining."
    },
    {
        "title": "ICR Probe: Tracking Hidden State Dynamics for Reliable Hallucination Detection in LLMs",
        "abstract": "Large language models (LLMs) excel at various natural language processing\ntasks, but their tendency to generate hallucinations undermines their\nreliability. Existing hallucination detection methods leveraging hidden states\npredominantly focus on static and isolated representations, overlooking their\ndynamic evolution across layers, which limits efficacy. To address this\nlimitation, we shift the focus to the hidden state update process and introduce\na novel metric, the ICR Score (Information Contribution to Residual Stream),\nwhich quantifies the contribution of modules to the hidden states' update. We\nempirically validate that the ICR Score is effective and reliable in\ndistinguishing hallucinations. Building on these insights, we propose a\nhallucination detection method, the ICR Probe, which captures the cross-layer\nevolution of hidden states. Experimental results show that the ICR Probe\nachieves superior performance with significantly fewer parameters. Furthermore,\nablation studies and case analyses offer deeper insights into the underlying\nmechanism of this method, improving its interpretability.",
        "url": "http://arxiv.org/abs/2507.16488v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16488v1",
        "arxiv_id": "2507.16488v1",
        "authors": [
            "Zhenliang Zhang",
            "Xinyu Hu",
            "Huixuan Zhang",
            "Junzhe Zhang",
            "Xiaojun Wan"
        ],
        "submitted": "2025-07-22 11:44:26",
        "source": "arxiv",
        "comment": "Accepted to ACL 2025 (Main Conference)",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it involves natural language processing, the focus is on large language models and hallucination detection, which is not a core area of interest for you."
    },
    {
        "title": "ReMeREC: Relation-aware and Multi-entity Referring Expression Comprehension",
        "abstract": "Referring Expression Comprehension (REC) aims to localize specified entities\nor regions in an image based on natural language descriptions. While existing\nmethods handle single-entity localization, they often ignore complex\ninter-entity relationships in multi-entity scenes, limiting their accuracy and\nreliability. Additionally, the lack of high-quality datasets with fine-grained,\npaired image-text-relation annotations hinders further progress. To address\nthis challenge, we first construct a relation-aware, multi-entity REC dataset\ncalled ReMeX, which includes detailed relationship and textual annotations. We\nthen propose ReMeREC, a novel framework that jointly leverages visual and\ntextual cues to localize multiple entities while modeling their\ninter-relations. To address the semantic ambiguity caused by implicit entity\nboundaries in language, we introduce the Text-adaptive Multi-entity Perceptron\n(TMP), which dynamically infers both the quantity and span of entities from\nfine-grained textual cues, producing distinctive representations. Additionally,\nour Entity Inter-relationship Reasoner (EIR) enhances relational reasoning and\nglobal scene understanding. To further improve language comprehension for\nfine-grained prompts, we also construct a small-scale auxiliary dataset,\nEntityText, generated using large language models. Experiments on four\nbenchmark datasets show that ReMeREC achieves state-of-the-art performance in\nmulti-entity grounding and relation prediction, outperforming existing\napproaches by a large margin.",
        "url": "http://arxiv.org/abs/2507.16877v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16877v1",
        "arxiv_id": "2507.16877v1",
        "authors": [
            "Yizhi Hu",
            "Zezhao Tian",
            "Xingqun Qi",
            "Chen Su",
            "Bingkun Yang",
            "Junhui Yin",
            "Muyi Sun",
            "Man Zhang",
            "Zhenan Sun"
        ],
        "submitted": "2025-07-22 11:23:48",
        "source": "arxiv",
        "comment": "15 pages, 7 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Referring Expression Comprehension in images, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves natural language processing, the context is specific to image-text pairs and does not align with the user's interests in query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Towards Enforcing Company Policy Adherence in Agentic Workflows",
        "abstract": "Large Language Model (LLM) agents hold promise for a flexible and scalable\nalternative to traditional business process automation, but struggle to\nreliably follow complex company policies. In this study we introduce a\ndeterministic, transparent, and modular framework for enforcing business policy\nadherence in agentic workflows. Our method operates in two phases: (1) an\noffline buildtime stage that compiles policy documents into verifiable guard\ncode associated with tool use, and (2) a runtime integration where these guards\nensure compliance before each agent action. We demonstrate our approach on the\nchallenging $\\tau$-bench Airlines domain, showing encouraging preliminary\nresults in policy enforcement, and further outline key challenges for\nreal-world deployments.",
        "url": "http://arxiv.org/abs/2507.16459v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16459v1",
        "arxiv_id": "2507.16459v1",
        "authors": [
            "Naama Zwerdling",
            "David Boaz",
            "Ella Rabinovich",
            "Guy Uziel",
            "David Amid",
            "Ateret Anaby-Tavor"
        ],
        "submitted": "2025-07-22 11:00:37",
        "source": "arxiv",
        "comment": "11 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on enforcing company policy adherence in agentic workflows, using Large Language Model agents, which is unrelated to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's abstract does not mention query understanding, ranking models, or user behavior modeling, and the topic is not relevant to the user's background in e-commerce or their primary focus on deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "PromptAL: Sample-Aware Dynamic Soft Prompts for Few-Shot Active Learning",
        "abstract": "Active learning (AL) aims to optimize model training and reduce annotation\ncosts by selecting the most informative samples for labeling. Typically, AL\nmethods rely on the empirical distribution of labeled data to define the\ndecision boundary and perform uncertainty or diversity estimation, subsequently\nidentifying potential high-quality samples. In few-shot scenarios, the\nempirical distribution often diverges significantly from the target\ndistribution, causing the decision boundary to shift away from its optimal\nposition. However, existing methods overlook the role of unlabeled samples in\nenhancing the empirical distribution to better align with the target\ndistribution, resulting in a suboptimal decision boundary and the selection of\nsamples that inadequately represent the target distribution. To address this,\nwe propose a hybrid AL framework, termed \\textbf{PromptAL} (Sample-Aware\nDynamic Soft \\textbf{Prompts} for Few-Shot \\textbf{A}ctive \\textbf{L}earning).\nThis framework accounts for the contribution of each unlabeled data point in\naligning the current empirical distribution with the target distribution,\nthereby optimizing the decision boundary. Specifically, PromptAL first\nleverages unlabeled data to construct sample-aware dynamic soft prompts that\nadjust the model's predictive distribution and decision boundary. Subsequently,\nbased on the adjusted decision boundary, it integrates uncertainty estimation\nwith both global and local diversity to select high-quality samples that more\naccurately represent the target distribution. Experimental results on six\nin-domain and three out-of-domain datasets show that PromptAL achieves superior\nperformance over nine baselines. Our codebase is openly accessible.",
        "url": "http://arxiv.org/abs/2507.16424v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16424v1",
        "arxiv_id": "2507.16424v1",
        "authors": [
            "Hui Xiang",
            "Jinqiao Shi",
            "Ting Zhang",
            "Xiaojie Zhao",
            "Yong Liu",
            "Yong Ma"
        ],
        "submitted": "2025-07-22 10:17:42",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on active learning and few-shot scenarios, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions 'prompts' and 'predictive distribution', the context is different from the user's interests in NLP and IR."
    },
    {
        "title": "SpeLLM: Character-Level Multi-Head Decoding",
        "abstract": "Scaling LLM vocabulary is often used to reduce input sequence length and\nalleviate attention's quadratic cost. Yet, current LLM architectures impose a\ncritical bottleneck to this procedure: the output projection layer scales\nlinearly with vocabulary size, rendering substantial expansion impractical. We\npropose SpeLLM, a method that decouples input and output vocabularies by\npredicting character-level strings through multiple output heads. In SpeLLM,\neach of the $k$ linear heads predicts a single character simultaneously,\nenabling the model to represent a much larger output space using smaller,\nindependent linear heads. We present a self-distillation approach for\nconverting a standard LLM to a SpeLLM. Our experiments with four pre-trained\nLLMs show their SpeLLM variants achieve competitive performance on downstream\ntasks while reducing runtime by 5.1% on average across models. Our approach\nprovides a potential avenue for reducing LLM costs, while increasing support\nfor underrepresented languages and domains.",
        "url": "http://arxiv.org/abs/2507.16323v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16323v1",
        "arxiv_id": "2507.16323v1",
        "authors": [
            "Amit Ben-Artzy",
            "Roy Schwartz"
        ],
        "submitted": "2025-07-22 08:07:06",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on scaling language models (LLMs) by decoupling input and output vocabularies, which is not directly related to information retrieval, query understanding, or ranking models. Although it touches on the topic of reducing costs, it does not address user behavior modeling or click models, and its relevance to e-commerce or other domains is unclear."
    },
    {
        "title": "iShumei-Chinchunmei at SemEval-2025 Task 4: A balanced forgetting and retention multi-task framework using effective unlearning loss",
        "abstract": "As the Large Language Model (LLM) gains widespread adoption, increasing\nattention has been given to the challenge of making LLM forget non-compliant\ndata memorized during its pre-training. Machine Unlearning focuses on\nefficiently erasing sensitive information from LLM under limited computational\nresources. To advance research in this area, SemEval 2025 Task 4: \"Unlearning\nSensitive Content from Large Language Models\" introduces three unlearning\ndatasets and establishes a benchmark by evaluating both forgetting\neffectiveness and the preservation of standard capabilities. In this work, we\npropose a more controllable forgetting loss, Effective Unlearning Loss, and\nexplore its integration with various techniques to achieve more efficient and\ncontrolled unlearning. Our system ultimately ranked 5th on the competition\nleaderboard.",
        "url": "http://arxiv.org/abs/2507.16263v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16263v1",
        "arxiv_id": "2507.16263v1",
        "authors": [
            "Yujian Sun",
            "Tian Li"
        ],
        "submitted": "2025-07-22 06:21:54",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on machine unlearning, a topic not directly related to information retrieval, search technologies, or query understanding. While it involves large language models, the primary goal is to erase sensitive information, which is not aligned with the user's interests in ranking models, user behavior modeling, or deep semantic understanding."
    },
    {
        "title": "SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting",
        "abstract": "Chronic Obstructive Pulmonary Disease (COPD), a major chronic respiratory\ndisease with persistent airflow limitation, is a leading global cause of\ndisability and mortality. Respiratory spirogram time series, routinely\ncollected during pulmonary function tests (PFTs), play a critical role in the\nearly detection of repsiratory diseases and in monitoring lung function over\ntime. However, most current AI models for COPD diagnosis are limited to\noutputting classification results without providing a rationale for their\ndiagnostic process, while current Large Language Models (LLMs) cannot\nunderstand spirograms yet, which severely limits their clinical trust and\nadoption. To tackle this challenge, we leverage a cohort of 234,028 individuals\nfrom the UK Biobank (UKB) to propose SpiroLLM, the first multimodal large\nlanguage model that can understand spirogram. The model extracts morphological\nfeatures from respiratory curves via a SpiroEncoder and aligns them with PFT\nnumerical values in a unified latent space using a SpiroProjector, ultimately\nempowering a large language model to generate a comprehensive diagnostic\nreport. Experimental results confirm that SpiroLLM achieved a diagnostic AUROC\nof 0.8980 (95% CI: 0.8820-0.9132). In a robustness test with missing core data,\nit maintained a 100% valid response rate, far surpassing the 13.4% of a\ntext-only model and showcasing the superiority of its multimodal design. This\nwork demonstrates the substantial potential of deeply fusing physiological\nsignals with large language models, establishing a new paradigm for the next\ngeneration of interpretable and reliable clinical decision support tools.",
        "url": "http://arxiv.org/abs/2507.16145v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16145v1",
        "arxiv_id": "2507.16145v1",
        "authors": [
            "Shuhao Mei",
            "Yongchao Long",
            "Shan Cao",
            "Xiaobo Han",
            "Shijia Geng",
            "Jinbo Sun",
            "Yuxi Zhou",
            "Shenda Hong"
        ],
        "submitted": "2025-07-22 01:44:12",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on applying large language models to understand spirogram time series in COPD reporting, which is not directly related to information retrieval, search technologies, or query understanding. While it involves NLP and data mining, the context is medical and clinical, which is not a primary focus of your research interests."
    },
    {
        "title": "Enhancing Hindi NER in Low Context: A Comparative study of Transformer-based models with vs. without Retrieval Augmentation",
        "abstract": "One major challenge in natural language processing is named entity\nrecognition (NER), which identifies and categorises named entities in textual\ninput. In order to improve NER, this study investigates a Hindi NER technique\nthat makes use of Hindi-specific pretrained encoders (MuRIL and XLM-R) and\nGenerative Models ( Llama-2-7B-chat-hf (Llama2-7B), Llama-2-70B-chat-hf\n(Llama2-70B), Llama-3-70B-Instruct (Llama3-70B) and GPT3.5-turbo), and augments\nthe data with retrieved data from external relevant contexts, notably from\nWikipedia. We have fine-tuned MuRIL, XLM-R and Llama2-7B with and without RA.\nHowever, Llama2-70B, lama3-70B and GPT3.5-turbo are utilised for few-shot NER\ngeneration. Our investigation shows that the mentioned language models (LMs)\nwith Retrieval Augmentation (RA) outperform baseline methods that don't\nincorporate RA in most cases. The macro F1 scores for MuRIL and XLM-R are 0.69\nand 0.495, respectively, without RA and increase to 0.70 and 0.71,\nrespectively, in the presence of RA. Fine-tuned Llama2-7B outperforms Llama2-7B\nby a significant margin. On the other hand the generative models which are not\nfine-tuned also perform better with augmented data. GPT3.5-turbo adopted RA\nwell; however, Llama2-70B and llama3-70B did not adopt RA with our retrieval\ncontext. The findings show that RA significantly improves performance,\nespecially for low-context data. This study adds significant knowledge about\nhow best to use data augmentation methods and pretrained models to enhance NER\nperformance, particularly in languages with limited resources.",
        "url": "http://arxiv.org/abs/2507.16002v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16002v1",
        "arxiv_id": "2507.16002v1",
        "authors": [
            "Sumit Singh",
            "Rohit Mishra",
            "Uma Shanker Tiwary"
        ],
        "submitted": "2025-07-21 18:41:58",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on named entity recognition (NER) in Hindi, which is not directly related to information retrieval or search technologies. While it uses transformer-based models and retrieval augmentation, the context is specific to NLP and language processing, and the relevance to the user's interests is limited."
    },
    {
        "title": "Zebra-CoT: A Dataset for Interleaved Vision Language Reasoning",
        "abstract": "Humans often use visual aids, for example diagrams or sketches, when solving\ncomplex problems. Training multimodal models to do the same, known as Visual\nChain of Thought (Visual CoT), is challenging due to: (1) poor off-the-shelf\nvisual CoT performance, which hinders reinforcement learning, and (2) the lack\nof high-quality visual CoT training data. We introduce $\\textbf{Zebra-CoT}$, a\ndiverse large-scale dataset with 182,384 samples, containing logically coherent\ninterleaved text-image reasoning traces. We focus on four categories of tasks\nwhere sketching or visual reasoning is especially natural, spanning scientific\nquestions such as geometry, physics, and algorithms; 2D visual reasoning tasks\nlike visual search and jigsaw puzzles; 3D reasoning tasks including 3D\nmulti-hop inference, embodied and robot planning; visual logic problems and\nstrategic games like chess. Fine-tuning the Anole-7B model on the Zebra-CoT\ntraining corpus results in an improvement of +12% in our test-set accuracy and\nyields up to +13% performance gain on standard VLM benchmark evaluations.\nFine-tuning Bagel-7B yields a model that generates high-quality interleaved\nvisual reasoning chains, underscoring Zebra-CoT's effectiveness for developing\nmultimodal reasoning abilities. We open-source our dataset and models to\nsupport development and evaluation of visual CoT.",
        "url": "http://arxiv.org/abs/2507.16746v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16746v1",
        "arxiv_id": "2507.16746v1",
        "authors": [
            "Ang Li",
            "Charles Wang",
            "Kaiyu Yue",
            "Zikui Cai",
            "Ollie Liu",
            "Deqing Fu",
            "Peng Guo",
            "Wang Bill Zhu",
            "Vatsal Sharan",
            "Robin Jia",
            "Willie Neiswanger",
            "Furong Huang",
            "Tom Goldstein",
            "Micah Goldblum"
        ],
        "submitted": "2025-07-22 16:35:36",
        "source": "arxiv",
        "comment": "dataset link:\n  https://huggingface.co/datasets/multimodal-reasoning-lab/Zebra-CoT",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on a specific topic of visual language reasoning, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions multimodal models, the context is different from the user's focus on query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Exploring Gender Bias in Large Language Models: An In-depth Dive into the German Language",
        "abstract": "In recent years, various methods have been proposed to evaluate gender bias\nin large language models (LLMs). A key challenge lies in the transferability of\nbias measurement methods initially developed for the English language when\napplied to other languages. This work aims to contribute to this research\nstrand by presenting five German datasets for gender bias evaluation in LLMs.\nThe datasets are grounded in well-established concepts of gender bias and are\naccessible through multiple methodologies. Our findings, reported for eight\nmultilingual LLM models, reveal unique challenges associated with gender bias\nin German, including the ambiguous interpretation of male occupational terms\nand the influence of seemingly neutral nouns on gender perception. This work\ncontributes to the understanding of gender bias in LLMs across languages and\nunderscores the necessity for tailored evaluation frameworks.",
        "url": "http://arxiv.org/abs/2507.16557v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16557v1",
        "arxiv_id": "2507.16557v1",
        "authors": [
            "Kristin Gnadt",
            "David Thulke",
            "Simone Kopeinik",
            "Ralf Schlüter"
        ],
        "submitted": "2025-07-22 13:09:41",
        "source": "arxiv",
        "comment": "Accepted at the 6th Workshop on Gender Bias in Natural Language\n  Processing (GeBNLP) at ACL 2025",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on evaluating gender bias in large language models, which is a topic outside your primary focus."
    },
    {
        "title": "Introducing Quality Estimation to Machine Translation Post-editing Workflow: An Empirical Study on Its Usefulness",
        "abstract": "This preliminary study investigates the usefulness of sentence-level Quality\nEstimation (QE) in English-Chinese Machine Translation Post-Editing (MTPE),\nfocusing on its impact on post-editing speed and student translators'\nperceptions. It also explores the interaction effects between QE and MT\nquality, as well as between QE and translation expertise. The findings reveal\nthat QE significantly reduces post-editing time. The examined interaction\neffects were not significant, suggesting that QE consistently improves MTPE\nefficiency across medium- and high-quality MT outputs and among student\ntranslators with varying levels of expertise. In addition to indicating\npotentially problematic segments, QE serves multiple functions in MTPE, such as\nvalidating translators' evaluations of MT quality and enabling them to\ndouble-check translation outputs. However, interview data suggest that\ninaccurate QE may hinder post-editing processes. This research provides new\ninsights into the strengths and limitations of QE, facilitating its more\neffective integration into MTPE workflows to enhance translators' productivity.",
        "url": "http://arxiv.org/abs/2507.16515v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16515v1",
        "arxiv_id": "2507.16515v1",
        "authors": [
            "Siqi Liu",
            "Guangrong Dai",
            "Dechao Li"
        ],
        "submitted": "2025-07-22 12:25:00",
        "source": "arxiv",
        "comment": "11 pages, 5 figures, 2 tables. To be published in the Proceedings of\n  the 20th Machine Translation Summit (MT Summit 2025; Geneva, Switzerland)",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on Machine Translation Post-editing, Quality Estimation, and translation expertise, which are outside the user's primary research areas."
    },
    {
        "title": "Knowledge-aware Diffusion-Enhanced Multimedia Recommendation",
        "abstract": "Multimedia recommendations aim to use rich multimedia content to enhance\nhistorical user-item interaction information, which can not only indicate the\ncontent relatedness among items but also reveal finer-grained preferences of\nusers. In this paper, we propose a Knowledge-aware Diffusion-Enhanced\narchitecture using contrastive learning paradigms (KDiffE) for multimedia\nrecommendations. Specifically, we first utilize original user-item graphs to\nbuild an attention-aware matrix into graph neural networks, which can learn the\nimportance between users and items for main view construction. The\nattention-aware matrix is constructed by adopting a random walk with a restart\nstrategy, which can preserve the importance between users and items to generate\naggregation of attention-aware node features. Then, we propose a guided\ndiffusion model to generate strongly task-relevant knowledge graphs with less\nnoise for constructing a knowledge-aware contrastive view, which utilizes user\nembeddings with an edge connected to an item to guide the generation of\nstrongly task-relevant knowledge graphs for enhancing the item's semantic\ninformation. We perform comprehensive experiments on three multimedia datasets\nthat reveal the effectiveness of our KDiffE and its components on various\nstate-of-the-art methods. Our source codes are available\nhttps://github.com/1453216158/KDiffE.",
        "url": "http://arxiv.org/abs/2507.16396v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16396v1",
        "arxiv_id": "2507.16396v1",
        "authors": [
            "Xian Mo",
            "Fei Liu",
            "Rui Tang",
            "Jintao",
            "Gao",
            "Hao Liu"
        ],
        "submitted": "2025-07-22 09:47:56",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on multimedia recommendation, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions graph neural networks and contrastive learning paradigms, the context is different from the user's background in e-commerce and query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "FinResearchBench: A Logic Tree based Agent-as-a-Judge Evaluation Framework for Financial Research Agents",
        "abstract": "Recently, AI agents are rapidly evolving in intelligence and widely used in\nprofessional research applications, such as STEM, software development,\nfinance, etc. Among these AI agents, deep research agent is a key category as\nit can perform long-horizon tasks and solve problems of greater complexity.\nHowever, there are few evaluation frameworks and benchmarks that systematically\nand automatically investigate the capabilities of these research agents.\nFurthermore, financial research problems have distinct complexity and subtlety.\nTo fill in the gap, we propose FinResearchBench, which is a logic tree based\nAgent-as-a-Judge and targets specifically for the financial research agents. It\nprovides a comprehensive and automatic assessment of the research agents across\n7 key types of tasks in the financial research domain. The contributions of\nthis work are two-folded: (1) the first and innovative Agent-as-a-Judge system\nthat extracts the logic tree of the research outcome and uses it as the\nintermediate information to present a comprehensive, reliable and robust\nevaluation; (2) finance oriented that it covers 70 typical financial research\nquestions, spreading across 7 frequently encountered types of tasks in the\ndomain.",
        "url": "http://arxiv.org/abs/2507.16248v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16248v1",
        "arxiv_id": "2507.16248v1",
        "authors": [
            "Run Sun",
            "Zuo Bai",
            "Wentao Zhang",
            "Yuxiang Zhang",
            "Li Zhao",
            "Shan Sun",
            "Zhengwen Qiu"
        ],
        "submitted": "2025-07-22 05:40:25",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper proposes a framework for evaluating financial research agents, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions AI agents, the focus is on financial research and does not seem to involve ranking models, user behavior modeling, or deep semantic understanding."
    },
    {
        "title": "Characterizing Online Activities Contributing to Suicide Mortality among Youth",
        "abstract": "The recent rise in youth suicide highlights the urgent need to understand how\nonline experiences contribute to this public health issue. Our mixed-methods\napproach responds to this challenge by developing a set of themes focused on\nrisk factors for suicide mortality in online spaces among youth ages 10-24, and\na framework to model these themes at scale. Using 29,124 open text summaries of\ndeath investigations between 2013-2022, we conducted a thematic analysis to\nidentify 12 types of online activities that were considered by investigators or\nnext of kin to be relevant in contextualizing a given suicide death. We then\ndevelop a zero-shot learning framework to model these 12 themes at scale, and\nanalyze variation in these themes by decedent characteristics and over time.\nOur work uncovers several online activities related to harm to self, harm to\nothers, interpersonal interactions, activity levels online, and life events,\nwhich correspond to different phases of suicide risk from two prominent suicide\ntheories. We find an association between these themes and decedent\ncharacteristics like age, means of death, and interpersonal problems, and many\nthemes became more prevalent during the 2020 COVID-19 lockdowns. While digital\nspaces have taken some steps to address expressions of suicidality online, our\nwork illustrates the opportunities for developing interventions related to less\nexplicit indicators of suicide risk by combining suicide theories with\ncomputational research.",
        "url": "http://arxiv.org/abs/2507.16185v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16185v1",
        "arxiv_id": "2507.16185v1",
        "authors": [
            "Aparna Ananthasubramaniam",
            "Elyse J. Thulin",
            "Viktoryia Kalesnikava",
            "Silas Falde",
            "Jonathan Kertawidjaja",
            "Lily Johns",
            "Alejandro Rodríguez-Putnam",
            "Emma Spring",
            "Kara Zivin",
            "Briana Mezuk"
        ],
        "submitted": "2025-07-22 02:55:51",
        "source": "arxiv",
        "comment": "Accepted at the AAAI International Conference on Web and Social Media\n  (ICWSM) 2026",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topic of suicide mortality among youth and online activities contributing to it is outside the scope of your research areas, and the paper does not discuss query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Pixels, Patterns, but No Poetry: To See The World like Humans",
        "abstract": "Achieving human-like perception and reasoning in Multimodal Large Language\nModels (MLLMs) remains a central challenge in artificial intelligence. While\nrecent research has primarily focused on enhancing reasoning capabilities in\nMLLMs, a fundamental question persists: Can Multimodal Large Language Models\ntruly perceive the world as humans do? This paper shifts focus from reasoning\nto perception. Rather than constructing benchmarks specifically for reasoning,\nwe introduce the Turing Eye Test (TET), a challenging perception-oriented\nbenchmark comprising four diagnostic tasks that evaluate MLLMs' performance on\nsynthetic images that humans process intuitively. Our findings reveal that\nstate-of-the-art MLLMs exhibit catastrophic failures on our perceptual tasks\ntrivial for humans. Both in-context learning and training on language\nbackbone-effective for previous benchmarks-fail to improve performance on our\ntasks, while fine-tuning the vision tower enables rapid adaptation, suggesting\nthat our benchmark poses challenges for vision tower generalization rather than\nfor the knowledge and reasoning capabilities of the language backbone-a key gap\nbetween current MLLMs and human perception. We release a representative subset\nof TET tasks in this version, and will introduce more diverse tasks and methods\nto enhance visual generalization in future work.",
        "url": "http://arxiv.org/abs/2507.16863v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16863v1",
        "arxiv_id": "2507.16863v1",
        "authors": [
            "Hongcheng Gao",
            "Zihao Huang",
            "Lin Xu",
            "Jingyi Tang",
            "Xinhao Li",
            "Yue Liu",
            "Haoyang Li",
            "Taihang Hu",
            "Minhua Lin",
            "Xinlong Yang",
            "Ge Wu",
            "Balong Bi",
            "Hongyu Chen",
            "Wentao Zhang"
        ],
        "submitted": "2025-07-21 21:50:16",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on Multimodal Large Language Models and their ability to perceive the world like humans, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on the topic of benchmarking, it is primarily concerned with the perception capabilities of language models, rather than ranking models or user behavior modeling."
    },
    {
        "title": "Efficient Compositional Multi-tasking for On-device Large Language Models",
        "abstract": "Adapter parameters provide a mechanism to modify the behavior of machine\nlearning models and have gained significant popularity in the context of large\nlanguage models (LLMs) and generative AI. These parameters can be merged to\nsupport multiple tasks via a process known as task merging. However, prior work\non merging in LLMs, particularly in natural language processing, has been\nlimited to scenarios where each test example addresses only a single task. In\nthis paper, we focus on on-device settings and study the problem of text-based\ncompositional multi-tasking, where each test example involves the simultaneous\nexecution of multiple tasks. For instance, generating a translated summary of a\nlong text requires solving both translation and summarization tasks\nconcurrently. To facilitate research in this setting, we propose a benchmark\ncomprising four practically relevant compositional tasks. We also present an\nefficient method (Learnable Calibration) tailored for on-device applications,\nwhere computational resources are limited, emphasizing the need for solutions\nthat are both resource-efficient and high-performing. Our contributions lay the\ngroundwork for advancing the capabilities of LLMs in real-world multi-tasking\nscenarios, expanding their applicability to complex, resource-constrained use\ncases.",
        "url": "http://arxiv.org/abs/2507.16083v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16083v1",
        "arxiv_id": "2507.16083v1",
        "authors": [
            "Ondrej Bohdal",
            "Mete Ozay",
            "Jijoong Moon",
            "Kyeng-Hun Lee",
            "Hyeonmok Ko",
            "Umberto Michieli"
        ],
        "submitted": "2025-07-21 21:39:23",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on large language models and task merging, which is related to my interests in NLP and data mining. However, the specific context of on-device settings and compositional multi-tasking is not directly aligned with my primary focus on information retrieval and query understanding."
    },
    {
        "title": "AutoMeet: a proof-of-concept study of genAI to automate meetings in automotive engineering",
        "abstract": "In large organisations, knowledge is mainly shared in meetings, which takes\nup significant amounts of work time. Additionally, frequent in-person meetings\nproduce inconsistent documentation -- official minutes, personal notes,\npresentations may or may not exist. Shared information therefore becomes hard\nto retrieve outside of the meeting, necessitating lengthy updates and\nhigh-frequency meeting schedules.\n  Generative Artificial Intelligence (genAI) models like Large Language Models\n(LLMs) exhibit an impressive performance on spoken and written language\nprocessing. This motivates a practical usage of genAI for knowledge management\nin engineering departments: using genAI for transcribing meetings and\nintegrating heterogeneous additional information sources into an easily usable\nformat for ad-hoc searches.\n  We implement an end-to-end pipeline to automate the entire meeting\ndocumentation workflow in a proof-of-concept state: meetings are recorded and\nminutes are created by genAI. These are further made easily searchable through\na chatbot interface. The core of our work is to test this genAI-based software\ntooling in a real-world engineering department and collect extensive survey\ndata on both ethical and technical aspects. Direct feedback from this\nreal-world setup points out both opportunities and risks: a) users agree that\nthe effort for meetings could be significantly reduced with the help of genAI\nmodels, b) technical aspects are largely solved already, c) organizational\naspects are crucial for a successful ethical usage of such a system.",
        "url": "http://arxiv.org/abs/2507.16054v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16054v1",
        "arxiv_id": "2507.16054v1",
        "authors": [
            "Simon Baeuerle",
            "Max Radyschevski",
            "Ulrike Pado"
        ],
        "submitted": "2025-07-21 20:44:53",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on applying genAI to automate meetings in automotive engineering, which is outside the scope of Information Retrieval, Search technologies, and Natural Language Processing. The paper does not address query understanding, ranking models, or user behavior modeling, which are key areas of interest for you."
    },
    {
        "title": "Learning without training: The implicit dynamics of in-context learning",
        "abstract": "One of the most striking features of Large Language Models (LLM) is their\nability to learn in context. Namely at inference time an LLM is able to learn\nnew patterns without any additional weight update when these patterns are\npresented in the form of examples in the prompt, even if these patterns were\nnot seen during training. The mechanisms through which this can happen are\nstill largely unknown. In this work, we show that the stacking of a\nself-attention layer with an MLP, allows the transformer block to implicitly\nmodify the weights of the MLP layer according to the context. We argue through\ntheory and experimentation that this simple mechanism may be the reason why\nLLMs can learn in context and not only during training. Specifically, we show\nunder mild simplifying assumptions how a transformer block implicitly\ntransforms a context into a low-rank weight-update of the MLP layer.",
        "url": "http://arxiv.org/abs/2507.16003v1",
        "pdf_url": "http://arxiv.org/pdf/2507.16003v1",
        "arxiv_id": "2507.16003v1",
        "authors": [
            "Benoit Dherin",
            "Michael Munn",
            "Hanna Mazzawi",
            "Michael Wunder",
            "Javier Gonzalvo"
        ],
        "submitted": "2025-07-21 18:44:35",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on the ability of Large Language Models to learn in context, which is a topic in NLP. However, it does not directly relate to Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling, which are the user's primary research interests."
    },
    {
        "title": "Scaling Recommender Transformers to One Billion Parameters",
        "abstract": "While large transformer models have been successfully used in many real-world\napplications such as natural language processing, computer vision, and speech\nprocessing, scaling transformers for recommender systems remains a challenging\nproblem. Recently, Generative Recommenders framework was proposed to scale\nbeyond typical Deep Learning Recommendation Models (DLRMs). Reformulation of\nrecommendation as sequential transduction task led to improvement of scaling\nproperties in terms of compute. Nevertheless, the largest encoder configuration\nreported by the HSTU authors amounts only to ~176 million parameters, which is\nconsiderably smaller than the hundreds of billions or even trillions of\nparameters common in modern language models.\n  In this work, we present a recipe for training large transformer recommenders\nwith up to a billion parameters. We show that autoregressive learning on user\nhistories naturally decomposes into two subtasks, feedback prediction and\nnext-item prediction, and demonstrate that such a decomposition scales\neffectively across a wide range of transformer sizes. Furthermore, we report a\nsuccessful deployment of our proposed architecture on a large-scale music\nplatform serving millions of users. According to our online A/B tests, this new\nmodel increases total listening time by +2.26% and raises the likelihood of\nuser likes by +6.37%, constituting (to our knowledge) the largest improvement\nin recommendation quality reported for any deep learning-based system in the\nplatform's history.",
        "url": "http://arxiv.org/abs/2507.15994v1",
        "pdf_url": "http://arxiv.org/pdf/2507.15994v1",
        "arxiv_id": "2507.15994v1",
        "authors": [
            "Kirill Khrylchenko",
            "Artem Matveev",
            "Sergei Makeev",
            "Vladimir Baikalov"
        ],
        "submitted": "2025-07-21 18:30:43",
        "source": "arxiv",
        "comment": "To be submitted",
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on scaling transformer models for recommender systems, which is only loosely related to the user's primary interest in Information Retrieval and Search technologies. Although it mentions transformers, the context is different from the user's focus on query understanding, ranking models, and user behavior modeling."
    }
]