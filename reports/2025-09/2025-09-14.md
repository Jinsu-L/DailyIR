# Daily Papers Report - 2025-09-14

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. A Research Vision for Web Search on Emerging Topics

- **LLM Score**: 8
- **Keyword Score**: 2
- **Authors**: Alisa Rieger, Stefan Dietze, Ran Yu
- **URL**: <http://arxiv.org/abs/2509.10212v1>
- **Submitted**: 2025-09-12 13:00:06
- **Topic Keywords**: web search, search
- **Reason**: This paper aligns with your interests in Information Retrieval, particularly in the context of web search and emerging topics. The focus on knowledge acquisition, dynamic topic awareness, and responsible opinion formation resonates with your expertise in query understanding and ranking models. While it doesn't delve into specific NLP or recommender systems, the paper's emphasis on real-time relevance optimization and system building makes it relevant to your broader research interests.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Challenges and opportunities of web search in the context of emerging topics.
- **Aim**: To investigate how current search systems handle emerging topics and propose solutions to improve user experience and mitigate potential harms.
- **Rationale**: Current large language models (LLMs) are ill-equipped to handle emerging topics due to their training data often lacking up-to-date information, potentially leading users to outdated or inaccurate information and increasing susceptibility to manipulation, misinformation, and bias.
- **Ground**: The research draws upon a wide range of studies in web search, information retrieval, and online information consumption, exploring key themes such as the evolution of search interfaces, the impact of search features, LLMs and echo chambers, user behavior on controversial topics, knowledge acquisition during search, emotional design and learning, belief dynamics and biases, mitigating confirmation bias, information retrieval and task dimensions, the impact of short-form video platforms, online misinformation, boosting informed search, and user awareness of search engine biases.
- **Experiment**: The research emphasizes a sociotechnical imaginary that prioritizes both societal and user needs in information access. It proposes a multi-faceted approach incorporating quantitative and qualitative methods, theoretical analysis, and participatory design involving diverse stakeholders, including domain experts like journalists.
- **Takeaway**: The paper concludes by emphasizing the importance of developing information systems that better align with individual and societal needs, ultimately contributing to a healthier and more empowering information ecosystem.

#### Abstract
> We regularly encounter information on novel, emerging topics for which the
body of knowledge is still evolving, which can be linked, for instance, to
current events. A primary way to learn more about such topics is through web
search. However, information on emerging topics is sparse and evolves
dynamically as knowledge grows, making it uncertain and variable in quality and
trustworthiness and prone to deliberate or accidental manipulation,
misinformation, and bias. In this paper, we outline a research vision towards
search systems and interfaces that support effective knowledge acquisition,
awareness of the dynamic nature of topics, and responsible opinion formation
among people searching the web for information on emerging topics. To realize
this vision, we propose three overarching research questions, aimed at
understanding the status quo, determining requirements of systems aligned with
our vision, and building these systems. For each of the three questions, we
highlight relevant literature, including pointers on how they could be
addressed. Lastly, we discuss the challenges that will potentially arise in
pursuing the proposed vision.

---

### 2. DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL

- **LLM Score**: 8
- **Keyword Score**: 1
- **Authors**: Rui Lu, Zhenyu Hou, Zihan Wang, Hanchen Zhang, Xiao Liu, Yujiang Li, Shi Feng, Jie Tang, Yuxiao Dong
- **URL**: <http://arxiv.org/abs/2509.10446v1>
- **Submitted**: 2025-09-12 17:52:35
- **Topic Keywords**: search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of deep semantic understanding and real-time relevance optimization. The use of knowledge graphs and multi-turn reinforcement learning to enhance large language models' long-horizon reasoning capacity aligns with your focus on query understanding and ranking models. However, the e-commerce domain is not explicitly mentioned, which is the only reason it doesn't score higher.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Deep Search with Large Language Models
- **Aim**: To enhance the capabilities of open-source LLMs in deep search tasks by addressing limitations in long-horizon reasoning and challenging training data.
- **Rationale**: Deep search tasks require LLMs to perform complex reasoning and utilize tools effectively, which current models struggle with due to limited training data and reasoning abilities.
- **Ground**: Open-source LLMs, knowledge graphs (KGs), and reinforcement learning (RL) techniques.
- **Experiment**: DeepDive, a novel framework, is introduced that utilizes automatic question synthesis from KGs and multi-turn RL to train LLMs for deep search. DeepDive-32B, a model trained with these techniques, is evaluated on four deep search benchmarks.
- **Takeaway**: DeepDive-32B achieves state-of-the-art results, demonstrating the effectiveness of automatic question synthesis, multi-turn RL, and synthetic data for training deep search agents. The research highlights the potential of open-source models in this domain and suggests future directions for improvement.

#### Abstract
> Augmenting large language models (LLMs) with browsing tools substantially
improves their potential as deep search agents to solve complex, real-world
tasks. Yet, open LLMs still perform poorly in such settings due to limited
long-horizon reasoning capacity with browsing tools and the lack of
sufficiently difficult supervised data. To address these challenges, we present
DeepDive to advance deep search agents. First, we propose a strategy to
automatically synthesize complex, difficult, and hard-to-find questions from
open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement
learning (RL) to enhance LLMs' long-horizon reasoning with deep search.
Experiments show that DeepDive-32B achieves a new open-source competitive
result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and
Search-o1. We demonstrate that multi-turn RL training improves deep search
ability and significantly contributes to the performance improvements across
multiple benchmarks. We observe that DeepDive enables test-time scaling of tool
calls and parallel sampling. All datasets, models, and code are publicly
available at https://github.com/THUDM/DeepDive.

---

### 3. Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery

- **LLM Score**: 7
- **Keyword Score**: 11
- **Authors**: Mustapha Adamu, Qi Zhang, Huitong Pan, Longin Jan Latecki, Eduard C. Dragut
- **URL**: <http://arxiv.org/abs/2509.10087v1>
- **Submitted**: 2025-09-12 09:28:29
- **Comment**: ACM SIGIR 2025 Workshop MANILA
- **Topic Keywords**: query, queries, rag, retrieval, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the area of query understanding and semantic search. Although it focuses on a specific domain (climate science), it explores the use of Knowledge Graphs and semantic queries, which aligns with your interests in deep semantic understanding and real-time relevance optimization. However, the paper's focus on a specific domain and application limits its relevance to your broader interests in e-commerce and NLP.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Climate Science Information Retrieval
- **Aim**: To develop a domain-specific knowledge graph, ClimatePub4KG, to improve the navigation and understanding of climate science literature.
- **Rationale**: Traditional keyword-based search and LLMs like ChatGPT-4o struggle to handle the complexity and interconnectedness of climate science information.
- **Ground**: ClimatePub4KG is built from climate publications and scientific texts, capturing relationships between key entities like climate models, variables, locations, datasets, and teleconnection patterns.
- **Experiment**: The authors demonstrate ClimatePub4KG's utility through example queries, showcasing its ability to retrieve specific details, discover interconnections, and leverage external data.
- **Takeaway**: ClimatePub4KG offers enhanced precision, recall, and the ability to handle complex, multi-hop queries, making it a valuable tool for researchers and anyone seeking accurate climate science information.

#### Abstract
> The growing complexity and volume of climate science literature make it
increasingly difficult for researchers to find relevant information across
models, datasets, regions, and variables. This paper introduces a
domain-specific Knowledge Graph (KG) built from climate publications and
broader scientific texts, aimed at improving how climate knowledge is accessed
and used. Unlike keyword based search, our KG supports structured, semantic
queries that help researchers discover precise connections such as which models
have been validated in specific regions or which datasets are commonly used
with certain teleconnection patterns. We demonstrate how the KG answers such
questions using Cypher queries, and outline its integration with large language
models in RAG systems to improve transparency and reliability in
climate-related question answering. This work moves beyond KG construction to
show its real world value for climate researchers, model developers, and others
who rely on accurate, contextual scientific information.

---

### 4. Topic-Guided Reinforcement Learning with LLMs for Enhancing Multi-Document Summarization

- **LLM Score**: 6
- **Keyword Score**: 5
- **Authors**: Chuyuan Li, Austin Xu, Shafiq Joty, Giuseppe Carenini
- **URL**: <http://arxiv.org/abs/2509.09852v1>
- **Submitted**: 2025-09-11 21:01:54
- **Topic Keywords**: relevance, rag
- **Reason**: This paper explores Multi-Document Summarization, which is related to Information Retrieval, but it focuses on summarization rather than search or ranking. The use of Large Language Models and reinforcement learning is relevant to NLP, but the specific application to summarization is not a central match to the user's core research themes.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Abstractive Multi-Document Summarization (MDS)
- **Aim**: Enhance abstractive MDS using reinforcement learning (RL) with topic guidance.
- **Rationale**: Topic guidance can improve the focus and accuracy of summaries by providing high-level context.
- **Ground**: Source documents with extracted topic labels.
- **Experiment**: Train smaller LLMs (Qwen2.5-0.5B and 1.5B) using RL with topic-guided rewards and a length penalty.
- **Takeaway**: RL-trained models with topic guidance outperform baseline and supervised fine-tuning models, demonstrating the effectiveness of this approach for abstractive MDS.

#### Abstract
> A key challenge in Multi-Document Summarization (MDS) is effectively
integrating information from multiple sources while maintaining coherence and
topical relevance. While Large Language Models have shown impressive results in
single-document summarization, their performance on MDS still leaves room for
improvement. In this paper, we propose a topic-guided reinforcement learning
approach to improve content selection in MDS. We first show that explicitly
prompting models with topic labels enhances the informativeness of the
generated summaries. Building on this insight, we propose a novel topic reward
within the Group Relative Policy Optimization (GRPO) framework to measure topic
alignment between the generated summary and source documents. Experimental
results on the Multi-News and Multi-XScience datasets demonstrate that our
method consistently outperforms strong baselines, highlighting the
effectiveness of leveraging topical cues in MDS.

---

### 5. Towards Reliable and Interpretable Document Question Answering via VLMs

- **LLM Score**: 6
- **Keyword Score**: 1
- **Authors**: Alessio Chen, Simone Giovannini, Andrea Gemelli, Fabio Coppini, Simone Marinai
- **URL**: <http://arxiv.org/abs/2509.10129v1>
- **Submitted**: 2025-09-12 10:44:24
- **Topic Keywords**: search
- **Reason**: This paper explores the application of Vision-Language Models (VLMs) in document question answering, which is somewhat related to information retrieval and query understanding. However, the focus on spatial localization and bounding-box prediction is not directly aligned with my core research themes in ranking models and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Vision-Language Models (VLMs) for Document-Level Spatial Reasoning
- **Aim**: To develop VLMs capable of accurately answering questions about documents, focusing on both textual accuracy and spatial grounding.
- **Rationale**: Existing VLMs struggle with accurately localizing answers within documents, hindering their ability to fully understand document-level information.
- **Ground**: BoundingDocs dataset, a new dataset for evaluating document-level spatial reasoning in VQA, with ground truth bounding boxes for answers.
- **Experiment**: Evaluated various prompting techniques and proposed DocExplainerV0, a plug-and-play module to improve spatial grounding capabilities of VLMs.
- **Takeaway**: DocExplainerV0 outperforms prompting-based methods in spatial accuracy but still lags behind OCR baselines. Highlights the need for more sophisticated methods for evaluating the interpretability and groundedness of VLMs in document understanding tasks.

#### Abstract
> Vision-Language Models (VLMs) have shown strong capabilities in document
understanding, particularly in identifying and extracting textual information
from complex documents. Despite this, accurately localizing answers within
documents remains a major challenge, limiting both interpretability and
real-world applicability. To address this, we introduce
\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that
decouples answer generation from spatial localization. This design makes it
applicable to existing VLMs, including proprietary systems where fine-tuning is
not feasible. Through systematic evaluation, we provide quantitative insights
into the gap between textual accuracy and spatial grounding, showing that
correct answers often lack reliable localization. Our standardized framework
highlights these shortcomings and establishes a benchmark for future research
toward more interpretable and robust document information extraction VLMs.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Latency and Token-Aware Test-Time Compute

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Jenny Y. Huang, Mehul Damani, Yousef El-Kurdi, Ramon Astudillo, Wei Sun
- **URL**: <http://arxiv.org/abs/2509.09864v1>
- **Submitted**: 2025-09-11 21:35:19
- **Topic Keywords**: query, queries, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of large language models and inference-time scaling. However, it primarily focuses on improving the performance of language models, which is not a central match to your interests in query understanding, ranking models, and user behavior modeling. The paper's emphasis on latency and token-aware test-time compute is also not directly related to your core research themes.

#### Abstract
> Inference-time scaling has emerged as a powerful way to improve large
language model (LLM) performance by generating multiple candidate responses and
selecting among them. However, existing work on dynamic allocation for
test-time compute typically considers only parallel generation methods such as
best-of-N, overlooking incremental decoding methods like beam search, and has
largely ignored latency, focusing only on token usage. We formulate
inference-time scaling as a problem of dynamic compute allocation and method
selection, where the system must decide which strategy to apply and how much
compute to allocate on a per-query basis. Our framework explicitly incorporates
both token cost and wall-clock latency, the latter being critical for user
experience and particularly for agentic workflows where models must issue
multiple queries efficiently. Experiments on reasoning benchmarks show that our
approach consistently outperforms static strategies, achieving favorable
accuracy-cost trade-offs while remaining practical for deployment.

### 7. Diversified recommendations of cultural activities with personalized determinantal point processes

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Carole Ibrahim, Hiba Bederina, Daniel Cuesta, Laurent Montier, Cyrille Delabre, Jill-J√™nn Vie
- **URL**: <http://arxiv.org/abs/2509.10392v1>
- **Submitted**: 2025-09-12 16:34:07
- **Comment**: 7 pages, accepted at RecSys workshop RecSoGood 2025
- **Topic Keywords**: relevance, recommend
- **Reason**: This paper is somewhat related to the user's research interests in Information Retrieval and Search technologies, but it focuses more on recommender systems and diversification of recommendations. While it touches on user behavior modeling, it doesn't delve into query understanding, ranking models, or deep semantic understanding, which are the user's primary areas of interest.

#### Abstract
> While optimizing recommendation systems for user engagement is a
well-established practice, effectively diversifying recommendations without
negatively impacting core business metrics remains a significant industry
challenge. In line with our initiative to broaden our audience's cultural
practices, this study investigates using personalized Determinantal Point
Processes (DPPs) to sample diverse and relevant recommendations. We rely on a
well-known quality-diversity decomposition of the similarity kernel to give
more weight to user preferences. In this paper, we present our implementations
of the personalized DPP sampling, evaluate the trade-offs between relevance and
diversity through both offline and online metrics, and give insights for
practitioners on their use in a production environment. For the sake of
reproducibility, we release the full code for our platform and experiments on
GitHub.

### 8. RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Shadikur Rahman, Aroosa Hameed, Gautam Srivastava, Syed Muhammad Danish
- **URL**: <http://arxiv.org/abs/2509.10436v1>
- **Submitted**: 2025-09-12 17:44:22
- **Comment**: 12 pages, 5 figures, submitted to IEEE Transactions on Services
  Computing
- **Topic Keywords**: relevance
- **Reason**: The paper discusses a novel architecture for optimizing Large Language Models (LLMs) in cloud-edge deployment, which is somewhat related to information retrieval and NLP. However, the focus on coding question solutions and multi-domain coding tasks is not directly aligned with the user's core research themes in query understanding, ranking models, and user behavior modeling. The paper's relevance to recommender systems is also not a central match.

#### Abstract
> To optimize the reasoning and problem-solving capabilities of Large Language
Models (LLMs), we propose a novel cloud-edge collaborative architecture that
enables a structured, multi-agent prompting framework. This framework comprises
three specialized components: GuideLLM, a lightweight model deployed at the
edge to provide methodological guidance; SolverLLM, a more powerful model
hosted in the cloud responsible for generating code solutions; and JudgeLLM, an
automated evaluator for assessing solution correctness and quality. To evaluate
and demonstrate the effectiveness of this architecture in realistic settings,
we introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate
and enhance the performance of Large Language Models (LLMs) across multi-domain
coding tasks. Motivated by the limitations of existing benchmarks,
RefactorCoderQA systematically covers various technical domains, including
Software Engineering, Data Science, Machine Learning, and Natural Language
Processing, using authentic coding challenges from Stack Overflow. Extensive
experiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves
state-of-the-art performance, significantly outperforming leading open-source
and commercial baselines with an overall accuracy of 76.84%. Human evaluations
further validate the interpretability, accuracy, and practical relevance of the
generated solutions. In addition, we evaluate system-level metrics, such as
throughput and latency, to gain deeper insights into the performance
characteristics and trade-offs of the proposed architecture.

### 9. RecoWorld: Building Simulated Environments for Agentic Recommender Systems

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Fei Liu, Xinyu Lin, Hanchao Yu, Mingyuan Wu, Jianyu Wang, Qiang Zhang, Zhuokai Zhao, Yinglong Xia, Yao Zhang, Weiwei Li, Mingze Gao, Qifan Wang, Lizhu Zhang, Benyu Zhang, Xiangjun Fan
- **URL**: <http://arxiv.org/abs/2509.10397v1>
- **Submitted**: 2025-09-12 16:44:34
- **Topic Keywords**: rag, recommend
- **Reason**: This paper focuses on recommender systems, which is a related topic to your research interests in Information Retrieval and Search technologies. However, it primarily deals with agentic recommender systems and simulated environments, which is not a central match to your core research themes. The use of modern LLMs and multi-turn RL is somewhat relevant to your interests in ranking models and user behavior modeling.

#### Abstract
> We present RecoWorld, a blueprint for building simulated environments
tailored to agentic recommender systems. Such environments give agents a proper
training space where they can learn from errors without impacting real users.
RecoWorld distinguishes itself with a dual-view architecture: a simulated user
and an agentic recommender engage in multi-turn interactions aimed at
maximizing user retention. The user simulator reviews recommended items,
updates its mindset, and when sensing potential user disengagement, generates
reflective instructions. The agentic recommender adapts its recommendations by
incorporating these user instructions and reasoning traces, creating a dynamic
feedback loop that actively engages users. This process leverages the
exceptional reasoning capabilities of modern LLMs. We explore diverse content
representations within the simulator, including text-based, multimodal, and
semantic ID modeling, and discuss how multi-turn RL enables the recommender to
refine its strategies through iterative interactions. RecoWorld also supports
multi-agent simulations, allowing creators to simulate the responses of
targeted user populations. It marks an important first step toward recommender
systems where users and agents collaboratively shape personalized information
streams. We envision new interaction paradigms where "user instructs,
recommender responds," jointly optimizing user retention and engagement.

### 10. Model-agnostic post-hoc explainability for recommender systems

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Irina Ar√©valo, Jose L Salmeron
- **URL**: <http://arxiv.org/abs/2509.10245v1>
- **Submitted**: 2025-09-12 13:43:16
- **Topic Keywords**: recommend, search
- **Reason**: While this paper focuses on recommender systems, which is a related area to information retrieval, it does not directly address query understanding, ranking models, or user behavior modeling. The paper's emphasis on explainability and interpretability is also not a primary focus of your research interests. However, the use of deep learning-based recommender systems and collaborative filtering techniques may be of some interest to you.

#### Abstract
> Recommender systems often benefit from complex feature embeddings and deep
learning algorithms, which deliver sophisticated recommendations that enhance
user experience, engagement, and revenue. However, these methods frequently
reduce the interpretability and transparency of the system. In this research,
we develop a systematic application, adaptation, and evaluation of deletion
diagnostics in the recommender setting. The method compares the performance of
a model to that of a similar model trained without a specific user or item,
allowing us to quantify how that observation influences the recommender, either
positively or negatively. To demonstrate its model-agnostic nature, the
proposal is applied to both Neural Collaborative Filtering (NCF), a widely used
deep learning-based recommender, and Singular Value Decomposition (SVD), a
classical collaborative filtering technique. Experiments on the MovieLens and
Amazon Reviews datasets provide insights into model behavior and highlight the
generality of the approach across different recommendation paradigms.

### 11. Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Adnan Ahmad, Philine Kowol, Stefan Hillmann, Sebastian M√∂ller
- **URL**: <http://arxiv.org/abs/2509.10010v1>
- **Submitted**: 2025-09-12 07:10:55
- **Topic Keywords**: rag
- **Reason**: This paper focuses on dialogue understanding and multi-intent recognition using Large Language Models, which is somewhat related to your interests in Natural Language Processing (NLP) and related topics. However, it does not directly align with your primary focus on Information Retrieval (IR), query understanding, and ranking models.

#### Abstract
> In this paper, we provide an extensive analysis of multi-label intent
classification using Large Language Models (LLMs) that are open-source,
publicly available, and can be run in consumer hardware. We use the MultiWOZ
2.1 dataset, a benchmark in the dialogue system domain, to investigate the
efficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,
Mistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot
setup, giving 20 examples in the prompt with some instructions. Our approach
focuses on the differences in performance of these models across several
performance metrics by methodically assessing these models on multi-label
intent classification tasks. Additionally, we compare the performance of the
instruction-based fine-tuning approach with supervised learning using the
smaller transformer model BertForSequenceClassification as a baseline. To
evaluate the performance of the models, we use evaluation metrics like
accuracy, precision, and recall as well as micro, macro, and weighted F1 score.
We also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1
outperforms two other generative models on 11 intent classes out of 14 in terms
of F-Score, with a weighted average of 0.50. It also has relatively lower
Humming Loss and higher Jaccard Similarity, making it the winning model in the
few-shot setting. We find BERT based supervised classifier having superior
performance compared to the best performing few-shot generative LLM. The study
provides a framework for small open-source LLMs in detecting complex
multi-intent dialogues, enhancing the Natural Language Understanding aspect of
task-oriented chatbots.

### 12. Unsupervised Hallucination Detection by Inspecting Reasoning Processes

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Ponhvoan Srey, Xiaobao Wu, Anh Tuan Luu
- **URL**: <http://arxiv.org/abs/2509.10004v1>
- **Submitted**: 2025-09-12 06:58:17
- **Comment**: To appear in EMNLP 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on unsupervised hallucination detection in large language models, which is somewhat related to information retrieval and NLP. However, the primary focus on factual correctness and truthfulness verification does not directly align with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is limited to the intersection of NLP and IR, but it does not address the user's core research themes.

#### Abstract
> Unsupervised hallucination detection aims to identify hallucinated content
generated by large language models (LLMs) without relying on labeled data.
While unsupervised methods have gained popularity by eliminating
labor-intensive human annotations, they frequently rely on proxy signals
unrelated to factual correctness. This misalignment biases detection probes
toward superficial or non-truth-related aspects, limiting generalizability
across datasets and scenarios. To overcome these limitations, we propose IRIS,
an unsupervised hallucination detection framework, leveraging internal
representations intrinsic to factual correctness. IRIS prompts the LLM to
carefully verify the truthfulness of a given statement, and obtain its
contextualized embedding as informative features for training. Meanwhile, the
uncertainty of each response is considered a soft pseudolabel for truthfulness.
Experimental results demonstrate that IRIS consistently outperforms existing
unsupervised methods. Our approach is fully unsupervised, computationally low
cost, and works well even with few training data, making it suitable for
real-time detection.

### 13. Error Analysis in a Modular Meeting Transcription System

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Peter Vieting, Simon Berger, Thilo von Neumann, Christoph Boeddeker, Ralf Schl√ºter, Reinhold Haeb-Umbach
- **URL**: <http://arxiv.org/abs/2509.10143v1>
- **Submitted**: 2025-09-12 11:10:38
- **Comment**: Accepted at ITG Conference on Speech Communication 2025
- **Topic Keywords**: relevance, acl
- **Reason**: This paper appears to be focused on meeting transcription, speech separation, and voice activity detection, which are not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some form of data analysis, the context and methodology seem to be specific to the meeting transcription domain and do not align with the user's interests in query understanding, ranking models, or user behavior modeling.

#### Abstract
> Meeting transcription is a field of high relevance and remarkable progress in
recent years. Still, challenges remain that limit its performance. In this
work, we extend a previously proposed framework for analyzing leakage in speech
separation with proper sensitivity to temporal locality. We show that there is
significant leakage to the cross channel in areas where only the primary
speaker is active. At the same time, the results demonstrate that this does not
affect the final performance much as these leaked parts are largely ignored by
the voice activity detection (VAD). Furthermore, different segmentations are
compared showing that advanced diarization approaches are able to reduce the
gap to oracle segmentation by a third compared to a simple energy-based VAD. We
additionally reveal what factors contribute to the remaining difference. The
results represent state-of-the-art performance on LibriCSS among systems that
train the recognition module on LibriSpeech data only.

### 14. Arabic Large Language Models for Medical Text Generation

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Abdulrahman Allam, Seif Ahmed, Ali Hamdi, Ammar Mohammed
- **URL**: <http://arxiv.org/abs/2509.10095v1>
- **Submitted**: 2025-09-12 09:37:26
- **Comment**: Published in 2025 4th International Conference on Computer
  Technologies (ICCTech)
- **Topic Keywords**: rag, recommend, search
- **Reason**: This paper focuses on Arabic Large Language Models for Medical Text Generation, which is not directly related to Information Retrieval, Search technologies, or your other areas of interest. While it involves NLP and generative models, the context is medical text generation and hospital management, which is not a central match to your research themes.

#### Abstract
> Efficient hospital management systems (HMS) are critical worldwide to address
challenges such as overcrowding, limited resources, and poor availability of
urgent health care. Existing methods often lack the ability to provide
accurate, real-time medical advice, particularly for irregular inputs and
underrepresented languages. To overcome these limitations, this study proposes
an approach that fine-tunes large language models (LLMs) for Arabic medical
text generation. The system is designed to assist patients by providing
accurate medical advice, diagnoses, drug recommendations, and treatment plans
based on user input. The research methodology required the collection of a
unique dataset from social media platforms, capturing real-world medical
conversations between patients and doctors. The dataset, which includes patient
complaints together with medical advice, was properly cleaned and preprocessed
to account for multiple Arabic dialects. Fine-tuning state-of-the-art
generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2
Medium, optimized the system's ability to generate reliable medical text.
Results from evaluations indicate that the fine-tuned Mistral-7B model
outperformed the other models, achieving average BERT (Bidirectional Encoder
Representations from Transformers) Score values in precision, recall, and
F1-scores of 68.5\%, 69.08\%, and 68.5\%, respectively. Comparative
benchmarking and qualitative assessments validate the system's ability to
produce coherent and relevant medical replies to informal input. This study
highlights the potential of generative artificial intelligence (AI) in
advancing HMS, offering a scalable and adaptable solution for global healthcare
challenges, especially in linguistically and culturally diverse environments.

### 15. Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Dongmin Choi, Woojung Song, Jongwook Han, Eun-Ju Lee, Yohan Jo
- **URL**: <http://arxiv.org/abs/2509.10078v1>
- **Submitted**: 2025-09-12 09:14:42
- **Comment**: 17 pages, 4 figures
- **Topic Keywords**: queries, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. It focuses on the application of established psychometric questionnaires to Large Language Models, which is outside your primary areas of interest.

#### Abstract
> Researchers have applied established psychometric questionnaires (e.g., BFI,
PVQ) to measure the personality traits and values reflected in the responses of
Large Language Models (LLMs). However, concerns have been raised about applying
these human-designed questionnaires to LLMs. One such concern is their lack of
ecological validity--the extent to which survey questions adequately reflect
and resemble real-world contexts in which LLMs generate texts in response to
user queries. However, it remains unclear how established questionnaires and
ecologically valid questionnaires differ in their outcomes, and what insights
these differences may provide. In this paper, we conduct a comprehensive
comparative analysis of the two types of questionnaires. Our analysis reveals
that established questionnaires (1) yield substantially different profiles of
LLMs from ecologically valid ones, deviating from the psychological
characteristics expressed in the context of user queries, (2) suffer from
insufficient items for stable measurement, (3) create misleading impressions
that LLMs possess stable constructs, and (4) yield exaggerated profiles for
persona-prompted LLMs. Overall, our work cautions against the use of
established psychological questionnaires for LLMs. Our code will be released
upon publication.

### 16. MatSKRAFT: A framework for large-scale materials knowledge extraction from scientific tables

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Kausik Hira, Mohd Zaki, Mausam, N. M. Anoop Krishnan
- **URL**: <http://arxiv.org/abs/2509.10448v1>
- **Submitted**: 2025-09-12 17:55:11
- **Topic Keywords**: rag, search
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves data extraction and analysis, the focus is on materials science and scientific knowledge extraction, which is not a central match to your research themes.

#### Abstract
> Scientific progress increasingly depends on synthesizing knowledge across
vast literature, yet most experimental data remains trapped in semi-structured
formats that resist systematic extraction and analysis. Here, we present
MatSKRAFT, a computational framework that automatically extracts and integrates
materials science knowledge from tabular data at unprecedented scale. Our
approach transforms tables into graph-based representations processed by
constraint-driven GNNs that encode scientific principles directly into model
architecture. MatSKRAFT significantly outperforms state-of-the-art large
language models, achieving F1 scores of 88.68 for property extraction and 71.35
for composition extraction, while processing data $19$-$496\times$ faster than
them (compared to the slowest and the fastest models, respectively) with modest
hardware requirements. Applied to nearly 69,000 tables from more than 47,000
research publications, we construct a comprehensive database containing over
535,000 entries, including 104,000 compositions that expand coverage beyond
major existing databases, pending manual validation. This systematic approach
reveals previously overlooked materials with distinct property combinations and
enables data-driven discovery of composition-property relationships forming the
cornerstone of materials and scientific discovery.

### 17. Population-Aligned Persona Generation for LLM-based Social Simulation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Zhengyu Hu, Zheyuan Xiao, Max Xiong, Yuxuan Lei, Tianfu Wang, Jianxun Lian, Kaize Ding, Ziang Xiao, Nicholas Jing Yuan, Xing Xie
- **URL**: <http://arxiv.org/abs/2509.10127v1>
- **Submitted**: 2025-09-12 10:43:47
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on persona generation for social simulation using large language models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context is more aligned with social science and simulation, rather than search or retrieval.

#### Abstract
> Recent advances in large language models (LLMs) have enabled human-like
social simulations at unprecedented scale and fidelity, offering new
opportunities for computational social science. A key challenge, however, is
the construction of persona sets that authentically represent the diversity and
distribution of real-world populations. Most existing LLM-based social
simulation studies focus primarily on designing agentic frameworks and
simulation environments, often overlooking the complexities of persona
generation and the potential biases introduced by unrepresentative persona
sets. In this paper, we propose a systematic framework for synthesizing
high-quality, population-aligned persona sets for LLM-driven social simulation.
Our approach begins by leveraging LLMs to generate narrative personas from
long-term social media data, followed by rigorous quality assessment to filter
out low-fidelity profiles. We then apply importance sampling to achieve global
alignment with reference psychometric distributions, such as the Big Five
personality traits. To address the needs of specific simulation contexts, we
further introduce a task-specific module that adapts the globally aligned
persona set to targeted subpopulations. Extensive experiments demonstrate that
our method significantly reduces population-level bias and enables accurate,
flexible social simulation for a wide range of research and policy
applications.

### 18. Large Language Models Meet Legal Artificial Intelligence: A Survey

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Zhitian Hou, Zihan Ye, Nanli Zeng, Tianyong Hao, Kun Zeng
- **URL**: <http://arxiv.org/abs/2509.09969v1>
- **Submitted**: 2025-09-12 05:08:11
- **Topic Keywords**: rag, search
- **Reason**: This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves Large Language Models, which are a subset of NLP, the focus is on Legal Artificial Intelligence, which is not a primary area of interest for the user.

#### Abstract
> Large Language Models (LLMs) have significantly advanced the development of
Legal Artificial Intelligence (Legal AI) in recent years, enhancing the
efficiency and accuracy of legal tasks. To advance research and applications of
LLM-based approaches in legal domain, this paper provides a comprehensive
review of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and
also gather 15 benchmarks and 29 datasets to evaluate different legal
capabilities. Additionally, we analyse the challenges and discuss future
directions for LLM-based approaches in the legal domain. We hope this paper
provides a systematic introduction for beginners and encourages future research
in this field. Resources are available at
https://github.com/ZhitianHou/LLMs4LegalAI.

### 19. Pragmatic Frames Evoked by Gestures: A FrameNet Brasil Approach to Multimodality in Turn Organization

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Helen de Andrade Abreu, Tiago Timponi Torrent, Ely Edison da Silva Matos
- **URL**: <http://arxiv.org/abs/2509.09804v1>
- **Submitted**: 2025-09-11 19:14:57
- **Comment**: Paper submitted to Language Sciences Journal
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on multimodal conversational turn organization and gesture analysis, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> This paper proposes a framework for modeling multimodal conversational turn
organization via the proposition of correlations between language and
interactive gestures, based on analysis as to how pragmatic frames are
conceptualized and evoked by communicators. As a means to provide evidence for
the analysis, we developed an annotation methodology to enrich a multimodal
dataset (annotated for semantic frames) with pragmatic frames modeling
conversational turn organization. Although conversational turn organization has
been studied by researchers from diverse fields, the specific strategies,
especially gestures used by communicators, had not yet been encoded in a
dataset that can be used for machine learning. To fill this gap, we enriched
the Frame2 dataset with annotations of gestures used for turn organization. The
Frame2 dataset features 10 episodes from the Brazilian TV series Pedro Pelo
Mundo annotated for semantic frames evoked in both video and text. This dataset
allowed us to closely observe how communicators use interactive gestures
outside a laboratory, in settings, to our knowledge, not previously recorded in
related literature. Our results have confirmed that communicators involved in
face-to-face conversation make use of gestures as a tool for passing, taking
and keeping conversational turns, and also revealed variations of some gestures
that had not been documented before. We propose that the use of these gestures
arises from the conceptualization of pragmatic frames, involving mental spaces,
blending and conceptual metaphors. In addition, our data demonstrate that the
annotation of pragmatic frames contributes to a deeper understanding of human
cognition and language.

### 20. HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Brennen Hill
- **URL**: <http://arxiv.org/abs/2509.09801v1>
- **Submitted**: 2025-09-11 19:06:46
- **Topic Keywords**: rank, acl
- **Reason**: This paper focuses on improving the efficiency and accuracy of language model reasoning through a novel hierarchical adaptation strategy. While it involves fine-tuning a large language model, the topic is not directly related to information retrieval, search technologies, or user behavior modeling, which are the core areas of your research interests.

#### Abstract
> The adaptation of large language models (LLMs) to specialized reasoning tasks
is fundamentally constrained by computational resources. Parameter-Efficient
Fine-Tuning (PEFT) methods have emerged as a powerful solution, yet the
landscape of these techniques is diverse, with distinct methods operating in
either the model's weight space or its representation space. This paper
investigates the hypothesis that a synergistic combination of these paradigms
can unlock superior performance and efficiency. We introduce HEFT (Hierarchical
Efficient Fine-Tuning), a novel hierarchical adaptation strategy that composes
two distinct PEFT methods in a coarse-to-fine manner: first, a broad,
foundational adaptation in the weight space using Low-Rank Adaptation (LoRA),
followed by a precise, surgical refinement of internal activations using
Representation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a
Llama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential
reasoning. Our results reveal a profound synergistic effect. A model fine-tuned
for only three epochs with our HEFT strategy achieves an accuracy of 85.17\%,
exceeding the performance of models trained for 20 epochs with either LoRA-only
(85.05\%) or ReFT-only (83.36\%) methodologies. This work demonstrates that the
thoughtful composition of PEFT methods is a potent algorithmic innovation,
offering a more efficient and effective path toward advancing the reasoning
capabilities of language models. By achieving superior results with a fraction
of the computational budget, our findings present a principled approach to
overcoming the obstacles inherent in adapting large-scale models for complex
cognitive tasks.

### 21. Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Alva West, Yixuan Weng, Minjun Zhu, Zhen Lin, Yue Zhang
- **URL**: <http://arxiv.org/abs/2509.10401v1>
- **Submitted**: 2025-09-12 16:51:15
- **Topic Keywords**: rag
- **Reason**: This paper focuses on causal inference and failure attribution in multi-agent systems, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.

### 22. Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing Generative AI with Synthetic Patient Records

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Abdulrahman Allam, Seif Ahmed, Ali Hamdi, Khaled Shaban
- **URL**: <http://arxiv.org/abs/2509.10108v1>
- **Submitted**: 2025-09-12 09:58:11
- **Comment**: Accepted in AICCSA 2025
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Arabic medical chatbots and generative AI, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve NLP, the specific domain and application are quite different from your areas of focus.

#### Abstract
> The development of medical chatbots in Arabic is significantly constrained by
the scarcity of large-scale, high-quality annotated datasets. While prior
efforts compiled a dataset of 20,000 Arabic patient-doctor interactions from
social media to fine-tune large language models (LLMs), model scalability and
generalization remained limited. In this study, we propose a scalable synthetic
data augmentation strategy to expand the training corpus to 100,000 records.
Using advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated
80,000 contextually relevant and medically coherent synthetic question-answer
pairs grounded in the structure of the original dataset. These synthetic
samples were semantically filtered, manually validated, and integrated into the
training pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,
and evaluated their performance using BERTScore metrics and expert-driven
qualitative assessments. To further analyze the effectiveness of synthetic
sources, we conducted an ablation study comparing ChatGPT-4o and
Gemini-generated data independently. The results showed that ChatGPT-4o data
consistently led to higher F1-scores and fewer hallucinations across all
models. Overall, our findings demonstrate the viability of synthetic
augmentation as a practical solution for enhancing domain-specific language
models in-low resource medical NLP, paving the way for more inclusive,
scalable, and accurate Arabic healthcare chatbot systems.

### 23. !MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for Readability Assessment

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Mohamed Basem, Mohamed Younes, Seif Ahmed, Abdelrahman Moustafa
- **URL**: <http://arxiv.org/abs/2509.10040v1>
- **Submitted**: 2025-09-12 08:08:45
- **Comment**: 10 Pages , 8 figures , ArabicNLP 2025 , Co-located with EMNLP 2025
- **Topic Keywords**: ctr
- **Reason**: This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. Although it involves transformer models and fine-tuning, the focus is on readability assessment in Arabic, which is not a primary area of interest for the user.

#### Abstract
> We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained
Arabic readability assessment, achieving first place in six of six tracks. Our
approach is a confidence-weighted ensemble of four complementary transformer
models (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with
distinct loss functions to capture diverse readability signals. To tackle
severe class imbalance and data scarcity, we applied weighted training,
advanced preprocessing, SAMER corpus relabeling with our strongest model, and
synthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level
samples. A targeted post-processing step corrected prediction distribution
skew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system
reached 87.5 percent QWK at the sentence level and 87.4 percent at the document
level, demonstrating the power of model and loss diversity, confidence-informed
fusion, and intelligent augmentation for robust Arabic readability prediction.

### 24. Benchmark of stylistic variation in LLM-generated texts

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Ji≈ô√≠ Miliƒçka, Anna Marklov√°, V√°clav Cvrƒçek
- **URL**: <http://arxiv.org/abs/2509.10179v1>
- **Submitted**: 2025-09-12 12:12:20
- **Topic Keywords**: rank
- **Reason**: This paper focuses on the stylistic variation in LLM-generated texts, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing, particularly in areas requiring deep semantic understanding and real-time relevance optimization.

#### Abstract
> This study investigates the register variation in texts written by humans and
comparable texts produced by large language models (LLMs). Biber's
multidimensional analysis (MDA) is applied to a sample of human-written texts
and AI-created texts generated to be their counterparts to find the dimensions
of variation in which LLMs differ most significantly and most systematically
from humans. As textual material, a new LLM-generated corpus AI-Brown is used,
which is comparable to BE-21 (a Brown family corpus representing contemporary
British English). Since all languages except English are underrepresented in
the training data of frontier LLMs, similar analysis is replicated on Czech
using AI-Koditex corpus and Czech multidimensional model. Examined were 16
frontier models in various settings and prompts, with emphasis placed on the
difference between base models and instruction-tuned models. Based on this, a
benchmark is created through which models can be compared with each other and
ranked in interpretable dimensions.

### 25. Prominence-aware automatic speech recognition for conversational speech

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Julian Linke, Barbara Schuppler
- **URL**: <http://arxiv.org/abs/2509.10116v1>
- **Submitted**: 2025-09-12 10:18:38
- **Topic Keywords**: search
- **Reason**: This paper focuses on automatic speech recognition and prosody-enhanced ASR, which is outside the user's core research themes in Information Retrieval and Search technologies. While it involves NLP, the topic is not directly related to query understanding, ranking models, or user behavior modeling.

#### Abstract
> This paper investigates prominence-aware automatic speech recognition (ASR)
by combining prominence detection and speech recognition for conversational
Austrian German. First, prominence detectors were developed by fine-tuning
wav2vec2 models to classify word-level prominence. The detector was then used
to automatically annotate prosodic prominence in a large corpus. Based on those
annotations, we trained novel prominence-aware ASR systems that simultaneously
transcribe words and their prominence levels. The integration of prominence
information did not change performance compared to our baseline ASR system,
while reaching a prominence detection accuracy of 85.53% for utterances where
the recognized word sequence was correct. This paper shows that
transformer-based models can effectively encode prosodic information and
represents a novel contribution to prosody-enhanced ASR, with potential
applications for linguistic research and prosody-informed dialogue systems.

### 26. VARCO-VISION-2.0 Technical Report

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Young-rok Cha, Jeongho Ju, SunYoung Park, Jong-Hyeon Lee, Younghyun Yu, Youngjune Kim
- **URL**: <http://arxiv.org/abs/2509.10105v1>
- **Submitted**: 2025-09-12 09:55:56
- **Comment**: 19 pages, 1 figure, 14 tables. Technical report for VARCO-VISION-2.0,
  a Korean-English bilingual VLM in 14B and 1.7B variants. Key features:
  multi-image understanding, OCR with text localization, improved Korean
  capabilities
- **Topic Keywords**: korea
- **Reason**: This paper focuses on vision-language models, which is a related but distinct area from information retrieval and search technologies. While it involves multimodal alignment and understanding, it does not directly address query understanding, ranking models, or user behavior modeling, making it less relevant to your core research interests.

#### Abstract
> We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model
(VLM) for Korean and English with improved capabilities compared to the
previous model VARCO-VISION-14B. The model supports multi-image understanding
for complex inputs such as documents, charts, and tables, and delivers
layoutaware OCR by predicting both textual content and its spatial location.
Trained with a four-stage curriculum with memory-efficient techniques, the
model achieves enhanced multimodal alignment, while preserving core language
abilities and improving safety via preference optimization. Extensive benchmark
evaluations demonstrate strong spatial grounding and competitive results for
both languages, with the 14B model achieving 8th place on the OpenCompass VLM
leaderboard among models of comparable scale. Alongside the 14B-scale model, we
release a 1.7B version optimized for on-device deployment. We believe these
models advance the development of bilingual VLMs and their practical
applications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a
full-scale 14B model and a lightweight 1.7B model.

### 27. CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Guixian Xu, Zeli Su, Ziyin Zhang, Jianing Liu, XU Han, Ting Zhang, Yushuang Dong
- **URL**: <http://arxiv.org/abs/2509.09990v1>
- **Submitted**: 2025-09-12 06:18:44
- **Topic Keywords**: search
- **Reason**: This paper focuses on headline generation for minority languages in China, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves NLP, the specific task and domain are quite different from the user's interests.

#### Abstract
> Minority languages in China, such as Tibetan, Uyghur, and Traditional
Mongolian, face significant challenges due to their unique writing systems,
which differ from international standards. This discrepancy has led to a severe
lack of relevant corpora, particularly for supervised tasks like headline
generation. To address this gap, we introduce a novel dataset, Chinese Minority
Headline Generation (CMHG), which includes 100,000 entries for Tibetan, and
50,000 entries each for Uyghur and Mongolian, specifically curated for headline
generation tasks. Additionally, we propose a high-quality test set annotated by
native speakers, designed to serve as a benchmark for future research in this
domain. We hope this dataset will become a valuable resource for advancing
headline generation in Chinese minority languages and contribute to the
development of related benchmarks.

### 28. Emulating Public Opinion: A Proof-of-Concept of AI-Generated Synthetic Survey Responses for the Chilean Case

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Basti√°n Gonz√°lez-Bustamante, Nando Verelst, Carla Cisternas
- **URL**: <http://arxiv.org/abs/2509.09871v1>
- **Submitted**: 2025-09-11 21:43:59
- **Comment**: Working paper: 18 pages, 4 tables, 2 figures
- **Topic Keywords**: search
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing, as it focuses on emulating public opinion using AI-generated synthetic survey responses. While it involves Large Language Models, the context and application are distinct from your areas of focus.

#### Abstract
> Large Language Models (LLMs) offer promising avenues for methodological and
applied innovations in survey research by using synthetic respondents to
emulate human answers and behaviour, potentially mitigating measurement and
representation errors. However, the extent to which LLMs recover aggregate item
distributions remains uncertain and downstream applications risk reproducing
social stereotypes and biases inherited from training data. We evaluate the
reliability of LLM-generated synthetic survey responses against ground-truth
human responses from a Chilean public opinion probabilistic survey.
Specifically, we benchmark 128 prompt-model-question triplets, generating
189,696 synthetic profiles, and pool performance metrics (i.e., accuracy,
precision, recall, and F1-score) in a meta-analysis across 128
question-subsample pairs to test for biases along key sociodemographic
dimensions. The evaluation spans OpenAI's GPT family and o-series reasoning
models, as well as Llama and Qwen checkpoints. Three results stand out. First,
synthetic responses achieve excellent performance on trust items (F1-score and
accuracy > 0.90). Second, GPT-4o, GPT-4o-mini and Llama 4 Maverick perform
comparably on this task. Third, synthetic-human alignment is highest among
respondents aged 45-59. Overall, LLM-based synthetic samples approximate
responses from a probabilistic sample, though with substantial item-level
heterogeneity. Capturing the full nuance of public opinion remains challenging
and requires careful calibration and additional distributional tests to ensure
algorithmic fidelity and reduce errors.

### 29. Linguistic trajectories of bipolar disorder on social media

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Laurin Plank, Armin Zlomuzica
- **URL**: <http://arxiv.org/abs/2509.10035v1>
- **Submitted**: 2025-09-12 08:02:38
- **Comment**: Pre-print
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on analyzing linguistic patterns in social media to diagnose and monitor mental health conditions, which is outside your areas of expertise.

#### Abstract
> Language provides valuable markers of affective disorders such as bipolar
disorder (BD), yet clinical assessments remain limited in scale. In response,
analyses of social media (SM) language have gained prominence due to their high
temporal resolution and longitudinal scope. Here, we introduce a method to
determine the timing of users' diagnoses and apply it to study language
trajectories from 3 years before to 21 years after BD diagnosis - contrasted
with uses reporting unipolar depression (UD) and non-affected users (HC). We
show that BD diagnosis is accompanied by pervasive linguistic alterations
reflecting mood disturbance, psychiatric comorbidity, substance abuse,
hospitalization, medical comorbidities, unusual thought content, and
disorganized thought. We further observe recurring mood-related language
changes across two decades after the diagnosis, with a pronounced 12-month
periodicity suggestive of seasonal mood episodes. Finally, trend-level evidence
suggests an increased periodicity in users estimated to be female. In sum, our
findings provide evidence for language alterations in the acute and chronic
phase of BD. This validates and extends recent efforts leveraging SM for
scalable monitoring of mental health.

---

