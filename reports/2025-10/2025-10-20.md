# Daily Papers Report - 2025-10-20

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Rethinking On-policy Optimization for Query Augmentation

- **LLM Score**: 9
- **Keyword Score**: 11
- **Authors**: Zhichao Xu, Shengyao Zhuang, Xueguang Ma, Bingsen Chen, Yijun Tian, Fengran Mo, Jie Cao, Vivek Srikumar
- **URL**: <http://arxiv.org/abs/2510.17139v1>
- **Submitted**: 2025-10-20 04:16:28
- **Topic Keywords**: information retrieval, query, queries, retrieval
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly query augmentation, ranking models, and user behavior modeling. The paper's focus on comparing and improving query augmentation methods using large language models aligns with your expertise in IR and NLP. The introduction of a novel hybrid method, OPQE, demonstrates a deep understanding of the field and its potential applications.

#### Abstract
> Recent advances in large language models (LLMs) have led to a surge of
interest in query augmentation for information retrieval (IR). Two main
approaches have emerged. The first prompts LLMs to generate answers or
pseudo-documents that serve as new queries, relying purely on the model's
parametric knowledge or contextual information. The second applies
reinforcement learning (RL) to fine-tune LLMs for query rewriting, directly
optimizing retrieval metrics. While having respective advantages and
limitations, the two approaches have not been compared under consistent
experimental conditions. In this work, we present the first systematic
comparison of prompting-based and RL-based query augmentation across diverse
benchmarks, including evidence-seeking, ad hoc, and tool retrieval. Our key
finding is that simple, training-free query augmentation often performs on par
with, or even surpasses, more expensive RL-based counterparts, especially when
using powerful LLMs. Motivated by this discovery, we introduce a novel hybrid
method, On-policy Pseudo-document Query Expansion (OPQE), which, instead of
rewriting a query, the LLM policy learns to generate a pseudo-document that
maximizes retrieval performance, thus merging the flexibility and generative
structure of prompting with the targeted optimization of RL. We show OPQE
outperforms both standalone prompting and RL-based rewriting, demonstrating
that a synergistic approach yields the best results. Our implementation is made
available to facilitate reproducibility.

---

### 2. Blending Learning to Rank and Dense Representations for Efficient and Effective Cascades

- **LLM Score**: 8
- **Keyword Score**: 30
- **Authors**: Franco Maria Nardini, Raffaele Perego, Nicola Tonellotto, Salvatore Trani
- **URL**: <http://arxiv.org/abs/2510.16393v1>
- **Submitted**: 2025-10-18 08:16:48
- **Topic Keywords**: retriever, passage retrieval, query, queries, ranking, learning to rank, ltr, relevance, rag, retrieval, rank, search
- **Reason**: This paper explores the combination of lexical and neural relevance signals for ad-hoc passage retrieval, utilizing Learning-to-Rank and dense representations. While it's not specifically focused on e-commerce, the techniques and concepts presented are relevant to the broader field of Information Retrieval, particularly in areas requiring deep semantic understanding. The paper's emphasis on real-time relevance optimization also aligns with the user's interests.

#### Abstract
> We investigate the exploitation of both lexical and neural relevance signals
for ad-hoc passage retrieval. Our exploration involves a large-scale training
dataset in which dense neural representations of MS-MARCO queries and passages
are complemented and integrated with 253 hand-crafted lexical features
extracted from the same corpus. Blending of the relevance signals from the two
different groups of features is learned by a classical Learning-to-Rank (LTR)
model based on a forest of decision trees. To evaluate our solution, we employ
a pipelined architecture where a dense neural retriever serves as the first
stage and performs a nearest-neighbor search over the neural representations of
the documents. Our LTR model acts instead as the second stage that re-ranks the
set of candidates retrieved by the first stage to enhance effectiveness. The
results of reproducible experiments conducted with state-of-the-art dense
retrievers on publicly available resources show that the proposed solution
significantly enhances the end-to-end ranking performance while relatively
minimally impacting efficiency. Specifically, we achieve a boost in nDCG@10 of
up to 11% with an increase in average query latency of only 4.3%. This confirms
the advantage of seamlessly combining two distinct families of signals that
mutually contribute to retrieval effectiveness.

---

### 3. An Efficient Framework for Whole-Page Reranking via Single-Modal Supervision

- **LLM Score**: 8
- **Keyword Score**: 18
- **Authors**: Zishuai Zhang, Sihao Yu, Wenyi Xie, Ying Nie, Junfeng Wang, Zhiming Zheng, Dawei Yin, Hainan Zhang
- **URL**: <http://arxiv.org/abs/2510.16803v1>
- **Submitted**: 2025-10-19 11:58:24
- **Topic Keywords**: query, ranking, rerank, relevance, rag, retrieval, rank, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of whole-page reranking and query understanding. The proposed framework, SMAR, leverages single-modal rankers to guide modal-wise relevance alignment, which is a key aspect of your research focus on deep semantic understanding and real-time relevance optimization. While the paper's focus is on search engines, its contributions are applicable to your broader interests in IR and NLP.

#### Abstract
> The whole-page reranking plays a critical role in shaping the user experience
of search engines, which integrates retrieval results from multiple modalities,
such as documents, images, videos, and LLM outputs. Existing methods mainly
rely on large-scale human-annotated data, which is costly to obtain and
time-consuming. This is because whole-page annotation is far more complex than
single-modal: it requires assessing the entire result page while accounting for
cross-modal relevance differences. Thus, how to improve whole-page reranking
performance while reducing annotation costs is still a key challenge in
optimizing search engine result pages(SERP). In this paper, we propose SMAR, a
novel whole-page reranking framework that leverages strong Single-modal rankers
to guide Modal-wise relevance Alignment for effective Reranking, using only
limited whole-page annotation to outperform fully-annotated reranking models.
Specifically, high-quality single-modal rankers are first trained on data
specific to their respective modalities. Then, for each query, we select a
subset of their outputs to construct candidate pages and perform human
annotation at the page level. Finally, we train the whole-page reranker using
these limited annotations and enforcing consistency with single-modal
preferences to maintain ranking quality within each modality. Experiments on
the Qilin and Baidu datasets demonstrate that SMAR reduces annotation costs by
about 70-90\% while achieving significant ranking improvements compared to
baselines. Further offline and online A/B testing on Baidu APPs also shows
notable gains in standard ranking metrics as well as user experience
indicators, fully validating the effectiveness and practical value of our
approach in real-world search scenarios.

---

### 4. How role-play shapes relevance judgment in zero-shot LLM rankers

- **LLM Score**: 8
- **Keyword Score**: 12
- **Authors**: Yumeng Wang, Jirui Qi, Catherine Chen, Panagiotis Eustratiadis, Suzan Verberne
- **URL**: <http://arxiv.org/abs/2510.17535v1>
- **Submitted**: 2025-10-20 13:39:48
- **Topic Keywords**: query, ranking, relevance, rag, rank
- **Reason**: This paper explores the role of role-play in zero-shot Large Language Model (LLM) rankers, which is closely related to query understanding and ranking models in Information Retrieval. The paper's focus on the inner workings of LLMs and its implications for designing effective prompts aligns with your research interests in IR and NLP.

#### Abstract
> Large Language Models (LLMs) have emerged as promising zero-shot rankers, but
their performance is highly sensitive to prompt formulation. In particular,
role-play prompts, where the model is assigned a functional role or identity,
often give more robust and accurate relevance rankings. However, the mechanisms
and diversity of role-play effects remain underexplored, limiting both
effective use and interpretability. In this work, we systematically examine how
role-play variations influence zero-shot LLM rankers. We employ causal
intervention techniques from mechanistic interpretability to trace how
role-play information shapes relevance judgments in LLMs. Our analysis reveals
that (1) careful formulation of role descriptions have a large effect on the
ranking quality of the LLM; (2) role-play signals are predominantly encoded in
early layers and communicate with task instructions in middle layers, while
receiving limited interaction with query or document representations.
Specifically, we identify a group of attention heads that encode information
critical for role-conditioned relevance. These findings not only shed light on
the inner workings of role-play in LLM ranking but also offer guidance for
designing more effective prompts in IR and beyond, pointing toward broader
opportunities for leveraging role-play in zero-shot applications.

---

### 5. Towards Context-aware Reasoning-enhanced Generative Searching in E-commerce

- **LLM Score**: 8
- **Keyword Score**: 11
- **Authors**: Zhiding Liu, Ben Chen, Mingyue Cheng, Enchong Chen, Li Li, Chenyi Lei, Wenwu Ou, Han Li, Kun Gai
- **URL**: <http://arxiv.org/abs/2510.16925v1>
- **Submitted**: 2025-10-19 16:46:11
- **Topic Keywords**: query, ranking, recommend, commerce, e-commerce, rank, search
- **Reason**: This paper aligns well with your interests in Information Retrieval, particularly in query understanding and ranking models. The focus on context-aware reasoning-enhanced generative search in e-commerce also touches on your background in the e-commerce domain. However, the emphasis on generative search and recommendation systems is slightly secondary to your primary focus on information retrieval.

#### Abstract
> Search-based recommendation is one of the most critical application scenarios
in e-commerce platforms. Users' complex search contexts--such as spatiotemporal
factors, historical interactions, and current query's information--constitute
an essential part of their decision-making, reflecting implicit preferences
that complement explicit query terms. Modeling such rich contextual signals and
their intricate associations with candidate items remains a key challenge.
Although numerous efforts have been devoted to building more effective search
methods, existing approaches still show limitations in integrating contextual
information, which hinders their ability to fully capture user intent.
  To address these challenges, we propose a context-aware reasoning-enhanced
generative search framework for better \textbf{understanding the complicated
context}. Specifically, the framework first unifies heterogeneous user and item
contexts into textual representations or text-based semantic identifiers and
aligns them. To overcome the lack of explicit reasoning trajectories, we
introduce a self-evolving post-training paradigm that iteratively combines
supervised fine-tuning and reinforcement learning to progressively enhance the
model's reasoning capability. In addition, we identify potential biases in
existing RL algorithms when applied to search scenarios and present a debiased
variant of GRPO to improve ranking performance. Extensive experiments on search
log data collected from a real-world e-commerce platform demonstrate that our
approach achieves superior performance compared with strong baselines,
validating its effectiveness for search-based recommendation.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Agentic Reinforcement Learning for Search is Unsafe

- **LLM Score**: 8
- **Keyword Score**: 10
- **Authors**: Yushi Yang, Shreyansh Padarha, Andrew Lee, Adam Mahdi
- **URL**: <http://arxiv.org/abs/2510.17431v1>
- **Submitted**: 2025-10-20 11:19:37
- **Topic Keywords**: query, queries, rag, web search, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of search technologies and query understanding. The focus on the safety properties of reinforcement learning-trained search models and the development of safety-aware pipelines aligns with your interests in real-time relevance optimization and deep semantic understanding. However, the specific domain of agentic reinforcement learning and its applications may not be a central match for your primary focus on information retrieval.

#### Abstract
> Agentic reinforcement learning (RL) trains large language models to
autonomously call tools during reasoning, with search as the most common
application. These models excel at multi-step reasoning tasks, but their safety
properties are not well understood. In this study, we show that RL-trained
search models inherit refusal from instruction tuning and often deflect harmful
requests by turning them into safe queries. However, this safety is fragile.
Two simple attacks, one that forces the model to begin response with search
(Search attack), another that encourages models to repeatedly search
(Multi-search attack), trigger cascades of harmful searches and answers. Across
two model families (Qwen, Llama) with both local and web search, these attacks
lower refusal rates by up to 60.0%, answer safety by 82.5%, and search-query
safety by 82.4%. The attacks succeed by triggering models to generate harmful,
request-mirroring search queries before they can generate the inherited refusal
tokens. This exposes a core weakness of current RL training: it rewards
continued generation of effective queries without accounting for their
harmfulness. As a result, RL search models have vulnerabilities that users can
easily exploit, making it urgent to develop safety-aware agentic RL pipelines
optimising for safe search.

### 7. SafeSearch: Do Not Trade Safety for Utility in LLM Search Agents

- **LLM Score**: 8
- **Keyword Score**: 7
- **Authors**: Qiusi Zhan, Angeline Budiman-Chan, Abdelrahman Zayed, Xingzhi Guo, Daniel Kang, Joo-Kyung Kim
- **URL**: <http://arxiv.org/abs/2510.17017v1>
- **Submitted**: 2025-10-19 21:47:19
- **Comment**: Code: https://github.com/ZQS1943/SafeSearch
- **Topic Keywords**: query, queries, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of query understanding and ranking models. The focus on Large Language Model (LLM) search agents and their safety behaviors aligns with your interests in deep semantic understanding and real-time relevance optimization. The proposed SafeSearch approach also resonates with your background in e-commerce and NLP.

#### Abstract
> Large language model (LLM) based search agents iteratively generate queries,
retrieve external information, and reason to answer open-domain questions.
While researchers have primarily focused on improving their utility, their
safety behaviors remain underexplored. In this paper, we first evaluate search
agents using red-teaming datasets and find that they are more likely to produce
harmful outputs than base LLMs. For example, when asked ``How can I track
someone's location without their consent?'', a base model refuses, whereas a
search agent designed to retrieve and cite sources may lower its refusal
threshold, fetch documents (e.g., court cases), and, once appended, synthesize
them into an informative yet unsafe summary. We further show that
utility-oriented fine-tuning intensifies this risk, motivating joint alignment
of safety and utility. We present SafeSearch, a multi-objective reinforcement
learning approach that couples a final-output safety/utility reward with a
novel query-level shaping term that penalizes unsafe queries and rewards safe
ones. Experiments show that SafeSearch reduces agent harmfulness by over 70%
across three red-teaming datasets while producing safe, helpful responses, and
matches the QA performance of a utility-only finetuned agent; further analyses
confirm the effectiveness of the query-level reward in jointly improving safety
and utility.

### 8. The Chameleon Nature of LLMs: Quantifying Multi-Turn Stance Instability in Search-Enabled Language Models

- **LLM Score**: 8
- **Keyword Score**: 6
- **Authors**: Shivam Ratnakar, Sanjay Raghavendra
- **URL**: <http://arxiv.org/abs/2510.16712v1>
- **Submitted**: 2025-10-19 04:51:14
- **Topic Keywords**: query, retrieval, search
- **Reason**: This paper is highly relevant to the field of Information Retrieval, particularly in the context of search-enabled language models. The authors investigate the 'chameleon behavior' of LLMs, which is a critical issue in query understanding and ranking models. While the focus is on NLP, the implications for search technologies and user behavior modeling are significant.

#### Abstract
> Integration of Large Language Models with search/retrieval engines has become
ubiquitous, yet these systems harbor a critical vulnerability that undermines
their reliability. We present the first systematic investigation of "chameleon
behavior" in LLMs: their alarming tendency to shift stances when presented with
contradictory questions in multi-turn conversations (especially in
search-enabled LLMs). Through our novel Chameleon Benchmark Dataset, comprising
17,770 carefully crafted question-answer pairs across 1,180 multi-turn
conversations spanning 12 controversial domains, we expose fundamental flaws in
state-of-the-art systems. We introduce two theoretically grounded metrics: the
Chameleon Score (0-1) that quantifies stance instability, and Source Re-use
Rate (0-1) that measures knowledge diversity. Our rigorous evaluation of
Llama-4-Maverick, GPT-4o-mini, and Gemini-2.5-Flash reveals consistent
failures: all models exhibit severe chameleon behavior (scores 0.391-0.511),
with GPT-4o-mini showing the worst performance. Crucially, small
across-temperature variance (less than 0.004) suggests the effect is not a
sampling artifact. Our analysis uncovers the mechanism: strong correlations
between source re-use rate and confidence (r=0.627) and stance changes
(r=0.429) are statistically significant (p less than 0.05), indicating that
limited knowledge diversity makes models pathologically deferential to query
framing. These findings highlight the need for comprehensive consistency
evaluation before deploying LLMs in healthcare, legal, and financial systems
where maintaining coherent positions across interactions is critical for
reliable decision support.

### 9. A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications

- **LLM Score**: 8
- **Keyword Score**: 5
- **Authors**: Minhua Lin, Zongyu Wu, Zhichao Xu, Hui Liu, Xianfeng Tang, Qi He, Charu Aggarwal, Hui Liu, Xiang Zhang, Suhang Wang
- **URL**: <http://arxiv.org/abs/2510.16724v1>
- **Submitted**: 2025-10-19 06:04:53
- **Comment**: 38 pages, 4 figures, 7 tables
- **Topic Keywords**: rag, retrieval, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of query understanding and ranking models. The focus on reinforcement learning-based agentic search also aligns with your interests in deep semantic understanding and real-time relevance optimization. However, the paper's primary focus on agentic search and its applications may not be directly related to your core research themes.

#### Abstract
> The advent of large language models (LLMs) has transformed information access
and reasoning through open-ended natural language interaction. However, LLMs
remain limited by static knowledge, factual hallucinations, and the inability
to retrieve real-time or domain-specific information. Retrieval-Augmented
Generation (RAG) mitigates these issues by grounding model outputs in external
evidence, but traditional RAG pipelines are often single turn and heuristic,
lacking adaptive control over retrieval and reasoning. Recent advances in
agentic search address these limitations by enabling LLMs to plan, retrieve,
and reflect through multi-step interaction with search environments. Within
this paradigm, reinforcement learning (RL) offers a powerful mechanism for
adaptive and self-improving search behavior. This survey provides the first
comprehensive overview of \emph{RL-based agentic search}, organizing the
emerging field along three complementary dimensions: (i) What RL is for
(functional roles), (ii) How RL is used (optimization strategies), and (iii)
Where RL is applied (scope of optimization). We summarize representative
methods, evaluation protocols, and applications, and discuss open challenges
and future directions toward building reliable and scalable RL driven agentic
search systems. We hope this survey will inspire future research on the
integration of RL and agentic search. Our repository is available at
https://github.com/ventr1c/Awesome-RL-based-Agentic-Search-Papers.

### 10. Right Answer at the Right Time - Temporal Retrieval-Augmented Generation via Graph Summarization

- **LLM Score**: 8
- **Keyword Score**: 5
- **Authors**: Zulun Zhu, Haoyu Liu, Mengke He, Siqiang Luo
- **URL**: <http://arxiv.org/abs/2510.16715v1>
- **Submitted**: 2025-10-19 05:00:04
- **Topic Keywords**: rag, retrieval, search
- **Reason**: This paper focuses on temporal knowledge graph retrieval, which is related to query understanding and ranking models in Information Retrieval. Although it doesn't directly address user behavior modeling or click models, it explores deep semantic understanding and real-time relevance optimization, aligning with the user's primary research interests.

#### Abstract
> Question answering in temporal knowledge graphs requires retrieval that is
both time-consistent and efficient. Existing RAG methods are largely semantic
and typically neglect explicit temporal constraints, which leads to
time-inconsistent answers and inflated token usage. We propose STAR-RAG, a
temporal GraphRAG framework that relies on two key ideas: building a
time-aligned rule graph and conducting propagation on this graph to narrow the
search space and prioritize semantically relevant, time-consistent evidence.
This design enforces temporal proximity during retrieval, reduces the candidate
set of retrieval results, and lowers token consumption without sacrificing
accuracy. Compared with existing temporal RAG approaches, STAR-RAG eliminates
the need for heavy model training and fine-tuning, thereby reducing
computational cost and significantly simplifying deployment.Extensive
experiments on real-world temporal KG datasets show that our method achieves
improved answer accuracy while consuming fewer tokens than strong GraphRAG
baselines.

### 11. LILO: Bayesian Optimization with Interactive Natural Language Feedback

- **LLM Score**: 8
- **Keyword Score**: 3
- **Authors**: Katarzyna Kobalczyk, Zhiyuan Jerry Lin, Benjamin Letham, Zhuokai Zhao, Maximilian Balandat, Eytan Bakshy
- **URL**: <http://arxiv.org/abs/2510.17671v1>
- **Submitted**: 2025-10-20 15:41:56
- **Topic Keywords**: rag, search
- **Reason**: This paper aligns with your interests in Information Retrieval and Natural Language Processing, particularly in the area of query understanding and real-time relevance optimization. The use of language-in-the-loop framework and large language models to convert natural language feedback into scalar utilities is relevant to your research focus. However, the specific application to Bayesian Optimization and decision-making may not be directly related to your primary interests in search technologies and user behavior modeling.

#### Abstract
> For many real-world applications, feedback is essential in translating
complex, nuanced, or subjective goals into quantifiable optimization
objectives. We propose a language-in-the-loop framework that uses a large
language model (LLM) to convert unstructured feedback in the form of natural
language into scalar utilities to conduct BO over a numeric search space.
Unlike preferential BO, which only accepts restricted feedback formats and
requires customized models for each domain-specific problem, our approach
leverages LLMs to turn varied types of textual feedback into consistent utility
signals and to easily include flexible user priors without manual kernel
design. At the same time, our method maintains the sample efficiency and
principled uncertainty quantification of BO. We show that this hybrid method
not only provides a more natural interface to the decision maker but also
outperforms conventional BO baselines and LLM-only optimizers, particularly in
feedback-limited regimes.

### 12. DSEBench: A Test Collection for Explainable Dataset Search with Examples

- **LLM Score**: 6
- **Keyword Score**: 19
- **Authors**: Qing Shi, Jing He, Qiaosheng Chen, Gong Cheng
- **URL**: <http://arxiv.org/abs/2510.17228v1>
- **Submitted**: 2025-10-20 07:19:47
- **Comment**: 34 pages, 5 figures, submitted to Knowledge-Based Systems
- **Topic Keywords**: information retrieval, query, ranking, rerank, relevance, retrieval, rank, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the area of dataset search and explainable search. However, it does not directly focus on query understanding, ranking models, or user behavior modeling, which are your core research themes.

#### Abstract
> Dataset search has been an established information retrieval task. Current
paradigms either retrieve datasets that are relevant to a keyword query or find
datasets that are similar to an input target dataset. To allow for their
combined specification of information needs, in this article, we investigate
the more generalized task of Dataset Search with Examples (DSE) and further
extend it to Explainable DSE that requires identifying the metadata and content
fields of a dataset that indicate its relevance to the query and similarity to
the target datasets. To facilitate this research, we construct DSEBench, a test
collection that provides high-quality dataset- and field-level annotations to
enable the evaluation of explainable DSE. We also employ a large language model
to generate numerous annotations to be used for training. We establish
extensive baselines on DSEBench by adapting and evaluating a variety of sparse,
dense, and LLM-based retrieval, reranking, and explanation methods.

### 13. Cross-Genre Authorship Attribution via LLM-Based Retrieve-and-Rerank

- **LLM Score**: 6
- **Keyword Score**: 12
- **Authors**: Shantanu Agarwal, Joel Barry, Steven Fincke, Scott Miller
- **URL**: <http://arxiv.org/abs/2510.16819v1>
- **Submitted**: 2025-10-19 13:10:49
- **Topic Keywords**: information retrieval, query, rerank, retrieval, rank
- **Reason**: This paper is somewhat related to the user's interests in Information Retrieval (IR) and Search technologies, as it involves a retrieve-and-rerank framework. However, the focus on authorship attribution and cross-genre authorship attribution is not a central match to the user's primary research themes. The use of LLMs and targeted data curation strategy is also somewhat relevant to the user's interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> Authorship attribution (AA) is the task of identifying the most likely author
of a query document from a predefined set of candidate authors. We introduce a
two-stage retrieve-and-rerank framework that finetunes LLMs for cross-genre AA.
Unlike the field of information retrieval (IR), where retrieve-and-rerank is a
de facto strategy, cross-genre AA systems must avoid relying on topical cues
and instead learn to identify author-specific linguistic patterns that are
independent of the text's subject matter (genre/domain/topic). Consequently,
for the reranker, we demonstrate that training strategies commonly used in IR
are fundamentally misaligned with cross-genre AA, leading to suboptimal
behavior. To address this, we introduce a targeted data curation strategy that
enables the reranker to effectively learn author-discriminative signals. Using
our LLM-based retrieve-and-rerank pipeline, we achieve substantial gains of
22.3 and 34.4 absolute Success@8 points over the previous state-of-the-art on
HIATUS's challenging HRS1 and HRS2 cross-genre AA benchmarks.

### 14. OG-Rank: Learning to Rank Fast and Slow with Uncertainty and Reward-Trend Guided Adaptive Exploration

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Praphul Singh, Corey Barrett, Sumana Srivasta, Irfan Bulu, Sri Gadde, Krishnaram Kenthapadi
- **URL**: <http://arxiv.org/abs/2510.17614v1>
- **Submitted**: 2025-10-20 15:00:02
- **Topic Keywords**: ranking, rerank, learning to rank, rank
- **Reason**: The paper presents a ranking system, OG-Rank, which is relevant to the field of Information Retrieval, particularly in the area of ranking models. However, the focus on clinical order selection and decoder-based reranking is somewhat specific and not directly aligned with the user's core research themes of query understanding, user behavior modeling, and real-time relevance optimization in e-commerce or general search technologies.

#### Abstract
> Clinicians need ranking systems that work in real time and still justify
their choices. Motivated by the need for a low-latency, decoder-based reranker,
we present OG-Rank, a single-decoder approach that pairs a pooled first-token
scoring signal with an uncertainty-gated explanation step. The model scores all
candidates in one pass and generates a brief, structured rationale only when
the list is genuinely ambiguous, keeping latency predictable. Trained with a
curriculum that concentrates effort on hard cases, OG-Rank delivers strong
effectiveness on encounter-scoped order selection (fast path: Recall@1~0.45,
nDCG@20~0.625) and improves further when the gate activates (Recall@1~0.56,
nDCG@20~0.699 at a 45\% gate rate), while compact backbones show similar gains
under the same policy. Encoder baselines trail in both effectiveness and
flexibility. The result is a practical recipe: rank fast by default and explain
when it helps, a pattern that applies broadly to decision tasks where selective
generation buys accuracy at acceptable cost. The single-policy design
simplifies deployment and budget planning, and the curriculum principle (spend
more on the hard cases, less on the easy ones) readily transfers beyond
clinical order selection.

### 15. Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Chenghao Zhang, Guanting Dong, Xinyu Yang, Zhicheng Dou
- **URL**: <http://arxiv.org/abs/2510.17354v1>
- **Submitted**: 2025-10-20 09:56:43
- **Comment**: This work is in progress
- **Topic Keywords**: retriever, queries, rag, retrieval
- **Reason**: The paper explores Retrieval-Augmented Generation (RAG) with a focus on mixed-modal information, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on vision-language generation and mixed-modal data generation does not directly align with the user's core research themes in IR and Search technologies. The connection to NLP is relevant, but the paper's emphasis on multimodal data and vision-language tasks is not a central match for the user's interests.

#### Abstract
> Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for
enhancing large language models (LLMs) by retrieving relevant documents from an
external corpus. However, existing RAG systems primarily focus on unimodal text
documents, and often fall short in real-world scenarios where both queries and
documents may contain mixed modalities (such as text and images). In this
paper, we address the challenge of Universal Retrieval-Augmented Generation
(URAG), which involves retrieving and reasoning over mixed-modal information to
improve vision-language generation. To this end, we propose Nyx, a unified
mixed-modal to mixed-modal retriever tailored for URAG scenarios. To mitigate
the scarcity of realistic mixed-modal data, we introduce a four-stage automated
pipeline for generation and filtering, leveraging web documents to construct
NyxQA, a dataset comprising diverse mixed-modal question-answer pairs that
better reflect real-world information needs. Building on this high-quality
dataset, we adopt a two-stage training framework for Nyx: we first perform
pre-training on NyxQA along with a variety of open-source retrieval datasets,
followed by supervised fine-tuning using feedback from downstream
vision-language models (VLMs) to align retrieval outputs with generative
preferences. Experimental results demonstrate that Nyx not only performs
competitively on standard text-only RAG benchmarks, but also excels in the more
general and realistic URAG setting, significantly improving generation quality
in vision-language tasks.

### 16. Lingua Custodi's participation at the WMT 2025 Terminology shared task

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Jingshu Liu, Raheel Qader, Ga√´tan Caillaut, Mariam Nakhl√©
- **URL**: <http://arxiv.org/abs/2510.17504v1>
- **Submitted**: 2025-10-20 13:00:47
- **Topic Keywords**: ranking, retrieval, rank
- **Reason**: The paper explores multilingual sentence embeddings and their applications, which is somewhat related to the user's interests in Information Retrieval and Natural Language Processing. However, the focus on cross-lingual sentence embeddings and machine translation is not directly aligned with the user's primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> While BERT is an effective method for learning monolingual sentence
embeddings for semantic similarity and embedding based transfer learning BERT
based cross-lingual sentence embeddings have yet to be explored. We
systematically investigate methods for learning multilingual sentence
embeddings by combining the best methods for learning monolingual and
cross-lingual representations including: masked language modeling (MLM),
translation language modeling (TLM), dual encoder translation ranking, and
additive margin softmax. We show that introducing a pre-trained multilingual
language model dramatically reduces the amount of parallel training data
required to achieve good performance by 80%. Composing the best of these
methods produces a model that achieves 83.7% bi-text retrieval accuracy over
112 languages on Tatoeba, well above the 65.5 achieved by LASER, while still
performing competitively on monolingual transfer learning benchmarks. Parallel
data mined from CommonCrawl using our best model is shown to train competitive
NMT models for en-zh and en-de. We publicly release our best multilingual
sentence embedding model for 109+ languages at https://tfhub.dev/google/LaBSE.

### 17. Executable Knowledge Graphs for Replicating AI Research

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Yujie Luo, Zhuoyun Yu, Xuehai Wang, Yuqi Zhu, Ningyu Zhang, Lanning Wei, Lun Du, Da Zheng, Huajun Chen
- **URL**: <http://arxiv.org/abs/2510.17795v1>
- **Submitted**: 2025-10-20 17:53:23
- **Comment**: Work in progress
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper proposes a system for replicating AI research by integrating technical insights, code snippets, and domain-specific knowledge from scientific literature. While it touches on retrieval-augmented generation, which is related to query understanding and ranking models, the primary focus is on replicating AI research, which is not a central match to your research interests in information retrieval and search technologies.

#### Abstract
> Replicating AI research is a crucial yet challenging task for large language
model (LLM) agents. Existing approaches often struggle to generate executable
code, primarily due to insufficient background knowledge and the limitations of
retrieval-augmented generation (RAG) methods, which fail to capture latent
technical details hidden in referenced papers. Furthermore, previous approaches
tend to overlook valuable implementation-level code signals and lack structured
knowledge representations that support multi-granular retrieval and reuse. To
overcome these challenges, we propose Executable Knowledge Graphs (xKG), a
modular and pluggable knowledge base that automatically integrates technical
insights, code snippets, and domain-specific knowledge extracted from
scientific literature. When integrated into three agent frameworks with two
different LLMs, xKG shows substantial performance gains (10.9% with o3-mini) on
PaperBench, demonstrating its effectiveness as a general and extensible
solution for automated AI research replication. Code will released at
https://github.com/zjunlp/xKG.

### 18. Navigating through the hidden embedding space: steering LLMs to improve mental health assessment

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Federico Ravenda, Seyed Ali Bahrainian, Andrea Raballo, Antonietta Mira
- **URL**: <http://arxiv.org/abs/2510.16373v1>
- **Submitted**: 2025-10-18 06:51:39
- **Topic Keywords**: relevance, rag
- **Reason**: The paper explores the application of Large Language Models (LLMs) in mental health assessment, which is a domain-specific area. However, the focus is on steering LLMs using linear transformations and steering vectors, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on relevance prediction, it is not a primary focus of the study.

#### Abstract
> The rapid evolution of Large Language Models (LLMs) is transforming AI,
opening new opportunities in sensitive and high-impact areas such as Mental
Health (MH). Yet, despite these advancements, recent evidence reveals that
smaller-scale models still struggle to deliver optimal performance in
domain-specific applications. In this study, we present a cost-efficient yet
powerful approach to improve MH assessment capabilities of an LLM, without
relying on any computationally intensive techniques. Our lightweight method
consists of a linear transformation applied to a specific layer's activations,
leveraging steering vectors to guide the model's output. Remarkably, this
intervention enables the model to achieve improved results across two distinct
tasks: (1) identifying whether a Reddit post is useful for detecting the
presence or absence of depressive symptoms (relevance prediction task), and (2)
completing a standardized psychological screening questionnaire for depression
based on users' Reddit post history (questionnaire completion task). Results
highlight the untapped potential of steering mechanisms as computationally
efficient tools for LLMs' MH domain adaptation.

### 19. ScholarEval: Research Idea Evaluation Grounded in Literature

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Hanane Nour Moussa, Patrick Queiroz Da Silva, Daniel Adu-Ampratwum, Alyson East, Zitong Lu, Nikki Puccetti, Mingyi Xue, Huan Sun, Bodhisattwa Prasad Majumder, Sachin Kumar
- **URL**: <http://arxiv.org/abs/2510.16234v1>
- **Submitted**: 2025-10-17 21:55:07
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper ScholarEval focuses on research idea evaluation, which is somewhat related to information retrieval, particularly in the context of query understanding and ranking models. However, the paper's primary focus is on evaluating research ideas rather than search technologies or user behavior modeling. While it involves literature analysis, it is not directly related to the user's core research themes in IR and NLP.

#### Abstract
> As AI tools become increasingly common for research ideation, robust
evaluation is critical to ensure the validity and usefulness of generated
ideas. We introduce ScholarEval, a retrieval augmented evaluation framework
that assesses research ideas based on two fundamental criteria: soundness - the
empirical validity of proposed methods based on existing literature, and
contribution - the degree of advancement made by the idea across different
dimensions relative to prior research. To evaluate ScholarEval, we introduce
ScholarIdeas, the first expert-annotated dataset of multi-domain research ideas
and reviews, comprised of 117 ideas across four disciplines: artificial
intelligence, neuroscience, biochemistry, and ecology. Our evaluation shows
that ScholarEval achieves significantly higher coverage of points mentioned in
the human expert annotated rubrics in ScholarIdeas compared to all baselines.
Furthermore, ScholarEval is consistently preferred over our strongest baseline
o4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI,
in terms of evaluation actionability, depth, and evidence support. Our
large-scale user study also shows that ScholarEval significantly outperforms
deep research in literature engagement, idea refinement, and usefulness. We
openly release our code, dataset, and ScholarEval tool for the community to use
and build on.

### 20. Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Akshara Prabhakar, Roshan Ram, Zixiang Chen, Silvio Savarese, Frank Wang, Caiming Xiong, Huan Wang, Weiran Yao
- **URL**: <http://arxiv.org/abs/2510.17797v1>
- **Submitted**: 2025-10-20 17:55:11
- **Comment**: Technical report; 13 pages plus references and appendices
- **Topic Keywords**: query, search
- **Reason**: The paper presents a multi-agent system for enterprise analytics, which involves search and query decomposition. While it touches on search and NLP, the primary focus is on multi-agent reasoning and enterprise integration, which is somewhat related to the user's interests in IR and NLP. However, the emphasis on enterprise deployment and analytics makes it less central to the user's core research themes.

#### Abstract
> As information grows exponentially, enterprises face increasing pressure to
transform unstructured data into coherent, actionable insights. While
autonomous agents show promise, they often struggle with domain-specific
nuances, intent alignment, and enterprise integration. We present Enterprise
Deep Research (EDR), a multi-agent system that integrates (1) a Master Planning
Agent for adaptive query decomposition, (2) four specialized search agents
(General, Academic, GitHub, LinkedIn), (3) an extensible MCP-based tool
ecosystem supporting NL2SQL, file analysis, and enterprise workflows, (4) a
Visualization Agent for data-driven insights, and (5) a reflection mechanism
that detects knowledge gaps and updates research direction with optional
human-in-the-loop steering guidance. These components enable automated report
generation, real-time streaming, and seamless enterprise deployment, as
validated on internal datasets. On open-ended benchmarks including DeepResearch
Bench and DeepConsult, EDR outperforms state-of-the-art agentic systems without
any human steering. We release the EDR framework and benchmark trajectories to
advance research on multi-agent reasoning applications.
  Code at https://github.com/SalesforceAIResearch/enterprise-deep-research and
Dataset at https://huggingface.co/datasets/Salesforce/EDR-200

### 21. MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Mir Nafis Sharear Shopnil, Sharad Duwal, Abhishek Tyagi, Adiba Mahbub Proma
- **URL**: <http://arxiv.org/abs/2510.17590v1>
- **Submitted**: 2025-10-20 14:40:26
- **Comment**: 16 pages, 3 tables, 1 figure
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper MIRAGE focuses on misinformation detection using multimodal posts, which involves web retrieval and reasoning. While it leverages NLP and vision-language models, its primary goal is not query understanding, ranking models, or user behavior modeling, which are core areas of interest. However, the paper's use of web retrieval and reasoning might be tangentially related to information retrieval, making it somewhat relevant to your research interests.

#### Abstract
> Misinformation spreads across web platforms through billions of daily
multimodal posts that combine text and images, overwhelming manual
fact-checking capacity. Supervised detection models require domain-specific
training data and fail to generalize across diverse manipulation tactics. We
present MIRAGE, an inference-time, model-pluggable agentic framework that
decomposes multimodal verification into four sequential modules: visual
veracity assessment detects AI-generated images, cross-modal consistency
analysis identifies out-of-context repurposing, retrieval-augmented factual
checking grounds claims in web evidence through iterative question generation,
and a calibrated judgment module integrates all signals. MIRAGE orchestrates
vision-language model reasoning with targeted web retrieval, outputs structured
and citation-linked rationales. On MMFakeBench validation set (1,000 samples),
MIRAGE with GPT-4o-mini achieves 81.65% F1 and 75.1% accuracy, outperforming
the strongest zero-shot baseline (GPT-4V with MMD-Agent at 74.0% F1) by 7.65
points while maintaining 34.3% false positive rate versus 97.3% for a
judge-only baseline. Test set results (5,000 samples) confirm generalization
with 81.44% F1 and 75.08% accuracy. Ablation studies show visual verification
contributes 5.18 F1 points and retrieval-augmented reasoning contributes 2.97
points. Our results demonstrate that decomposed agentic reasoning with web
retrieval can match supervised detector performance without domain-specific
training, enabling misinformation detection across modalities where labeled
data remains scarce.

### 22. Disparities in Multilingual LLM-Based Healthcare Q&A

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Ipek Baris Schlicht, Burcu Sayin, Zhixue Zhao, Frederik M. Labont√©, Cesare Barbera, Marco Viviani, Paolo Rosso, Lucie Flek
- **URL**: <http://arxiv.org/abs/2510.17476v1>
- **Submitted**: 2025-10-20 12:19:08
- **Comment**: Under review
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper explores the disparities in multilingual LLM-based healthcare Q&A, which touches on the topic of information retrieval and NLP. However, the focus on healthcare and multilingualism is not directly aligned with the user's core research themes, particularly query understanding, ranking models, and user behavior modeling.

#### Abstract
> Equitable access to reliable health information is vital when integrating AI
into healthcare. Yet, information quality varies across languages, raising
concerns about the reliability and consistency of multilingual Large Language
Models (LLMs). We systematically examine cross-lingual disparities in
pre-training source and factuality alignment in LLM answers for multilingual
healthcare Q&A across English, German, Turkish, Chinese (Mandarin), and
Italian. We (i) constructed Multilingual Wiki Health Care
(MultiWikiHealthCare), a multilingual dataset from Wikipedia; (ii) analyzed
cross-lingual healthcare coverage; (iii) assessed LLM response alignment with
these references; and (iv) conducted a case study on factual alignment through
the use of contextual information and Retrieval-Augmented Generation (RAG). Our
findings reveal substantial cross-lingual disparities in both Wikipedia
coverage and LLM factual alignment. Across LLMs, responses align more with
English Wikipedia, even when the prompts are non-English. Providing contextual
excerpts from non-English Wikipedia at inference time effectively shifts
factual alignment toward culturally relevant knowledge. These results highlight
practical pathways for building more equitable, multilingual AI systems for
healthcare.

### 23. DTKG: Dual-Track Knowledge Graph-Verified Reasoning Framework for Multi-Hop QA

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Changhao Wang, Yanfang Liu, Xinxin Fan, Anzhi Zhou, Lao Tian, Yunfeng Lu
- **URL**: <http://arxiv.org/abs/2510.16302v1>
- **Submitted**: 2025-10-18 02:19:11
- **Comment**: 13 pages, 5 figures
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper explores multi-hop reasoning for question answering, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on knowledge graph-verified reasoning and question answering is not directly aligned with the user's primary research interests in search technologies and user behavior modeling.

#### Abstract
> Multi-hop reasoning for question answering (QA) plays a critical role in
retrieval-augmented generation (RAG) for modern large language models (LLMs).
The accurate answer can be obtained through retrieving relational structure of
entities from knowledge graph (KG). Regarding the inherent relation-dependency
and reasoning pattern, multi-hop reasoning can be in general classified into
two categories: i) parallel fact-verification multi-hop reasoning question,
i.e., requiring simultaneous verifications of multiple independent
sub-questions; and ii) chained multi-hop reasoning questions, i.e., demanding
sequential multi-step inference with intermediate conclusions serving as
essential premises for subsequent reasoning. Currently, the multi-hop reasoning
approaches singly employ one of two techniques: LLM response-based fact
verification and KG path-based chain construction. Nevertheless, the former
excels at parallel fact-verification but underperforms on chained reasoning
tasks, while the latter demonstrates proficiency in chained multi-hop reasoning
but suffers from redundant path retrieval when handling parallel
fact-verification reasoning. These limitations deteriorate the efficiency and
accuracy for multi-hop QA tasks. To address this challenge, we propose a novel
dual-track KG verification and reasoning framework DTKG, which is inspired by
the Dual Process Theory in cognitive science. Specifically, DTKG comprises two
main stages: the Classification Stage and the Branch Processing Stage.

### 24. LawChain: Modeling Legal Reasoning Chains for Chinese Tort Case Analysis

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Huiyuan Xie, Chenyang Li, Huining Zhu, Chubin Zhang, Yuxiao Ye, Zhenghao Liu, Zhiyuan Liu
- **URL**: <http://arxiv.org/abs/2510.17602v1>
- **Submitted**: 2025-10-20 14:50:58
- **Topic Keywords**: rag, search
- **Reason**: This paper is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, as it involves the analysis of legal reasoning and the evaluation of language models. However, the focus on legal reasoning and tort cases is not directly aligned with the user's primary research themes, which include query understanding, ranking models, and user behavior modeling.

#### Abstract
> Legal reasoning is a fundamental component of legal analysis and
decision-making. Existing computational approaches to legal reasoning
predominantly rely on generic reasoning frameworks such as syllogism and IRAC,
which do not comprehensively examine the nuanced processes that underpin legal
reasoning. Moreover, current research has largely focused on criminal cases,
with insufficient modeling for civil cases. In this work, we present a novel
framework for explicitly modeling legal reasoning in the analysis of Chinese
tort-related civil cases. We first operationalize the legal reasoning processes
used in tort analysis into the LawChain framework. LawChain is a three-module
reasoning framework, with each module consisting of multiple finer-grained
sub-steps. Informed by the LawChain framework, we introduce the task of tort
legal reasoning and construct an evaluation benchmark, LawChain$_{eval}$, to
systematically assess the critical steps within analytical reasoning chains for
tort analysis. Leveraging this benchmark, we evaluate state-of-the-art large
language models for their legal reasoning ability in civil tort contexts. Our
results indicate that current models still fall short in accurately handling
crucial elements of tort legal reasoning. Furthermore, we introduce several
baseline approaches that explicitly incorporate LawChain-style reasoning
through prompting or post-training. We conduct further experiments on
additional legal analysis tasks, such as Legal Named-Entity Recognition and
Criminal Damages Calculation, to verify the generalizability of these
baselines. The proposed baseline approaches achieve significant improvements in
tort-related legal reasoning and generalize well to related legal analysis
tasks, thus demonstrating the value of explicitly modeling legal reasoning
chains to enhance the reasoning capabilities of language models.

### 25. On Efficiency-Effectiveness Trade-off of Diffusion-based Recommenders

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Wenyu Mao, Jiancan Wu, Guoqing Hu, Wei Ji, Xiang Wang
- **URL**: <http://arxiv.org/abs/2510.17245v1>
- **Submitted**: 2025-10-20 07:35:12
- **Topic Keywords**: recommend, acl
- **Reason**: This paper focuses on recommender systems, specifically diffusion-based models, which is somewhat related to your interests in Information Retrieval and Search technologies. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of your research. The paper's emphasis on recommender systems and deep semantic understanding is somewhat aligned with your interests, but it's not a central match.

#### Abstract
> Diffusion models have emerged as a powerful paradigm for generative
sequential recommendation, which typically generate next items to recommend
guided by user interaction histories with a multi-step denoising process.
However, the multi-step process relies on discrete approximations, introducing
discretization error that creates a trade-off between computational efficiency
and recommendation effectiveness. To address this trade-off, we propose TA-Rec,
a two-stage framework that achieves one-step generation by smoothing the
denoising function during pretraining while alleviating trajectory deviation by
aligning with user preferences during fine-tuning. Specifically, to improve the
efficiency without sacrificing the recommendation performance, TA-Rec pretrains
the denoising model with Temporal Consistency Regularization (TCR), enforcing
the consistency between the denoising results across adjacent steps. Thus, we
can smooth the denoising function to map the noise as oracle items in one step
with bounded error. To further enhance effectiveness, TA-Rec introduces
Adaptive Preference Alignment (APA) that aligns the denoising process with user
preference adaptively based on preference pair similarity and timesteps.
Extensive experiments prove that TA-Rec's two-stage objective effectively
mitigates the discretization errors-induced trade-off, enhancing both
efficiency and effectiveness of diffusion-based recommenders.

### 26. Investigating Thinking Behaviours of Reasoning-Based Language Models for Social Bias Mitigation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Guoqing Luo, Iffat Maab, Lili Mou, Junichi Yamagishi
- **URL**: <http://arxiv.org/abs/2510.17062v1>
- **Submitted**: 2025-10-20 00:33:44
- **Topic Keywords**: queries
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and deep semantic understanding, but it focuses on social bias mitigation in reasoning-based language models, which is not a central match to your primary focus on information retrieval and search technologies.

#### Abstract
> While reasoning-based large language models excel at complex tasks through an
internal, structured thinking process, a concerning phenomenon has emerged that
such a thinking process can aggregate social stereotypes, leading to biased
outcomes. However, the underlying behaviours of these language models in social
bias scenarios remain underexplored. In this work, we systematically
investigate mechanisms within the thinking process behind this phenomenon and
uncover two failure patterns that drive social bias aggregation: 1) stereotype
repetition, where the model relies on social stereotypes as its primary
justification, and 2) irrelevant information injection, where it fabricates or
introduces new details to support a biased narrative. Building on these
insights, we introduce a lightweight prompt-based mitigation approach that
queries the model to review its own initial reasoning against these specific
failure patterns. Experiments on question answering (BBQ and StereoSet) and
open-ended (BOLD) benchmarks show that our approach effectively reduces bias
while maintaining or improving accuracy.

### 27. Safire: Similarity Framework for Visualization Retrieval

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Huyen N. Nguyen, Nils Gehlenborg
- **URL**: <http://arxiv.org/abs/2510.16662v1>
- **Submitted**: 2025-10-18 23:11:40
- **Comment**: To appear in IEEE VIS 2025
- **Topic Keywords**: retrieval, recommend
- **Reason**: The paper focuses on visualization retrieval, which is somewhat related to information retrieval, but the scope and application are distinct. While it touches on aspects of similarity and comparison, it doesn't directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest.

#### Abstract
> Effective visualization retrieval necessitates a clear definition of
similarity. Despite the growing body of work in specialized visualization
retrieval systems, a systematic approach to understanding visualization
similarity remains absent. We introduce the Similarity Framework for
Visualization Retrieval (Safire), a conceptual model that frames visualization
similarity along two dimensions: comparison criteria and representation
modalities. Comparison criteria identify the aspects that make visualizations
similar, which we divide into primary facets (data, visual encoding,
interaction, style, metadata) and derived properties (data-centric and
human-centric measures). Safire connects what to compare with how comparisons
are executed through representation modalities. We categorize existing
representation approaches into four groups based on their levels of information
content and visualization determinism: raster image, vector image,
specification, and natural language description, together guiding what is
computable and comparable. We analyze several visualization retrieval systems
using Safire to demonstrate its practical value in clarifying similarity
considerations. Our findings reveal how particular criteria and modalities
align across different use cases. Notably, the choice of representation
modality is not only an implementation detail but also an important decision
that shapes retrieval capabilities and limitations. Based on our analysis, we
provide recommendations and discuss broader implications for multimodal
learning, AI applications, and visualization reproducibility.

### 28. FrugalPrompt: Reducing Contextual Overhead in Large Language Models via Token Attribution

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Syed Rifat Raiyan, Md Farhan Ishmam, Abdullah Al Imran, Mohammad Ali Moni
- **URL**: <http://arxiv.org/abs/2510.16439v1>
- **Submitted**: 2025-10-18 10:22:13
- **Topic Keywords**: rag, rank
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Large Language Models, but it does not directly address your core focus on Information Retrieval (IR) and query understanding. The paper's focus on prompt compression and token attribution is an interesting aspect, but it is more aligned with NLP and deep learning techniques rather than IR and search technologies.

#### Abstract
> Large language models (LLMs) owe much of their stellar performance to
expansive input contexts, yet such verbosity inflates monetary costs, carbon
footprint, and inference-time latency. Much of this overhead manifests from the
redundant low-utility tokens present in typical prompts, as only a fraction of
tokens typically carries the majority of the semantic weight. We address this
inefficiency by introducing FrugalPrompt, a novel prompt compression framework
for LLMs, which retains only the most semantically significant tokens.
Leveraging two state-of-the-art token attribution methods, GlobEnc and DecompX,
we assign salience scores to every token in an input sequence, rank them to
preserve the top-k% tokens in their original order, and obtain a sparse
frugalized prompt. We evaluate the approach across four NLP tasks: Sentiment
Analysis, Commonsense QA, Summarization, and Mathematical Reasoning, using a
suite of frontier LLMs. For the first three tasks, a 20% prompt reduction
incurs only a marginal loss in task performance, demonstrating that
contemporary LLMs can reconstruct elided context from high-salience cues. In
contrast, performance on mathematical reasoning deteriorates sharply,
reflecting a stronger dependence on complete token continuity. Further analysis
with bottom-k% and random-k% tokens reveals asymmetric performance patterns
that may suggest potential task contamination effects, wherein models may
resort to shallow memorized patterns from pretraining exposure for conventional
NLP tasks. We posit that our work contributes to a more nuanced understanding
of LLM behavior in performance-efficiency trade-offs, and delineate the
boundary between tasks tolerant to contextual sparsity and those requiring
exhaustive context. Our source code and models are available at:
https://github.com/Starscream-11813/Frugal-ICL

### 29. Towards Low-Resource Alignment to Diverse Perspectives with Sparse Feedback

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Chu Fei Luo, Samuel Dahan, Xiaodan Zhu
- **URL**: <http://arxiv.org/abs/2510.16257v1>
- **Submitted**: 2025-10-17 23:06:21
- **Comment**: Findings of EMNLP 2025, 5 pages
- **Topic Keywords**: query
- **Reason**: The paper explores language model alignment to diverse perspectives, which is related to query understanding and deep semantic understanding in Information Retrieval. However, the focus is on NLP rather than search technologies, and the context is not directly related to e-commerce or recommender systems. The paper's relevance is somewhat tangential to the user's core research themes.

#### Abstract
> As language models have a greater impact on society, it is important to
ensure they are aligned to a diverse range of perspectives and are able to
reflect nuance in human values. However, the most popular training paradigms
for modern language models often assume there is one optimal answer for every
query, leading to generic responses and poor alignment. In this work, we aim to
enhance pluralistic alignment of language models in a low-resource setting with
two methods: pluralistic decoding and model steering. We empirically
demonstrate that model steering offers consistent improvement over zero-shot
and few-shot baselines with only 50 annotated samples. Our proposed methods
decrease false positives in several high-stakes tasks such as hate speech
detection and misinformation detection, and improves the distributional
alignment to human values in GlobalOpinionQA. We hope our work highlights the
importance of diversity and how language models can be adapted to consider
nuanced perspectives.

### 30. Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains

- **LLM Score**: 2
- **Keyword Score**: 9
- **Authors**: Austin Xu, Xuan-Phi Nguyen, Yilun Zhou, Chien-Sheng Wu, Caiming Xiong, Shafiq Joty
- **URL**: <http://arxiv.org/abs/2510.17793v1>
- **Submitted**: 2025-10-20 17:52:06
- **Comment**: 29 pages, 9 tables, 6 figures
- **Topic Keywords**: rerank, pairwise, rank, acl
- **Reason**: This paper focuses on developing generative evaluators for reasoning-centric domains, which is not directly related to information retrieval, search technologies, or query understanding. While it involves training and evaluation, the context is more aligned with NLP and AI model evaluation, but lacks direct relevance to the user's core research themes.

#### Abstract
> Finetuning specialized generative evaluators has emerged as a popular
paradigm to meet the increasing demand for scalable evaluation during both
training and test-time. However, recent work has largely focused on applying
new methodology, such as reinforcement learning (RL), to training evaluators,
shying away from large-scale, data-driven development. In this work, we focus
on data scaling, curating a set of 2.5M samples spanning five unique evaluation
tasks (pairwise, step-level, reference-free and reference-based verification,
and single rating) and multiple domains focused on reasoning evaluation. With
our data, we train Foundational Automatic Reasoning Evaluators (FARE), a family
of 8B and 20B (with 3.6B active) parameter evaluators, with a simple iterative
rejection-sampling supervised finetuning (SFT) approach. FARE-8B challenges
larger specialized RL-trained evaluators and FARE-20B sets the new standard for
open-source evaluators, surpassing specialized 70B+ evaluators. Beyond static
benchmarks, we evaluate FARE in real-world tasks: As inference-time rerankers,
FARE-20B achieves near-oracle performance on MATH. As verifiers in RL training,
FARE improves the downstream RL-trained model performance by up to 14.1% vs.
string-matching verifiers. When initialized from FARE, a continually-finetuned
FARE-Code outperforms gpt-oss-20B by 65% on evaluating test-case quality.

### 31. UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Yuhao Yang, Zhen Yang, Zi-Yi Dou, Anh Nguyen, Keen You, Omar Attia, Andrew Szot, Michael Feng, Ram Ramrakhya, Alexander Toshev, Chao Huang, Yinfei Yang, Zhe Gan
- **URL**: <http://arxiv.org/abs/2510.17790v1>
- **Submitted**: 2025-10-20 17:48:26
- **Topic Keywords**: ltr, rag, click
- **Reason**: This paper appears to be focused on computer use agents and multimodal interaction, which is not directly related to your primary research interests in Information Retrieval and Search technologies. While it does involve some form of 'action' and 'trajectory collection', the context and application seem to be quite different from your areas of focus.

#### Abstract
> Multimodal agents for computer use rely exclusively on primitive actions
(click, type, scroll) that require accurate visual grounding and lengthy
execution chains, leading to cascading failures and performance bottlenecks.
While other agents leverage rich programmatic interfaces (APIs, MCP servers,
tools), computer-use agents (CUAs) remain isolated from these capabilities. We
present UltraCUA, a foundation model that bridges this gap through hybrid
action -- seamlessly integrating GUI primitives with high-level programmatic
tool calls. To achieve this, our approach comprises four key components: (1) an
automated pipeline that scales programmatic tools from software documentation,
open-source repositories, and code generation; (2) a synthetic data engine
producing over 17,000 verifiable tasks spanning real-world computer-use
scenarios; (3) a large-scale high-quality hybrid action trajectory collection
with both low-level GUI actions and high-level programmatic tool calls; and (4)
a two-stage training pipeline combining supervised fine-tuning with online
reinforcement learning, enabling strategic alternation between low-level and
high-level actions. Experiments with our 7B and 32B models demonstrate
substantial improvements over state-of-the-art agents. On OSWorld, UltraCUA
models achieve an average 22% relative improvement over base models, while
being 11% faster in terms of steps. Out-of-domain evaluation on
WindowsAgentArena shows our model reaches 21.7% success rate, outperforming
baselines trained on Windows data. The hybrid action mechanism proves critical,
reducing error propagation while maintaining execution efficiency.

### 32. Bits Leaked per Query: Information-Theoretic Bounds on Adversarial Attacks against LLMs

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Masahiro Kaneko, Timothy Baldwin
- **URL**: <http://arxiv.org/abs/2510.17000v1>
- **Submitted**: 2025-10-19 20:51:24
- **Comment**: NeurIPS 2025 (spotlight)
- **Topic Keywords**: query, queries
- **Reason**: This paper is primarily focused on adversarial attacks against Large Language Models (LLMs), which is not a core area of interest in Information Retrieval or Search technologies. While it touches on the concept of 'information leaked', the context is different from query understanding, ranking models, or user behavior modeling.

#### Abstract
> Adversarial attacks by malicious users that threaten the safety of large
language models (LLMs) can be viewed as attempts to infer a target property $T$
that is unknown when an instruction is issued, and becomes knowable only after
the model's reply is observed. Examples of target properties $T$ include the
binary flag that triggers an LLM's harmful response or rejection, and the
degree to which information deleted by unlearning can be restored, both
elicited via adversarial instructions. The LLM reveals an \emph{observable
signal} $Z$ that potentially leaks hints for attacking through a response
containing answer tokens, thinking process tokens, or logits. Yet the scale of
information leaked remains anecdotal, leaving auditors without principled
guidance and defenders blind to the transparency--risk trade-off. We fill this
gap with an information-theoretic framework that computes how much information
can be safely disclosed, and enables auditors to gauge how close their methods
come to the fundamental limit. Treating the mutual information $I(Z;T)$ between
the observation $Z$ and the target property $T$ as the leaked bits per query,
we show that achieving error $\varepsilon$ requires at least
$\log(1/\varepsilon)/I(Z;T)$ queries, scaling linearly with the inverse leak
rate and only logarithmically with the desired accuracy. Thus, even a modest
increase in disclosure collapses the attack cost from quadratic to logarithmic
in terms of the desired accuracy. Experiments on seven LLMs across
system-prompt leakage, jailbreak, and relearning attacks corroborate the
theory: exposing answer tokens alone requires about a thousand queries; adding
logits cuts this to about a hundred; and revealing the full thinking process
trims it to a few dozen. Our results provide the first principled yardstick for
balancing transparency and security when deploying LLMs.

### 33. FRONTIER-RevRec: A Large-scale Dataset for Reviewer Recommendation

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Qiyao Peng, Chen Wang, Yinghui Wang, Hongtao Liu, Xuan Guo, Wenjun Wang
- **URL**: <http://arxiv.org/abs/2510.16597v1>
- **Submitted**: 2025-10-18 17:52:38
- **Topic Keywords**: rag, recommend, search, www
- **Reason**: This paper is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves recommendation systems, it is focused on reviewer recommendation in academic publishing, which is a niche area that doesn't align with your primary focus on e-commerce and deep semantic understanding.

#### Abstract
> Reviewer recommendation is a critical task for enhancing the efficiency of
academic publishing workflows. However, research in this area has been
persistently hindered by the lack of high-quality benchmark datasets, which are
often limited in scale, disciplinary scope, and comparative analyses of
different methodologies. To address this gap, we introduce FRONTIER-RevRec, a
large-scale dataset constructed from authentic peer review records (2007-2025)
from the Frontiers open-access publishing platform
https://www.frontiersin.org/. The dataset contains 177941 distinct reviewers
and 478379 papers across 209 journals spanning multiple disciplines including
clinical medicine, biology, psychology, engineering, and social sciences. Our
comprehensive evaluation on this dataset reveals that content-based methods
significantly outperform collaborative filtering. This finding is explained by
our structural analysis, which uncovers fundamental differences between
academic recommendation and commercial domains. Notably, approaches leveraging
language models are particularly effective at capturing the semantic alignment
between a paper's content and a reviewer's expertise. Furthermore, our
experiments identify optimal aggregation strategies to enhance the
recommendation pipeline. FRONTIER-RevRec is intended to serve as a
comprehensive benchmark to advance research in reviewer recommendation and
facilitate the development of more effective academic peer review systems. The
FRONTIER-RevRec dataset is available at:
https://anonymous.4open.science/r/FRONTIER-RevRec-5D05.

### 34. Resolution-Aware Retrieval Augmented Zero-Shot Forecasting

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Iman Deznabi, Peeyush Kumar, Madalina Fiterau
- **URL**: <http://arxiv.org/abs/2510.16695v1>
- **Submitted**: 2025-10-19 03:29:57
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper focuses on zero-shot forecasting and resolution-aware retrieval, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves data mining and forecasting, the context and application are quite different from the user's interests in e-commerce, query understanding, and ranking models.

#### Abstract
> Zero-shot forecasting aims to predict outcomes for previously unseen
conditions without direct historical data, posing a significant challenge for
traditional forecasting methods. We introduce a Resolution-Aware
Retrieval-Augmented Forecasting model that enhances predictive accuracy by
leveraging spatial correlations and temporal frequency characteristics. By
decomposing signals into different frequency components, our model employs
resolution-aware retrieval, where lower-frequency components rely on broader
spatial context, while higher-frequency components focus on local influences.
This allows the model to dynamically retrieve relevant data and adapt to new
locations with minimal historical context.
  Applied to microclimate forecasting, our model significantly outperforms
traditional forecasting methods, numerical weather prediction models, and
modern foundation time series models, achieving 71% lower MSE than HRRR and 34%
lower MSE than Chronos on the ERA5 dataset.
  Our results highlight the effectiveness of retrieval-augmented and
resolution-aware strategies, offering a scalable and data-efficient solution
for zero-shot forecasting in microclimate modeling and beyond.

### 35. On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active Marginal-Samples Exploration

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yehonathan Refael, Amit Aides, Aviad Barzilai, George Leifman, Genady Beryozkin, Vered Silverman, Bolous Jaber, Tomer Shekel
- **URL**: <http://arxiv.org/abs/2510.17670v1>
- **Submitted**: 2025-10-20 15:41:55
- **Topic Keywords**: queries
- **Reason**: This paper focuses on open-vocabulary object detection and active learning strategies, which are not directly related to the user's core research themes in Information Retrieval and Search technologies. While it involves user-annotated examples, the context is object detection in Remote Sensing, which is not a primary area of interest for the user.

#### Abstract
> Open-vocabulary object detection (OVD) models offer remarkable flexibility by
detecting objects from arbitrary text queries. However, their zero-shot
performance in specialized domains like Remote Sensing (RS) is often
compromised by the inherent ambiguity of natural language, limiting critical
downstream applications. For instance, an OVD model may struggle to distinguish
between fine-grained classes such as "fishing boat" and "yacht" since their
embeddings are similar and often inseparable. This can hamper specific user
goals, such as monitoring illegal fishing, by producing irrelevant detections.
To address this, we propose a cascaded approach that couples the broad
generalization of a large pre-trained OVD model with a lightweight few-shot
classifier. Our method first employs the zero-shot model to generate
high-recall object proposals. These proposals are then refined for high
precision by a compact classifier trained in real-time on only a handful of
user-annotated examples - drastically reducing the high costs of RS imagery
annotation.The core of our framework is FLAME, a one-step active learning
strategy that selects the most informative samples for training. FLAME
identifies, on the fly, uncertain marginal candidates near the decision
boundary using density estimation, followed by clustering to ensure sample
diversity. This efficient sampling technique achieves high accuracy without
costly full-model fine-tuning and enables instant adaptation, within less then
a minute, which is significantly faster than state-of-the-art alternatives.Our
method consistently surpasses state-of-the-art performance on RS benchmarks,
establishing a practical and resource-efficient framework for adapting
foundation models to specific user needs.

### 36. Qomhra: A Bilingual Irish-English Large Language Model

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Joseph McInerney
- **URL**: <http://arxiv.org/abs/2510.17652v1>
- **Submitted**: 2025-10-20 15:27:53
- **Topic Keywords**: rag, rank
- **Reason**: This paper focuses on developing a bilingual Irish-English large language model, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language understanding and generation, the context and application are not aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> This paper introduces Qomhr\'a, a bilingual Irish-English large language
model (LLM), developed under low-resource constraints presenting a complete
pipeline spanning bilingual continued pre-training, instruction tuning, and
alignment from human preferences. Newly accessible Irish corpora and English
text are mixed and curated to improve Irish performance while preserving
English ability. 6 closed-weight LLMs are judged for their Irish text
generation by a native speaker, a learner and other LLMs. Google's
Gemini-2.5-Pro is ranked the highest and is subsequently used to synthesise
instruction tuning and human preference datasets. Two datasets are contributed
leveraging Gemini-2.5-Pro: a 30K Irish-English parallel instruction tuning
dataset and a 1K human preference dataset, generating accepted and rejected
responses that show near perfect alignment with a native Irish speaker.
Qomhr\'a is comprehensively evaluated across benchmarks testing translation,
gender understanding, topic identification and world knowledge with gains of up
to 29% in Irish and 44% in English. Qomhr\'a also undergoes instruction tuning
and demonstrates clear progress in instruction following, crucial for chatbot
functionality.

### 37. Deep Self-Evolving Reasoning

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Zihan Liu, Shun Zheng, Xumeng Wen, Yang Wang, Jiang Bian, Mao Yang
- **URL**: <http://arxiv.org/abs/2510.17498v1>
- **Submitted**: 2025-10-20 12:51:42
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on developing a framework for long-form chain-of-thought reasoning in large language models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on the concept of reasoning and model capabilities, it does not align with your specific areas of focus such as query understanding, ranking models, and user behavior modeling.

#### Abstract
> Long-form chain-of-thought reasoning has become a cornerstone of advanced
reasoning in large language models. While recent verification-refinement
frameworks have enabled proprietary models to solve Olympiad-level problems,
their effectiveness hinges on strong, reliable verification and correction
capabilities, which remain fragile in open-weight, smaller-scale models. This
work demonstrates that even with weak verification and refinement capabilities
on hard tasks, the reasoning limits of such models can be substantially
extended through a probabilistic paradigm we call Deep Self-Evolving Reasoning
(DSER). We conceptualize iterative reasoning as a Markov chain, where each step
represents a stochastic transition in the solution space. The key insight is
that convergence to a correct solution is guaranteed as long as the probability
of improvement marginally exceeds that of degradation. By running multiple
long-horizon, self-evolving processes in parallel, DSER amplifies these small
positive tendencies, enabling the model to asymptotically approach correct
answers. Empirically, we apply DSER to the DeepSeek-R1-0528-Qwen3-8B model. On
the challenging AIME 2024-2025 benchmark, DSER solves 5 out of 9 previously
unsolvable problems and boosts overall performance, enabling this compact model
to surpass the single-turn accuracy of its 600B-parameter teacher through
majority voting. Beyond its immediate utility for test-time scaling, the DSER
framework serves to diagnose the fundamental limitations of current open-weight
reasoners. By clearly delineating their shortcomings in self-verification,
refinement, and stability, our findings establish a clear research agenda for
developing next-generation models with powerful, intrinsic self-evolving
capabilities.

### 38. Multilingual Clinical NER for Diseases and Medications Recognition in Cardiology Texts using BERT Embeddings

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Manuela Daniela Danu, George Marica, Constantin Suciu, Lucian Mihai Itu, Oladimeji Farri
- **URL**: <http://arxiv.org/abs/2510.17437v1>
- **Submitted**: 2025-10-20 11:26:22
- **Comment**: 11 pages, 5 figures, 1 table, published in Working Notes of the
  Conference and Labs of the Evaluation Forum (CLEF 2024)
- **Topic Keywords**: ctr, search
- **Reason**: This paper focuses on clinical named entity recognition using BERT embeddings, which is outside your primary research interests in Information Retrieval and Search technologies. Although it involves NLP, the domain and application are quite different from your areas of focus.

#### Abstract
> The rapidly increasing volume of electronic health record (EHR) data
underscores a pressing need to unlock biomedical knowledge from unstructured
clinical texts to support advancements in data-driven clinical systems,
including patient diagnosis, disease progression monitoring, treatment effects
assessment, prediction of future clinical events, etc. While contextualized
language models have demonstrated impressive performance improvements for named
entity recognition (NER) systems in English corpora, there remains a scarcity
of research focused on clinical texts in low-resource languages. To bridge this
gap, our study aims to develop multiple deep contextual embedding models to
enhance clinical NER in the cardiology domain, as part of the BioASQ
MultiCardioNER shared task. We explore the effectiveness of different
monolingual and multilingual BERT-based models, trained on general domain text,
for extracting disease and medication mentions from clinical case reports
written in English, Spanish, and Italian. We achieved an F1-score of 77.88% on
Spanish Diseases Recognition (SDR), 92.09% on Spanish Medications Recognition
(SMR), 91.74% on English Medications Recognition (EMR), and 88.9% on Italian
Medications Recognition (IMR). These results outperform the mean and median F1
scores in the test leaderboard across all subtasks, with the mean/median values
being: 69.61%/75.66% for SDR, 81.22%/90.18% for SMR, 89.2%/88.96% for EMR, and
82.8%/87.76% for IMR.

### 39. Addressing Antisocial Behavior in Multi-Party Dialogs Through Multimodal Representation Learning

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Hajar Bakarou, Mohamed Sinane El Messoussi, Ana√Øs Ollagnier
- **URL**: <http://arxiv.org/abs/2510.17289v1>
- **Submitted**: 2025-10-20 08:27:38
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on addressing antisocial behavior in multi-party dialogs through multimodal representation learning, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP and representation learning, its application to antisocial behavior detection is not aligned with your primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Antisocial behavior (ASB) on social media -- including hate speech,
harassment, and cyberbullying -- poses growing risks to platform safety and
societal well-being. Prior research has focused largely on networks such as X
and Reddit, while \textit{multi-party conversational settings} remain
underexplored due to limited data. To address this gap, we use
\textit{CyberAgressionAdo-Large}, a French open-access dataset simulating ASB
in multi-party conversations, and evaluate three tasks: \textit{abuse
detection}, \textit{bullying behavior analysis}, and \textit{bullying
peer-group identification}. We benchmark six text-based and eight graph-based
\textit{representation-learning methods}, analyzing lexical cues, interactional
dynamics, and their multimodal fusion. Results show that multimodal models
outperform unimodal baselines. The late fusion model \texttt{mBERT + WD-SGCN}
achieves the best overall results, with top performance on abuse detection
(0.718) and competitive scores on peer-group identification (0.286) and
bullying analysis (0.606). Error analysis highlights its effectiveness in
handling nuanced ASB phenomena such as implicit aggression, role transitions,
and context-dependent hostility.

### 40. How News Feels: Understanding Affective Bias in Multilingual Headlines for Human-Centered Media Design

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Mohd Ruhul Ameen, Akif Islam, Abu Saleh Musa Miah, Ayesha Siddiqua, Jungpil Shin
- **URL**: <http://arxiv.org/abs/2510.17252v1>
- **Submitted**: 2025-10-20 07:40:46
- **Comment**: 15 pages, 7 figures, 4 tables. Submitted to the International
  Conference on Data and Applied Analytics (IDAA 2025)
- **Topic Keywords**: rag, search
- **Reason**: This paper primarily focuses on affective bias in news headlines, which is related to information retrieval but not directly aligned with the user's core research themes of query understanding, ranking models, and user behavior modeling. While it touches on media design and user experience, it doesn't explore deep semantic understanding or real-time relevance optimization, making it only loosely relevant to the user's interests.

#### Abstract
> News media often shape the public mood not only by what they report but by
how they frame it. The same event can appear calm in one outlet and alarming in
another, reflecting subtle emotional bias in reporting. Negative or emotionally
charged headlines tend to attract more attention and spread faster, which in
turn encourages outlets to frame stories in ways that provoke stronger
reactions. This research explores that tendency through large-scale emotion
analysis of Bengali news. Using zero-shot inference with Gemma-3 4B, we
analyzed 300000 Bengali news headlines and their content to identify the
dominant emotion and overall tone of each. The findings reveal a clear
dominance of negative emotions, particularly anger, fear, and disappointment,
and significant variation in how similar stories are emotionally portrayed
across outlets. Based on these insights, we propose design ideas for a
human-centered news aggregator that visualizes emotional cues and helps readers
recognize hidden affective framing in daily news.

### 41. Wisdom is Knowing What not to Say: Hallucination-Free LLMs Unlearning via Attention Shifting

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Chenchen Tan, Youyang Qu, Xinghao Li, Hui Zhang, Shujie Cui, Cunjian Chen, Longxiang Gao
- **URL**: <http://arxiv.org/abs/2510.17210v1>
- **Submitted**: 2025-10-20 06:50:03
- **Comment**: 22 pages, 10 figures
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on machine unlearning for large language models, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves NLP, the context is more about model reliability and knowledge retention rather than query understanding, ranking models, or deep semantic understanding.

#### Abstract
> The increase in computing power and the necessity of AI-assisted
decision-making boost the growing application of large language models (LLMs).
Along with this, the potential retention of sensitive data of LLMs has spurred
increasing research into machine unlearning. However, existing unlearning
approaches face a critical dilemma: Aggressive unlearning compromises model
utility, while conservative strategies preserve utility but risk hallucinated
responses. This significantly limits LLMs' reliability in knowledge-intensive
applications. To address this, we introduce a novel Attention-Shifting (AS)
framework for selective unlearning. AS is driven by two design objectives: (1)
context-preserving suppression that attenuates attention to fact-bearing tokens
without disrupting LLMs' linguistic structure; and (2) hallucination-resistant
response shaping that discourages fabricated completions when queried about
unlearning content. AS realizes these objectives through two attention-level
interventions, which are importance-aware suppression applied to the unlearning
set to reduce reliance on memorized knowledge and attention-guided retention
enhancement that reinforces attention toward semantically essential tokens in
the retained dataset to mitigate unintended degradation. These two components
are jointly optimized via a dual-loss objective, which forms a soft boundary
that localizes unlearning while preserving unrelated knowledge under
representation superposition. Experimental results show that AS improves
performance preservation over the state-of-the-art unlearning methods,
achieving up to 15% higher accuracy on the ToFU benchmark and 10% on the TDEC
benchmark, while maintaining competitive hallucination-free unlearning
effectiveness. Compared to existing methods, AS demonstrates a superior balance
between unlearning effectiveness, generalization, and response reliability.

### 42. Offline Policy Evaluation of Multi-Turn LLM Health Coaching with Real Users

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Melik Ozolcer, Sang Won Bae
- **URL**: <http://arxiv.org/abs/2510.17173v1>
- **Submitted**: 2025-10-20 05:28:59
- **Comment**: Accepted to the NeurIPS 2025 Workshop on Multi-Turn Interactions in
  Large Language Models
- **Topic Keywords**: rag, personalization
- **Reason**: This paper appears to be focused on evaluating a language model-based health coaching system, which is not directly related to information retrieval or search technologies. While it involves a language model, the primary focus is on offline policy evaluation and subgroup-aware decision making, which does not align with the user's core research themes.

#### Abstract
> We study a web-deployed, tool-augmented LLM health coach with real users. In
a pilot with seven users (280 rated turns), offline policy evaluation (OPE)
over factorized decision heads (Tool/Style) shows that a uniform heavy-tool
policy raises average value on logs but harms specific subgroups, most notably
low-health-literacy/high-self-efficacy users. A lightweight simulator with
hidden archetypes further shows that adding a small early information-gain
bonus reliably shortens trait identification and improves goal success and
pass@3. Together, these early findings indicate an evaluation-first path to
personalization: freeze the generator, learn subgroup-aware decision heads on
typed rewards (objective tool outcomes and satisfaction), and always report
per-archetype metrics to surface subgroup harms that averages obscure.

### 43. DeepAnalyze: Agentic Large Language Models for Autonomous Data Science

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Shaolei Zhang, Ju Fan, Meihao Fan, Guoliang Li, Xiaoyong Du
- **URL**: <http://arxiv.org/abs/2510.16872v1>
- **Submitted**: 2025-10-19 15:13:42
- **Comment**: Code: https://github.com/ruc-datalab/DeepAnalyze Model:
  https://huggingface.co/RUC-DataLab/DeepAnalyze-8B
- **Topic Keywords**: ctr, search
- **Reason**: This paper focuses on autonomous data science and large language models, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on the application of language models, it does not explore query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's research.

#### Abstract
> Autonomous data science, from raw data sources to analyst-grade deep research
reports, has been a long-standing challenge, and is now becoming feasible with
the emergence of powerful large language models (LLMs). Recent workflow-based
data agents have shown promising results on specific data tasks but remain
fundamentally limited in achieving fully autonomous data science due to their
reliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B,
the first agentic LLM designed for autonomous data science, capable of
automatically completing the end-toend pipeline from data sources to
analyst-grade deep research reports. To tackle high-complexity data science
tasks, we propose a curriculum-based agentic training paradigm that emulates
the learning trajectory of human data scientists, enabling LLMs to
progressively acquire and integrate multiple capabilities in real-world
environments. We also introduce a data-grounded trajectory synthesis framework
that constructs high-quality training data. Through agentic training,
DeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data
question answering and specialized analytical tasks to open-ended data
research. Experiments demonstrate that, with only 8B parameters, DeepAnalyze
outperforms previous workflow-based agents built on most advanced proprietary
LLMs. The model, code, and training data of DeepAnalyze are open-sourced,
paving the way toward autonomous data science.

### 44. All You Need is One: Capsule Prompt Tuning with a Single Vector

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yiyang Liu, James C. Liang, Heng Fan, Wenhao Yang, Yiming Cui, Xiaotian Han, Lifu Huang, Dongfang Liu, Qifan Wang, Cheng Han
- **URL**: <http://arxiv.org/abs/2510.16670v1>
- **Submitted**: 2025-10-19 00:02:59
- **Comment**: NeurIPS 2025
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on prompt-based learning for Large Language Models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on some NLP aspects, it doesn't seem to address your specific areas of interest in query understanding, ranking models, or user behavior modeling.

#### Abstract
> Prompt-based learning has emerged as a parameter-efficient finetuning (PEFT)
approach to facilitate Large Language Model (LLM) adaptation to downstream
tasks by conditioning generation with task-aware guidance. Despite its
successes, current prompt-based learning methods heavily rely on laborious grid
searching for optimal prompt length and typically require considerable number
of prompts, introducing additional computational burden. Worse yet, our pioneer
findings indicate that the task-aware prompt design is inherently limited by
its absence of instance-aware information, leading to a subtle attention
interplay with the input sequence. In contrast, simply incorporating
instance-aware information as a part of the guidance can enhance the
prompt-tuned model performance without additional fine-tuning. Moreover, we
find an interesting phenomenon, namely "attention anchor", that incorporating
instance-aware tokens at the earliest position of the sequence can successfully
preserve strong attention to critical structural information and exhibit more
active attention interaction with all input tokens. In light of our
observation, we introduce Capsule Prompt-Tuning (CaPT), an efficient and
effective solution that leverages off-the-shelf, informative instance semantics
into prompt-based learning. Our approach innovatively integrates both
instance-aware and task-aware information in a nearly parameter-free manner
(i.e., one single capsule prompt). Empirical results demonstrate that our
method can exhibit superior performance across various language tasks (e.g.,
84.03\% average accuracy on T5-Large), serving as an "attention anchor," while
enjoying high parameter efficiency (e.g., 0.003\% of model parameters on
Llama3.2-1B).

### 45. Probing the Hidden Talent of ASR Foundation Models for L2 English Oral Assessment

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Fu-An Chao, Bi-Cheng Yan, Berlin Chen
- **URL**: <http://arxiv.org/abs/2510.16387v1>
- **Submitted**: 2025-10-18 08:10:24
- **Topic Keywords**: relevance
- **Reason**: This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves a deep learning model, its application is in Automatic Speech Recognition and Spoken Language Assessment, which is not a primary focus of the user's interests.

#### Abstract
> In this paper, we explore the untapped potential of Whisper, a
well-established automatic speech recognition (ASR) foundation model, in the
context of L2 spoken language assessment (SLA). Unlike prior studies that
extrinsically analyze transcriptions produced by Whisper, our approach goes a
step further to probe its latent capabilities by extracting acoustic and
linguistic features from hidden representations. With only a lightweight
classifier being trained on top of Whisper's intermediate and final outputs,
our method achieves strong performance on the GEPT picture-description dataset,
outperforming existing cutting-edge baselines, including a multimodal approach.
Furthermore, by incorporating image and text-prompt information as auxiliary
relevance cues, we demonstrate additional performance gains. Finally, we
conduct an in-depth analysis of Whisper's embeddings, which reveals that, even
without task-specific fine-tuning, the model intrinsically encodes both ordinal
proficiency patterns and semantic aspects of speech, highlighting its potential
as a powerful foundation for SLA and other spoken language understanding tasks.

### 46. WEBSERV: A Browser-Server Environment for Efficient Training of Reinforcement Learning-based Web Agents at Scale

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yuxuan Lu, Jing Huang, Hui Liu, Jiri Gesi, Yan Han, Shihan Fu, Tianqi Zheng, Dakuo Wang
- **URL**: <http://arxiv.org/abs/2510.16252v1>
- **Submitted**: 2025-10-17 22:54:33
- **Topic Keywords**: rag, shopping
- **Reason**: This paper focuses on Reinforcement Learning (RL) for web agents, which is not a core area of interest for the user. While it involves a browser-server environment, the context is not related to information retrieval, search technologies, or natural language processing, making it less relevant to the user's research interests.

#### Abstract
> Training and evaluation of Reinforcement Learning (RL) web agents have gained
increasing attention, yet a scalable and efficient environment that couples
realistic and robust browser-side interaction with controllable server-side
state at scale is still missing. Existing environments tend to have one or more
of the following issues: they overwhelm policy models with excessive and noisy
context; they perform actions non-deterministically without waiting for the UI
or network to stabilize; or they cannot scale isolated client-server containers
effectively for parallel RL rollouts. We propose WEBSERV, an environment that
includes 1) a compact, site-agnostic browser environment that balances context
and action complexity, and 2) a scalable RL environment via efficient launching
and resetting web-servers to enable scalable RL training and evaluation. We
evaluate WEBSERV on the shopping CMS and Gitlab tasks in WebArena, achieving
state-of-the-art single-prompt success rates while cutting launch latency by
~5x and storage need by ~240x, with a comparable memory footprint, enabling
200+ concurrent containers on a single host.

### 47. Mapping Post-Training Forgetting in Language Models at Scale

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jackson Harmon, Andreas Hochlehnert, Matthias Bethge, Ameya Prabhu
- **URL**: <http://arxiv.org/abs/2510.17776v1>
- **Submitted**: 2025-10-20 17:35:47
- **Comment**: 43 pages,15 figures
- **Topic Keywords**: rag
- **Reason**: This paper focuses on the post-training behavior of language models, which is not directly related to information retrieval, search technologies, or query understanding. While it does involve deep semantic understanding, the context is on language models rather than search or IR.

#### Abstract
> Scaled post-training now drives many of the largest capability gains in
language models (LMs), yet its effect on pretrained knowledge remains poorly
understood. Not all forgetting is equal: Forgetting one fact (e.g., a U.S.
president or an API call) does not "average out" by recalling another. Hence,
we propose a sample-wise paradigm to measure what is forgotten and when
backward transfer occurs. Our metric counts 1->0 transitions (correct before
post-training, incorrect after) to quantify forgetting and 0->1 transitions to
quantify backward transfer. Traditional task averages conflate these effects
and obscure large changes. For multiple-choice benchmarks, we add
chance-adjusted variants that subtract the expected contribution of random
guessing from pre- and post-training accuracies. We apply this framework across
post-training stages, model sizes, and data scales. Our large-scale analysis
shows that: (1) Domain-continual pretraining induces moderate forgetting with
low-to-moderate backward transfer; (2) RL/SFT post-training applied to base
models and Instruction tuning yields moderate-to-large backward transfer on
math and logic with overall low-to-moderate forgetting; (3) Applying RL/SFT to
instruction-tuned models is sensitive on data scale: at small scales, both
forgetting and backward transfer are small; at larger scales, effects are mixed
and warrant further study with better controls; (4) Model merging does not
reliably mitigate forgetting. Overall, our framework offers a practical
yardstick for mapping how post-training alters pretrained knowledge at scale --
enabling progress towards generally capable AI systems.

### 48. Exact Nearest-Neighbor Search on Energy-Efficient FPGA Devices

- **LLM Score**: 0
- **Keyword Score**: 7
- **Authors**: Patrizio Dazzi, William Guglielmo, Franco Maria Nardini, Raffaele Perego, Salvatore Trani
- **URL**: <http://arxiv.org/abs/2510.16736v1>
- **Submitted**: 2025-10-19 07:29:16
- **Topic Keywords**: query, queries, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, or data mining. The focus on energy-efficient FPGA devices for exact kNN search is unrelated to your areas of expertise.

#### Abstract
> This paper investigates the usage of FPGA devices for energy-efficient exact
kNN search in high-dimension latent spaces. This work intercepts a relevant
trend that tries to support the increasing popularity of learned
representations based on neural encoder models by making their large-scale
adoption greener and more inclusive. The paper proposes two different
energy-efficient solutions adopting the same FPGA low-level configuration. The
first solution maximizes system throughput by processing the queries of a batch
in parallel over a streamed dataset not fitting into the FPGA memory. The
second minimizes latency by processing each kNN incoming query in parallel over
an in-memory dataset. Reproducible experiments on publicly available image and
text datasets show that our solution outperforms state-of-the-art CPU-based
competitors regarding throughput, latency, and energy consumption.
Specifically, experiments show that the proposed FPGA solutions achieve the
best throughput in terms of queries per second and the best-observed latency
with scale-up factors of up to 16.6X. Similar considerations can be made
regarding energy efficiency, where results show that our solutions can achieve
up to 11.9X energy saving w.r.t. strong CPU-based competitors.

### 49. U-Codec: Ultra Low Frame-rate Neural Speech Codec for Fast High-fidelity Speech Generation

- **LLM Score**: 0
- **Keyword Score**: 7
- **Authors**: Xusheng Yang, Long Zhou, Wenfu Wang, Kai Hu, Shulin Feng, Chenxing Li, Meng Yu, Dong Yu, Yuexian Zou
- **URL**: <http://arxiv.org/abs/2510.16718v1>
- **Submitted**: 2025-10-19 05:09:20
- **Topic Keywords**: ltr, rag, ctr
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, or data mining. The paper focuses on neural speech codec and speech synthesis, which is outside your primary areas of interest.

#### Abstract
> We propose \textbf{U-Codec}, an \textbf{U}ltra low frame-rate neural speech
\textbf{Codec} that achieves high-fidelity reconstruction and fast speech
generation at an extremely low frame-rate of 5Hz (5 frames per second). Extreme
compression at 5Hz typically leads to severe intelligibility and spectral
detail loss, we introduce a Transformer-based inter-frame long-term dependency
module and systematically explore residual vector quantization (RVQ) depth and
codebook size to identify optimal configurations. Moreover, we apply U-Codec
into a large language model (LLM)-based auto-regressive TTS model, which
leverages global and local hierarchical architecture to effectively capture
dependencies across multi-layer tokens. We extend LLM-based TTS from 3-layer
RVQ at 50Hz to 32-layer RVQ at 5Hz. Experimental results demonstrate that
U-Codec improves LLM-based TTS inference speed by around 3 $\times$ over
high-frame-rate codecs while maintaining similarity and naturalness. These
results validate the feasibility of using highly compressed 5Hz discrete tokens
for fast and high-fidelity speech synthesis.

### 50. Copy-Augmented Representation for Structure Invariant Template-Free Retrosynthesis

- **LLM Score**: 0
- **Keyword Score**: 3
- **Authors**: Jiaxi Zhuang, Yu Zhang, Aimin Zhou, Ying Qian
- **URL**: <http://arxiv.org/abs/2510.16588v1>
- **Submitted**: 2025-10-18 17:25:36
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. It focuses on a specific application in computational drug discovery and chemical synthesis, using novel molecular representations and generation techniques.

#### Abstract
> Retrosynthesis prediction is fundamental to drug discovery and chemical
synthesis, requiring the identification of reactants that can produce a target
molecule. Current template-free methods struggle to capture the structural
invariance inherent in chemical reactions, where substantial molecular
scaffolds remain unchanged, leading to unnecessarily large search spaces and
reduced prediction accuracy. We introduce C-SMILES, a novel molecular
representation that decomposes traditional SMILES into element-token pairs with
five special tokens, effectively minimizing editing distance between reactants
and products. Building upon this representation, we incorporate a
copy-augmented mechanism that dynamically determines whether to generate new
tokens or preserve unchanged molecular fragments from the product. Our approach
integrates SMILES alignment guidance to enhance attention consistency with
ground-truth atom mappings, enabling more chemically coherent predictions.
Comprehensive evaluation on USPTO-50K and large-scale USPTO-FULL datasets
demonstrates significant improvements: 67.2% top-1 accuracy on USPTO-50K and
50.8% on USPTO-FULL, with 99.9% validity in generated molecules. This work
establishes a new paradigm for structure-aware molecular generation with direct
applications in computational drug discovery.

---

