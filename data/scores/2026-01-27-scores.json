[
    {
        "title": "PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation",
        "abstract": "Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.",
        "url": "http://arxiv.org/abs/2601.18777v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18777v1",
        "arxiv_id": "2601.18777v1",
        "authors": [
            "Abhishek Divekar",
            "Anirban Majumder"
        ],
        "submitted": "2026-01-26 18:46:49",
        "source": "arxiv",
        "comment": "Accepted at AAAI 2026 - Innovative Applications of AI (IAAI-26)",
        "score": 18,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of ranking models and evaluation metrics. The use of Large Language Models (LLMs) as automated judges for search and ranking systems aligns with your focus on deep semantic understanding and real-time relevance optimization. The proposed framework, PRECISE, addresses a critical issue in LLM evaluations, making it a useful contribution to the field."
    },
    {
        "title": "GenCI: Generative Modeling of User Interest Shift via Cohort-based Intent Learning for CTR Prediction",
        "abstract": "Click-through rate (CTR) prediction plays a pivotal role in online advertising and recommender systems. Despite notable progress in modeling user preferences from historical behaviors, two key challenges persist. First, exsiting discriminative paradigms focus on matching candidates to user history, often overfitting to historically dominant features and failing to adapt to rapid interest shifts. Second, a critical information chasm emerges from the point-wise ranking paradigm. By scoring each candidate in isolation, CTR models discard the rich contextual signal implied by the recalled set as a whole, leading to a misalignment where long-term preferences often override the user's immediate, evolving intent. To address these issues, we propose GenCI, a generative user intent framework that leverages semantic interest cohorts to model dynamic user preferences for CTR prediction. The framework first employs a generative model, trained with a next-item prediction (NTP) objective, to proactively produce candidate interest cohorts. These cohorts serve as explicit, candidate-agnostic representations of a user's immediate intent. A hierarchical candidate-aware network then injects this rich contextual signal into the ranking stage, refining them with cross-attention to align with both user history and the target item. The entire model is trained end-to-end, creating a more aligned and effective CTR prediction pipeline. Extensive experiments on three widely used datasets demonstrate the effectiveness of our approach.",
        "url": "http://arxiv.org/abs/2601.18251v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18251v1",
        "arxiv_id": "2601.18251v1",
        "authors": [
            "Kesha Ou",
            "Zhen Tian",
            "Wayne Xin Zhao",
            "Hongyu Lu",
            "Ji-Rong Wen"
        ],
        "submitted": "2026-01-26 08:15:04",
        "source": "arxiv",
        "comment": "Accepted by WWW 2026 Research Track",
        "score": 13,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'click' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'click-through rate' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper aligns well with your research interests in Information Retrieval, particularly in click models and user behavior modeling. The proposed GenCI framework addresses challenges in CTR prediction, leveraging semantic interest cohorts and contextual signals, which is relevant to your focus on deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval",
        "abstract": "Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions.\n  In this paper, we propose that a retrieval engine must be capable of ``Capturing $\\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\\mathbf{P}$. We introduce \\texttt{ComputePN}, a novel evaluation algorithm that makes $\\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \\texttt{ComputePN} ensures the efficient evaluation of any query in $\\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.",
        "url": "http://arxiv.org/abs/2601.18747v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18747v1",
        "arxiv_id": "2601.18747v1",
        "authors": [
            "Amir Aavani"
        ],
        "submitted": "2026-01-26 18:07:40",
        "source": "arxiv",
        "comment": null,
        "score": 12,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on the expressive power and efficient evaluation of Boolean retrieval, which is somewhat related to information retrieval and search technologies. However, the specific context of complex, neuro-symbolic reasoning workflows and polynomial-time property evaluation does not directly align with the user's core research themes in query understanding, ranking models, and user behavior modeling. While it touches on the efficiency dilemma in retrieval architectures, it does not explore real-time relevance optimization or deep semantic understanding."
    },
    {
        "title": "FastInsight: Fast and Insightful Retrieval via Fusion Operators for Graph RAG",
        "abstract": "Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency.",
        "url": "http://arxiv.org/abs/2601.18579v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18579v1",
        "arxiv_id": "2601.18579v1",
        "authors": [
            "Seonho An",
            "Chaejeong Hyun",
            "Min-Soo Kim"
        ],
        "submitted": "2026-01-26 15:23:41",
        "source": "arxiv",
        "comment": "under review",
        "score": 9,
        "keyword_reasons": [
            "Found 'rerank' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "While this paper explores graph retrieval and fusion operators, it does not directly relate to the user's core research interests in Information Retrieval, query understanding, ranking models, or user behavior modeling. Although it touches on retrieval accuracy and efficiency, the focus is on graph retrieval and Large Language Model reasoning, which is somewhat tangential to the user's primary interests in IR and NLP."
    },
    {
        "title": "Think When Needed: Model-Aware Reasoning Routing for LLM-based Ranking",
        "abstract": "Large language models (LLMs) are increasingly applied to ranking tasks in retrieval and recommendation. Although reasoning prompting can enhance ranking utility, our preliminary exploration reveals that its benefits are inconsistent and come at a substantial computational cost, suggesting that when to reason is as crucial as how to reason. To address this issue, we propose a reasoning routing framework that employs a lightweight, plug-and-play router head to decide whether to use direct inference (Non-Think) or reasoning (Think) for each instance before generation. The router head relies solely on pre-generation signals: i) compact ranking-aware features (e.g., candidate dispersion) and ii) model-aware difficulty signals derived from a diagnostic checklist reflecting the model's estimated need for reasoning. By leveraging these features before generation, the router outputs a controllable token that determines whether to apply the Think mode. Furthermore, the router can adaptively select its operating policy along the validation Pareto frontier during deployment, enabling dynamic allocation of computational resources toward instances most likely to benefit from Think under varying system constraints. Experiments on three public ranking datasets with different scales of open-source LLMs show consistent improvements in ranking utility with reduced token consumption (e.g., +6.3\\% NDCG@10 with -49.5\\% tokens on MovieLens with Qwen3-4B), demonstrating reasoning routing as a practical solution to the accuracy-efficiency trade-off.",
        "url": "http://arxiv.org/abs/2601.18146v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18146v1",
        "arxiv_id": "2601.18146v1",
        "authors": [
            "Huizhong Guo",
            "Tianjun Wei",
            "Dongxia Wang",
            "Yingpeng Du",
            "Ziyan Wang",
            "Jie Zhang",
            "Zhu Sun"
        ],
        "submitted": "2026-01-26 05:09:07",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in ranking models and real-time relevance optimization. The proposed reasoning routing framework for LLM-based ranking is a novel approach that aligns with your focus on deep semantic understanding and query understanding. The paper's emphasis on accuracy-efficiency trade-off and its application to public ranking datasets also resonates with your interests."
    },
    {
        "title": "FadeMem: Biologically-Inspired Forgetting for Efficient Agent Memory",
        "abstract": "Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems.",
        "url": "http://arxiv.org/abs/2601.18642v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18642v1",
        "arxiv_id": "2601.18642v1",
        "authors": [
            "Lei Wei",
            "Xu Dong",
            "Xiao Peng",
            "Niantao Xie",
            "Bin Wang"
        ],
        "submitted": "2026-01-26 16:12:54",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on memory management for large language models, proposing a biologically-inspired forgetting mechanism. While it touches on the concept of relevance and retention, it does not directly address query understanding, ranking models, or user behavior modeling in the context of information retrieval, making it only loosely relevant to your research interests."
    },
    {
        "title": "From Classification to Ranking: Enhancing LLM Reasoning Capabilities for MBTI Personality Detection",
        "abstract": "Personality detection aims to measure an individual's corresponding personality traits through their social media posts. The advancements in Large Language Models (LLMs) offer novel perspectives for personality detection tasks. Existing approaches enhance personality trait analysis by leveraging LLMs to extract semantic information from textual posts as prompts, followed by training classifiers for categorization. However, accurately classifying personality traits remains challenging due to the inherent complexity of human personality and subtle inter-trait distinctions. Moreover, prompt-based methods often exhibit excessive dependency on expert-crafted knowledge without autonomous pattern-learning capacity. To address these limitations, we view personality detection as a ranking task rather than a classification and propose a corresponding reinforcement learning training paradigm. First, we employ supervised fine-tuning (SFT) to establish personality trait ranking capabilities while enforcing standardized output formats, creating a robust initialization. Subsequently, we introduce Group Relative Policy Optimization (GRPO) with a specialized ranking-based reward function. Unlike verification tasks with definitive solutions, personality assessment involves subjective interpretations and blurred boundaries between trait categories. Our reward function explicitly addresses this challenge by training LLMs to learn optimal answer rankings. Comprehensive experiments have demonstrated that our method achieves state-of-the-art performance across multiple personality detection benchmarks.",
        "url": "http://arxiv.org/abs/2601.18582v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18582v1",
        "arxiv_id": "2601.18582v1",
        "authors": [
            "Yuan Cao",
            "Feixiang Liu",
            "Xinyue Wang",
            "Yihan Zhu",
            "Hui Xu",
            "Zheng Wang",
            "Qiang Qiu"
        ],
        "submitted": "2026-01-26 15:28:43",
        "source": "arxiv",
        "comment": "9 pages, 4 figures, AAAI 2026 Bridge",
        "score": 6,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of Large Language Models (LLMs) for personality detection, which is somewhat related to the user's interests in Natural Language Processing (NLP) and deep semantic understanding. However, the focus on personality detection and ranking is not directly aligned with the user's core research themes in Information Retrieval (IR) and Search technologies. The paper's use of reinforcement learning and ranking-based reward function is an interesting aspect, but it does not strongly connect to the user's research interests."
    },
    {
        "title": "Orchestrating Specialized Agents for Trustworthy Enterprise RAG",
        "abstract": "Retrieval-Augmented Generation (RAG) shows promise for enterprise knowledge work, yet it often underperforms in high-stakes decision settings that require deep synthesis, strict traceability, and recovery from underspecified prompts. One-pass retrieval-and-write pipelines frequently yield shallow summaries, inconsistent grounding, and weak mechanisms for completeness verification. We introduce ADORE (Adaptive Deep Orchestration for Research in Enterprise), an agentic framework that replaces linear retrieval with iterative, user-steered investigation coordinated by a central orchestrator and a set of specialized agents. ADORE's key insight is that a structured Memory Bank (a curated evidence store with explicit claim-evidence linkage and section-level admissible evidence) enables traceable report generation and systematic checks for evidence completeness. Our contributions are threefold: (1) Memory-locked synthesis - report generation is constrained to a structured Memory Bank (Claim-Evidence Graph) with section-level admissible evidence, enabling traceable claims and grounded citations; (2) Evidence-coverage-guided execution - a retrieval-reflection loop audits section-level evidence coverage to trigger targeted follow-up retrieval and terminates via an evidence-driven stopping criterion; (3) Section-packed long-context grounding - section-level packing, pruning, and citation-preserving compression make long-form synthesis feasible under context limits. Across our evaluation suite, ADORE ranks first on DeepResearch Bench (52.65) and achieves the highest head-to-head preference win rate on DeepConsult (77.2%) against commercial systems.",
        "url": "http://arxiv.org/abs/2601.18267v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18267v1",
        "arxiv_id": "2601.18267v1",
        "authors": [
            "Xincheng You",
            "Qi Sun",
            "Neha Bora",
            "Huayi Li",
            "Shubham Goel",
            "Kang Li",
            "Sean Culatana"
        ],
        "submitted": "2026-01-26 08:48:41",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper introduces a framework for trustworthy enterprise knowledge work, leveraging Retrieval-Augmented Generation (RAG) with a Memory Bank and specialized agents. While it touches on information retrieval and generation, its focus on enterprise knowledge work and trustworthy decision-making is somewhat tangential to your core research interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR",
        "abstract": "Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains.",
        "url": "http://arxiv.org/abs/2601.18207v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18207v1",
        "arxiv_id": "2601.18207v1",
        "authors": [
            "James Burgess",
            "Jan N. Hansen",
            "Duo Peng",
            "Yuhui Zhang",
            "Alejandro Lozano",
            "Min Woo Sun",
            "Emma Lundberg",
            "Serena Yeung-Levy"
        ],
        "submitted": "2026-01-26 06:46:16",
        "source": "arxiv",
        "comment": "EACL 2026",
        "score": 6,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 9,
        "llm_reason": "This paper aligns closely with your research interests in Information Retrieval, particularly query understanding and ranking models, as it involves training agents to search and reason over scientific papers. The use of reinforcement learning with verifiable rewards (RLVR) and the focus on technical AI systems in science, engineering, and medicine also resonate with your background in e-commerce and NLP."
    },
    {
        "title": "Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.",
        "url": "http://arxiv.org/abs/2601.18771v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18771v1",
        "arxiv_id": "2601.18771v1",
        "authors": [
            "Yanming Liu",
            "Xinyue Peng",
            "Zixuan Yan",
            "Yanxin Shen",
            "Wenjie Xu",
            "Yuefeng Huang",
            "Xinyi Wang",
            "Jiannan Cao",
            "Jianwei Yin",
            "Xuhong Zhang"
        ],
        "submitted": "2026-01-26 18:42:33",
        "source": "arxiv",
        "comment": "Dep-Search 1st version",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper proposes a dependency-aware search framework (Dep-Search) that integrates structured reasoning, retrieval, and persistent memory, which aligns with your interests in query understanding, ranking models, and user behavior modeling. Although the primary focus is on large language models and question answering, the framework's ability to manage dependencies and reuse previously retrieved knowledge is relevant to your research in information retrieval and search technologies."
    },
    {
        "title": "HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences",
        "abstract": "Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as \"HalluCitation\" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.",
        "url": "http://arxiv.org/abs/2601.18724v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18724v1",
        "arxiv_id": "2601.18724v1",
        "authors": [
            "Yusuke Sakai",
            "Hidetaka Kamigaito",
            "Taro Watanabe"
        ],
        "submitted": "2026-01-26 17:48:23",
        "source": "arxiv",
        "comment": "Work In Progress",
        "score": 5,
        "keyword_reasons": [
            "Found 'acl' (score: +2)",
            "Found 'naacl' (score: +1)",
            "Found 'emnlp' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not related to Information Retrieval, Search technologies, or any of the user's core research themes. It focuses on the issue of hallucinated citations in conference papers, which is a concern for scientific reliability and credibility, but does not align with the user's research interests in IR, NLP, and related topics."
    },
    {
        "title": "Token-level Collaborative Alignment for LLM-based Generative Recommendation",
        "abstract": "Large Language Models (LLMs) have demonstrated strong potential for generative recommendation by leveraging rich semantic knowledge. However, existing LLM-based recommender systems struggle to effectively incorporate collaborative filtering (CF) signals, due to a fundamental mismatch between item-level preference modeling in CF and token-level next-token prediction (NTP) optimization in LLMs. Prior approaches typically treat CF as contextual hints or representation bias, and resort to multi-stage training to reduce behavioral semantic space discrepancies, leaving CF unable to explicitly regulate LLM generation. In this work, we propose Token-level Collaborative Alignment for Recommendation (TCA4Rec), a model-agnostic and plug-and-play framework that establishes an explicit optimization-level interface between CF supervision and LLM generation. TCA4Rec consists of (i) Collaborative Tokenizer, which projects raw item-level CF logits into token-level distributions aligned with the LLM token space, and (ii) Soft Label Alignment, which integrates these CF-informed distributions with one-hot supervision to optimize a soft NTP objective. This design preserves the generative nature of LLM training while enabling collaborative alignment with essential user preference of CF models. We highlight TCA4Rec is compatible with arbitrary traditional CF models and generalizes across a wide range of decoder-based LLM recommender architectures. Moreover, it provides an explicit mechanism to balance behavioral alignment and semantic fluency, yielding generative recommendations that are both accurate and controllable. Extensive experiments demonstrate that TCA4Rec consistently improves recommendation performance across a broad spectrum of CF models and LLM-based recommender systems.",
        "url": "http://arxiv.org/abs/2601.18457v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18457v1",
        "arxiv_id": "2601.18457v1",
        "authors": [
            "Fake Lin",
            "Binbin Hu",
            "Zhi Zheng",
            "Xi Zhu",
            "Ziqi Liu",
            "Zhiqiang Zhang",
            "Jun Zhou",
            "Tong Xu"
        ],
        "submitted": "2026-01-26 13:05:02",
        "source": "arxiv",
        "comment": "11 pages, 2 figures, 7 tables, WWW 2026",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores a novel approach to integrating collaborative filtering and large language models for recommendation. While it touches on aspects of query understanding and ranking models, its primary focus is on recommender systems, which is somewhat related to your interests in information retrieval. However, the emphasis on generative recommendation and LLMs is not a central match for your core research themes."
    },
    {
        "title": "CitiLink: Enhancing Municipal Transparency and Citizen Engagement through Searchable Meeting Minutes",
        "abstract": "City council minutes are typically lengthy and formal documents with a bureaucratic writing style. Although publicly available, their structure often makes it difficult for citizens or journalists to efficiently find information. In this demo, we present CitiLink, a platform designed to transform unstructured municipal meeting minutes into structured and searchable data, demonstrating how NLP and IR can enhance the accessibility and transparency of local government. The system employs LLMs to extract metadata, discussed subjects, and voting outcomes, which are then indexed in a database to support full-text search with BM25 ranking and faceted filtering through a user-friendly interface. The developed system was built over a collection of 120 minutes made available by six Portuguese municipalities. To assess its usability, CitiLink was tested through guided sessions with municipal personnel, providing insights into how real users interact with the system. In addition, we evaluated Gemini's performance in extracting relevant information from the minutes, highlighting its effectiveness in data extraction.",
        "url": "http://arxiv.org/abs/2601.18374v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18374v1",
        "arxiv_id": "2601.18374v1",
        "authors": [
            "Rodrigo Silva",
            "José Evans",
            "José Isidro",
            "Miguel Marques",
            "Afonso Fonseca",
            "Ricardo Morais",
            "João Canavilhas",
            "Arian Pasquali",
            "Purificação Silvano",
            "Alípio Jorge",
            "Nuno Guimarães",
            "Sérgio Nunes",
            "Ricardo Campos"
        ],
        "submitted": "2026-01-26 11:26:57",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Search technologies, particularly in the application of NLP and IR to enhance accessibility and transparency of local government. The use of LLMs, BM25 ranking, and faceted filtering aligns with your focus on query understanding and ranking models. However, the specific domain and application of the paper are somewhat different from your primary focus on e-commerce and deep semantic understanding."
    },
    {
        "title": "PEAR: Pairwise Evaluation for Automatic Relative Scoring in Machine Translation",
        "abstract": "We present PEAR (Pairwise Evaluation for Automatic Relative Scoring), a supervised Quality Estimation (QE) metric family that reframes reference-free Machine Translation (MT) evaluation as a graded pairwise comparison. Given a source segment and two candidate translations, PEAR predicts the direction and magnitude of their quality difference. The metrics are trained using pairwise supervision derived from differences in human judgments, with an additional regularization term that encourages sign inversion under candidate order reversal. On the WMT24 meta-evaluation benchmark, PEAR outperforms strictly matched single-candidate QE baselines trained with the same data and backbones, isolating the benefit of the proposed pairwise formulation. Despite using substantially fewer parameters than recent large metrics, PEAR surpasses far larger QE models and reference-based metrics. Our analysis further indicates that PEAR yields a less redundant evaluation signal relative to other top metrics. Finally, we show that PEAR is an effective utility function for Minimum Bayes Risk (MBR) decoding, reducing pairwise scoring cost at negligible impact.",
        "url": "http://arxiv.org/abs/2601.18006v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18006v1",
        "arxiv_id": "2601.18006v1",
        "authors": [
            "Lorenzo Proietti",
            "Roman Grundkiewicz",
            "Matt Post"
        ],
        "submitted": "2026-01-25 21:52:30",
        "source": "arxiv",
        "comment": "18 pages",
        "score": 5,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus is on Machine Translation and Quality Estimation, which is a different area of NLP. While it involves ranking and evaluation, it's not directly related to your core themes."
    },
    {
        "title": "SD-E$^2$: Semantic Exploration for Reasoning Under Token Budgets",
        "abstract": "Small language models (SLMs) struggle with complex reasoning because exploration is expensive under tight compute budgets. We introduce Semantic Diversity-Exploration-Exploitation (SD-E$^2$), a reinforcement learning framework that makes exploration explicit by optimizing semantic diversity in generated reasoning trajectories. Using a frozen sentence-embedding model, SD-E$^2$ assigns a diversity reward that captures (i) the coverage of semantically distinct solution strategies and (ii) their average pairwise dissimilarity in embedding space, rather than surface-form novelty. This diversity reward is combined with outcome correctness and solution efficiency in a z-score-normalized multi-objective objective that stabilizes training. On GSM8K, SD-E$^2$ surpasses the base Qwen2.5-3B-Instruct and strong GRPO baselines (GRPO-CFL and GRPO-CFEE) by +27.4, +5.2, and +1.5 percentage points, respectively, while discovering on average 9.8 semantically distinct strategies per question. We further improve MedMCQA to 49.64% versus 38.37% for the base model and show gains on the harder AIME benchmark (1983-2025), reaching 13.28% versus 6.74% for the base. These results indicate that rewarding semantic novelty yields a more compute-efficient exploration-exploitation signal for training reasoning-capable SLMs. By introducing cognitive adaptation-adjusting the reasoning process structure rather than per-token computation-SD-E$^2$ offers a complementary path to efficiency gains in resource-constrained models.",
        "url": "http://arxiv.org/abs/2601.17982v1",
        "pdf_url": "https://arxiv.org/pdf/2601.17982v1",
        "arxiv_id": "2601.17982v1",
        "authors": [
            "Kshitij Mishra",
            "Nils Lukas",
            "Salem Lahlou"
        ],
        "submitted": "2026-01-25 20:21:52",
        "source": "arxiv",
        "comment": "Accepted at EACL 2026",
        "score": 5,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper explores a reinforcement learning framework for semantic diversity in generated reasoning trajectories, which aligns with the user's interests in query understanding and ranking models. However, the focus on small language models and reasoning capabilities is somewhat related but not a central match to the user's primary focus on information retrieval and real-time relevance optimization."
    },
    {
        "title": "POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration",
        "abstract": "Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.",
        "url": "http://arxiv.org/abs/2601.18779v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18779v1",
        "arxiv_id": "2601.18779v1",
        "authors": [
            "Yuxiao Qu",
            "Amrith Setlur",
            "Virginia Smith",
            "Ruslan Salakhutdinov",
            "Aviral Kumar"
        ],
        "submitted": "2026-01-26 18:47:21",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on reinforcement learning and its application to large language models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on the concept of reasoning and optimization, the context is different and not aligned with your primary focus on real-time relevance optimization and deep semantic understanding."
    },
    {
        "title": "Exploring Fine-Tuning for In-Context Retrieval and Efficient KV-Caching in Long-Context Language Models",
        "abstract": "With context windows of millions of tokens, Long-Context Language Models (LCLMs) can encode entire document collections, offering a strong alternative to conventional retrieval-augmented generation (RAG). However, it remains unclear whether fine-tuning strategies can improve long-context performance and translate to greater robustness under KV-cache compression techniques. In this work, we investigate which training strategies most effectively enhance LCLMs' ability to identify and use relevant information, as well as enhancing their robustness under KV-cache compression. Our experiments show substantial in-domain improvements, achieving gains of up to +20 points over the base model. However, out-of-domain generalization remains task dependent with large variance -- LCLMs excels on finance questions (+9 points), while RAG shows stronger performance on multiple-choice questions (+6 points) over the baseline models. Finally, we show that our fine-tuning approaches bring moderate improvements in robustness under KV-cache compression, with gains varying across tasks.",
        "url": "http://arxiv.org/abs/2601.18527v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18527v1",
        "arxiv_id": "2601.18527v1",
        "authors": [
            "Francesco Maria Molfese",
            "Momchil Hardalov",
            "Rexhina Blloshmi",
            "Bill Byrne",
            "Adrià de Gispert"
        ],
        "submitted": "2026-01-26 14:37:02",
        "source": "arxiv",
        "comment": "European Chapter of the Association for Computational Linguistics EACL 2026",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper explores the performance of Long-Context Language Models in retrieval tasks, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the focus on fine-tuning and KV-cache compression is not directly aligned with your core research themes, such as query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "DMAP: Human-Aligned Structural Document Map for Multimodal Document Understanding",
        "abstract": "Existing multimodal document question-answering (QA) systems predominantly rely on flat semantic retrieval, representing documents as a set of disconnected text chunks and largely neglecting their intrinsic hierarchical and relational structures. Such flattening disrupts logical and spatial dependencies - such as section organization, figure-text correspondence, and cross-reference relations, that humans naturally exploit for comprehension. To address this limitation, we introduce a document-level structural Document MAP (DMAP), which explicitly encodes both hierarchical organization and inter-element relationships within multimodal documents. Specifically, we design a Structured-Semantic Understanding Agent to construct DMAP by organizing textual content together with figures, tables, charts, etc. into a human-aligned hierarchical schema that captures both semantic and layout dependencies. Building upon this representation, a Reflective Reasoning Agent performs structure-aware and evidence-driven reasoning, dynamically assessing the sufficiency of retrieved context and iteratively refining answers through targeted interactions with DMAP. Extensive experiments on MMDocQA benchmarks demonstrate that DMAP yields document-specific structural representations aligned with human interpretive patterns, substantially enhancing retrieval precision, reasoning consistency, and multimodal comprehension over conventional RAG-based approaches. Code is available at https://github.com/Forlorin/DMAP",
        "url": "http://arxiv.org/abs/2601.18203v2",
        "pdf_url": "https://arxiv.org/pdf/2601.18203v2",
        "arxiv_id": "2601.18203v2",
        "authors": [
            "ShunLiang Fu",
            "Yanxin Zhang",
            "Yixin Xiang",
            "Xiaoyu Du",
            "Jinhui Tang"
        ],
        "submitted": "2026-01-26 06:38:25",
        "source": "arxiv",
        "comment": "WebConf 2026",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the area of multimodal document understanding and question-answering systems. However, it focuses more on the structural representation of documents rather than query understanding, ranking models, or user behavior modeling, which are your core areas of interest."
    },
    {
        "title": "FABLE: Forest-Based Adaptive Bi-Path LLM-Enhanced Retrieval for Multi-Document Reasoning",
        "abstract": "The rapid expansion of long-context Large Language Models (LLMs) has reignited debate on whether Retrieval-Augmented Generation (RAG) remains necessary. However, empirical evidence reveals persistent limitations of long-context inference, including the lost-in-the-middle phenomenon, high computational cost, and poor scalability for multi-document reasoning. Conversely, traditional RAG systems, while efficient, are constrained by flat chunk-level retrieval that introduces semantic noise and fails to support structured cross-document synthesis.\n  We present \\textbf{FABLE}, a \\textbf{F}orest-based \\textbf{A}daptive \\textbf{B}i-path \\textbf{L}LM-\\textbf{E}nhanced retrieval framework that integrates LLMs into both knowledge organization and retrieval. FABLE constructs LLM-enhanced hierarchical forest indexes with multi-granularity semantic structures, then employs a bi-path strategy combining LLM-guided hierarchical traversal with structure-aware propagation for fine-grained evidence acquisition, with explicit budget control for adaptive efficiency trade-offs.\n  Extensive experiments demonstrate that FABLE consistently outperforms SOTA RAG methods and achieves comparable accuracy to full-context LLM inference with up to 94\\% token reduction, showing that long-context LLMs amplify rather than fully replace the need for structured retrieval.",
        "url": "http://arxiv.org/abs/2601.18116v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18116v1",
        "arxiv_id": "2601.18116v1",
        "authors": [
            "Lin Sun",
            "Linglin Zhang",
            "Jingang Huang",
            "Change Jia",
            "Zhengwei Cheng",
            "Xiangzheng Zhang"
        ],
        "submitted": "2026-01-26 04:00:56",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper presents a novel retrieval framework, FABLE, which integrates Large Language Models (LLMs) into both knowledge organization and retrieval. Although it's primarily focused on multi-document reasoning and retrieval, it touches on query understanding and ranking models, making it somewhat relevant to your interests in Information Retrieval and Search technologies. However, the specific application domain and emphasis on LLMs and multi-document reasoning make it less central to your core research themes."
    },
    {
        "title": "Gained in Translation: Privileged Pairwise Judges Enhance Multilingual Reasoning",
        "abstract": "When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \\texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \\textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \\textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \\texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than\n  of the training data across the single-language, multilingual, and generalization to unseen language settings.",
        "url": "http://arxiv.org/abs/2601.18722v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18722v1",
        "arxiv_id": "2601.18722v1",
        "authors": [
            "Lintang Sutawika",
            "Gokul Swamy",
            "Zhiwei Steven Wu",
            "Graham Neubig"
        ],
        "submitted": "2026-01-26 17:46:44",
        "source": "arxiv",
        "comment": "Code available at https://github.com/lintangsutawika/SP3F",
        "score": 3,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on enhancing multilingual reasoning in large language models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on language translation and model fine-tuning does not directly align with the user's core research themes in IR and Search technologies. The paper's relevance is somewhat enhanced by its use of self-play and feedback mechanisms, but it does not strongly overlap with the user's interests in user behavior modeling, click models, or recommender systems."
    },
    {
        "title": "One Persona, Many Cues, Different Results: How Sociodemographic Cues Impact LLM Personalization",
        "abstract": "Personalization of LLMs by sociodemographic subgroup often improves user experience, but can also introduce or amplify biases and unfair outcomes across groups. Prior work has employed so-called personas, sociodemographic user attributes conveyed to a model, to study bias in LLMs by relying on a single cue to prompt a persona, such as user names or explicit attribute mentions. This disregards LLM sensitivity to prompt variations (robustness) and the rarity of some cues in real interactions (external validity). We compare six commonly used persona cues across seven open and proprietary LLMs on four writing and advice tasks. While cues are overall highly correlated, they produce substantial variance in responses across personas. We therefore caution against claims from a single persona cue and recommend future personalization research to evaluate multiple externally valid cues.",
        "url": "http://arxiv.org/abs/2601.18572v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18572v1",
        "arxiv_id": "2601.18572v1",
        "authors": [
            "Franziska Weeber",
            "Vera Neplenbroek",
            "Jan Batzner",
            "Sebastian Padó"
        ],
        "submitted": "2026-01-26 15:15:58",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'personalization' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the personalization of Large Language Models (LLMs) using sociodemographic cues, which is somewhat related to your interests in Information Retrieval and Natural Language Processing. However, the focus on LLMs and personalization is not directly aligned with your primary research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Demographic Probing of Large Language Models Lacks Construct Validity",
        "abstract": "Demographic probing is widely used to study how large language models (LLMs) adapt their behavior to signaled demographic attributes. This approach typically uses a single demographic cue in isolation (e.g., a name or dialect) as a signal for group membership, implicitly assuming strong construct validity: that such cues are interchangeable operationalizations of the same underlying, demographically conditioned behavior. We test this assumption in realistic advice-seeking interactions, focusing on race and gender in a U.S. context. We find that cues intended to represent the same demographic group induce only partially overlapping changes in model behavior, while differentiation between groups within a given cue is weak and uneven. Consequently, estimated disparities are unstable, with both magnitude and direction varying across cues. We further show that these inconsistencies partly arise from variation in how strongly cues encode demographic attributes and from linguistic confounders that independently shape model behavior. Together, our findings suggest that demographic probing lacks construct validity: it does not yield a single, stable characterization of how LLMs condition on demographic information, which may reflect a misspecified or fragmented construct. We conclude by recommending the use of multiple, ecologically valid cues and explicit control of confounders to support more defensible claims about demographic effects in LLMs.",
        "url": "http://arxiv.org/abs/2601.18486v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18486v1",
        "arxiv_id": "2601.18486v1",
        "authors": [
            "Manuel Tonneau",
            "Neil K. R. Seghal",
            "Niyati Malhotra",
            "Victor Orozco-Olvera",
            "Ana María Muñoz Boudet",
            "Lakshmi Subramanian",
            "Sharath Chandra Guntuku",
            "Valentin Hofmann"
        ],
        "submitted": "2026-01-26 13:41:35",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. The focus on demographic probing of Large Language Models and its implications for construct validity is more aligned with NLP and AI ethics, but it does not address your core areas of interest."
    },
    {
        "title": "Corpus-Based Approaches to Igbo Diacritic Restoration",
        "abstract": "With natural language processing (NLP), researchers aim to enable computers to identify and understand patterns in human languages. This is often difficult because a language embeds many dynamic and varied properties in its syntax, pragmatics and phonology, which need to be captured and processed. The capacity of computers to process natural languages is increasing because NLP researchers are pushing its boundaries. But these research works focus more on well-resourced languages such as English, Japanese, German, French, Russian, Mandarin Chinese, etc. Over 95% of the world's 7000 languages are low-resourced for NLP, i.e. they have little or no data, tools, and techniques for NLP work.\n  In this thesis, we present an overview of diacritic ambiguity and a review of previous diacritic disambiguation approaches on other languages. Focusing on the Igbo language, we report the steps taken to develop a flexible framework for generating datasets for diacritic restoration. Three main approaches, the standard n-gram model, the classification models and the embedding models were proposed. The standard n-gram models use a sequence of previous words to the target stripped word as key predictors of the correct variants. For the classification models, a window of words on both sides of the target stripped word was used. The embedding models compare the similarity scores of the combined context word embeddings and the embeddings of each of the candidate variant vectors.",
        "url": "http://arxiv.org/abs/2601.18380v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18380v1",
        "arxiv_id": "2601.18380v1",
        "authors": [
            "Ignatius Ezeani"
        ],
        "submitted": "2026-01-26 11:30:36",
        "source": "arxiv",
        "comment": "270 page. Ph.D. Thesis. The University of Sheffield",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on diacritic restoration in the Igbo language, which is a low-resourced language for NLP. While it involves NLP techniques, it does not align with the user's core research themes in Information Retrieval, Search technologies, or related topics such as query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books",
        "abstract": "Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes \"good writing.\" These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.",
        "url": "http://arxiv.org/abs/2601.18353v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18353v1",
        "arxiv_id": "2601.18353v1",
        "authors": [
            "Tuhin Chakrabarty",
            "Paramveer S. Dhillon"
        ],
        "submitted": "2026-01-26 10:59:21",
        "source": "arxiv",
        "comment": "Proceedings of CHI 2026 Conference (To Appear)",
        "score": 3,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing, as it focuses on Generative AI in creative writing, which is outside your primary areas of focus."
    },
    {
        "title": "U-Fold: Dynamic Intent-Aware Context Folding for User-Centric Agents",
        "abstract": "Large language model (LLM)-based agents have been successfully deployed in many tool-augmented settings, but their scalability is fundamentally constrained by context length. Existing context-folding methods mitigate this issue by summarizing past interactions, yet they are typically designed for single-query or single-intent scenarios. In more realistic user-centric dialogues, we identify two major failure modes: (i) they irreversibly discard fine-grained constraints and intermediate facts that are crucial for later decisions, and (ii) their summaries fail to track evolving user intent, leading to omissions and erroneous actions. To address these limitations, we propose U-Fold, a dynamic context-folding framework tailored to user-centric tasks. U-Fold retains the full user--agent dialogue and tool-call history but, at each turn, uses two core components to produce an intent-aware, evolving dialogue summary and a compact, task-relevant tool log. Extensive experiments on $τ$-bench, $τ^2$-bench, VitaBench, and harder context-inflated settings show that U-Fold consistently outperforms ReAct (achieving a 71.4% win rate in long-context settings) and prior folding baselines (with improvements of up to 27.0%), particularly on long, noisy, multi-turn tasks. Our study demonstrates that U-Fold is a promising step toward transferring context-management techniques from single-query benchmarks to realistic user-centric applications.",
        "url": "http://arxiv.org/abs/2601.18285v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18285v1",
        "arxiv_id": "2601.18285v1",
        "authors": [
            "Jin Su",
            "Runnan Fang",
            "Yeqiu Li",
            "Xiaobin Wang",
            "Shihao Cai",
            "Pengjun Xie",
            "Ningyu Zhang",
            "Fajie Yuan"
        ],
        "submitted": "2026-01-26 09:11:49",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper explores context-folding for user-centric agents, which is somewhat related to query understanding and user behavior modeling in Information Retrieval. However, the focus on dialogue summarization and intent-aware context management is not a central match to your primary research interests in IR and Search technologies. The connection to NLP is more relevant, but still not a direct alignment."
    },
    {
        "title": "Generative Chain of Behavior for User Trajectory Prediction",
        "abstract": "Modeling long-term user behavior trajectories is essential for understanding evolving preferences and enabling proactive recommendations. However, most sequential recommenders focus on next-item prediction, overlooking dependencies across multiple future actions. We propose Generative Chain of Behavior (GCB), a generative framework that models user interactions as an autoregressive chain of semantic behaviors over multiple future steps. GCB first encodes items into semantic IDs via RQ-VAE with k-means refinement, forming a discrete latent space that preserves semantic proximity. On top of this space, a transformer-based autoregressive generator predicts multi-step future behaviors conditioned on user history, capturing long-horizon intent transitions and generating coherent trajectories. Experiments on benchmark datasets show that GCB consistently outperforms state-of-the-art sequential recommenders in multi-step accuracy and trajectory consistency. Beyond these gains, GCB offers a unified generative formulation for capturing user preference evolution.",
        "url": "http://arxiv.org/abs/2601.18213v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18213v1",
        "arxiv_id": "2601.18213v1",
        "authors": [
            "Chengkai Huang",
            "Xiaodi Chen",
            "Hongtao Huang",
            "Quan Z. Sheng",
            "Lina Yao"
        ],
        "submitted": "2026-01-26 06:57:31",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'user behavior' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on user behavior modeling and sequential recommendation, which is somewhat related to your interests in Information Retrieval and user behavior modeling. However, the emphasis on recommender systems and sequential prediction is not a central match for your primary focus on information retrieval and deep semantic understanding."
    },
    {
        "title": "Fine-Grained Emotion Detection on GoEmotions: Experimental Comparison of Classical Machine Learning, BiLSTM, and Transformer Models",
        "abstract": "Fine-grained emotion recognition is a challenging multi-label NLP task due to label overlap and class imbalance. In this work, we benchmark three modeling families on the GoEmotions dataset: a TF-IDF-based logistic regression system trained with binary relevance, a BiLSTM with attention, and a BERT model fine-tuned for multi-label classification. Experiments follow the official train/validation/test split, and imbalance is mitigated using inverse-frequency class weights. Across several metrics, namely Micro-F1, Macro-F1, Hamming Loss, and Subset Accuracy, we observe that logistic regression attains the highest Micro-F1 of 0.51, while BERT achieves the best overall balance surpassing the official paper's reported results, reaching Macro-F1 0.49, Hamming Loss 0.036, and Subset Accuracy 0.36. This suggests that frequent emotions often rely on surface lexical cues, whereas contextual representations improve performance on rarer emotions and more ambiguous examples.",
        "url": "http://arxiv.org/abs/2601.18162v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18162v1",
        "arxiv_id": "2601.18162v1",
        "authors": [
            "Ani Harutyunyan",
            "Sachin Kumar"
        ],
        "submitted": "2026-01-26 05:29:27",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on fine-grained emotion detection, which is a topic in Natural Language Processing (NLP). While it involves machine learning and deep learning models, it is not directly related to Information Retrieval (IR), query understanding, or ranking models, which are core areas of your research interests."
    },
    {
        "title": "Enhancing LLM-based Recommendation with Preference Hint Discovery from Knowledge Graph",
        "abstract": "LLMs have garnered substantial attention in recommendation systems. Yet they fall short of traditional recommenders when capturing complex preference patterns. Recent works have tried integrating traditional recommendation embeddings into LLMs to resolve this issue, yet a core gap persists between their continuous embedding and discrete semantic spaces. Intuitively, textual attributes derived from interactions can serve as critical preference rationales for LLMs' recommendation logic. However, directly inputting such attribute knowledge presents two core challenges: (1) Deficiency of sparse interactions in reflecting preference hints for unseen items; (2) Substantial noise introduction from treating all attributes as hints. To this end, we propose a preference hint discovery model based on the interaction-integrated knowledge graph, enhancing LLM-based recommendation. It utilizes traditional recommendation principles to selectively extract crucial attributes as hints. Specifically, we design a collaborative preference hint extraction schema, which utilizes semantic knowledge from similar users' explicit interactions as hints for unseen items. Furthermore, we develop an instance-wise dual-attention mechanism to quantify the preference credibility of candidate attributes, identifying hints specific to each unseen item. Using these item- and user-based hints, we adopt a flattened hint organization method to shorten input length and feed the textual hint information to the LLM for commonsense reasoning. Extensive experiments on both pair-wise and list-wise recommendation tasks verify the effectiveness of our proposed framework, indicating an average relative improvement of over 3.02% against baselines.",
        "url": "http://arxiv.org/abs/2601.18096v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18096v1",
        "arxiv_id": "2601.18096v1",
        "authors": [
            "Yuting Zhang",
            "Ziliang Pei",
            "Chao Wang",
            "Ying Sun",
            "Fuzhen Zhuang"
        ],
        "submitted": "2026-01-26 03:20:42",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a method to enhance LLM-based recommendation systems by discovering preference hints from a knowledge graph. While it touches on aspects of information retrieval and natural language processing, its primary focus is on recommendation systems, which is somewhat related to the user's interests in information retrieval and search technologies. However, the paper's emphasis on recommender systems and the specific application to LLM-based recommendation limits its relevance to the user's core research themes."
    },
    {
        "title": "Evaluating Semantic and Syntactic Understanding in Large Language Models for Payroll Systems",
        "abstract": "Large language models are now used daily for writing, search, and analysis, and their natural language understanding continues to improve. However, they remain unreliable on exact numerical calculation and on producing outputs that are straightforward to audit. We study synthetic payroll system as a focused, high-stakes example and evaluate whether models can understand a payroll schema, apply rules in the right order, and deliver cent-accurate results. Our experiments span a tiered dataset from basic to complex cases, a spectrum of prompts from minimal baselines to schema-guided and reasoning variants, and multiple model families including GPT, Claude, Perplexity, Grok and Gemini. Results indicate clear regimes where careful prompting is sufficient and regimes where explicit computation is required. The work offers a compact, reproducible framework and practical guidance for deploying LLMs in settings that demand both accuracy and assurance.",
        "url": "http://arxiv.org/abs/2601.18012v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18012v1",
        "arxiv_id": "2601.18012v1",
        "authors": [
            "Hendrika Maclean",
            "Mert Can Cakmak",
            "Muzakkiruddin Ahmed Mohammed",
            "Shames Al Mandalawi",
            "John Talburt"
        ],
        "submitted": "2026-01-25 22:12:22",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper evaluates the performance of large language models in a payroll system, focusing on their ability to understand and apply rules. While it touches on natural language understanding, it is primarily concerned with numerical calculation and auditing, which is somewhat related to information retrieval but not a central match to your research interests."
    },
    {
        "title": "LLMs as Cultural Archives: Cultural Commonsense Knowledge Graph Extraction",
        "abstract": "Large language models (LLMs) encode rich cultural knowledge learned from diverse web-scale data, offering an unprecedented opportunity to model cultural commonsense at scale. Yet this knowledge remains mostly implicit and unstructured, limiting its interpretability and use. We present an iterative, prompt-based framework for constructing a Cultural Commonsense Knowledge Graph (CCKG) that treats LLMs as cultural archives, systematically eliciting culture-specific entities, relations, and practices and composing them into multi-step inferential chains across languages. We evaluate CCKG on five countries with human judgments of cultural relevance, correctness, and path coherence. We find that the cultural knowledge graphs are better realized in English, even when the target culture is non-English (e.g., Chinese, Indonesian, Arabic), indicating uneven cultural encoding in current LLMs. Augmenting smaller LLMs with CCKG improves performance on cultural reasoning and story generation, with the largest gains from English chains. Our results show both the promise and limits of LLMs as cultural technologies and that chain-structured cultural knowledge is a practical substrate for culturally grounded NLP.",
        "url": "http://arxiv.org/abs/2601.17971v1",
        "pdf_url": "https://arxiv.org/pdf/2601.17971v1",
        "arxiv_id": "2601.17971v1",
        "authors": [
            "Junior Cedric Tonga",
            "Chen Cecilia Liu",
            "Iryna Gurevych",
            "Fajri Koto"
        ],
        "submitted": "2026-01-25 20:05:04",
        "source": "arxiv",
        "comment": "EACL 2026 MAIN",
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the cultural knowledge encoded in Large Language Models (LLMs), which is somewhat related to the user's interests in Information Retrieval and Natural Language Processing. However, the focus on cultural commonsense knowledge graph extraction and its application to NLP tasks is not directly aligned with the user's primary research themes, such as query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "MEGnifying Emotion: Sentiment Analysis from Annotated Brain Data",
        "abstract": "Decoding emotion from brain activity could unlock a deeper understanding of the human experience. While a number of existing datasets align brain data with speech and with speech transcripts, no datasets have annotated brain data with sentiment. To bridge this gap, we explore the use of pre-trained Text-to-Sentiment models to annotate non invasive brain recordings, acquired using magnetoencephalography (MEG), while participants listened to audiobooks. Having annotated the text, we employ force-alignment of the text and audio to align our sentiment labels with the brain recordings. It is straightforward then to train Brainto-Sentiment models on these data. Experimental results show an improvement in balanced accuracy for Brain-to-Sentiment compared to baseline, supporting the proposed approach as a proof-of-concept for leveraging existing MEG datasets and learning to decode sentiment directly from the brain.",
        "url": "http://arxiv.org/abs/2601.18792v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18792v1",
        "arxiv_id": "2601.18792v1",
        "authors": [
            "Brian Liu",
            "Oiwi Parker Jones"
        ],
        "submitted": "2026-01-26 18:55:44",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on sentiment analysis from brain activity, which is a topic in Natural Language Processing (NLP), but it does not align with the user's primary interests in Information Retrieval (IR), query understanding, ranking models, and user behavior modeling. The paper's use of magnetoencephalography (MEG) and brain recordings is not directly related to the user's background in e-commerce or their focus on real-time relevance optimization."
    },
    {
        "title": "Unsupervised Text Segmentation via Kernel Change-Point Detection on Sentence Embeddings",
        "abstract": "Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation.",
        "url": "http://arxiv.org/abs/2601.18788v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18788v1",
        "arxiv_id": "2601.18788v1",
        "authors": [
            "Mumin Jia",
            "Jairo Diaz-Rodriguez"
        ],
        "submitted": "2026-01-26 18:54:34",
        "source": "arxiv",
        "comment": "arXiv admin note: substantial text overlap with arXiv:2510.03437. substantial text overlap with arXiv:2510.03437. substantial text overlap with arXiv:2510.03437. substantial text overlap with arXiv:2510.03437",
        "score": 2,
        "keyword_reasons": [
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper on unsupervised text segmentation via kernel change-point detection on sentence embeddings is somewhat related to the user's interests in Information Retrieval and Natural Language Processing. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's focus on text segmentation and sentence embeddings is somewhat tangential to the user's primary research themes."
    },
    {
        "title": "Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability",
        "abstract": "Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.",
        "url": "http://arxiv.org/abs/2601.18778v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18778v1",
        "arxiv_id": "2601.18778v1",
        "authors": [
            "Shobhita Sundaram",
            "John Quan",
            "Ariel Kwiatkowski",
            "Kartik Ahuja",
            "Yann Ollivier",
            "Julia Kempe"
        ],
        "submitted": "2026-01-26 18:46:56",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores a self-improvement framework for large reasoning models, leveraging latent knowledge to generate an automated curriculum. While it touches on aspects of learning and optimization, it doesn't directly relate to query understanding, ranking models, or user behavior modeling in the context of information retrieval. The focus on meta-RL and self-play is more aligned with NLP and deep learning, but the connection to IR is tenuous."
    },
    {
        "title": "Beyond Preferences: Learning Alignment Principles Grounded in Human Reasons and Values",
        "abstract": "A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \\textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \\textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic.",
        "url": "http://arxiv.org/abs/2601.18760v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18760v1",
        "arxiv_id": "2601.18760v1",
        "authors": [
            "Henry Bell",
            "Lara Neubauer da Costa Schertel",
            "Bochu Ding",
            "Brandon Fain"
        ],
        "submitted": "2026-01-26 18:27:00",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, which are your core research themes. While it touches on Natural Language Processing through the use of Large Language Models, its focus on alignment principles and human values is not a central match for your research interests."
    },
    {
        "title": "Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models",
        "abstract": "Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.",
        "url": "http://arxiv.org/abs/2601.18734v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18734v1",
        "arxiv_id": "2601.18734v1",
        "authors": [
            "Siyan Zhao",
            "Zhihui Xie",
            "Mengchen Liu",
            "Jing Huang",
            "Guan Pang",
            "Feiyu Chen",
            "Aditya Grover"
        ],
        "submitted": "2026-01-26 17:56:50",
        "source": "arxiv",
        "comment": "13 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on knowledge distillation and large language models, which is somewhat related to your interests in Natural Language Processing (NLP) and related topics. However, the specific context of large language models and knowledge distillation does not directly align with your core research themes in Information Retrieval (IR), query understanding, and ranking models."
    },
    {
        "title": "AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning",
        "abstract": "When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \\textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.",
        "url": "http://arxiv.org/abs/2601.18631v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18631v1",
        "arxiv_id": "2601.18631v1",
        "authors": [
            "Mingyang Song",
            "Haoyu Sun",
            "Jiawei Gu",
            "Linjie Li",
            "Luxin Xu",
            "Ranjay Krishna",
            "Yu Cheng"
        ],
        "submitted": "2026-01-26 16:04:43",
        "source": "arxiv",
        "comment": "28 pages, 10 figures and 13 tables",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multimodal large language models and tool orchestration for visual reasoning, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves multimodal models and learning, the context is more aligned with visual reasoning and tool use rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Evaluating Morphological Plausibility of Subword Tokenization via Statistical Alignment with Morpho-Syntactic Features",
        "abstract": "We present a novel metric for the evaluation of the morphological plausibility of subword segmentation. Unlike the typically used morpheme boundary or retrieval F-score, which requires gold segmentation data that is either unavailable or of inconsistent quality across many languages, our approach utilizes morpho-syntactic features. These are available in resources such as Universal Dependencies or UniMorph for a much wider range of languages. The metric works by probabilistically aligning subwords with morphological features through an IBM Model 1. Our experiments show that the metric correlates well with traditional morpheme boundary recall while being more broadly applicable across languages with different morphological systems.",
        "url": "http://arxiv.org/abs/2601.18536v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18536v1",
        "arxiv_id": "2601.18536v1",
        "authors": [
            "Abishek Stephen",
            "Jindřich Libovický"
        ],
        "submitted": "2026-01-26 14:41:44",
        "source": "arxiv",
        "comment": "Accepted to Findings of EACL 2026, 9 pages, 6 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on subword tokenization and morphological plausibility evaluation, which is a topic in Natural Language Processing (NLP). However, it does not directly relate to the user's core research interests in Information Retrieval (IR), query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "GenAI for Social Work Field Education: Client Simulation with Real-Time Feedback",
        "abstract": "Field education is the signature pedagogy of social work, yet providing timely and objective feedback during training is constrained by the availability of instructors and counseling clients. In this paper, we present SWITCH, the Social Work Interactive Training Chatbot. SWITCH integrates realistic client simulation, real-time counseling skill classification, and a Motivational Interviewing (MI) progression system into the training workflow. To model a client, SWITCH uses a cognitively grounded profile comprising static fields (e.g., background, beliefs) and dynamic fields (e.g., emotions, automatic thoughts, openness), allowing the agent's behavior to evolve throughout a session realistically. The skill classification module identifies the counseling skills from the user utterances, and feeds the result to the MI controller that regulates the MI stage transitions. To enhance classification accuracy, we study in-context learning with retrieval over annotated transcripts, and a fine-tuned BERT multi-label classifier. In the experiments, we demonstrated that both BERT-based approach and in-context learning outperforms the baseline with big margin. SWITCH thereby offers a scalable, low-cost, and consistent training workflow that complements field education, and allows supervisors to focus on higher-level mentorship.",
        "url": "http://arxiv.org/abs/2601.18517v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18517v1",
        "arxiv_id": "2601.18517v1",
        "authors": [
            "James Sungarda",
            "Hongkai Liu",
            "Zilong Zhou",
            "Tien-Hsuan Wu",
            "Johnson Chun-Sing Cheung",
            "Ben Kao"
        ],
        "submitted": "2026-01-26 14:26:54",
        "source": "arxiv",
        "comment": "2025 IEEE International Conference on Big Data. ISBN: 979-8-3315-9447-3/25. Page numbers: 3544-3553",
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on social work field education and client simulation using a chatbot, which does not align with your areas of expertise in Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "Pisets: A Robust Speech Recognition System for Lectures and Interviews",
        "abstract": "This work presents a speech-to-text system \"Pisets\" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2, false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper. The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality. The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to WhisperX and the usual Whisper model. The source code of \"Pisets\" system is publicly available at GitHub: https://github.com/bond005/pisets.",
        "url": "http://arxiv.org/abs/2601.18415v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18415v1",
        "arxiv_id": "2601.18415v1",
        "authors": [
            "Ivan Bondarenko",
            "Daniil Grebenkin",
            "Oleg Sedukhin",
            "Mikhail Klementev",
            "Roman Derunets",
            "Lyudmila Budneva"
        ],
        "submitted": "2026-01-26 12:14:51",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is about speech recognition, which is a topic in Natural Language Processing (NLP), but it does not align with the user's primary focus on Information Retrieval (IR), query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Noise-Robust AV-ASR Using Visual Features Both in the Whisper Encoder and Decoder",
        "abstract": "In audiovisual automatic speech recognition (AV-ASR) systems, information fusion of visual features in a pre-trained ASR has been proven as a promising method to improve noise robustness. In this work, based on the prominent Whisper ASR, first, we propose a simple and effective visual fusion method -- use of visual features both in encoder and decoder (dual-use) -- to learn the audiovisual interactions in the encoder and to weigh modalities in the decoder. Second, we compare visual fusion methods in Whisper models of various sizes. Our proposed dual-use method shows consistent noise robustness improvement, e.g., a 35% relative improvement (WER: 4.41% vs. 6.83%) based on Whisper small, and a 57% relative improvement (WER: 4.07% vs. 9.53%) based on Whisper medium, compared to typical reference middle fusion in babble noise with a signal-to-noise ratio (SNR) of 0dB. Third, we conduct ablation studies examining the impact of various module designs and fusion options. Fine-tuned on 1929 hours of audiovisual data, our dual-use method using Whisper medium achieves 4.08% (MUSAN babble noise) and 4.43% (NoiseX babble noise) average WER across various SNRs, thereby establishing a new state-of-the-art in noisy conditions on the LRS3 AV-ASR benchmark. Our code is at https://github.com/ifnspaml/Dual-Use-AVASR",
        "url": "http://arxiv.org/abs/2601.18396v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18396v1",
        "arxiv_id": "2601.18396v1",
        "authors": [
            "Zhengyang Li",
            "Thomas Graave",
            "Björn Möller",
            "Zehang Wu",
            "Matthias Franz",
            "Tim Fingscheidt"
        ],
        "submitted": "2026-01-26 11:55:07",
        "source": "arxiv",
        "comment": "accepted at ICASSP2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on audiovisual automatic speech recognition (AV-ASR) and noise robustness, which is outside your primary areas of interest."
    },
    {
        "title": "OCR-Enhanced Multimodal ASR Can Read While Listening",
        "abstract": "Visual information, such as subtitles in a movie, often helps automatic speech recognition. In this paper, we propose Donut-Whisper, an audio-visual ASR model with dual encoder to leverage visual information to improve speech recognition performance in both English and Chinese. Donut-Whisper combines the advantage of the linear and the Q-Former-based modality alignment structures via a cross-attention module, generating more powerful audio-visual features. Meanwhile, we propose a lightweight knowledge distillation scheme showcasing the potential of using audio-visual models to teach audio-only models to achieve better performance. Moreover, we propose a new multilingual audio-visual speech recognition dataset based on movie clips containing both Chinese and English partitions. As a result, Donut-Whisper achieved significantly better performance on both English and Chinese partition of the dataset compared to both Donut and Whisper large V3 baselines. In particular, an absolute 5.75% WER reduction and a 16.5% absolute CER reduction were achieved on the English and Chinese sets respectively compared to the Whisper ASR baseline.",
        "url": "http://arxiv.org/abs/2601.18393v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18393v1",
        "arxiv_id": "2601.18393v1",
        "authors": [
            "Junli Chen",
            "Changli Tang",
            "Yixuan Li",
            "Guangzhi Sun",
            "Chao Zhang"
        ],
        "submitted": "2026-01-26 11:51:08",
        "source": "arxiv",
        "comment": "4 pages, 2 figures. Submitted to ICASSP 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multimodal automatic speech recognition, leveraging visual information to improve speech recognition performance. While it involves deep learning and multimodal processing, it does not directly relate to information retrieval, search technologies, or user behavior modeling, which are your primary research interests."
    },
    {
        "title": "Integrating Fine-Grained Audio-Visual Evidence for Robust Multimodal Emotion Reasoning",
        "abstract": "Multimodal emotion analysis is shifting from static classification to generative reasoning. Beyond simple label prediction, robust affective reasoning must synthesize fine-grained signals such as facial micro-expressions and prosodic which shifts to decode the latent causality within complex social contexts. However, current Multimodal Large Language Models (MLLMs) face significant limitations in fine-grained perception, primarily due to data scarcity and insufficient cross-modal fusion. As a result, these models often exhibit unimodal dominance which leads to hallucinations in complex multimodal interactions, particularly when visual and acoustic cues are subtle, ambiguous, or even contradictory (e.g., in sarcastic scenery). To address this, we introduce SABER-LLM, a framework designed for robust multimodal reasoning. First, we construct SABER, a large-scale emotion reasoning dataset comprising 600K video clips, annotated with a novel six-dimensional schema that jointly captures audiovisual cues and causal logic. Second, we propose the structured evidence decomposition paradigm, which enforces a \"perceive-then-reason\" separation between evidence extraction and reasoning to alleviate unimodal dominance. The ability to perceive complex scenes is further reinforced by consistency-aware direct preference optimization, which explicitly encourages alignment among modalities under ambiguous or conflicting perceptual conditions. Experiments on EMER, EmoBench-M, and SABER-Test demonstrate that SABER-LLM significantly outperforms open-source baselines and achieves robustness competitive with closed-source models in decoding complex emotional dynamics. The dataset and model are available at https://github.com/zxzhao0/SABER-LLM.",
        "url": "http://arxiv.org/abs/2601.18321v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18321v1",
        "arxiv_id": "2601.18321v1",
        "authors": [
            "Zhixian Zhao",
            "Wenjie Tian",
            "Xiaohai Tian",
            "Jun Zhang",
            "Lei Xie"
        ],
        "submitted": "2026-01-26 10:03:26",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multimodal emotion analysis and large language models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some aspects of multimodal fusion, it is primarily concerned with affective reasoning and emotion analysis, which is not a central match for your research themes."
    },
    {
        "title": "Calibrating Beyond English: Language Diversity for Better Quantized Multilingual LLM",
        "abstract": "Quantization is an effective technique for reducing the storage footprint and computational costs of Large Language Models (LLMs), but it often results in performance degradation. Existing post-training quantization methods typically use small, English-only calibration sets; however, their impact on multilingual models remains underexplored. We systematically evaluate eight calibration settings (five single-language and three multilingual mixes) on two quantizers (GPTQ, AWQ) on data from 10 languages. Our findings reveal a consistent trend: non-English and multilingual calibration sets significantly improve perplexity compared to English-only baselines. Specifically, we observe notable average perplexity gains across both quantizers on Llama3.1 8B and Qwen2.5 7B, with multilingual mixes achieving the largest overall reductions of up to 3.52 points in perplexity. Furthermore, our analysis indicates that tailoring calibration sets to the evaluation language yields the largest improvements for individual languages, underscoring the importance of linguistic alignment. We also identify specific failure cases where certain language-quantizer combinations degrade performance, which we trace to differences in activation range distributions across languages. These results highlight that static one-size-fits-all calibration is suboptimal and that tailoring calibration data, both in language and diversity, plays a crucial role in robustly quantizing multilingual LLMs.",
        "url": "http://arxiv.org/abs/2601.18306v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18306v1",
        "arxiv_id": "2601.18306v1",
        "authors": [
            "Everlyn Asiko Chimoto",
            "Mostafa Elhoushi",
            "Bruce A. Bassett"
        ],
        "submitted": "2026-01-26 09:36:03",
        "source": "arxiv",
        "comment": "Accepted to EACL 2026 Main Conference",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multilingual Large Language Models (LLMs) and quantization techniques, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on NLP, the specific context and application are quite different from your areas of focus."
    },
    {
        "title": "Suppressing Final Layer Hidden State Jumps in Transformer Pretraining",
        "abstract": "This paper discusses the internal behavior of Transformer language models. Many recent pre-trained models have been reported to exhibit only slight changes in the angular distance between the input and output hidden state vectors in the middle Transformer layers, despite a disproportionately large ``jump'' in the angular distance occurring in or around the final Transformer layer. To characterize this, we first introduce a quantitative metric for the jump strength around the final layer, and then demonstrate its prevalence across many open-weight models, as well as its amplification throughout pre-training. Assuming such jumps indicate an undesirable property, we propose the jump-suppressing regularizer (JREG) which penalizes this jump during pre-training, thereby encouraging more balanced capability usage across the middle layers. Empirical evaluations of three model sizes of Llama-based models, trained with the proposed JREG method, reveal improved task performance compared to the baseline without altering the model architecture.",
        "url": "http://arxiv.org/abs/2601.18302v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18302v1",
        "arxiv_id": "2601.18302v1",
        "authors": [
            "Keigo Shibata",
            "Kazuki Yano",
            "Ryosuke Takahashi",
            "Jaesung Lee",
            "Wataru Ikeda",
            "Jun Suzuki"
        ],
        "submitted": "2026-01-26 09:30:49",
        "source": "arxiv",
        "comment": "Accepted to the Findings of EACL 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. It focuses on the internal behavior of Transformer language models and proposes a regularizer to suppress hidden state jumps during pretraining, which is not related to query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "BoRP: Bootstrapped Regression Probing for Scalable and Human-Aligned LLM Evaluation",
        "abstract": "Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED.",
        "url": "http://arxiv.org/abs/2601.18253v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18253v1",
        "arxiv_id": "2601.18253v1",
        "authors": [
            "Peng Sun",
            "Xiangyu Zhang",
            "Duan Wu"
        ],
        "submitted": "2026-01-26 08:20:02",
        "source": "arxiv",
        "comment": "This is a pre-print",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on evaluating conversational AI using a novel framework called BoRP, which leverages the geometric properties of LLM latent space. While it touches on aspects of user satisfaction and implicit metrics, it doesn't directly relate to query understanding, ranking models, or user behavior modeling in search technologies. However, it does involve NLP and deep semantic understanding, making it somewhat relevant to your broader interests."
    },
    {
        "title": "TechING: Towards Real World Technical Image Understanding via VLMs",
        "abstract": "Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.",
        "url": "http://arxiv.org/abs/2601.18238v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18238v1",
        "arxiv_id": "2601.18238v1",
        "authors": [
            "Tafazzul Nadeem",
            "Bhavik Shangari",
            "Manish Rai",
            "Gagan Raj Gupta",
            "Ashutosh Modi"
        ],
        "submitted": "2026-01-26 07:43:55",
        "source": "arxiv",
        "comment": "Accepted at Findings of EACL 2026, 30 Pages (9 Pages main paper + 4 pages references + 17 pages appendix)",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on technical image understanding using Vision Language Models (VLMs), which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves fine-tuning a model, the context is image understanding rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "MemWeaver: Weaving Hybrid Memories for Traceable Long-Horizon Agentic Reasoning",
        "abstract": "Large language model-based agents operating in long-horizon interactions require memory systems that support temporal consistency, multi-hop reasoning, and evidence-grounded reuse across sessions. Existing approaches largely rely on unstructured retrieval or coarse abstractions, which often lead to temporal conflicts, brittle reasoning, and limited traceability. We propose MemWeaver, a unified memory framework that consolidates long-term agent experiences into three interconnected components: a temporally grounded graph memory for structured relational reasoning, an experience memory that abstracts recurring interaction patterns from repeated observations, and a passage memory that preserves original textual evidence. MemWeaver employs a dual-channel retrieval strategy that jointly retrieves structured knowledge and supporting evidence to construct compact yet information-dense contexts for reasoning. Experiments on the LoCoMo benchmark demonstrate that MemWeaver substantially improves multi-hop and temporal reasoning accuracy while reducing input context length by over 95\\% compared to long-context baselines.",
        "url": "http://arxiv.org/abs/2601.18204v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18204v1",
        "arxiv_id": "2601.18204v1",
        "authors": [
            "Juexiang Ye",
            "Xue Li",
            "Xinyu Yang",
            "Chengkai Huang",
            "Lanshun Nie",
            "Lina Yao",
            "Dechen Zhan"
        ],
        "submitted": "2026-01-26 06:39:27",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be primarily focused on memory systems for large language model-based agents, which is not directly related to your core research interests in Information Retrieval and Search technologies. While it does involve retrieval and reasoning, the context is more aligned with NLP and agent reasoning, which is somewhat tangential to your interests."
    },
    {
        "title": "DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints",
        "abstract": "While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.",
        "url": "http://arxiv.org/abs/2601.18137v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18137v1",
        "arxiv_id": "2601.18137v1",
        "authors": [
            "Yinger Zhang",
            "Shutong Jiang",
            "Renhao Li",
            "Jianhong Tu",
            "Yang Su",
            "Lianghao Deng",
            "Xudong Guo",
            "Chenxu Lv",
            "Junyang Lin"
        ],
        "submitted": "2026-01-26 04:43:49",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'shopping' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be off-topic for your research interests as it focuses on agent planning and evaluation in the context of long-horizon tasks, which does not align with your primary focus on Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "Sparks of Cooperative Reasoning: LLMs as Strategic Hanabi Agents",
        "abstract": "Cooperative reasoning under incomplete information remains challenging for both humans and multi-agent systems. The card game Hanabi embodies this challenge, requiring theory-of-mind reasoning and strategic communication. We benchmark 17 state-of-the-art LLM agents in 2-5 player games and study the impact of context engineering across model scales (4B to 600B+) to understand persistent coordination failures and robustness to scaffolding: from a minimal prompt with only explicit card details (Watson setting), to scaffolding with programmatic, Bayesian-motivated deductions (Sherlock setting), to multi-turn state tracking via working memory (Mycroft setting). We show that (1) agents can maintain an internal working memory for state tracking and (2) cross-play performance between different LLMs smoothly interpolates with model strength. In the Sherlock setting, the strongest reasoning models exceed 15 points on average across player counts, yet still trail experienced humans and specialist Hanabi agents, both consistently scoring above 20. We release the first public Hanabi datasets with annotated trajectories and move utilities: (1) HanabiLogs, containing 1,520 full game logs for instruction tuning, and (2) HanabiRewards, containing 560 games with dense move-level value annotations for all candidate moves. Supervised and RL finetuning of a 4B open-weight model (Qwen3-Instruct) on our datasets improves cooperative Hanabi play by 21% and 156% respectively, bringing performance to within ~3 points of a strong proprietary reasoning model (o4-mini) and surpassing the best non-reasoning model (GPT-4.1) by 52%. The HanabiRewards RL-finetuned model further generalizes beyond Hanabi, improving performance on a cooperative group-guessing benchmark by 11%, temporal reasoning on EventQA by 6.4%, instruction-following on IFBench-800K by 1.7 Pass@10, and matching AIME 2025 mathematical reasoning Pass@10.",
        "url": "http://arxiv.org/abs/2601.18077v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18077v1",
        "arxiv_id": "2601.18077v1",
        "authors": [
            "Mahesh Ramesh",
            "Kaousheik Jayakumar",
            "Aswinkumar Ramkumar",
            "Pavan Thodima",
            "Aniket Rege"
        ],
        "submitted": "2026-01-26 02:23:47",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on cooperative reasoning and multi-agent systems, leveraging large language models (LLMs) to play the card game Hanabi. While it involves AI and deep learning, it is not directly related to information retrieval, search technologies, or user behavior modeling, which are the core areas of your research interests."
    },
    {
        "title": "Neurocomputational Mechanisms of Syntactic Transfer in Bilingual Sentence Production",
        "abstract": "We discuss the benefits of incorporating into the study of bilingual production errors and their traditionally documented timing signatures (e.g., event-related potentials) certain types of oscillatory signatures, which can offer new implementational-level constraints for theories of bilingualism. We argue that a recent neural model of language, ROSE, can offer a neurocomputational account of syntactic transfer in bilingual production, capturing some of its formal properties and the scope of morphosyntactic sequencing failure modes. We take as a case study cross-linguistic influence (CLI) and attendant theories of functional inhibition/competition, and present these as being driven by specific oscillatory failure modes during L2 sentence planning. We argue that modeling CLI in this way not only offers the kind of linking hypothesis ROSE was built to encourage, but also licenses the exploration of more spatiotemporally complex biomarkers of language dysfunction than more commonly discussed neural signatures.",
        "url": "http://arxiv.org/abs/2601.18056v1",
        "pdf_url": "https://arxiv.org/pdf/2601.18056v1",
        "arxiv_id": "2601.18056v1",
        "authors": [
            "Ahmet Yavuz Uluslu",
            "Elliot Murphy"
        ],
        "submitted": "2026-01-26 01:00:58",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper appears to be unrelated to Information Retrieval, Search technologies, or any of the user's specified areas of interest. It focuses on neurocomputational mechanisms of bilingual sentence production, which is a topic in the field of linguistics and cognitive psychology."
    }
]