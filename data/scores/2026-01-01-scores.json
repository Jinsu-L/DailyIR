[
    {
        "title": "AdaGReS:Adaptive Greedy Context Selection via Redundancy-Aware Scoring for Token-Budgeted RAG",
        "abstract": "Retrieval-augmented generation (RAG) is highly sensitive to the quality of selected context, yet standard top-k retrieval often returns redundant or near-duplicate chunks that waste token budget and degrade downstream generation. We present AdaGReS, a redundancy-aware context selection framework for token-budgeted RAG that optimizes a set-level objective combining query-chunk relevance and intra-set redundancy penalties. AdaGReS performs greedy selection under a token-budget constraint using marginal gains derived from the objective, and introduces a closed-form, instance-adaptive calibration of the relevance-redundancy trade-off parameter to eliminate manual tuning and adapt to candidate-pool statistics and budget limits. We further provide a theoretical analysis showing that the proposed objective exhibits epsilon-approximate submodularity under practical embedding similarity conditions, yielding near-optimality guarantees for greedy selection. Experiments on open-domain question answering (Natural Questions) and a high-redundancy biomedical (drug) corpus demonstrate consistent improvements in redundancy control and context quality, translating to better end-to-end answer quality and robustness across settings.",
        "url": "http://arxiv.org/abs/2512.25052v1",
        "pdf_url": "https://arxiv.org/pdf/2512.25052v1",
        "arxiv_id": "2512.25052v1",
        "authors": [
            "Chao Peng",
            "Bin Wang",
            "Zhilei Long",
            "Jinfang Sheng"
        ],
        "submitted": "2025-12-31 18:48:07",
        "source": "arxiv",
        "comment": "Preprint. Under review",
        "score": 10,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of retrieval-augmented generation (RAG) and context selection. However, the focus on token-budgeted RAG and redundancy-aware scoring is more specific and less central to your core themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "HiGR: Efficient Generative Slate Recommendation via Hierarchical Planning and Multi-Objective Preference Alignment",
        "abstract": "Slate recommendation, where users are presented with a ranked list of items simultaneously, is widely adopted in online platforms. Recent advances in generative models have shown promise in slate recommendation by modeling sequences of discrete semantic IDs autoregressively. However, existing autoregressive approaches suffer from semantically entangled item tokenization and inefficient sequential decoding that lacks holistic slate planning. To address these limitations, we propose HiGR, an efficient generative slate recommendation framework that integrates hierarchical planning with listwise preference alignment. First, we propose an auto-encoder utilizing residual quantization and contrastive constraints to tokenize items into semantically structured IDs for controllable generation. Second, HiGR decouples generation into a list-level planning stage for global slate intent, followed by an item-level decoding stage for specific item selection. Third, we introduce a listwise preference alignment objective to directly optimize slate quality using implicit user feedback. Experiments on our large-scale commercial media platform demonstrate that HiGR delivers consistent improvements in both offline evaluations and online deployment. Specifically, it outperforms state-of-the-art methods by over 10% in offline recommendation quality with a 5x inference speedup, while further achieving a 1.22% and 1.73% increase in Average Watch Time and Average Video Views in online A/B tests.",
        "url": "http://arxiv.org/abs/2512.24787v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24787v1",
        "arxiv_id": "2512.24787v1",
        "authors": [
            "Yunsheng Pang",
            "Zijian Liu",
            "Yudong Li",
            "Shaojie Zhu",
            "Zijian Luo",
            "Chenyun Yu",
            "Sikai Wu",
            "Shichen Shen",
            "Cong Xu",
            "Bin Wang",
            "Kai Jiang",
            "Hongyong Yu",
            "Chengxiang Zhuo",
            "Zang Li"
        ],
        "submitted": "2025-12-31 11:16:24",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'listwise' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper focuses on slate recommendation, which is related to information retrieval, but its primary contribution is in the area of recommender systems, specifically generative models. While it involves deep semantic understanding, the context is more aligned with recommender systems than traditional IR. The use of hierarchical planning and multi-objective preference alignment is an interesting aspect, but it doesn't directly relate to the user's core research themes in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment",
        "abstract": "Search relevance plays a central role in web e-commerce. While large language models (LLMs) have shown significant results on relevance task, existing benchmarks lack sufficient complexity for comprehensive model assessment, resulting in an absence of standardized relevance evaluation metrics across the industry. To address this limitation, we propose Rule-Aware benchmark with Image for Relevance assessment(RAIR), a Chinese dataset derived from real-world scenarios. RAIR established a standardized framework for relevance assessment and provides a set of universal rules, which forms the foundation for standardized evaluation. Additionally, RAIR analyzes essential capabilities required for current relevance models and introduces a comprehensive dataset consists of three subset: (1) a general subset with industry-balanced sampling to evaluate fundamental model competencies; (2) a long-tail hard subset focus on challenging cases to assess performance limits; (3) a visual salience subset for evaluating multimodal understanding capabilities. We conducted experiments on RAIR using 14 open and closed-source models. The results demonstrate that RAIR presents sufficient challenges even for GPT-5, which achieved the best performance. RAIR data are now available, serving as an industry benchmark for relevance assessment while providing new insights into general LLM and Visual Language Model(VLM) evaluation.",
        "url": "http://arxiv.org/abs/2512.24943v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24943v1",
        "arxiv_id": "2512.24943v1",
        "authors": [
            "Chenji Lu",
            "Zhuo Chen",
            "Hui Zhao",
            "Zhenyi Wang",
            "Pengjie Wang",
            "Jian Xu",
            "Bo Zheng"
        ],
        "submitted": "2025-12-31 16:09:08",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper RAIR is somewhat related to your research interests in Information Retrieval, particularly in the context of e-commerce, but it focuses more on benchmarking and evaluation metrics rather than query understanding, ranking models, or user behavior modeling. While it touches on the challenges of relevance assessment, it does not delve into the deep semantic understanding and real-time relevance optimization aspects that are central to your interests."
    },
    {
        "title": "Cleaning English Abstracts of Scientific Publications",
        "abstract": "Scientific abstracts are often used as proxies for the content and thematic focus of research publications. However, a significant share of published abstracts contains extraneous information-such as publisher copyright statements, section headings, author notes, registrations, and bibliometric or bibliographic metadata-that can distort downstream analyses, particularly those involving document similarity or textual embeddings. We introduce an open-source, easy-to-integrate language model designed to clean English-language scientific abstracts by automatically identifying and removing such clutter. We demonstrate that our model is both conservative and precise, alters similarity rankings of cleaned abstracts and improves information content of standard-length embeddings.",
        "url": "http://arxiv.org/abs/2512.24459v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24459v1",
        "arxiv_id": "2512.24459v1",
        "authors": [
            "Michael E. Rose",
            "Nils A. Herrmann",
            "Sebastian Erhardt"
        ],
        "submitted": "2025-12-30 20:45:50",
        "source": "arxiv",
        "comment": "2 tables, 2 figures",
        "score": 5,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on cleaning scientific abstracts, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves text processing, the context and application are quite different from your areas of focus."
    },
    {
        "title": "Encyclo-K: Evaluating LLMs with Dynamically Composed Knowledge Statements",
        "abstract": "Benchmarks play a crucial role in tracking the rapid advancement of large language models (LLMs) and identifying their capability boundaries. However, existing benchmarks predominantly curate questions at the question level, suffering from three fundamental limitations: vulnerability to data contamination, restriction to single-knowledge-point assessment, and reliance on costly domain expert annotation. We propose Encyclo-K, a statement-based benchmark that rethinks benchmark construction from the ground up. Our key insight is that knowledge statements, not questions, can serve as the unit of curation, and questions can then be constructed from them. We extract standalone knowledge statements from authoritative textbooks and dynamically compose them into evaluation questions through random sampling at test time. This design directly addresses all three limitations: the combinatorial space is too vast to memorize, and model rankings remain stable across dynamically generated question sets, enabling reliable periodic dataset refresh; each question aggregates 8-10 statements for comprehensive multi-knowledge assessment; annotators only verify formatting compliance without requiring domain expertise, substantially reducing annotation costs. Experiments on over 50 LLMs demonstrate that Encyclo-K poses substantial challenges with strong discriminative power. Even the top-performing OpenAI-GPT-5.1 achieves only 62.07% accuracy, and model performance displays a clear gradient distribution--reasoning models span from 16.04% to 62.07%, while chat models range from 9.71% to 50.40%. These results validate the challenges introduced by dynamic evaluation and multi-statement comprehensive understanding. These findings establish Encyclo-K as a scalable framework for dynamic evaluation of LLMs' comprehensive understanding over multiple fine-grained disciplinary knowledge statements.",
        "url": "http://arxiv.org/abs/2512.24867v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24867v1",
        "arxiv_id": "2512.24867v1",
        "authors": [
            "Yiming Liang",
            "Yizhi Li",
            "Yantao Du",
            "Ge Zhang",
            "Jiayi Zhou",
            "Yuchen Wu",
            "Yinzhu Piao",
            "Denghui Cao",
            "Tong Sun",
            "Ziniu Li",
            "Li Du",
            "Bo Lei",
            "Jiaheng Liu",
            "Chenghua Lin",
            "Zhaoxiang Zhang",
            "Wenhao Huang",
            "Jiajun Zhang"
        ],
        "submitted": "2025-12-31 13:55:54",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and large language models (LLMs), but it does not directly address your core focus on Information Retrieval (IR) and query understanding. The paper's emphasis on benchmarking and evaluation of LLMs' comprehensive understanding is relevant, but it does not seem to be directly connected to your interests in search technologies, ranking models, or user behavior modeling."
    },
    {
        "title": "PrivacyBench: A Conversational Benchmark for Evaluating Privacy in Personalized AI",
        "abstract": "Personalized AI agents rely on access to a user's digital footprint, which often includes sensitive data from private emails, chats and purchase histories. Yet this access creates a fundamental societal and privacy risk: systems lacking social-context awareness can unintentionally expose user secrets, threatening digital well-being. We introduce PrivacyBench, a benchmark with socially grounded datasets containing embedded secrets and a multi-turn conversational evaluation to measure secret preservation. Testing Retrieval-Augmented Generation (RAG) assistants reveals that they leak secrets in up to 26.56% of interactions. A privacy-aware prompt lowers leakage to 5.12%, yet this measure offers only partial mitigation. The retrieval mechanism continues to access sensitive data indiscriminately, which shifts the entire burden of privacy preservation onto the generator. This creates a single point of failure, rendering current architectures unsafe for wide-scale deployment. Our findings underscore the urgent need for structural, privacy-by-design safeguards to ensure an ethical and inclusive web for everyone.",
        "url": "http://arxiv.org/abs/2512.24848v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24848v1",
        "arxiv_id": "2512.24848v1",
        "authors": [
            "Srija Mukhopadhyay",
            "Sathwik Reddy",
            "Shruthi Muthukumar",
            "Jisun An",
            "Ponnurangam Kumaraguru"
        ],
        "submitted": "2025-12-31 13:16:45",
        "source": "arxiv",
        "comment": "11 pages, 2 figures",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it touches on conversational AI and retrieval mechanisms, its primary focus is on privacy and security, which is not a central match to your research interests."
    },
    {
        "title": "OpenOneRec Technical Report",
        "abstract": "While the OneRec series has successfully unified the fragmented recommendation pipeline into an end-to-end generative framework, a significant gap remains between recommendation systems and general intelligence. Constrained by isolated data, they operate as domain specialists-proficient in pattern matching but lacking world knowledge, reasoning capabilities, and instruction following. This limitation is further compounded by the lack of a holistic benchmark to evaluate such integrated capabilities. To address this, our contributions are: 1) RecIF Bench & Open Data: We propose RecIF-Bench, a holistic benchmark covering 8 diverse tasks that thoroughly evaluate capabilities from fundamental prediction to complex reasoning. Concurrently, we release a massive training dataset comprising 96 million interactions from 160,000 users to facilitate reproducible research. 2) Framework & Scaling: To ensure full reproducibility, we open-source our comprehensive training pipeline, encompassing data processing, co-pretraining, and post-training. Leveraging this framework, we demonstrate that recommendation capabilities can scale predictably while mitigating catastrophic forgetting of general knowledge. 3) OneRec-Foundation: We release OneRec Foundation (1.7B and 8B), a family of models establishing new state-of-the-art (SOTA) results across all tasks in RecIF-Bench. Furthermore, when transferred to the Amazon benchmark, our models surpass the strongest baselines with an average 26.8% improvement in Recall@10 across 10 diverse datasets (Figure 1). This work marks a step towards building truly intelligent recommender systems. Nonetheless, realizing this vision presents significant technical and theoretical challenges, highlighting the need for broader research engagement in this promising direction.",
        "url": "http://arxiv.org/abs/2512.24762v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24762v1",
        "arxiv_id": "2512.24762v1",
        "authors": [
            "Guorui Zhou",
            "Honghui Bao",
            "Jiaming Huang",
            "Jiaxin Deng",
            "Jinghao Zhang",
            "Junda She",
            "Kuo Cai",
            "Lejian Ren",
            "Lu Ren",
            "Qiang Luo",
            "Qianqian Wang",
            "Qigen Hu",
            "Rongzhou Zhang",
            "Ruiming Tang",
            "Shiyao Wang",
            "Wuchao Li",
            "Xiangyu Wu",
            "Xinchen Luo",
            "Xingmei Wang",
            "Yifei Hu",
            "Yunfan Wu",
            "Zhanyu Liu",
            "Zhiyang Zhang",
            "Zixing Zhang",
            "Bo Chen",
            "Bin Wen",
            "Chaoyi Ma",
            "Chengru Song",
            "Chenglong Chu",
            "Defu Lian",
            "Fan Yang",
            "Feng Jiang",
            "Hongtao Cheng",
            "Huanjie Wang",
            "Kun Gai",
            "Pengfei Zheng",
            "Qiang Wang",
            "Rui Huang",
            "Siyang Mao",
            "Tingting Gao",
            "Wei Yuan",
            "Yan Wang",
            "Yang Zhou",
            "Yi Su",
            "Zexuan Cheng",
            "Zhixin Ling",
            "Ziming Li"
        ],
        "submitted": "2025-12-31 10:15:53",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on recommender systems, which is a related but secondary interest of yours. While it does involve some aspects of information retrieval, such as ranking models, the primary focus is on recommendation capabilities and their integration with general intelligence, which is not a core theme of your research."
    },
    {
        "title": "Scaling Open-Ended Reasoning to Predict the Future",
        "abstract": "High-stakes decision making involves reasoning under uncertainty about the future. In this work, we train language models to make predictions on open-ended forecasting questions. To scale up training data, we synthesize novel forecasting questions from global events reported in daily news, using a fully automated, careful curation recipe. We train the Qwen3 thinking models on our dataset, OpenForesight. To prevent leakage of future information during training and evaluation, we use an offline news corpus, both for data generation and retrieval in our forecasting system. Guided by a small validation set, we show the benefits of retrieval, and an improved reward function for reinforcement learning (RL). Once we obtain our final forecasting system, we perform held-out testing between May to August 2025. Our specialized model, OpenForecaster 8B, matches much larger proprietary models, with our training improving the accuracy, calibration, and consistency of predictions. We find calibration improvements from forecasting training generalize across popular benchmarks. We open-source all our models, code, and data to make research on language model forecasting broadly accessible.",
        "url": "http://arxiv.org/abs/2512.25070v1",
        "pdf_url": "https://arxiv.org/pdf/2512.25070v1",
        "arxiv_id": "2512.25070v1",
        "authors": [
            "Nikhil Chandak",
            "Shashwat Goel",
            "Ameya Prabhu",
            "Moritz Hardt",
            "Jonas Geiping"
        ],
        "submitted": "2025-12-31 18:59:51",
        "source": "arxiv",
        "comment": "45 pages",
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on open-ended reasoning and language model forecasting, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context and application are quite different from the user's interests."
    },
    {
        "title": "Recursive Language Models",
        "abstract": "We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.",
        "url": "http://arxiv.org/abs/2512.24601v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24601v1",
        "arxiv_id": "2512.24601v1",
        "authors": [
            "Alex L. Zhang",
            "Tim Kraska",
            "Omar Khattab"
        ],
        "submitted": "2025-12-31 03:43:41",
        "source": "arxiv",
        "comment": "9 pages, 33 with Appendix",
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on recursive language models, which, while related to NLP, does not directly align with the user's primary interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. The paper's focus on long-context tasks and large language models also does not directly relate to the user's background in e-commerce or their interest in real-time relevance optimization."
    },
    {
        "title": "Many Minds from One Model: Bayesian Transformers for Population Intelligence",
        "abstract": "Despite their scale and success, modern transformers are almost universally trained as single-minded systems: optimization produces one deterministic set of parameters, representing a single functional hypothesis about the data. Motivated by the idea that intelligence emerge from many minds, we propose Population Bayesian Transformers (B-Trans), which transform a standard Large Language Model into a Bayesian Transformer model to supports sampling diverse yet coherent model instances from a single set of pre-trained weights.\n  B-Trans introduces a Bayesian-motivated posterior proxy by treating the bias-like offsets in normalization layers as stochastic variables with a Gaussian variational approximation, inducing a distribution over model behavior without the cost of training full Bayesian neural networks. Sampling from this proxy yields a set of model instances with diverse behaviors while maintaining general competence. To preserve coherence within each generation, we freeze the sampled noise at the sequence level, enforcing temporal consistency across tokens. B-Trans allows for population-level decision-making, where aggregating predictions across sampled individuals significantly enhances exploration. Experiments across zero-shot generation, Reinforcement Learning with Verifiable Rewards (RLVR), and RL without explicit labels demonstrate that B-Trans effectively leverage the wisdom of crowds, yielding superior semantic diversity while achieving better task performance compared to deterministic baselines.",
        "url": "http://arxiv.org/abs/2512.25063v1",
        "pdf_url": "https://arxiv.org/pdf/2512.25063v1",
        "arxiv_id": "2512.25063v1",
        "authors": [
            "Diji Yang",
            "Yi Zhang"
        ],
        "submitted": "2025-12-31 18:56:02",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Bayesian Transformers for population intelligence, which is not directly related to information retrieval, search technologies, or query understanding. While it involves deep learning and neural networks, the context is more aligned with NLP and AI, but the specific application and goals are not a central match for your research interests."
    },
    {
        "title": "BEDA: Belief Estimation as Probabilistic Constraints for Performing Strategic Dialogue Acts",
        "abstract": "Strategic dialogue requires agents to execute distinct dialogue acts, for which belief estimation is essential. While prior work often estimates beliefs accurately, it lacks a principled mechanism to use those beliefs during generation. We bridge this gap by first formalizing two core acts Adversarial and Alignment, and by operationalizing them via probabilistic constraints on what an agent may generate. We instantiate this idea in BEDA, a framework that consists of the world set, the belief estimator for belief estimation, and the conditional generator that selects acts and realizes utterances consistent with the inferred beliefs. Across three settings, Conditional Keeper Burglar (CKBG, adversarial), Mutual Friends (MF, cooperative), and CaSiNo (negotiation), BEDA consistently outperforms strong baselines: on CKBG it improves success rate by at least 5.0 points across backbones and by 20.6 points with GPT-4.1-nano; on Mutual Friends it achieves an average improvement of 9.3 points; and on CaSiNo it achieves the optimal deal relative to all baselines. These results indicate that casting belief estimation as constraints provides a simple, general mechanism for reliable strategic dialogue.",
        "url": "http://arxiv.org/abs/2512.24885v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24885v1",
        "arxiv_id": "2512.24885v1",
        "authors": [
            "Hengli Li",
            "Zhaoxin Yu",
            "Qi Shen",
            "Chenxi Li",
            "Mengmeng Wang",
            "Tinglang Wu",
            "Yipeng Kang",
            "Yuxuan Wang",
            "Song-Chun Zhu",
            "Zixia Jia",
            "Zilong Zheng"
        ],
        "submitted": "2025-12-31 14:26:55",
        "source": "arxiv",
        "comment": "Accepted by AAMAS 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on strategic dialogue acts and belief estimation in the context of dialogue systems, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some NLP aspects, the paper's primary focus on dialogue systems and strategic dialogue acts makes it less relevant to the user's research interests."
    },
    {
        "title": "Triangulation as an Acceptance Rule for Multilingual Mechanistic Interpretability",
        "abstract": "Multilingual language models achieve strong aggregate performance yet often behave unpredictably across languages, scripts, and cultures. We argue that mechanistic explanations for such models should satisfy a \\emph{causal} standard: claims must survive causal interventions and must \\emph{cross-reference} across environments that perturb surface form while preserving meaning. We formalize \\emph{reference families} as predicate-preserving variants and introduce \\emph{triangulation}, an acceptance rule requiring necessity (ablating the circuit degrades the target behavior), sufficiency (patching activations transfers the behavior), and invariance (both effects remain directionally stable and of sufficient magnitude across the reference family). To supply candidate subgraphs, we adopt automatic circuit discovery and \\emph{accept or reject} those candidates by triangulation. We ground triangulation in causal abstraction by casting it as an approximate transformation score over a distribution of interchange interventions, connect it to the pragmatic interpretability agenda, and present a comparative experimental protocol across multiple model families, language pairs, and tasks. Triangulation provides a falsifiable standard for mechanistic claims that filters spurious circuits passing single-environment tests but failing cross-lingual invariance.",
        "url": "http://arxiv.org/abs/2512.24842v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24842v1",
        "arxiv_id": "2512.24842v1",
        "authors": [
            "Yanan Long"
        ],
        "submitted": "2025-12-31 13:03:34",
        "source": "arxiv",
        "comment": "NeurIPS 2025 Workshop Evaluating the Evolving LLM Lifecycle: Benchmarks, Emergent Abilities, and Scaling",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper focuses on mechanistic interpretability of multilingual language models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language models, the primary goal is to improve interpretability, not query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "MUSIC: MUlti-Step Instruction Contrast for Multi-Turn Reward Models",
        "abstract": "Evaluating the quality of multi-turn conversations is crucial for developing capable Large Language Models (LLMs), yet remains a significant challenge, often requiring costly human evaluation. Multi-turn reward models (RMs) offer a scalable alternative and can provide valuable signals for guiding LLM training. While recent work has advanced multi-turn \\textit{training} techniques, effective automated \\textit{evaluation} specifically for multi-turn interactions lags behind. We observe that standard preference datasets, typically contrasting responses based only on the final conversational turn, provide insufficient signal to capture the nuances of multi-turn interactions. Instead, we find that incorporating contrasts spanning \\textit{multiple} turns is critical for building robust multi-turn RMs. Motivated by this finding, we propose \\textbf{MU}lti-\\textbf{S}tep \\textbf{I}nstruction \\textbf{C}ontrast (MUSIC), an unsupervised data augmentation strategy that synthesizes contrastive conversation pairs exhibiting differences across multiple turns. Leveraging MUSIC on the Skywork preference dataset, we train a multi-turn RM based on the Gemma-2-9B-Instruct model. Empirical results demonstrate that our MUSIC-augmented RM outperforms baseline methods, achieving higher alignment with judgments from advanced proprietary LLM judges on multi-turn conversations, crucially, without compromising performance on standard single-turn RM benchmarks.",
        "url": "http://arxiv.org/abs/2512.24693v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24693v1",
        "arxiv_id": "2512.24693v1",
        "authors": [
            "Wenzhe Li",
            "Shujian Zhang",
            "Wenxuan Zhou",
            "John Lambert",
            "Chi Jin",
            "Andrew Hard",
            "Rajiv Mathews",
            "Lun Wang"
        ],
        "submitted": "2025-12-31 07:54:30",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval or Search technologies, but rather focuses on Large Language Models and multi-turn conversations. While it involves training and evaluation of models, the context and techniques are not relevant to the user's core research themes."
    },
    {
        "title": "Quantum Visual Word Sense Disambiguation: Unraveling Ambiguities Through Quantum Inference Model",
        "abstract": "Visual word sense disambiguation focuses on polysemous words, where candidate images can be easily confused. Traditional methods use classical probability to calculate the likelihood of an image matching each gloss of the target word, summing these to form a posterior probability. However, due to the challenge of semantic uncertainty, glosses from different sources inevitably carry semantic biases, which can lead to biased disambiguation results. Inspired by quantum superposition in modeling uncertainty, this paper proposes a Quantum Inference Model for Unsupervised Visual Word Sense Disambiguation (Q-VWSD). It encodes multiple glosses of the target word into a superposition state to mitigate semantic biases. Then, the quantum circuit is executed, and the results are observed. By formalizing our method, we find that Q-VWSD is a quantum generalization of the method based on classical probability. Building on this, we further designed a heuristic version of Q-VWSD that can run more efficiently on classical computing. The experiments demonstrate that our method outperforms state-of-the-art classical methods, particularly by effectively leveraging non-specialized glosses from large language models, which further enhances performance. Our approach showcases the potential of quantum machine learning in practical applications and provides a case for leveraging quantum modeling advantages on classical computers while quantum hardware remains immature.",
        "url": "http://arxiv.org/abs/2512.24687v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24687v1",
        "arxiv_id": "2512.24687v1",
        "authors": [
            "Wenbo Qiao",
            "Peng Zhang",
            "Qinghua Hu"
        ],
        "submitted": "2025-12-31 07:47:14",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores a novel approach to visual word sense disambiguation using quantum inference, which is somewhat related to the user's interests in Information Retrieval and Natural Language Processing. However, the focus on quantum machine learning and visual word sense disambiguation is not a central match to the user's core research themes, particularly query understanding and ranking models."
    },
    {
        "title": "R-Debater: Retrieval-Augmented Debate Generation through Argumentative Memory",
        "abstract": "We present R-Debater, an agentic framework for generating multi-turn debates built on argumentative memory. Grounded in rhetoric and memory studies, the system views debate as a process of recalling and adapting prior arguments to maintain stance consistency, respond to opponents, and support claims with evidence. Specifically, R-Debater integrates a debate knowledge base for retrieving case-like evidence and prior debate moves with a role-based agent that composes coherent utterances across turns. We evaluate on standardized ORCHID debates, constructing a 1,000-item retrieval corpus and a held-out set of 32 debates across seven domains. Two tasks are evaluated: next-utterance generation, assessed by InspireScore (subjective, logical, and factual), and adversarial multi-turn simulations, judged by Debatrix (argument, source, language, and overall). Compared with strong LLM baselines, R-Debater achieves higher single-turn and multi-turn scores. Human evaluation with 20 experienced debaters further confirms its consistency and evidence use, showing that combining retrieval grounding with structured planning yields more faithful, stance-aligned, and coherent debates across turns.",
        "url": "http://arxiv.org/abs/2512.24684v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24684v1",
        "arxiv_id": "2512.24684v1",
        "authors": [
            "Maoyuan Li",
            "Zhongsheng Wang",
            "Haoyuan Li",
            "Jiamou Liu"
        ],
        "submitted": "2025-12-31 07:33:12",
        "source": "arxiv",
        "comment": "Accepteed by AAMAS 2026 full paper",
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 3,
        "llm_reason": "While this paper explores the intersection of information retrieval and natural language processing, its focus on debate generation and argumentative memory is somewhat tangential to the user's core research interests in query understanding, ranking models, and user behavior modeling. The paper's emphasis on retrieval for debate generation is relevant, but its application domain is distinct from the user's e-commerce background and primary focus on information retrieval for real-time relevance optimization."
    },
    {
        "title": "Paragraph Segmentation Revisited: Towards a Standard Task for Structuring Speech",
        "abstract": "Automatic speech transcripts are often delivered as unstructured word streams that impede readability and repurposing. We recast paragraph segmentation as the missing structuring step and fill three gaps at the intersection of speech processing and text segmentation. First, we establish TEDPara (human-annotated TED talks) and YTSegPara (YouTube videos with synthetic labels) as the first benchmarks for the paragraph segmentation task. The benchmarks focus on the underexplored speech domain, where paragraph segmentation has traditionally not been part of post-processing, while also contributing to the wider text segmentation field, which still lacks robust and naturalistic benchmarks. Second, we propose a constrained-decoding formulation that lets large language models insert paragraph breaks while preserving the original transcript, enabling faithful, sentence-aligned evaluation. Third, we show that a compact model (MiniSeg) attains state-of-the-art accuracy and, when extended hierarchically, jointly predicts chapters and paragraphs with minimal computational cost. Together, our resources and methods establish paragraph segmentation as a standardized, practical task in speech processing.",
        "url": "http://arxiv.org/abs/2512.24517v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24517v1",
        "arxiv_id": "2512.24517v1",
        "authors": [
            "Fabian Retkowski",
            "Alexander Waibel"
        ],
        "submitted": "2025-12-30 23:29:51",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on paragraph segmentation in speech processing, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves text segmentation, it is more specific to speech processing and does not address query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "MDiffFR: Modality-Guided Diffusion Generation for Cold-start Items in Federated Recommendation",
        "abstract": "Federated recommendations (FRs) provide personalized services while preserving user privacy by keeping user data on local clients, which has attracted significant attention in recent years. However, due to the strict privacy constraints inherent in FRs, access to user-item interaction data and user profiles across clients is highly restricted, making it difficult to learn globally effective representations for new (cold-start) items. Consequently, the item cold-start problem becomes even more challenging in FRs. Existing solutions typically predict embeddings for new items through the attribute-to-embedding mapping paradigm, which establishes a fixed one-to-one correspondence between item attributes and their embeddings. However, this one-to-one mapping paradigm often fails to model varying data distributions and tends to cause embedding misalignment, as verified by our empirical studies. To this end, we propose MDiffFR, a novel generation-based modality-guided diffusion method for cold-start items in FRs. In this framework, we employ a tailored diffusion model on the server to generate embeddings for new items, which are then distributed to clients for cold-start inference. To align item semantics, we deploy a pre-trained modality encoder to extract modality features as conditional signals to guide the reverse denoising process. Furthermore, our theoretical analysis verifies that the proposed method achieves stronger privacy guarantees compared to existing mapping-based approaches. Extensive experiments on four real datasets demonstrate that our method consistently outperforms all baselines in FRs.",
        "url": "http://arxiv.org/abs/2512.24715v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24715v1",
        "arxiv_id": "2512.24715v1",
        "authors": [
            "Kang Fu",
            "Honglei Zhang",
            "Xuechao Zou",
            "Yidong Li"
        ],
        "submitted": "2025-12-31 08:29:34",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on federated recommendation and the item cold-start problem, proposing a novel generation-based method. However, it does not align with the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing, and its relevance to query understanding, ranking models, or user behavior modeling is limited."
    },
    {
        "title": "Korean Canonical Legal Benchmark: Toward Knowledge-Independent Evaluation of LLMs' Legal Reasoning Capabilities",
        "abstract": "We introduce the Korean Canonical Legal Benchmark (KCL), a benchmark designed to assess language models' legal reasoning capabilities independently of domain-specific knowledge. KCL provides question-level supporting precedents, enabling a more faithful disentanglement of reasoning ability from parameterized knowledge. KCL consists of two components: (1) KCL-MCQA, multiple-choice problems of 283 questions with 1,103 aligned precedents, and (2) KCL-Essay, open-ended generation problems of 169 questions with 550 aligned precedents and 2,739 instance-level rubrics for automated evaluation. Our systematic evaluation of 30+ models shows large remaining gaps, particularly in KCL-Essay, and that reasoning-specialized models consistently outperform their general-purpose counterparts. We release all resources, including the benchmark dataset and evaluation code, at https://github.com/lbox-kr/kcl.",
        "url": "http://arxiv.org/abs/2512.24572v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24572v1",
        "arxiv_id": "2512.24572v1",
        "authors": [
            "Hongseok Oh",
            "Wonseok Hwang",
            "Kyoung-Woon On"
        ],
        "submitted": "2025-12-31 02:35:54",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'korea' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat relevant to your research interests in Natural Language Processing (NLP) and related topics, particularly in the context of language models and their evaluation. However, it does not directly align with your primary focus on Information Retrieval, especially in areas that require deep semantic understanding and real-time relevance optimization. The paper's focus on legal reasoning capabilities and benchmarking language models' abilities is an interesting application of NLP, but it does not seem to be a central match for your research interests."
    },
    {
        "title": "More Than Bits: Multi-Envelope Double Binary Factorization for Extreme Quantization",
        "abstract": "For extreme low-bit quantization of large language models (LLMs), Double Binary Factorization (DBF) is attractive as it enables efficient inference without sacrificing accuracy. However, the scaling parameters of DBF are too restrictive; after factoring out signs, all rank components share the same magnitude profile, resulting in performance saturation. We propose Multi-envelope DBF (MDBF), which retains a shared pair of 1-bit sign bases but replaces the single envelope with a rank-$l$ envelope. By sharing sign matrices among envelope components, MDBF effectively maintains a binary carrier and utilizes the limited memory budget for magnitude expressiveness. We also introduce a closed-form initialization and an alternating refinement method to optimize MDBF. Across the LLaMA and Qwen families, MDBF enhances perplexity and zero-shot accuracy over previous binary formats at matched bits per weight while preserving the same deployment-friendly inference primitive.",
        "url": "http://arxiv.org/abs/2512.24545v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24545v1",
        "arxiv_id": "2512.24545v1",
        "authors": [
            "Yuma Ichikawa",
            "Yoshihiko Fujisawa",
            "Yudai Fujimoto",
            "Akira Sakai",
            "Katsuki Fujisawa"
        ],
        "submitted": "2025-12-31 01:04:34",
        "source": "arxiv",
        "comment": "14 pages, 2 figures",
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it primarily focuses on extreme low-bit quantization of large language models, which is a topic in the field of machine learning and deep learning, but not directly related to information retrieval, search technologies, or natural language processing."
    },
    {
        "title": "IELTS Writing Revision Platform with Automated Essay Scoring and Adaptive Feedback",
        "abstract": "This paper presents the design, development, and evaluation of a proposed revision platform assisting candidates for the International English Language Testing System (IELTS) writing exam. Traditional IELTS preparation methods lack personalised feedback, catered to the IELTS writing rubric. To address these shortcomings, the platform features an attractive user interface (UI), an Automated Essay Scoring system (AES), and targeted feedback tailored to candidates and the IELTS writing rubric. The platform architecture separates conversational guidance from a dedicated writing interface to reduce cognitive load and simulate exam conditions. Through iterative, Design-Based Research (DBR) cycles, the study progressed from rule-based to transformer-based with a regression head scoring, mounted with adaptive feedback.\n  Early cycles (2-3) revealed fundamental limitations of rule-based approaches: mid-band compression, low accuracy, and negative $R^2$ values. DBR Cycle 4 implemented a DistilBERT transformer model with a regression head, yielding substantial improvements with MAE of 0.66 and positive $R^2$. This enabled Cycle 5's adaptive feedback implementation, which demonstrated statistically significant score improvements (mean +0.060 bands, p = 0.011, Cohen's d = 0.504), though effectiveness varied by revision strategy. Findings suggest automated feedback functions are most suited as a supplement to human instruction, with conservative surface-level corrections proving more reliable than aggressive structural interventions for IELTS preparation contexts. Challenges remain in assessing higher-band essays, and future work should incorporate longitudinal studies with real IELTS candidates and validation from official examiners.",
        "url": "http://arxiv.org/abs/2512.24460v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24460v1",
        "arxiv_id": "2512.24460v1",
        "authors": [
            "Titas Ramancauskas",
            "Kotryna Ramancauske"
        ],
        "submitted": "2025-12-30 20:49:43",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper's focus on automated essay scoring and adaptive feedback for IELTS writing preparation is somewhat related to information retrieval, but it primarily deals with natural language processing and education, which are not central to your research interests."
    }
]