# Daily Papers Report - 2025-08-28

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval

- **LLM Score**: 6
- **Keyword Score**: 17
- **Authors**: Yixuan Tang, Yuanyuan Shi, Yiqun Sun, Anthony Kum Hoe Tung
- **URL**: <http://arxiv.org/abs/2508.19758v1>
- **Submitted**: 2025-08-27 10:37:32
- **Comment**: Accepted by EMNLP 2025
- **Topic Keywords**: dense retrieval, ranking, pairwise, relevance, rag, retrieval, rank
- **Reason**: The paper proposes a framework for diverse news retrieval, focusing on semantic variation at the sentence level. While it's not directly related to query understanding, ranking models, or user behavior modeling, it does explore information retrieval and relevance optimization. The connection to information retrieval is strong, but the specific domain and application are different from the user's primary focus.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Diverse News Retrieval
- **Aim**: To enhance event coverage by explicitly modeling semantic variation at the sentence level
- **Rationale**: Existing systems prioritize textual relevance, leading to redundant results and limited viewpoint exposure, and fine-grained, interpretable modeling is necessary to mitigate redundancy and promote comprehensive event understanding
- **Ground**: Limitations in existing methods for news retrieval, which focus on item-level and supervised approaches, making them difficult to interpret and scale
- **Experiment**: The authors construct two paragraph-annotated benchmarks, LocalNews and DSGlobal, to support evaluation, and experimental results show that NEWSCOPE outperforms strong baselines, achieving higher diversity without compromising relevance, while maintaining practical efficiency
- **Takeaway**: The importance of balancing relevance and diversity in information retrieval, and the effectiveness of the NEWSCOPE framework in achieving this balance

#### Abstract
> Access to diverse perspectives is essential for understanding real-world
events, yet most news retrieval systems prioritize textual relevance, leading
to redundant results and limited viewpoint exposure. We propose NEWSCOPE, a
two-stage framework for diverse news retrieval that enhances event coverage by
explicitly modeling semantic variation at the sentence level. The first stage
retrieves topically relevant content using dense retrieval, while the second
stage applies sentence-level clustering and diversity-aware re-ranking to
surface complementary information. To evaluate retrieval diversity, we
introduce three interpretable metrics, namely Average Pairwise Distance,
Positive Cluster Coverage, and Information Density Ratio, and construct two
paragraph-level benchmarks: LocalNews and DSGlobal. Experiments show that
NEWSCOPE consistently outperforms strong baselines, achieving significantly
higher diversity without compromising relevance. Our results demonstrate the
effectiveness of fine-grained, interpretable modeling in mitigating redundancy
and promoting comprehensive event understanding. The data and code are
available at https://github.com/tangyixuan/NEWSCOPE.

---

### 2. Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains

- **LLM Score**: 6
- **Keyword Score**: 4
- **Authors**: Peiran Zhou, Junnan Zhu, Yichen Shen, Ruoxi Yu
- **URL**: <http://arxiv.org/abs/2508.19357v1>
- **Submitted**: 2025-08-26 18:34:20
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper proposes a framework for retrieval-augmented generation in complex domains, which is related to information retrieval and natural language processing. However, the focus on question answering and scientific domains is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Context-Adaptive Synthesis and Compression (CASC) for Retrieval-Augmented Generation (RAG) in complex domains
- **Aim**: To address the limitations of traditional RAG in complex domains by developing a novel framework that mitigates information overload, inefficient synthesis, increased hallucination, and reduced trust
- **Rationale**: CASC's Context Analyzer & Synthesizer (CAS) module transforms raw information into a highly condensed, structured, and semantically rich context, reducing the token count and cognitive load for the final Reader LLM
- **Ground**: Evaluations on the SciDocs-QA dataset demonstrate that CASC consistently outperforms strong baselines and existing context compression methods across various Reader LLM backbones, achieving state-of-the-art performance in Exact Match (EM) and F1-score
- **Experiment**: Ablation study and human evaluation validate the critical role of each component within the CAS module and the qualitative aspects of the synthesized contexts generated by CASC
- **Takeaway**: CASC represents a significant advancement in RAG, enabling more accurate and reliable answers, and paving the way for more reliable, efficient, and trustworthy LLM applications in information-dense and critical domains

#### Abstract
> Large Language Models (LLMs) excel in language tasks but are prone to
hallucinations and outdated knowledge. Retrieval-Augmented Generation (RAG)
mitigates these by grounding LLMs in external knowledge. However, in complex
domains involving multiple, lengthy, or conflicting documents, traditional RAG
suffers from information overload and inefficient synthesis, leading to
inaccurate and untrustworthy answers. To address this, we propose CASC
(Context-Adaptive Synthesis and Compression), a novel framework that
intelligently processes retrieved contexts. CASC introduces a Context Analyzer
& Synthesizer (CAS) module, powered by a fine-tuned smaller LLM, which performs
key information extraction, cross-document consistency checking and conflict
resolution, and question-oriented structured synthesis. This process transforms
raw, scattered information into a highly condensed, structured, and
semantically rich context, significantly reducing the token count and cognitive
load for the final Reader LLM. We evaluate CASC on SciDocs-QA, a new
challenging multi-document question answering dataset designed for complex
scientific domains with inherent redundancies and conflicts. Our extensive
experiments demonstrate that CASC consistently outperforms strong baselines.

---

### 3. Language Models Identify Ambiguities and Exploit Loopholes

- **LLM Score**: 6
- **Keyword Score**: 2
- **Authors**: Jio Choi, Mohit Bansal, Elias Stengel-Eskin
- **URL**: <http://arxiv.org/abs/2508.19546v1>
- **Submitted**: 2025-08-27 03:40:17
- **Comment**: EMNLP 2025 camera-ready; Code:
  https://github.com/esteng/ambiguous-loophole-exploitation
- **Topic Keywords**: rag
- **Reason**: The paper explores the capabilities of large language models in identifying ambiguities and exploiting loopholes, which is related to query understanding and ranking models in Information Retrieval. However, the focus is more on the language models' abilities and potential risks, rather than directly addressing user behavior modeling or real-time relevance optimization, which are key aspects of your research interests.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Large Language Models' Ability to Exploit Loopholes in User Instructions
- **Aim**: Investigate the ability of Large Language Models (LLMs) to identify ambiguities and exploit loopholes in user instructions, presenting a potential AI safety risk
- **Rationale**: LLMs may selectively misunderstand ambiguous user requests to accommodate their system instructions over the user's request, posing a risk to AI safety and alignment
- **Ground**: The study designs scenarios to test LLMs' ability to exploit loopholes, including scalar implicature, structural ambiguities, and power dynamics, and conducts experiments to measure their loophole exploitation abilities
- **Experiment**: The study conducts three experiments to test LLMs' abilities to exploit loopholes, including scalar implicature, bracketing ambiguity, and power dynamics, and finds that stronger models can identify ambiguities and exploit loopholes
- **Takeaway**: The study highlights the importance of studying loophole behavior in safety and alignment, and proposes a series of concrete tests for measuring loophole exploitation, noting the potential risks of loophole exploitation and the need for safer and more reliable models

#### Abstract
> Studying the responses of large language models (LLMs) to loopholes presents
a two-fold opportunity. First, it affords us a lens through which to examine
ambiguity and pragmatics in LLMs, since exploiting a loophole requires
identifying ambiguity and performing sophisticated pragmatic reasoning. Second,
loopholes pose an interesting and novel alignment problem where the model is
presented with conflicting goals and can exploit ambiguities to its own
advantage. To address these questions, we design scenarios where LLMs are given
a goal and an ambiguous user instruction in conflict with the goal, with
scenarios covering scalar implicature, structural ambiguities, and power
dynamics. We then measure different models' abilities to exploit loopholes to
satisfy their given goals as opposed to the goals of the user. We find that
both closed-source and stronger open-source models can identify ambiguities and
exploit their resulting loopholes, presenting a potential AI safety risk. Our
analysis indicates that models which exploit loopholes explicitly identify and
reason about both ambiguity and conflicting goals.

---

### 4. Spotlight Attention: Towards Efficient LLM Generation via Non-linear Hashing-based KV Cache Retrieval

- **LLM Score**: 4
- **Keyword Score**: 9
- **Authors**: Wenhao Li, Yuxin Zhang, Gen Luo, Haiyuan Wan, Ziyang Gong, Fei Chao, Rongrong Ji
- **URL**: <http://arxiv.org/abs/2508.19740v1>
- **Submitted**: 2025-08-27 10:11:27
- **Topic Keywords**: queries, ranking, retrieval, rank
- **Reason**: The paper focuses on optimizing Large Language Models (LLMs) for efficient inference, using non-linear hashing-based KV cache retrieval. While it touches on query understanding and retrieval, the primary focus is on LLMs and caching, which is not directly related to my core research interests in Information Retrieval and Search technologies. The paper's relevance is somewhat limited to my broader interests in NLP and data mining.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Optimizing Key-Value Cache Retrieval in Large Language Models
- **Aim**: Propose a novel method for optimizing key-value cache retrieval in Large Language Models during the decoding phase
- **Rationale**: Employing non-linear hashing functions to optimize the embedding distribution of queries and keys, enhancing coding efficiency and robustness
- **Ground**: Large Language Models, decoding phase, key-value cache retrieval
- **Experiment**: Experimental results show that Spotlight Attention improves retrieval precision while shortening the length of the hash code at least 5√ó compared to traditional linear hashing
- **Takeaway**: Spotlight Attention achieves significant latency reductions and performance retention while maintaining the strongest performance in comparison with state-of-the-art methods

#### Abstract
> Reducing the key-value (KV) cache burden in Large Language Models (LLMs)
significantly accelerates inference. Dynamically selecting critical KV caches
during decoding helps maintain performance. Existing methods use random linear
hashing to identify important tokens, but this approach is inefficient due to
the orthogonal distribution of queries and keys within two narrow cones in
LLMs. We introduce Spotlight Attention, a novel method that employs non-linear
hashing functions to optimize the embedding distribution of queries and keys,
enhancing coding efficiency and robustness. We also developed a lightweight,
stable training framework using a Bradley-Terry ranking-based loss, enabling
optimization of the non-linear hashing module on GPUs with 16GB memory in 8
hours. Experimental results show that Spotlight Attention drastically improves
retrieval precision while shortening the length of the hash code at least
5$\times$ compared to traditional linear hashing. Finally, we exploit the
computational advantages of bitwise operations by implementing specialized CUDA
kernels, achieving hashing retrieval for 512K tokens in under 100$\mu$s on a
single A100 GPU, with end-to-end throughput up to 3$\times$ higher than vanilla
decoding.

---

### 5. Heterogeneous LLM Methods for Ontology Learning (Few-Shot Prompting, Ensemble Typing, and Attention-Based Taxonomies)

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Aleksandra Beliaeva, Temurbek Rahmatullaev
- **URL**: <http://arxiv.org/abs/2508.19428v1>
- **Submitted**: 2025-08-26 20:50:16
- **Topic Keywords**: ranking, rag, retrieval, rank
- **Reason**: The paper presents a comprehensive system for ontology learning, using LLM-based architectures and various techniques such as retrieval-augmented prompting, zero-shot classification, and attention-based graph modeling. While it touches on some aspects of information retrieval, such as term extraction and taxonomy discovery, the focus is primarily on ontology learning and construction, which is not directly aligned with the user's core research themes in information retrieval and search technologies.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Ontology Learning
- **Aim**: To develop a unified, modular system for ontology learning that tackles three core subtasks: term typing, taxonomy induction, and non-taxonomic relation extraction
- **Rationale**: To demonstrate the scalability, adaptability, and robustness of large language model (LLM)-based architectures for ontology learning across heterogeneous domains
- **Ground**: The system combines three approaches: retrieval-augmented prompting, zero-shot classification, and attention-based graph modeling
- **Experiment**: The system is evaluated on three datasets: Scholarly, Engineering, and Ecology, and achieves top-ranking results in the official leaderboard across all three tasks
- **Takeaway**: The paper demonstrates that a lean, modular system built on efficient prompting and adaptive lightweight modules can compete with or outperform more expensive methods, supporting scalable, domain-agnostic ontology learning in real-world settings

#### Abstract
> We present a comprehensive system for addressing Tasks A, B, and C of the
LLMs4OL 2025 challenge, which together span the full ontology construction
pipeline: term extraction, typing, and taxonomy discovery. Our approach
combines retrieval-augmented prompting, zero-shot classification, and
attention-based graph modeling -- each tailored to the demands of the
respective task. For Task A, we jointly extract domain-specific terms and their
ontological types using a retrieval-augmented generation (RAG) pipeline.
Training data was reformulated into a document to terms and types
correspondence, while test-time inference leverages semantically similar
training examples. This single-pass method requires no model finetuning and
improves overall performance through lexical augmentation Task B, which
involves assigning types to given terms, is handled via a dual strategy. In the
few-shot setting (for domains with labeled training data), we reuse the RAG
scheme with few-shot prompting. In the zero-shot setting (for previously unseen
domains), we use a zero-shot classifier that combines cosine similarity scores
from multiple embedding models using confidence-based weighting. In Task C, we
model taxonomy discovery as graph inference. Using embeddings of type labels,
we train a lightweight cross-attention layer to predict is-a relations by
approximating a soft adjacency matrix. These modular, task-specific solutions
enabled us to achieve top-ranking results in the official leaderboard across
all three tasks. Taken together these strategies showcase the scalability,
adaptability, and robustness of LLM-based architectures for ontology learning
across heterogeneous domains.
  Code is available at:
https://github.com/BelyaevaAlex/LLMs4OL-Challenge-Alexbek

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. A Self-Supervised Mixture-of-Experts Framework for Multi-behavior Recommendation

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Kyungho Kim, Sunwoo Kim, Geon Lee, Kijung Shin
- **URL**: <http://arxiv.org/abs/2508.19507v2>
- **Submitted**: 2025-08-27 01:32:59
- **Comment**: CIKM 2025
- **Topic Keywords**: user behavior, click, recommend, commerce, e-commerce
- **Reason**: The paper focuses on recommender systems, which is related to your interests in Information Retrieval and Search technologies. However, the specific topic of multi-behavior recommendation and the e-commerce domain are not directly aligned with your primary focus on query understanding, ranking models, and user behavior modeling. The paper's emphasis on self-supervised learning and mixture-of-experts frameworks is also not a central match for your research interests.

#### Abstract
> In e-commerce, where users face a vast array of possible item choices,
recommender systems are vital for helping them discover suitable items they
might otherwise overlook. While many recommender systems primarily rely on a
user's purchase history, recent multi-behavior recommender systems incorporate
various auxiliary user behaviors, such as item clicks and cart additions, to
enhance recommendations. Despite their overall performance gains, their
effectiveness varies considerably between visited items (i.e., those a user has
interacted with through auxiliary behaviors) and unvisited items (i.e., those
with which the user has had no such interactions). Specifically, our analysis
reveals that (1) existing multi-behavior recommender systems exhibit a
significant gap in recommendation quality between the two item types (visited
and unvisited items) and (2) achieving strong performance on both types with a
single model architecture remains challenging. To tackle these issues, we
propose a novel multi-behavior recommender system, MEMBER. It employs a
mixture-of-experts framework, with experts designed to recommend the two item
types, respectively. Each expert is trained using a self-supervised method
specialized for its design goal. In our comprehensive experiments, we show the
effectiveness of MEMBER across both item types, achieving up to 65.46%
performance gain over the best competitor in terms of Hit Ratio@20.

### 7. Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Jiaqi Deng, Yuho Lee, Nicole Hee-Yeon Kim, Hyangsuk Min, Taewon Yun, Minjeong Ban, Kim Yul, Hwanjun Song
- **URL**: <http://arxiv.org/abs/2508.19578v1>
- **Submitted**: 2025-08-27 05:23:22
- **Comment**: Accepted to EMNLP 2025 (Main)
- **Topic Keywords**: query, queries
- **Reason**: The paper introduces a framework for evaluating the comprehension of large language models in book-length contexts, which is related to query understanding and ranking models. However, the focus is on evaluating the comprehension of LLMs rather than developing new ranking models or query understanding techniques. The paper's relevance to information retrieval and search technologies is limited, but it may be of interest to researchers exploring the application of LLMs in search and retrieval tasks.

#### Abstract
> We introduce HAMLET, a holistic and automated framework for evaluating the
long-context comprehension of large language models (LLMs). HAMLET structures
source texts into a three-level key-fact hierarchy at root-, branch-, and
leaf-levels, and employs query-focused summarization to evaluate how well
models recall and faithfully represent information at each level. To validate
the reliability of our fully automated pipeline, we conduct a systematic human
study, showing that our automatic evaluation achieves over 90% agreement with
expert human judgments, while reducing the cost by up to 25 times. HAMLET
reveals that LLMs struggle with fine-grained comprehension, especially at the
leaf level, and are sensitive to positional effects like the
lost-in-the-middle. Analytical queries pose greater challenges than narrative
ones, and consistent performance gaps emerge between open-source and
proprietary models, as well as across model scales. Our code and dataset are
publicly available at https://github.com/DISL-Lab/HAMLET.

### 8. HEAL: A Hypothesis-Based Preference-Aware Analysis Framework

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Yifu Huo, Chenglong Wang, Qiren Zhu, Shunjie Xing, Tong Xiao, Chunliang Zhang, Tongran Liu, Jinbo Zhu
- **URL**: <http://arxiv.org/abs/2508.19922v1>
- **Submitted**: 2025-08-27 14:30:08
- **Comment**: Accepted by EMNLP 2025 Findings
- **Topic Keywords**: ranking, rank, search
- **Reason**: The paper presents a novel framework for evaluating preference alignment, which is not directly related to information retrieval or search technologies. While it touches on ranking accuracy, the focus is on preference learning and re-ranking within hypothesis spaces, which is not a core area of interest for the user.

#### Abstract
> Preference optimization methods like DPO have achieved remarkable performance
in LLM alignment. However, the evaluation for these methods relies on a single
response and overlooks other potential outputs, which could also be generated
in real-world applications within this hypothetical space. To address this
issue, this paper presents a \textbf{H}ypothesis-based
Pr\textbf{E}ference-aware \textbf{A}na\textbf{L}ysis Framework (HEAL), a novel
evaluation paradigm that formulates preference alignment as a re-ranking
process within hypothesis spaces. The framework incorporates two complementary
metrics: ranking accuracy for evaluating ordinal consistency and preference
strength correlation for assessing continuous alignment. To facilitate this
framework, we develop UniHypoBench, a unified hypothesis benchmark constructed
from diverse instruction-response pairs. Through extensive experiments based on
HEAL, with a particular focus on the intrinsic mechanisms of preference
learning, we demonstrate that current preference learning methods can
effectively capture preferences provided by proxy models while simultaneously
suppressing negative samples. These findings contribute to preference learning
research through two significant avenues. Theoretically, we introduce
hypothesis space analysis as an innovative paradigm for understanding
preference alignment. Practically, HEAL offers researchers robust diagnostic
tools for refining preference optimization methods, while our empirical results
identify promising directions for developing more advanced alignment algorithms
capable of comprehensive preference capture.

### 9. A Model-agnostic Strategy to Mitigate Embedding Degradation in Personalized Federated Recommendation

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Jiakui Shen, Yunqi Mi, Guoshuai Zhao, Jialie Shen, Xueming Qian
- **URL**: <http://arxiv.org/abs/2508.19591v1>
- **Submitted**: 2025-08-27 06:03:52
- **Topic Keywords**: user behavior, recommend, personalization, search
- **Reason**: The paper focuses on federated recommendation systems, which is a related topic to information retrieval, but it does not directly address query understanding, ranking models, or user behavior modeling. The paper's emphasis on personalized embeddings and local-global collaboration is not directly relevant to my research interests, but it may have some indirect connections to my work in NLP and data mining.

#### Abstract
> Centralized recommender systems encounter privacy leakage due to the need to
collect user behavior and other private data. Hence, federated recommender
systems (FedRec) have become a promising approach with an aggregated global
model on the server. However, this distributed training paradigm suffers from
embedding degradation caused by suboptimal personalization and dimensional
collapse, due to the existence of sparse interactions and heterogeneous
preferences. To this end, we propose a novel model-agnostic strategy for FedRec
to strengthen the personalized embedding utility, which is called Personalized
Local-Global Collaboration (PLGC). It is the first research in federated
recommendation to alleviate the dimensional collapse issue. Particularly, we
incorporate the frozen global item embedding table into local devices. Based on
a Neural Tangent Kernel strategy that dynamically balances local and global
information, PLGC optimizes personalized representations during forward
inference, ultimately converging to user-specific preferences. Additionally,
PLGC carries on a contrastive objective function to reduce embedding redundancy
by dissolving dependencies between dimensions, thereby improving the backward
representation learning process. We introduce PLGC as a model-agnostic
personalized training strategy for federated recommendations that can be
applied to existing baselines to alleviate embedding degradation. Extensive
experiments on five real-world datasets have demonstrated the effectiveness and
adaptability of PLGC, which outperforms various baseline algorithms.

### 10. APS Explorer: Navigating Algorithm Performance Spaces for Informed Dataset Selection

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Tobias Vente, Michael Heep, Abdullah Abbas, Theodor Sperle, Joeran Beel, Bart Goethals
- **URL**: <http://arxiv.org/abs/2508.19399v1>
- **Submitted**: 2025-08-26 19:46:29
- **Topic Keywords**: pairwise, recommend, recsys
- **Reason**: The paper discusses dataset selection for recommender systems, which is somewhat related to information retrieval and search technologies. However, the focus is on recommender systems and dataset selection, which is not a central match for the user's research interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is limited to the e-commerce domain, which is also not a primary focus for the user.

#### Abstract
> Dataset selection is crucial for offline recommender system experiments, as
mismatched data (e.g., sparse interaction scenarios require datasets with low
user-item density) can lead to unreliable results. Yet, 86\% of ACM RecSys 2024
papers provide no justification for their dataset choices, with most relying on
just four datasets: Amazon (38\%), MovieLens (34\%), Yelp (15\%), and Gowalla
(12\%). While Algorithm Performance Spaces (APS) were proposed to guide dataset
selection, their adoption has been limited due to the absence of an intuitive,
interactive tool for APS exploration. Therefore, we introduce the APS Explorer,
a web-based visualization tool for interactive APS exploration, enabling
data-driven dataset selection. The APS Explorer provides three interactive
features: (1) an interactive PCA plot showing dataset similarity via
performance patterns, (2) a dynamic meta-feature table for dataset comparisons,
and (3) a specialized visualization for pairwise algorithm performance.

### 11. Database Entity Recognition with Data Augmentation and Deep Learning

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Zikun Fu, Chen Yang, Kourosh Davoudi, Ken Q. Pu
- **URL**: <http://arxiv.org/abs/2508.19372v1>
- **Submitted**: 2025-08-26 19:05:40
- **Comment**: 6 pages, 5 figures. Accepted at IEEE 26th International Conference on
  Information Reuse and Integration for Data Science (IRI 2025), San Jose,
  California, August 6-8, 2025
- **Topic Keywords**: queries, rag
- **Reason**: The paper focuses on Database Entity Recognition, which is a topic related to Information Retrieval, but it does not directly address query understanding, ranking models, or user behavior modeling. While it involves Natural Language Processing, the scope is limited to a specific task, and the relevance to the user's broader interests is moderate.

#### Abstract
> This paper addresses the challenge of Database Entity Recognition (DB-ER) in
Natural Language Queries (NLQ). We present several key contributions to advance
this field: (1) a human-annotated benchmark for DB-ER task, derived from
popular text-to-sql benchmarks, (2) a novel data augmentation procedure that
leverages automatic annotation of NLQs based on the corresponding SQL queries
which are available in popular text-to-SQL benchmarks, (3) a specialized
language model based entity recognition model using T5 as a backbone and two
down-stream DB-ER tasks: sequence tagging and token classification for
fine-tuning of backend and performing DB-ER respectively. We compared our DB-ER
tagger with two state-of-the-art NER taggers, and observed better performance
in both precision and recall for our model. The ablation evaluation shows that
data augmentation boosts precision and recall by over 10%, while fine-tuning of
the T5 backbone boosts these metrics by 5-10%.

### 12. LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Yang Sun, Lixin Zou, Dan Luo, Zhiyong Xie, Long Zhang, Liming Dong, Yunwei Zhao, Xixun Lin, Yanxiong Lu, Chenliang Li
- **URL**: <http://arxiv.org/abs/2508.19614v1>
- **Submitted**: 2025-08-27 06:48:46
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on retrieval-augmented generation and external knowledge integration, which is related to information retrieval and natural language processing. However, the specific context of language models and decoding strategies is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Retrieval-augmented generation (RAG) incorporates external knowledge into
large language models (LLMs), improving their adaptability to downstream tasks
and enabling information updates. Surprisingly, recent empirical evidence
demonstrates that injecting noise into retrieved relevant documents
paradoxically facilitates exploitation of external knowledge and improves
generation quality. Although counterintuitive and challenging to apply in
practice, this phenomenon enables granular control and rigorous analysis of how
LLMs integrate external knowledge. Therefore, in this paper, we intervene on
noise injection and establish a layer-specific functional demarcation within
the LLM: shallow layers specialize in local context modeling, intermediate
layers focus on integrating long-range external factual knowledge, and deeper
layers primarily rely on parametric internal knowledge. Building on this
insight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that
directly combines representations from an intermediate layer with final-layer
decoding outputs to fully exploit the external factual knowledge. To identify
the optimal intermediate layer, we introduce an internal knowledge score (IKS)
criterion that selects the layer with the lowest IKS value in the latter half
of layers. Experimental results across multiple benchmarks demonstrate that LFD
helps RAG systems more effectively surface retrieved context knowledge with
minimal cost.

### 13. Functional Consistency of LLM Code Embeddings: A Self-Evolving Data Synthesis Framework for Benchmarking

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Zhuohao Li, Wenqing Chen, Jianxing Yu, Zhichao Lu
- **URL**: <http://arxiv.org/abs/2508.19558v1>
- **Submitted**: 2025-08-27 04:17:02
- **Topic Keywords**: ctr, retrieval
- **Reason**: The paper explores the functional consistency of code embeddings from large language models, which is a topic related to information retrieval and query understanding. However, the focus on code-level functional semantics and code clone detection is not directly aligned with the user's interests in search technologies and user behavior modeling.

#### Abstract
> Embedding models have demonstrated strong performance in tasks like
clustering, retrieval, and feature extraction while offering computational
advantages over generative models and cross-encoders. Benchmarks such as MTEB
have shown that text embeddings from large language models (LLMs) capture rich
semantic information, but their ability to reflect code-level functional
semantics remains unclear. Existing studies largely focus on code clone
detection, which emphasizes syntactic similarity and overlooks functional
understanding. In this paper, we focus on the functional consistency of LLM
code embeddings, which determines if two code snippets perform the same
function regardless of syntactic differences. We propose a novel data synthesis
framework called Functionality-Oriented Code Self-Evolution to construct
diverse and challenging benchmarks. Specifically, we define code examples
across four semantic and syntactic categories and find that existing datasets
predominantly capture syntactic properties. Our framework generates four unique
variations from a single code instance, providing a broader spectrum of code
examples that better reflect functional differences. Extensive experiments on
three downstream tasks-code clone detection, code functional consistency
identification, and code retrieval-demonstrate that embedding models
significantly improve their performance when trained on our evolved datasets.
These results highlight the effectiveness and generalization of our data
synthesis framework, advancing the functional understanding of code.

### 14. A Hybrid Recommendation Framework for Enhancing User Engagement in Local News

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Payam Pourashraf, Bamshad Mobasher
- **URL**: <http://arxiv.org/abs/2508.19539v1>
- **Submitted**: 2025-08-27 03:27:20
- **Topic Keywords**: rag, recommend, personalization
- **Reason**: The paper focuses on recommender systems, which is somewhat related to the user's interests in Information Retrieval and Search technologies. However, the specific application to local news and the emphasis on global and local preference models do not align with the user's primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Local news organizations face an urgent need to boost reader engagement amid
declining circulation and competition from global media. Personalized news
recommender systems offer a promising solution by tailoring content to user
interests. Yet, conventional approaches often emphasize general preferences and
may overlook nuanced or eclectic interests in local news.
  We propose a hybrid news recommender that integrates local and global
preference models to improve engagement. Building on evidence of the value of
localized models, our method unifies local and non-local predictors in one
framework. The system adaptively combines recommendations from a local model,
specialized in region-specific content, and a global model that captures
broader preferences. Ensemble strategies and multiphase training balance the
two.
  We evaluated the model on two datasets: a synthetic set based on Syracuse
newspaper distributions and a Danish dataset (EB-NeRD) labeled for local and
non-local content with an LLM. Results show our integrated approach outperforms
single-model baselines in accuracy and coverage, suggesting improved
personalization that can drive user engagement.
  The findings have practical implications for publishers, especially local
outlets. By leveraging both community-specific and general user interests, the
hybrid recommender can deliver more relevant content, increasing retention and
subscriptions. In sum, this work introduces a new direction for recommender
systems, bridging local and global models to revitalize local news consumption
through scalable, personalized user experiences.

### 15. Refining Text Generation for Realistic Conversational Recommendation via Direct Preference Optimization

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Manato Tajiri, Michimasa Inaba
- **URL**: <http://arxiv.org/abs/2508.19918v2>
- **Submitted**: 2025-08-27 14:24:13
- **Comment**: Accepted to EMNLP 2025 Main Conference
- **Topic Keywords**: rag, recommend
- **Reason**: The paper focuses on conversational recommender systems, which is a related topic to information retrieval. However, the emphasis on natural language processing and dialogue generation is not directly aligned with my primary research interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is somewhat limited to my secondary interests in NLP and data mining.

#### Abstract
> Conversational Recommender Systems (CRSs) aim to elicit user preferences via
natural dialogue to provide suitable item recommendations. However, current
CRSs often deviate from realistic human interactions by rapidly recommending
items in brief sessions. This work addresses this gap by leveraging Large
Language Models (LLMs) to generate dialogue summaries from dialogue history and
item recommendation information from item description. This approach enables
the extraction of both explicit user statements and implicit preferences
inferred from the dialogue context. We introduce a method using Direct
Preference Optimization (DPO) to ensure dialogue summary and item
recommendation information are rich in information crucial for effective
recommendations. Experiments on two public datasets validate our method's
effectiveness in fostering more natural and realistic conversational
recommendation processes.Our implementation is publicly available at:
https://github.com/UEC-InabaLab/Refining-LLM-Text

### 16. Cross-Platform E-Commerce Product Categorization and Recategorization: A Multimodal Hierarchical Classification Approach

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Lotte Gross, Rebecca Walter, Nicole Zoppi, Adrien Justus, Alessandro Gambetti, Qiwei Han, Maximilian Kaiser
- **URL**: <http://arxiv.org/abs/2508.20013v1>
- **Submitted**: 2025-08-27 16:16:12
- **Comment**: 10 pages, 5 figures, 3 tables
- **Topic Keywords**: commerce, e-commerce
- **Reason**: The paper focuses on e-commerce product categorization and recategorization, which is related to information retrieval, but the emphasis is on categorization rather than query understanding, ranking models, or user behavior modeling. The multimodal hierarchical classification approach is also not directly applicable to my research interests in NLP, data mining, and related topics.

#### Abstract
> This study addresses critical industrial challenges in e-commerce product
categorization, namely platform heterogeneity and the structural limitations of
existing taxonomies, by developing and deploying a multimodal hierarchical
classification framework. Using a dataset of 271,700 products from 40
international fashion e-commerce platforms, we integrate textual features
(RoBERTa), visual features (ViT), and joint vision--language representations
(CLIP). We investigate fusion strategies, including early, late, and
attention-based fusion within a hierarchical architecture enhanced by dynamic
masking to ensure taxonomic consistency. Results show that CLIP embeddings
combined via an MLP-based late-fusion strategy achieve the highest hierarchical
F1 (98.59\%), outperforming unimodal baselines. To address shallow or
inconsistent categories, we further introduce a self-supervised ``product
recategorization'' pipeline using SimCLR, UMAP, and cascade clustering, which
discovered new, fine-grained categories (e.g., subtypes of ``Shoes'') with
cluster purities above 86\%. Cross-platform experiments reveal a
deployment-relevant trade-off: complex late-fusion methods maximize accuracy
with diverse training data, while simpler early-fusion methods generalize more
effectively to unseen platforms. Finally, we demonstrate the framework's
industrial scalability through deployment in EURWEB's commercial transaction
intelligence platform via a two-stage inference pipeline, combining a
lightweight RoBERTa stage with a GPU--accelerated multimodal stage to balance
cost and accuracy.

### 17. Selective Retrieval-Augmentation for Long-Tail Legal Text Classification

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Boheng Mao
- **URL**: <http://arxiv.org/abs/2508.19997v2>
- **Submitted**: 2025-08-27 15:56:34
- **Topic Keywords**: retrieval
- **Reason**: The paper focuses on legal text classification, which is a specific domain and task, and uses retrieval-augmentation to improve model performance on rare classes. While it touches on NLP, it is not directly related to query understanding, ranking models, or user behavior modeling, which are core areas of interest for you. The paper's relevance to your broader interests in IR, search technologies, and data mining is limited.

#### Abstract
> Legal text classification is a fundamental NLP task in the legal domain.
Benchmark datasets in this area often exhibit a long-tail label distribution,
where many labels are underrepresented, leading to poor model performance on
rare classes. This paper proposes Selective Retrieval-Augmentation (SRA) as a
solution to this problem. SRA focuses on augmenting samples belonging to
low-frequency labels in the training set, preventing the introduction of noise
for well-represented classes, and requires no changes to the model
architecture. Retrieval is performed only from the training data to ensure
there is no potential information leakage, removing the need for external
corpora simultaneously. The proposed SRA method is tested on two legal text
classification benchmark datasets with long-tail distributions: LEDGAR
(single-label) and UNFAIR-ToS (multi-label). The results indicate that SRA
attains higher micro-F1 and macro-F1 scores compared to all current LexGLUE
baselines across both datasets, illustrating consistent improvements in
long-tail legal text classification.

### 18. AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Lisa Alazraki, Lihu Chen, Ana Brassard, Joe Stacey, Hossein A. Rahmani, Marek Rei
- **URL**: <http://arxiv.org/abs/2508.19988v1>
- **Submitted**: 2025-08-27 15:47:19
- **Topic Keywords**: rag
- **Reason**: The paper introduces a benchmark for evaluating the compositional reasoning abilities of Large Language Models (LLMs) in real-world scenarios. While it touches on the idea of combining multiple reasoning steps, it does not specifically focus on query understanding, ranking models, or user behavior modeling, which are core areas of interest for you. The paper's relevance to your research is limited to the broader topic of information retrieval and NLP, but it does not address the specific aspects you are interested in.

#### Abstract
> Large Language Models (LLMs) have achieved high accuracy on complex
commonsense and mathematical problems that involve the composition of multiple
reasoning steps. However, current compositional benchmarks testing these skills
tend to focus on either commonsense or math reasoning, whereas LLM agents
solving real-world tasks would require a combination of both. In this work, we
introduce an Agentic Commonsense and Math benchmark (AgentCoMa), where each
compositional task requires a commonsense reasoning step and a math reasoning
step. We test it on 61 LLMs of different sizes, model families, and training
strategies. We find that LLMs can usually solve both steps in isolation, yet
their accuracy drops by ~30% on average when the two are combined. This is a
substantially greater performance gap than the one we observe in prior
compositional benchmarks that combine multiple steps of the same reasoning
type. In contrast, non-expert human annotators can solve the compositional
questions and the individual steps in AgentCoMa with similarly high accuracy.
Furthermore, we conduct a series of interpretability studies to better
understand the performance gap, examining neuron patterns, attention maps and
membership inference. Our work underscores a substantial degree of model
brittleness in the context of mixed-type compositional reasoning and offers a
test bed for future improvement.

### 19. Diffusion Language Models Know the Answer Before Decoding

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Pengxiang Li, Yefan Zhou, Dilxat Muhtar, Lu Yin, Shilin Yan, Li Shen, Yi Liang, Soroush Vosoughi, Shiwei Liu
- **URL**: <http://arxiv.org/abs/2508.19982v1>
- **Submitted**: 2025-08-27 15:40:25
- **Topic Keywords**: rag
- **Reason**: The paper discusses diffusion language models, which is a topic in NLP, but it doesn't directly relate to information retrieval, query understanding, ranking models, or user behavior modeling, which are the user's core research interests. The paper's focus on decoding and inference speedup is also not directly relevant to the user's interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> Diffusion language models (DLMs) have recently emerged as an alternative to
autoregressive approaches, offering parallel sequence generation and flexible
token orders. However, their inference remains slower than that of
autoregressive models, primarily due to the cost of bidirectional attention and
the large number of refinement steps required for high quality outputs. In this
work, we highlight and leverage an overlooked property of DLMs early answer
convergence: in many cases, the correct answer can be internally identified by
half steps before the final decoding step, both under semi-autoregressive and
random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99%
of instances, respectively, can be decoded correctly using only half of the
refinement steps. Building on this observation, we introduce Prophet, a
training-free fast decoding paradigm that enables early commit decoding.
Specifically, Prophet dynamically decides whether to continue refinement or to
go "all-in" (i.e., decode all remaining tokens in one step), using the
confidence gap between the top-2 prediction candidates as the criterion. It
integrates seamlessly into existing DLM implementations, incurs negligible
overhead, and requires no additional training. Empirical evaluations of
LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the
number of decoding steps by up to 3.4x while preserving high generation
quality. These results recast DLM decoding as a problem of when to stop
sampling, and demonstrate that early decode convergence provides a simple yet
powerful mechanism for accelerating DLM inference, complementary to existing
speedup techniques. Our code is publicly available at
https://github.com/pixeli99/Prophet.

### 20. NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Aritra Dutta, Swapnanil Mukherjee, Deepanway Ghosal, Somak Aditya
- **URL**: <http://arxiv.org/abs/2508.19724v2>
- **Submitted**: 2025-08-27 09:34:28
- **Topic Keywords**: retrieval
- **Reason**: The paper focuses on integrating natural language knowledge into small vision-language models for commonsense visual-question answering, which is not directly related to information retrieval or search technologies. While it involves natural language processing and knowledge retrieval, the primary application is in the context of visual question answering, which is not a core area of interest for the user.

#### Abstract
> Commonsense visual-question answering often hinges on knowledge that is
missing from the image or the question. Small vision-language models (sVLMs)
such as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative
counterparts. To study the effect of careful commonsense knowledge integration
on sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural
language facts, (ii) prompts an LLM to craft natural language explanations, and
(iii) feeds both signals to sVLMs respectively across two commonsense VQA
datasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts
retrieved using a fine-tuned ColBERTv2 and an object information-enriched
prompt yield explanations that largely cut down hallucinations, while lifting
the end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA
and other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B
and SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional
finetuning using noise-robust losses (such as symmetric cross entropy and
generalised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our
findings expose when LLM-based commonsense knowledge beats retrieval from
commonsense knowledge bases, how noise-aware training stabilises small models
in the context of external knowledge augmentation, and why parameter-efficient
commonsense reasoning is now within reach for 250M models.

### 21. Survey of Specialized Large Language Model

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Chenghan Yang, Ruiyu Zhao, Yang Liu, Ling Jiang
- **URL**: <http://arxiv.org/abs/2508.19667v1>
- **Submitted**: 2025-08-27 08:27:23
- **Comment**: 9 pages, 1 figures
- **Topic Keywords**: commerce, e-commerce
- **Reason**: The paper's focus on specialized large language models and their applications in various domains, including healthcare, finance, and technical fields, shows some relevance to the user's interests in NLP and data mining. However, the paper's primary focus on language models and their applications in professional settings, rather than information retrieval and search technologies, limits its alignment with the user's core research themes.

#### Abstract
> The rapid evolution of specialized large language models (LLMs) has
transitioned from simple domain adaptation to sophisticated native
architectures, marking a paradigm shift in AI development. This survey
systematically examines this progression across healthcare, finance, legal, and
technical domains. Besides the wide use of specialized LLMs, technical
breakthrough such as the emergence of domain-native designs beyond fine-tuning,
growing emphasis on parameter efficiency through sparse computation and
quantization, increasing integration of multimodal capabilities and so on are
applied to recent LLM agent. Our analysis reveals how these innovations address
fundamental limitations of general-purpose LLMs in professional applications,
with specialized models consistently performance gains on domain-specific
benchmarks. The survey further highlights the implications for E-Commerce field
to fill gaps in the field.

### 22. Understanding and Leveraging the Expert Specialization of Context Faithfulness in Mixture-of-Experts LLMs

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Jun Bai, Minghao Tong, Yang Liu, Zixia Jia, Zilong Zheng
- **URL**: <http://arxiv.org/abs/2508.19594v1>
- **Submitted**: 2025-08-27 06:07:13
- **Comment**: Accepted by EMNLP 2025 Main
- **Topic Keywords**: rag
- **Reason**: The paper explores the concept of context faithfulness in large language models, which is related to query understanding and ranking models in Information Retrieval. However, the focus is on language models and expert specialization, which is not directly aligned with the user's interests in search technologies and user behavior modeling.

#### Abstract
> Context faithfulness is essential for reliable reasoning in context-dependent
scenarios. However, large language models often struggle to ground their
outputs in the provided context, resulting in irrelevant responses. Inspired by
the emergent expert specialization observed in mixture-of-experts
architectures, this work investigates whether certain experts exhibit
specialization in context utilization, offering a potential pathway toward
targeted optimization for improved context faithfulness. To explore this, we
propose Router Lens, a method that accurately identifies context-faithful
experts. Our analysis reveals that these experts progressively amplify
attention to relevant contextual information, thereby enhancing context
grounding. Building on this insight, we introduce Context-faithful Expert
Fine-Tuning (CEFT), a lightweight optimization approach that selectively
fine-tunes context-faithful experts. Experiments across a wide range of
benchmarks and models demonstrate that CEFT matches or surpasses the
performance of full fine-tuning while being significantly more efficient.

### 23. Scalable and consistent few-shot classification of survey responses using text embeddings

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Jonas Timmann Mjaaland, Markus Fleten Kreutzer, Halvor Tyseng, Rebeckah K. Fussell, Gina Passante, N. G. Holmes, Anders Malthe-S√∏renssen, Tor Ole B. Odden
- **URL**: <http://arxiv.org/abs/2508.19836v1>
- **Submitted**: 2025-08-27 12:45:25
- **Topic Keywords**: search
- **Reason**: The paper focuses on text embeddings and few-shot classification for survey responses, which is related to Natural Language Processing (NLP) and data mining. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval (IR). The paper's relevance is somewhat limited due to its focus on qualitative analysis and survey responses, which is not directly applicable to search technologies.

#### Abstract
> Qualitative analysis of open-ended survey responses is a commonly-used
research method in the social sciences, but traditional coding approaches are
often time-consuming and prone to inconsistency. Existing solutions from
Natural Language Processing such as supervised classifiers, topic modeling
techniques, and generative large language models have limited applicability in
qualitative analysis, since they demand extensive labeled data, disrupt
established qualitative workflows, and/or yield variable results. In this
paper, we introduce a text embedding-based classification framework that
requires only a handful of examples per category and fits well with standard
qualitative workflows. When benchmarked against human analysis of a conceptual
physics survey consisting of 2899 open-ended responses, our framework achieves
a Cohen's Kappa ranging from 0.74 to 0.83 as compared to expert human coders in
an exhaustive coding scheme. We further show how performance of this framework
improves with fine-tuning of the text embedding model, and how the method can
be used to audit previously-analyzed datasets. These findings demonstrate that
text embedding-assisted coding can flexibly scale to thousands of responses
without sacrificing interpretability, opening avenues for deductive qualitative
analysis at scale.

### 24. Disabling Self-Correction in Retrieval-Augmented Generation via Stealthy Retriever Poisoning

- **LLM Score**: 2
- **Keyword Score**: 10
- **Authors**: Yanbo Dai, Zhenlan Ji, Zongjie Li, Kuan Li, Shuai Wang
- **URL**: <http://arxiv.org/abs/2508.20083v1>
- **Submitted**: 2025-08-27 17:49:28
- **Topic Keywords**: retriever, queries, rag, retrieval
- **Reason**: This paper is not directly related to Information Retrieval (IR) or Search technologies, and does not align with the user's focus on query understanding, ranking models, or user behavior modeling. The paper's topic is more focused on Natural Language Processing (NLP) and language model manipulation, which is not a central match for the user's research interests.

#### Abstract
> Retrieval-Augmented Generation (RAG) has become a standard approach for
improving the reliability of large language models (LLMs). Prior work
demonstrates the vulnerability of RAG systems by misleading them into
generating attacker-chosen outputs through poisoning the knowledge base.
However, this paper uncovers that such attacks could be mitigated by the strong
\textit{self-correction ability (SCA)} of modern LLMs, which can reject false
context once properly configured. This SCA poses a significant challenge for
attackers aiming to manipulate RAG systems.
  In contrast to previous poisoning methods, which primarily target the
knowledge base, we introduce \textsc{DisarmRAG}, a new poisoning paradigm that
compromises the retriever itself to suppress the SCA and enforce
attacker-chosen outputs. This compromisation enables the attacker to
straightforwardly embed anti-SCA instructions into the context provided to the
generator, thereby bypassing the SCA. To this end, we present a
contrastive-learning-based model editing technique that performs localized and
stealthy edits, ensuring the retriever returns a malicious instruction only for
specific victim queries while preserving benign retrieval behavior. To further
strengthen the attack, we design an iterative co-optimization framework that
automatically discovers robust instructions capable of bypassing prompt-based
defenses. We extensively evaluate DisarmRAG across six LLMs and three QA
benchmarks. Our results show near-perfect retrieval of malicious instructions,
which successfully suppress SCA and achieve attack success rates exceeding 90\%
under diverse defensive prompts. Also, the edited retriever remains stealthy
under several detection methods, highlighting the urgent need for
retriever-centric defenses.

### 25. Youtu-GraphRAG: Vertically Unified Agents for Graph Retrieval-Augmented Complex Reasoning

- **LLM Score**: 2
- **Keyword Score**: 10
- **Authors**: Junnan Dong, Siyu An, Yifei Yu, Qian-Wen Zhang, Linhao Luo, Xiao Huang, Yunsheng Wu, Di Yin, Xing Sun
- **URL**: <http://arxiv.org/abs/2508.19855v1>
- **Submitted**: 2025-08-27 13:13:20
- **Comment**: 19 pages, 7 figures, 6 tables
- **Topic Keywords**: retriever, queries, rag, retrieval
- **Reason**: The paper focuses on graph retrieval-augmented complex reasoning, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and query understanding. The paper's emphasis on graph construction, community detection, and anonymity reversion is not relevant to the user's primary focus on deep semantic understanding and real-time relevance optimization in IR.

#### Abstract
> Graph retrieval-augmented generation (GraphRAG) has effectively enhanced
large language models in complex reasoning by organizing fragmented knowledge
into explicitly structured graphs. Prior efforts have been made to improve
either graph construction or graph retrieval in isolation, yielding suboptimal
performance, especially when domain shifts occur. In this paper, we propose a
vertically unified agentic paradigm, Youtu-GraphRAG, to jointly connect the
entire framework as an intricate integration. Specifically, (i) a seed graph
schema is introduced to bound the automatic extraction agent with targeted
entity types, relations and attribute types, also continuously expanded for
scalability over unseen domains; (ii) To obtain higher-level knowledge upon the
schema, we develop novel dually-perceived community detection, fusing
structural topology with subgraph semantics for comprehensive knowledge
organization. This naturally yields a hierarchical knowledge tree that supports
both top-down filtering and bottom-up reasoning with community summaries; (iii)
An agentic retriever is designed to interpret the same graph schema to
transform complex queries into tractable and parallel sub-queries. It
iteratively performs reflection for more advanced reasoning; (iv) To alleviate
the knowledge leaking problem in pre-trained LLM, we propose a tailored
anonymous dataset and a novel 'Anonymity Reversion' task that deeply measures
the real performance of the GraphRAG frameworks. Extensive experiments across
six challenging benchmarks demonstrate the robustness of Youtu-GraphRAG,
remarkably moving the Pareto frontier with up to 90.71% saving of token costs
and 16.62% higher accuracy over state-of-the-art baselines. The results
indicate our adaptability, allowing seamless domain transfer with minimal
intervention on schema.

### 26. AI for Statutory Simplification: A Comprehensive State Legal Corpus and Labor Benchmark

- **LLM Score**: 2
- **Keyword Score**: 8
- **Authors**: Emaan Hariri, Daniel E. Ho
- **URL**: <http://arxiv.org/abs/2508.19365v1>
- **Submitted**: 2025-08-26 18:53:39
- **Comment**: 10 pages, 3 figures. To appear in ICAIL 2025
- **Topic Keywords**: information retrieval, rag, retrieval, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The focus is on AI for statutory simplification, code simplification, and regulatory simplification, which is outside your primary area of interest.

#### Abstract
> One of the emerging use cases of AI in law is for code simplification:
streamlining, distilling, and simplifying complex statutory or regulatory
language. One U.S. state has claimed to eliminate one third of its state code
using AI. Yet we lack systematic evaluations of the accuracy, reliability, and
risks of such approaches. We introduce LaborBench, a question-and-answer
benchmark dataset designed to evaluate AI capabilities in this domain. We
leverage a unique data source to create LaborBench: a dataset updated annually
by teams of lawyers at the U.S. Department of Labor, who compile differences in
unemployment insurance laws across 50 states for over 101 dimensions in a
six-month process, culminating in a 200-page publication of tables. Inspired by
our collaboration with one U.S. state to explore using large language models
(LLMs) to simplify codes in this domain, where complexity is particularly
acute, we transform the DOL publication into LaborBench. This provides a unique
benchmark for AI capacity to conduct, distill, and extract realistic statutory
and regulatory information. To assess the performance of retrieval augmented
generation (RAG) approaches, we also compile StateCodes, a novel and
comprehensive state statute and regulatory corpus of 8.7 GB, enabling much more
systematic research into state codes. We then benchmark the performance of
information retrieval and state-of-the-art large LLMs on this data and show
that while these models are helpful as preliminary research for code
simplification, the overall accuracy is far below the touted promises for LLMs
as end-to-end pipelines for regulatory simplification.

### 27. DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Liana Patel, Negar Arabzadeh, Harshit Gupta, Ankita Sundar, Ion Stoica, Matei Zaharia, Carlos Guestrin
- **URL**: <http://arxiv.org/abs/2508.20033v1>
- **Submitted**: 2025-08-27 16:36:34
- **Topic Keywords**: queries, retrieval, search
- **Reason**: The paper focuses on generative research synthesis, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on evaluating systems for generating long-form summaries and citing prior research is also not aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> The ability to research and synthesize knowledge is central to human
expertise and progress. An emerging class of systems promises these exciting
capabilities through generative research synthesis, performing retrieval over
the live web and synthesizing discovered sources into long-form, cited
summaries. However, evaluating such systems remains an open challenge: existing
question-answering benchmarks focus on short-form factual responses, while
expert-curated datasets risk staleness and data contamination. Both fail to
capture the complexity and evolving nature of real research synthesis tasks. In
this work, we introduce DeepScholar-bench, a live benchmark and holistic,
automated evaluation framework designed to evaluate generative research
synthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv
papers and focuses on a real research synthesis task: generating the related
work sections of a paper by retrieving, synthesizing, and citing prior
research. Our evaluation framework holistically assesses performance across
three key dimensions, knowledge synthesis, retrieval quality, and
verifiability. We also develop DeepScholar-base, a reference pipeline
implemented efficiently using the LOTUS API. Using the DeepScholar-bench
framework, we perform a systematic evaluation of prior open-source systems,
search AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that
DeepScholar-base establishes a strong baseline, attaining competitive or higher
performance than each other method. We also find that DeepScholar-bench remains
far from saturated, with no system exceeding a score of $19\%$ across all
metrics. These results underscore the difficulty of DeepScholar-bench, as well
as its importance for progress towards AI systems capable of generative
research synthesis. We make our code available at
https://github.com/guestrin-lab/deepscholar-bench.

### 28. Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Ziniu Zhang, Zhenshuo Zhang, Dongyue Li, Lu Wang, Jennifer Dy, Hongyang R. Zhang
- **URL**: <http://arxiv.org/abs/2508.19999v1>
- **Submitted**: 2025-08-27 15:59:47
- **Comment**: 19 pages. To appear in EMNLP'25
- **Topic Keywords**: query, rag
- **Reason**: This paper is not directly related to information retrieval, search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on in-context learning, demonstration selection, and gradient estimation, which are not core topics in the user's research interests.

#### Abstract
> This paper introduces an algorithm to select demonstration examples for
in-context learning of a query set. Given a set of $n$ examples, how can we
quickly select $k$ out of $n$ to best serve as the conditioning for downstream
inference? This problem has broad applications in prompt tuning and
chain-of-thought reasoning. Since model weights remain fixed during in-context
learning, previous work has sought to design methods based on the similarity of
token embeddings. This work proposes a new approach based on gradients of the
output taken in the input embedding space. Our approach estimates model outputs
through a first-order approximation using the gradients. Then, we apply this
estimation to multiple randomly sampled subsets. Finally, we aggregate the
sampled subset outcomes to form an influence score for each demonstration, and
select $k$ most relevant examples. This procedure only requires pre-computing
model outputs and gradients once, resulting in a linear-time algorithm relative
to model and training set sizes. Extensive experiments across various models
and datasets validate the efficiency of our approach. We show that the gradient
estimation procedure yields approximations of full inference with less than
$\mathbf{1}\%$ error across six datasets. This allows us to scale up subset
selection that would otherwise run full inference by up to
$\mathbf{37.7}\times$ on models with up to $34$ billion parameters, and
outperform existing selection methods based on input embeddings by
$\mathbf{11}\%$ on average.

### 29. KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Taebaek Hwang, Minseo Kim, Gisang Lee, Seonuk Kim, Hyunjun Eun
- **URL**: <http://arxiv.org/abs/2508.19944v1>
- **Submitted**: 2025-08-27 15:01:02
- **Topic Keywords**: rag, search, korea
- **Reason**: The paper focuses on a specific benchmark for Korean Reading and Reasoning in Text-rich VQA, which is not directly related to Information Retrieval, Search technologies, or query understanding. Although it mentions Vision-Language Models, the context is different from the user's interests in IR and NLP.

#### Abstract
> Understanding and reasoning over text within visual contexts poses a
significant challenge for Vision-Language Models (VLMs), given the complexity
and diversity of real-world scenarios. To address this challenge, text-rich
Visual Question Answering (VQA) datasets and benchmarks have emerged for
high-resource languages like English. However, a critical gap persists for
low-resource languages such as Korean, where the lack of comprehensive
benchmarks hinders robust model evaluation and comparison. To bridge this gap,
we introduce KRETA, a benchmark for Korean Reading and rEasoning in Text-rich
VQA Attuned to diverse visual contexts. KRETA facilitates an in-depth
evaluation of both visual text understanding and reasoning capabilities, while
also supporting a multifaceted assessment across 15 domains and 26 image types.
Additionally, we introduce a semi-automated VQA generation pipeline
specifically optimized for text-rich settings, leveraging refined stepwise
image decomposition and a rigorous seven-metric evaluation protocol to ensure
data quality. While KRETA is tailored for Korean, we hope our adaptable and
extensible pipeline will facilitate the development of similar benchmarks in
other languages, thereby accelerating multilingual VLM research. The code and
dataset for KRETA are available at https://github.com/tabtoyou/KRETA.

### 30. Bangla-Bayanno: A 52K-Pair Bengali Visual Question Answering Dataset with LLM-Assisted Translation Refinement

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Mohammed Rakibul Hasan, Rafi Majid, Ahanaf Tahmid
- **URL**: <http://arxiv.org/abs/2508.19887v1>
- **Submitted**: 2025-08-27 13:48:04
- **Topic Keywords**: query, search
- **Reason**: The paper focuses on a specific domain (Bangla language) and task (Visual Question Answering) that is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions multimodal AI research, it does not address query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user.

#### Abstract
> In this paper, we introduce Bangla-Bayanno, an open-ended Visual Question
Answering (VQA) Dataset in Bangla, a widely used, low-resource language in
multimodal AI research. The majority of existing datasets are either manually
annotated with an emphasis on a specific domain, query type, or answer type or
are constrained by niche answer formats. In order to mitigate human-induced
errors and guarantee lucidity, we implemented a multilingual LLM-assisted
translation refinement pipeline. This dataset overcomes the issues of
low-quality translations from multilingual sources. The dataset comprises
52,650 question-answer pairs across 4750+ images. Questions are classified into
three distinct answer types: nominal (short descriptive), quantitative
(numeric), and polar (yes/no). Bangla-Bayanno provides the most comprehensive
open-source, high-quality VQA benchmark in Bangla, aiming to advance research
in low-resource multimodal learning and facilitate the development of more
inclusive AI systems.

### 31. A Scenario-Oriented Survey of Federated Recommender Systems: Techniques, Challenges, and Future Directions

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Yunqi Mi, Jiakui Shen, Guoshuai Zhao, Jialie Shen, Xueming Qian
- **URL**: <http://arxiv.org/abs/2508.19620v1>
- **Submitted**: 2025-08-27 06:57:50
- **Topic Keywords**: rag, recommend, search
- **Reason**: This paper focuses on federated recommender systems, which is a topic related to recommender systems, but not directly aligned with the user's primary research interests in information retrieval, query understanding, and ranking models. The paper's emphasis on privacy and federated learning frameworks is also not a central match for the user's interests.

#### Abstract
> Extending recommender systems to federated learning (FL) frameworks to
protect the privacy of users or platforms while making recommendations has
recently gained widespread attention in academia. This is due to the natural
coupling of recommender systems and federated learning architectures: the data
originates from distributed clients (mostly mobile devices held by users),
which are highly related to privacy. In a centralized recommender system
(CenRec), the central server collects clients' data, trains the model, and
provides the service. Whereas in federated recommender systems (FedRec), the
step of data collecting is omitted, and the step of model training is offloaded
to each client. The server only aggregates the model and other knowledge, thus
avoiding client privacy leakage. Some surveys of federated recommender systems
discuss and analyze related work from the perspective of designing FL systems.
However, their utility drops by ignoring specific recommendation scenarios'
unique characteristics and practical challenges. For example, the statistical
heterogeneity issue in cross-domain FedRec originates from the label drift of
the data held by different platforms, which is mainly caused by the recommender
itself, but not the federated architecture. Therefore, it should focus more on
solving specific problems in real-world recommendation scenarios to encourage
the deployment FedRec. To this end, this review comprehensively analyzes the
coupling of recommender systems and federated learning from the perspective of
recommendation researchers and practitioners. We establish a clear link between
recommendation scenarios and FL frameworks, systematically analyzing
scenario-specific approaches, practical challenges, and potential
opportunities. We aim to develop guidance for the real-world deployment of
FedRec, bridging the gap between existing research and applications.

### 32. SoK: Large Language Model Copyright Auditing via Fingerprinting

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Shuo Shao, Yiming Li, Yu He, Hongwei Yao, Wenyuan Yang, Dacheng Tao, Zhan Qin
- **URL**: <http://arxiv.org/abs/2508.19843v1>
- **Submitted**: 2025-08-27 12:56:57
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on Large Language Model fingerprinting for copyright auditing, which is not related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper's topic is more relevant to Natural Language Processing and data mining, but it does not address the user's specific areas of interest.

#### Abstract
> The broad capabilities and substantial resources required to train Large
Language Models (LLMs) make them valuable intellectual property, yet they
remain vulnerable to copyright infringement, such as unauthorized use and model
theft. LLM fingerprinting, a non-intrusive technique that extracts and compares
the distinctive features from LLMs to identify infringements, offers a
promising solution to copyright auditing. However, its reliability remains
uncertain due to the prevalence of diverse model modifications and the lack of
standardized evaluation. In this SoK, we present the first comprehensive study
of LLM fingerprinting. We introduce a unified framework and formal taxonomy
that categorizes existing methods into white-box and black-box approaches,
providing a structured overview of the state of the art. We further propose
LeaFBench, the first systematic benchmark for evaluating LLM fingerprinting
under realistic deployment scenarios. Built upon mainstream foundation models
and comprising 149 distinct model instances, LeaFBench integrates 13
representative post-development techniques, spanning both parameter-altering
methods (e.g., fine-tuning, quantization) and parameter-independent mechanisms
(e.g., system prompts, RAG). Extensive experiments on LeaFBench reveal the
strengths and weaknesses of existing methods, thereby outlining future research
directions and critical open problems in this emerging field. The code is
available at https://github.com/shaoshuo-ss/LeaFBench.

### 33. Building Task Bots with Self-learning for Enhanced Adaptability, Extensibility, and Factuality

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Xiaoying Zhang
- **URL**: <http://arxiv.org/abs/2508.19689v1>
- **Submitted**: 2025-08-27 08:52:47
- **Comment**: 179 pages
- **Topic Keywords**: search, acl
- **Reason**: This paper appears to be unrelated to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on task bots and dialog research does not align with the user's primary interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Developing adaptable, extensible, and accurate task bots with minimal or zero
human intervention is a significant challenge in dialog research. This thesis
examines the obstacles and potential solutions for creating such bots, focusing
on innovative techniques that enable bots to learn and adapt autonomously in
constantly changing environments.

### 34. Automatic Question & Answer Generation Using Generative Large Language Model (LLM)

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Md. Alvee Ehsan, A. S. M Mehedi Hasan, Kefaya Benta Shahnoor, Syeda Sumaiya Tasneem
- **URL**: <http://arxiv.org/abs/2508.19475v1>
- **Submitted**: 2025-08-26 23:36:13
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on automatic question and answer generation using a generative large language model, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions NLP, the scope is limited to question generation for educational purposes, which is not a primary interest area.

#### Abstract
> \Abstract{In the realm of education, student evaluation holds equal
significance as imparting knowledge. To be evaluated, students usually need to
go through text-based academic assessment methods. Instructors need to make
diverse sets of questions that need to be fair for all students to prove their
adequacy over a particular topic. This can prove to be quite challenging as
they may need to manually go through several different lecture materials. Our
objective is to make this whole process much easier by implementing Automatic
Question Answer Generation /(AQAG), using fine-tuned generative LLM. For
tailoring the instructor's preferred question style (MCQ, conceptual, or
factual questions), prompt Engineering (PE) is being utilized. In this
research, we propose to leverage unsupervised learning methods in NLP,
primarily focusing on the English language. This approach empowers the base
Meta-Llama 2-7B model to integrate RACE dataset as training data for the
fine-tuning process. Creating a customized model that will offer efficient
solutions for educators, instructors, and individuals engaged in text-based
evaluations. A reliable and efficient tool for generating questions and answers
can free up valuable time and resources, thus streamlining their evaluation
processes.}

### 35. One Joke to Rule them All? On the (Im)possibility of Generalizing Humor

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Mor Turgeman, Chen Shani, Dafna Shahaf
- **URL**: <http://arxiv.org/abs/2508.19402v1>
- **Submitted**: 2025-08-26 19:55:40
- **Topic Keywords**: rag, search
- **Reason**: The paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. Although it touches on Natural Language Processing, the focus is on humor and language models, which is a distinct area of research.

#### Abstract
> Humor is a broad and complex form of communication that remains challenging
for machines. Despite its broadness, most existing research on computational
humor traditionally focused on modeling a specific type of humor. In this work,
we wish to understand whether competence on one or more specific humor tasks
confers any ability to transfer to novel, unseen types; in other words, is this
fragmentation inevitable? This question is especially timely as new humor types
continuously emerge in online and social media contexts (e.g., memes,
anti-humor, AI fails). If Large Language Models (LLMs) are to keep up with this
evolving landscape, they must be able to generalize across humor types by
capturing deeper, transferable mechanisms. To investigate this, we conduct a
series of transfer learning experiments across four datasets, representing
different humor tasks. We train LLMs under varied diversity settings (1-3
datasets in training, testing on a novel task). Experiments reveal that models
are capable of some transfer, and can reach up to 75% accuracy on unseen
datasets; training on diverse sources improves transferability (1.88-4.05%)
with minimal-to-no drop in in-domain performance. Further analysis suggests
relations between humor types, with Dad Jokes surprisingly emerging as the best
enabler of transfer (but is difficult to transfer to). We release data and
code.

### 36. AraHealthQA 2025: The First Shared Task on Arabic Health Question Answering

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Hassan Alhuzali, Farah Shamout, Muhammad Abdul-Mageed, Chaimae Abouzahir, Mouath Abu-Daoud, Ashwag Alasmari, Walid Al-Eisawi, Renad Al-Monef, Ali Alqahtani, Lama Ayash, Nizar Habash, Leen Kharouf
- **URL**: <http://arxiv.org/abs/2508.20047v2>
- **Submitted**: 2025-08-27 16:54:09
- **Topic Keywords**: emnlp
- **Reason**: The paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The focus is on Arabic Health Question Answering, which is a specific domain and not a core area of interest. The paper does not mention any relevance to the user's background in e-commerce or NLP.

#### Abstract
> We introduce {AraHealthQA 2025}, the {Comprehensive Arabic Health Question
Answering Shared Task}, held in conjunction with {ArabicNLP 2025} (co-located
with EMNLP 2025). This shared task addresses the paucity of high-quality Arabic
medical QA resources by offering two complementary tracks: {MentalQA}, focusing
on Arabic mental health Q\&A (e.g., anxiety, depression, stigma reduction), and
{MedArabiQ}, covering broader medical domains such as internal medicine,
pediatrics, and clinical decision making. Each track comprises multiple
subtasks, evaluation datasets, and standardized metrics, facilitating fair
benchmarking. The task was structured to promote modeling under realistic,
multilingual, and culturally nuanced healthcare contexts. We outline the
dataset creation, task design and evaluation framework, participation
statistics, baseline systems, and summarize the overall outcomes. We conclude
with reflections on the performance trends observed and prospects for future
iterations in Arabic health QA.

### 37. Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sheng Liu, Qiang Sheng, Danding Wang, Yang Li, Guang Yang, Juan Cao
- **URL**: <http://arxiv.org/abs/2508.20038v2>
- **Submitted**: 2025-08-27 16:44:03
- **Comment**: EMNLP 2025 findings
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topic of Large Language Model (LLM) safety and attacks is not directly related to your areas of focus, and the paper's methods and results do not contribute to your research themes.

#### Abstract
> Despite advances in improving large language model (LLM) to refuse to answer
malicious instructions, widely used LLMs remain vulnerable to jailbreak attacks
where attackers generate instructions with distributions differing from safety
alignment corpora. New attacks expose LLMs' inability to recognize unseen
malicious instructions, highlighting a critical distributional mismatch between
training data and real-world attacks that forces developers into reactive
patching cycles. To tackle this challenge, we propose IMAGINE, a synthesis
framework that leverages embedding space distribution analysis to generate
jailbreak-like instructions. This approach effectively fills the distributional
gap between authentic jailbreak patterns and safety alignment corpora. IMAGINE
follows an iterative optimization process that dynamically evolves text
generation distributions across iterations, thereby augmenting the coverage of
safety alignment data distributions through synthesized data examples. Based on
the safety-aligned corpus enhanced through IMAGINE, our framework demonstrates
significant decreases in attack success rate on Qwen2.5, Llama3.1, and Llama3.2
without compromising their utility.

### 38. Self-Supervised Pre-Training with Equilibrium Constraints

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xiaodong Cui, A F M Saif, Brian Kingsbury, Tianyi Chen
- **URL**: <http://arxiv.org/abs/2508.19990v1>
- **Submitted**: 2025-08-27 15:48:50
- **Topic Keywords**: rag
- **Reason**: The paper focuses on self-supervised pre-training with equilibrium constraints, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions pre-training and fine-tuning, the context is different from the user's interests in IR and NLP.

#### Abstract
> Self-supervised pre-training using unlabeled data is widely used in machine
learning. In this paper, we propose a new self-supervised pre-training approach
to dealing with heterogeneous data. Instead of mixing all the data and
minimizing the averaged global loss in the conventional way, we impose
additional equilibrium constraints to ensure that the models optimizes each
source of heterogeneous data to its local optima after $K$-step gradient
descent initialized from the model. We formulate this as a bilevel optimization
problem, and use the first-order approximation method to solve the problem. We
discuss its connection to model-agnostic meta learning (MAML). Experiments are
carried out on self-supervised pre-training using multi-domain and multilingual
datasets, demonstrating that the proposed approach can significantly improve
the adaptivity of the self-supervised pre-trained model for the downstream
supervised fine-tuning tasks.

### 39. GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Seongheon Park, Yixuan Li
- **URL**: <http://arxiv.org/abs/2508.19972v1>
- **Submitted**: 2025-08-27 15:30:06
- **Topic Keywords**: rag
- **Reason**: This paper focuses on object hallucination detection in large vision-language models, which is outside the scope of information retrieval and search technologies. Although it involves natural language processing, the topic is not directly related to query understanding, ranking models, or user behavior modeling, which are core areas of interest.

#### Abstract
> Object hallucination in large vision-language models presents a significant
challenge to their safe deployment in real-world applications. Recent works
have proposed object-level hallucination scores to estimate the likelihood of
object hallucination; however, these methods typically adopt either a global or
local perspective in isolation, which may limit detection reliability. In this
paper, we introduce GLSim, a novel training-free object hallucination detection
framework that leverages complementary global and local embedding similarity
signals between image and text modalities, enabling more accurate and reliable
hallucination detection in diverse scenarios. We comprehensively benchmark
existing object hallucination detection methods and demonstrate that GLSim
achieves superior detection performance, outperforming competitive baselines by
a significant margin.

### 40. Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Slimane Bellaouar, Attia Nehar, Soumia Souffi, Mounia Bouameur
- **URL**: <http://arxiv.org/abs/2508.19966v1>
- **Submitted**: 2025-08-27 15:20:12
- **Comment**: 25 pages, 7 figures
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Arabic subjectivity evaluation using fine-tuned language models, which is not directly related to my research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions language models, the context is specific to Arabic language processing and does not address query understanding, ranking models, or user behavior modeling, which are my primary areas of interest.

#### Abstract
> Despite its significance, Arabic, a linguistically rich and morphologically
complex language, faces the challenge of being under-resourced. The scarcity of
large annotated datasets hampers the development of accurate tools for
subjectivity analysis in Arabic. Recent advances in deep learning and
Transformers have proven highly effective for text classification in English
and French. This paper proposes a new approach for subjectivity assessment in
Arabic textual data. To address the dearth of specialized annotated datasets,
we developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic
datasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we
fine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and
ArabianGPT) on AraDhati+ for effective subjectivity classification.
Furthermore, we experimented with an ensemble decision approach to harness the
strengths of individual models. Our approach achieves a remarkable accuracy of
97.79\,\% for Arabic subjectivity classification. Results demonstrate the
effectiveness of the proposed approach in addressing the challenges posed by
limited resources in Arabic language processing.

### 41. Logical Reasoning with Outcome Reward Models for Test-Time Scaling

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ramya Keerthy Thatikonda, Wray Buntine, Ehsan Shareghi
- **URL**: <http://arxiv.org/abs/2508.19903v1>
- **Submitted**: 2025-08-27 14:08:43
- **Comment**: EMNLP 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on logical reasoning with large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions reward models, the context is different from the user's interests in ranking models and user behavior modeling.

#### Abstract
> Logical reasoning is a critical benchmark for evaluating the capabilities of
large language models (LLMs), as it reflects their ability to derive valid
conclusions from given premises. While the combination of test-time scaling
with dedicated outcome or process reward models has opened up new avenues to
enhance LLMs performance in complex reasoning tasks, this space is
under-explored in deductive logical reasoning. We present a set of Outcome
Reward Models (ORMs) for deductive reasoning. To train the ORMs we mainly
generate data using Chain-of-Thought (CoT) with single and multiple samples.
Additionally, we propose a novel tactic to further expand the type of errors
covered in the training dataset of the ORM. In particular, we propose an echo
generation technique that leverages LLMs' tendency to reflect incorrect
assumptions made in prompts to extract additional training data, covering
previously unexplored error types. While a standard CoT chain may contain
errors likely to be made by the reasoner, the echo strategy deliberately steers
the model toward incorrect reasoning. We show that ORMs trained on CoT and
echo-augmented data demonstrate improved performance on the FOLIO, JustLogic,
and ProverQA datasets across four different LLMs.

### 42. Beyond Shallow Heuristics: Leveraging Human Intuition for Curriculum Learning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Vanessa Toborek, Sebastian M√ºller, Tim Selbach, Tam√°s Horv√°th, Christian Bauckhage
- **URL**: <http://arxiv.org/abs/2508.19873v1>
- **Submitted**: 2025-08-27 13:35:13
- **Comment**: Presented at ICNLSP 2025; to appear in the ACL Anthology; received
  the Best Short Paper Award
- **Topic Keywords**: rag
- **Reason**: The paper focuses on curriculum learning, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions language models, the context is pre-training and linguistic difficulty, which is not a key area of interest for the user.

#### Abstract
> Curriculum learning (CL) aims to improve training by presenting data from
"easy" to "hard", yet defining and measuring linguistic difficulty remains an
open challenge. We investigate whether human-curated simple language can serve
as an effective signal for CL. Using the article-level labels from the Simple
Wikipedia corpus, we compare label-based curricula to competence-based
strategies relying on shallow heuristics. Our experiments with a BERT-tiny
model show that adding simple data alone yields no clear benefit. However,
structuring it via a curriculum -- especially when introduced first --
consistently improves perplexity, particularly on simple language. In contrast,
competence-based curricula lead to no consistent gains over random ordering,
probably because they fail to effectively separate the two classes. Our results
suggest that human intuition about linguistic difficulty can guide CL for
language model pre-training.

### 43. TokenVerse++: Towards Flexible Multitask Learning with Dynamic Task Activation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Shashi Kumar, Srikanth Madikeri, Esa√∫ Villatoro-Tello, Sergio Burdisso, Pradeep Rangappa, Andr√©s Carofilis, Petr Motlicek, Karthik Pandia, Shankar Venkatesan, Kadri Hacioƒülu, Andreas Stolcke
- **URL**: <http://arxiv.org/abs/2508.19856v1>
- **Submitted**: 2025-08-27 13:16:31
- **Comment**: Accepted to IEEE ASRU 2025. Copyright\copyright 2025 IEEE
- **Topic Keywords**: rag
- **Reason**: The paper focuses on multitask learning and dynamic task activation in the context of ASR and language identification, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on acoustic embedding space and XLSR-Transducer ASR model also does not align with the user's background in e-commerce and focus on deep semantic understanding and real-time relevance optimization.

#### Abstract
> Token-based multitasking frameworks like TokenVerse require all training
utterances to have labels for all tasks, hindering their ability to leverage
partially annotated datasets and scale effectively. We propose TokenVerse++,
which introduces learnable vectors in the acoustic embedding space of the
XLSR-Transducer ASR model for dynamic task activation. This core mechanism
enables training with utterances labeled for only a subset of tasks, a key
advantage over TokenVerse. We demonstrate this by successfully integrating a
dataset with partial labels, specifically for ASR and an additional task,
language identification, improving overall performance. TokenVerse++ achieves
results on par with or exceeding TokenVerse across multiple tasks, establishing
it as a more practical multitask alternative without sacrificing ASR
performance.

### 44. Benchmarking Hindi LLMs: A New Suite of Datasets and a Comparative Analysis

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Anusha Kamath, Kanishk Singla, Rakesh Paul, Raviraj Joshi, Utkarsh Vaidya, Sanjay Singh Chauhan, Niranjan Wartikar
- **URL**: <http://arxiv.org/abs/2508.19831v1>
- **Submitted**: 2025-08-27 12:35:31
- **Topic Keywords**: rag
- **Reason**: The paper focuses on benchmarking Hindi Large Language Models, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves language models, the context is not relevant to the user's primary research interests.

#### Abstract
> Evaluating instruction-tuned Large Language Models (LLMs) in Hindi is
challenging due to a lack of high-quality benchmarks, as direct translation of
English datasets fails to capture crucial linguistic and cultural nuances. To
address this, we introduce a suite of five Hindi LLM evaluation datasets:
IFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, and BFCL-Hi. These were created
using a methodology that combines from-scratch human annotation with a
translate-and-verify process. We leverage this suite to conduct an extensive
benchmarking of open-source LLMs supporting Hindi, providing a detailed
comparative analysis of their current capabilities. Our curation process also
serves as a replicable methodology for developing benchmarks in other
low-resource languages.

### 45. Safety Alignment Should Be Made More Than Just A Few Attention Heads

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Chao Huang, Zefeng Zhang, Juewei Yue, Quangang Li, Chuang Zhang, Tingwen Liu
- **URL**: <http://arxiv.org/abs/2508.19697v1>
- **Submitted**: 2025-08-27 09:06:28
- **Topic Keywords**: rag
- **Reason**: This paper focuses on the safety of large language models, introducing a targeted ablation method to identify critical attention heads. While it touches on attention heads, which is related to ranking models, the paper's primary concern is safety, which is not directly aligned with the user's research interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Current safety alignment for large language models(LLMs) continues to present
vulnerabilities, given that adversarial prompting can effectively bypass their
safety measures.Our investigation shows that these safety mechanisms
predominantly depend on a limited subset of attention heads: removing or
ablating these heads can severely compromise model safety. To identify and
evaluate these safety-critical components, we introduce RDSHA, a targeted
ablation method that leverages the model's refusal direction to pinpoint
attention heads mostly responsible for safety behaviors. Further analysis shows
that existing jailbreak attacks exploit this concentration by selectively
bypassing or manipulating these critical attention heads. To address this
issue, we propose AHD, a novel training strategy designed to promote the
distributed encoding of safety-related behaviors across numerous attention
heads. Experimental results demonstrate that AHD successfully distributes
safety-related capabilities across more attention heads. Moreover, evaluations
under several mainstream jailbreak attacks show that models trained with AHD
exhibit considerably stronger safety robustness, while maintaining overall
functional utility.

### 46. A Symbolic Adversarial Learning Framework for Evolving Fake News Generation and Detection

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Chong Tian, Qirong Ho, Xiuying Chen
- **URL**: <http://arxiv.org/abs/2508.19633v1>
- **Submitted**: 2025-08-27 07:14:17
- **Comment**: Accepted to EMNLP 2025 Main Conference
- **Topic Keywords**: rag
- **Reason**: The paper focuses on fake news generation and detection, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on symbolic learning and adversarial training is also not aligned with the user's background in e-commerce and interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Rapid LLM advancements heighten fake news risks by enabling the automatic
generation of increasingly sophisticated misinformation. Previous detection
methods, including fine-tuned small models or LLM-based detectors, often
struggle with its dynamically evolving nature. In this work, we propose a novel
framework called the Symbolic Adversarial Learning Framework (SALF), which
implements an adversarial training paradigm by an agent symbolic learning
optimization process, rather than relying on numerical updates. SALF introduces
a paradigm where the generation agent crafts deceptive narratives, and the
detection agent uses structured debates to identify logical and factual flaws
for detection, and they iteratively refine themselves through such adversarial
interactions. Unlike traditional neural updates, we represent agents using
agent symbolic learning, where learnable weights are defined by agent prompts,
and simulate back-propagation and gradient descent by operating on natural
language representations of weights, loss, and gradients. Experiments on two
multilingual benchmark datasets demonstrate SALF's effectiveness, showing it
generates sophisticated fake news that degrades state-of-the-art detection
performance by up to 53.4% in Chinese and 34.2% in English on average. SALF
also refines detectors, improving detection of refined content by up to 7.7%.
We hope our work inspires further exploration into more robust, adaptable fake
news detection systems.

### 47. Geopolitical Parallax: Beyond Walter Lippmann Just After Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Mehmet Can Yavuz, Humza Gohar Kabir, Aylin √ñzkan
- **URL**: <http://arxiv.org/abs/2508.19492v1>
- **Submitted**: 2025-08-27 00:39:59
- **Comment**: 7 pages, 4 figures, 7 tables
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on the geopolitical biases in large language models and their impact on news quality and subjectivity assessments, which is outside the scope of your research areas.

#### Abstract
> Objectivity in journalism has long been contested, oscillating between ideals
of neutral, fact-based reporting and the inevitability of subjective framing.
With the advent of large language models (LLMs), these tensions are now
mediated by algorithmic systems whose training data and design choices may
themselves embed cultural or ideological biases. This study investigates
geopolitical parallax-systematic divergence in news quality and subjectivity
assessments-by comparing article-level embeddings from Chinese-origin (Qwen,
BGE, Jina) and Western-origin (Snowflake, Granite) model families. We evaluate
both on a human-annotated news quality benchmark spanning fifteen stylistic,
informational, and affective dimensions, and on parallel corpora covering
politically sensitive topics, including Palestine and reciprocal China-United
States coverage. Using logistic regression probes and matched-topic evaluation,
we quantify per-metric differences in predicted positive-class probabilities
between model families. Our findings reveal consistent, non-random divergences
aligned with model origin. In Palestine-related coverage, Western models assign
higher subjectivity and positive emotion scores, while Chinese models emphasize
novelty and descriptiveness. Cross-topic analysis shows asymmetries in
structural quality metrics Chinese-on-US scoring notably lower in fluency,
conciseness, technicality, and overall quality-contrasted by higher negative
emotion scores. These patterns align with media bias theory and our distinction
between semantic, emotional, and relational subjectivity, and extend LLM bias
literature by showing that geopolitical framing effects persist in downstream
quality assessment tasks. We conclude that LLM-based media evaluation pipelines
require cultural calibration to avoid conflating content differences with
model-induced bias.

### 48. LongReasonArena: A Long Reasoning Benchmark for Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jiayu Ding, Shuming Ma, Lei Cui, Nanning Zheng, Furu Wei
- **URL**: <http://arxiv.org/abs/2508.19363v1>
- **Submitted**: 2025-08-26 18:41:53
- **Topic Keywords**: retrieval
- **Reason**: The paper focuses on evaluating long reasoning capabilities of Large Language Models, which is not directly related to my research interests in Information Retrieval, Search technologies, and query understanding. While it touches on topics like retrieval, it is not relevant to my primary focus on real-time relevance optimization and deep semantic understanding.

#### Abstract
> Existing long-context benchmarks for Large Language Models (LLMs) focus on
evaluating comprehension of long inputs, while overlooking the evaluation of
long reasoning abilities. To address this gap, we introduce LongReasonArena, a
benchmark specifically designed to assess the long reasoning capabilities of
LLMs. Our tasks require models to solve problems by executing multi-step
algorithms that reflect key aspects of long reasoning, such as retrieval and
backtracking. By controlling the inputs, the required reasoning length can be
arbitrarily scaled, reaching up to 1 million tokens of reasoning for the most
challenging tasks. Extensive evaluation results demonstrate that
LongReasonArena presents a significant challenge for both open-source and
proprietary LLMs. For instance, Deepseek-R1 achieves only 7.5% accuracy on our
task. Further analysis also reveals that the accuracy exhibits a linear decline
with respect to the logarithm of the expected number of reasoning steps. Our
code and data is available at
https://github.com/LongReasonArena/LongReasonArena.

### 49. Reflective Agreement: Combining Self-Mixture of Agents with a Sequence Tagger for Robust Event Extraction

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Fatemeh Haji, Mazal Bethany, Cho-Yu Jason Chiang, Anthony Rios, Peyman Najafirad
- **URL**: <http://arxiv.org/abs/2508.19359v1>
- **Submitted**: 2025-08-26 18:36:23
- **Topic Keywords**: rag
- **Reason**: The paper focuses on Event Extraction, a topic outside of the user's primary research interests in Information Retrieval and Search technologies. Although it mentions Large Language Models, which are related to NLP, the application and methodology are not directly relevant to the user's areas of focus.

#### Abstract
> Event Extraction (EE) involves automatically identifying and extracting
structured information about events from unstructured text, including triggers,
event types, and arguments. Traditional discriminative models demonstrate high
precision but often exhibit limited recall, particularly for nuanced or
infrequent events. Conversely, generative approaches leveraging Large Language
Models (LLMs) provide higher semantic flexibility and recall but suffer from
hallucinations and inconsistent predictions. To address these challenges, we
propose Agreement-based Reflective Inference System (ARIS), a hybrid approach
combining a Self Mixture of Agents with a discriminative sequence tagger. ARIS
explicitly leverages structured model consensus, confidence-based filtering,
and an LLM reflective inference module to reliably resolve ambiguities and
enhance overall event prediction quality. We further investigate decomposed
instruction fine-tuning for enhanced LLM event extraction understanding.
Experiments demonstrate our approach outperforms existing state-of-the-art
event extraction methods across three benchmark datasets.

### 50. Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jingyu Guo, Yingying Xu
- **URL**: <http://arxiv.org/abs/2508.19919v1>
- **Submitted**: 2025-08-27 14:25:43
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on the emergence of stereotypes in AI agent interactions, which is a topic in Artificial Intelligence and Machine Learning, but not directly related to your areas of interest.

#### Abstract
> While stereotypes are well-documented in human social interactions, AI
systems are often presumed to be less susceptible to such biases. Previous
studies have focused on biases inherited from training data, but whether
stereotypes can emerge spontaneously in AI agent interactions merits further
exploration. Through a novel experimental framework simulating workplace
interactions with neutral initial conditions, we investigate the emergence and
evolution of stereotypes in LLM-based multi-agent systems. Our findings reveal
that (1) LLM-Based AI agents develop stereotype-driven biases in their
interactions despite beginning without predefined biases; (2) stereotype
effects intensify with increased interaction rounds and decision-making power,
particularly after introducing hierarchical structures; (3) these systems
exhibit group effects analogous to human social behavior, including halo
effects, confirmation bias, and role congruity; and (4) these stereotype
patterns manifest consistently across different LLM architectures. Through
comprehensive quantitative analysis, these findings suggest that stereotype
formation in AI systems may arise as an emergent property of multi-agent
interactions, rather than merely from training data biases. Our work
underscores the need for future research to explore the underlying mechanisms
of this phenomenon and develop strategies to mitigate its ethical impacts.

---

