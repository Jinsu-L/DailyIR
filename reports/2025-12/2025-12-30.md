# Daily Papers Report - 2025-12-30

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. RobustMask: Certified Robustness against Adversarial Neural Ranking Attack via Randomized Masking

- **LLM Score**: 8
- **Keyword Score**: 12
- **Authors**: Jiawei Liu, Zhuo Chen, Rui Zhu, Miaokun Chen, Yuyang Gong, Wei Lu, Xiaofeng Wang
- **URL**: <http://arxiv.org/abs/2512.23307v1>
- **Submitted**: 2025-12-29 08:51:35
- **Topic Keywords**: ranking, pairwise, rag, retrieval, rank, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, specifically in the area of robustness and security of neural ranking models. The proposed RobustMask defense mechanism aligns with your focus on real-time relevance optimization and deep semantic understanding. Although the paper's primary focus is on adversarial attacks, it contributes to the broader field of IR, making it a useful read.

#### Abstract
> Neural ranking models have achieved remarkable progress and are now widely deployed in real-world applications such as Retrieval-Augmented Generation (RAG). However, like other neural architectures, they remain vulnerable to adversarial manipulations: subtle character-, word-, or phrase-level perturbations can poison retrieval results and artificially promote targeted candidates, undermining the integrity of search engines and downstream systems. Existing defenses either rely on heuristics with poor generalization or on certified methods that assume overly strong adversarial knowledge, limiting their practical use. To address these challenges, we propose RobustMask, a novel defense that combines the context-prediction capability of pretrained language models with a randomized masking-based smoothing mechanism. Our approach strengthens neural ranking models against adversarial perturbations at the character, word, and phrase levels. Leveraging both the pairwise comparison ability of ranking models and probabilistic statistical analysis, we provide a theoretical proof of RobustMask's certified top-K robustness. Extensive experiments further demonstrate that RobustMask successfully certifies over 20% of candidate documents within the top-10 ranking positions against adversarial perturbations affecting up to 30% of their content. These results highlight the effectiveness of RobustMask in enhancing the adversarial robustness of neural ranking models, marking a significant step toward providing stronger security guarantees for real-world retrieval systems.

---

### 2. Nested Browser-Use Learning for Agentic Information Seeking

- **LLM Score**: 8
- **Keyword Score**: 3
- **Authors**: Baixuan Li, Jialong Wu, Wenbiao Yin, Kuan Li, Zhongwang Zhang, Huifeng Yin, Zhengwei Tao, Liwen Zhang, Pengjun Xie, Jingren Zhou, Yong Jiang
- **URL**: <http://arxiv.org/abs/2512.23647v1>
- **Submitted**: 2025-12-29 17:59:14
- **Topic Keywords**: retrieval, search
- **Reason**: This paper is highly relevant to Information Retrieval, particularly in the area of query understanding and real-time relevance optimization. The focus on browser interaction and deep-web information acquisition aligns with your interests in search technologies and user behavior modeling. However, the specific application to agentic information-seeking agents is somewhat niche, preventing a perfect match.

#### Abstract
> Information-seeking (IS) agents have achieved strong performance across a range of wide and deep search tasks, yet their tool use remains largely restricted to API-level snippet retrieval and URL-based page fetching, limiting access to the richer information available through real browsing. While full browser interaction could unlock deeper capabilities, its fine-grained control and verbose page content returns introduce substantial complexity for ReAct-style function-calling agents. To bridge this gap, we propose Nested Browser-Use Learning (NestBrowse), which introduces a minimal and complete browser-action framework that decouples interaction control from page exploration through a nested structure. This design simplifies agentic reasoning while enabling effective deep-web information acquisition. Empirical results on challenging deep IS benchmarks demonstrate that NestBrowse offers clear benefits in practice. Further in-depth analyses underscore its efficiency and flexibility.

---

### 3. Semantic Tree Inference on Text Corpa using a Nested Density Approach together with Large Language Model Embeddings

- **LLM Score**: 8
- **Keyword Score**: 1
- **Authors**: Thomas Haschka, Joseph Bakarji
- **URL**: <http://arxiv.org/abs/2512.23471v1>
- **Submitted**: 2025-12-29 13:55:23
- **Comment**: 20 pages, 9 figures
- **Topic Keywords**: search
- **Reason**: This paper is highly relevant to your interests in Information Retrieval, particularly in the area of query understanding and ranking models. The proposed nested density clustering approach and its application to large language model embeddings aligns with your focus on deep semantic understanding and real-time relevance optimization. However, the paper's primary focus on text classification and semantic relationships is somewhat tangential to your core research themes in search technologies and user behavior modeling.

#### Abstract
> Semantic text classification has undergone significant advances in recent years due to the rise of large language models (LLMs) and their high dimensional embeddings. While LLM-embeddings are frequently used to store and retrieve text by semantic similarity in vector databases, the global structure semantic relationships in text corpora often remains opaque. Herein we propose a nested density clustering approach, to infer hierarchical trees of semantically related texts. The method starts by identifying texts of strong semantic similarity as it searches for dense clusters in LLM embedding space. As the density criterion is gradually relaxed, these dense clusters merge into more diffuse clusters, until the whole dataset is represented by a single cluster -- the root of the tree. By embedding dense clusters into increasingly diffuse ones, we construct a tree structure that captures hierarchical semantic relationships among texts. We outline how this approach can be used to classify textual data for abstracts of scientific abstracts as a case study. This enables the data-driven discovery research areas and their subfields without predefined categories. To evaluate the general applicability of the method, we further apply it to established benchmark datasets such as the 20 Newsgroups and IMDB 50k Movie Reviews, demonstrating its robustness across domains. Finally we discuss possible applications on scientometrics, topic evolution, highlighting how nested density trees can reveal semantic structure and evolution in textual datasets.

---

### 4. Scoring, Reasoning, and Selecting the Best! Ensembling Large Language Models via a Peer-Review Process

- **LLM Score**: 7
- **Keyword Score**: 5
- **Authors**: Zhijun Chen, Zeyu Ji, Qianren Mao, Junhang Cheng, Bangjie Qin, Hao Wu, Zhuoran Li, Jingzheng Li, Kai Sun, Zizhe Wang, Yikun Ban, Zhu Sun, Xiangyang Ji, Hailong Sun
- **URL**: <http://arxiv.org/abs/2512.23213v1>
- **Submitted**: 2025-12-29 05:25:49
- **Topic Keywords**: query, rag
- **Reason**: This paper is somewhat related to the user's research interests in Information Retrieval, particularly in the context of query understanding and ranking models. The use of Large Language Models (LLMs) and ensemble methods is relevant to the user's interests in NLP and deep semantic understanding. However, the focus on LLMs and peer-review process is not directly aligned with the user's primary focus on e-commerce and real-time relevance optimization.

#### Abstract
> We propose LLM-PeerReview, an unsupervised LLM Ensemble method that selects the most ideal response from multiple LLM-generated candidates for each query, harnessing the collective wisdom of multiple models with diverse strengths. LLM-PeerReview is built on a novel, peer-review-inspired framework that offers a clear and interpretable mechanism, while remaining fully unsupervised for flexible adaptability and generalization. Specifically, it operates in three stages: For scoring, we use the emerging LLM-as-a-Judge technique to evaluate each response by reusing multiple LLMs at hand; For reasoning, we can apply a principled graphical model-based truth inference algorithm or a straightforward averaging strategy to aggregate multiple scores to produce a final score for each response; Finally, the highest-scoring response is selected as the best ensemble output. LLM-PeerReview is conceptually simple and empirically powerful. The two variants of the proposed approach obtain strong results across four datasets, including outperforming the recent advanced model Smoothie-Global by 6.9% and 7.3% points, respectively.

---

### 5. Not too long do read: Evaluating LLM-generated extreme scientific summaries

- **LLM Score**: 6
- **Keyword Score**: 3
- **Authors**: Zhuoqi Lyu, Qing Ke
- **URL**: <http://arxiv.org/abs/2512.23206v1>
- **Submitted**: 2025-12-29 05:03:02
- **Topic Keywords**: rag, search
- **Reason**: This paper explores the performance of Large Language Models (LLMs) in generating scientific summaries, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on summarization and LLMs is not a central match to the user's core research themes, which are more focused on search technologies and user behavior modeling.

#### Abstract
> High-quality scientific extreme summary (TLDR) facilitates effective science communication. How do large language models (LLMs) perform in generating them? How are LLM-generated summaries different from those written by human experts? However, the lack of a comprehensive, high-quality scientific TLDR dataset hinders both the development and evaluation of LLMs' summarization ability. To address these, we propose a novel dataset, BiomedTLDR, containing a large sample of researcher-authored summaries from scientific papers, which leverages the common practice of including authors' comments alongside bibliography items. We then test popular open-weight LLMs for generating TLDRs based on abstracts. Our analysis reveals that, although some of them successfully produce humanoid summaries, LLMs generally exhibit a greater affinity for the original text's lexical choices and rhetorical structures, hence tend to be more extractive rather than abstractive in general, compared to humans. Our code and datasets are available at https://github.com/netknowledge/LLM_summarization (Lyu and Ke, 2025).

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Eliciting Behaviors in Multi-Turn Conversations

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Jing Huang, Shujian Zhang, Lun Wang, Andrew Hard, Rajiv Mathews, John Lambert
- **URL**: <http://arxiv.org/abs/2512.23701v1>
- **Submitted**: 2025-12-29 18:57:10
- **Topic Keywords**: query, queries, rag
- **Reason**: This paper explores behavior elicitation in multi-turn conversations, which is somewhat related to user behavior modeling in information retrieval. However, the focus on conversational settings and language models is not directly aligned with the user's core research themes in IR and search technologies.

#### Abstract
> Identifying specific and often complex behaviors from large language models (LLMs) in conversational settings is crucial for their evaluation. Recent work proposes novel techniques to find natural language prompts that induce specific behaviors from a target model, yet they are mainly studied in single-turn settings. In this work, we study behavior elicitation in the context of multi-turn conversations. We first offer an analytical framework that categorizes existing methods into three families based on their interactions with the target model: those that use only prior knowledge, those that use offline interactions, and those that learn from online interactions. We then introduce a generalized multi-turn formulation of the online method, unifying single-turn and multi-turn elicitation. We evaluate all three families of methods on automatically generating multi-turn test cases. We investigate the efficiency of these approaches by analyzing the trade-off between the query budget, i.e., the number of interactions with the target model, and the success rate, i.e., the discovery rate of behavior-eliciting inputs. We find that online methods can achieve an average success rate of 45/19/77% with just a few thousand queries over three tasks where static methods from existing multi-turn conversation benchmarks find few or even no failure cases. Our work highlights a novel application of behavior elicitation methods in multi-turn conversation evaluation and the need for the community to move towards dynamic benchmarks.

### 7. A Stepwise-Enhanced Reasoning Framework for Large Language Models Based on External Subgraph Generation

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Xin Zhang, Yang Cao, Baoxing Wu, Xinyi Chen, Kai Song, Siying Li
- **URL**: <http://arxiv.org/abs/2512.23356v1>
- **Submitted**: 2025-12-29 10:35:53
- **Topic Keywords**: query, rag
- **Reason**: This paper proposes a framework to enhance the reasoning capabilities of Large Language Models (LLMs) by leveraging external knowledge bases. While it touches on query understanding and semantic structure, its primary focus is on improving reasoning accuracy in LLMs, which is somewhat related to your interests in Information Retrieval and NLP, but not directly aligned with your core themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large Language Models (LLMs) have achieved strong performance across a wide range of natural language processing tasks in recent years, including machine translation, text generation, and question answering. As their applications extend to increasingly complex scenarios, however, LLMs continue to face challenges in tasks that require deep reasoning and logical inference. In particular, models trained on large scale textual corpora may incorporate noisy or irrelevant information during generation, which can lead to incorrect predictions or outputs that are inconsistent with factual knowledge. To address this limitation, we propose a stepwise reasoning enhancement framework for LLMs based on external subgraph generation, termed SGR. The proposed framework dynamically constructs query relevant subgraphs from external knowledge bases and leverages their semantic structure to guide the reasoning process. By performing reasoning in a step by step manner over structured subgraphs, SGR reduces the influence of noisy information and improves reasoning accuracy. Specifically, the framework first generates an external subgraph tailored to the input query, then guides the model to conduct multi step reasoning grounded in the subgraph, and finally integrates multiple reasoning paths to produce the final answer. Experimental results on multiple benchmark datasets demonstrate that SGR consistently outperforms strong baselines, indicating its effectiveness in enhancing the reasoning capabilities of LLMs.

### 8. Fine-Tuning LLMs with Fine-Grained Human Feedback on Text Spans

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Sky CH-Wang, Justin Svegliato, Helen Appel, Jason Eisner
- **URL**: <http://arxiv.org/abs/2512.23693v1>
- **Submitted**: 2025-12-29 18:51:56
- **Topic Keywords**: ranking, rank
- **Reason**: This paper explores fine-tuning language models with human feedback, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on preference supervision and text span feedback is not directly aligned with the user's core research themes, but still shows some relevance to the broader field of NLP and deep semantic understanding.

#### Abstract
> We present a method and dataset for fine-tuning language models with preference supervision using feedback-driven improvement chains. Given a model response, an annotator provides fine-grained feedback by marking ``liked'' and ``disliked'' spans and specifying what they liked or disliked about them. The base model then rewrites the disliked spans accordingly, proceeding from left to right, forming a sequence of incremental improvements. We construct preference pairs for direct alignment from each adjacent step in the chain, enabling the model to learn from localized, targeted edits. We find that our approach outperforms direct alignment methods based on standard A/B preference ranking or full contrastive rewrites, demonstrating that structured, revision-based supervision leads to more efficient and effective preference tuning.

### 9. Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Kongcheng Zhang, Qi Yao, Shunyu Liu, Wenjian Zhang, Min Cen, Yang Zhou, Wenkai Fang, Yiru Zhao, Baisheng Lai, Mingli Song
- **URL**: <http://arxiv.org/abs/2512.23457v1>
- **Submitted**: 2025-12-29 13:31:08
- **Topic Keywords**: rag
- **Reason**: The paper explores Reinforcement Learning for instruction following, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on Large Language Models and instruction following tasks is not directly aligned with the user's primary research interests in IR and Search technologies.

#### Abstract
> Reinforcement Learning (RL) has shown promise for aligning Large Language Models (LLMs) to follow instructions with various constraints. Despite the encouraging results, RL improvement inevitably relies on sampling successful, high-quality responses; however, the initial model often struggles to generate responses that satisfy all constraints due to its limited capabilities, yielding sparse or indistinguishable rewards that impede learning. In this work, we propose Hindsight instruction Replay (HiR), a novel sample-efficient RL framework for complex instruction following tasks, which employs a select-then-rewrite strategy to replay failed attempts as successes based on the constraints that have been satisfied in hindsight. We perform RL on these replayed samples as well as the original ones, theoretically framing the objective as dual-preference learning at both the instruction- and response-level to enable efficient optimization using only a binary reward signal. Extensive experiments demonstrate that the proposed HiR yields promising results across different instruction following tasks, while requiring less computational budget. Our code and dataset is available at https://github.com/sastpg/HIR.

### 10. C2PO: Diagnosing and Disentangling Bias Shortcuts in LLMs

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Xuan Feng, Bo An, Tianlong Gu, Liang Chang, Fengrui Hao, Peipeng Yu, Shuai Zhao
- **URL**: <http://arxiv.org/abs/2512.23430v1>
- **Submitted**: 2025-12-29 12:49:32
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and Large Language Models (LLMs), but it does not directly address query understanding, ranking models, or user behavior modeling in the context of information retrieval. The paper's focus on bias mitigation in LLMs is relevant, but it is not a central match for the user's research themes.

#### Abstract
> Bias in Large Language Models (LLMs) poses significant risks to trustworthiness, manifesting primarily as stereotypical biases (e.g., gender or racial stereotypes) and structural biases (e.g., lexical overlap or position preferences). However, prior paradigms typically address these in isolation, often mitigating one at the expense of exacerbating the other. To address this, we conduct a systematic exploration of these reasoning failures and identify a primary inducement: the latent spurious feature correlations within the input that drive these erroneous reasoning shortcuts. Driven by these findings, we introduce Causal-Contrastive Preference Optimization (C2PO), a unified alignment framework designed to tackle these specific failures by simultaneously discovering and suppressing these correlations directly within the optimization process. Specifically, C2PO leverages causal counterfactual signals to isolate bias-inducing features from valid reasoning paths, and employs a fairness-sensitive preference update mechanism to dynamically evaluate logit-level contributions and suppress shortcut features. Extensive experiments across multiple benchmarks covering stereotypical bias (BBQ, Unqover), structural bias (MNLI, HANS, Chatbot, MT-Bench), out-of-domain fairness (StereoSet, WinoBias), and general utility (MMLU, GSM8K) demonstrate that C2PO effectively mitigates stereotypical and structural biases while preserving robust general reasoning capabilities.

### 11. VL-RouterBench: A Benchmark for Vision-Language Model Routing

- **LLM Score**: 2
- **Keyword Score**: 9
- **Authors**: Zhehao Huang, Baijiong Lin, Jingyuan Zhang, Jingying Wang, Yuhang Liu, Ning Lu, Tao Li, Xiaolin Huang
- **URL**: <http://arxiv.org/abs/2512.23562v1>
- **Submitted**: 2025-12-29 16:01:19
- **Topic Keywords**: ranking, rag, rank, search, acl
- **Reason**: This paper focuses on vision-language model routing, which is not a core area of interest for you. While it does involve multimodal routing, the emphasis is on visual cues and textual structure, which is more related to computer vision and NLP rather than information retrieval and search technologies.

#### Abstract
> Multi-model routing has evolved from an engineering technique into essential infrastructure, yet existing work lacks a systematic, reproducible benchmark for evaluating vision-language models (VLMs). We present VL-RouterBench to assess the overall capability of VLM routing systems systematically. The benchmark is grounded in raw inference and scoring logs from VLMs and constructs quality and cost matrices over sample-model pairs. In scale, VL-RouterBench covers 14 datasets across 3 task groups, totaling 30,540 samples, and includes 15 open-source models and 2 API models, yielding 519,180 sample-model pairs and a total input-output token volume of 34,494,977. The evaluation protocol jointly measures average accuracy, average cost, and throughput, and builds a ranking score from the harmonic mean of normalized cost and accuracy to enable comparison across router configurations and cost budgets. On this benchmark, we evaluate 10 routing methods and baselines and observe a significant routability gain, while the best current routers still show a clear gap to the ideal Oracle, indicating considerable room for improvement in router architecture through finer visual cues and modeling of textual structure. We will open-source the complete data construction and evaluation toolchain to promote comparability, reproducibility, and practical deployment in multimodal routing research.

### 12. Chinese Morph Resolution in E-commerce Live Streaming Scenarios

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Jiahao Zhu, Jipeng Qiang, Ran Bai, Chenyu Liu, Xiaoye Ouyang
- **URL**: <http://arxiv.org/abs/2512.23280v1>
- **Submitted**: 2025-12-29 08:04:48
- **Topic Keywords**: rag, commerce, e-commerce, search
- **Reason**: This paper focuses on Chinese Morph Resolution in e-commerce live streaming, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves text-to-text generation, it's more related to language understanding and regulation in a specific domain, rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> E-commerce live streaming in China, particularly on platforms like Douyin, has become a major sales channel, but hosts often use morphs to evade scrutiny and engage in false advertising. This study introduces the Live Auditory Morph Resolution (LiveAMR) task to detect such violations. Unlike previous morph research focused on text-based evasion in social media and underground industries, LiveAMR targets pronunciation-based evasion in health and medical live streams. We constructed the first LiveAMR dataset with 86,790 samples and developed a method to transform the task into a text-to-text generation problem. By leveraging large language models (LLMs) to generate additional training data, we improved performance and demonstrated that morph resolution significantly enhances live streaming regulation.

### 13. TabiBERT: A Large-Scale ModernBERT Foundation Model and Unified Benchmarking Framework for Turkish

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Melik≈üah T√ºrker, A. Ebrar Kƒ±zƒ±loƒülu, Onur G√ºng√∂r, Susan √úsk√ºdarlƒ±
- **URL**: <http://arxiv.org/abs/2512.23065v1>
- **Submitted**: 2025-12-28 20:18:22
- **Comment**: 31 pages, 1 figure, 13 tables
- **Topic Keywords**: rag, retrieval, search
- **Reason**: This paper focuses on developing a Turkish language model, TabiBERT, which is a significant contribution to the field of NLP. However, it does not align with the user's primary research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling, which are not directly related to language model development or Turkish language-specific research.

#### Abstract
> Since the inception of BERT, encoder-only Transformers have evolved significantly in computational efficiency, training stability, and long-context modeling. ModernBERT consolidates these advances by integrating Rotary Positional Embeddings (RoPE), FlashAttention, and refined normalization. Despite these developments, Turkish NLP lacks a monolingual encoder trained from scratch incorporating such modern architectural paradigms. This work introduces TabiBERT, a monolingual Turkish encoder based on ModernBERT architecture trained from scratch on a large, curated corpus. TabiBERT is pre-trained on one trillion tokens sampled from an 84.88B token multi-domain corpus: web text (73%), scientific publications (20%), source code (6%), and mathematical content (0.3%). The model supports 8,192-token context length (16x original BERT), achieves up to 2.65x inference speedup, and reduces GPU memory consumption, enabling larger batch sizes. We introduce TabiBench with 28 datasets across eight task categories with standardized splits and protocols, evaluated using GLUE-style macro-averaging. TabiBERT attains 77.58 on TabiBench, outperforming BERTurk by 1.62 points and establishing state-of-the-art on five of eight categories: question answering (+9.55), code retrieval (+2.41), and document retrieval (+0.60). Compared with task-specific prior best results, including specialized models like TurkishBERTweet, TabiBERT achieves +1.47 average improvement, indicating robust cross-domain generalization. We release model weights, training configurations, and evaluation code for transparent, reproducible Turkish encoder research.

### 14. PROFASR-BENCH: A Benchmark for Context-Conditioned ASR in High-Stakes Professional Speech

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Deepak Babu Piskala
- **URL**: <http://arxiv.org/abs/2512.23686v1>
- **Submitted**: 2025-12-29 18:43:23
- **Comment**: Benchmark dataset and evaluation suite. Data and code available at: https://huggingface.co/datasets/prdeepakbabu/ProfASR-Bench https://github.com/prdeepakbabu/ProfASR-Bench
- **Topic Keywords**: rag, acl
- **Reason**: This paper focuses on Automatic Speech Recognition (ASR) in professional settings, which is not a primary area of interest for you. While it involves some aspects of deep semantic understanding, the context is not directly related to information retrieval, search technologies, or user behavior modeling, which are your core research themes.

#### Abstract
> Automatic Speech Recognition (ASR) in professional settings faces challenges that existing benchmarks underplay: dense domain terminology, formal register variation, and near-zero tolerance for critical entity errors. We present ProfASR-Bench, a professional-talk evaluation suite for high-stakes applications across finance, medicine, legal, and technology. Each example pairs a natural-language prompt (domain cue and/or speaker profile) with an entity-rich target utterance, enabling controlled measurement of context-conditioned recognition. The corpus supports conventional ASR metrics alongside entity-aware scores and slice-wise reporting by accent and gender. Using representative families Whisper (encoder-decoder ASR) and Qwen-Omni (audio language models) under matched no-context, profile, domain+profile, oracle, and adversarial conditions, we find a consistent pattern: lightweight textual context produces little to no change in average word error rate (WER), even with oracle prompts, and adversarial prompts do not reliably degrade performance. We term this the context-utilization gap (CUG): current systems are nominally promptable yet underuse readily available side information. ProfASR-Bench provides a standardized context ladder, entity- and slice-aware reporting with confidence intervals, and a reproducible testbed for comparing fusion strategies across model families.
  Dataset: https://huggingface.co/datasets/prdeepakbabu/ProfASR-Bench
  Code: https://github.com/prdeepakbabu/ProfASR-Bench

### 15. Training AI Co-Scientists Using Rubric Rewards

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Shashwat Goel, Rishi Hazra, Dulhan Jayalath, Timon Willi, Parag Jain, William F. Shen, Ilias Leontiadis, Francesco Barbieri, Yoram Bachrach, Jonas Geiping, Chenxi Whitehouse
- **URL**: <http://arxiv.org/abs/2512.23707v1>
- **Submitted**: 2025-12-29 18:59:33
- **Comment**: 11 pages in the main paper, total 119 including sample outputs in the Appendix
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on training AI co-scientists for research plan generation, leveraging reinforcement learning and self-grading. While it involves natural language processing and model training, it does not directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> AI co-scientists are emerging as a tool to assist human researchers in achieving their research goals. A crucial feature of these AI co-scientists is the ability to generate a research plan given a set of aims and constraints. The plan may be used by researchers for brainstorming, or may even be implemented after further refinement. However, language models currently struggle to generate research plans that follow all constraints and implicit requirements. In this work, we study how to leverage the vast corpus of existing research papers to train language models that generate better research plans. We build a scalable, diverse training corpus by automatically extracting research goals and goal-specific grading rubrics from papers across several domains. We then train models for research plan generation via reinforcement learning with self-grading. A frozen copy of the initial policy acts as the grader during training, with the rubrics creating a generator-verifier gap that enables improvements without external human supervision. To validate this approach, we conduct a study with human experts for machine learning research goals, spanning 225 hours. The experts prefer plans generated by our finetuned Qwen3-30B-A3B model over the initial model for 70% of research goals, and approve 84% of the automatically extracted goal-specific grading rubrics. To assess generality, we also extend our approach to research goals from medical papers, and new arXiv preprints, evaluating with a jury of frontier models. Our finetuning yields 12-22% relative improvements and significant cross-domain generalization, proving effective even in problem settings like medical research where execution feedback is infeasible. Together, these findings demonstrate the potential of a scalable, automated training recipe as a step towards improving general AI co-scientists.

### 16. AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jiafeng Liang, Hao Li, Chang Li, Jiaqi Zhou, Shixin Jiang, Zekun Wang, Changkai Ji, Zhihao Zhu, Runxuan Liu, Tao Ren, Jinlan Fu, See-Kiong Ng, Xia Liang, Ming Liu, Bing Qin
- **URL**: <http://arxiv.org/abs/2512.23343v1>
- **Submitted**: 2025-12-29 10:01:32
- **Comment**: 57 pages, 5 figures
- **Topic Keywords**: rag, search
- **Reason**: This paper appears to be primarily focused on the intersection of cognitive neuroscience and artificial intelligence, with a focus on memory systems. While it touches on the concept of autonomous agents, which may be tangentially related to information retrieval, the paper's core themes and methodologies do not align closely with the user's research interests in IR, query understanding, ranking models, and user behavior modeling.

#### Abstract
> Memory serves as the pivotal nexus bridging past and future, providing both humans and AI systems with invaluable concepts and experience to navigate complex tasks. Recent research on autonomous agents has increasingly focused on designing efficient memory workflows by drawing on cognitive neuroscience. However, constrained by interdisciplinary barriers, existing works struggle to assimilate the essence of human memory mechanisms. To bridge this gap, we systematically synthesizes interdisciplinary knowledge of memory, connecting insights from cognitive neuroscience with LLM-driven agents. Specifically, we first elucidate the definition and function of memory along a progressive trajectory from cognitive neuroscience through LLMs to agents. We then provide a comparative analysis of memory taxonomy, storage mechanisms, and the complete management lifecycle from both biological and artificial perspectives. Subsequently, we review the mainstream benchmarks for evaluating agent memory. Additionally, we explore memory security from dual perspectives of attack and defense. Finally, we envision future research directions, with a focus on multimodal memory systems and skill acquisition.

### 17. Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Dianyun Wang, Qingsen Ma, Yuhu Shang, Zhifeng Lu, Lechen Ning, Zhenbo Xu, Huijia Wu, Zhaofeng He
- **URL**: <http://arxiv.org/abs/2512.23260v1>
- **Submitted**: 2025-12-29 07:39:49
- **Topic Keywords**: rag, rank
- **Reason**: This paper focuses on low-rank adaptation methods for fine-tuning large language models, which is not directly related to your core research themes in Information Retrieval and Search technologies. While it touches on aspects of model adaptation, it lacks relevance to your specific interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Parameter-efficient fine-tuning has become the dominant paradigm for adapting large language models to downstream tasks. Low-rank adaptation methods such as LoRA operate under the assumption that task-relevant weight updates reside in a low-rank subspace, yet this subspace is learned implicitly from data in a black-box manner, offering no interpretability or direct control. We hypothesize that this difficulty stems from polysemanticity--individual dimensions encoding multiple entangled concepts. To address this, we leverage pre-trained Sparse Autoencoders (SAEs) to identify task-relevant features in a disentangled feature space, then construct an explicit, interpretable low-rank subspace to guide adapter initialization. We provide theoretical analysis proving that under monosemanticity assumptions, SAE-based subspace identification achieves arbitrarily small recovery error, while direct identification in polysemantic space suffers an irreducible error floor. On safety alignment, our method achieves up to 99.6% safety rate--exceeding full fine-tuning by 7.4 percentage points and approaching RLHF-based methods--while updating only 0.19-0.24% of parameters. Crucially, our method provides interpretable insights into the learned alignment subspace through the semantic grounding of SAE features. Our work demonstrates that incorporating mechanistic interpretability into the fine-tuning process can simultaneously improve both performance and transparency.

### 18. Close the Loop: Synthesizing Infinite Tool-Use Data via Multi-Agent Role-Playing

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yuwen Li, Wei Zhang, Zelong Huang, Mason Yang, Jiajun Wu, Shawn Guo, Huahao Hu, Lingyi Sun, Jian Yang, Mingjie Tang, Byran Dai
- **URL**: <http://arxiv.org/abs/2512.23611v1>
- **Submitted**: 2025-12-29 17:12:39
- **Topic Keywords**: rag
- **Reason**: This paper appears to be unrelated to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on Large Language Models, tool invocation, and multi-agent synthesis does not align with your areas of expertise.

#### Abstract
> Enabling Large Language Models (LLMs) to reliably invoke external tools remains a critical bottleneck for autonomous agents. Existing approaches suffer from three fundamental challenges: expensive human annotation for high-quality trajectories, poor generalization to unseen tools, and quality ceilings inherent in single-model synthesis that perpetuate biases and coverage gaps. We introduce InfTool, a fully autonomous framework that breaks these barriers through self-evolving multi-agent synthesis. Given only raw API specifications, InfTool orchestrates three collaborative agents (User Simulator, Tool-Calling Assistant, and MCP Server) to generate diverse, verified trajectories spanning single-turn calls to complex multi-step workflows. The framework establishes a closed loop: synthesized data trains the model via Group Relative Policy Optimization (GRPO) with gated rewards, the improved model generates higher-quality data targeting capability gaps, and this cycle iterates without human intervention. Experiments on the Berkeley Function-Calling Leaderboard (BFCL) demonstrate that InfTool transforms a base 32B model from 19.8% to 70.9% accuracy (+258%), surpassing models 10x larger and rivaling Claude-Opus, and entirely from synthetic data without human annotation.

### 19. Automatic Detection of Complex Quotation Patterns in Aggadic Literature

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Hadar Miller, Tsvi Kuflik, Moshe Lavee
- **URL**: <http://arxiv.org/abs/2512.23504v1>
- **Submitted**: 2025-12-29 14:45:58
- **Comment**: This paper is under review at Cogent Arts & Humanities
- **Topic Keywords**: rag
- **Reason**: This paper focuses on detecting biblical quotations in Rabbinic literature using a novel algorithm, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves text analysis and pattern detection, the context and application are not relevant to the user's interests in query understanding, ranking models, or user behavior modeling.

#### Abstract
> This paper presents ACT (Allocate Connections between Texts), a novel three-stage algorithm for the automatic detection of biblical quotations in Rabbinic literature. Unlike existing text reuse frameworks that struggle with short, paraphrased, or structurally embedded quotations, ACT combines a morphology-aware alignment algorithm with a context-sensitive enrichment stage that identifies complex citation patterns such as "Wave" and "Echo" quotations.
  Our approach was evaluated against leading systems, including Dicta, Passim, Text-Matcher, as well as human-annotated critical editions. We further assessed three ACT configurations to isolate the contribution of each component. Results demonstrate that the full ACT pipeline (ACT-QE) outperforms all baselines, achieving an F1 score of 0.91, with superior Recall (0.89) and Precision (0.94). Notably, ACT-2, which lacks stylistic enrichment, achieves higher Recall (0.90) but suffers in Precision, while ACT-3, using longer n-grams, offers a tradeoff between coverage and specificity.
  In addition to improving quotation detection, ACT's ability to classify stylistic patterns across corpora opens new avenues for genre classification and intertextual analysis. This work contributes to digital humanities and computational philology by addressing the methodological gap between exhaustive machine-based detection and human editorial judgment. ACT lays a foundation for broader applications in historical textual analysis, especially in morphologically rich and citation-dense traditions like Aggadic literature.

### 20. AI4Reading: Chinese Audiobook Interpretation System Based on Multi-Agent Collaboration

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Minjiang Huang, Jipeng Qiang, Yi Zhu, Chaowei Zhang, Xiangyu Zhao, Kui Yu
- **URL**: <http://arxiv.org/abs/2512.23300v1>
- **Submitted**: 2025-12-29 08:41:54
- **Comment**: ACL 2025 demo
- **Topic Keywords**: rag
- **Reason**: This paper focuses on a Chinese audiobook interpretation system, which, although related to information retrieval and NLP, does not align with the user's core research themes of query understanding, ranking models, and user behavior modeling. The paper's emphasis on speech synthesis and multi-agent collaboration is also not directly relevant to the user's interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> Audiobook interpretations are attracting increasing attention, as they provide accessible and in-depth analyses of books that offer readers practical insights and intellectual inspiration. However, their manual creation process remains time-consuming and resource-intensive. To address this challenge, we propose AI4Reading, a multi-agent collaboration system leveraging large language models (LLMs) and speech synthesis technology to generate podcast, like audiobook interpretations. The system is designed to meet three key objectives: accurate content preservation, enhanced comprehensibility, and a logical narrative structure. To achieve these goals, we develop a framework composed of 11 specialized agents,including topic analysts, case analysts, editors, a narrator, and proofreaders that work in concert to explore themes, extract real world cases, refine content organization, and synthesize natural spoken language. By comparing expert interpretations with our system's output, the results show that although AI4Reading still has a gap in speech generation quality, the generated interpretative scripts are simpler and more accurate.

### 21. Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Panagiotis Theocharopoulos, Ajinkya Kulkarni, Mathew Magimai. -Doss
- **URL**: <http://arxiv.org/abs/2512.23684v1>
- **Submitted**: 2025-12-29 18:43:05
- **Topic Keywords**: icml
- **Reason**: This paper appears to be primarily focused on the security and vulnerability of Large Language Models (LLMs) in academic peer review, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on the use of LLMs, it does not explore query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's interests.

#### Abstract
> Large language models (LLMs) are increasingly considered for use in high-impact workflows, including academic peer review. However, LLMs are vulnerable to document-level hidden prompt injection attacks. In this work, we construct a dataset of approximately 500 real academic papers accepted to ICML and evaluate the effect of embedding hidden adversarial prompts within these documents. Each paper is injected with semantically equivalent instructions in four different languages and reviewed using an LLM. We find that prompt injection induces substantial changes in review scores and accept/reject decisions for English, Japanese, and Chinese injections, while Arabic injections produce little to no effect. These results highlight the susceptibility of LLM-based reviewing systems to document-level prompt injection and reveal notable differences in vulnerability across languages.

### 22. Less is more: Probabilistic reduction is best explained by small-scale predictability measures

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Cassandra L. Jacobs, Andr√©s Bux√≥-Lugo, Anna K. Taylor, Marie Leopold-Hooke
- **URL**: <http://arxiv.org/abs/2512.23659v1>
- **Submitted**: 2025-12-29 18:12:37
- **Topic Keywords**: search
- **Reason**: This paper appears to be more focused on the relationship between language model probabilities and cognitive phenomena, which doesn't seem to align closely with your research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on probabilistic aspects, it doesn't seem to relate to your specific areas of interest such as query understanding, ranking models, or user behavior modeling.

#### Abstract
> The primary research questions of this paper center on defining the amount of context that is necessary and/or appropriate when investigating the relationship between language model probabilities and cognitive phenomena. We investigate whether whole utterances are necessary to observe probabilistic reduction and demonstrate that n-gram representations suffice as cognitive units of planning.

### 23. Anka: A Domain-Specific Language for Reliable LLM Code Generation

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Saif Khalfan Saif Al Mazrouei
- **URL**: <http://arxiv.org/abs/2512.23214v1>
- **Submitted**: 2025-12-29 05:28:17
- **Comment**: 11 pages, 1 figure, 4 tables. Code and benchmarks available at https://github.com/BleBlo/Anka
- **Topic Keywords**: search
- **Reason**: This paper focuses on Large Language Models (LLMs) and code generation, which is not a primary area of interest for you. While it touches on the concept of constrained syntax, it doesn't directly relate to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation, yet they exhibit systematic errors on complex, multi-step programming tasks. We hypothesize that these errors stem from the flexibility of general-purpose languages, which permits multiple valid approaches and requires implicit state management. To test this hypothesis, we introduce Anka, a domain-specific language (DSL) for data transformation pipelines designed with explicit, constrained syntax that reduces ambiguity in code generation. Despite having zero prior training exposure to Anka, Claude 3.5 Haiku achieves 99.9% parse success and 95.8% overall task accuracy across 100 benchmark problems. Critically, Anka demonstrates a 40 percentage point accuracy advantage over Python on multi-step pipeline tasks (100% vs. 60%), where Python's flexible syntax leads to frequent errors in operation sequencing and variable management. Cross-model validation with GPT-4o-mini confirms this advantage (+26.7 percentage points on multi-step tasks). Our results demonstrate that: (1) LLMs can learn novel DSLs entirely from in-context prompts, achieving near-native accuracy; (2) constrained syntax significantly reduces errors on complex tasks; and (3) domain-specific languages purposefully designed for LLM generation can outperform general-purpose languages on which the LLM has extensive training. We release the complete language implementation, benchmark suite, and evaluation framework to facilitate further research.

### 24. Scalable Residual Feature Aggregation Framework with Hybrid Metaheuristic Optimization for Robust Early Pancreatic Neoplasm Detection in Multimodal CT Imaging

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Janani Annur Thiruvengadam, Kiran Mayee Nabigaru, Anusha Kovi
- **URL**: <http://arxiv.org/abs/2512.23597v1>
- **Submitted**: 2025-12-29 16:51:13
- **Topic Keywords**: rag
- **Reason**: This paper is unrelated to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, and data mining. The paper focuses on medical imaging and deep learning for early detection of pancreatic neoplasm, which is outside your areas of expertise.

#### Abstract
> The early detection of pancreatic neoplasm is a major clinical dilemma, and it is predominantly so because tumors are likely to occur with minimal contrast margins and a large spread anatomy-wide variation amongst patients on a CT scan. These complexities require to be addressed with an effective and scalable system that can assist in enhancing the salience of the subtle visual cues and provide a high level of the generalization on the multimodal imaging data. A Scalable Residual Feature Aggregation (SRFA) framework is proposed to be used to meet these conditions in this study. The framework integrates a pipeline of preprocessing followed by the segmentation using the MAGRes-UNet that is effective in making the pancreatic structures and isolating regions of interest more visible. DenseNet-121 performed with residual feature storage is used to extract features to allow deep hierarchical features to be aggregated without properties loss. To go further, hybrid HHO-BA metaheuristic feature selection strategy is used, which guarantees the best feature subset refinement. To be classified, the system is trained based on a new hybrid model that integrates the ability to pay attention on the world, which is the Vision Transformer (ViT) with the high representational efficiency of EfficientNet-B3. A dual optimization mechanism incorporating SSA and GWO is used to fine-tune hyperparameters to enhance greater robustness and less overfitting. Experimental results support the significant improvement in performance, with the suggested model reaching 96.23% accuracy, 95.58% F1-score and 94.83% specificity, the model is significantly better than the traditional CNNs and contemporary transformer-based models. Such results highlight the possibility of the SRFA framework as a useful instrument in the early detection of pancreatic tumors.

---

