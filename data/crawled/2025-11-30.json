[
    {
        "title": "ThetaEvolve: Test-time Learning on Open Problems",
        "abstract": "Recent advances in large language models (LLMs) have enabled breakthroughs in mathematical discovery, exemplified by AlphaEvolve, a closed-source system that evolves programs to improve bounds on open problems. However, it relies on ensembles of frontier LLMs to achieve new bounds and is a pure inference system that models cannot internalize the evolving strategies. We introduce ThetaEvolve, an open-source framework that simplifies and extends AlphaEvolve to efficiently scale both in-context learning and Reinforcement Learning (RL) at test time, allowing models to continually learn from their experiences in improving open optimization problems. ThetaEvolve features a single LLM, a large program database for enhanced exploration, batch sampling for higher throughput, lazy penalties to discourage stagnant outputs, and optional reward shaping for stable training signals, etc. ThetaEvolve is the first evolving framework that enable a small open-source model, like DeepSeek-R1-0528-Qwen3-8B, to achieve new best-known bounds on open problems (circle packing and first auto-correlation inequality) mentioned in AlphaEvolve. Besides, across two models and four open tasks, we find that ThetaEvolve with RL at test-time consistently outperforms inference-only baselines, and the model indeed learns evolving capabilities, as the RL-trained checkpoints demonstrate faster progress and better final performance on both trained target task and other unseen tasks. We release our code publicly: https://github.com/ypwang61/ThetaEvolve",
        "url": "http://arxiv.org/abs/2511.23473v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23473v1",
        "arxiv_id": "2511.23473v1",
        "authors": [
            "Yiping Wang",
            "Shao-Rong Su",
            "Zhiyuan Zeng",
            "Eva Xu",
            "Liliang Ren",
            "Xinyu Yang",
            "Zeyi Huang",
            "Xuehai He",
            "Luyao Ma",
            "Baolin Peng",
            "Hao Cheng",
            "Pengcheng He",
            "Weizhu Chen",
            "Shuohang Wang",
            "Simon Shaolei Du",
            "Yelong Shen"
        ],
        "submitted": "2025-11-28 18:58:14",
        "source": "arxiv",
        "comment": "30 pages, link: https://github.com/ypwang61/ThetaEvolve"
    },
    {
        "title": "MegaChat: A Synthetic Persian Q&A Dataset for High-Quality Sales Chatbot Evaluation",
        "abstract": "Small and medium-sized enterprises (SMEs) in Iran increasingly leverage Telegram for sales, where real-time engagement is essential for conversion. However, developing AI-driven chatbots for this purpose requires large, high-quality question-and-answer (Q&A) datasets, which are typically expensive and resource-intensive to produce, especially for low-resource languages like Persian. In this paper, we introduce MegaChat, the first fully synthetic Persian Q&A dataset designed to evaluate intelligent sales chatbots in Telegram-based e-commerce. We propose a novel, automated multi-agent architecture that generates persona-aware Q&A pairs by collecting data from active Telegram shopping channels. The system employs specialized agents for question generation, validation, and refinement, ensuring the production of realistic and diverse conversational data. To evaluate answer generation, we compare three classic retrieval-augmented generation (RAG) models with our advanced agentic system, which features multi-query retrieval, reranking, and persona-aligned response synthesis. Using GPT-5.1 for evaluation across six quality dimensions, our results show that the agentic architecture outperformed traditional RAG models in 4 out of 5 diverse channels, demonstrating its ability to generate scalable, high-quality datasets without relying on expensive human annotation or complex fine-tuning. MegaChat provides SMEs with an efficient, cost-effective solution for building intelligent customer engagement systems in specialized commercial domains, enabling advancements in multilingual conversational AI for low-resource languages. Download: https://github.com/MegaChat-Tech/MegaChat-DataSet",
        "url": "http://arxiv.org/abs/2511.23397v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23397v1",
        "arxiv_id": "2511.23397v1",
        "authors": [
            "Mahdi Rahmani",
            "AmirHossein Saffari",
            "Reyhane Rahmani"
        ],
        "submitted": "2025-11-28 17:44:20",
        "source": "arxiv",
        "comment": "6 pages, 11 figures, 2 tables"
    },
    {
        "title": "Ambiguity Awareness Optimization: Towards Semantic Disambiguation for Direct Preference Optimization",
        "abstract": "Direct Preference Optimization (DPO) is a widely used reinforcement learning from human feedback (RLHF) method across various domains. Recent research has increasingly focused on the role of token importance in improving DPO effectiveness. It is observed that identical or semantically similar content (defined as ambiguous content) frequently appears within the preference pairs. We hypothesize that the presence of ambiguous content during DPO training may introduce ambiguity, thereby limiting further improvements in alignment. Through mathematical analysis and proof-of-concept experiments, we reveal that ambiguous content may potentially introduce ambiguities, thereby degrading performance. To address this issue, we introduce Ambiguity Awareness Optimization (AAO), a simple yet effective approach that automatically re-weights ambiguous content to reduce ambiguities by calculating semantic similarity from preference pairs. Through extensive experiments, we demonstrate that AAO consistently and significantly surpasses state-of-the-art approaches in performance, without markedly increasing response length, across multiple model scales and widely adopted benchmark datasets, including AlpacaEval 2, MT-Bench, and Arena-Hard. Specifically, AAO outperforms DPO by up to 8.9 points on AlpacaEval 2 and achieves an improvement of by up to 15.0 points on Arena-Hard.",
        "url": "http://arxiv.org/abs/2511.23391v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23391v1",
        "arxiv_id": "2511.23391v1",
        "authors": [
            "Jian Li",
            "Shenglin Yin",
            "Yujia Zhang",
            "Alan Zhao",
            "Xi Chen",
            "Xiaohui Zhou",
            "Pengfei Xu"
        ],
        "submitted": "2025-11-28 17:32:54",
        "source": "arxiv",
        "comment": "Accepted at EMNLP 2025 main"
    },
    {
        "title": "Is Passive Expertise-Based Personalization Enough? A Case Study in AI-Assisted Test-Taking",
        "abstract": "Novice and expert users have different systematic preferences in task-oriented dialogues. However, whether catering to these preferences actually improves user experience and task performance remains understudied. To investigate the effects of expertise-based personalization, we first built a version of an enterprise AI assistant with passive personalization. We then conducted a user study where participants completed timed exams, aided by the two versions of the AI assistant. Preliminary results indicate that passive personalization helps reduce task load and improve assistant perception, but reveal task-specific limitations that can be addressed through providing more user agency. These findings underscore the importance of combining active and passive personalization to optimize user experience and effectiveness in enterprise task-oriented environments.",
        "url": "http://arxiv.org/abs/2511.23376v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23376v1",
        "arxiv_id": "2511.23376v1",
        "authors": [
            "Li Siyan",
            "Jason Zhang",
            "Akash Maharaj",
            "Yuanming Shi",
            "Yunyao Li"
        ],
        "submitted": "2025-11-28 17:21:41",
        "source": "arxiv",
        "comment": "Accepted into Tailoring AI: Exploring Active and Passive LLM Personalization (PALS) workshop at EMNLP 2025"
    },
    {
        "title": "Optimizing Multimodal Language Models through Attention-based Interpretability",
        "abstract": "Modern large language models become multimodal, analyzing various data formats like text and images. While fine-tuning is effective for adapting these multimodal language models (MLMs) to downstream tasks, full fine-tuning is computationally expensive. Parameter-Efficient Fine-Tuning (PEFT) methods address this by training only a small portion of model weights. However, MLMs are difficult to interpret, making it challenging to identify which components are most effective for training to balance efficiency and performance. We propose an attention-based interpretability method for MLMs by analyzing attention scores relative to image tokens. The core idea is to identify attention heads that focus on image key objects. We utilize this information to select optimal model components for PEFT in multimodal models. Our contributions include a method for identifying attention heads associated with image key objects, its application to PEFT for image captioning, and the creation of a new dataset containing images, key object masks, and their textual descriptions. We conducted experiments on MLMs with 2-3 billion parameters to validate the method's effectiveness. By calculating Head Impact (HI) scores we quantify an attention head's focus on key objects, indicating its significance in image understanding. Our fine-tuning experiments demonstrate that adapting layers with the highest HI scores leads to the most significant shifts in metrics compared to pre-trained, randomly selected, or lowest-HI-score layers. This indicates that fine-tuning a small percentage (around 0.01%) of parameters in these crucial layers can substantially influence image understanding capabilities.",
        "url": "http://arxiv.org/abs/2511.23375v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23375v1",
        "arxiv_id": "2511.23375v1",
        "authors": [
            "Alexander Sergeev",
            "Evgeny Kotelnikov"
        ],
        "submitted": "2025-11-28 17:21:31",
        "source": "arxiv",
        "comment": "Accepted for ICAI-2025 conference"
    },
    {
        "title": "Scaling HuBERT for African Languages: From Base to Large and XL",
        "abstract": "Despite recent progress in multilingual speech processing, African languages remain under-represented in both research and deployed systems, particularly when it comes to strong, open-weight encoders that transfer well under low-resource supervision. Self-supervised learning has proven especially promising in such settings, yet most publicly released models targeting African speech remain at BASE scale, leaving unanswered whether larger encoders, trained exclusively on Africa-centric audio, offer tangible benefits and how model capacity interacts with data composition. This work addresses that gap by introducing SSA-HuBERT-Large (317M parameters) and SSA-HuBERT-XL (964M parameters), the first large models trained solely on African speech, alongside a BASE size counterpart. We release these models as open weights: see https://huggingface.co/collections/Orange/african-speech-foundation-models. By conducting a carefully controlled experimental study focused exclusively on Sub-Saharan languages, covering automatic speech recognition (ASR) and language identification (LID) tasks, we demonstrate that larger architectures significantly improve performance by effectively leveraging large audio datasets.",
        "url": "http://arxiv.org/abs/2511.23370v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23370v1",
        "arxiv_id": "2511.23370v1",
        "authors": [
            "Antoine Caubrière",
            "Elodie Gauthier"
        ],
        "submitted": "2025-11-28 17:17:40",
        "source": "arxiv",
        "comment": "Journée d'études AFIA-ATALA 2025 : Technologies linguistiques pour les langues peu dotées"
    },
    {
        "title": "Towards Improving Interpretability of Language Model Generation through a Structured Knowledge Discovery Approach",
        "abstract": "Knowledge-enhanced text generation aims to enhance the quality of generated text by utilizing internal or external knowledge sources. While language models have demonstrated impressive capabilities in generating coherent and fluent text, the lack of interpretability presents a substantial obstacle. The limited interpretability of generated text significantly impacts its practical usability, particularly in knowledge-enhanced text generation tasks that necessitate reliability and explainability. Existing methods often employ domain-specific knowledge retrievers that are tailored to specific data characteristics, limiting their generalizability to diverse data types and tasks. To overcome this limitation, we directly leverage the two-tier architecture of structured knowledge, consisting of high-level entities and low-level knowledge triples, to design our task-agnostic structured knowledge hunter. Specifically, we employ a local-global interaction scheme for structured knowledge representation learning and a hierarchical transformer-based pointer network as the backbone for selecting relevant knowledge triples and entities. By combining the strong generative ability of language models with the high faithfulness of the knowledge hunter, our model achieves high interpretability, enabling users to comprehend the model output generation process. Furthermore, we empirically demonstrate the effectiveness of our model in both internal knowledge-enhanced table-to-text generation on the RotoWireFG dataset and external knowledge-enhanced dialogue response generation on the KdConv dataset. Our task-agnostic model outperforms state-of-the-art methods and corresponding language models, setting new standards on the benchmark.",
        "url": "http://arxiv.org/abs/2511.23335v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23335v1",
        "arxiv_id": "2511.23335v1",
        "authors": [
            "Shuqi Liu",
            "Han Wu",
            "Guanzhi Deng",
            "Jianshu Chen",
            "Xiaoyang Wang",
            "Linqi Song"
        ],
        "submitted": "2025-11-28 16:43:46",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Tackling a Challenging Corpus for Early Detection of Gambling Disorder: UNSL at MentalRiskES 2025",
        "abstract": "Gambling disorder is a complex behavioral addiction that is challenging to understand and address, with severe physical, psychological, and social consequences. Early Risk Detection (ERD) on the Web has become a key task in the scientific community for identifying early signs of mental health behaviors based on social media activity. This work presents our participation in the MentalRiskES 2025 challenge, specifically in Task 1, aimed at classifying users at high or low risk of developing a gambling-related disorder. We proposed three methods based on a CPI+DMC approach, addressing predictive effectiveness and decision-making speed as independent objectives. The components were implemented using the SS3, BERT with extended vocabulary, and SBERT models, followed by decision policies based on historical user analysis. Although it was a challenging corpus, two of our proposals achieved the top two positions in the official results, performing notably in decision metrics. Further analysis revealed some difficulty in distinguishing between users at high and low risk, reinforcing the need to explore strategies to improve data interpretation and quality, and to promote more transparent and reliable ERD systems for mental disorders.",
        "url": "http://arxiv.org/abs/2511.23325v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23325v1",
        "arxiv_id": "2511.23325v1",
        "authors": [
            "Horacio Thompson",
            "Marcelo Errecalde"
        ],
        "submitted": "2025-11-28 16:26:00",
        "source": "arxiv",
        "comment": "In Iberian Language Evaluation Forum (IberLEF 2025), Zaragoza, Spain"
    },
    {
        "title": "Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models",
        "abstract": "This work explores the challenge of building ``Machines that Can Remember'', framing long-term memory as the problem of efficient ultra-long context modeling. We argue that this requires three key properties: \\textbf{sparsity}, \\textbf{random-access flexibility}, and \\textbf{length generalization}. To address ultra-long-context modeling, we leverage Hierarchical Sparse Attention (HSA), a novel attention mechanism that satisfies all three properties. We integrate HSA into Transformers to build HSA-UltraLong, which is an 8B-parameter MoE model trained on over 8 trillion tokens and is rigorously evaluated on different tasks with in-domain and out-of-domain context lengths to demonstrate its capability in handling ultra-long contexts. Results show that our model performs comparably to full-attention baselines on in-domain lengths while achieving over 90\\% accuracy on most in-context retrieval tasks with contexts up to 16M. This report outlines our experimental insights and open problems, contributing a foundation for future research in ultra-long context modeling.",
        "url": "http://arxiv.org/abs/2511.23319v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23319v1",
        "arxiv_id": "2511.23319v1",
        "authors": [
            "Xiang Hu",
            "Zhanchao Zhou",
            "Ruiqi Liang",
            "Zehuan Li",
            "Wei Wu",
            "Jianguo Li"
        ],
        "submitted": "2025-11-28 16:17:53",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Do LLM-judges Align with Human Relevance in Cranfield-style Recommender Evaluation?",
        "abstract": "Evaluating recommender systems remains a long-standing challenge, as offline methods based on historical user interactions and train-test splits often yield unstable and inconsistent results due to exposure bias, popularity bias, sampled evaluations, and missing-not-at-random patterns. In contrast, textual document retrieval benefits from robust, standardized evaluation via Cranfield-style test collections, which combine pooled relevance judgments with controlled setups. While recent work shows that adapting this methodology to recommender systems is feasible, constructing such collections remains costly due to the need for manual relevance judgments, thus limiting scalability. This paper investigates whether Large Language Models (LLMs) can serve as reliable automatic judges to address these scalability challenges. Using the ML-32M-ext Cranfield-style movie recommendation collection, we first examine the limitations of existing evaluation methodologies. Then we explore the alignment and the recommender systems ranking agreement between the LLM-judge and human provided relevance labels. We find that incorporating richer item metadata and longer user histories improves alignment, and that LLM-judge yields high agreement with human-based rankings (Kendall's tau = 0.87). Finally, an industrial case study in the podcast recommendation domain demonstrates the practical value of LLM-judge for model selection. Overall, our results show that LLM-judge is a viable and scalable approach for evaluating recommender systems.",
        "url": "http://arxiv.org/abs/2511.23312v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23312v1",
        "arxiv_id": "2511.23312v1",
        "authors": [
            "Gustavo Penha",
            "Aleksandr V. Petrov",
            "Claudia Hauff",
            "Enrico Palumbo",
            "Ali Vardasbi",
            "Edoardo D'Amico",
            "Francesco Fabbri",
            "Alice Wang",
            "Praveen Chandar",
            "Henrik Lindstrom",
            "Hugues Bouchard",
            "Mounia Lalmas"
        ],
        "submitted": "2025-11-28 16:10:39",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Toward Automatic Safe Driving Instruction: A Large-Scale Vision Language Model Approach",
        "abstract": "Large-scale Vision Language Models (LVLMs) exhibit advanced capabilities in tasks that require visual information, including object detection. These capabilities have promising applications in various industrial domains, such as autonomous driving. For example, LVLMs can generate safety-oriented descriptions of videos captured by road-facing cameras. However, ensuring comprehensive safety requires monitoring driver-facing views as well to detect risky events, such as the use of mobiles while driving. Thus, the ability to process synchronized inputs is necessary from both driver-facing and road-facing cameras. In this study, we develop models and investigate the capabilities of LVLMs by constructing a dataset and evaluating their performance on this dataset. Our experimental results demonstrate that while pre-trained LVLMs have limited effectiveness, fine-tuned LVLMs can generate accurate and safety-aware driving instructions. Nonetheless, several challenges remain, particularly in detecting subtle or complex events in the video. Our findings and error analysis provide valuable insights that can contribute to the improvement of LVLM-based systems in this domain.",
        "url": "http://arxiv.org/abs/2511.23311v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23311v1",
        "arxiv_id": "2511.23311v1",
        "authors": [
            "Haruki Sakajo",
            "Hiroshi Takato",
            "Hiroshi Tsutsui",
            "Komei Soda",
            "Hidetaka Kamigaito",
            "Taro Watanabe"
        ],
        "submitted": "2025-11-28 16:09:36",
        "source": "arxiv",
        "comment": "Accepted to MMLoSo 2025"
    },
    {
        "title": "Transformer-Driven Triple Fusion Framework for Enhanced Multimodal Author Intent Classification in Low-Resource Bangla",
        "abstract": "The expansion of the Internet and social networks has led to an explosion of user-generated content. Author intent understanding plays a crucial role in interpreting social media content. This paper addresses author intent classification in Bangla social media posts by leveraging both textual and visual data. Recognizing limitations in previous unimodal approaches, we systematically benchmark transformer-based language models (mBERT, DistilBERT, XLM-RoBERTa) and vision architectures (ViT, Swin, SwiftFormer, ResNet, DenseNet, MobileNet), utilizing the Uddessho dataset of 3,048 posts spanning six practical intent categories. We introduce a novel intermediate fusion strategy that significantly outperforms early and late fusion on this task. Experimental results show that intermediate fusion, particularly with mBERT and Swin Transformer, achieves 84.11% macro-F1 score, establishing a new state-of-the-art with an 8.4 percentage-point improvement over prior Bangla multimodal approaches. Our analysis demonstrates that integrating visual context substantially enhances intent classification. Cross-modal feature integration at intermediate levels provides optimal balance between modality-specific representation and cross-modal learning. This research establishes new benchmarks and methodological standards for Bangla and other low-resource languages. We call our proposed framework BangACMM (Bangla Author Content MultiModal).",
        "url": "http://arxiv.org/abs/2511.23287v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23287v1",
        "arxiv_id": "2511.23287v1",
        "authors": [
            "Ariful Islam",
            "Tanvir Mahmud",
            "Md Rifat Hossen"
        ],
        "submitted": "2025-11-28 15:44:42",
        "source": "arxiv",
        "comment": "Accepted at the 28th International Conference on Computer and Information Technology (ICCIT 2025). To be published in IEEE proceedings"
    },
    {
        "title": "MCP vs RAG vs NLWeb vs HTML: A Comparison of the Effectiveness and Efficiency of Different Agent Interfaces to the Web (Technical Report)",
        "abstract": "Large language model agents are increasingly used to automate web tasks such as product search, offer comparison, and checkout. Current research explores different interfaces through which these agents interact with websites, including traditional HTML browsing, retrieval-augmented generation (RAG) over pre-crawled content, communication via Web APIs using the Model Context Protocol (MCP), and natural-language querying through the NLWeb interface. However, no prior work has compared these four architectures within a single controlled environment using identical tasks.\n  To address this gap, we introduce a testbed consisting of four simulated e-shops, each offering its products via HTML, MCP, and NLWeb interfaces. For each interface (HTML, RAG, MCP, and NLWeb) we develop specialized agents that perform the same sets of tasks, ranging from simple product searches and price comparisons to complex queries for complementary or substitute products and checkout processes. We evaluate the agents using GPT 4.1, GPT 5, GPT 5 mini, and Claude Sonnet 4 as underlying LLM. Our evaluation shows that the RAG, MCP and NLWeb agents outperform HTML on both effectiveness and efficiency. Averaged over all tasks, F1 rises from 0.67 for HTML to between 0.75 and 0.77 for the other agents. Token usage falls from about 241k for HTML to between 47k and 140k per task. The runtime per task drops from 291 seconds to between 50 and 62 seconds. The best overall configuration is RAG with GPT 5 achieving an F1 score of 0.87 and a completion rate of 0.79. Also taking cost into consideration, RAG with GPT 5 mini offers a good compromise between API usage fees and performance. Our experiments show the choice of the interaction interface has a substantial impact on both the effectiveness and efficiency of LLM-based web agents.",
        "url": "http://arxiv.org/abs/2511.23281v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23281v1",
        "arxiv_id": "2511.23281v1",
        "authors": [
            "Aaron Steiner",
            "Ralph Peeters",
            "Christian Bizer"
        ],
        "submitted": "2025-11-28 15:32:15",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Behavior-Equivalent Token: Single-Token Replacement for Long Prompts in LLMs",
        "abstract": "Carefully engineered system prompts play a critical role in guiding the behavior of LLM agents, but their considerable length introduces significant drawbacks, including increased inference latency, higher computational cost, and reduced effective context length. This raises the question of whether such lengthy prompts can be replaced by a drastically reduced number of tokens while preserving their behavioral effect on downstream tasks. To enable this, we propose a lightweight three-stage training framework that learns a single prompt-specific Behavior-Equivalent token ([BE]). The framework first trains [BE] to encode the natural-language content of the original system prompt via reconstruction, and then distills the prompt 's downstream behavior into this single token. Importantly, our method requires no access to model internals, no auxiliary compression models, and no labeled responses. Empirical evaluations on three datasets show that a single [BE] token achieves up to a 3000x reduction in prompt length, while retaining about 98% of the downstream performance of the original system prompts. This substantially reduces inference cost and leaves almost the entire context window available for user inputs.",
        "url": "http://arxiv.org/abs/2511.23271v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23271v1",
        "arxiv_id": "2511.23271v1",
        "authors": [
            "Jiancheng Dong",
            "Pengyue Jia",
            "Jingyu Peng",
            "Maolin Wang",
            "Yuhao Wang",
            "Lixin Su",
            "Xin Sun",
            "Shuaiqiang Wang",
            "Dawei Yin",
            "Xiangyu Zhao"
        ],
        "submitted": "2025-11-28 15:22:52",
        "source": "arxiv",
        "comment": "15 pages, 5 figures"
    },
    {
        "title": "BanglaSentNet: An Explainable Hybrid Deep Learning Framework for Multi-Aspect Sentiment Analysis with Cross-Domain Transfer Learning",
        "abstract": "Multi-aspect sentiment analysis of Bangla e-commerce reviews remains challenging due to limited annotated datasets, morphological complexity, code-mixing phenomena, and domain shift issues, affecting 300 million Bangla-speaking users. Existing approaches lack explainability and cross-domain generalization capabilities crucial for practical deployment. We present BanglaSentNet, an explainable hybrid deep learning framework integrating LSTM, BiLSTM, GRU, and BanglaBERT through dynamic weighted ensemble learning for multi-aspect sentiment classification. We introduce a dataset of 8,755 manually annotated Bangla product reviews across four aspects (Quality, Service, Price, Decoration) from major Bangladeshi e-commerce platforms. Our framework incorporates SHAP-based feature attribution and attention visualization for transparent insights. BanglaSentNet achieves 85% accuracy and 0.88 F1-score, outperforming standalone deep learning models by 3-7% and traditional approaches substantially. The explainability suite achieves 9.4/10 interpretability score with 87.6% human agreement. Cross-domain transfer learning experiments reveal robust generalization: zero-shot performance retains 67-76% effectiveness across diverse domains (BanglaBook reviews, social media, general e-commerce, news headlines); few-shot learning with 500-1000 samples achieves 90-95% of full fine-tuning performance, significantly reducing annotation costs. Real-world deployment demonstrates practical utility for Bangladeshi e-commerce platforms, enabling data-driven decision-making for pricing optimization, service improvement, and customer experience enhancement. This research establishes a new state-of-the-art benchmark for Bangla sentiment analysis, advances ensemble learning methodologies for low-resource languages, and provides actionable solutions for commercial applications.",
        "url": "http://arxiv.org/abs/2511.23264v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23264v1",
        "arxiv_id": "2511.23264v1",
        "authors": [
            "Ariful Islam",
            "Md Rifat Hossen",
            "Tanvir Mahmud"
        ],
        "submitted": "2025-11-28 15:17:22",
        "source": "arxiv",
        "comment": "Submitted to Springer Nature Computer Science (SNCS) as an extended version of our ICDSAIA 2025 conference paper"
    },
    {
        "title": "Tourism Question Answer System in Indian Language using Domain-Adapted Foundation Models",
        "abstract": "This article presents the first comprehensive study on designing a baseline extractive question-answering (QA) system for the Hindi tourism domain, with a specialized focus on the Varanasi-a cultural and spiritual hub renowned for its Bhakti-Bhaav (devotional ethos). Targeting ten tourism-centric subdomains-Ganga Aarti, Cruise, Food Court, Public Toilet, Kund, Museum, General, Ashram, Temple and Travel, the work addresses the absence of language-specific QA resources in Hindi for culturally nuanced applications. In this paper, a dataset comprising 7,715 Hindi QA pairs pertaining to Varanasi tourism was constructed and subsequently augmented with 27,455 pairs generated via Llama zero-shot prompting. We propose a framework leveraging foundation models-BERT and RoBERTa, fine-tuned using Supervised Fine-Tuning (SFT) and Low-Rank Adaptation (LoRA), to optimize parameter efficiency and task performance. Multiple variants of BERT, including pre-trained languages (e.g., Hindi-BERT), are evaluated to assess their suitability for low-resource domain-specific QA. Evaluation metrics - F1, BLEU, and ROUGE-L - highlight trade-offs between answer precision and linguistic fluency. Experiments demonstrate that LoRA-based fine-tuning achieves competitive performance (85.3\\% F1) while reducing trainable parameters by 98\\% compared to SFT, striking a balance between efficiency and accuracy. Comparative analysis across models reveals that RoBERTa with SFT outperforms BERT variants in capturing contextual nuances, particularly for culturally embedded terms (e.g., Aarti, Kund). This work establishes a foundational baseline for Hindi tourism QA systems, emphasizing the role of LORA in low-resource settings and underscoring the need for culturally contextualized NLP frameworks in the tourism domain.",
        "url": "http://arxiv.org/abs/2511.23235v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23235v1",
        "arxiv_id": "2511.23235v1",
        "authors": [
            "Praveen Gatla",
            "Anushka",
            "Nikita Kanwar",
            "Gouri Sahoo",
            "Rajesh Kumar Mundotiya"
        ],
        "submitted": "2025-11-28 14:44:16",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "TWEO: Transformers Without Extreme Outliers Enables FP8 Training And Quantization For Dummies",
        "abstract": "Native FP8 support in modern hardware is essential for training large Transformers, but is severely hindered by extreme activation outliers. Existing solutions either rely on complex mixed-precision engineering or invasive architectural modifications. This paper fundamentally challenges the conventional wisdom that outliers are data-driven. We demonstrate that extreme outliers are a data-independent, mechanically-produced artifact of training, originating from specific structural properties of the weight matrices (i.e., colinearity). Based on this insight, we propose TWEO (Transformers Without Extreme Outliers), a novel, non-invasive loss function. TWEO effectively prevents extreme outliers via a very simple loss term, which reduces outliers from 10000+ to less than 20. TWEO then enables full-model FP8 pre-training with neither engineering tricks nor architectural changes for both LLM and ViT. When standard FP8 training catastrophically collapses, TWEO achieves performance comparable to the BF16 baseline while delivering a 36% increase in training throughput. Also, TWEO enables a new quantization paradigm. Hardware-friendly W8A8 per-tensor static quantization of LLMs, previously considered completely unusable due to outliers, achieves SOTA performance for the first time on TWEO-trained models.",
        "url": "http://arxiv.org/abs/2511.23225v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23225v1",
        "arxiv_id": "2511.23225v1",
        "authors": [
            "Guang Liang",
            "Jie Shao",
            "Ningyuan Tang",
            "Xinyao Liu",
            "Jianxin Wu"
        ],
        "submitted": "2025-11-28 14:33:21",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Listwise Preference Optimization with Element-wise Confusions for Aspect Sentiment Quad Prediction",
        "abstract": "Aspect sentiment quad prediction (ASQP) is inherently challenging to predict a structured quadruple with four core sentiment elements, including aspect term (a), aspect category (c), opinion term (o), and sentiment polarity (s). Prior methods relying on marker-based prediction struggle with modeling the intricate relationships among elements and experience sharp performance declines when predicting higher-order elements (e.g., c and s) under standard supervised fine-tuning. To address these limitations, we employ reasoning-based generation to output both the quadruple and a natural language rationale under element prefixes within a unified template, encouraging explicit relational reasoning and interpretability. To further enhance element-wise alignment, we introduce a listwise preference optimization framework for improving structural validity and relational coherence. Specifically, we generate element-wise confusable candidates via syntactic and semantic proximity, then train the model with listwise objectives to prefer the gold candidates over closely competing alternatives. Extensive experiments on four benchmark datasets demonstrate that our framework effectively improves quadruple prediction accuracy and explanation consistency.",
        "url": "http://arxiv.org/abs/2511.23184v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23184v1",
        "arxiv_id": "2511.23184v1",
        "authors": [
            "Wenna Lai",
            "Haoran Xie",
            "Guandong Xu",
            "Qing Li",
            "S. Joe Qin"
        ],
        "submitted": "2025-11-28 13:52:01",
        "source": "arxiv",
        "comment": "11 pages, 7 figures, and 6 tables"
    },
    {
        "title": "Are LLMs Good Safety Agents or a Propaganda Engine?",
        "abstract": "Large Language Models (LLMs) are trained to refuse to respond to harmful content. However, systematic analyses of whether this behavior is truly a reflection of its safety policies or an indication of political censorship, that is practiced globally by countries, is lacking. Differentiating between safety influenced refusals or politically motivated censorship is hard and unclear. For this purpose we introduce PSP, a dataset built specifically to probe the refusal behaviors in LLMs from an explicitly political context. PSP is built by formatting existing censored content from two data sources, openly available on the internet: sensitive prompts in China generalized to multiple countries, and tweets that have been censored in various countries. We study: 1) impact of political sensitivity in seven LLMs through data-driven (making PSP implicit) and representation-level approaches (erasing the concept of politics); and, 2) vulnerability of models on PSP through prompt injection attacks (PIAs). Associating censorship with refusals on content with masked implicit intent, we find that most LLMs perform some form of censorship. We conclude with summarizing major attributes that can cause a shift in refusal distributions across models and contexts of different countries.",
        "url": "http://arxiv.org/abs/2511.23174v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23174v1",
        "arxiv_id": "2511.23174v1",
        "authors": [
            "Neemesh Yadav",
            "Francesco Ortu",
            "Jiarui Liu",
            "Joeun Yook",
            "Bernhard Schölkopf",
            "Rada Mihalcea",
            "Alberto Cazzaniga",
            "Zhijing Jin"
        ],
        "submitted": "2025-11-28 13:36:00",
        "source": "arxiv",
        "comment": "15 pages, 7 tables, 4 figures"
    },
    {
        "title": "Multi-chain Graph Refinement and Selection for Reliable Reasoning in Large Language Models",
        "abstract": "The complex reasoning ability of Large Language Models (LLMs) poses a critical bottleneck for their practical applications. Test-time expansion methods such as Tree-of-Thought (ToT) and Graph-of-Thought (GoT) enhance reasoning by introducing intermediate reasoning structures, tree search, or graph-based exploration mechanisms. However, their reasoning strategies suffer from limited diversity, redundant search branches, and inadequate integration and error correction across heterogeneous reasoning paths. To address these limitations, we propose a novel reasoning framework called Multi-chain Graph Refinement & Selection (MGRS), which first generates multiple diverse reasoning trajectories for a given problem, refines candidate responses using a composite self- and cross-verification strategy, then constructs a reasoning relation graph and estimates the success rate of intermediate nodes, and finally computes cumulative success rates to select the most reliable answer and corresponding reasoning trajectory. Experimental results demonstrate that MGRS significantly advances both the reasoning capability and computational efficiency of reasoning enhancement methods. Across six benchmark datasets spanning four distinct tasks, MGRS achieves an average accuracy of 82.9%, outperforming state-of-the-art baselines by a clear margin of 2.1%. Remarkably, on the 24-point game, MGRS attains 100% accuracy for the first time, while delivering a 13.6x speed-up compared to the leading Forest of Thoughts framework.",
        "url": "http://arxiv.org/abs/2511.23136v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23136v1",
        "arxiv_id": "2511.23136v1",
        "authors": [
            "Yujiao Yang",
            "Jing Lian",
            "Linhui Li"
        ],
        "submitted": "2025-11-28 12:35:16",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Dripper: Token-Efficient Main HTML Extraction with a Lightweight LM",
        "abstract": "Accurately and efficiently extracting main content from general web pages is of great significance for obtaining training data for large models. Using well-pre-trained decoder-only generative language models offers excellent document comprehension capabilities, thereby effectively enhancing parsing quality. However, it remains constrained by issues such as context window length, inference cost, and format hallucination. We present Dripper, an efficient HTML main content extraction framework powered by lightweight language models, which addresses these challenges through four key innovations: (1) We design a specialized HTML simplification algorithm that reduces input token count to 22\\% compared to raw HTML while preserving critical structural information; (2) We reformulate main content extraction as a semantic block sequence classification task, significantly reducing inference cost; (3) We introduce a controlled decoding mechanism that strictly constrains the output space through logits processors, effectively eliminating hallucination issues common in small-scale models; (4) We propose WebMainBench, an evaluation dataset containing over 7,800 web pages with meticulously human-annotated main content extraction labels. Experimental results demonstrate that using only a 0.6B parameter model, Dripper achieves state-of-the-art performance across all evaluation benchmarks and outperforms all baseline methods, attaining an ROUGE-N F1 score of 81.58\\%( 83.13\\% with fall-back strategy) on our proposed WebMainBench dataset.",
        "url": "http://arxiv.org/abs/2511.23119v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23119v1",
        "arxiv_id": "2511.23119v1",
        "authors": [
            "Mengjie Liu",
            "Jiahui Peng",
            "Pei Chu",
            "Jiantao Qiu",
            "Ren Ma",
            "He Zhu",
            "Rui Min",
            "Lindong Lu",
            "Wenchang Ning",
            "Linfeng Hou",
            "Kaiwen Liu",
            "Yuan Qu",
            "Zhenxiang Li",
            "Chao Xu",
            "Zhongying Tu",
            "Wentao Zhang",
            "Conghui He"
        ],
        "submitted": "2025-11-28 12:04:46",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Mind Reading or Misreading? LLMs on the Big Five Personality Test",
        "abstract": "We evaluate large language models (LLMs) for automatic personality prediction from text under the binary Five Factor Model (BIG5). Five models -- including GPT-4 and lightweight open-source alternatives -- are tested across three heterogeneous datasets (Essays, MyPersonality, Pandora) and two prompting strategies (minimal vs. enriched with linguistic and psychological cues). Enriched prompts reduce invalid outputs and improve class balance, but also introduce a systematic bias toward predicting trait presence. Performance varies substantially: Openness and Agreeableness are relatively easier to detect, while Extraversion and Neuroticism remain challenging. Although open-source models sometimes approach GPT-4 and prior benchmarks, no configuration yields consistently reliable predictions in zero-shot binary settings. Moreover, aggregate metrics such as accuracy and macro-F1 mask significant asymmetries, with per-class recall offering clearer diagnostic value. These findings show that current out-of-the-box LLMs are not yet suitable for APPT, and that careful coordination of prompt design, trait framing, and evaluation metrics is essential for interpretable results.",
        "url": "http://arxiv.org/abs/2511.23101v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23101v1",
        "arxiv_id": "2511.23101v1",
        "authors": [
            "Francesco Di Cursi",
            "Chiara Boldrini",
            "Marco Conti",
            "Andrea Passarella"
        ],
        "submitted": "2025-11-28 11:40:30",
        "source": "arxiv",
        "comment": "Funding: SoBigDatait (IR0000013), FAIR (PE00000013), ICSC (CN00000013)"
    },
    {
        "title": "Accent Placement Models for Rigvedic Sanskrit Text",
        "abstract": "The Rigveda, among the oldest Indian texts in Vedic Sanskrit, employs a distinctive pitch-accent system : udātta, anudātta, svarita whose marks encode melodic and interpretive cues but are often absent from modern e-texts. This work develops a parallel corpus of accented-unaccented ślokas and conducts a controlled comparison of three strategies for automatic accent placement in Rigvedic verse: (i) full fine-tuning of ByT5, a byte-level Transformer that operates directly on Unicode combining marks, (ii) a from-scratch BiLSTM-CRF sequence-labeling baseline, and (iii) LoRA-based parameter-efficient fine-tuning atop ByT5.\n  Evaluation uses Word Error Rate (WER) and Character Error Rate (CER) for orthographic fidelity, plus a task-specific Diacritic Error Rate (DER) that isolates accent edits. Full ByT5 fine-tuning attains the lowest error across all metrics; LoRA offers strong efficiency-accuracy trade-offs, and BiLSTM-CRF serves as a transparent baseline. The study underscores practical requirements for accent restoration - Unicode-safe preprocessing, mark-aware tokenization, and evaluation that separates grapheme from accent errors - and positions heritage-language technology as an emerging NLP area connecting computational modeling with philological and pedagogical aims. Results establish reproducible baselines for Rigvedic accent restoration and provide guidance for downstream tasks such as accent-aware OCR, ASR/chant synthesis, and digital scholarship.",
        "url": "http://arxiv.org/abs/2511.23088v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23088v1",
        "arxiv_id": "2511.23088v1",
        "authors": [
            "Akhil Rajeev P",
            "Annarao Kulkarni"
        ],
        "submitted": "2025-11-28 11:22:17",
        "source": "arxiv",
        "comment": "Submitted to AACL-IJCNLP 2025"
    },
    {
        "title": "Bharat Scene Text: A Novel Comprehensive Dataset and Benchmark for Indian Language Scene Text Understanding",
        "abstract": "Reading scene text, that is, text appearing in images, has numerous application areas, including assistive technology, search, and e-commerce. Although scene text recognition in English has advanced significantly and is often considered nearly a solved problem, Indian language scene text recognition remains an open challenge. This is due to script diversity, non-standard fonts, and varying writing styles, and, more importantly, the lack of high-quality datasets and open-source models. To address these gaps, we introduce the Bharat Scene Text Dataset (BSTD) - a large-scale and comprehensive benchmark for studying Indian Language Scene Text Recognition. It comprises more than 100K words that span 11 Indian languages and English, sourced from over 6,500 scene images captured across various linguistic regions of India. The dataset is meticulously annotated and supports multiple scene text tasks, including: (i) Scene Text Detection, (ii) Script Identification, (iii) Cropped Word Recognition, and (iv) End-to-End Scene Text Recognition. We evaluated state-of-the-art models originally developed for English by adapting (fine-tuning) them for Indian languages. Our results highlight the challenges and opportunities in Indian language scene text recognition. We believe that this dataset represents a significant step toward advancing research in this domain. All our models and data are open source.",
        "url": "http://arxiv.org/abs/2511.23071v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23071v1",
        "arxiv_id": "2511.23071v1",
        "authors": [
            "Anik De",
            "Abhirama Subramanyam Penamakuri",
            "Rajeev Yadav",
            "Aditya Rathore",
            "Harshiv Shah",
            "Devesh Sharma",
            "Sagar Agarwal",
            "Pravin Kumar",
            "Anand Mishra"
        ],
        "submitted": "2025-11-28 10:58:37",
        "source": "arxiv",
        "comment": "Under Peer Review"
    },
    {
        "title": "Conveying Imagistic Thinking in TCM Translation: A Prompt Engineering and LLM-Based Evaluation Framework",
        "abstract": "Traditional Chinese Medicine theory is built on imagistic thinking, in which medical principles and diagnostic and therapeutic logic are structured through metaphor and metonymy. However, existing English translations largely rely on literal rendering, making it difficult for target-language readers to reconstruct the underlying conceptual networks and apply them in clinical practice. This study adopted a human-in-the-loop framework and selected four passages from the medical canon Huangdi Neijing that are fundamental in theory. Through prompt-based cognitive scaffolding, DeepSeek V3.1 was guided to identify metaphor and metonymy in the source text and convey the theory in translation. In the evaluation stage, ChatGPT 5 Pro and Gemini 2.5 Pro were instructed by prompts to simulate three types of real-world readers. Human translations, baseline model translations, and prompt-adjusted translations were scored by the simulated readers across five cognitive dimensions, followed by structured interviews and Interpretative Phenomenological Analysis. Results show that the prompt-adjusted LLM translations perform best across all five dimensions, with high cross-model and cross-role consistency. The interview themes reveal differences between human and machine translation, effective strategies for metaphor and metonymy transfer, and readers' cognitive preferences. This study provides a cognitive, efficient and replicable HITL methodological pathway for translation of ancient, concept-dense texts like TCM.",
        "url": "http://arxiv.org/abs/2511.23059v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23059v1",
        "arxiv_id": "2511.23059v1",
        "authors": [
            "Jiatong Han"
        ],
        "submitted": "2025-11-28 10:35:10",
        "source": "arxiv",
        "comment": "3 figures"
    },
    {
        "title": "Standard Occupation Classifier -- A Natural Language Processing Approach",
        "abstract": "Standard Occupational Classifiers (SOC) are systems used to categorize and classify different types of jobs and occupations based on their similarities in terms of job duties, skills, and qualifications. Integrating these facets with Big Data from job advertisement offers the prospect to investigate labour demand that is specific to various occupations. This project investigates the use of recent developments in natural language processing to construct a classifier capable of assigning an occupation code to a given job advertisement. We develop various classifiers for both UK ONS SOC and US O*NET SOC, using different Language Models. We find that an ensemble model, which combines Google BERT and a Neural Network classifier while considering job title, description, and skills, achieved the highest prediction accuracy. Specifically, the ensemble model exhibited a classification accuracy of up to 61% for the lower (or fourth) tier of SOC, and 72% for the third tier of SOC. This model could provide up to date, accurate information on the evolution of the labour market using job advertisements.",
        "url": "http://arxiv.org/abs/2511.23057v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23057v1",
        "arxiv_id": "2511.23057v1",
        "authors": [
            "Sidharth Rony",
            "Jack Patman"
        ],
        "submitted": "2025-11-28 10:30:37",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Decoding the Past: Explainable Machine Learning Models for Dating Historical Texts",
        "abstract": "Accurately dating historical texts is essential for organizing and interpreting cultural heritage collections. This article addresses temporal text classification using interpretable, feature-engineered tree-based machine learning models. We integrate five feature categories - compression-based, lexical structure, readability, neologism detection, and distance features - to predict the temporal origin of English texts spanning five centuries. Comparative analysis shows that these feature domains provide complementary temporal signals, with combined models outperforming any individual feature set. On a large-scale corpus, we achieve 76.7% accuracy for century-scale prediction and 26.1% for decade-scale classification, substantially above random baselines (20% and 2.3%). Under relaxed temporal precision, performance increases to 96.0% top-2 accuracy for centuries and 85.8% top-10 accuracy for decades. The final model exhibits strong ranking capabilities with AUCROC up to 94.8% and AUPRC up to 83.3%, and maintains controlled errors with mean absolute deviations of 27 years and 30 years, respectively. For authentication-style tasks, binary models around key thresholds (e.g., 1850-1900) reach 85-98% accuracy. Feature importance analysis identifies distance features and lexical structure as most informative, with compression-based features providing complementary signals. SHAP explainability reveals systematic linguistic evolution patterns, with the 19th century emerging as a pivot point across feature domains. Cross-dataset evaluation on Project Gutenberg highlights domain adaptation challenges, with accuracy dropping by 26.4 percentage points, yet the computational efficiency and interpretability of tree-based models still offer a scalable, explainable alternative to neural architectures.",
        "url": "http://arxiv.org/abs/2511.23056v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23056v1",
        "arxiv_id": "2511.23056v1",
        "authors": [
            "Paulo J. N. Pinto",
            "Armando J. Pinho",
            "Diogo Pratas"
        ],
        "submitted": "2025-11-28 10:27:48",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Social Perceptions of English Spelling Variation on Twitter: A Comparative Analysis of Human and LLM Responses",
        "abstract": "Spelling variation (e.g. funnnn vs. fun) can influence the social perception of texts and their writers: we often have various associations with different forms of writing (is the text informal? does the writer seem young?). In this study, we focus on the social perception of spelling variation in online writing in English and study to what extent this perception is aligned between humans and large language models (LLMs). Building on sociolinguistic methodology, we compare LLM and human ratings on three key social attributes of spelling variation (formality, carefulness, age). We find generally strong correlations in the ratings between humans and LLMs. However, notable differences emerge when we analyze the distribution of ratings and when comparing between different types of spelling variation.",
        "url": "http://arxiv.org/abs/2511.23041v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23041v1",
        "arxiv_id": "2511.23041v1",
        "authors": [
            "Dong Nguyen",
            "Laura Rosseel"
        ],
        "submitted": "2025-11-28 10:06:18",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Masked Diffusion for Generative Recommendation",
        "abstract": "Generative recommendation (GR) with semantic IDs (SIDs) has emerged as a promising alternative to traditional recommendation approaches due to its performance gains, capitalization on semantic information provided through language model embeddings, and inference and storage efficiency. Existing GR with SIDs works frame the probability of a sequence of SIDs corresponding to a user's interaction history using autoregressive modeling. While this has led to impressive next item prediction performances in certain settings, these autoregressive GR with SIDs models suffer from expensive inference due to sequential token-wise decoding, potentially inefficient use of training data and bias towards learning short-context relationships among tokens. Inspired by recent breakthroughs in NLP, we propose to instead model and learn the probability of a user's sequence of SIDs using masked diffusion. Masked diffusion employs discrete masking noise to facilitate learning the sequence distribution, and models the probability of masked tokens as conditionally independent given the unmasked tokens, allowing for parallel decoding of the masked tokens. We demonstrate through thorough experiments that our proposed method consistently outperforms autoregressive modeling. This performance gap is especially pronounced in data-constrained settings and in terms of coarse-grained recall, consistent with our intuitions. Moreover, our approach allows the flexibility of predicting multiple SIDs in parallel during inference while maintaining superior performance to autoregressive modeling.",
        "url": "http://arxiv.org/abs/2511.23021v1",
        "pdf_url": "https://arxiv.org/pdf/2511.23021v1",
        "arxiv_id": "2511.23021v1",
        "authors": [
            "Kulin Shah",
            "Bhuvesh Kumar",
            "Neil Shah",
            "Liam Collins"
        ],
        "submitted": "2025-11-28 09:36:26",
        "source": "arxiv",
        "comment": "25 pages"
    },
    {
        "title": "ShoppingComp: Are LLMs Really Ready for Your Shopping Cart?",
        "abstract": "We present ShoppingComp, a challenging real-world benchmark for rigorously evaluating LLM-powered shopping agents on three core capabilities: precise product retrieval, expert-level report generation, and safety critical decision making. Unlike prior e-commerce benchmarks, ShoppingComp introduces highly complex tasks under the principle of guaranteeing real products and ensuring easy verifiability, adding a novel evaluation dimension for identifying product safety hazards alongside recommendation accuracy and report quality. The benchmark comprises 120 tasks and 1,026 scenarios, curated by 35 experts to reflect authentic shopping needs. Results reveal stark limitations of current LLMs: even state-of-the-art models achieve low performance (e.g., 11.22% for GPT-5, 3.92% for Gemini-2.5-Flash). These findings highlight a substantial gap between research benchmarks and real-world deployment, where LLMs make critical errors such as failure to identify unsafe product usage or falling for promotional misinformation, leading to harmful recommendations. ShoppingComp fills the gap and thus establishes a new standard for advancing reliable and practical agents in e-commerce.",
        "url": "http://arxiv.org/abs/2511.22978v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22978v1",
        "arxiv_id": "2511.22978v1",
        "authors": [
            "Huaixiao Tou",
            "Ying Zeng",
            "Cong Ma",
            "Muzhi Li",
            "Minghao Li",
            "Weijie Yuan",
            "He Zhang",
            "Kai Jia"
        ],
        "submitted": "2025-11-28 08:32:54",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Pooling Attention: Evaluating Pretrained Transformer Embeddings for Deception Classification",
        "abstract": "This paper investigates fake news detection as a downstream evaluation of Transformer representations, benchmarking encoder-only and decoder-only pre-trained models (BERT, GPT-2, Transformer-XL) as frozen embedders paired with lightweight classifiers. Through controlled preprocessing comparing pooling versus padding and neural versus linear heads, results demonstrate that contextual self-attention encodings consistently transfer effectively. BERT embeddings combined with logistic regression outperform neural baselines on LIAR dataset splits, while analyses of sequence length and aggregation reveal robustness to truncation and advantages from simple max or average pooling. This work positions attention-based token encoders as robust, architecture-centric foundations for veracity tasks, isolating Transformer contributions from classifier complexity.",
        "url": "http://arxiv.org/abs/2511.22977v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22977v1",
        "arxiv_id": "2511.22977v1",
        "authors": [
            "Sumit Mamtani",
            "Abhijeet Bhure"
        ],
        "submitted": "2025-11-28 08:32:49",
        "source": "arxiv",
        "comment": "Accepted at the IEEE 7th Computing, Communications and IoT Applications Conference (ComComAp 2025), Madrid, Spain, December 2025. 6 pages"
    },
    {
        "title": "Training-Free Loosely Speculative Decoding: Accepting Semantically Correct Drafts Beyond Exact Match",
        "abstract": "Large language models (LLMs) achieve strong performance across diverse tasks but suffer from high inference latency due to their autoregressive generation. Speculative Decoding (SPD) mitigates this issue by verifying candidate tokens in parallel from a smaller draft model, yet its strict exact-match verification discards many semantically valid continuations. Moreover, existing training-based SPD methods often suffer from performance degradation on out-of-distribution (OOD) tasks. To this end, we propose Training-Free Loosely Speculative Decoding (FLy), a novel method that loosens the rigid verification criterion by leveraging the target model's self-corrective behavior to judge whether a draft-target mismatch remains semantically valid. FLy introduces a two-tier mechanism: an entropy-level gate that identifies whether the current token allows multiple plausible alternatives or is nearly deterministic, and a token-level deferred window that distinguishes genuine errors from differently worded yet semantically correct variants. To further reduce latency, we design a multi-level acceleration strategy that accelerates not only the target model but also the drafter itself. Owing to its training-free design, FLy composes seamlessly with arbitrary draft-target pairs and generalizes across models and domains without hyperparameter re-tuning. Experiments show that FLy preserves more than 99% of the target model's accuracy while achieving an average 2.81x speedup on Llama-3.1-70B-Instruct and 5.07x speedup on the 405B variant. Notably, on out-of-domain datasets, our method remains highly effective and outperforms the training-based method EAGLE-3 by 1.62x.",
        "url": "http://arxiv.org/abs/2511.22972v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22972v1",
        "arxiv_id": "2511.22972v1",
        "authors": [
            "Jinze Li",
            "Yixing Xu",
            "Guanchen Li",
            "Shuo Yang",
            "Jinfeng Xu",
            "Xuanwu Yin",
            "Dong Li",
            "Edith C. H. Ngai",
            "Emad Barsoum"
        ],
        "submitted": "2025-11-28 08:23:30",
        "source": "arxiv",
        "comment": "Under review"
    },
    {
        "title": "Visual Puns from Idioms: An Iterative LLM-T2IM-MLLM Framework",
        "abstract": "We study idiom-based visual puns--images that align an idiom's literal and figurative meanings--and present an iterative framework that coordinates a large language model (LLM), a text-to-image model (T2IM), and a multimodal LLM (MLLM) for automatic generation and evaluation. Given an idiom, the system iteratively (i) generates detailed visual prompts, (ii) synthesizes an image, (iii) infers the idiom from the image, and (iv) refines the prompt until recognition succeeds or a step limit is reached. Using 1,000 idioms as inputs, we synthesize a corresponding dataset of visual pun images with paired prompts, enabling benchmarking of both generation and understanding. Experiments across 10 LLMs, 10 MLLMs, and one T2IM (Qwen-Image) show that MLLM choice is the primary performance driver: GPT achieves the highest accuracies, Gemini follows, and the best open-source MLLM (Gemma) is competitive with some closed models. On the LLM side, Claude attains the strongest average performance for prompt generation.",
        "url": "http://arxiv.org/abs/2511.22943v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22943v1",
        "arxiv_id": "2511.22943v1",
        "authors": [
            "Kelaiti Xiao",
            "Liang Yang",
            "Dongyu Zhang",
            "Paerhati Tulajiang",
            "Hongfei Lin"
        ],
        "submitted": "2025-11-28 07:30:58",
        "source": "arxiv",
        "comment": "Submitted to ICASSP 2026 (under review)"
    },
    {
        "title": "Artwork Interpretation with Vision Language Models: A Case Study on Emotions and Emotion Symbols",
        "abstract": "Emotions are a fundamental aspect of artistic expression. Due to their abstract nature, there is a broad spectrum of emotion realization in artworks. These are subject to historical change and their analysis requires expertise in art history. In this article, we investigate which aspects of emotional expression can be detected by current (2025) vision language models (VLMs). We present a case study of three VLMs (Llava-Llama and two Qwen models) in which we ask these models four sets of questions of increasing complexity about artworks (general content, emotional content, expression of emotions, and emotion symbols) and carry out a qualitative expert evaluation. We find that the VLMs recognize the content of the images surprisingly well and often also which emotions they depict and how they are expressed. The models perform best for concrete images but fail for highly abstract or highly symbolic images. Reliable recognition of symbols remains fundamentally difficult. Furthermore, the models continue to exhibit the well-known LLM weakness of providing inconsistent answers to related questions.",
        "url": "http://arxiv.org/abs/2511.22929v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22929v1",
        "arxiv_id": "2511.22929v1",
        "authors": [
            "Sebastian Padó",
            "Kerstin Thomas"
        ],
        "submitted": "2025-11-28 07:04:09",
        "source": "arxiv",
        "comment": "Accepted for publication at the IJCNLP-AACL workshop on Multimodal Models for Low-Resource Contexts and Social Impact"
    },
    {
        "title": "Language-conditioned world model improves policy generalization by reading environmental descriptions",
        "abstract": "To interact effectively with humans in the real world, it is important for agents to understand language that describes the dynamics of the environment--that is, how the environment behaves--rather than just task instructions specifying \"what to do\". Understanding this dynamics-descriptive language is important for human-agent interaction and agent behavior. Recent work address this problem using a model-based approach: language is incorporated into a world model, which is then used to learn a behavior policy. However, these existing methods either do not demonstrate policy generalization to unseen games or rely on limiting assumptions. For instance, assuming that the latency induced by inference-time planning is tolerable for the target task or expert demonstrations are available. Expanding on this line of research, we focus on improving policy generalization from a language-conditioned world model while dropping these assumptions. We propose a model-based reinforcement learning approach, where a language-conditioned world model is trained through interaction with the environment, and a policy is learned from this model--without planning or expert demonstrations. Our method proposes Language-aware Encoder for Dreamer World Model (LED-WM) built on top of DreamerV3. LED-WM features an observation encoder that uses an attention mechanism to explicitly ground language descriptions to entities in the observation. We show that policies trained with LED-WM generalize more effectively to unseen games described by novel dynamics and language compared to other baselines in several settings in two environments: MESSENGER and MESSENGER-WM.To highlight how the policy can leverage the trained world model before real-world deployment, we demonstrate the policy can be improved through fine-tuning on synthetic test trajectories generated by the world model.",
        "url": "http://arxiv.org/abs/2511.22904v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22904v1",
        "arxiv_id": "2511.22904v1",
        "authors": [
            "Anh Nguyen",
            "Stefan Lee"
        ],
        "submitted": "2025-11-28 06:13:27",
        "source": "arxiv",
        "comment": "NeuRIPS 2025. Workshop: LAW 2025: Bridging Language, Agent, and World Models"
    },
    {
        "title": "ORION: Teaching Language Models to Reason Efficiently in the Language of Thought",
        "abstract": "Large Reasoning Models (LRMs) achieve strong performance in mathematics, code generation, and task planning, but their reliance on long chains of verbose \"thinking\" tokens leads to high latency, redundancy, and incoherent reasoning paths. Inspired by the Language of Thought Hypothesis, which posits that human reasoning operates over a symbolic, compositional mental language called Mentalese, we introduce a framework that trains models to reason in a similarly compact style. Mentalese encodes abstract reasoning as ultra-compressed, structured tokens, enabling models to solve complex problems with far fewer steps. To improve both efficiency and accuracy, we propose SHORTER LENGTH PREFERENCE OPTIMIZATION (SLPO), a reinforcement learning method that rewards concise solutions that stay correct, while still allowing longer reasoning when needed. Applied to Mentalese-aligned models, SLPO yields significantly higher compression rates by enabling concise reasoning that preserves the benefits of detailed thinking without the computational overhead. Across benchmarks including AIME 2024 and 2025, MinervaMath, OlympiadBench, Math500, and AMC, our ORION models produce reasoning traces with 4-16x fewer tokens, achieve up to 5x lower inference latency, and reduce training costs by 7-9x relative to the DeepSeek R1 Distilled model, while maintaining 90-98% of its accuracy. ORION also surpasses Claude and ChatGPT-4o by up to 5% in accuracy while maintaining 2x compression. These results show that Mentalese-style compressed reasoning offers a step toward human-like cognitive efficiency, enabling real-time, cost-effective reasoning without sacrificing accuracy.",
        "url": "http://arxiv.org/abs/2511.22891v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22891v1",
        "arxiv_id": "2511.22891v1",
        "authors": [
            "Kumar Tanmay",
            "Kriti Aggarwal",
            "Paul Pu Liang",
            "Subhabrata Mukherjee"
        ],
        "submitted": "2025-11-28 05:41:55",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "FEANEL: A Benchmark for Fine-Grained Error Analysis in K-12 English Writing",
        "abstract": "Large Language Models (LLMs) have transformed artificial intelligence, offering profound opportunities for educational applications. However, their ability to provide fine-grained educational feedback for K-12 English writing remains underexplored. In this paper, we challenge the error analysis and pedagogical skills of LLMs by introducing the problem of Fine-grained Error Analysis for English Learners and present the Fine-grained Error ANalysis for English Learners (FEANEL) Benchmark. The benchmark comprises 1,000 essays written by elementary and secondary school students, and a well-developed English writing error taxonomy. Each error is annotated by language education experts and categorized by type, severity, and explanatory feedback, using a part-of-speech-based taxonomy they co-developed. We evaluate state-of-the-art LLMs on the FEANEL Benchmark to explore their error analysis and pedagogical abilities. Experimental results reveal significant gaps in current LLMs' ability to perform fine-grained error analysis, highlighting the need for advancements in particular methods for educational applications.",
        "url": "http://arxiv.org/abs/2511.22883v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22883v1",
        "arxiv_id": "2511.22883v1",
        "authors": [
            "Jingheng Ye",
            "Shen Wang",
            "Jiaqi Chen",
            "Hebin Wang",
            "Deqing Zou",
            "Yanyu Zhu",
            "Jiwei Tang",
            "Hai-Tao Zheng",
            "Ruitong Liu",
            "Haoyang Li",
            "Yanfeng Wang",
            "Qingsong Wen"
        ],
        "submitted": "2025-11-28 05:17:45",
        "source": "arxiv",
        "comment": "19 pages, 7 figures, and 4 tables. The dataset is available at https://huggingface.co/datasets/Feanel/FEANEL"
    },
    {
        "title": "CNN-Based Framework for Pedestrian Age and Gender Classification Using Far-View Surveillance in Mixed-Traffic Intersections",
        "abstract": "Pedestrian safety remains a pressing concern in congested urban intersections, particularly in low- and middle-income countries where traffic is multimodal, and infrastructure often lacks formal control. Demographic factors like age and gender significantly influence pedestrian vulnerability, yet real-time monitoring systems rarely capture this information. To address this gap, this study proposes a deep learning framework that classifies pedestrian age group and gender from far-view intersection footage using convolutional neural networks (CNNs), without relying on facial recognition or high-resolution imagery. The classification is structured as a unified six-class problem, distinguishing adult, teenager, and child pedestrians for both males and females, based on full-body visual cues. Video data was collected from three high-risk intersections in Dhaka, Bangladesh. Two CNN architectures were implemented: ResNet50, a deep convolutional neural network pretrained on ImageNet, and a custom lightweight CNN optimized for computational efficiency. Eight model variants explored combinations of pooling strategies and optimizers. ResNet50 with Max Pooling and SGD achieved the highest accuracy (86.19%), while the custom CNN performed comparably (84.15%) with fewer parameters and faster training. The model's efficient design enables real-time inference on standard surveillance feeds. For practitioners, this system provides a scalable, cost-effective tool to monitor pedestrian demographics at intersections using existing camera infrastructure. Its outputs can shape intersection design, optimize signal timing, and enable targeted safety interventions for vulnerable groups such as children or the elderly. By offering demographic insights often missing in conventional traffic data, the framework supports more inclusive, data-driven planning in mixed-traffic environments.",
        "url": "http://arxiv.org/abs/2511.22873v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22873v1",
        "arxiv_id": "2511.22873v1",
        "authors": [
            "Shisir Shahriar Arif",
            "Md. Muhtashim Shahrier",
            "Nazmul Haque",
            "Md Asif Raihan",
            "Md. Hadiuzzaman"
        ],
        "submitted": "2025-11-28 04:32:04",
        "source": "arxiv",
        "comment": "Accepted for poster presentation at the 105th Annual Meeting of the Transportation Research Board"
    },
    {
        "title": "FedAU2: Attribute Unlearning for User-Level Federated Recommender Systems with Adaptive and Robust Adversarial Training",
        "abstract": "Federated Recommender Systems (FedRecs) leverage federated learning to protect user privacy by retaining data locally. However, user embeddings in FedRecs often encode sensitive attribute information, rendering them vulnerable to attribute inference attacks. Attribute unlearning has emerged as a promising approach to mitigate this issue. In this paper, we focus on user-level FedRecs, which is a more practical yet challenging setting compared to group-level FedRecs. Adversarial training emerges as the most feasible approach within this context. We identify two key challenges in implementing adversarial training-based attribute unlearning for user-level FedRecs: i) mitigating training instability caused by user data heterogeneity, and ii) preventing attribute information leakage through gradients. To address these challenges, we propose FedAU2, an attribute unlearning method for user-level FedRecs. For CH1, we propose an adaptive adversarial training strategy, where the training dynamics are adjusted in response to local optimization behavior. For CH2, we propose a dual-stochastic variational autoencoder to perturb the adversarial model, effectively preventing gradient-based information leakage. Extensive experiments on three real-world datasets demonstrate that our proposed FedAU2 achieves superior performance in unlearning effectiveness and recommendation performance compared to existing baselines.",
        "url": "http://arxiv.org/abs/2511.22872v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22872v1",
        "arxiv_id": "2511.22872v1",
        "authors": [
            "Yuyuan Li",
            "Junjie Fang",
            "Fengyuan Yu",
            "Xichun Sheng",
            "Tianyu Du",
            "Xuyang Teng",
            "Shaowei Jiang",
            "Linbo Jiang",
            "Jianan Lin",
            "Chaochao Chen"
        ],
        "submitted": "2025-11-28 04:22:27",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "JBE-QA: Japanese Bar Exam QA Dataset for Assessing Legal Domain Knowledge",
        "abstract": "We introduce JBE-QA, a Japanese Bar Exam Question-Answering dataset to evaluate large language models' legal knowledge. Derived from the multiple-choice (tanto-shiki) section of the Japanese bar exam (2015-2024), JBE-QA provides the first comprehensive benchmark for Japanese legal-domain evaluation of LLMs. It covers the Civil Code, the Penal Code, and the Constitution, extending beyond the Civil Code focus of prior Japanese resources. Each question is decomposed into independent true/false judgments with structured contextual fields. The dataset contains 3,464 items with balanced labels. We evaluate 26 LLMs, including proprietary, open-weight, Japanese-specialised, and reasoning models. Our results show that proprietary models with reasoning enabled perform best, and the Constitution questions are generally easier than the Civil Code or the Penal Code questions.",
        "url": "http://arxiv.org/abs/2511.22869v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22869v1",
        "arxiv_id": "2511.22869v1",
        "authors": [
            "Zhihan Cao",
            "Fumihito Nishino",
            "Hiroaki Yamada",
            "Nguyen Ha Thanh",
            "Yusuke Miyao",
            "Ken Satoh"
        ],
        "submitted": "2025-11-28 04:16:17",
        "source": "arxiv",
        "comment": "Three tables and one figure"
    },
    {
        "title": "RAG System for Supporting Japanese Litigation Procedures: Faithful Response Generation Complying with Legal Norms",
        "abstract": "This study discusses the essential components that a Retrieval-Augmented Generation (RAG)-based LLM system should possess in order to support Japanese medical litigation procedures complying with legal norms. In litigation, expert commissioners, such as physicians, architects, accountants, and engineers, provide specialized knowledge to help judges clarify points of dispute. When considering the substitution of these expert roles with a RAG-based LLM system, the constraint of strict adherence to legal norms is imposed. Specifically, three requirements arise: (1) the retrieval module must retrieve appropriate external knowledge relevant to the disputed issues in accordance with the principle prohibiting the use of private knowledge, (2) the responses generated must originate from the context provided by the RAG and remain faithful to that context, and (3) the retrieval module must reference external knowledge with appropriate timestamps corresponding to the issues at hand. This paper discusses the design of a RAG-based LLM system that satisfies these requirements.",
        "url": "http://arxiv.org/abs/2511.22858v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22858v1",
        "arxiv_id": "2511.22858v1",
        "authors": [
            "Yuya Ishihara",
            "Atsushi Keyaki",
            "Hiroaki Yamada",
            "Ryutaro Ohara",
            "Mihoko Sumida"
        ],
        "submitted": "2025-11-28 03:28:27",
        "source": "arxiv",
        "comment": "This is a preprint version of a paper reviewed and accepted at BREV-RAG 2025: Beyond Relevance-based EValuation of RAG Systems, a SIGIR-AP 2025 workshop"
    },
    {
        "title": "Two-Stage Distributionally Robust Optimization Framework for Secure Communications in Aerial-RIS Systems",
        "abstract": "This letter proposes a two-stage distributionally robust optimization (DRO) framework for secure deployment and beamforming in an aerial reconfigurable intelligent surface (A-RIS) assisted millimeter-wave system. To account for multi-timescale uncertainties arising from user mobility, imperfect channel state information (CSI), and hardware impairments, our approach decouples the long-term unmanned aerial vehicle (UAV) placement from the per-slot beamforming design. By employing the conditional value-at-risk (CVaR) as a distribution-free risk metric, a low-complexity algorithm is developed, which combines a surrogate model for efficient deployment with an alternating optimization (AO) scheme for robust real-time beamforming. Simulation results validate that the proposed DRO-CVaR framework significantly enhances the tail-end secrecy spectral efficiency and maintains a lower outage probability compared to benchmark schemes, especially under severe uncertainty conditions.",
        "url": "http://arxiv.org/abs/2511.22855v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22855v1",
        "arxiv_id": "2511.22855v1",
        "authors": [
            "Zhongming Feng",
            "Qiling Gao",
            "Zeping Sui",
            "Yun Lin",
            "Michail Matthaiou"
        ],
        "submitted": "2025-11-28 03:20:19",
        "source": "arxiv",
        "comment": "5 pages"
    },
    {
        "title": "Mitigating Semantic Drift: Evaluating LLMs' Efficacy in Psychotherapy through MI Dialogue Summarization",
        "abstract": "Recent advancements in large language models (LLMs) have shown their potential across both general and domain-specific tasks. However, there is a growing concern regarding their lack of sensitivity, factual incorrectness in responses, inconsistent expressions of empathy, bias, hallucinations, and overall inability to capture the depth and complexity of human understanding, especially in low-resource and sensitive domains such as psychology. To address these challenges, our study employs a mixed-methods approach to evaluate the efficacy of LLMs in psychotherapy. We use LLMs to generate precise summaries of motivational interviewing (MI) dialogues and design a two-stage annotation scheme based on key components of the Motivational Interviewing Treatment Integrity (MITI) framework, namely evocation, collaboration, autonomy, direction, empathy, and a non-judgmental attitude. Using expert-annotated MI dialogues as ground truth, we formulate multi-class classification tasks to assess model performance under progressive prompting techniques, incorporating one-shot and few-shot prompting. Our results offer insights into LLMs' capacity for understanding complex psychological constructs and highlight best practices to mitigate ``semantic drift\" in therapeutic settings. Our work contributes not only to the MI community by providing a high-quality annotated dataset to address data scarcity in low-resource domains but also critical insights for using LLMs for precise contextual interpretation in complex behavioral therapy.",
        "url": "http://arxiv.org/abs/2511.22818v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22818v1",
        "arxiv_id": "2511.22818v1",
        "authors": [
            "Vivek Kumar",
            "Pushpraj Singh Rajawat",
            "Eirini Ntoutsi"
        ],
        "submitted": "2025-11-28 00:37:58",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Intelligent Neural Networks: From Layered Architectures to Graph-Organized Intelligence",
        "abstract": "Biological neurons exhibit remarkable intelligence: they maintain internal states, communicate selectively with other neurons, and self-organize into complex graphs rather than rigid hierarchical layers. What if artificial intelligence could emerge from similarly intelligent computational units? We introduce Intelligent Neural Networks (INN), a paradigm shift where neurons are first-class entities with internal memory and learned communication patterns, organized in complete graphs rather than sequential layers.\n  Each Intelligent Neuron combines selective state-space dynamics (knowing when to activate) with attention-based routing (knowing to whom to send signals), enabling emergent computation through graph-structured interactions. On the standard Text8 character modeling benchmark, INN achieves 1.705 Bit-Per-Character (BPC), significantly outperforming a comparable Transformer (2.055 BPC) and matching a highly optimized LSTM baseline. Crucially, a parameter-matched baseline of stacked Mamba blocks fails to converge (>3.4 BPC) under the same training protocol, demonstrating that INN's graph topology provides essential training stability. Ablation studies confirm this: removing inter-neuron communication degrades performance or leads to instability, proving the value of learned neural routing.\n  This work demonstrates that neuron-centric design with graph organization is not merely bio-inspired -- it is computationally effective, opening new directions for modular, interpretable, and scalable neural architectures.",
        "url": "http://arxiv.org/abs/2511.22813v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22813v1",
        "arxiv_id": "2511.22813v1",
        "authors": [
            "Antoine Salomon"
        ],
        "submitted": "2025-11-27 23:59:29",
        "source": "arxiv",
        "comment": "Code available at https://github.com/AntoineSal/IntelligentNeuralNetwork"
    },
    {
        "title": "PRISM: Privacy-Aware Routing for Adaptive Cloud-Edge LLM Inference via Semantic Sketch Collaboration",
        "abstract": "Large Language Models (LLMs) demonstrate impressive capabilities in natural language understanding and generation, but incur high communication overhead and privacy risks in cloud deployments, while facing compute and memory constraints when confined to edge devices. Cloud-edge inference has emerged as a promising paradigm for improving privacy in LLM services by retaining sensitive computations on local devices. However, existing cloud-edge inference approaches apply uniform privacy protection without considering input sensitivity, resulting in unnecessary perturbation and degraded utility even for non-sensitive tokens. To address this limitation, we propose Privacy-aware Routing for Inference with Semantic Modulation (PRISM), a context-aware framework that dynamically balances privacy and inference quality. PRISM executes in four stages: (1) the edge device profiles entity-level sensitivity; (2) a soft gating module on the edge selects an execution mode - cloud, edge, or collaboration; (3) for collaborative paths, the edge applies adaptive two-layer local differential privacy based on entity risks; and (4) the cloud LLM generates a semantic sketch from the perturbed prompt, which is then refined by the edge-side small language model (SLM) using local context. Our results show that PRISM consistently achieves superior privacy-utility trade-offs across various scenarios, reducing energy consumption and latency to 40-50% of baseline methods such as Uniform and Selective LDP, while maintaining high output quality under strong privacy constraints. These findings are validated through comprehensive evaluations involving realistic prompts, actual energy measurements, and heterogeneous cloud-edge model deployments.",
        "url": "http://arxiv.org/abs/2511.22788v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22788v1",
        "arxiv_id": "2511.22788v1",
        "authors": [
            "Junfei Zhan",
            "Haoxun Shen",
            "Zheng Lin",
            "Tengjiao He"
        ],
        "submitted": "2025-11-27 22:32:33",
        "source": "arxiv",
        "comment": "Accepted to AAAI 2026. This is the arXiv preprint version"
    },
    {
        "title": "Modeling Romanized Hindi and Bengali: Dataset Creation and Multilingual LLM Integration",
        "abstract": "The development of robust transliteration techniques to enhance the effectiveness of transforming Romanized scripts into native scripts is crucial for Natural Language Processing tasks, including sentiment analysis, speech recognition, information retrieval, and intelligent personal assistants. Despite significant advancements, state-of-the-art multilingual models still face challenges in handling Romanized script, where the Roman alphabet is adopted to represent the phonetic structure of diverse languages. Within the South Asian context, where the use of Romanized script for Indo-Aryan languages is widespread across social media and digital communication platforms, such usage continues to pose significant challenges for cutting-edge multilingual models. While a limited number of transliteration datasets and models are available for Indo-Aryan languages, they generally lack sufficient diversity in pronunciation and spelling variations, adequate code-mixed data for large language model (LLM) training, and low-resource adaptation. To address this research gap, we introduce a novel transliteration dataset for two popular Indo-Aryan languages, Hindi and Bengali, which are ranked as the 3rd and 7th most spoken languages worldwide. Our dataset comprises nearly 1.8 million Hindi and 1 million Bengali transliteration pairs. In addition to that, we pre-train a custom multilingual seq2seq LLM based on Marian architecture using the developed dataset. Experimental results demonstrate significant improvements compared to existing relevant models in terms of BLEU and CER metrics.",
        "url": "http://arxiv.org/abs/2511.22769v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22769v1",
        "arxiv_id": "2511.22769v1",
        "authors": [
            "Kanchon Gharami",
            "Quazi Sarwar Muhtaseem",
            "Deepti Gupta",
            "Lavanya Elluri",
            "Shafika Showkat Moni"
        ],
        "submitted": "2025-11-27 21:39:48",
        "source": "arxiv",
        "comment": "Proceedings of the 8th Workshop on Big Data for Cybersecurity (BigCyber)"
    },
    {
        "title": "ReAG: Reasoning-Augmented Generation for Knowledge-based Visual Question Answering",
        "abstract": "Multimodal Large Language Models (MLLMs) have shown impressive capabilities in jointly understanding text, images, and videos, often evaluated via Visual Question Answering (VQA). However, even state-of-the-art MLLMs struggle with domain-specific or knowledge-intensive queries, where relevant information is underrepresented in pre-training data. Knowledge-based VQA (KB-VQA) addresses this by retrieving external documents to condition answer generation, but current retrieval-augmented approaches suffer from low precision, noisy passages, and limited reasoning. To address this, we propose ReAG, a novel Reasoning-Augmented Multimodal RAG approach that combines coarse- and fine-grained retrieval with a critic model that filters irrelevant passages, ensuring high-quality additional context. The model follows a multi-stage training strategy leveraging reinforcement learning to enhance reasoning over retrieved content, while supervised fine-tuning serves only as a cold start. Extensive experiments on Encyclopedic-VQA and InfoSeek demonstrate that ReAG significantly outperforms prior methods, improving answer accuracy and providing interpretable reasoning grounded in retrieved evidence. Our source code is publicly available at: https://github.com/aimagelab/ReAG.",
        "url": "http://arxiv.org/abs/2511.22715v1",
        "pdf_url": "https://arxiv.org/pdf/2511.22715v1",
        "arxiv_id": "2511.22715v1",
        "authors": [
            "Alberto Compagnoni",
            "Marco Morini",
            "Sara Sarto",
            "Federico Cocchi",
            "Davide Caffagni",
            "Marcella Cornia",
            "Lorenzo Baraldi",
            "Rita Cucchiara"
        ],
        "submitted": "2025-11-27 19:01:02",
        "source": "arxiv",
        "comment": null
    }
]