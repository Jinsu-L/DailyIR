[
    {
        "title": "FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval",
        "abstract": "Financial disclosures such as 10-K filings present challenging retrieval\nproblems due to their length, regulatory section hierarchy, and domain-specific\nlanguage, which standard retrieval-augmented generation (RAG) models underuse.\nWe introduce FinGEAR (Financial Mapping-Guided Enhanced Answer Retrieval), a\nretrieval framework tailored to financial documents. FinGEAR combines a finance\nlexicon for Item-level guidance (FLAM), dual hierarchical indices for\nwithin-Item search (Summary Tree and Question Tree), and a two-stage\ncross-encoder reranker. This design aligns retrieval with disclosure structure\nand terminology, enabling fine-grained, query-aware context selection.\nEvaluated on full 10-Ks with queries aligned to the FinQA dataset, FinGEAR\ndelivers consistent gains in precision, recall, F1, and relevancy, improving F1\nby up to 56.7% over flat RAG, 12.5% over graph-based RAGs, and 217.6% over\nprior tree-based systems, while also increasing downstream answer accuracy with\na fixed reader. By jointly modeling section hierarchy and domain lexicon\nsignals, FinGEAR improves retrieval fidelity and provides a practical\nfoundation for high-stakes financial analysis.",
        "url": "http://arxiv.org/abs/2509.12042v1",
        "pdf_url": "http://arxiv.org/pdf/2509.12042v1",
        "arxiv_id": "2509.12042v1",
        "authors": [
            "Ying Li",
            "Mengyu Wang",
            "Miguel de Carvalho",
            "Sotirios Sabanis",
            "Tiejun Ma"
        ],
        "submitted": "2025-09-15 15:25:26",
        "source": "arxiv",
        "comment": null,
        "score": 15,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to Information Retrieval, specifically in the area of query understanding and ranking models, with a focus on financial documents. Although it's domain-specific, the techniques and methods described can be applied to other areas of IR, making it a useful read. The use of hierarchical indices and cross-encoder reranker is particularly interesting for its potential to improve retrieval fidelity."
    },
    {
        "title": "MillStone: How Open-Minded Are LLMs?",
        "abstract": "Large language models equipped with Web search, information retrieval tools,\nand other agentic capabilities are beginning to supplant traditional search\nengines. As users start to rely on LLMs for information on many topics,\nincluding controversial and debatable issues, it is important to understand how\nthe stances and opinions expressed in LLM outputs are influenced by the\ndocuments they use as their information sources.\n  In this paper, we present MillStone, the first benchmark that aims to\nsystematically measure the effect of external arguments on the stances that\nLLMs take on controversial issues (not all of them political). We apply\nMillStone to nine leading LLMs and measure how ``open-minded'' they are to\narguments supporting opposite sides of these issues, whether different LLMs\nagree with each other, which arguments LLMs find most persuasive, and whether\nthese arguments are the same for different LLMs.\n  In general, we find that LLMs are open-minded on most issues. An\nauthoritative source of information can easily sway an LLM's stance,\nhighlighting the importance of source selection and the risk that LLM-based\ninformation retrieval and search systems can be manipulated.",
        "url": "http://arxiv.org/abs/2509.11967v2",
        "pdf_url": "http://arxiv.org/pdf/2509.11967v2",
        "arxiv_id": "2509.11967v2",
        "authors": [
            "Harold Triedman",
            "Vitaly Shmatikov"
        ],
        "submitted": "2025-09-15 14:18:51",
        "source": "arxiv",
        "comment": "19 pages, 7 tables, 7 figures",
        "score": 7,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'web search' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper explores the interaction between Large Language Models (LLMs) and information retrieval, which is relevant to your interests in Information Retrieval and Search technologies. However, the focus on LLMs and their potential manipulation through source selection is somewhat tangential to your core research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Unsupervised Candidate Ranking for Lexical Substitution via Holistic Sentence Semantics",
        "abstract": "A key subtask in lexical substitution is ranking the given candidate words. A\ncommon approach is to replace the target word with a candidate in the original\nsentence and feed the modified sentence into a model to capture semantic\ndifferences before and after substitution. However, effectively modeling the\nbidirectional influence of candidate substitution on both the target word and\nits context remains challenging. Existing methods often focus solely on\nsemantic changes at the target position or rely on parameter tuning over\nmultiple evaluation metrics, making it difficult to accurately characterize\nsemantic variation. To address this, we investigate two approaches: one based\non attention weights and another leveraging the more interpretable integrated\ngradients method, both designed to measure the influence of context tokens on\nthe target token and to rank candidates by incorporating semantic similarity\nbetween the original and substituted sentences. Experiments on the LS07 and\nSWORDS datasets demonstrate that both approaches improve ranking performance.",
        "url": "http://arxiv.org/abs/2509.11513v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11513v1",
        "arxiv_id": "2509.11513v1",
        "authors": [
            "Zhongyang Hu",
            "Naijie Gu",
            "Xiangzhi Tao",
            "Tianhui Gu",
            "Yibing Zhou"
        ],
        "submitted": "2025-09-15 01:57:09",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores ranking models for lexical substitution, which is somewhat related to the user's interests in ranking models and query understanding. However, the focus is on a specific task within NLP, and the paper does not directly address the user's core research themes in Information Retrieval or e-commerce. The use of attention weights and integrated gradients is an interesting approach, but it is not directly applicable to the user's areas of interest."
    },
    {
        "title": "AKCIT-FN at CheckThat! 2025: Switching Fine-Tuned SLMs and LLM Prompting for Multilingual Claim Normalization",
        "abstract": "Claim normalization, the transformation of informal social media posts into\nconcise, self-contained statements, is a crucial step in automated\nfact-checking pipelines. This paper details our submission to the CLEF-2025\nCheckThat! Task~2, which challenges systems to perform claim normalization\nacross twenty languages, divided into thirteen supervised (high-resource) and\nseven zero-shot (no training data) tracks.\n  Our approach, leveraging fine-tuned Small Language Models (SLMs) for\nsupervised languages and Large Language Model (LLM) prompting for zero-shot\nscenarios, achieved podium positions (top three) in fifteen of the twenty\nlanguages. Notably, this included second-place rankings in eight languages,\nfive of which were among the seven designated zero-shot languages, underscoring\nthe effectiveness of our LLM-based zero-shot strategy. For Portuguese, our\ninitial development language, our system achieved an average METEOR score of\n0.5290, ranking third. All implementation artifacts, including inference,\ntraining, evaluation scripts, and prompt configurations, are publicly available\nat https://github.com/ju-resplande/checkthat2025_normalization.",
        "url": "http://arxiv.org/abs/2509.11496v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11496v1",
        "arxiv_id": "2509.11496v1",
        "authors": [
            "Fabrycio Leite Nakano Almada",
            "Kauan Divino Pouso Mariano",
            "Maykon Adriell Dutra",
            "Victor Emanuel da Silva Monteiro",
            "Juliana Resplande Sant'Anna Gomes",
            "Arlindo Rodrigues Galv√£o Filho",
            "Anderson da Silva Soares"
        ],
        "submitted": "2025-09-15 01:19:49",
        "source": "arxiv",
        "comment": "15 pages, 2 figures",
        "score": 6,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to the user's interests in Natural Language Processing (NLP) and Information Retrieval (IR), particularly in the context of claim normalization and fact-checking pipelines. However, it does not directly address the user's core research themes of query understanding, ranking models, or user behavior modeling. The paper's focus on multilingual claim normalization and Large Language Model (LLM) prompting is an interesting aspect, but it does not align closely with the user's primary research interests."
    },
    {
        "title": "Query-Focused Extractive Summarization for Sentiment Explanation",
        "abstract": "Constructive analysis of feedback from clients often requires determining the\ncause of their sentiment from a substantial amount of text documents. To assist\nand improve the productivity of such endeavors, we leverage the task of\nQuery-Focused Summarization (QFS). Models of this task are often impeded by the\nlinguistic dissonance between the query and the source documents. We propose\nand substantiate a multi-bias framework to help bridge this gap at a\ndomain-agnostic, generic level; we then formulate specialized approaches for\nthe problem of sentiment explanation through sentiment-based biases and query\nexpansion. We achieve experimental results outperforming baseline models on a\nreal-world proprietary sentiment-aware QFS dataset.",
        "url": "http://arxiv.org/abs/2509.11989v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11989v1",
        "arxiv_id": "2509.11989v1",
        "authors": [
            "Ahmed Moubtahij",
            "Sylvie Ratt√©",
            "Yazid Attabi",
            "Maxime Dumas"
        ],
        "submitted": "2025-09-15 14:41:18",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper explores Query-Focused Summarization, which is related to query understanding in Information Retrieval. However, the focus on sentiment explanation and summarization is somewhat tangential to the user's primary interests in ranking models and user behavior modeling."
    },
    {
        "title": "MOOM: Maintenance, Organization and Optimization of Memory in Ultra-Long Role-Playing Dialogues",
        "abstract": "Memory extraction is crucial for maintaining coherent ultra-long dialogues in\nhuman-robot role-playing scenarios. However, existing methods often exhibit\nuncontrolled memory growth. To address this, we propose MOOM, the first\ndual-branch memory plugin that leverages literary theory by modeling plot\ndevelopment and character portrayal as core storytelling elements.\nSpecifically, one branch summarizes plot conflicts across multiple time scales,\nwhile the other extracts the user's character profile. MOOM further integrates\na forgetting mechanism, inspired by the ``competition-inhibition'' memory\ntheory, to constrain memory capacity and mitigate uncontrolled growth.\nFurthermore, we present ZH-4O, a Chinese ultra-long dialogue dataset\nspecifically designed for role-playing, featuring dialogues that average 600\nturns and include manually annotated memory information. Experimental results\ndemonstrate that MOOM outperforms all state-of-the-art memory extraction\nmethods, requiring fewer large language model invocations while maintaining a\ncontrollable memory capacity.",
        "url": "http://arxiv.org/abs/2509.11860v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11860v1",
        "arxiv_id": "2509.11860v1",
        "authors": [
            "Weishu Chen",
            "Jinyi Tang",
            "Zhouhui Hou",
            "Shihao Han",
            "Mingjie Zhan",
            "Zhiyuan Huang",
            "Delong Liu",
            "Jiawei Guo",
            "Zhicheng Zhao",
            "Fei Su"
        ],
        "submitted": "2025-09-15 12:35:14",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'ltr' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on memory extraction in role-playing dialogues, leveraging literary theory and a forgetting mechanism. While it involves NLP and deep semantic understanding, its primary focus is on memory management in a specific domain, which is not directly related to information retrieval, search technologies, or user behavior modeling."
    },
    {
        "title": "A Dynamic Knowledge Update-Driven Model with Large Language Models for Fake News Detection",
        "abstract": "As the Internet and social media evolve rapidly, distinguishing credible news\nfrom a vast amount of complex information poses a significant challenge. Due to\nthe suddenness and instability of news events, the authenticity labels of news\ncan potentially shift as events develop, making it crucial for fake news\ndetection to obtain the latest event updates. Existing methods employ\nretrieval-augmented generation to fill knowledge gaps, but they suffer from\nissues such as insufficient credibility of retrieved content and interference\nfrom noisy information. We propose a dynamic knowledge update-driven model for\nfake news detection (DYNAMO), which leverages knowledge graphs to achieve\ncontinuous updating of new knowledge and integrates with large language models\nto fulfill dual functions: news authenticity detection and verification of new\nknowledge correctness, solving the two key problems of ensuring the\nauthenticity of new knowledge and deeply mining news semantics. Specifically,\nwe first construct a news-domain-specific knowledge graph. Then, we use Monte\nCarlo Tree Search to decompose complex news and verify them step by step.\nFinally, we extract and update new knowledge from verified real news texts and\nreasoning paths. Experimental results demonstrate that DYNAMO achieves the best\nperformance on two real-world datasets.",
        "url": "http://arxiv.org/abs/2509.11687v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11687v1",
        "arxiv_id": "2509.11687v1",
        "authors": [
            "Di Jin",
            "Jun Yang",
            "Xiaobao Wang",
            "Junwei Zhang",
            "Shuqi Li",
            "Dongxiao He"
        ],
        "submitted": "2025-09-15 08:38:08",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it involves fake news detection and knowledge graph construction. However, the focus on fake news detection and large language models is not directly aligned with your primary interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "RAGs to Riches: RAG-like Few-shot Learning for Large Language Model Role-playing",
        "abstract": "Role-playing Large language models (LLMs) are increasingly deployed in\nhigh-stakes domains such as healthcare, education, and governance, where\nfailures can directly impact user trust and well-being. A cost effective\nparadigm for LLM role-playing is few-shot learning, but existing approaches\noften cause models to break character in unexpected and potentially harmful\nways, especially when interacting with hostile users. Inspired by\nRetrieval-Augmented Generation (RAG), we reformulate LLM role-playing into a\ntext retrieval problem and propose a new prompting framework called\nRAGs-to-Riches, which leverages curated reference demonstrations to condition\nLLM responses. We evaluate our framework with LLM-as-a-judge preference voting\nand introduce two novel token-level ROUGE metrics: Intersection over Output\n(IOO) to quantity how much an LLM improvises and Intersection over References\n(IOR) to measure few-shot demonstrations utilization rate during the evaluation\ntasks. When simulating interactions with a hostile user, our prompting strategy\nincorporates in its responses during inference an average of 35% more tokens\nfrom the reference demonstrations. As a result, across 453 role-playing\ninteractions, our models are consistently judged as being more authentic, and\nremain in-character more often than zero-shot and in-context Learning (ICL)\nmethods. Our method presents a scalable strategy for building robust,\nhuman-aligned LLM role-playing frameworks.",
        "url": "http://arxiv.org/abs/2509.12168v1",
        "pdf_url": "http://arxiv.org/pdf/2509.12168v1",
        "arxiv_id": "2509.12168v1",
        "authors": [
            "Timothy Rupprecht",
            "Enfu Nan",
            "Arash Akbari",
            "Arman Akbari",
            "Lei Lu",
            "Priyanka Maan",
            "Sean Duffy",
            "Pu Zhao",
            "Yumei He",
            "David Kaeli",
            "Yanzhi Wang"
        ],
        "submitted": "2025-09-15 17:31:15",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Large Language Model role-playing and few-shot learning, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve text retrieval and generation, the context and application are quite different from your areas of focus."
    },
    {
        "title": "XplaiNLP at CheckThat! 2025: Multilingual Subjectivity Detection with Finetuned Transformers and Prompt-Based Inference with Large Language Models",
        "abstract": "This notebook reports the XplaiNLP submission to the CheckThat! 2025 shared\ntask on multilingual subjectivity detection. We evaluate two approaches: (1)\nsupervised fine-tuning of transformer encoders, EuroBERT, XLM-RoBERTa, and\nGerman-BERT, on monolingual and machine-translated training data; and (2)\nzero-shot prompting using two LLMs: o3-mini for Annotation (rule-based\nlabelling) and gpt-4.1-mini for DoubleDown (contrastive rewriting) and\nPerspective (comparative reasoning). The Annotation Approach achieves 1st place\nin the Italian monolingual subtask with an F_1 score of 0.8104, outperforming\nthe baseline of 0.6941. In the Romanian zero-shot setting, the fine-tuned\nXLM-RoBERTa model obtains an F_1 score of 0.7917, ranking 3rd and exceeding the\nbaseline of 0.6461. The same model also performs reliably in the multilingual\ntask and improves over the baseline in Greek. For German, a German-BERT model\nfine-tuned on translated training data from typologically related languages\nyields competitive performance over the baseline. In contrast, performance in\nthe Ukrainian and Polish zero-shot settings falls slightly below the respective\nbaselines, reflecting the challenge of generalization in low-resource\ncross-lingual scenarios.",
        "url": "http://arxiv.org/abs/2509.12130v1",
        "pdf_url": "http://arxiv.org/pdf/2509.12130v1",
        "arxiv_id": "2509.12130v1",
        "authors": [
            "Ariana Sahitaj",
            "Jiaao Li",
            "Pia Wenzel Neves",
            "Fedor Splitt",
            "Premtim Sahitaj",
            "Charlott Jakob",
            "Veronika Solopova",
            "Vera Schmitt"
        ],
        "submitted": "2025-09-15 16:53:41",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multilingual subjectivity detection using NLP techniques, which is somewhat related to the user's interests in NLP and IR. However, the specific topic of subjectivity detection and the use of large language models for inference are not directly aligned with the user's core research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "SAQ: Pushing the Limits of Vector Quantization through Code Adjustment and Dimension Segmentation",
        "abstract": "Approximate Nearest Neighbor Search (ANNS) plays a critical role in\napplications such as search engines, recommender systems, and RAG for LLMs.\nVector quantization (VQ), a crucial technique for ANNS, is commonly used to\nreduce space overhead and accelerate distance computations. However, despite\nsignificant research advances, state-of-the-art VQ methods still face\nchallenges in balancing encoding efficiency and quantization accuracy. To\naddress these limitations, we propose a novel VQ method called SAQ. To improve\naccuracy, SAQ employs a new dimension segmentation technique to strategically\npartition PCA-projected vectors into segments along their dimensions. By\nprioritizing leading dimension segments with larger magnitudes, SAQ allocates\nmore bits to high-impact segments, optimizing the use of the available space\nquota. An efficient dynamic programming algorithm is developed to optimize\ndimension segmentation and bit allocation, ensuring minimal quantization error.\nTo speed up vector encoding, SAQ devises a code adjustment technique to first\nquantize each dimension independently and then progressively refine quantized\nvectors using a coordinate-descent-like approach to avoid exhaustive\nenumeration. Extensive experiments demonstrate SAQ's superiority over classical\nmethods (e.g., PQ, PCA) and recent state-of-the-art approaches (e.g., LVQ,\nExtended RabitQ). SAQ achieves up to 80% reduction in quantization error and\naccelerates encoding speed by over 80x compared to Extended RabitQ.",
        "url": "http://arxiv.org/abs/2509.12086v1",
        "pdf_url": "http://arxiv.org/pdf/2509.12086v1",
        "arxiv_id": "2509.12086v1",
        "authors": [
            "Hui Li",
            "Shiyuan Deng",
            "Xiao Yan",
            "Xiangyu Zhi",
            "James Cheng"
        ],
        "submitted": "2025-09-15 16:14:05",
        "source": "arxiv",
        "comment": "13 pages, 12 figures, accepted by SIGMOD",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Vector Quantization, a technique used in Approximate Nearest Neighbor Search, which is relevant to Recommender Systems. However, it does not directly relate to Information Retrieval, query understanding, ranking models, or user behavior modeling, which are the core areas of your research interests."
    },
    {
        "title": "Analyzing Information-Seeking Behaviors in a Hakka AI Chatbot: A Cognitive-Pragmatic Study",
        "abstract": "With many endangered languages at risk of disappearing, efforts to preserve\nthem now rely more than ever on using technology alongside culturally informed\nteaching strategies. This study examines user behaviors in TALKA, a generative\nAI-powered chatbot designed for Hakka language engagement, by employing a\ndual-layered analytical framework grounded in Bloom's Taxonomy of cognitive\nprocesses and dialogue act categorization. We analyzed 7,077 user utterances,\neach carefully annotated according to six cognitive levels and eleven dialogue\nact types. These included a variety of functions, such as asking for\ninformation, requesting translations, making cultural inquiries, and using\nlanguage creatively. Pragmatic classifications further highlight how different\ntypes of dialogue acts--such as feedback, control commands, and social\ngreetings--align with specific cognitive intentions. The results suggest that\ngenerative AI chatbots can support language learning in meaningful\nways--especially when they are designed with an understanding of how users\nthink and communicate. They may also help learners express themselves more\nconfidently and connect with their cultural identity. The TALKA case provides\nempirical insights into how AI-mediated dialogue facilitates cognitive\ndevelopment in low-resource language learners, as well as pragmatic negotiation\nand socio-cultural affiliation. By focusing on AI-assisted language learning,\nthis study offers new insights into how technology can support language\npreservation and educational practice.",
        "url": "http://arxiv.org/abs/2509.11591v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11591v1",
        "arxiv_id": "2509.11591v1",
        "authors": [
            "Chu-Hsuan Lee",
            "Chen-Chi Chang",
            "Hung-Shin Lee",
            "Yun-Hsiang Hsu",
            "Ching-Yuan Chen"
        ],
        "submitted": "2025-09-15 05:18:17",
        "source": "arxiv",
        "comment": "Accepted to HICSS-59 (2026)",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'user behavior' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to Information Retrieval, but its focus on AI-assisted language learning and language preservation is not a central match to your primary research interests in query understanding, ranking models, and user behavior modeling. However, the study's use of a generative AI chatbot and analysis of user behaviors may provide some insights into user behavior modeling, which is a related topic."
    },
    {
        "title": "HiChunk: Evaluating and Enhancing Retrieval-Augmented Generation with Hierarchical Chunking",
        "abstract": "Retrieval-Augmented Generation (RAG) enhances the response capabilities of\nlanguage models by integrating external knowledge sources. However, document\nchunking as an important part of RAG system often lacks effective evaluation\ntools. This paper first analyzes why existing RAG evaluation benchmarks are\ninadequate for assessing document chunking quality, specifically due to\nevidence sparsity. Based on this conclusion, we propose HiCBench, which\nincludes manually annotated multi-level document chunking points, synthesized\nevidence-dense quetion answer(QA) pairs, and their corresponding evidence\nsources. Additionally, we introduce the HiChunk framework, a multi-level\ndocument structuring framework based on fine-tuned LLMs, combined with the\nAuto-Merge retrieval algorithm to improve retrieval quality. Experiments\ndemonstrate that HiCBench effectively evaluates the impact of different\nchunking methods across the entire RAG pipeline. Moreover, HiChunk achieves\nbetter chunking quality within reasonable time consumption, thereby enhancing\nthe overall performance of RAG systems.",
        "url": "http://arxiv.org/abs/2509.11552v2",
        "pdf_url": "http://arxiv.org/pdf/2509.11552v2",
        "arxiv_id": "2509.11552v2",
        "authors": [
            "Wensheng Lu",
            "Keyu Chen",
            "Ruizhi Qiao",
            "Xing Sun"
        ],
        "submitted": "2025-09-15 03:32:50",
        "source": "arxiv",
        "comment": "17 pages, 5 figures, 6 tables",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on Retrieval-Augmented Generation (RAG) and proposes a new evaluation framework (HiCBench) and a document structuring framework (HiChunk). While it touches on information retrieval, its primary focus is on language models and generation, which is somewhat related to the user's interests in query understanding and ranking models, but not a central match."
    },
    {
        "title": "CEMTM: Contextual Embedding-based Multimodal Topic Modeling",
        "abstract": "We introduce CEMTM, a context-enhanced multimodal topic model designed to\ninfer coherent and interpretable topic structures from both short and long\ndocuments containing text and images. CEMTM builds on fine-tuned large vision\nlanguage models (LVLMs) to obtain contextualized embeddings, and employs a\ndistributional attention mechanism to weight token-level contributions to topic\ninference. A reconstruction objective aligns topic-based representations with\nthe document embedding, encouraging semantic consistency across modalities.\nUnlike existing approaches, CEMTM can process multiple images per document\nwithout repeated encoding and maintains interpretability through explicit\nword-topic and document-topic distributions. Extensive experiments on six\nmultimodal benchmarks show that CEMTM consistently outperforms unimodal and\nmultimodal baselines, achieving a remarkable average LLM score of 2.61. Further\nanalysis shows its effectiveness in downstream few-shot retrieval and its\nability to capture visually grounded semantics in complex domains such as\nscientific articles.",
        "url": "http://arxiv.org/abs/2509.11465v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11465v1",
        "arxiv_id": "2509.11465v1",
        "authors": [
            "Amirhossein Abaskohi",
            "Raymond Li",
            "Chuyuan Li",
            "Shafiq Joty",
            "Giuseppe Carenini"
        ],
        "submitted": "2025-09-14 23:07:46",
        "source": "arxiv",
        "comment": "EMNLP 2025",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper introduces a multimodal topic model that leverages contextualized embeddings and attention mechanisms for topic inference. While it touches on aspects of information retrieval and semantic understanding, its primary focus is on multimodal topic modeling, which is somewhat related to your interests in query understanding and ranking models. However, the paper's emphasis on multimodal processing and visual semantics is not a central match for your research themes."
    },
    {
        "title": "AEFS: Adaptive Early Feature Selection for Deep Recommender Systems",
        "abstract": "Feature selection has emerged as a crucial technique in refining recommender\nsystems. Recent advancements leveraging Automated Machine Learning (AutoML) has\ndrawn significant attention, particularly in two main categories: early feature\nselection and late feature selection, differentiated by whether the selection\noccurs before or after the embedding layer. The early feature selection selects\na fixed subset of features and retrains the model, while the late feature\nselection, known as adaptive feature selection, dynamically adjusts feature\nchoices for each data instance, recognizing the variability in feature\nsignificance. Although adaptive feature selection has shown remarkable\nimprovements in performance, its main drawback lies in its post-embedding layer\nfeature selection. This process often becomes cumbersome and inefficient in\nlarge-scale recommender systems with billions of ID-type features, leading to a\nhighly sparse and parameter-heavy embedding layer. To overcome this, we\nintroduce Adaptive Early Feature Selection (AEFS), a very simple method that\nnot only adaptively selects informative features for each instance, but also\nsignificantly reduces the activated parameters of the embedding layer. AEFS\nemploys a dual-model architecture, encompassing an auxiliary model dedicated to\nfeature selection and a main model responsible for prediction. To ensure\neffective alignment between these two models, we incorporate two collaborative\ntraining loss constraints. Our extensive experiments on three benchmark\ndatasets validate the efficiency and effectiveness of our approach. Notably,\nAEFS matches the performance of current state-of-theart Adaptive Late Feature\nSelection methods while achieving a significant reduction of 37. 5% in the\nactivated parameters of the embedding layer. AEFS is open-source at\nhttps://github. com/fly-dragon211/AEFS .",
        "url": "http://arxiv.org/abs/2509.12076v1",
        "pdf_url": "http://arxiv.org/pdf/2509.12076v1",
        "arxiv_id": "2509.12076v1",
        "authors": [
            "Fan Hu",
            "Gaofeng Lu",
            "Jun Chen",
            "Chaonan Guo",
            "Yuekui Yang",
            "Xirong Li"
        ],
        "submitted": "2025-09-15 16:04:24",
        "source": "arxiv",
        "comment": "Accepted by TKDE",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on recommender systems, specifically introducing a new method called Adaptive Early Feature Selection (AEFS). While it leverages machine learning and AutoML, it doesn't directly relate to information retrieval, query understanding, ranking models, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "How to Evaluate Medical AI",
        "abstract": "The integration of artificial intelligence (AI) into medical diagnostic\nworkflows requires robust and consistent evaluation methods to ensure\nreliability, clinical relevance, and the inherent variability in expert\njudgments. Traditional metrics like precision and recall often fail to account\nfor the inherent variability in expert judgments, leading to inconsistent\nassessments of AI performance. Inter-rater agreement statistics like Cohen's\nKappa are more reliable but they lack interpretability. We introduce Relative\nPrecision and Recall of Algorithmic Diagnostics (RPAD and RRAD) - a new\nevaluation metrics that compare AI outputs against multiple expert opinions\nrather than a single reference. By normalizing performance against inter-expert\ndisagreement, these metrics provide a more stable and realistic measure of the\nquality of predicted diagnosis. In addition to the comprehensive analysis of\ndiagnostic quality measures, our study contains a very important side result.\nOur evaluation methodology allows us to avoid selecting diagnoses from a\nlimited list when evaluating a given case. Instead, both the models being\ntested and the examiners verifying them arrive at a free-form diagnosis. In\nthis automated methodology for establishing the identity of free-form clinical\ndiagnoses, a remarkable 98% accuracy becomes attainable. We evaluate our\napproach using 360 medical dialogues, comparing multiple large language models\n(LLMs) against a panel of physicians. Large-scale study shows that\ntop-performing models, such as DeepSeek-V3, achieve consistency on par with or\nexceeding expert consensus. Moreover, we demonstrate that expert judgments\nexhibit significant variability - often greater than that between AI and\nhumans. This finding underscores the limitations of any absolute metrics and\nsupports the need to adopt relative metrics in medical AI.",
        "url": "http://arxiv.org/abs/2509.11941v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11941v1",
        "arxiv_id": "2509.11941v1",
        "authors": [
            "Ilia Kopanichuk",
            "Petr Anokhin",
            "Vladimir Shaposhnikov",
            "Vladimir Makharev",
            "Ekaterina Tsapieva",
            "Iaroslav Bespalov",
            "Dmitry V. Dylov",
            "Ivan Oseledets"
        ],
        "submitted": "2025-09-15 14:01:22",
        "source": "arxiv",
        "comment": "10 pages, 7 fugures",
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves AI and large language models, the focus is on medical AI evaluation and diagnosis, which is outside your primary domain of e-commerce and related areas."
    },
    {
        "title": "From Fuzzy Speech to Medical Insight: Benchmarking LLMs on Noisy Patient Narratives",
        "abstract": "The widespread adoption of large language models (LLMs) in healthcare raises\ncritical questions about their ability to interpret patient-generated\nnarratives, which are often informal, ambiguous, and noisy. Existing benchmarks\ntypically rely on clean, structured clinical text, offering limited insight\ninto model performance under realistic conditions. In this work, we present a\nnovel synthetic dataset designed to simulate patient self-descriptions\ncharacterized by varying levels of linguistic noise, fuzzy language, and\nlayperson terminology. Our dataset comprises clinically consistent scenarios\nannotated with ground-truth diagnoses, spanning a spectrum of communication\nclarity to reflect diverse real-world reporting styles. Using this benchmark,\nwe fine-tune and evaluate several state-of-the-art models (LLMs), including\nBERT-based and encoder-decoder T5 models. To support reproducibility and future\nresearch, we release the Noisy Diagnostic Benchmark (NDB), a structured dataset\nof noisy, synthetic patient descriptions designed to stress-test and compare\nthe diagnostic capabilities of large language models (LLMs) under realistic\nlinguistic conditions. We made the benchmark available for the community:\nhttps://github.com/lielsheri/PatientSignal",
        "url": "http://arxiv.org/abs/2509.11803v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11803v1",
        "arxiv_id": "2509.11803v1",
        "authors": [
            "Eden Mama",
            "Liel Sheri",
            "Yehudit Aperstein",
            "Alexander Apartsin"
        ],
        "submitted": "2025-09-15 11:34:46",
        "source": "arxiv",
        "comment": "6 pages, 1 figure",
        "score": 3,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and deep semantic understanding, but it is not directly focused on Information Retrieval (IR) or Search technologies. The paper explores the application of LLMs in healthcare, which is an area that may be tangentially related to your e-commerce background, but it does not appear to be a central match for your primary research themes."
    },
    {
        "title": "When Curiosity Signals Danger: Predicting Health Crises Through Online Medication Inquiries",
        "abstract": "Online medical forums are a rich and underutilized source of insight into\npatient concerns, especially regarding medication use. Some of the many\nquestions users pose may signal confusion, misuse, or even the early warning\nsigns of a developing health crisis. Detecting these critical questions that\nmay precede severe adverse events or life-threatening complications is vital\nfor timely intervention and improving patient safety. This study introduces a\nnovel annotated dataset of medication-related questions extracted from online\nforums. Each entry is manually labelled for criticality based on clinical risk\nfactors. We benchmark the performance of six traditional machine learning\nclassifiers using TF-IDF textual representations, alongside three\nstate-of-the-art large language model (LLM)-based classification approaches\nthat leverage deep contextual understanding. Our results highlight the\npotential of classical and modern methods to support real-time triage and alert\nsystems in digital health spaces. The curated dataset is made publicly\navailable to encourage further research at the intersection of\npatient-generated data, natural language processing, and early warning systems\nfor critical health events. The dataset and benchmark are available at:\nhttps://github.com/Dvora-coder/LLM-Medication-QA-Risk-Classifier-MediGuard.",
        "url": "http://arxiv.org/abs/2509.11802v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11802v1",
        "arxiv_id": "2509.11802v1",
        "authors": [
            "Dvora Goncharok",
            "Arbel Shifman",
            "Alexander Apartsin",
            "Yehudit Aperstein"
        ],
        "submitted": "2025-09-15 11:31:25",
        "source": "arxiv",
        "comment": "5 pages, 2 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and data mining, as it involves text classification and the use of large language models. However, the focus on health crises and medication inquiries is not directly aligned with your primary interest in Information Retrieval, especially in e-commerce or real-time relevance optimization."
    },
    {
        "title": "User eXperience Perception Insights Dataset (UXPID): Synthetic User Feedback from Public Industrial Forums",
        "abstract": "Customer feedback in industrial forums reflect a rich but underexplored\nsource of insight into real-world product experience. These publicly shared\ndiscussions offer an organic view of user expectations, frustrations, and\nsuccess stories shaped by the specific contexts of use. Yet, harnessing this\ninformation for systematic analysis remains challenging due to the unstructured\nand domain-specific nature of the content. The lack of structure and\nspecialized vocabulary makes it difficult for traditional data analysis\ntechniques to accurately interpret, categorize, and quantify the feedback,\nthereby limiting its potential to inform product development and support\nstrategies. To address these challenges, this paper presents the User\neXperience Perception Insights Dataset (UXPID), a collection of 7130\nartificially synthesized and anonymized user feedback branches extracted from a\npublic industrial automation forum. Each JavaScript object notation (JSON)\nrecord contains multi-post comments related to specific hardware and software\nproducts, enriched with metadata and contextual conversation data. Leveraging a\nlarge language model (LLM), each branch is systematically analyzed and\nannotated for UX insights, user expectations, severity and sentiment ratings,\nand topic classifications. The UXPID dataset is designed to facilitate research\nin user requirements, user experience (UX) analysis, and AI-driven feedback\nprocessing, particularly where privacy and licensing restrictions limit access\nto real-world data. UXPID supports the training and evaluation of\ntransformer-based models for tasks such as issue detection, sentiment analysis,\nand requirements extraction in the context of technical forums.",
        "url": "http://arxiv.org/abs/2509.11777v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11777v1",
        "arxiv_id": "2509.11777v1",
        "authors": [
            "Mikhail Kulyabin",
            "Jan Joosten",
            "Choro Ulan uulu",
            "Nuno Miguel Martins Pacheco",
            "Fabian Ries",
            "Filippos Petridis",
            "Jan Bosch",
            "Helena Holmstr√∂m Olsson"
        ],
        "submitted": "2025-09-15 10:58:41",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper presents a dataset for user experience analysis in industrial forums, which is somewhat related to information retrieval and user behavior modeling. However, the focus is on data analysis and annotation rather than query understanding, ranking models, or real-time relevance optimization, making it less directly relevant to your core research interests."
    },
    {
        "title": "MindVL: Towards Efficient and Effective Training of Multimodal Large Language Models on Ascend NPUs",
        "abstract": "We propose MindVL, a multimodal large langauge model trained on Ascend NPUs.\nSimilar to Qwen2.5-VL, MindVL adopts native-resolution Vision Transformers,\nwhich enables it to process images at their original variable resolutions. This\ndesign avoids the degradation caused by fixed-resolution tiling while\npreserving fine-grained details and global layouts, which is crucial for\nvisually dense content such as complex charts and diagrams. To ensure the\nsmooth training of MindVL on Ascend NPUs, we develop Mindspeed-MLLM, a\ndistributed multimodal training framework tailored for Ascend NPUs. To maintain\ntraining accuracy, we implement equivalent replacements for certain operators.\nMindVL undergoes a three-phase training process, namely the warm-up phase,\nmultitask training phase, and supervised instruction tuning phase, to gradually\nenhance its capabilities. This process starts with basic visual and multimodal\npre-training, followed by large-scale multiask trainging and instruction\ntuning. We also adopt multimodal data packaging and hybrid parallelism\ntechniques, which significantly improve end-to-end training speed. To further\nboost model performance, we specifically introduce test-time resolution search\nand model weight averaging. Notably, despite using about 1/10 of the training\ndata required by Qwen2.5-VL, MindVL achieves performance on par with Qwen2.5-VL\nin evaluations of general multimodal understanding and document/table\ncomprehension. Beyond overall scores, MindVL also delivers leading performance\nin OCR assessments.",
        "url": "http://arxiv.org/abs/2509.11662v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11662v1",
        "arxiv_id": "2509.11662v1",
        "authors": [
            "Feilong Chen",
            "Yijiang Liu",
            "Yi Huang",
            "Hao Wang",
            "Miren Tian",
            "Ya-Qi Yu",
            "Minghui Liao",
            "Jihao Wu"
        ],
        "submitted": "2025-09-15 08:00:31",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multimodal large language models and their training on Ascend NPUs, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some NLP aspects, the primary focus is on model training and optimization, which is not a central match for the user's interests."
    },
    {
        "title": "MALLM: Multi-Agent Large Language Models Framework",
        "abstract": "Multi-agent debate (MAD) has demonstrated the ability to augment collective\nintelligence by scaling test-time compute and leveraging expertise. Current\nframeworks for multi-agent debate are often designed towards tool use, lack\nintegrated evaluation, or provide limited configurability of agent personas,\nresponse generators, discussion paradigms, and decision protocols. We introduce\nMALLM (Multi-Agent Large Language Models), an open-source framework that\nenables systematic analysis of MAD components. MALLM offers more than 144\nunique configurations of MAD, including (1) agent personas (e.g., Expert,\nPersonality), (2) response generators (e.g., Critical, Reasoning), (3)\ndiscussion paradigms (e.g., Memory, Relay), and (4) decision protocols (e.g.,\nVoting, Consensus). MALLM uses simple configuration files to define a debate.\nFurthermore, MALLM can load any textual Huggingface dataset (e.g., MMLU-Pro,\nWinoGrande) and provides an evaluation pipeline for easy comparison of MAD\nconfigurations. MALLM is tailored towards researchers and provides a window\ninto the heart of multi-agent debate, facilitating the understanding of its\ncomponents and their interplay.",
        "url": "http://arxiv.org/abs/2509.11656v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11656v1",
        "arxiv_id": "2509.11656v1",
        "authors": [
            "Jonas Becker",
            "Lars Benedikt Kaesberg",
            "Niklas Bauer",
            "Jan Philip Wahle",
            "Terry Ruas",
            "Bela Gipp"
        ],
        "submitted": "2025-09-15 07:48:02",
        "source": "arxiv",
        "comment": "Accepted at EMNLP 2025 (Demo)",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multi-agent debate and large language models, which is outside the user's primary research interests in Information Retrieval and Search technologies. While it involves NLP, the context and application are not directly related to the user's core themes."
    },
    {
        "title": "Event2Vec: A Geometric Approach to Learning Composable Representations of Event Sequences",
        "abstract": "The study of neural representations, both in biological and artificial\nsystems, is increasingly revealing the importance of geometric and topological\nstructures. Inspired by this, we introduce Event2Vec, a novel framework for\nlearning representations of discrete event sequences. Our model leverages a\nsimple, additive recurrent structure to learn composable, interpretable\nembeddings. We provide a theoretical analysis demonstrating that, under\nspecific training objectives, our model's learned representations in a\nEuclidean space converge to an ideal additive structure. This ensures that the\nrepresentation of a sequence is the vector sum of its constituent events, a\nproperty we term the linear additive hypothesis. To address the limitations of\nEuclidean geometry for hierarchical data, we also introduce a variant of our\nmodel in hyperbolic space, which is naturally suited to embedding tree-like\nstructures with low distortion. We present experiments to validate our\nhypothesis and demonstrate the benefits of each geometry, highlighting the\nimproved performance of the hyperbolic model on hierarchical event sequences.",
        "url": "http://arxiv.org/abs/2509.12188v1",
        "pdf_url": "http://arxiv.org/pdf/2509.12188v1",
        "arxiv_id": "2509.12188v1",
        "authors": [
            "Antonin Sulc"
        ],
        "submitted": "2025-09-15 17:51:02",
        "source": "arxiv",
        "comment": "10 pages, 3 figures, Symmetry and Geometry in Neural Representations\n  Workshop at NeuralIPS (Neurreps) 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on learning representations of event sequences using geometric and topological structures, which is not directly related to the user's interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves neural representations and embeddings, the context is different from query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models",
        "abstract": "Recent advances in text-only \"slow-thinking\" reasoning have prompted efforts\nto transfer this capability to vision-language models (VLMs), for training\nvisual reasoning models (\\textbf{VRMs}). owever, such transfer faces critical\nchallenges: Effective \"slow thinking\" in VRMs requires \\textbf{visual\nreflection}, the ability to check the reasoning process based on visual\ninformation. Through quantitative analysis, we observe that current VRMs\nexhibit limited visual reflection, as their attention to visual information\ndiminishes rapidly with longer generated responses. To address this challenge,\nwe propose a new VRM \\textbf{Reflection-V}, which enhances visual reflection\nbased on reasoning data construction for cold-start and reward design for\nreinforcement learning (RL). Firstly, we construct vision-centered reasoning\ndata by leveraging an agent that interacts between VLMs and reasoning LLMs,\nenabling cold-start learning of visual reflection patterns. Secondly, a visual\nattention based reward model is employed during RL to encourage reasoning based\non visual information. Therefore, \\textbf{Reflection-V} demonstrates\nsignificant improvements across multiple visual reasoning benchmarks.\nFurthermore, \\textbf{Reflection-V} maintains a stronger and more consistent\nreliance on visual information during visual reasoning, indicating effective\nenhancement in visual reflection capabilities.",
        "url": "http://arxiv.org/abs/2509.12132v1",
        "pdf_url": "http://arxiv.org/pdf/2509.12132v1",
        "arxiv_id": "2509.12132v1",
        "authors": [
            "Pu Jian",
            "Junhong Wu",
            "Wei Sun",
            "Chen Wang",
            "Shuo Ren",
            "Jiajun Zhang"
        ],
        "submitted": "2025-09-15 16:57:25",
        "source": "arxiv",
        "comment": "EMNLP2025 Main",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores visual reflection in vision-language models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on visual reflection and reinforcement learning is not directly aligned with the user's core research themes. The paper's relevance is limited to the broader context of deep semantic understanding, but it does not specifically address the user's areas of interest."
    },
    {
        "title": "When marine radar target detection meets pretrained large language models",
        "abstract": "Deep learning (DL) methods are widely used to extract high-dimensional\npatterns from the sequence features of radar echo signals. However,\nconventional DL algorithms face challenges such as redundant feature segments,\nand constraints from restricted model sizes. To address these issues, we\npropose a framework that integrates feature preprocessing with large language\nmodels (LLMs). Our preprocessing module tokenizes radar sequence features,\napplies a patch selection algorithm to filter out uninformative segments, and\nprojects the selected patches into embeddings compatible with the feature space\nof pre-trained LLMs. Leveraging these refined embeddings, we incorporate a\npre-trained LLM, fine-tuning only the normalization layers to reduce training\nburdens while enhancing performance. Experiments on measured datasets\ndemonstrate that the proposed method significantly outperforms the\nstate-of-the-art baselines on supervised learning tests.",
        "url": "http://arxiv.org/abs/2509.12110v1",
        "pdf_url": "http://arxiv.org/pdf/2509.12110v1",
        "arxiv_id": "2509.12110v1",
        "authors": [
            "Qiying Hu",
            "Linping Zhang",
            "Xueqian Wang",
            "Gang Li",
            "Yu Liu",
            "Xiao-Ping Zhang"
        ],
        "submitted": "2025-09-15 16:38:13",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be unrelated to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on marine radar target detection and large language models in a different context does not align with the user's core themes."
    },
    {
        "title": "Is 'Hope' a person or an idea? A pilot benchmark for NER: comparing traditional NLP tools and large language models on ambiguous entities",
        "abstract": "This pilot study presents a small-scale but carefully annotated benchmark of\nNamed Entity Recognition (NER) performance across six systems: three non-LLM\nNLP tools (NLTK, spaCy, Stanza) and three general-purpose large language models\n(LLMs: Gemini-1.5-flash, DeepSeek-V3, Qwen-3-4B). The dataset contains 119\ntokens covering five entity types (PERSON, LOCATION, ORGANIZATION, DATE, TIME).\nWe evaluated each system's output against the manually annotated gold standard\ndataset using F1-score. The results show that LLMs generally outperform\nconventional tools in recognizing context-sensitive entities like person names,\nwith Gemini achieving the highest average F1-score. However, traditional\nsystems like Stanza demonstrate greater consistency in structured tags such as\nLOCATION and DATE. We also observed variability among LLMs, particularly in\nhandling temporal expressions and multi-word organizations. Our findings\nhighlight that while LLMs offer improved contextual understanding, traditional\ntools remain competitive in specific tasks, informing model selection.",
        "url": "http://arxiv.org/abs/2509.12098v1",
        "pdf_url": "http://arxiv.org/pdf/2509.12098v1",
        "arxiv_id": "2509.12098v1",
        "authors": [
            "Payam Latifi"
        ],
        "submitted": "2025-09-15 16:21:59",
        "source": "arxiv",
        "comment": "14 pages, 9 figures, 2 tables. This is a pilot study evaluating six\n  NER systems -- three traditional tools (NLTK, spaCy, Stanza) and three LLMs\n  (Gemini-1.5-flash, DeepSeek-V3, Qwen-3-4B) -- on a small, ambiguity-rich\n  dataset of 119 tokens. The annotated dataset, prompts are provided in\n  appendices for full reproducibility. All experiments were conducted on 14 May\n  2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Named Entity Recognition (NER), a subfield of NLP, and compares traditional NLP tools with large language models. While it touches on deep semantic understanding, the primary focus is on NER rather than information retrieval. The paper's relevance to the user's interests is somewhat related, but not a central match."
    },
    {
        "title": "Text Adaptation to Plain Language and Easy Read via Automatic Post-Editing Cycles",
        "abstract": "We describe Vicomtech's participation in the CLEARS challenge on text\nadaptation to Plain Language and Easy Read in Spanish. Our approach features\nautomatic post-editing of different types of initial Large Language Model\nadaptations, where successive adaptations are generated iteratively until\nreadability and similarity metrics indicate that no further adaptation\nrefinement can be successfully performed. Taking the average of all official\nmetrics, our submissions achieved first and second place in Plain language and\nEasy Read adaptation, respectively.",
        "url": "http://arxiv.org/abs/2509.11991v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11991v1",
        "arxiv_id": "2509.11991v1",
        "authors": [
            "Jes√∫s Calleja",
            "David Ponce",
            "Thierry Etchegoyhen"
        ],
        "submitted": "2025-09-15 14:42:44",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on text adaptation and post-editing, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves Large Language Models, the primary goal is readability and post-editing, rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Lost in Embeddings: Information Loss in Vision-Language Models",
        "abstract": "Vision--language models (VLMs) often process visual inputs through a\npretrained vision encoder, followed by a projection into the language model's\nembedding space via a connector component. While crucial for modality fusion,\nthe potential information loss induced by this projection step and its direct\nimpact on model capabilities remain understudied. We introduce two\ncomplementary approaches to examine and quantify this loss by analyzing the\nlatent representation space. First, we evaluate semantic information\npreservation by analyzing changes in k-nearest neighbor relationships between\nimage representations, before and after projection. Second, we directly measure\ninformation loss by reconstructing visual embeddings from the projected\nrepresentation, localizing loss at an image patch level. Experiments reveal\nthat connectors substantially distort the local geometry of visual\nrepresentations, with k-nearest neighbors diverging by 40--60\\%\npost-projection, correlating with degradation in retrieval performance. The\npatch-level embedding reconstruction provides interpretable insights for model\nbehavior on visually grounded question-answering tasks, finding that areas of\nhigh information loss reliably predict instances where models struggle.",
        "url": "http://arxiv.org/abs/2509.11986v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11986v1",
        "arxiv_id": "2509.11986v1",
        "authors": [
            "Wenyan Li",
            "Raphael Tang",
            "Chengzu Li",
            "Caiqi Zhang",
            "Ivan Vuliƒá",
            "Anders S√∏gaard"
        ],
        "submitted": "2025-09-15 14:38:06",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 3,
        "llm_reason": "The paper focuses on vision-language models, which is somewhat related to information retrieval, but the specific topic of information loss in embeddings is not directly aligned with the user's core research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "ToolRM: Outcome Reward Models for Tool-Calling Large Language Models",
        "abstract": "As large language models (LLMs) increasingly interact with external tools,\nreward modeling for tool use has become a critical yet underexplored area.\nExisting reward models, trained primarily on natural language outputs, struggle\nto evaluate tool-based reasoning and execution. To quantify this gap, we\nintroduce FC-RewardBench, the first benchmark designed to systematically assess\nreward models' performance in tool-calling scenarios. Our analysis shows that\ncurrent reward models often miss key signals of effective tool use,\nhighlighting the need for domain-specific modeling. To address this, we propose\na training framework for outcome-based reward models using data synthesized\nfrom permissively licensed, open-weight LLMs. We train models ranging from 1.7B\nto 14B parameters and evaluate them across seven out-of-domain benchmarks.\nThese models consistently outperform general-purpose baselines, achieving up to\n25\\% average improvement in downstream task performance and enabling\ndata-efficient fine-tuning through reward-guided filtering.",
        "url": "http://arxiv.org/abs/2509.11963v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11963v1",
        "arxiv_id": "2509.11963v1",
        "authors": [
            "Mayank Agarwal",
            "Ibrahim Abdelaziz",
            "Kinjal Basu",
            "Merve Unuvar",
            "Luis A. Lastras",
            "Yara Rizk",
            "Pavan Kapanipathi"
        ],
        "submitted": "2025-09-15 14:17:17",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Search technologies, as it involves large language models and reward modeling. However, the focus on tool-calling and external tool interaction is not directly aligned with your primary interests in query understanding, ranking models, and user behavior modeling. While it touches on NLP, it's more focused on model evaluation and fine-tuning rather than deep semantic understanding or real-time relevance optimization."
    },
    {
        "title": "PledgeTracker: A System for Monitoring the Fulfilment of Pledges",
        "abstract": "Political pledges reflect candidates' policy commitments, but tracking their\nfulfilment requires reasoning over incremental evidence distributed across\nmultiple, dynamically updated sources. Existing methods simplify this task into\na document classification task, overlooking its dynamic, temporal and\nmulti-document nature. To address this issue, we introduce\n\\textsc{PledgeTracker}, a system that reformulates pledge verification into\nstructured event timeline construction. PledgeTracker consists of three core\ncomponents: (1) a multi-step evidence retrieval module; (2) a timeline\nconstruction module and; (3) a fulfilment filtering module, allowing the\ncapture of the evolving nature of pledge fulfilment and producing interpretable\nand structured timelines. We evaluate PledgeTracker in collaboration with\nprofessional fact-checkers in real-world workflows, demonstrating its\neffectiveness in retrieving relevant evidence and reducing human verification\neffort.",
        "url": "http://arxiv.org/abs/2509.11804v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11804v1",
        "arxiv_id": "2509.11804v1",
        "authors": [
            "Yulong Chen",
            "Michael Sejr Schlichtkrull",
            "Zhenyun Deng",
            "David Corney",
            "Nasim Asl",
            "Joshua Salisbury",
            "Andrew Dudfield",
            "Andreas Vlachos"
        ],
        "submitted": "2025-09-15 11:37:47",
        "source": "arxiv",
        "comment": "EMNLP 2025 demo",
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or Natural Language Processing, which are the primary areas of interest. While it involves evidence retrieval and timeline construction, the context is focused on political pledge tracking, which is not a core theme in the user's research interests."
    },
    {
        "title": "CoachMe: Decoding Sport Elements with a Reference-Based Coaching Instruction Generation Model",
        "abstract": "Motion instruction is a crucial task that helps athletes refine their\ntechnique by analyzing movements and providing corrective guidance. Although\nrecent advances in multimodal models have improved motion understanding,\ngenerating precise and sport-specific instruction remains challenging due to\nthe highly domain-specific nature of sports and the need for informative\nguidance. We propose CoachMe, a reference-based model that analyzes the\ndifferences between a learner's motion and a reference under temporal and\nphysical aspects. This approach enables both domain-knowledge learning and the\nacquisition of a coach-like thinking process that identifies movement errors\neffectively and provides feedback to explain how to improve. In this paper, we\nillustrate how CoachMe adapts well to specific sports such as skating and\nboxing by learning from general movements and then leveraging limited data.\nExperiments show that CoachMe provides high-quality instructions instead of\ndirections merely in the tone of a coach but without critical information.\nCoachMe outperforms GPT-4o by 31.6% in G-Eval on figure skating and by 58.3% on\nboxing. Analysis further confirms that it elaborates on errors and their\ncorresponding improvement methods in the generated instructions. You can find\nCoachMe here: https://motionxperts.github.io/",
        "url": "http://arxiv.org/abs/2509.11698v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11698v1",
        "arxiv_id": "2509.11698v1",
        "authors": [
            "Wei-Hsin Yeh",
            "Yu-An Su",
            "Chih-Ning Chen",
            "Yi-Hsueh Lin",
            "Calvin Ku",
            "Wen-Hsin Chiu",
            "Min-Chun Hu",
            "Lun-Wei Ku"
        ],
        "submitted": "2025-09-15 09:01:39",
        "source": "arxiv",
        "comment": "Published in Proceedings of the 63rd Annual Meeting of the\n  Association for Computational Linguistics (Volume 1: Long Papers), ACL 2025.\n  Official version: https://doi.org/10.18653/v1/2025.acl-long.1413",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. The focus on motion instruction generation for sports and the use of multimodal models are outside your primary areas of interest."
    },
    {
        "title": "Bhaasha, Bhasa, Zaban: A Survey for Low-Resourced Languages in South Asia -- Current Stage and Challenges",
        "abstract": "Rapid developments of large language models have revolutionized many NLP\ntasks for English data. Unfortunately, the models and their evaluations for\nlow-resource languages are being overlooked, especially for languages in South\nAsia. Although there are more than 650 languages in South Asia, many of them\neither have very limited computational resources or are missing from existing\nlanguage models. Thus, a concrete question to be answered is: Can we assess the\ncurrent stage and challenges to inform our NLP community and facilitate model\ndevelopments for South Asian languages? In this survey, we have comprehensively\nexamined current efforts and challenges of NLP models for South Asian languages\nby retrieving studies since 2020, with a focus on transformer-based models,\nsuch as BERT, T5, & GPT. We present advances and gaps across 3 essential\naspects: data, models, & tasks, such as available data sources, fine-tuning\nstrategies, & domain applications. Our findings highlight substantial issues,\nincluding missing data in critical domains (e.g., health), code-mixing, and\nlack of standardized evaluation benchmarks. Our survey aims to raise awareness\nwithin the NLP community for more targeted data curation, unify benchmarks\ntailored to cultural and linguistic nuances of South Asia, and encourage an\nequitable representation of South Asian languages. The complete list of\nresources is available at: https://github.com/trust-nlp/LM4SouthAsia-Survey.",
        "url": "http://arxiv.org/abs/2509.11570v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11570v1",
        "arxiv_id": "2509.11570v1",
        "authors": [
            "Sampoorna Poria",
            "Xiaolei Huang"
        ],
        "submitted": "2025-09-15 04:31:22",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Natural Language Processing (NLP), but it focuses on low-resourced languages in South Asia, which is not a central match for the user's primary focus on information retrieval, especially in areas requiring deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "D$^2$HScore: Reasoning-Aware Hallucination Detection via Semantic Breadth and Depth Analysis in LLMs",
        "abstract": "Although large Language Models (LLMs) have achieved remarkable success, their\npractical application is often hindered by the generation of non-factual\ncontent, which is called \"hallucination\". Ensuring the reliability of LLMs'\noutputs is a critical challenge, particularly in high-stakes domains such as\nfinance, security, and healthcare. In this work, we revisit hallucination\ndetection from the perspective of model architecture and generation dynamics.\nLeveraging the multi-layer structure and autoregressive decoding process of\nLLMs, we decompose hallucination signals into two complementary dimensions: the\nsemantic breadth of token representations within each layer, and the semantic\ndepth of core concepts as they evolve across layers. Based on this insight, we\npropose \\textbf{D$^2$HScore (Dispersion and Drift-based Hallucination Score)},\na training-free and label-free framework that jointly measures: (1)\n\\textbf{Intra-Layer Dispersion}, which quantifies the semantic diversity of\ntoken representations within each layer; and (2) \\textbf{Inter-Layer Drift},\nwhich tracks the progressive transformation of key token representations across\nlayers. To ensure drift reflects the evolution of meaningful semantics rather\nthan noisy or redundant tokens, we guide token selection using attention\nsignals. By capturing both the horizontal and vertical dynamics of\nrepresentation during inference, D$^2$HScore provides an interpretable and\nlightweight proxy for hallucination detection. Extensive experiments across\nfive open-source LLMs and five widely used benchmarks demonstrate that\nD$^2$HScore consistently outperforms existing training-free baselines.",
        "url": "http://arxiv.org/abs/2509.11569v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11569v1",
        "arxiv_id": "2509.11569v1",
        "authors": [
            "Yue Ding",
            "Xiaofang Zhu",
            "Tianze Xia",
            "Junfei Wu",
            "Xinlong Chen",
            "Qiang Liu",
            "Liang Wang"
        ],
        "submitted": "2025-09-15 04:28:38",
        "source": "arxiv",
        "comment": "under review",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on hallucination detection in Large Language Models (LLMs), which is related to query understanding and deep semantic understanding in Information Retrieval. However, the specific application domain and methodology are not directly aligned with the user's primary research interests."
    },
    {
        "title": "Acoustic Overspecification in Electronic Dance Music Taxonomy",
        "abstract": "Electronic Dance Music (EDM) classification typically relies on\nindustry-defined taxonomies with numerous subgenres, yet the acoustic basis for\nthese distinctions remains unclear. Current approaches use supervised learning\nwith prescribed genre labels, assuming their validity without systematic\nevaluation. In this paper, we propose an unsupervised approach to discover the\nnatural acoustic structure of EDM independent of commercial labels. Our method\ncombines novel tempogram-based features capturing EDM's layered rhythmic\npatterns with multi-criteria feature selection. To validate that our findings\nreflect genuine acoustic structure rather than methodological artifacts, we\ncompare our results against state-of-the-art pre-trained audio embeddings (MERT\nand CLAP). Both our feature space and embedding representations converge to\n19-23 natural acoustic families compared to the prescribed 35, providing\nconsistent evidence of significant overspecification in current EDM taxonomy by\napproximately one-third.",
        "url": "http://arxiv.org/abs/2509.11474v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11474v1",
        "arxiv_id": "2509.11474v1",
        "authors": [
            "Weilun Xu",
            "Tianhao Dai",
            "Oscar Goudet",
            "Xiaoxuan Wang"
        ],
        "submitted": "2025-09-14 23:38:45",
        "source": "arxiv",
        "comment": "5 pages, 3 figures, conference paper",
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, or data mining. The paper focuses on acoustic analysis of Electronic Dance Music and taxonomy, which is outside your areas of expertise."
    },
    {
        "title": "A Transformer-Based Cross-Platform Analysis of Public Discourse on the 15-Minute City Paradigm",
        "abstract": "This study presents the first multi-platform sentiment analysis of public\nopinion on the 15-minute city concept across Twitter, Reddit, and news media.\nUsing compressed transformer models and Llama-3-8B for annotation, we classify\nsentiment across heterogeneous text domains. Our pipeline handles long-form and\nshort-form text, supports consistent annotation, and enables reproducible\nevaluation. We benchmark five models (DistilRoBERTa, DistilBERT, MiniLM,\nELECTRA, TinyBERT) using stratified 5-fold cross-validation, reporting\nF1-score, AUC, and training time. DistilRoBERTa achieved the highest F1\n(0.8292), TinyBERT the best efficiency, and MiniLM the best cross-platform\nconsistency. Results show News data yields inflated performance due to class\nimbalance, Reddit suffers from summarization loss, and Twitter offers moderate\nchallenge. Compressed models perform competitively, challenging assumptions\nthat larger models are necessary. We identify platform-specific trade-offs and\npropose directions for scalable, real-world sentiment classification in urban\nplanning discourse.",
        "url": "http://arxiv.org/abs/2509.11443v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11443v1",
        "arxiv_id": "2509.11443v1",
        "authors": [
            "Gaurab Chhetri",
            "Darrell Anderson",
            "Boniphace Kutela",
            "Subasish Das"
        ],
        "submitted": "2025-09-14 21:36:24",
        "source": "arxiv",
        "comment": "This is the author's preprint version of a paper accepted for\n  presentation at the 24th International Conference on Machine Learning and\n  Applications (ICMLA 2025), December 3-5, 2025, Florida, USA. The final\n  published version will appear in the official IEEE proceedings. Conference\n  site: https://www.icmla-conference.org/icmla25/",
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores sentiment analysis on social media platforms using transformer-based models, which is somewhat related to information retrieval and NLP. However, the focus on sentiment analysis and urban planning discourse is not directly aligned with the user's core research themes in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Securing AI Agents: Implementing Role-Based Access Control for Industrial Applications",
        "abstract": "The emergence of Large Language Models (LLMs) has significantly advanced\nsolutions across various domains, from political science to software\ndevelopment. However, these models are constrained by their training data,\nwhich is static and limited to information available up to a specific date.\nAdditionally, their generalized nature often necessitates fine-tuning --\nwhether for classification or instructional purposes -- to effectively perform\nspecific downstream tasks. AI agents, leveraging LLMs as their core, mitigate\nsome of these limitations by accessing external tools and real-time data,\nenabling applications such as live weather reporting and data analysis. In\nindustrial settings, AI agents are transforming operations by enhancing\ndecision-making, predictive maintenance, and process optimization. For example,\nin manufacturing, AI agents enable near-autonomous systems that boost\nproductivity and support real-time decision-making. Despite these advancements,\nAI agents remain vulnerable to security threats, including prompt injection\nattacks, which pose significant risks to their integrity and reliability. To\naddress these challenges, this paper proposes a framework for integrating\nRole-Based Access Control (RBAC) into AI agents, providing a robust security\nguardrail. This framework aims to support the effective and scalable deployment\nof AI agents, with a focus on on-premises implementations.",
        "url": "http://arxiv.org/abs/2509.11431v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11431v1",
        "arxiv_id": "2509.11431v1",
        "authors": [
            "Aadil Gani Ganie"
        ],
        "submitted": "2025-09-14 20:58:08",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on securing AI agents, which is not a primary area of interest for you. While it mentions AI agents leveraging Large Language Models, it does not discuss query understanding, ranking models, or user behavior modeling, which are core aspects of your research."
    },
    {
        "title": "AMQ: Enabling AutoML for Mixed-precision Weight-Only Quantization of Large Language Models",
        "abstract": "To enable broader deployment of Large Language Models (LLMs), it is essential\nto identify the best-performing model under strict memory constraints. We\npresent AMQ, Automated Mixed-Precision Weight-Only Quantization, a framework\nthat assigns layer-wise quantization bit-widths to optimally balance model\nquality and memory usage. However, the combinatorial search space, with over\n10^{100} possible configurations, makes conventional black-box optimization\ninfeasible. AMQ overcomes this challenge through four key innovations:(1)\nsearch space pruning using prior knowledge to exclude unpromising\nconfigurations, (2) quantization proxy to bypass costly format conversions\nduring search, (3) quality predictor to minimize evaluation overhead, and (4)\niterative search-and-update strategy for fast and stable convergence. By\nintegrating these components, AMQ efficiently explores the quality-efficiency\nlandscape, reaching the Pareto frontier and yielding LLMs that are both compact\nand high-performing. Our code is available at https://github.com/dlwns147/amq.",
        "url": "http://arxiv.org/abs/2509.12019v1",
        "pdf_url": "http://arxiv.org/pdf/2509.12019v1",
        "arxiv_id": "2509.12019v1",
        "authors": [
            "Sangjun Lee",
            "Seung-taek Woo",
            "Jungyu Jin",
            "Changhun Lee",
            "Eunhyeok Park"
        ],
        "submitted": "2025-09-15 14:59:35",
        "source": "arxiv",
        "comment": "EMNLP 2025 Main Conference, Long Paper (Oral)",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on optimizing large language models for memory constraints through mixed-precision weight quantization. While it involves deep learning and model optimization, it doesn't directly relate to information retrieval, search technologies, or query understanding, which are the core areas of your research interests."
    },
    {
        "title": "Designing LLMs for cultural sensitivity: Evidence from English-Japanese translation",
        "abstract": "Large language models (LLMs) are increasingly used in everyday communication,\nincluding multilingual interactions across different cultural contexts. While\nLLMs can now generate near-perfect literal translations, it remains unclear\nwhether LLMs support culturally appropriate communication. In this paper, we\nanalyze the cultural sensitivity of different LLM designs when applied to\nEnglish-Japanese translations of workplace e-mails. Here, we vary the prompting\nstrategies: (1) naive \"just translate\" prompts, (2) audience-targeted prompts\nspecifying the recipient's cultural background, and (3) instructional prompts\nwith explicit guidance on Japanese communication norms. Using a mixed-methods\nstudy, we then analyze culture-specific language patterns to evaluate how well\ntranslations adapt to cultural norms. Further, we examine the appropriateness\nof the tone of the translations as perceived by native speakers. We find that\nculturally-tailored prompting can improve cultural fit, based on which we offer\nrecommendations for designing culturally inclusive LLMs in multilingual\nsettings.",
        "url": "http://arxiv.org/abs/2509.11921v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11921v1",
        "arxiv_id": "2509.11921v1",
        "authors": [
            "Helene Tenzer",
            "Oumnia Abidi",
            "Stefan Feuerriegel"
        ],
        "submitted": "2025-09-15 13:37:35",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Large Language Models (LLMs), but it focuses on cultural sensitivity and translation, which is not a central match to your primary focus on information retrieval and query understanding."
    },
    {
        "title": "Decoding in Latent Spaces for Efficient Inference in LLM-based Recommendation",
        "abstract": "Fine-tuning large language models (LLMs) for recommendation in a generative\nmanner has delivered promising results, but encounters significant inference\noverhead due to autoregressive decoding in the language space. This work\nexplores bypassing language-space decoding by directly matching candidate items\nwith the LLM's internal thought representations in the latent space,\neliminating the time-consuming autoregressive process to reduce computational\ncosts. Towards this, we introduce Light Latent-space Decoding (L2D), an\neffective and efficient latent-space decoding method. L2D represents\nuser-preferred items by using the hidden states of test sequences reflecting\nthe LLM's internal thought, and obtains candidate item representations from the\nhidden states of training sequences labeled with the corresponding candidate\nitems. It then matches the two types of representations to decode items,\nachieving latent-space decoding. In this way, it enables efficient decoding\nwithout altering the LLM's generative tuning paradigm, thereby preserving\nperformance. Extensive empirical results demonstrate that L2D is more than 10x\nfaster than language-space decoding while maintaining or enhancing performance.",
        "url": "http://arxiv.org/abs/2509.11524v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11524v1",
        "arxiv_id": "2509.11524v1",
        "authors": [
            "Chengbing Wang",
            "Yang Zhang",
            "Zhicheng Wang",
            "Tianhao Shi",
            "Keqin Bao",
            "Fuli Feng",
            "Tat-Seng Chua"
        ],
        "submitted": "2025-09-15 02:30:35",
        "source": "arxiv",
        "comment": "Accepted for publication in EMNLP'25",
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores a novel approach to recommendation systems using large language models, but its focus on efficient inference and latent-space decoding is somewhat tangential to the user's core research interests in Information Retrieval, query understanding, and ranking models. While it touches on related topics like NLP and data mining, the paper's primary contribution is in the recommender systems domain, which is not the user's primary focus. The paper's relevance is somewhat mitigated by its lack of direct connection to the user's areas of expertise."
    },
    {
        "title": "PeruMedQA: Benchmarking Large Language Models (LLMs) on Peruvian Medical Exams -- Dataset Construction and Evaluation",
        "abstract": "BACKGROUND: Medical large language models (LLMS) have demonstrated remarkable\nperformance in answering medical examinations. However, the extent to which\nthis high performance is transferable to medical questions in Spanish and from\na Latin American country remains unexplored. This knowledge is crucial as\nLLM-based medical applications gain traction in Latin America. AIMS: to build a\ndataset of questions from medical examinations taken by Peruvian physicians\npursuing specialty training; to fine-tune a LLM on this dataset; to evaluate\nand compare the performance in terms of accuracy between vanilla LLMs and the\nfine-tuned LLM. METHODS: We curated PeruMedQA, a multiple-choice\nquestion-answering (MCQA) datasets containing 8,380 questions spanning 12\nmedical domains (2018-2025). We selected eight medical LLMs including\nmedgemma-4b-it and medgemma-27b-text-it, and developed zero-shot task-specific\nprompts to answer the questions appropriately. We employed parameter-efficient\nfine tuning (PEFT)and low-rant adaptation (LoRA) to fine-tune medgemma-4b-it\nutilizing all questions except those from 2025 (test set). RESULTS:\nmedgemma-27b-text-it outperformed all other models, achieving a proportion of\ncorrect answers exceeding 90% in several instances. LLMs with <10 billion\nparameters exhibited <60% of correct answers, while some exams yielded results\n<50%. The fine-tuned version of medgemma-4b-it emerged victorious agains all\nLLMs with <10 billion parameters and rivaled a LLM with 70 billion parameters\nacross various examinations. CONCLUSIONS: For medical AI application and\nresearch that require knowledge bases from Spanish-speaking countries and those\nexhibiting similar epidemiological profiles to Peru's, interested parties\nshould utilize medgemma-27b-text-it or a fine-tuned version of medgemma-4b-it.",
        "url": "http://arxiv.org/abs/2509.11517v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11517v1",
        "arxiv_id": "2509.11517v1",
        "authors": [
            "Rodrigo M. Carrillo-Larco",
            "Jesus Lov√≥n Melgarejo",
            "Manuel Castillo-Cara",
            "Gusseppe Bravo-Rocca"
        ],
        "submitted": "2025-09-15 02:07:26",
        "source": "arxiv",
        "comment": "https://github.com/rodrigo-carrillo/PeruMedQA",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is primarily focused on evaluating the performance of Large Language Models (LLMs) on medical exams in Spanish, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. While it involves NLP, the context is specific to medical exams and does not align with the user's core research themes."
    },
    {
        "title": "LVLMs are Bad at Overhearing Human Referential Communication",
        "abstract": "During spontaneous conversations, speakers collaborate on novel referring\nexpressions, which they can then re-use in subsequent conversations.\nUnderstanding such referring expressions is an important ability for an\nembodied agent, so that it can carry out tasks in the real world. This requires\nintegrating and understanding language, vision, and conversational interaction.\nWe study the capabilities of seven state-of-the-art Large Vision Language\nModels (LVLMs) as overhearers to a corpus of spontaneous conversations between\npairs of human discourse participants engaged in a collaborative\nobject-matching task. We find that such a task remains challenging for current\nLVLMs and they all fail to show a consistent performance improvement as they\noverhear more conversations from the same discourse participants repeating the\nsame task for multiple rounds. We release our corpus and code for\nreproducibility and to facilitate future research.",
        "url": "http://arxiv.org/abs/2509.11514v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11514v1",
        "arxiv_id": "2509.11514v1",
        "authors": [
            "Zhengxiang Wang",
            "Weiling Li",
            "Panagiotis Kaliosis",
            "Owen Rambow",
            "Susan E. Brennan"
        ],
        "submitted": "2025-09-15 02:03:18",
        "source": "arxiv",
        "comment": "EMNLP 2025 (Main)",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the capabilities of Large Vision Language Models (LVLMs) in understanding human referential communication, which is a topic in Natural Language Processing (NLP). However, it does not directly relate to the user's core research themes in Information Retrieval (IR), query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Trading-R1: Financial Trading with LLM Reasoning via Reinforcement Learning",
        "abstract": "Developing professional, structured reasoning on par with human financial\nanalysts and traders remains a central challenge in AI for finance, where\nmarkets demand interpretability and trust. Traditional time-series models lack\nexplainability, while LLMs face challenges in turning natural-language analysis\ninto disciplined, executable trades. Although reasoning LLMs have advanced in\nstep-by-step planning and verification, their application to risk-sensitive\nfinancial decisions is underexplored. We present Trading-R1, a\nfinancially-aware model that incorporates strategic thinking and planning for\ncomprehensive thesis composition, facts-grounded analysis, and\nvolatility-adjusted decision making. Trading-R1 aligns reasoning with trading\nprinciples through supervised fine-tuning and reinforcement learning with a\nthree-stage easy-to-hard curriculum. Training uses Tauric-TR1-DB, a 100k-sample\ncorpus spanning 18 months, 14 equities, and five heterogeneous financial data\nsources. Evaluated on six major equities and ETFs, Trading-R1 demonstrates\nimproved risk-adjusted returns and lower drawdowns compared to both open-source\nand proprietary instruction-following models as well as reasoning models. The\nsystem generates structured, evidence-based investment theses that support\ndisciplined and interpretable trading decisions. Trading-R1 Terminal will be\nreleased at https://github.com/TauricResearch/Trading-R1.",
        "url": "http://arxiv.org/abs/2509.11420v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11420v1",
        "arxiv_id": "2509.11420v1",
        "authors": [
            "Yijia Xiao",
            "Edward Sun",
            "Tong Chen",
            "Fang Wu",
            "Di Luo",
            "Wei Wang"
        ],
        "submitted": "2025-09-14 20:13:41",
        "source": "arxiv",
        "comment": "Tauric Research: https://github.com/TauricResearch",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves deep learning models, the focus is on financial trading and decision-making, which is outside your primary research areas."
    },
    {
        "title": "Continually Adding New Languages to Multilingual Language Models",
        "abstract": "Multilingual language models are trained on a fixed set of languages, and to\nsupport new languages, the models need to be retrained from scratch. This is an\nexpensive endeavor and is often infeasible, as model developers tend not to\nrelease their pre-training data. Naive approaches, such as continued\npretraining, suffer from catastrophic forgetting; however, mitigation\nstrategies like experience replay cannot be applied due to the lack of original\npretraining data. In this work, we investigate the problem of continually\nadding new languages to a multilingual model, assuming access to pretraining\ndata in only the target languages. We explore multiple approaches to address\nthis problem and propose Layer-Selective LoRA (LayRA), which adds Low-Rank\nAdapters (LoRA) to selected initial and final layers while keeping the rest of\nthe model frozen. LayRA builds on two insights: (1) LoRA reduces forgetting,\nand (2) multilingual models encode inputs in the source language in the initial\nlayers, reason in English in intermediate layers, and translate back to the\nsource language in final layers. We experiment with adding multiple\ncombinations of Galician, Swahili, and Urdu to pretrained language models and\nevaluate each method on diverse multilingual tasks. We find that LayRA provides\nthe overall best tradeoff between preserving models' capabilities in previously\nsupported languages, while being competitive with existing approaches such as\nLoRA in learning new languages. We also demonstrate that using model\narithmetic, the adapted models can be equipped with strong instruction\nfollowing abilities without access to any instruction tuning data in the target\nlanguages.",
        "url": "http://arxiv.org/abs/2509.11414v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11414v1",
        "arxiv_id": "2509.11414v1",
        "authors": [
            "Abraham Toluwase Owodunni",
            "Sachin Kumar"
        ],
        "submitted": "2025-09-14 20:08:15",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multilingual language models and proposes a method to continually add new languages, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves NLP, the topic is more aligned with model development and adaptation rather than query understanding or ranking models."
    },
    {
        "title": "Transformer Enhanced Relation Classification: A Comparative Analysis of Contextuality, Data Efficiency and Sequence Complexity",
        "abstract": "In the era of large language model, relation extraction (RE) plays an\nimportant role in information extraction through the transformation of\nunstructured raw text into structured data (Wadhwa et al., 2023). In this\npaper, we systematically compare the performance of deep supervised learning\napproaches without transformers and those with transformers. We used a series\nof non-transformer architectures such as PA-LSTM(Zhang et al., 2017),\nC-GCN(Zhang et al., 2018), and AGGCN(attention guide GCN)(Guo et al., 2019),\nand a series of transformer architectures such as BERT, RoBERTa, and R-BERT(Wu\nand He, 2019). Our comparison included traditional metrics like micro F1, as\nwell as evaluations in different scenarios, varying sentence lengths, and\ndifferent percentages of the dataset for training. Our experiments were\nconducted on TACRED, TACREV, and RE-TACRED. The results show that\ntransformer-based models outperform non-transformer models, achieving micro F1\nscores of 80-90% compared to 64-67% for non-transformer models. Additionally,\nwe briefly review the research journey in supervised relation classification\nand discuss the role and current status of large language models (LLMs) in\nrelation extraction.",
        "url": "http://arxiv.org/abs/2509.11374v1",
        "pdf_url": "http://arxiv.org/pdf/2509.11374v1",
        "arxiv_id": "2509.11374v1",
        "authors": [
            "Bowen Jing",
            "Yang Cui",
            "Tianpeng Huang"
        ],
        "submitted": "2025-09-14 18:11:31",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and deep semantic understanding, but it primarily focuses on relation classification and large language models, which is not a central match to your core interests in Information Retrieval and Search technologies."
    }
]