[
    {
        "title": "Aligned Query Expansion: Efficient Query Expansion for Information Retrieval through LLM Alignment",
        "abstract": "With the breakthroughs in large language models (LLMs), query generation\ntechniques that expand documents and queries with related terms are becoming\nincreasingly popular in the information retrieval field. Such techniques have\nbeen shown to improve the effectiveness of traditional lexical retrieval\nmethods by dealing with the vocabulary mismatch problem. Recent work has found\nthat generating queries with a greedy decoding strategy can produce sub-optimal\nqueries, including hallucinations, and proposed to filter out queries before\nexpansion. This `generate-then-filter' approach is costly, as it requires\ngenerating multiple queries and applying a relevance model to all of them and\ndoes not teach the LLM which of the generated queries is more effective for\nexpansion. To overcome such limitations, we propose Aligned Query Expansion\n(AQE), a novel approach to enhance query expansion for passage retrieval in\nopen-domain question answering. AQE leverages recent techniques in LLM\nalignment to fine-tune models for generating query expansions that directly\noptimize the effectiveness of the retrieval task, eliminating the need for\nadditional filtering steps. This alignment ensures that queries are more\nrelevant, reducing computational costs while improving retrieval effectiveness.\nEmpirical evaluations show that AQE outperforms baseline models for query\nexpansion in both in-domain and out-of-domain settings, demonstrating\nsignificant improvements in retrieval effectiveness.",
        "url": "http://arxiv.org/abs/2507.11042v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11042v1",
        "arxiv_id": "2507.11042v1",
        "authors": [
            "Adam Yang",
            "Gustavo Penha",
            "Enrico Palumbo",
            "Hugues Bouchard"
        ],
        "submitted": "2025-07-15 07:11:29",
        "source": "arxiv",
        "comment": null,
        "score": 19,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'passage retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "The paper focuses on query expansion techniques in information retrieval, leveraging large language models (LLMs) for alignment, which aligns with your interest in query understanding and ranking models. The approach also addresses the vocabulary mismatch problem, a common issue in IR, and demonstrates improvements in retrieval effectiveness, making it a relevant contribution to the field."
    },
    {
        "title": "Extracting Document Relations from Search Corpus by Marginalizing over User Queries",
        "abstract": "Understanding relationships between documents in large-scale corpora is\nessential for knowledge discovery and information organization. However,\nexisting approaches rely heavily on manual annotation or predefined\nrelationship taxonomies. We propose EDR-MQ (Extracting Document Relations by\nMarginalizing over User Queries), a novel framework that discovers document\nrelationships through query marginalization. EDR-MQ is based on the insight\nthat strongly related documents often co-occur in results across diverse user\nqueries, enabling us to estimate joint probabilities between document pairs by\nmarginalizing over a collection of queries. To enable this query\nmarginalization approach, we develop Multiply Conditioned Retrieval-Augmented\nGeneration (MC-RAG), which employs conditional retrieval where subsequent\ndocument retrievals depend on previously retrieved content. By observing\nco-occurrence patterns across diverse queries, EDR-MQ estimates joint\nprobabilities between document pairs without requiring labeled training data or\npredefined taxonomies. Experimental results show that our query marginalization\napproach successfully identifies meaningful document relationships, revealing\ntopical clusters, evidence chains, and cross-domain connections that are not\napparent through traditional similarity-based methods. Our query-driven\nframework offers a practical approach to document organization that adapts to\ndifferent user perspectives and information needs.",
        "url": "http://arxiv.org/abs/2507.10726v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10726v1",
        "arxiv_id": "2507.10726v1",
        "authors": [
            "Yuki Iwamoto",
            "Kaoru Tsunoda",
            "Ken Kaneiwa"
        ],
        "submitted": "2025-07-14 18:47:13",
        "source": "arxiv",
        "comment": "9 pages, 6 figures",
        "score": 11,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "The paper's focus on extracting document relations from a search corpus, using query marginalization, aligns with your interest in Information Retrieval and Search technologies. The approach also involves ranking models and user behavior modeling, which are relevant to your research themes. While the paper's scope is broader than your specific focus on e-commerce, the concepts and techniques discussed are relevant to your broader interests in IR and NLP."
    },
    {
        "title": "LiLM-RDB-SFC: Lightweight Language Model with Relational Database-Guided DRL for Optimized SFC Provisioning",
        "abstract": "Effective management of Service Function Chains (SFCs) and optimal Virtual\nNetwork Function (VNF) placement are critical challenges in modern\nSoftware-Defined Networking (SDN) and Network Function Virtualization (NFV)\nenvironments. Although Deep Reinforcement Learning (DRL) is widely adopted for\ndynamic network decision-making, its inherent dependency on structured data and\nfixed action rules often limits adaptability and responsiveness, particularly\nunder unpredictable network conditions. This paper introduces LiLM-RDB-SFC, a\nnovel approach combining Lightweight Language Model (LiLM) with Relational\nDatabase (RDB) to answer network state queries to guide DRL model for efficient\nSFC provisioning. Our proposed approach leverages two LiLMs, Bidirectional and\nAuto-Regressive Transformers (BART) and the Fine-tuned Language Net T5\n(FLAN-T5), to interpret network data and support diverse query types related to\nSFC demands, data center resources, and VNF availability. Results demonstrate\nthat FLAN-T5 outperforms BART with a lower test loss (0.00161 compared to\n0.00734), higher accuracy (94.79% compared to 80.2%), and less processing time\n(2h 2min compared to 2h 38min). Moreover, when compared to the large language\nmodel SQLCoder, FLAN-T5 matches the accuracy of SQLCoder while cutting\nprocessing time by 96% (SQLCoder: 54 h 43 min; FLAN-T5: 2 h 2 min).",
        "url": "http://arxiv.org/abs/2507.10903v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10903v1",
        "arxiv_id": "2507.10903v1",
        "authors": [
            "Parisa Fard Moshiri",
            "Xinyu Zhu",
            "Poonam Lohan",
            "Burak Kantarci",
            "Emil Janulewicz"
        ],
        "submitted": "2025-07-15 01:42:44",
        "source": "arxiv",
        "comment": "9 pages, 6 figures, Accepted to IEEE 16th International Conference on\n  Network of the Future (NoF) 2025",
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on Service Function Chains, Virtual Network Functions, and Deep Reinforcement Learning in the context of Software-Defined Networking and Network Function Virtualization, which is outside your primary research areas."
    },
    {
        "title": "Language Models for Adult Service Website Text Analysis",
        "abstract": "Sex trafficking refers to the use of force, fraud, or coercion to compel an\nindividual to perform in commercial sex acts against their will. Adult service\nwebsites (ASWs) have and continue to be linked to sex trafficking, offering a\nplatform for traffickers to advertise their victims. Thus, organizations\ninvolved in the fight against sex trafficking often use ASW data when\nattempting to identify potential sex trafficking victims. A critical challenge\nin transforming ASW data into actionable insight is text analysis. Previous\nresearch using ASW data has shown that ASW ad text is important for linking\nads. However, working with this text is challenging due to its extensive use of\nemojis, poor grammar, and deliberate obfuscation to evade law enforcement\nscrutiny. We conduct a comprehensive study of language modeling approaches for\nthis application area, including simple information retrieval methods,\npre-trained transformers, and custom transformer models. We demonstrate that\ncharacteristics of ASW text data allow efficient custom transformer models to\nbe trained with relatively small GPU resources and used efficiently for\ninference on consumer hardware. Our custom models outperform fine-tuned\nvariants of well-known encoder-only transformer models, including BERT-base,\nRoBERTa, and ModernBERT, on accuracy, recall, F1 score, and ROC AUC. We\ndemonstrate the use of our best-performing custom configuration on three tasks\nrelated to ASW data analysis: (i) decomposing the giant component in a graph\nrepresentation of ASW data, (ii) clustering ASW ad text, and (iii) using the\nlearned token embeddings to understand the use of emojis in the illicit context\nwe study. The models we develop represent a significant advancement in ASW text\nanalysis, which can be leveraged in a variety of downstream applications and\nresearch.",
        "url": "http://arxiv.org/abs/2507.10743v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10743v1",
        "arxiv_id": "2507.10743v1",
        "authors": [
            "Nickolas Freeman",
            "Thanh Nguyen",
            "Gregory Bott",
            "Jason Parton",
            "Collin Francel"
        ],
        "submitted": "2025-07-14 19:08:07",
        "source": "arxiv",
        "comment": "32 pages, 12 figures, 1 table",
        "score": 8,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on language models for adult service website text analysis, which is a specific domain and application area. The topics of query understanding, ranking models, and user behavior modeling are not addressed, and the paper's focus on text analysis and language models is not aligned with your interests in information retrieval and search technologies."
    },
    {
        "title": "An Empirical Study of Multi-Agent RAG for Real-World University Admissions Counseling",
        "abstract": "This paper presents MARAUS (Multi-Agent and Retrieval-Augmented University\nAdmission System), a real-world deployment of a conversational AI platform for\nhigher education admissions counseling in Vietnam. While large language models\n(LLMs) offer potential for automating advisory tasks, most existing solutions\nremain limited to prototypes or synthetic benchmarks. MARAUS addresses this gap\nby combining hybrid retrieval, multi-agent orchestration, and LLM-based\ngeneration into a system tailored for real-world university admissions. In\ncollaboration with the University of Transport Technology (UTT) in Hanoi, we\nconducted a two-phase study involving technical development and real-world\nevaluation. MARAUS processed over 6,000 actual user interactions, spanning six\ncategories of queries. Results show substantial improvements over LLM-only\nbaselines: on average 92 percent accuracy, hallucination rates reduced from 15\nprecent to 1.45 percent, and average response times below 4 seconds. The system\noperated cost-effectively, with a two-week deployment cost of 11.58 USD using\nGPT-4o mini. This work provides actionable insights for the deployment of\nagentic RAG systems in low-resource educational settings.",
        "url": "http://arxiv.org/abs/2507.11272v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11272v1",
        "arxiv_id": "2507.11272v1",
        "authors": [
            "Anh Nguyen-Duc",
            "Chien Vu Manh",
            "Bao Anh Tran",
            "Viet Phuong Ngo",
            "Luan Le Chi",
            "Anh Quang Nguyen"
        ],
        "submitted": "2025-07-15 12:49:42",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper's focus on conversational AI and university admissions counseling is somewhat related to information retrieval, but it does not directly align with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's use of large language models and retrieval-augmented systems is also not directly applicable to the user's background in e-commerce and NLP."
    },
    {
        "title": "From Chaos to Automation: Enabling the Use of Unstructured Data for Robotic Process Automation",
        "abstract": "The growing volume of unstructured data within organizations poses\nsignificant challenges for data analysis and process automation. Unstructured\ndata, which lacks a predefined format, encompasses various forms such as\nemails, reports, and scans. It is estimated to constitute approximately 80% of\nenterprise data. Despite the valuable insights it can offer, extracting\nmeaningful information from unstructured data is more complex compared to\nstructured data. Robotic Process Automation (RPA) has gained popularity for\nautomating repetitive tasks, improving efficiency, and reducing errors.\nHowever, RPA is traditionally reliant on structured data, limiting its\napplication to processes involving unstructured documents. This study addresses\nthis limitation by developing the UNstructured Document REtrieval SyStem\n(UNDRESS), a system that uses fuzzy regular expressions, techniques for natural\nlanguage processing, and large language models to enable RPA platforms to\neffectively retrieve information from unstructured documents. The research\ninvolved the design and development of a prototype system, and its subsequent\nevaluation based on text extraction and information retrieval performance. The\nresults demonstrate the effectiveness of UNDRESS in enhancing RPA capabilities\nfor unstructured data, providing a significant advancement in the field. The\nfindings suggest that this system could facilitate broader RPA adoption across\nprocesses traditionally hindered by unstructured data, thereby improving\noverall business process efficiency.",
        "url": "http://arxiv.org/abs/2507.11364v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11364v1",
        "arxiv_id": "2507.11364v1",
        "authors": [
            "Kelly Kurowski",
            "Xixi Lu",
            "Hajo A. Reijers"
        ],
        "submitted": "2025-07-15 14:32:49",
        "source": "arxiv",
        "comment": "Accepted at AUTOMATE 2025",
        "score": 6,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Robotic Process Automation (RPA) and unstructured data, which is not directly related to Information Retrieval (IR) or Search technologies, the user's primary research interests. While it mentions natural language processing (NLP) techniques, the context is different from the user's background in e-commerce and NLP for IR applications."
    },
    {
        "title": "LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP",
        "abstract": "Timely identification and accurate risk stratification of cardiovascular\ndisease (CVD) remain essential for reducing global mortality. While existing\nprediction models primarily leverage structured data, unstructured clinical\nnotes contain valuable early indicators. This study introduces a novel\nLLM-augmented clinical NLP pipeline that employs domain-adapted large language\nmodels for symptom extraction, contextual reasoning, and correlation from\nfree-text reports. Our approach integrates cardiovascular-specific fine-tuning,\nprompt-based inference, and entity-aware reasoning. Evaluations on MIMIC-III\nand CARDIO-NLP datasets demonstrate improved performance in precision, recall,\nF1-score, and AUROC, with high clinical relevance (kappa = 0.82) assessed by\ncardiologists. Challenges such as contextual hallucination, which occurs when\nplausible information contracts with provided source, and temporal ambiguity,\nwhich is related with models struggling with chronological ordering of events\nare addressed using prompt engineering and hybrid rule-based verification. This\nwork underscores the potential of LLMs in clinical decision support systems\n(CDSS), advancing early warning systems and enhancing the translation of\npatient narratives into actionable risk assessments.",
        "url": "http://arxiv.org/abs/2507.11052v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11052v1",
        "arxiv_id": "2507.11052v1",
        "authors": [
            "Haowei Yang",
            "Ziyu Shen",
            "Junli Shao",
            "Luyao Men",
            "Xinyue Han",
            "Jing Dong"
        ],
        "submitted": "2025-07-15 07:32:16",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on clinical NLP and cardiovascular disease risk prediction, which is outside your primary area of interest in Information Retrieval, Search technologies, and Natural Language Processing. The paper's application in clinical decision support systems is also not directly related to your research themes."
    },
    {
        "title": "Access Control for Information-Theoretically Secure Key-Document Stores",
        "abstract": "This paper presents a novel key-based access control technique for secure\noutsourcing key-value stores where values correspond to documents that are\nindexed and accessed using keys. The proposed approach adopts Shamir's\nsecret-sharing that offers unconditional or information-theoretic security. It\nsupports keyword-based document retrieval while preventing leakage of the data,\naccess rights of users, or the size (\\textit{i}.\\textit{e}., volume of the\noutput that satisfies a query). The proposed approach allows servers to detect\n(and abort) malicious clients from gaining unauthorized access to data, and\nprevents malicious servers from altering data undetected while ensuring\nefficient access -- it takes 231.5ms over 5,000 keywords across 500,000 files.",
        "url": "http://arxiv.org/abs/2507.10730v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10730v1",
        "arxiv_id": "2507.10730v1",
        "authors": [
            "Yin Li",
            "Sharad Mehrota",
            "Shantanu Sharma",
            "Komal Kumari"
        ],
        "submitted": "2025-07-14 18:51:20",
        "source": "arxiv",
        "comment": "An extended abstract of this version has been accepted in VLDB 2025",
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on access control and secret-sharing techniques for secure key-value stores, which is outside the user's primary focus areas."
    },
    {
        "title": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge",
        "abstract": "Novelty is a crucial criterion in the peer review process for evaluating\nacademic papers. Traditionally, it's judged by experts or measure by unique\nreference combinations. Both methods have limitations: experts have limited\nknowledge, and the effectiveness of the combination method is uncertain.\nMoreover, it's unclear if unique citations truly measure novelty. The large\nlanguage model (LLM) possesses a wealth of knowledge, while human experts\npossess judgment abilities that the LLM does not possess. Therefore, our\nresearch integrates the knowledge and abilities of LLM and human experts to\naddress the limitations of novelty assessment. One of the most common types of\nnovelty in academic papers is the introduction of new methods. In this paper,\nwe propose leveraging human knowledge and LLM to assist pretrained language\nmodels (PLMs, e.g. BERT etc.) in predicting the method novelty of papers.\nSpecifically, we extract sentences related to the novelty of the academic paper\nfrom peer review reports and use LLM to summarize the methodology section of\nthe academic paper, which are then used to fine-tune PLMs. In addition, we have\ndesigned a text-guided fusion module with novel Sparse-Attention to better\nintegrate human and LLM knowledge. We compared the method we proposed with a\nlarge number of baselines. Extensive experiments demonstrate that our method\nachieves superior performance.",
        "url": "http://arxiv.org/abs/2507.11330v2",
        "pdf_url": "http://arxiv.org/pdf/2507.11330v2",
        "arxiv_id": "2507.11330v2",
        "authors": [
            "Wenqing Wu",
            "Chengzhi Zhang",
            "Yi Zhao"
        ],
        "submitted": "2025-07-15 14:03:55",
        "source": "arxiv",
        "comment": "Journal of the Association for Information Science and Technology,\n  2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper's focus on novelty evaluation in academic papers and the use of large language models is somewhat related to my interests in Information Retrieval and Natural Language Processing. However, the specific application and methodology are not directly aligned with my core research themes, such as query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding",
        "abstract": "Large language models (LLMs) based on Transformer Decoders have become the\npreferred choice for conversational generative AI. Despite the overall\nsuperiority of the Decoder architecture, the gradually increasing Key-Value\n(KV) cache during inference has emerged as a primary efficiency bottleneck,\nboth in aspects of memory consumption and data transfer bandwidth limitations.\nTo address these challenges, we propose a paradigm called KV-Latent. By\ndown-sampling the Key-Value vector dimensions into a latent space, we can\nsignificantly reduce the KV Cache footprint and improve inference speed, only\nwith a small amount of extra training, less than 1\\% of pre-training takes.\nBesides, we enhanced the stability of Rotary Positional Embedding applied on\nlower-dimensional vectors by modifying its frequency sampling mechanism,\navoiding noise introduced by higher frequencies while retaining position\nattenuation. Our experiments, including both models with Grouped Query\nAttention and those without, have yielded satisfactory results. Finally, we\nconducted comparative experiments to study the impact of separately reducing\nKey and Value components on model's performance. Our approach allows for the\nconstruction of more efficient language model systems, and opens the new\npossibility on KV Cache saving and efficient LLMs. Our code is available at\nhttps://github.com/ShiLuohe/KV-Latent.",
        "url": "http://arxiv.org/abs/2507.11273v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11273v1",
        "arxiv_id": "2507.11273v1",
        "authors": [
            "Luohe Shi",
            "Zuchao Li",
            "Lefei Zhang",
            "Guoming Liu",
            "Baoyuan Qi",
            "Hai Zhao"
        ],
        "submitted": "2025-07-15 12:52:12",
        "source": "arxiv",
        "comment": "To be published in The 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025)",
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on language models, KV cache reduction, and positional embedding, which are not directly related to your areas of interest."
    },
    {
        "title": "Journalism-Guided Agentic In-Context Learning for News Stance Detection",
        "abstract": "As online news consumption grows, personalized recommendation systems have\nbecome integral to digital journalism. However, these systems risk reinforcing\nfilter bubbles and political polarization by failing to incorporate diverse\nperspectives. Stance detection -- identifying a text's position on a target --\ncan help mitigate this by enabling viewpoint-aware recommendations and\ndata-driven analyses of media bias. Yet, existing stance detection research\nremains largely limited to short texts and high-resource languages. To address\nthese gaps, we introduce \\textsc{K-News-Stance}, the first Korean dataset for\narticle-level stance detection, comprising 2,000 news articles with\narticle-level and 19,650 segment-level stance annotations across 47 societal\nissues. We also propose \\textsc{JoA-ICL}, a \\textbf{Jo}urnalism-guided\n\\textbf{A}gentic \\textbf{I}n-\\textbf{C}ontext \\textbf{L}earning framework that\nemploys a language model agent to predict the stances of key structural\nsegments (e.g., leads, quotes), which are then aggregated to infer the overall\narticle stance. Experiments show that \\textsc{JoA-ICL} outperforms existing\nstance detection methods, highlighting the benefits of segment-level agency in\ncapturing the overall position of long-form news articles. Two case studies\nfurther demonstrate its broader utility in promoting viewpoint diversity in\nnews recommendations and uncovering patterns of media bias.",
        "url": "http://arxiv.org/abs/2507.11049v2",
        "pdf_url": "http://arxiv.org/pdf/2507.11049v2",
        "arxiv_id": "2507.11049v2",
        "authors": [
            "Dahyun Lee",
            "Jonghyeon Choi",
            "Jiyoung Han",
            "Kunwoo Park"
        ],
        "submitted": "2025-07-15 07:22:04",
        "source": "arxiv",
        "comment": "Preprint. 24 pages",
        "score": 3,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)",
            "Found 'korea' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on stance detection in news articles, which is a specific application of Natural Language Processing (NLP). While it touches on the topic of personalized recommendation systems, it does not directly relate to query understanding, ranking models, or user behavior modeling in Information Retrieval (IR). The paper's emphasis on journalism and media bias is also not directly aligned with the user's research interests."
    },
    {
        "title": "Mario at EXIST 2025: A Simple Gateway to Effective Multilingual Sexism Detection",
        "abstract": "This paper presents our approach to EXIST 2025 Task 1, addressing text-based\nsexism detection in English and Spanish tweets through hierarchical Low-Rank\nAdaptation (LoRA) of Llama 3.1 8B. Our method introduces conditional adapter\nrouting that explicitly models label dependencies across three hierarchically\nstructured subtasks: binary sexism identification, source intention detection,\nand multilabel sexism categorization. Unlike conventional LoRA applications\nthat target only attention layers, we apply adaptation to all linear\ntransformations, enhancing the model's capacity to capture task-specific\npatterns. In contrast to complex data processing and ensemble approaches, we\nshow that straightforward parameter-efficient fine-tuning achieves strong\nperformance. We train separate LoRA adapters (rank=16, QLoRA 4-bit) for each\nsubtask using unified multilingual training that leverages Llama 3.1's native\nbilingual capabilities. The method requires minimal preprocessing and uses\nstandard supervised learning. Our multilingual training strategy eliminates the\nneed for separate language-specific models, achieving 1.7-2.4\\% F1 improvements\nthrough cross-lingual transfer. With only 1.67\\% trainable parameters compared\nto full fine-tuning, our approach reduces training time by 75\\% and model\nstorage by 98\\%, while achieving competitive performance across all subtasks\n(ICM-Hard: 0.6774 for binary classification, 0.4991 for intention detection,\n0.6519 for multilabel categorization).",
        "url": "http://arxiv.org/abs/2507.10996v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10996v1",
        "arxiv_id": "2507.10996v1",
        "authors": [
            "Lin Tian",
            "Johanne R. Trippas",
            "Marian-Andrei Rizoiu"
        ],
        "submitted": "2025-07-15 05:30:32",
        "source": "arxiv",
        "comment": "12 pages, 5 tables, CLEF 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on multilingual sexism detection in tweets, which is not related to the user's interests in Information Retrieval, Search technologies, and Natural Language Processing. The techniques and applications described in the paper are not relevant to the user's areas of focus, such as query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training",
        "abstract": "Large language models (LLMs) often show poor performance in low-resource\nlanguages like Korean, partly due to unique linguistic challenges such as\nhomophonous Sino-Korean words that are indistinguishable in Hangul script. To\naddress this semantic ambiguity, we propose HanjaBridge, a novel\nmeaning-injection technique integrated into a continual pre-training (CPT)\nframework. Instead of deterministically mapping a word to a single Hanja\n(Chinese character), HanjaBridge presents the model with all possible Hanja\ncandidates for a given homograph, encouraging the model to learn contextual\ndisambiguation. This process is paired with token-level knowledge distillation\nto prevent catastrophic forgetting. Experimental results show that HanjaBridge\nsignificantly improves Korean language understanding, achieving a 21\\% relative\nimprovement on the KoBALT benchmark. Notably, by reinforcing semantic alignment\nbetween Korean and Chinese through shared Hanja, we observe a strong positive\ncross-lingual transfer. Furthermore, these gains persist even when Hanja\naugmentation is omitted at inference time, ensuring practical efficiency with\nno additional run-time cost.",
        "url": "http://arxiv.org/abs/2507.10920v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10920v1",
        "arxiv_id": "2507.10920v1",
        "authors": [
            "Seungho Choi"
        ],
        "submitted": "2025-07-15 02:26:47",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'korea' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a novel technique to address semantic ambiguity in Korean language models, which is a specific problem in NLP. While it's not directly related to information retrieval or search technologies, it's a relevant topic in NLP and could potentially be applied to IR tasks. However, the focus on Korean language and Hanja characters limits its broader applicability to the user's research interests."
    },
    {
        "title": "Seq vs Seq: An Open Suite of Paired Encoders and Decoders",
        "abstract": "The large language model (LLM) community focuses almost exclusively on\ndecoder-only language models, since they are easier to use for text generation.\nHowever, a large subset of the community still uses encoder-only models for\ntasks such as classification or retrieval. Previous work has attempted to\ncompare these architectures, but is forced to make comparisons with models that\nhave different numbers of parameters, training techniques, and datasets. We\nintroduce the SOTA open-data Ettin suite of models: paired encoder-only and\ndecoder-only models ranging from 17 million parameters to 1 billion, trained on\nup to 2 trillion tokens. Using the same recipe for both encoder-only and\ndecoder-only models produces SOTA recipes in both categories for their\nrespective sizes, beating ModernBERT as an encoder and Llama 3.2 and SmolLM2 as\ndecoders. Like previous work, we find that encoder-only models excel at\nclassification and retrieval tasks while decoders excel at generative tasks.\nHowever, we show that adapting a decoder model to encoder tasks (and vice\nversa) through continued training is subpar compared to using only the reverse\nobjective (i.e. a 400M encoder outperforms a 1B decoder on MNLI, and vice versa\nfor generative tasks). We open-source all artifacts of this study including\ntraining data, training order segmented by checkpoint, and 200+ checkpoints to\nallow future work to analyze or extend all aspects of training.",
        "url": "http://arxiv.org/abs/2507.11412v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11412v1",
        "arxiv_id": "2507.11412v1",
        "authors": [
            "Orion Weller",
            "Kathryn Ricci",
            "Marc Marone",
            "Antoine Chaffin",
            "Dawn Lawrie",
            "Benjamin Van Durme"
        ],
        "submitted": "2025-07-15 15:31:51",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on comparing encoder-only and decoder-only language models, which is related to query understanding and ranking models in Information Retrieval. However, the paper's primary focus is on language models and their applications, rather than specifically on search technologies or user behavior modeling, which are key areas of interest for your research."
    },
    {
        "title": "EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes",
        "abstract": "This technical report introduces EXAONE 4.0, which integrates a Non-reasoning\nmode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5\nand the advanced reasoning abilities of EXAONE Deep. To pave the way for the\nagentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool\nuse, and its multilingual capabilities are extended to support Spanish in\naddition to English and Korean. The EXAONE 4.0 model series consists of two\nsizes: a mid-size 32B model optimized for high performance, and a small-size\n1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates\nsuperior performance compared to open-weight models in its class and remains\ncompetitive even against frontier-class models. The models are publicly\navailable for research purposes and can be easily downloaded via\nhttps://huggingface.co/LGAI-EXAONE.",
        "url": "http://arxiv.org/abs/2507.11407v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11407v1",
        "arxiv_id": "2507.11407v1",
        "authors": [
            "LG AI Research",
            ":",
            "Kyunghoon Bae",
            "Eunbi Choi",
            "Kibong Choi",
            "Stanley Jungkyu Choi",
            "Yemuk Choi",
            "Kyubeen Han",
            "Seokhee Hong",
            "Junwon Hwang",
            "Taewan Hwang",
            "Joonwon Jang",
            "Hyojin Jeon",
            "Kijeong Jeon",
            "Gerrard Jeongwon Jo",
            "Hyunjik Jo",
            "Jiyeon Jung",
            "Euisoon Kim",
            "Hyosang Kim",
            "Jihoon Kim",
            "Joonkee Kim",
            "Seonghwan Kim",
            "Soyeon Kim",
            "Sunkyoung Kim",
            "Yireun Kim",
            "Yongil Kim",
            "Youchul Kim",
            "Edward Hwayoung Lee",
            "Gwangho Lee",
            "Haeju Lee",
            "Honglak Lee",
            "Jinsik Lee",
            "Kyungmin Lee",
            "Sangha Park",
            "Young Min Paik",
            "Yongmin Park",
            "Youngyong Park",
            "Sanghyun Seo",
            "Sihoon Yang",
            "Heuiyeen Yeen",
            "Sihyuk Yi",
            "Hyeongu Yun"
        ],
        "submitted": "2025-07-15 15:24:51",
        "source": "arxiv",
        "comment": "Technical Report, 30 Pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'search' (score: +1)",
            "Found 'korea' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on large language models, integrating non-reasoning and reasoning modes, which is not directly related to information retrieval, search technologies, or user behavior modeling. The topic is more aligned with natural language processing and deep learning, but lacks specific relevance to query understanding, ranking models, or real-time relevance optimization."
    },
    {
        "title": "DCR: Quantifying Data Contamination in LLMs Evaluation",
        "abstract": "The rapid advancement of large language models (LLMs) has heightened concerns\nabout benchmark data contamination (BDC), where models inadvertently memorize\nevaluation data, inflating performance metrics and undermining genuine\ngeneralization assessment. This paper introduces the Data Contamination Risk\n(DCR) framework, a lightweight, interpretable pipeline designed to detect and\nquantify BDC across four granular levels: semantic, informational, data, and\nlabel. By synthesizing contamination scores via a fuzzy inference system, DCR\nproduces a unified DCR Factor that adjusts raw accuracy to reflect\ncontamination-aware performance. Validated on 9 LLMs (0.5B-72B) across\nsentiment analysis, fake news detection, and arithmetic reasoning tasks, the\nDCR framework reliably diagnoses contamination severity and with accuracy\nadjusted using the DCR Factor to within 4% average error across the three\nbenchmarks compared to the uncontaminated baseline. Emphasizing computational\nefficiency and transparency, DCR provides a practical tool for integrating\ncontamination assessment into routine evaluations, fostering fairer comparisons\nand enhancing the credibility of LLM benchmarking practices.",
        "url": "http://arxiv.org/abs/2507.11405v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11405v1",
        "arxiv_id": "2507.11405v1",
        "authors": [
            "Cheng Xu",
            "Nan Yan",
            "Shuhao Guan",
            "Changhong Jin",
            "Yuke Mei",
            "Yibing Guo",
            "M-Tahar Kechadi"
        ],
        "submitted": "2025-07-15 15:23:53",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on large language models (LLMs) and benchmark data contamination, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on evaluation metrics, the topic is more relevant to NLP and model assessment, rather than IR or search technologies."
    },
    {
        "title": "LRCTI: A Large Language Model-Based Framework for Multi-Step Evidence Retrieval and Reasoning in Cyber Threat Intelligence Credibility Verification",
        "abstract": "Verifying the credibility of Cyber Threat Intelligence (CTI) is essential for\nreliable cybersecurity defense. However, traditional approaches typically treat\nthis task as a static classification problem, relying on handcrafted features\nor isolated deep learning models. These methods often lack the robustness\nneeded to handle incomplete, heterogeneous, or noisy intelligence, and they\nprovide limited transparency in decision-making-factors that reduce their\neffectiveness in real-world threat environments. To address these limitations,\nwe propose LRCTI, a Large Language Model (LLM)-based framework designed for\nmulti-step CTI credibility verification. The framework first employs a text\nsummarization module to distill complex intelligence reports into concise and\nactionable threat claims. It then uses an adaptive multi-step evidence\nretrieval mechanism that iteratively identifies and refines supporting\ninformation from a CTI-specific corpus, guided by LLM feedback. Finally, a\nprompt-based Natural Language Inference (NLI) module is applied to evaluate the\ncredibility of each claim while generating interpretable justifications for the\nclassification outcome. Experiments conducted on two benchmark datasets,\nCTI-200 and PolitiFact show that LRCTI improves F1-Macro and F1-Micro scores by\nover 5%, reaching 90.9% and 93.6%, respectively, compared to state-of-the-art\nbaselines. These results demonstrate that LRCTI effectively addresses the core\nlimitations of prior methods, offering a scalable, accurate, and explainable\nsolution for automated CTI credibility verification",
        "url": "http://arxiv.org/abs/2507.11310v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11310v1",
        "arxiv_id": "2507.11310v1",
        "authors": [
            "Fengxiao Tang",
            "Huan Li",
            "Ming Zhao",
            "Zongzong Wu",
            "Shisong Peng",
            "Tao Yin"
        ],
        "submitted": "2025-07-15 13:42:32",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a framework for credibility verification in Cyber Threat Intelligence, leveraging large language models and natural language inference. While it touches on some relevant topics like text summarization and evidence retrieval, the focus is on a specific domain (cybersecurity) and does not directly align with the user's primary interests in Information Retrieval, Search technologies, and query understanding."
    },
    {
        "title": "FMC: Formalization of Natural Language Mathematical Competition Problems",
        "abstract": "Efficient and accurate autoformalization methods, which leverage large-scale\ndatasets of extensive natural language mathematical problems to construct\nformal language datasets, are key to advancing formal mathematical reasoning.\nIn this paper, we propose an autoformalization pipeline based on large language\nmodels with error feedback, achieving a fully automatic and training-free\nformalization approach. Using this pipeline, we curate an Olympiad-level\ndataset aligning natural language problems with Lean formalizations. The\ndataset comprises $3,922$ mathematical problems in natural language and $9,787$\nin Lean, of which $64.46\\%$ were assessed as at least above-average quality,\nmaking it suitable as a benchmark for automated theorem provers. Additionally,\nwe investigate the formalization and reasoning capabilities of various LLMs and\nempirically demonstrate that few-shot learning, error feedback, and increasing\nsampling numbers enhance the autoformalization process. Experiments of three\nautomated theorem provers on the \\dataset\\ dataset also highlight its\nchallenging nature and its value as a benchmark for formal reasoning tasks.",
        "url": "http://arxiv.org/abs/2507.11275v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11275v1",
        "arxiv_id": "2507.11275v1",
        "authors": [
            "Jiaxuan Xie",
            "Chengwu Liu",
            "Ye Yuan",
            "Siqi Li",
            "Zhiping Xiao",
            "Ming Zhang"
        ],
        "submitted": "2025-07-15 12:52:47",
        "source": "arxiv",
        "comment": "Accepted in ICML 2025 AI4MATH Workshop",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it involves natural language processing, the focus is on formalizing mathematical problems, which is not a primary interest of yours."
    },
    {
        "title": "An Agentic Flow for Finite State Machine Extraction using Prompt Chaining",
        "abstract": "Finite-State Machines (FSMs) are critical for modeling the operational logic\nof network protocols, enabling verification, analysis, and vulnerability\ndiscovery. However, existing FSM extraction techniques face limitations such as\nscalability, incomplete coverage, and ambiguity in natural language\nspecifications. In this paper, we propose FlowFSM, a novel agentic framework\nthat leverages Large Language Models (LLMs) combined with prompt chaining and\nchain-of-thought reasoning to extract accurate FSMs from raw RFC documents.\nFlowFSM systematically processes protocol specifications, identifies state\ntransitions, and constructs structured rule-books by chaining agent outputs.\nExperimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM\nachieves high extraction precision while minimizing hallucinated transitions,\nshowing promising results. Our findings highlight the potential of agent-based\nLLM systems in the advancement of protocol analysis and FSM inference for\ncybersecurity and reverse engineering applications.",
        "url": "http://arxiv.org/abs/2507.11222v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11222v1",
        "arxiv_id": "2507.11222v1",
        "authors": [
            "Fares Wael",
            "Youssef Maklad",
            "Ali Hamdi",
            "Wael Elsersy"
        ],
        "submitted": "2025-07-15 11:50:25",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on Finite-State Machines, protocol analysis, and cybersecurity, which are outside your primary research areas."
    },
    {
        "title": "Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification",
        "abstract": "The growing prevalence of cross-border financial activities in global markets\nhas underscored the necessity of accurately identifying and classifying foreign\nentities. This practice is essential within the Spanish financial system for\nensuring robust risk management, regulatory adherence, and the prevention of\nfinancial misconduct. This process involves a labor-intensive entity-matching\ntask, where entities need to be validated against available reference sources.\nChallenges arise from linguistic variations, special characters, outdated\nnames, and changes in legal forms, complicating traditional matching algorithms\nlike Jaccard, cosine, and Levenshtein distances. These methods struggle with\ncontextual nuances and semantic relationships, leading to mismatches. To\naddress these limitations, we explore Large Language Models (LLMs) as a\nflexible alternative. LLMs leverage extensive training to interpret context,\nhandle abbreviations, and adapt to legal transitions. We evaluate traditional\nmethods, Hugging Face-based LLMs, and interface-based LLMs (e.g., Microsoft\nCopilot, Alibaba's Qwen 2.5) using a dataset of 65 Portuguese company cases.\nResults show traditional methods achieve accuracies over 92% but suffer high\nfalse positive rates (20-40%). Interface-based LLMs outperform, achieving\naccuracies above 93%, F1 scores exceeding 96%, and lower false positives\n(40-80%).",
        "url": "http://arxiv.org/abs/2507.11086v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11086v1",
        "arxiv_id": "2507.11086v1",
        "authors": [
            "Andres Azqueta-Gavaldn",
            "Joaquin Ramos Cosgrove"
        ],
        "submitted": "2025-07-15 08:28:24",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of Large Language Models (LLMs) for cross-border entity identification, which is not directly related to the user's primary focus on Information Retrieval, Search technologies, and query understanding. While the paper touches on the limitations of traditional algorithms, it does not address the user's specific interests in ranking models, user behavior modeling, or deep semantic understanding."
    },
    {
        "title": "First-Order Error Matters: Accurate Compensation for Quantized Large Language Models",
        "abstract": "Post-training quantization (PTQ) offers an efficient approach to compressing\nlarge language models (LLMs), significantly reducing memory access and\ncomputational costs. Existing compensation-based weight calibration methods\noften rely on a second-order Taylor expansion to model quantization error,\nunder the assumption that the first-order term is negligible in well-trained\nfull-precision models. However, we reveal that the progressive compensation\nprocess introduces accumulated first-order deviations between latent weights\nand their full-precision counterparts, making this assumption fundamentally\nflawed. To address this, we propose FOEM, a novel PTQ method that explicitly\nincorporates first-order gradient terms to improve quantization error\ncompensation. FOEM approximates gradients by directly computing the difference\nbetween latent and full-precision weights, avoiding the high cost and limited\ngeneralization of backpropagation-based gradient computation. This approach\nintroduces minimal additional computational overhead. Moreover, FOEM leverages\nprecomputed Cholesky factors to efficiently recover the inverse of Hessian\nsubmatrices in real time. Extensive experiments across a wide range of models\nand benchmarks demonstrate that FOEM consistently outperforms the classical\nGPTQ method. In 3-bit weight-only quantization, FOEM reduces the perplexity of\nLlama3-8B by 89.6%, and improves the 5-shot MMLU accuracy of Llama3-70B from\n51.7% to 74.9%, approaching the full-precision performance of 78.6%.\nFurthermore, FOEM can be seamlessly integrated with advanced techniques such as\nGPTAQ and SpinQuant, yielding additional improvements under the challenging\nW4A4KV4 setting, and further narrowing the accuracy gap with full-precision\nbaselines beyond what current state-of-the-art methods achieve. The code is\navailable at https://github.com/Xingyu-Zheng/FOEM.",
        "url": "http://arxiv.org/abs/2507.11017v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11017v1",
        "arxiv_id": "2507.11017v1",
        "authors": [
            "Xingyu Zheng",
            "Haotong Qin",
            "Yuye Li",
            "Jiakai Wang",
            "Jinyang Guo",
            "Michele Magno",
            "Xianglong Liu"
        ],
        "submitted": "2025-07-15 06:18:46",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on post-training quantization of large language models, which is a topic in Natural Language Processing, but not directly related to your core interests."
    },
    {
        "title": "Teach Me Sign: Stepwise Prompting LLM for Sign Language Production",
        "abstract": "Large language models, with their strong reasoning ability and rich\nknowledge, have brought revolution to many tasks of AI, but their impact on\nsign language generation remains limited due to its complexity and unique\nrules. In this paper, we propose TEAch Me Sign (TEAM-Sign), treating sign\nlanguage as another natural language. By fine-tuning an LLM, we enable it to\nlearn the correspondence between text and sign language, and facilitate\ngeneration. Considering the differences between sign and spoken language, we\nemploy a stepwise prompting strategy to extract the inherent sign language\nknowledge within the LLM, thereby supporting the learning and generation\nprocess. Experimental results on How2Sign and Phoenix14T datasets demonstrate\nthat our approach effectively leverages both the sign language knowledge and\nreasoning capabilities of LLM to align the different distribution and\ngrammatical rules between sign and spoken language.",
        "url": "http://arxiv.org/abs/2507.10972v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10972v1",
        "arxiv_id": "2507.10972v1",
        "authors": [
            "Zhaoyi An",
            "Rei Kawakami"
        ],
        "submitted": "2025-07-15 04:31:52",
        "source": "arxiv",
        "comment": "Accepted by IEEE ICIP 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on sign language generation using large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it employs a stepwise prompting strategy, the paper's primary concern is sign language production, which is outside the user's core research themes."
    },
    {
        "title": "Supporting SENOTEN Language Documentation Efforts with Automatic Speech Recognition",
        "abstract": "The SEN\\'{C}OTEN language, spoken on the Saanich peninsula of southern\nVancouver Island, is in the midst of vigorous language revitalization efforts\nto turn the tide of language loss as a result of colonial language policies. To\nsupport these on-the-ground efforts, the community is turning to digital\ntechnology. Automatic Speech Recognition (ASR) technology holds great promise\nfor accelerating language documentation and the creation of educational\nresources. However, developing ASR systems for SEN\\'{C}OTEN is challenging due\nto limited data and significant vocabulary variation from its polysynthetic\nstructure and stress-driven metathesis. To address these challenges, we propose\nan ASR-driven documentation pipeline that leverages augmented speech data from\na text-to-speech (TTS) system and cross-lingual transfer learning with Speech\nFoundation Models (SFMs). An n-gram language model is also incorporated via\nshallow fusion or n-best restoring to maximize the use of available data.\nExperiments on the SEN\\'{C}OTEN dataset show a word error rate (WER) of 19.34%\nand a character error rate (CER) of 5.09% on the test set with a 57.02%\nout-of-vocabulary (OOV) rate. After filtering minor cedilla-related errors, WER\nimproves to 14.32% (26.48% on unseen words) and CER to 3.45%, demonstrating the\npotential of our ASR-driven pipeline to support SEN\\'{C}OTEN language\ndocumentation.",
        "url": "http://arxiv.org/abs/2507.10827v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10827v1",
        "arxiv_id": "2507.10827v1",
        "authors": [
            "Mengzhe Geng",
            "Patrick Littell",
            "Aidan Pine",
            "PEN",
            "Marc Tessier",
            "Roland Kuhn"
        ],
        "submitted": "2025-07-14 21:44:35",
        "source": "arxiv",
        "comment": "Accepted by ComputEL-8",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on developing an Automatic Speech Recognition system for the SENOTEN language, which is not related to Information Retrieval, Search technologies, or Natural Language Processing. The paper's primary concern is language documentation and revitalization, which is outside the scope of the user's research interests."
    },
    {
        "title": "Testing Hypotheses from the Social Approval Theory of Online Hate: An Analysis of 110 Million Posts from Parler",
        "abstract": "In this paper, we explored how online hate is motivated by receiving social\napproval from others. We specifically examined two central tenets of Walther's\n(2024) social approval theory of online hate: (H1a) more signals of social\napproval on hate messages predicts more subsequent hate messages, and (H1b) as\nsocial approval increases, hate speech messages become more extreme. Using over\n110 million posts from Parler (2018-2021), we observed that the number of\nupvotes a person received on a hate speech post was unassociated with the\namount of hate speech in their next post and posts during the next week, month,\nthree months, and six months. Between-person effects revealed an average\nnegative relationship between social approval and hate speech production at the\npost level, but this relationship was mixed at other time intervals. Social\napproval reinforcement mechanisms of online hate may operate differently on\nniche social media platforms.",
        "url": "http://arxiv.org/abs/2507.10810v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10810v1",
        "arxiv_id": "2507.10810v1",
        "authors": [
            "David M. Markowitz",
            "Samuel Hardman Taylor"
        ],
        "submitted": "2025-07-14 21:10:39",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper's focus on social approval theory of online hate and its analysis of hate speech posts on Parler is outside the user's primary research areas."
    },
    {
        "title": "Theory of Mind and Self-Disclosure to CUIs",
        "abstract": "Self-disclosure is important to help us feel better, yet is often difficult.\nThis difficulty can arise from how we think people are going to react to our\nself-disclosure. In this workshop paper, we briefly discuss self-disclosure to\nconversational user interfaces (CUIs) in relation to various social cues. We\nthen, discuss how expressions of uncertainty or representation of a CUI's\nreasoning could help encourage self-disclosure, by making a CUI's intended\n\"theory of mind\" more transparent to users.",
        "url": "http://arxiv.org/abs/2507.10773v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10773v1",
        "arxiv_id": "2507.10773v1",
        "authors": [
            "Samuel Rhys Cox"
        ],
        "submitted": "2025-07-14 19:57:18",
        "source": "arxiv",
        "comment": "Workshop paper presented at ToMinHAI at CUI'2025: Theory of Mind in\n  Human-CUI Interaction, held in conjunction with the 2025 ACM conference on\n  Conversational User Interfaces, July 8th, 2025. 4 pages. 3 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The topic of self-disclosure to conversational user interfaces is outside the scope of the user's primary focus on information retrieval and deep semantic understanding."
    },
    {
        "title": "Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs",
        "abstract": "Labeled property graphs often contain rich textual attributes that can\nenhance analytical tasks when properly leveraged. This work explores the use of\npretrained text embedding models to enable efficient semantic analysis in such\ngraphs. By embedding textual node and edge properties, we support downstream\ntasks including node classification and relation prediction with improved\ncontextual understanding. Our approach integrates language model embeddings\ninto the graph pipeline without altering its structure, demonstrating that\ntextual semantics can significantly enhance the accuracy and interpretability\nof property graph analysis.",
        "url": "http://arxiv.org/abs/2507.10772v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10772v1",
        "arxiv_id": "2507.10772v1",
        "authors": [
            "Michal Podstawski"
        ],
        "submitted": "2025-07-14 19:53:56",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of text embedding models in property graphs, which is related to information retrieval and NLP. However, the focus is on graph analysis and node classification, which is not directly aligned with the user's primary interest in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air",
        "abstract": "Operating Large Language Models (LLMs) on edge devices is increasingly\nchallenged by limited communication bandwidth and strained computational and\nmemory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable.\nNevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ\nfixed or heuristic rank configurations, and the subsequent over-the-air\ntransmission of all LoRA parameters could be rather inefficient. To address\nthis limitation, we develop AirLLM, a hierarchical diffusion policy framework\nfor communication-aware LoRA adaptation. Specifically, AirLLM models the rank\nconfiguration as a structured action vector that spans all LoRA-inserted\nprojections. To solve the underlying high-dimensional sequential\ndecision-making problem, a Proximal Policy Optimization (PPO) agent generates\ncoarse-grained decisions by jointly observing wireless states and linguistic\ncomplexity, which are then refined via Denoising Diffusion Implicit Models\n(DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The\ntwo modules are optimized alternatively, with the DDIM trained under the\nClassifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards.\nExperiments under varying signal-to-noise ratios demonstrate that AirLLM\nconsistently enhances fine-tuning performance while significantly reducing\ntransmission costs, highlighting the effectiveness of reinforcement-driven,\ndiffusion-refined rank adaptation for scalable and efficient remote fine-tuning\nover the air.",
        "url": "http://arxiv.org/abs/2507.11515v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11515v1",
        "arxiv_id": "2507.11515v1",
        "authors": [
            "Shiyi Yang",
            "Xiaoxue Yu",
            "Rongpeng Li",
            "Jianhang Zhu",
            "Zhifeng Zhao",
            "Honggang Zhang"
        ],
        "submitted": "2025-07-15 17:36:37",
        "source": "arxiv",
        "comment": "11 pages, 8 figures",
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on remote fine-tuning of Large Language Models over the air, using a hierarchical diffusion policy framework. While it mentions 'rank configuration' and 'projections', the context is unclear and seems unrelated to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval and Search technologies."
    },
    {
        "title": "Real-World Summarization: When Evaluation Reaches Its Limits",
        "abstract": "We examine evaluation of faithfulness to input data in the context of hotel\nhighlights: brief LLM-generated summaries that capture unique features of\naccommodations. Through human evaluation campaigns involving categorical error\nassessment and span-level annotation, we compare traditional metrics, trainable\nmethods, and LLM-as-a-judge approaches. Our findings reveal that simpler\nmetrics like word overlap correlate surprisingly well with human judgments\n(Spearman correlation rank of 0.63), often outperforming more complex methods\nwhen applied to out-of-domain data. We further demonstrate that while LLMs can\ngenerate high-quality highlights, they prove unreliable for evaluation as they\ntend to severely under- or over-annotate. Our analysis of real-world business\nimpacts shows incorrect and non-checkable information pose the greatest risks.\nWe also highlight challenges in crowdsourced evaluations.",
        "url": "http://arxiv.org/abs/2507.11508v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11508v1",
        "arxiv_id": "2507.11508v1",
        "authors": [
            "Patrcia Schmidtov",
            "Ondej Duek",
            "Saad Mahamood"
        ],
        "submitted": "2025-07-15 17:23:56",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on summarization and evaluation metrics, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on natural language processing, the context is different from the user's primary interests in IR and search technologies."
    },
    {
        "title": "What is the Best Process Model Representation? A Comparative Analysis for Process Modeling with Large Language Models",
        "abstract": "Large Language Models (LLMs) are increasingly applied for Process Modeling\n(PMo) tasks such as Process Model Generation (PMG). To support these tasks,\nresearchers have introduced a variety of Process Model Representations (PMRs)\nthat serve as model abstractions or generation targets. However, these PMRs\ndiffer widely in structure, complexity, and usability, and have never been\nsystematically compared. Moreover, recent PMG approaches rely on distinct\nevaluation strategies and generation techniques, making comparison difficult.\nThis paper presents the first empirical study that evaluates multiple PMRs in\nthe context of PMo with LLMs. We introduce the PMo Dataset, a new dataset\ncontaining 55 process descriptions paired with models in nine different PMRs.\nWe evaluate PMRs along two dimensions: suitability for LLM-based PMo and\nperformance on PMG. \\textit{Mermaid} achieves the highest overall score across\nsix PMo criteria, whereas \\textit{BPMN text} delivers the best PMG results in\nterms of process element similarity.",
        "url": "http://arxiv.org/abs/2507.11356v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11356v1",
        "arxiv_id": "2507.11356v1",
        "authors": [
            "Alexis Brissard",
            "Frdric Cuppens",
            "Amal Zouaq"
        ],
        "submitted": "2025-07-15 14:26:50",
        "source": "arxiv",
        "comment": "12 pages, 7 figures, to be published in AI4BPM 2025 Proceedings",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on Process Modeling and Large Language Models, which is outside the user's primary research interests."
    },
    {
        "title": "Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded Term Lexicon, and Enhanced Detection Frameworks",
        "abstract": "The proliferation of hate speech has inflicted significant societal harm,\nwith its intensity and directionality closely tied to specific targets and\narguments. In recent years, numerous machine learning-based methods have been\ndeveloped to detect hateful comments on online platforms automatically.\nHowever, research on Chinese hate speech detection lags behind, and\ninterpretability studies face two major challenges: first, the scarcity of\nspan-level fine-grained annotated datasets limits models' deep semantic\nunderstanding of hate speech; second, insufficient research on identifying and\ninterpreting coded hate speech restricts model explainability in complex\nreal-world scenarios. To address these, we make the following contributions:\n(1) We introduce the Span-level Target-Aware Toxicity Extraction dataset (STATE\nToxiCN), the first span-level Chinese hate speech dataset, and evaluate the\nhate semantic understanding of existing models using it. (2) We conduct the\nfirst comprehensive study on Chinese coded hate terms, LLMs' ability to\ninterpret hate semantics. (3) We propose a method to integrate an annotated\nlexicon into models, significantly enhancing hate speech detection performance.\nOur work provides valuable resources and insights to advance the\ninterpretability of Chinese hate speech detection research.",
        "url": "http://arxiv.org/abs/2507.11292v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11292v1",
        "arxiv_id": "2507.11292v1",
        "authors": [
            "Zewen Bai",
            "Liang Yang",
            "Shengdi Yin",
            "Yuanyuan Sun",
            "Hongfei Lin"
        ],
        "submitted": "2025-07-15 13:19:18",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on hate speech detection in Chinese, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on interpretability and semantic understanding is not specific to the user's areas of interest, and the recommender systems aspect is not explored."
    },
    {
        "title": "Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding",
        "abstract": "Large Language Models (LLMs) enable new possibilities for qualitative\nresearch at scale, including coding and data annotation. While multi-agent\nsystems (MAS) can emulate human coding workflows, their benefits over\nsingle-agent coding remain poorly understood. We conducted an experimental\nstudy of how agent persona and temperature shape consensus-building and coding\naccuracy of dialog segments based on a codebook with 8 codes. Our open-source\nMAS mirrors deductive human coding through structured agent discussion and\nconsensus arbitration. Using six open-source LLMs (with 3 to 32 billion\nparameters) and 18 experimental configurations, we analyze over 77,000 coding\ndecisions against a gold-standard dataset of human-annotated transcripts from\nonline math tutoring sessions. Temperature significantly impacted whether and\nwhen consensus was reached across all six LLMs. MAS with multiple personas\n(including neutral, assertive, or empathetic), significantly delayed consensus\nin four out of six LLMs compared to uniform personas. In three of those LLMs,\nhigher temperatures significantly diminished the effects of multiple personas\non consensus. However, neither temperature nor persona pairing lead to robust\nimprovements in coding accuracy. Single agents matched or outperformed MAS\nconsensus in most conditions. Only one model (OpenHermesV2:7B) and code\ncategory showed above-chance gains from MAS deliberation when temperature was\n0.5 or lower and especially when the agents included at least one assertive\npersona. Qualitative analysis of MAS collaboration for these configurations\nsuggests that MAS may nonetheless aid in narrowing ambiguous code applications\nthat could improve codebooks and human-AI coding. We contribute new insight\ninto the limits of LLM-based qualitative methods, challenging the notion that\ndiverse MAS personas lead to better outcomes. We open-source our MAS and\nexperimentation code.",
        "url": "http://arxiv.org/abs/2507.11198v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11198v1",
        "arxiv_id": "2507.11198v1",
        "authors": [
            "Conrad Borchers",
            "Bahar Shahrokhian",
            "Francesco Balzan",
            "Elham Tajik",
            "Sreecharan Sankaranarayanan",
            "Sebastian Simon"
        ],
        "submitted": "2025-07-15 11:06:32",
        "source": "arxiv",
        "comment": "Manuscript submitted for review",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on Large Language Models, multi-agent systems, and qualitative coding, which is outside the user's primary research interests."
    },
    {
        "title": "What Should LLMs Forget? Quantifying Personal Data in LLMs for Right-to-Be-Forgotten Requests",
        "abstract": "Large Language Models (LLMs) can memorize and reveal personal information,\nraising concerns regarding compliance with the EU's GDPR, particularly the\nRight to Be Forgotten (RTBF). Existing machine unlearning methods assume the\ndata to forget is already known but do not address how to identify which\nindividual-fact associations are stored in the model. Privacy auditing\ntechniques typically operate at the population level or target a small set of\nidentifiers, limiting applicability to individual-level data inquiries. We\nintroduce WikiMem, a dataset of over 5,000 natural language canaries covering\n243 human-related properties from Wikidata, and a model-agnostic metric to\nquantify human-fact associations in LLMs. Our approach ranks ground-truth\nvalues against counterfactuals using calibrated negative log-likelihood across\nparaphrased prompts. We evaluate 200 individuals across 15 LLMs (410M-70B\nparameters), showing that memorization correlates with subject web presence and\nmodel scale. We provide a foundation for identifying memorized personal data in\nLLMs at the individual level, enabling the dynamic construction of forget sets\nfor machine unlearning and RTBF requests.",
        "url": "http://arxiv.org/abs/2507.11128v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11128v1",
        "arxiv_id": "2507.11128v1",
        "authors": [
            "Dimitri Staufer"
        ],
        "submitted": "2025-07-15 09:28:44",
        "source": "arxiv",
        "comment": "16 pages, 3 figures. Accepted at the 7th Workshop on eXplainable\n  Knowledge Discovery in Data Mining (XKDD 2025), ECML PKDD 2025, Porto,\n  Portugal",
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on the topic of privacy and data protection in Large Language Models (LLMs), which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on machine unlearning and Right-to-Be-Forgotten requests is also outside the user's primary focus."
    },
    {
        "title": "Team HUMANE at AVeriTeC 2025: HerO 2 for Efficient Fact Verification",
        "abstract": "This paper presents HerO 2, Team HUMANE's system for the AVeriTeC shared task\nat the FEVER-25 workshop. HerO 2 is an enhanced version of HerO, the\nbest-performing open-source model from the previous year's challenge. It\nimproves evidence quality through document summarization and answer\nreformulation, optimizes veracity prediction via post-training quantization\nunder computational constraints, and enhances overall system performance by\nintegrating updated language model (LM) backbones. HerO 2 ranked second on the\nleaderboard while achieving the shortest runtime among the top three systems,\ndemonstrating both high efficiency and strong potential for real-world fact\nverification. The code is available at https://github.com/ssu-humane/HerO2.",
        "url": "http://arxiv.org/abs/2507.11004v1",
        "pdf_url": "http://arxiv.org/pdf/2507.11004v1",
        "arxiv_id": "2507.11004v1",
        "authors": [
            "Yejun Yoon",
            "Jaeyoon Jung",
            "Seunghyun Yoon",
            "Kunwoo Park"
        ],
        "submitted": "2025-07-15 05:42:50",
        "source": "arxiv",
        "comment": "ACL 2025 Workshop (FEVER)",
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. Although it mentions language models, it focuses on fact verification, which is a different area of research."
    },
    {
        "title": "Modeling Understanding of Story-Based Analogies Using Large Language Models",
        "abstract": "Recent advancements in Large Language Models (LLMs) have brought them closer\nto matching human cognition across a variety of tasks. How well do these models\nalign with human performance in detecting and mapping analogies? Prior research\nhas shown that LLMs can extract similarities from analogy problems but lack\nrobust human-like reasoning. Building on Webb, Holyoak, and Lu (2023), the\ncurrent study focused on a story-based analogical mapping task and conducted a\nfine-grained evaluation of LLM reasoning abilities compared to human\nperformance. First, it explored the semantic representation of analogies in\nLLMs, using sentence embeddings to assess whether they capture the similarity\nbetween the source and target texts of an analogy, and the dissimilarity\nbetween the source and distractor texts. Second, it investigated the\neffectiveness of explicitly prompting LLMs to explain analogies. Throughout, we\nexamine whether LLMs exhibit similar performance profiles to those observed in\nhumans by evaluating their reasoning at the level of individual analogies, and\nnot just at the level of overall accuracy (as prior studies have done). Our\nexperiments include evaluating the impact of model size (8B vs. 70B parameters)\nand performance variation across state-of-the-art model architectures such as\nGPT-4 and LLaMA3. This work advances our understanding of the analogical\nreasoning abilities of LLMs and their potential as models of human reasoning.",
        "url": "http://arxiv.org/abs/2507.10957v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10957v1",
        "arxiv_id": "2507.10957v1",
        "authors": [
            "Kalit Inani",
            "Keshav Kabra",
            "Vijay Marupudi",
            "Sashank Varma"
        ],
        "submitted": "2025-07-15 03:40:21",
        "source": "arxiv",
        "comment": "To appear at CogSci 2025",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the understanding of story-based analogies using Large Language Models, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on the topic of semantic representation and model performance, it does not address ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest for your research."
    },
    {
        "title": "Unraveling the Biomarker Prospects of High-Altitude Diseases: Insights from Biomolecular Event Network Constructed using Text Mining",
        "abstract": "High-altitude diseases (HAD), encompassing acute mountain sickness (AMS),\nhigh-altitude cerebral edema (HACE), and high-altitude pulmonary edema (HAPE),\nare triggered by hypobaric hypoxia at elevations above 2,500 meters. These\nconditions pose significant health risks, yet the molecular mechanisms remain\ninsufficiently understood. In this study, we developed a biomolecular event\nextraction pipeline integrating supervised machine learning with feature-based\nand multiscale Laplacian graph kernels to analyze 7,847 curated HAD-related\nabstracts from PubMed. We extracted over 150 unique biomolecular events\nincluding gene expression, regulation, binding, and localization and\nconstructed a weighted, undirected biomolecular event network comprising 97\nnodes and 153 edges. Using the PageRank algorithm, we prioritized key\nbiomolecules based on their centrality within the event network. The top-ranked\nproteins included Erythropoietin (EPO) (0.0163), Vascular endothelial growth\nfactor (VEGF) (0.0148), Hypoxia-inducible factor 1 (HIF-1) alpha (0.0136),\nEndothelial PAS Domain Protein 1 (EPAS1) and Angiotensin-Converting Enzyme\n(ACE) (0.0119), Egl nine homolog 1 (EGLN1), Endothelin 1 (ET-1), and 70\nkilodalton heat shock protein (Hsp70)(0.0118), all of which play crucial roles\nin oxygen sensing, vascular remodeling, erythropoiesis, and blood pressure\nregulation. Subnetwork analysis revealed three major functional clusters\ncentered on hypoxia response, inflammation, and stress adaptation pathways. Our\nintegrative approach demonstrates the utility of large-scale text mining and\ngraph-based analysis to uncover mechanistic insights and prioritize potential\nbiomarkers for high-altitude disease.",
        "url": "http://arxiv.org/abs/2507.10953v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10953v1",
        "arxiv_id": "2507.10953v1",
        "authors": [
            "Balu Bhasuran",
            "Sabenabanu Abdulkadhar",
            "Jeyakumar Natarajan"
        ],
        "submitted": "2025-07-15 03:34:00",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on biomolecular event extraction and network analysis in the context of high-altitude diseases, which is outside the user's primary research areas."
    },
    {
        "title": "LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation",
        "abstract": "Recently, much effort has been devoted to modeling users' multi-interests\nbased on their behaviors or auxiliary signals. However, existing methods often\nrely on heuristic assumptions, e.g., co-occurring items indicate the same\ninterest of users, failing to capture user multi-interests aligning with\nreal-world scenarios. While large language models (LLMs) show significant\npotential for multi-interest analysis due to their extensive knowledge and\npowerful reasoning capabilities, two key challenges remain. First, the\ngranularity of LLM-driven multi-interests is agnostic, possibly leading to\noverly fine or coarse interest grouping. Second, individual user analysis\nprovides limited insights due to the data sparsity issue. In this paper, we\npropose an LLM-driven dual-level multi-interest modeling framework for more\neffective recommendation. At the user-individual level, we exploit LLMs to\nflexibly allocate items engaged by users into different semantic clusters,\nindicating their diverse and distinct interests. To alleviate the agnostic\ngeneration of LLMs, we adaptively assign these semantic clusters to users'\ncollaborative multi-interests learned from global user-item interactions,\nallowing the granularity to be automatically adjusted according to the user's\nbehaviors using an alignment module. To alleviate the limited insights derived\nfrom individual users' behaviors, at the user-crowd level, we propose\naggregating user cliques into synthesized users with rich behaviors for more\ncomprehensive LLM-driven multi-interest analysis. We formulate a max covering\nproblem to ensure the compactness and representativeness of synthesized users'\nbehaviors, and then conduct contrastive learning based on their LLM-driven\nmulti-interests to disentangle item representations among different interests.\nExperiments on real-world datasets show the superiority of our approach against\nstate-of-the-art methods.",
        "url": "http://arxiv.org/abs/2507.10917v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10917v1",
        "arxiv_id": "2507.10917v1",
        "authors": [
            "Ziyan Wang",
            "Yingpeng Du",
            "Zhu Sun",
            "Jieyi Bi",
            "Haoyan Chua",
            "Tianjun Wei",
            "Jie Zhang"
        ],
        "submitted": "2025-07-15 02:13:54",
        "source": "arxiv",
        "comment": "10 pages, 5 figures",
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a framework for multi-interest modeling using large language models, which is related to query understanding and user behavior modeling in the context of information retrieval. However, the focus on recommendation systems and the use of LLMs for item clustering and representation learning are not directly aligned with the user's primary research interests in search technologies and ranking models."
    },
    {
        "title": "NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization",
        "abstract": "Language-guided navigation is a cornerstone of embodied AI, enabling agents\nto interpret language instructions and navigate complex environments. However,\nexpert-provided instructions are limited in quantity, while synthesized\nannotations often lack quality, making them insufficient for large-scale\nresearch. To address this, we propose NavComposer, a novel framework for\nautomatically generating high-quality navigation instructions. NavComposer\nexplicitly decomposes semantic entities such as actions, scenes, and objects,\nand recomposes them into natural language instructions. Its modular\narchitecture allows flexible integration of state-of-the-art techniques, while\nthe explicit use of semantic entities enhances both the richness and accuracy\nof instructions. Moreover, it operates in a data-agnostic manner, supporting\nadaptation to diverse navigation trajectories without domain-specific training.\nComplementing NavComposer, we introduce NavInstrCritic, a comprehensive\nannotation-free evaluation system that assesses navigation instructions on\nthree dimensions: contrastive matching, semantic consistency, and linguistic\ndiversity. NavInstrCritic provides a holistic evaluation of instruction\nquality, addressing limitations of traditional metrics that rely heavily on\nexpert annotations. By decoupling instruction generation and evaluation from\nspecific navigation agents, our method enables more scalable and generalizable\nresearch. Extensive experiments provide direct and practical evidence for the\neffectiveness of our method.",
        "url": "http://arxiv.org/abs/2507.10894v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10894v1",
        "arxiv_id": "2507.10894v1",
        "authors": [
            "Zongtao He",
            "Liuyi Wang",
            "Lu Chen",
            "Chengju Liu",
            "Qijun Chen"
        ],
        "submitted": "2025-07-15 01:20:22",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a framework for generating navigation instructions, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing, the focus is on language-guided navigation rather than search or retrieval. The paper's relevance to the user's interests is limited, but it may be of interest to those working on embodied AI or natural language processing."
    },
    {
        "title": "Domain-Adaptive Small Language Models for Structured Tax Code Prediction",
        "abstract": "Every day, multinational firms process thousands of transactions, each of\nwhich must adhere to tax regulations that vary by jurisdiction and are often\nnuanced. The determination of product and service tax codes, such as HSN or SAC\nis a major use case in Tax compliance. An accurate determination of such codes\nis imperative to avoid any tax penalties. This paper proposes a domain-adaptive\nsmall language model (SLM) with an encoder-decoder architecture for the\nenhanced prediction of product and service tax codes. In this approach, we\naddress the problem of predicting hierarchical tax code sequences using\nunstructured product and services data. We employ an SLM based upon\nencoder-decoder architecture as this enables sequential generation of tax codes\nto capture the hierarchical dependencies present within the tax codes. Our\nexperiments demonstrate that encoder-decoder SLMs can be successfully applied\nto the sequential prediction of structured tax codes, a domain that remains\ncomparatively unexplored in current NLP research. In this paper, we demonstrate\nthe superior performance of the domain-adaptive encoder-decoder SLMs over flat\nclassifiers when applied to the Harmonized System of Nomenclature (HSN), and\nachieve superior results compared to decoder-only and encoder-only\narchitectures for structured sequence generation tasks. This approach can also\nbe scaled to other government-mandated tax commodity codes, such as United\nNations Standard Products and Services Codes (UNSPSC), or Brazil's Nomenclatura\nComum do Mercosul (NCM).",
        "url": "http://arxiv.org/abs/2507.10880v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10880v1",
        "arxiv_id": "2507.10880v1",
        "authors": [
            "Souvik Nath",
            "Sumit Wadhwa",
            "Luiz Perez"
        ],
        "submitted": "2025-07-15 00:46:01",
        "source": "arxiv",
        "comment": "10 pages, 3 figures",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on structured tax code prediction using small language models, which is not directly related to information retrieval, search technologies, or query understanding. While it involves NLP, the domain is specific to tax compliance and does not align with the user's broader interests in e-commerce, data mining, or real-time relevance optimization."
    },
    {
        "title": "LLMs on Trial: Evaluating Judicial Fairness for Large Language Models",
        "abstract": "Large Language Models (LLMs) are increasingly used in high-stakes fields\nwhere their decisions impact rights and equity. However, LLMs' judicial\nfairness and implications for social justice remain underexplored. When LLMs\nact as judges, the ability to fairly resolve judicial issues is a prerequisite\nto ensure their trustworthiness. Based on theories of judicial fairness, we\nconstruct a comprehensive framework to measure LLM fairness, leading to a\nselection of 65 labels and 161 corresponding values. Applying this framework to\nthe judicial system, we compile an extensive dataset, JudiFair, comprising\n177,100 unique case facts. To achieve robust statistical inference, we develop\nthree evaluation metrics, inconsistency, bias, and imbalanced inaccuracy, and\nintroduce a method to assess the overall fairness of multiple LLMs across\nvarious labels. Through experiments with 16 LLMs, we uncover pervasive\ninconsistency, bias, and imbalanced inaccuracy across models, underscoring\nsevere LLM judicial unfairness. Particularly, LLMs display notably more\npronounced biases on demographic labels, with slightly less bias on substance\nlabels compared to procedure ones. Interestingly, increased inconsistency\ncorrelates with reduced biases, but more accurate predictions exacerbate\nbiases. While we find that adjusting the temperature parameter can influence\nLLM fairness, model size, release date, and country of origin do not exhibit\nsignificant effects on judicial fairness. Accordingly, we introduce a publicly\navailable toolkit containing all datasets and code, designed to support future\nresearch in evaluating and improving LLM fairness.",
        "url": "http://arxiv.org/abs/2507.10852v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10852v1",
        "arxiv_id": "2507.10852v1",
        "authors": [
            "Yiran Hu",
            "Zongyue Xue",
            "Haitao Li",
            "Siyuan Zheng",
            "Qingjing Chen",
            "Shaochun Wang",
            "Xihan Zhang",
            "Ning Zheng",
            "Yun Liu",
            "Qingyao Ai",
            "Yiqun Liu",
            "Charles L. A. Clarke",
            "Weixing Shen"
        ],
        "submitted": "2025-07-14 22:56:58",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus is on evaluating the fairness of Large Language Models in a judicial context, which is outside your primary areas of interest."
    },
    {
        "title": "Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case",
        "abstract": "Background Large language models (LLMs) face challenges in inductive thematic\nanalysis, a task requiring deep interpretive and domain-specific expertise. We\nevaluated the feasibility of using LLMs to replicate expert-driven thematic\nanalysis of social media data. Methods Using two temporally non-intersecting\nReddit datasets on xylazine (n=286 and n=686, for model optimization and\nvalidation, respectively) with twelve expert-derived themes, we evaluated five\nLLMs against expert coding. We modeled the task as a series of binary\nclassifications, rather than a single, multi-label classification, employing\nzero-, single-, and few-shot prompting strategies and measuring performance via\naccuracy, precision, recall, and F1-score. Results On the validation set,\nGPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:\n0.71). For high-prevalence themes, model-derived thematic distributions closely\nmirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:\n16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based\napproaches can automate thematic analyses, offering a scalable supplement for\nqualitative research. Keywords: thematic analysis, large language models,\nnatural language processing, qualitative analysis, social media, prompt\nengineering, public health",
        "url": "http://arxiv.org/abs/2507.10803v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10803v1",
        "arxiv_id": "2507.10803v1",
        "authors": [
            "JaMor Hairston",
            "Ritvik Ranjan",
            "Sahithi Lakamana",
            "Anthony Spadaro",
            "Selen Bozkurt",
            "Jeanmarie Perrone",
            "Abeed Sarker"
        ],
        "submitted": "2025-07-14 20:57:52",
        "source": "arxiv",
        "comment": "Pages: 19, Abstract word count: 151 words, Manuscript word count:\n  2185 words, References: 14, Figures: 3, Tables: 2",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of large language models (LLMs) in thematic analysis, which is related to natural language processing (NLP) and information retrieval (IR). However, the focus on social media data and public health is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling, making it only loosely relevant."
    },
    {
        "title": "Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers",
        "abstract": "This paper introduces MISS-QA, the first benchmark specifically designed to\nevaluate the ability of models to interpret schematic diagrams within\nscientific literature. MISS-QA comprises 1,500 expert-annotated examples over\n465 scientific papers. In this benchmark, models are tasked with interpreting\nschematic diagrams that illustrate research overviews and answering\ncorresponding information-seeking questions based on the broader context of the\npaper. We assess the performance of 18 frontier multimodal foundation models,\nincluding o4-mini, Gemini-2.5-Flash, and Qwen2.5-VL. We reveal a significant\nperformance gap between these models and human experts on MISS-QA. Our analysis\nof model performance on unanswerable questions and our detailed error analysis\nfurther highlight the strengths and limitations of current models, offering key\ninsights to enhance models in comprehending multimodal scientific literature.",
        "url": "http://arxiv.org/abs/2507.10787v1",
        "pdf_url": "http://arxiv.org/pdf/2507.10787v1",
        "arxiv_id": "2507.10787v1",
        "authors": [
            "Yilun Zhao",
            "Chengye Wang",
            "Chuhan Li",
            "Arman Cohan"
        ],
        "submitted": "2025-07-14 20:35:25",
        "source": "arxiv",
        "comment": "ACL 2025 Findings",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores multimodal foundation models' ability to understand schematic diagrams in scientific papers, which is related to information retrieval and query understanding. However, the focus on multimodal foundation models and scientific papers is not directly aligned with the user's interests in e-commerce and real-time relevance optimization."
    }
]