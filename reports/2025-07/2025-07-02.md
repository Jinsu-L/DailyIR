# Daily Papers Report - 2025-07-02

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Question Decomposition for Retrieval-Augmented Generation

- **LLM Score**: 8
- **Keyword Score**: 14
- **Authors**: Paul J. L. Ammann, Jonas Golde, Alan Akbik
- **URL**: <http://arxiv.org/abs/2507.00355v1>
- **Submitted**: 2025-07-01 01:01:54
- **Comment**: Accepted to ACL SRW 2025. 9 Pages, 2 Figures, 4 Tables
- **Topic Keywords**: query, ranking, rerank, rag, retrieval, rank
- **Reason**: The paper explores retrieval-augmented generation, which aligns with your interest in Information Retrieval and Search technologies. The focus on question decomposition and reranking models is also relevant to your research themes, particularly in the context of query understanding and ranking models. However, the paper's primary focus is on question answering and retrieval for specific tasks, which is somewhat narrower than your broader interests in NLP and data mining.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Multi-hop Question Answering using Retrieval-Augmented Generation (RAG) pipeline
- **Aim**: To propose a RAG pipeline that incorporates question decomposition (QD) and reranking (RR) to address the challenges of multi-hop question answering
- **Rationale**: The QD module breaks down complex queries into focused subqueries, increasing retrieval coverage, while the RR module filters out noise and scores each retrieved document based on its relevance to the original complex query
- **Ground**: The authors evaluate their approach on the MultiHop-RAG and HotpotQA datasets, demonstrating substantial gains in retrieval recall, ranking quality, and final answer accuracy over standard RAG and single-component variants
- **Experiment**: The proposed pipeline (QD+RR) achieves the strongest results overall, with improvements in Hits@k, MAP@10, MRR@10, answer EM, F1, precision, and recall
- **Takeaway**: The paper presents a comprehensive approach to multi-hop question answering, highlighting the strengths and limitations of combining QD and RR in RAG pipelines, and suggests potential directions for future research

#### Abstract
> Grounding large language models (LLMs) in verifiable external sources is a
well-established strategy for generating reliable answers. Retrieval-augmented
generation (RAG) is one such approach, particularly effective for tasks like
question answering: it retrieves passages that are semantically related to the
question and then conditions the model on this evidence. However, multi-hop
questions, such as "Which company among NVIDIA, Apple, and Google made the
biggest profit in 2023?," challenge RAG because relevant facts are often
distributed across multiple documents rather than co-occurring in one source,
making it difficult for standard RAG to retrieve sufficient information. To
address this, we propose a RAG pipeline that incorporates question
decomposition: (i) an LLM decomposes the original query into sub-questions,
(ii) passages are retrieved for each sub-question, and (iii) the merged
candidate pool is reranked to improve the coverage and precision of the
retrieved evidence. We show that question decomposition effectively assembles
complementary documents, while reranking reduces noise and promotes the most
relevant passages before answer generation. Although reranking itself is
standard, we show that pairing an off-the-shelf cross-encoder reranker with
LLM-driven question decomposition bridges the retrieval gap on multi-hop
questions and provides a practical, drop-in enhancement, without any extra
training or specialized indexing. We evaluate our approach on the MultiHop-RAG
and HotpotQA, showing gains in retrieval (MRR@10: +36.7%) and answer accuracy
(F1: +11.6%) over standard RAG baselines.

---

### 2. MassTool: A Multi-Task Search-Based Tool Retrieval Framework for Large Language Models

- **LLM Score**: 7
- **Keyword Score**: 11
- **Authors**: Jianghao Lin, Xinyuan Wang, Xinyi Dai, Menghui Zhu, Bo Chen, Ruiming Tang, Yong Yu, Weinan Zhang
- **URL**: <http://arxiv.org/abs/2507.00487v2>
- **Submitted**: 2025-07-01 07:02:26
- **Topic Keywords**: query, queries, rag, retrieval, search
- **Reason**: The paper focuses on tool retrieval for large language models, which is related to information retrieval and search technologies. The use of query-centric graph convolution network (QC-GCN) for query-tool matching and search-based user intent modeling (SUIM) for handling diverse queries are relevant to query understanding and ranking models. However, the paper's primary focus is on tool retrieval, which is not directly aligned with the user's core research themes.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: MassTool: A Novel Multi-Task Search-Based Framework for Tool Retrieval in Large Language Models
- **Aim**: To develop a framework that enhances query representation and tool retrieval accuracy for large language models (LLMs) by addressing the challenges of tool retrieval, including capturing diverse user intents and handling out-of-distribution (OOD) user queries
- **Rationale**: The proposed framework, MassTool, employs a two-tower architecture consisting of a tool usage detection tower and a tool retrieval tower, and incorporates search-based user intent modeling (SUIM) and an adaptive knowledge transfer (AdaKT) module for efficient multi-task learning
- **Ground**: The authors introduce a new dataset, ToolDet, which consists of 31,229 non-tool-invocation queries, and formulate the tool retrieval problem as a dual-step sequential decision-making problem
- **Experiment**: Extensive experiments are conducted on three public datasets, validating the superiority of MassTool for query comprehension and tool retrieval compared to existing baseline methods
- **Takeaway**: MassTool is effective in capturing nuanced user intent and addressing the dual-step sequential decision-making nature of tool retrieval, and has the potential to explore the synergy between tool-augmented LLMs and external tools with the tool retriever as the bridge

#### Abstract
> Tool retrieval is a critical component in enabling large language models
(LLMs) to interact effectively with external tools. It aims to precisely filter
the massive tools into a small set of candidates for the downstream
tool-augmented LLMs. However, most existing approaches primarily focus on
optimizing tool representations, often neglecting the importance of precise
query comprehension. To address this gap, we introduce MassTool, a multi-task
search-based framework designed to enhance both query representation and tool
retrieval accuracy. MassTool employs a two-tower architecture: a tool usage
detection tower that predicts the need for function calls, and a tool retrieval
tower that leverages a query-centric graph convolution network (QC-GCN) for
effective query-tool matching. It also incorporates search-based user intent
modeling (SUIM) to handle diverse and out-of-distribution queries, alongside an
adaptive knowledge transfer (AdaKT) module for efficient multi-task learning.
By jointly optimizing tool usage detection loss, list-wise retrieval loss, and
contrastive regularization loss, MassTool establishes a robust dual-step
sequential decision-making pipeline for precise query understanding. Extensive
experiments demonstrate its effectiveness in improving retrieval accuracy. Our
code is available at https://github.com/wxydada/MassTool.

---

### 3. Read the Docs Before Rewriting: Equip Rewriter with Domain Knowledge via Continual Pre-training

- **LLM Score**: 6
- **Keyword Score**: 10
- **Authors**: Qi Wang, Yixuan Cao, Yifan Liu, Jiangtao Zhao, Ping Luo
- **URL**: <http://arxiv.org/abs/2507.00477v1>
- **Submitted**: 2025-07-01 06:51:00
- **Topic Keywords**: query, queries, rag, retrieval
- **Reason**: The paper explores Retrieval-Augmented Generation (RAG) for question-answering, which is related to Information Retrieval. The focus on query rewriting and domain-specific knowledge is also relevant to query understanding and ranking models. However, the paper's primary focus on question-answering and language models is not directly aligned with the user's interests in search technologies and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Retrieval-Augmented Generation (RAG) for question-answering (QA) systems
- **Aim**: To enhance the retrieval process in RAG by incorporating domain knowledge and addressing the 'Query-Document Discrepancy' challenge
- **Rationale**: By rewriting user queries using domain-specific knowledge and continual pre-training, the system can better retrieve relevant documents and improve QA performance
- **Ground**: The proposed method, R&R, is evaluated on four datasets and compared with several baselines, demonstrating its effectiveness in professional QA across multiple domains
- **Experiment**: The experimental results show that R&R excels in professional QA, is resource-efficient, and outperforms baselines across all datasets, with the combination of continual pretraining and supervised fine-tuning yielding the best performance
- **Takeaway**: The R&R method has the potential to significantly improve QA performance in professional domains, but its limitations include its inability to improve performance in the general domain and its dependency on domain corpora

#### Abstract
> A Retrieval-Augmented Generation (RAG)-based question-answering (QA) system
enhances a large language model's knowledge by retrieving relevant documents
based on user queries. Discrepancies between user queries and document
phrasings often necessitate query rewriting. However, in specialized domains,
the rewriter model may struggle due to limited domain-specific knowledge. To
resolve this, we propose the R\&R (Read the doc before Rewriting) rewriter,
which involves continual pre-training on professional documents, akin to how
students prepare for open-book exams by reviewing textbooks. Additionally, it
can be combined with supervised fine-tuning for improved results. Experiments
on multiple datasets demonstrate that R\&R excels in professional QA across
multiple domains, effectively bridging the query-document gap, while
maintaining good performance in general scenarios, thus advancing the
application of RAG-based QA systems in specialized fields.

---

### 4. ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context

- **LLM Score**: 6
- **Keyword Score**: 3
- **Authors**: Joongwon Kim, Anirudh Goyal, Liang Tan, Hannaneh Hajishirzi, Srinivasan Iyer, Tianlu Wang
- **URL**: <http://arxiv.org/abs/2507.00417v1>
- **Submitted**: 2025-07-01 04:10:15
- **Comment**: 36 pages, 23 figures
- **Topic Keywords**: rag, search
- **Reason**: The paper introduces a framework for training language models to reason like search algorithms, leveraging self-reflection, backtracking, and exploration. While it's related to search technologies and query understanding, the focus is on reasoning models rather than ranking models or user behavior modeling, which are core areas of interest. The connection to information retrieval is indirect, but the paper's emphasis on search-inspired training and its application to language models makes it somewhat relevant.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Training language models to reason like search algorithms
- **Aim**: Enhance the reasoning capabilities of non-reasoner models, including Llama 3
- **Rationale**: Recent advancements in training large language models via reinforcement learning have led to improved reasoning capabilities, but it is unclear how to enhance the reasoning capabilities of non-reasoner models
- **Ground**: ASTRO framework leverages self-reflection, backtracking, and exploration in its outputs, and uses a synthetic dataset derived from Monte Carlo Tree Search over mathematical problem-solving trajectories
- **Experiment**: Applying ASTRO to the Llama 3 family of models, fine-tuning on search-derived traces and further improving via RL with verifiable rewards
- **Takeaway**: Achieving absolute performance gains of 16.0%, 26.9%, and 20.0% on MATH-500, AMC 2023, and AIME 2024, respectively, particularly improving on challenging problems requiring iterative correction

#### Abstract
> We introduce ASTRO, the "Autoregressive Search-Taught Reasoner", a framework
for training language models to reason like search algorithms, explicitly
leveraging self-reflection, backtracking, and exploration in their outputs.
Recently, training large language models (LLMs) via reinforcement learning (RL)
has led to the advent of reasoning models with greatly enhanced reasoning
capabilities. Open-source replications of reasoning models, while successful,
build upon models that already exhibit strong reasoning capabilities along with
search behavior observed even before RL. As a result, it is yet unclear how to
boost the reasoning capabilities of other non-reasoner models including Llama
3. ASTRO teaches such models to internalize structured search behavior through
a synthetic dataset derived from Monte Carlo Tree Search (MCTS) over
mathematical problem-solving trajectories. By converting search traces into
natural language chain-of-thoughts that capture both successes and recoveries
from failure, ASTRO bootstraps models with a rich prior for exploration during
RL. We finetune our models on these search-derived traces and further improve
performance via RL with verifiable rewards. We apply ASTRO to the Llama 3
family of models and achieve absolute performance gains of 16.0% on MATH-500,
26.9% on AMC 2023, and 20.0% on AIME 2024, especially improving upon
challenging problems that require iterative correction. Our results demonstrate
that search-inspired training offers a principled way to instill robust
reasoning capabilities into open LLMs.

---

### 5. LineRetriever: Planning-Aware Observation Reduction for Web Agents

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Imene Kerboua, Sahar Omidi Shayegan, Megh Thakkar, Xing Han L√π, Massimo Caccia, V√©ronique Eglin, Alexandre Aussem, J√©r√©my Espinas, Alexandre Lacoste
- **URL**: <http://arxiv.org/abs/2507.00210v1>
- **Submitted**: 2025-06-30 19:24:45
- **Topic Keywords**: retriever, rag, retrieval
- **Reason**: The paper introduces a novel approach for web agents to retrieve relevant information for adaptive planning, leveraging a language model to identify observation lines. While it touches on retrieval methods, it does not specifically focus on query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval. The paper's relevance is somewhat related, but not a central match.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Planning-Aware Observation Reduction in Web Agents Powered by Large Language Models
- **Aim**: To develop a novel approach for reducing observation size in web agents while maintaining performance, addressing the challenge of processing modern websites with large context windows
- **Rationale**: Existing retrieval mechanisms in zero-shot settings rely solely on semantic similarity, which does not always provide all necessary information, and LineRetriever addresses this by leveraging a language model to identify and retrieve relevant observation lines
- **Ground**: The evolution of web agents with the integration of large language models for understanding and interacting with complex web interfaces, with existing approaches relying on AxTrees, DOM, or screen-shots, each having its limitations
- **Experiment**: Experimental evaluation on three benchmarks (WorkArena L1, Weblinx, and WebArena) with two post-processing approaches (direct line removal and structure-preserving filtering) and comparison with two baselines (Observation Bottom Truncation and Embedding Retrieval)
- **Takeaway**: LineRetriever achieves remarkable observation reductions up to 73% while maintaining competitive performance, outperforming embedding-based approaches, and demonstrating the importance of preserving structural integrity and planning-aware context reduction for scalable web agents

#### Abstract
> While large language models have demonstrated impressive capabilities in web
navigation tasks, the extensive context of web pages, often represented as DOM
or Accessibility Tree (AxTree) structures, frequently exceeds model context
limits. Current approaches like bottom-up truncation or embedding-based
retrieval lose critical information about page state and action history. This
is particularly problematic for adaptive planning in web agents, where
understanding the current state is essential for determining future actions. We
hypothesize that embedding models lack sufficient capacity to capture
plan-relevant information, especially when retrieving content that supports
future action prediction. This raises a fundamental question: how can retrieval
methods be optimized for adaptive planning in web navigation tasks? In
response, we introduce \textit{LineRetriever}, a novel approach that leverages
a language model to identify and retrieve observation lines most relevant to
future navigation steps. Unlike traditional retrieval methods that focus solely
on semantic similarity, \textit{LineRetriever} explicitly considers the
planning horizon, prioritizing elements that contribute to action prediction.
Our experiments demonstrate that \textit{LineRetriever} can reduce the size of
the observation at each step for the web agent while maintaining consistent
performance within the context limitations.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Digital Collections Explorer: An Open-Source, Multimodal Viewer for Searching Digital Collections

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Ying-Hsiang Huang, Benjamin Charles Germain Lee
- **URL**: <http://arxiv.org/abs/2507.00961v1>
- **Submitted**: 2025-07-01 17:10:34
- **Comment**: 14 pages, 8 figures, 2 tables
- **Topic Keywords**: queries, rag, search
- **Reason**: The paper presents a multimodal search platform for digital collections, leveraging CLIP for visual discovery. While it touches on search and retrieval aspects, its focus is more on the platform's architecture and implementation, rather than query understanding, ranking models, or user behavior modeling, which are key areas of interest in Information Retrieval. The paper's relevance to the user's research is somewhat limited.

#### Abstract
> We present Digital Collections Explorer, a web-based, open-source exploratory
search platform that leverages CLIP (Contrastive Language-Image Pre-training)
for enhanced visual discovery of digital collections. Our Digital Collections
Explorer can be installed locally and configured to run on a visual collection
of interest on disk in just a few steps. Building upon recent advances in
multimodal search techniques, our interface enables natural language queries
and reverse image searches over digital collections with visual features. This
paper describes the system's architecture, implementation, and application to
various cultural heritage collections, demonstrating its potential for
democratizing access to digital archives, especially those with impoverished
metadata. We present case studies with maps, photographs, and PDFs extracted
from web archives in order to demonstrate the flexibility of the Digital
Collections Explorer, as well as its ease of use. We demonstrate that the
Digital Collections Explorer scales to hundreds of thousands of images on a
MacBook Pro with an M4 chip. Lastly, we host a public demo of Digital
Collections Explorer.

### 7. TeamCMU at Touch√©: Adversarial Co-Evolution for Advertisement Integration and Detection in Conversational Search

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: To Eun Kim, Jo√£o Coelho, Gbemileke Onilude, Jai Singh
- **URL**: <http://arxiv.org/abs/2507.00509v1>
- **Submitted**: 2025-07-01 07:24:29
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper focuses on advertisement integration and detection in conversational search, which is a specific application of search technologies. While it involves query understanding and ranking models, the primary focus is on advertisement management rather than information retrieval. The paper's relevance to the user's interests is somewhat limited, but it does touch on some related topics.

#### Abstract
> As conversational search engines increasingly adopt generation-based
paradigms powered by Large Language Models (LLMs) and Retrieval-Augmented
Generation (RAG), the integration of advertisements into generated responses
presents both commercial opportunities and challenges for user experience.
Unlike traditional search, where advertisements are clearly delineated,
generative systems blur the boundary between informational content and
promotional material, raising concerns around transparency and trust. In this
work, we propose a modular pipeline for advertisement management in RAG-based
conversational systems, consisting of an ad-rewriter for seamless ad
integration and a robust ad-classifier for detection. We leverage synthetic
data to train high-performing classifiers, which are then used to guide two
complementary ad-integration strategies: supervised fine-tuning of the
ad-rewriter and a best-of-N sampling approach that selects the least detectable
ad-integrated response among multiple candidates. Our evaluation focuses on two
core questions: the effectiveness of ad classifiers in detecting diverse ad
integration strategies, and the training methods that best support coherent,
minimally intrusive ad insertion. Experimental results show that our
ad-classifier, trained on synthetic advertisement data inspired by marketing
strategies and enhanced through curriculum learning, achieves robust detection
performance. Additionally, we demonstrate that classifier-guided optimization,
through both fine-tuning and best-of-N sampling, significantly improves ad
stealth, enabling more seamless integration. These findings contribute an
adversarial co-evolution framework for developing more sophisticated ad-aware
generative search systems and robust ad classifiers.

### 8. Rethinking Group Recommender Systems in the Era of Generative AI: From One-Shot Recommendations to Agentic Group Decision Support

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Dietmar Jannach, Amra Deliƒá, Francesco Ricci, Markus Zanker
- **URL**: <http://arxiv.org/abs/2507.00535v1>
- **Submitted**: 2025-07-01 07:56:37
- **Comment**: Submitted for publication
- **Topic Keywords**: rag, recommend, search
- **Reason**: The paper explores group recommender systems, which is a related topic to information retrieval and search technologies. However, the focus on Generative AI and chat-based interaction is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's emphasis on group decision-making and chat-based interfaces is also not a central match for the user's research themes.

#### Abstract
> More than twenty-five years ago, first ideas were developed on how to design
a system that can provide recommendations to groups of users instead of
individual users. Since then, a rich variety of algorithmic proposals were
published, e.g., on how to acquire individual preferences, how to aggregate
them, and how to generate recommendations for groups of users. However, despite
the rich literature on the topic, barely any examples of real-world group
recommender systems can be found. This lets us question common assumptions in
academic research, in particular regarding communication processes in a group
and how recommendation-supported decisions are made. In this essay, we argue
that these common assumptions and corresponding system designs often may not
match the needs or expectations of users. We thus call for a reorientation in
this research area, leveraging the capabilities of modern Generative AI
assistants like ChatGPT. Specifically, as one promising future direction, we
envision group recommender systems to be systems where human group members
interact in a chat and an AI-based group recommendation agent assists the
decision-making process in an agentic way. Ultimately, this shall lead to a
more natural group decision-making environment and finally to wider adoption of
group recommendation systems in practice.

### 9. Embedding-based Retrieval in Multimodal Content Moderation

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Hanzhong Liang, Jinghao Shi, Xiang Shen, Zixuan Wang, Vera Wen, Ardalan Mehrani, Zhiqian Chen, Yifan Wu, Zhixin Zhang
- **URL**: <http://arxiv.org/abs/2507.01066v1>
- **Submitted**: 2025-06-30 19:11:25
- **Comment**: Camera ready for SIGIR 2025
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on content moderation in short video platforms, using embedding-based retrieval to improve trend handling. While it involves multimodal content and retrieval, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core aspects of your research interests in Information Retrieval and Search technologies.

#### Abstract
> Video understanding plays a fundamental role for content moderation on short
video platforms, enabling the detection of inappropriate content. While
classification remains the dominant approach for content moderation, it often
struggles in scenarios requiring rapid and cost-efficient responses, such as
trend adaptation and urgent escalations. To address this issue, we introduce an
Embedding-Based Retrieval (EBR) method designed to complement traditional
classification approaches. We first leverage a Supervised Contrastive Learning
(SCL) framework to train a suite of foundation embedding models, including both
single-modal and multi-modal architectures. Our models demonstrate superior
performance over established contrastive learning methods such as CLIP and
MoCo. Building on these embedding models, we design and implement the
embedding-based retrieval system that integrates embedding generation and video
retrieval to enable efficient and effective trend handling. Comprehensive
offline experiments on 25 diverse emerging trends show that EBR improves
ROC-AUC from 0.85 to 0.99 and PR-AUC from 0.35 to 0.95. Further online
experiments reveal that EBR increases action rates by 10.32% and reduces
operational costs by over 80%, while also enhancing interpretability and
flexibility compared to classification-based solutions.

### 10. Table Understanding and (Multimodal) LLMs: A Cross-Domain Case Study on Scientific vs. Non-Scientific Data

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Ekaterina Borisova, Fabio Barth, Nils Feldhus, Raia Abu Ahmad, Malte Ostendorff, Pedro Ortiz Suarez, Georg Rehm, Sebastian M√∂ller
- **URL**: <http://arxiv.org/abs/2507.00152v1>
- **Submitted**: 2025-06-30 18:04:36
- **Comment**: TRL@ACL 2025, camera-ready version
- **Topic Keywords**: relevance, search
- **Reason**: The paper explores the application of Large Language Models (LLMs) to table understanding tasks, which is related to information retrieval and natural language processing. However, the focus on table understanding and multimodal LLMs is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Tables are among the most widely used tools for representing structured data
in research, business, medicine, and education. Although LLMs demonstrate
strong performance in downstream tasks, their efficiency in processing tabular
data remains underexplored. In this paper, we investigate the effectiveness of
both text-based and multimodal LLMs on table understanding tasks through a
cross-domain and cross-modality evaluation. Specifically, we compare their
performance on tables from scientific vs. non-scientific contexts and examine
their robustness on tables represented as images vs. text. Additionally, we
conduct an interpretability analysis to measure context usage and input
relevance. We also introduce the TableEval benchmark, comprising 3017 tables
from scholarly publications, Wikipedia, and financial reports, where each table
is provided in five different formats: Image, Dictionary, HTML, XML, and LaTeX.
Our findings indicate that while LLMs maintain robustness across table
modalities, they face significant challenges when processing scientific tables.

### 11. TUM-MiKaNi at SemEval-2025 Task 3: Towards Multilingual and Knowledge-Aware Non-factual Hallucination Identification

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Miriam Ansch√ºtz, Ekaterina Gikalo, Niklas Herbster, Georg Groh
- **URL**: <http://arxiv.org/abs/2507.00579v1>
- **Submitted**: 2025-07-01 09:00:50
- **Comment**: 6 pages, 3 figures, SemEval-2025 Task 3, ACL
- **Topic Keywords**: retrieval, search
- **Reason**: The paper focuses on hallucinations in Large Language Models (LLMs), which is a related topic to query understanding and ranking models. However, the paper's primary focus is on identifying hallucinations rather than query understanding or ranking models, and it does not directly relate to user behavior modeling or real-time relevance optimization. The paper's connection to information retrieval is indirect, as it aims to improve LLM outputs, which can potentially impact search results.

#### Abstract
> Hallucinations are one of the major problems of LLMs, hindering their
trustworthiness and deployment to wider use cases. However, most of the
research on hallucinations focuses on English data, neglecting the multilingual
nature of LLMs. This paper describes our submission to the SemEval-2025 Task-3
- Mu-SHROOM, the Multilingual Shared-task on Hallucinations and Related
Observable Overgeneration Mistakes. We propose a two-part pipeline that
combines retrieval-based fact verification against Wikipedia with a BERT-based
system fine-tuned to identify common hallucination patterns. Our system
achieves competitive results across all languages, reaching top-10 results in
eight languages, including English. Moreover, it supports multiple languages
beyond the fourteen covered by the shared task. This multilingual hallucination
identifier can help to improve LLM outputs and their usefulness in the future.

### 12. Reliable Annotations with Less Effort: Evaluating LLM-Human Collaboration in Search Clarifications

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Leila Tavakoli, Hamed Zamani
- **URL**: <http://arxiv.org/abs/2507.00543v1>
- **Submitted**: 2025-07-01 08:04:58
- **Comment**: 9 pages,5 figures
- **Topic Keywords**: rag, search
- **Reason**: The paper explores the collaboration between large language models (LLMs) and humans in search clarifications, which is related to query understanding and ranking models. However, the focus on annotation and evaluation tasks is not directly aligned with my primary research interests in information retrieval, search technologies, and user behavior modeling.

#### Abstract
> Despite growing interest in using large language models (LLMs) to automate
annotation, their effectiveness in complex, nuanced, and multi-dimensional
labelling tasks remains relatively underexplored. This study focuses on
annotation for the search clarification task, leveraging a high-quality,
multi-dimensional dataset that includes five distinct fine-grained annotation
subtasks. Although LLMs have shown impressive capabilities in general settings,
our study reveals that even state-of-the-art models struggle to replicate
human-level performance in subjective or fine-grained evaluation tasks. Through
a systematic assessment, we demonstrate that LLM predictions are often
inconsistent, poorly calibrated, and highly sensitive to prompt variations. To
address these limitations, we propose a simple yet effective human-in-the-loop
(HITL) workflow that uses confidence thresholds and inter-model disagreement to
selectively involve human review. Our findings show that this lightweight
intervention significantly improves annotation reliability while reducing human
effort by up to 45%, offering a relatively scalable and cost-effective yet
accurate path forward for deploying LLMs in real-world evaluation settings.

### 13. Overcoming Long-Context Limitations of State-Space Models via Context-Dependent Sparse Attention

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Zhihao Zhan, Jianan Zhao, Zhaocheng Zhu, Jian Tang
- **URL**: <http://arxiv.org/abs/2507.00449v1>
- **Submitted**: 2025-07-01 06:03:50
- **Comment**: Proceedings of the 42nd International Conference on Machine Learning,
  ES-FoMo III: 3rd Workshop on Efficient Systems for Foundation Models, 18
  pages, 9 figures
- **Topic Keywords**: query
- **Reason**: The paper focuses on state-space models and attention mechanisms, which are not directly related to information retrieval, query understanding, or ranking models. While it touches on natural language processing, the specific context and methodology are not aligned with the user's primary research interests.

#### Abstract
> Efficient long-context modeling remains a critical challenge for natural
language processing (NLP), as the time complexity of the predominant
Transformer architecture scales quadratically with the sequence length. While
state-space models (SSMs) offer alternative sub-quadratic solutions, they
struggle to capture long-range dependencies effectively. In this work, we focus
on analyzing and improving the long-context modeling capabilities of SSMs. We
show that the widely used synthetic task, associative recall, which requires a
model to recall a value associated with a single key without context,
insufficiently represents the complexities of real-world long-context modeling.
To address this limitation, we extend the associative recall to a novel
synthetic task, \emph{joint recall}, which requires a model to recall the value
associated with a key given in a specified context. Theoretically, we prove
that SSMs do not have the expressiveness to solve multi-query joint recall in
sub-quadratic time complexity. To resolve this issue, we propose a solution
based on integrating SSMs with Context-Dependent Sparse Attention (CDSA), which
has the expressiveness to solve multi-query joint recall with sub-quadratic
computation. To bridge the gap between theoretical analysis and real-world
applications, we propose locality-sensitive Hashing Attention with sparse Key
Selection (HAX), which instantiates the theoretical solution and is further
tailored to natural language domains. Extensive experiments on both synthetic
and real-world long-context benchmarks show that HAX consistently outperforms
SSM baselines and SSMs integrated with context-independent sparse attention
(CISA).

### 14. Beyond Sociodemographic Prompting: Using Supervision to Align LLMs with Human Response Distributions

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Gauri Kambhatla, Sanjana Gautam, Angela Zhang, Alex Liu, Ravi Srinivasan, Junyi Jessy Li, Matthew Lease
- **URL**: <http://arxiv.org/abs/2507.00439v1>
- **Submitted**: 2025-07-01 05:46:22
- **Topic Keywords**: rag, search
- **Reason**: The paper explores the alignment of language models with human response distributions, which is related to query understanding and ranking models in Information Retrieval. However, the focus on language models and population groups is not directly aligned with the user's interests in search technologies, user behavior modeling, and deep semantic understanding.

#### Abstract
> The ability to accurately predict how different population groups would
answer subjective questions would have great value. In this work, we show that
use of relatively simple supervision can greatly improve language model
alignment with diverse population groups, as measured over three datasets
spanning various topics. Beyond evaluating average performance, we also report
how alignment varies across specific groups. The simplicity and generality of
our approach promotes easy adoption, while our broad findings provide useful
guidance for when to use or not use our approach in practice. By conducting
evaluation over many LLMs and prompting strategies, along with open-sourcing
our work, we provide a useful benchmark to stimulate future research.

### 15. Two-Stage Reasoning-Infused Learning: Improving Classification with LLM-Generated Reasoning

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Mads Henrichsen, Rasmus Krebs
- **URL**: <http://arxiv.org/abs/2507.00214v1>
- **Submitted**: 2025-06-30 19:34:57
- **Topic Keywords**: rag
- **Reason**: The paper explores the use of Large Language Model-generated reasonings to improve text classification, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on text classification and emotion prediction is not directly aligned with the user's primary interests in search technologies and user behavior modeling.

#### Abstract
> Standard classification models often map inputs directly to labels without
explicit reasoning, potentially limiting their performance, robustness, and
interpretability. This paper introduces a novel two-stage approach to enhance
text classification by leveraging Large Language Model (LLM)-generated
reasonings. In the first stage, we fine-tune a Llama-3.2-1B-Instruct model
(henceforth Llama-R-Gen) on a general-purpose reasoning dataset
(syvai/reasoning-gen) to generate textual reasoning (R) given a question and
its answer. In the second stage, this generally trained Llama-R-Gen is used
offline to create an augmented training dataset for a downstream generative
model. This downstream model, based on Llama-3.2-1B-Instruct, takes only the
input text (Q) and is trained to output the generated reasoning (R) immediately
followed by the predicted emotion (A). We demonstrate this methodology on the
dair-ai/emotion dataset for emotion classification. Our experiments show that
the generative model trained to output reasoning and the emotion (Classifier
Q->RA) achieves a significant improvement of 8.7 percentage points in accuracy
(for emotion prediction) compared to a baseline generative model trained solely
to output the emotion (Classifier Q->A), highlighting the strong generalization
capabilities of the reasoning generation and the benefit of explicit reasoning
training. This work underscores the potential of LLM-generated reasonings for
creating richer training datasets, thereby improving the performance of diverse
downstream NLP tasks and providing explicit explanations.

### 16. Should We Still Pretrain Encoders with Masked Language Modeling?

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Hippolyte Gisserot-Boukhlef, Nicolas Boizard, Manuel Faysse, Duarte M. Alves, Emmanuel Malherbe, Andr√© F. T. Martins, C√©line Hudelot, Pierre Colombo
- **URL**: <http://arxiv.org/abs/2507.00994v1>
- **Submitted**: 2025-07-01 17:45:48
- **Comment**: 23 pages, 10 figures, 17 tables
- **Topic Keywords**: search
- **Reason**: The paper explores the effectiveness of different pretraining objectives for encoder models in NLP tasks, which is related to my interests in NLP and information retrieval. However, the focus on masked language modeling and causal language modeling is not directly aligned with my primary research themes, such as query understanding, ranking models, and user behavior modeling.

#### Abstract
> Learning high-quality text representations is fundamental to a wide range of
NLP tasks. While encoder pretraining has traditionally relied on Masked
Language Modeling (MLM), recent evidence suggests that decoder models
pretrained with Causal Language Modeling (CLM) can be effectively repurposed as
encoders, often surpassing traditional encoders on text representation
benchmarks. However, it remains unclear whether these gains reflect an inherent
advantage of the CLM objective or arise from confounding factors such as model
and data scale. In this paper, we address this question through a series of
large-scale, carefully controlled pretraining ablations, training a total of 30
models ranging from 210 million to 1 billion parameters, and conducting over
15,000 fine-tuning and evaluation runs. We find that while training with MLM
generally yields better performance across text representation tasks,
CLM-trained models are more data-efficient and demonstrate improved fine-tuning
stability. Building on these findings, we experimentally show that a biphasic
training strategy that sequentially applies CLM and then MLM, achieves optimal
performance under a fixed computational training budget. Moreover, we
demonstrate that this strategy becomes more appealing when initializing from
readily available pretrained CLM models (from the existing LLM ecosystem),
reducing the computational burden needed to train best-in-class encoder models.
We release all project artifacts at https://hf.co/MLMvsCLM to foster further
research.

### 17. On Mitigating Data Sparsity in Conversational Recommender Systems

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Sixiao Zhang, Mingrui Liu, Cheng Long, Wei Yuan, Hongxu Chen, Xiangyu Zhao, Hongzhi Yin
- **URL**: <http://arxiv.org/abs/2507.00479v1>
- **Submitted**: 2025-07-01 06:54:51
- **Topic Keywords**: recommend
- **Reason**: The paper focuses on conversational recommender systems, which is a related topic to information retrieval. However, the paper's primary concern is on mitigating data sparsity in CRSs, which is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's techniques, such as dialogue augmentation and knowledge-guided entity modeling, are not directly applicable to the user's areas of interest.

#### Abstract
> Conversational recommender systems (CRSs) capture user preference through
textual information in dialogues. However, they suffer from data sparsity on
two fronts: the dialogue space is vast and linguistically diverse, while the
item space exhibits long-tail and sparse distributions. Existing methods
struggle with (1) generalizing to varied dialogue expressions due to
underutilization of rich textual cues, and (2) learning informative item
representations under severe sparsity. To address these problems, we propose a
CRS model named DACRS. It consists of three modules, namely Dialogue
Augmentation, Knowledge-Guided Entity Modeling, and Dialogue-Entity Matching.
In the Dialogue Augmentation module, we apply a two-stage augmentation pipeline
to augment the dialogue context to enrich the data and improve
generalizability. In the Knowledge-Guided Entity Modeling, we propose a
knowledge graph (KG) based entity substitution and an entity similarity
constraint to enhance the expressiveness of entity embeddings. In the
Dialogue-Entity Matching module, we fuse the dialogue embedding with the
mentioned entity embeddings through a dialogue-guided attention aggregation to
acquire user embeddings that contain both the explicit and implicit user
preferences. Extensive experiments on two public datasets demonstrate the
state-of-the-art performance of DACRS.

### 18. SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks

- **LLM Score**: 2
- **Keyword Score**: 10
- **Authors**: Yilun Zhao, Kaiyan Zhang, Tiansheng Hu, Sihong Wu, Ronan Le Bras, Taira Anderson, Jonathan Bragg, Joseph Chee Chang, Jesse Dodge, Matt Latzke, Yixin Liu, Charles McGrady, Xiangru Tang, Zihang Wang, Chen Zhao, Hannaneh Hajishirzi, Doug Downey, Arman Cohan
- **URL**: <http://arxiv.org/abs/2507.01001v1>
- **Submitted**: 2025-07-01 17:51:59
- **Topic Keywords**: ranking, pairwise, rag, rank, search
- **Reason**: The paper focuses on evaluating foundation models on scientific literature tasks, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on natural language processing and data mining, the scope is narrow and not aligned with the user's primary research interests.

#### Abstract
> We present SciArena, an open and collaborative platform for evaluating
foundation models on scientific literature tasks. Unlike traditional benchmarks
for scientific literature understanding and synthesis, SciArena engages the
research community directly, following the Chatbot Arena evaluation approach of
community voting on model comparisons. By leveraging collective intelligence,
SciArena offers a community-driven evaluation of model performance on
open-ended scientific tasks that demand literature-grounded, long-form
responses. The platform currently supports 23 open-source and proprietary
foundation models and has collected over 13,000 votes from trusted researchers
across diverse scientific domains. We analyze the data collected so far and
confirm that the submitted questions are diverse, aligned with real-world
literature needs, and that participating researchers demonstrate strong
self-consistency and inter-annotator agreement in their evaluations. We discuss
the results and insights based on the model ranking leaderboard. To further
promote research in building model-based automated evaluation systems for
literature tasks, we release SciArena-Eval, a meta-evaluation benchmark based
on our collected preference data. The benchmark measures the accuracy of models
in judging answer quality by comparing their pairwise assessments with human
votes. Our experiments highlight the benchmark's challenges and emphasize the
need for more reliable automated evaluation methods.

### 19. WebANNS: Fast and Efficient Approximate Nearest Neighbor Search in Web Browsers

- **LLM Score**: 2
- **Keyword Score**: 8
- **Authors**: Mugeng Liu, Siqi Zhong, Qi Yang, Yudong Han, Xuanzhe Liu, Yun Ma
- **URL**: <http://arxiv.org/abs/2507.00521v2>
- **Submitted**: 2025-07-01 07:37:18
- **Comment**: SIGIR 2025
- **Topic Keywords**: query, rag, retrieval, search
- **Reason**: This paper focuses on approximate nearest neighbor search in web browsers, which is not directly related to information retrieval, query understanding, ranking models, or user behavior modeling. While it touches on retrieval-augmented generation, the primary focus is on the technical challenges of ANNS in web browsers, which is not a core area of interest for the user.

#### Abstract
> Approximate nearest neighbor search (ANNS) has become vital to modern AI
infrastructure, particularly in retrieval-augmented generation (RAG)
applications. Numerous in-browser ANNS engines have emerged to seamlessly
integrate with popular LLM-based web applications, while addressing privacy
protection and challenges of heterogeneous device deployments. However, web
browsers present unique challenges for ANNS, including computational
limitations, external storage access issues, and memory utilization
constraints, which state-of-the-art (SOTA) solutions fail to address
comprehensively. We propose WebANNS, a novel ANNS engine specifically designed
for web browsers. WebANNS leverages WebAssembly to overcome computational
bottlenecks, designs a lazy loading strategy to optimize data retrieval from
external storage, and applies a heuristic approach to reduce memory usage.
Experiments show that WebANNS is fast and memory efficient, achieving up to
$743.8\times$ improvement in 99th percentile query latency over the SOTA
engine, while reducing memory usage by up to 39\%. Note that WebANNS decreases
query time from 10 seconds to the 10-millisecond range in browsers, making
in-browser ANNS practical with user-acceptable latency.

### 20. Leveraging Large Language Models for Spontaneous Speech-Based Suicide Risk Detection

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Yifan Gao, Jiao Fu, Long Guo, Hong Liu
- **URL**: <http://arxiv.org/abs/2507.00693v1>
- **Submitted**: 2025-07-01 11:45:23
- **Comment**: Accepted to Interspeech 2025
- **Topic Keywords**: ranking, rag, rank, search
- **Reason**: This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus is on speech-based suicide risk detection using large language models, which is not related to query understanding, ranking models, or user behavior modeling.

#### Abstract
> Early identification of suicide risk is crucial for preventing suicidal
behaviors. As a result, the identification and study of patterns and markers
related to suicide risk have become a key focus of current research. In this
paper, we present the results of our work in the 1st SpeechWellness Challenge
(SW1), which aims to explore speech as a non-invasive and easily accessible
mental health indicator for identifying adolescents at risk of suicide.Our
approach leverages large language model (LLM) as the primary tool for feature
extraction, alongside conventional acoustic and semantic features. The proposed
method achieves an accuracy of 74\% on the test set, ranking first in the SW1
challenge. These findings demonstrate the potential of LLM-based methods for
analyzing speech in the context of suicide risk assessment.

### 21. ONLY: One-Layer Intervention Sufficiently Mitigates Hallucinations in Large Vision-Language Models

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Zifu Wan, Ce Zhang, Silong Yong, Martin Q. Ma, Simon Stepputtis, Louis-Philippe Morency, Deva Ramanan, Katia Sycara, Yaqi Xie
- **URL**: <http://arxiv.org/abs/2507.00898v1>
- **Submitted**: 2025-07-01 16:01:08
- **Comment**: Accepted by ICCV 2025. Project page: https://zifuwan.github.io/ONLY/
- **Topic Keywords**: query, queries
- **Reason**: This paper is not relevant to your research interests as it focuses on Large Vision-Language Models and hallucination mitigation in the context of visual language understanding, which is outside the scope of Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on visual language models and entropy ratio for token amplification is not aligned with your interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Recent Large Vision-Language Models (LVLMs) have introduced a new paradigm
for understanding and reasoning about image input through textual responses.
Although they have achieved remarkable performance across a range of
multi-modal tasks, they face the persistent challenge of hallucination, which
introduces practical weaknesses and raises concerns about their reliable
deployment in real-world applications. Existing work has explored contrastive
decoding approaches to mitigate this issue, where the output of the original
LVLM is compared and contrasted with that of a perturbed version. However,
these methods require two or more queries that slow down LVLM response
generation, making them less suitable for real-time applications. To overcome
this limitation, we propose ONLY, a training-free decoding approach that
requires only a single query and a one-layer intervention during decoding,
enabling efficient real-time deployment. Specifically, we enhance textual
outputs by selectively amplifying crucial textual information using a
text-to-visual entropy ratio for each token. Extensive experimental results
demonstrate that our proposed ONLY consistently outperforms state-of-the-art
methods across various benchmarks while requiring minimal implementation effort
and computational cost. Code is available at https://github.com/zifuwan/ONLY.

### 22. Linearly Decoding Refused Knowledge in Aligned Language Models

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Aryan Shrivastava, Ari Holtzman
- **URL**: <http://arxiv.org/abs/2507.00239v1>
- **Submitted**: 2025-06-30 20:13:49
- **Topic Keywords**: pairwise, rag
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on language models and their internal representations, which is a topic in Natural Language Processing, but not specifically in the areas of interest.

#### Abstract
> Most commonly used language models (LMs) are instruction-tuned and aligned
using a combination of fine-tuning and reinforcement learning, causing them to
refuse users requests deemed harmful by the model. However, jailbreak prompts
can often bypass these refusal mechanisms and elicit harmful responses. In this
work, we study the extent to which information accessed via jailbreak prompts
is decodable using linear probes trained on LM hidden states. We show that a
great deal of initially refused information is linearly decodable. For example,
across models, the response of a jailbroken LM for the average IQ of a country
can be predicted by a linear probe with Pearson correlations exceeding $0.8$.
Surprisingly, we find that probes trained on base models (which do not refuse)
sometimes transfer to their instruction-tuned versions and are capable of
revealing information that jailbreaks decode generatively, suggesting that the
internal representations of many refused properties persist from base LMs
through instruction-tuning. Importantly, we show that this information is not
merely "leftover" in instruction-tuned models, but is actively used by them: we
find that probe-predicted values correlate with LM generated pairwise
comparisons, indicating that the information decoded by our probes align with
suppressed generative behavior that may be expressed more subtly in other
downstream tasks. Overall, our results suggest that instruction-tuning does not
wholly eliminate or even relocate harmful information in representation
space-they merely suppress its direct expression, leaving it both linearly
accessible and indirectly influential in downstream behavior.

### 23. Verifiable Natural Language to Linear Temporal Logic Translation: A Benchmark Dataset and Evaluation Suite

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: William H English, Chase Walker, Dominic Simon, Sumit Kumar Jha, Rickard Ewetz
- **URL**: <http://arxiv.org/abs/2507.00877v1>
- **Submitted**: 2025-07-01 15:41:57
- **Topic Keywords**: rag, search, www
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling, which are the user's primary research interests. The paper focuses on natural language to temporal logic translation, which is a topic in Natural Language Processing, but it does not seem to be closely related to the user's background in e-commerce or real-time relevance optimization.

#### Abstract
> Empirical evaluation of state-of-the-art natural-language (NL) to
temporal-logic (TL) translation systems reveals near-perfect performance on
existing benchmarks. However, current studies measure only the accuracy of the
translation of NL logic into formal TL, ignoring a system's capacity to ground
atomic propositions into new scenarios or environments. This is a critical
feature, necessary for the verification of resulting formulas in a concrete
state space. Consequently, most NL-to-TL translation frameworks propose their
own bespoke dataset in which the correct grounding is known a-priori, inflating
performance metrics and neglecting the need for extensible, domain-general
systems. In this paper, we introduce the Verifiable Linear Temporal Logic
Benchmark ( VLTL-Bench), a unifying benchmark that measures verification and
verifiability of automated NL-to-LTL translation. The dataset consists of three
unique state spaces and thousands of diverse natural language specifications
and corresponding formal specifications in temporal logic. Moreover, the
benchmark contains sample traces to validate the temporal logic expressions.
While the benchmark directly supports end-to-end evaluation, we observe that
many frameworks decompose the process into i) lifting, ii) grounding, iii)
translation, and iv) verification. The benchmark provides ground truths after
each of these steps to enable researches to improve and evaluate different
substeps of the overall problem. To encourage methodologically sound advances
in verifiable NL-to-LTL translation approaches, we release VLTL-Bench here:
https://www.kaggle.com/datasets/dubascudes/vltl bench.

### 24. Generative AI and the future of scientometrics: current topics and future questions

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Benedetto Lepori, Jens Peter Andersen, Karsten Donnay
- **URL**: <http://arxiv.org/abs/2507.00783v1>
- **Submitted**: 2025-07-01 14:22:16
- **Topic Keywords**: rag, recommend, search
- **Reason**: This paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on Generative AI and its applications in scientometrics, which is a different field and does not align with the user's primary focus.

#### Abstract
> The aim of this paper is to review the use of GenAI in scientometrics, and to
begin a debate on the broader implications for the field. First, we provide an
introduction on GenAI's generative and probabilistic nature as rooted in
distributional linguistics. And we relate this to the debate on the extent to
which GenAI might be able to mimic human 'reasoning'. Second, we leverage this
distinction for a critical engagement with recent experiments using GenAI in
scientometrics, including topic labelling, the analysis of citation contexts,
predictive applications, scholars' profiling, and research assessment. GenAI
shows promise in tasks where language generation dominates, such as labelling,
but faces limitations in tasks that require stable semantics, pragmatic
reasoning, or structured domain knowledge. However, these results might become
quickly outdated. Our recommendation is, therefore, to always strive to
systematically compare the performance of different GenAI models for specific
tasks. Third, we inquire whether, by generating large amounts of scientific
language, GenAI might have a fundamental impact on our field by affecting
textual characteristics used to measure science, such as authors, words, and
references. We argue that careful empirical work and theoretical reflection
will be essential to remain capable of interpreting the evolving patterns of
knowledge production.

### 25. LitBench: A Benchmark and Dataset for Reliable Evaluation of Creative Writing

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Daniel Fein, Sebastian Russo, Violet Xiang, Kabir Jolly, Rafael Rafailov, Nick Haber
- **URL**: <http://arxiv.org/abs/2507.00769v1>
- **Submitted**: 2025-07-01 14:10:36
- **Topic Keywords**: ranking, rank
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on creative writing evaluation, large language models, and reward models, which are outside your primary areas of interest.

#### Abstract
> Evaluating creative writing generated by large language models (LLMs) remains
challenging because open-ended narratives lack ground truths. Without
performant automated evaluation methods, off-the-shelf (OTS) language models
are employed as zero-shot judges, yet their reliability is unclear in this
context. In pursuit of robust evaluation for creative writing, we introduce
LitBench, the first standardized benchmark and paired dataset for creative
writing verification, comprising a held-out test set of 2,480 debiased,
human-labeled story comparisons drawn from Reddit and a 43,827-pair training
corpus of human preference labels. Using LitBench, we (i) benchmark zero-shot
LLM judges, (ii) train Bradley Terry and generative reward models, and (iii)
conduct an online human study to validate reward model rankings on newly
LLM-generated stories. Our benchmark identifies Claude-3.7-Sonnet as the
strongest off-the-shelf judge, reaching 73% agreement with human preferences;
among trained reward models, Bradley-Terry and Generative reward models both
attain an accuracy of 78%, outperforming all off-the-shelf judges. An online
human study further confirms that our trained reward models consistently align
with human preferences in novel LLM-generated stories. We release LitBench and
reward models at
https://huggingface.co/collections/SAA-Lab/litbench-68267b5da3aafe58f9e43461,
providing a vetted resource for reliable, automated evaluation and optimization
of creative writing systems.

### 26. Pitfalls of Evaluating Language Models with Open Benchmarks

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Md. Najib Hasan, Mohammad Fakhruddin Babar, Souvika Sarkar, Monowar Hasan, Santu Karmaker
- **URL**: <http://arxiv.org/abs/2507.00460v1>
- **Submitted**: 2025-07-01 06:17:48
- **Topic Keywords**: ranking, rank
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it touches on the topic of benchmarks, its focus is on language models and their evaluation, which is outside the scope of the user's primary research interests.

#### Abstract
> Open Large Language Model (LLM) benchmarks, such as HELM and BIG-bench, offer
standardized, transparent protocols that facilitate the fair comparison,
reproducibility, and iterative advancement of Language Models (LMs). However,
their openness also introduces critical and underexplored pitfalls. This study
exposes these weaknesses by systematically constructing ``cheating'' models --
smaller variants of BART, T5, and GPT-2 fine-tuned directly on public test sets
-- which achieve top rankings on a prominent open, holistic benchmark (HELM)
despite poor generalization and limited practical utility. Our findings
underscore three key insights: \ca high leaderboard performance on open
benchmarks may not always reflect real-world effectiveness; \cb private or
dynamic benchmarks must complement open evaluations to safeguard integrity; and
\cc a fundamental reevaluation of current benchmarking practices is essential
to ensure robust and trustworthy LM assessments.

### 27. Towards Style Alignment in Cross-Cultural Translation

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Shreya Havaldar, Adam Stein, Eric Wong, Lyle Ungar
- **URL**: <http://arxiv.org/abs/2507.00216v1>
- **Submitted**: 2025-06-30 19:37:51
- **Comment**: Accepted to ACL 2025
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on cross-cultural translation and style alignment, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on language models and translation, the context and goals of the paper are distinct from the user's areas of focus.

#### Abstract
> Successful communication depends on the speaker's intended style (i.e., what
the speaker is trying to convey) aligning with the listener's interpreted style
(i.e., what the listener perceives). However, cultural differences often lead
to misalignment between the two; for example, politeness is often lost in
translation. We characterize the ways that LLMs fail to translate style -
biasing translations towards neutrality and performing worse in non-Western
languages. We mitigate these failures with RASTA (Retrieval-Augmented STylistic
Alignment), a method that leverages learned stylistic concepts to encourage LLM
translation to appropriately convey cultural communication norms and align
style.

### 28. La Leaderboard: A Large Language Model Leaderboard for Spanish Varieties and Languages of Spain and Latin America

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Mar√≠a Grandury, Javier Aula-Blasco, J√∫lia Falc√£o, Cl√©mentine Fourrier, Miguel Gonz√°lez, Gonzalo Mart√≠nez, Gonzalo Santamar√≠a, Rodrigo Agerri, Nuria Aldama, Luis Chiruzzo, Javier Conde, Helena G√≥mez, Marta Guerrero, Guido Ivetta, Natalia L√≥pez, Flor Miriam Plaza-del-Arco, Mar√≠a Teresa Mart√≠n-Valdivia, Helena Montoro, Carmen Mu√±oz, Pedro Reviriego, Leire Rosado, Alejandro Vaca, Mar√≠a Estrella Vallecillo-Rodr√≠guez, Jorge Vallego, Irune Zubiaga
- **URL**: <http://arxiv.org/abs/2507.00999v1>
- **Submitted**: 2025-07-01 17:50:48
- **Comment**: Accepted at ACL 2025 Main
- **Topic Keywords**: rag, search
- **Reason**: This paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling. The focus on Large Language Models and their evaluation in Spanish-speaking languages is outside the user's primary areas of interest.

#### Abstract
> Leaderboards showcase the current capabilities and limitations of Large
Language Models (LLMs). To motivate the development of LLMs that represent the
linguistic and cultural diversity of the Spanish-speaking community, we present
La Leaderboard, the first open-source leaderboard to evaluate generative LLMs
in languages and language varieties of Spain and Latin America. La Leaderboard
is a community-driven project that aims to establish an evaluation standard for
everyone interested in developing LLMs for the Spanish-speaking community. This
initial version combines 66 datasets in Basque, Catalan, Galician, and
different Spanish varieties, showcasing the evaluation results of 50 models. To
encourage community-driven development of leaderboards in other languages, we
explain our methodology, including guidance on selecting the most suitable
evaluation setup for each downstream task. In particular, we provide a
rationale for using fewer few-shot examples than typically found in the
literature, aiming to reduce environmental impact and facilitate access to
reproducible results for a broader research community.

### 29. EARN: Efficient Inference Acceleration for LLM-based Generative Recommendation by Register Tokens

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Chaoqun Yang, Xinyu Lin, Wenjie Wang, Yongqi Li, Teng Sun, Xianjing Han, Tat-Seng Chua
- **URL**: <http://arxiv.org/abs/2507.00715v1>
- **Submitted**: 2025-07-01 12:42:06
- **Comment**: Accepted by KDD 2025
- **Topic Keywords**: rag, recommend
- **Reason**: The paper focuses on efficient inference acceleration for large language model-based generative recommendation, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions attention patterns, it does not explore ranking models or user behavior modeling, making it only loosely relevant to the user's research interests.

#### Abstract
> Large Language Model-based generative recommendation (LLMRec) has achieved
notable success, but it suffers from high inference latency due to massive
computational overhead and memory pressure of KV Cache. Existing KV Cache
reduction methods face critical limitations: cache compression offers marginal
acceleration given recommendation tasks' short decoding steps, while prompt
compression risks discarding vital interaction history. Through systematic
analysis of attention patterns in LLMRec, we uncover two pivotal insights: 1)
layer-wise attention sparsity inversion where early layers retain dense
informative patterns while later layers exhibit high redundancy, and 2) dual
attention sinks phenomenon where attention scores concentrate on both head and
tail tokens of input sequences. Motivated by these insights, we propose EARN,
an efficient inference framework that leverages the early layers to compress
information into register tokens placed at the input sequence boundaries, then
focuses solely on these tokens in the subsequent layers. Extensive experiments
on three datasets, two LLMRec methods and two LLM architectures demonstrate
EARN's superiority, achieving up to 3.79x speedup and 80.8% KV Cache reduction
with better accuracy than the general finetuning approach. Our work bridges the
efficiency-effectiveness gap in LLMRec, offering practical deployment
advantages for industrial scenarios.

### 30. NIRANTAR: Continual Learning with New Languages and Domains on Real-world Speech Data

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Tahir Javed, Kaushal Bhogale, Mitesh M. Khapra
- **URL**: <http://arxiv.org/abs/2507.00534v1>
- **Submitted**: 2025-07-01 07:53:39
- **Comment**: Accepted in Interspecch 2025
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on continual learning in speech recognition, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions multilingual and multi-domain aspects, the context is different from the user's primary research interests in IR and NLP.

#### Abstract
> We introduce Nirantar, a comprehensive framework for evaluating continual
learning (CL) in multilingual and multi-domain ASR. Designed to reflect
real-world CL challenges, Nirantar leverages data collected incrementally
across 22 languages and 208 districts in India through natural episodes. This
enables evaluation across Language-Incremental (LIL), Domain-Incremental (DIL),
and the novel Language-Incremental Domain-Incremental Learning (LIDIL)
scenarios. Unlike prior work that relies on simulated episodes, Nirantar
presents dynamic, non-uniform language and domain shifts, making it an ideal
testbed for CL research. With 3250 hours of human-transcribed speech, including
1720 hours newly introduced in this work, our framework enables systematic
benchmarking of CL methods. We evaluate existing approaches and demonstrate
that no single method performs consistently well, underscoring the need for
more robust CL strategies.

### 31. Discourse Heuristics For Paradoxically Moral Self-Correction

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Guangliang Liu, Zimo Qi, Xitong Zhang, Kristen Marie Johnson
- **URL**: <http://arxiv.org/abs/2507.00985v1>
- **Submitted**: 2025-07-01 17:36:41
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topic of moral self-correction in Large Language Models is not directly related to your focus on query understanding, ranking models, and user behavior modeling. The paper's emphasis on discourse constructions and heuristic shortcuts is also outside your area of expertise.

#### Abstract
> Moral self-correction has emerged as a promising approach for aligning the
output of Large Language Models (LLMs) with human moral values. However, moral
self-correction techniques are subject to two primary paradoxes. First, despite
empirical and theoretical evidence to support the effectiveness of
self-correction, this LLM capability only operates at a superficial level.
Second, while LLMs possess the capability of self-diagnosing immoral aspects of
their output, they struggle to identify the cause of this moral inconsistency
during their self-correction process. To better understand and address these
paradoxes, we analyze the discourse constructions in fine-tuning corpora
designed to enhance moral self-correction, uncovering the existence of the
heuristics underlying effective constructions. We demonstrate that moral
self-correction relies on discourse constructions that reflect heuristic
shortcuts, and that the presence of these heuristic shortcuts during
self-correction leads to inconsistency when attempting to enhance both
self-correction and self-diagnosis capabilities jointly. Based on our findings,
we propose a solution to improve moral self-correction by leveraging the
heuristics of curated datasets. We also highlight the generalization challenges
of this capability, particularly in terms of learning from situated context and
model scales.

### 32. Enhancing LLM Agent Safety via Causal Influence Prompting

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Dongyoon Hahm, Woogyeol Jin, June Suk Choi, Sungsoo Ahn, Kimin Lee
- **URL**: <http://arxiv.org/abs/2507.00979v1>
- **Submitted**: 2025-07-01 17:31:51
- **Comment**: Accepted at ACL 2025 Findings, Source code:
  https://github.com/HahmDY/causal_influence_prompting.git
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling, which are the user's primary research interests. The paper focuses on enhancing the safety of autonomous agents powered by large language models, which is a topic in Natural Language Processing, but not directly relevant to the user's interests.

#### Abstract
> As autonomous agents powered by large language models (LLMs) continue to
demonstrate potential across various assistive tasks, ensuring their safe and
reliable behavior is crucial for preventing unintended consequences. In this
work, we introduce CIP, a novel technique that leverages causal influence
diagrams (CIDs) to identify and mitigate risks arising from agent
decision-making. CIDs provide a structured representation of cause-and-effect
relationships, enabling agents to anticipate harmful outcomes and make safer
decisions. Our approach consists of three key steps: (1) initializing a CID
based on task specifications to outline the decision-making process, (2)
guiding agent interactions with the environment using the CID, and (3)
iteratively refining the CID based on observed behaviors and outcomes.
Experimental results demonstrate that our method effectively enhances safety in
both code execution and mobile device control tasks.

### 33. MemeCMD: An Automatically Generated Chinese Multi-turn Dialogue Dataset with Contextually Retrieved Memes

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yuheng Wang, Xianhe Tang, Pufeng Huang
- **URL**: <http://arxiv.org/abs/2507.00891v1>
- **Submitted**: 2025-07-01 15:57:14
- **Topic Keywords**: retrieval
- **Reason**: This paper focuses on creating a dataset for multimodal dialogue generation with memes, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on conversational AI, the primary focus is on multimodal interactions and meme usage, which is not a core area of interest for the user.

#### Abstract
> Memes are widely used in online social interactions, providing vivid,
intuitive, and often humorous means to express intentions and emotions.
Existing dialogue datasets are predominantly limited to either manually
annotated or pure-text conversations, lacking the expressiveness and contextual
nuance that multimodal interactions provide.To address these challenges, we
introduce MemeCMD, an automatically generated Chinese Multi-turn Dialogue
dataset with contextually retrieved memes. Our dataset combines a large-scale,
MLLM-annotated meme library with dialogues auto-generated by dual agents across
diverse scenarios. We introduce a retrieval framework and adaptive threshold to
ensure contextually relevant, naturally spaced meme usage. Experiments
demonstrate the effectiveness of our approach in generating contextually
appropriate and diverse meme-incorporated dialogues, offering a scalable and
privacy-preserving resource for advancing multimodal conversational AI.

### 34. SAFER: Probing Safety in Reward Models with Sparse Autoencoder

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sihang Li, Wei Shi, Ziyuan Xie, Tao Liang, Guojun Ma, Xiang Wang
- **URL**: <http://arxiv.org/abs/2507.00665v1>
- **Submitted**: 2025-07-01 11:04:03
- **Topic Keywords**: rag
- **Reason**: The paper focuses on reward models in reinforcement learning from human feedback, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions large language models, the primary concern is safety and auditing, rather than deep semantic understanding or real-time relevance optimization.

#### Abstract
> Reinforcement learning from human feedback (RLHF) is a key paradigm for
aligning large language models (LLMs) with human values, yet the reward models
at its core remain largely opaque. In this work, we present sparse Autoencoder
For Enhanced Reward model (\textbf{SAFER}), a novel framework for interpreting
and improving reward models through mechanistic analysis. Leveraging Sparse
Autoencoders (SAEs), we uncover human-interpretable features in reward model
activations, enabling insight into safety-relevant decision-making. We apply
SAFER to safety-oriented preference datasets and quantify the salience of
individual features by activation differences between chosen and rejected
responses. Using these feature-level signals, we design targeted data poisoning
and denoising strategies. Experiments show that SAFER can precisely degrade or
enhance safety alignment with minimal data modification, without sacrificing
general chat performance. Our approach contributes to interpreting, auditing
and refining reward models in high-stakes LLM alignment tasks. Our codes are
available at https://github.com/xzy-101/SAFER-code. \textit{This paper
discusses topics related to large language model safety and may include
discussions or examples that highlight potential risks or unsafe outcomes.}

### 35. Beat and Downbeat Tracking in Performance MIDI Using an End-to-End Transformer Architecture

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sebastian Murgul, Michael Heizmann
- **URL**: <http://arxiv.org/abs/2507.00466v1>
- **Submitted**: 2025-07-01 06:27:42
- **Comment**: Accepted to the 22nd Sound and Music Computing Conference (SMC), 2025
- **Topic Keywords**: rag
- **Reason**: The paper is not relevant to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on music-related tasks, such as beat tracking in performance MIDI, is outside the user's primary areas of interest.

#### Abstract
> Beat tracking in musical performance MIDI is a challenging and important task
for notation-level music transcription and rhythmical analysis, yet existing
methods primarily focus on audio-based approaches. This paper proposes an
end-to-end transformer-based model for beat and downbeat tracking in
performance MIDI, leveraging an encoder-decoder architecture for
sequence-to-sequence translation of MIDI input to beat annotations. Our
approach introduces novel data preprocessing techniques, including dynamic
augmentation and optimized tokenization strategies, to improve accuracy and
generalizability across different datasets. We conduct extensive experiments
using the A-MAPS, ASAP, GuitarSet, and Leduc datasets, comparing our model
against state-of-the-art hidden Markov models (HMMs) and deep learning-based
beat tracking methods. The results demonstrate that our model outperforms
existing symbolic music beat tracking approaches, achieving competitive
F1-scores across various musical styles and instruments. Our findings highlight
the potential of transformer architectures for symbolic beat tracking and
suggest future integration with automatic music transcription systems for
enhanced music analysis and score generation.

### 36. Modeling Data Diversity for Joint Instance and Verbalizer Selection in Cold-Start Scenarios

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Mohna Chakraborty, Adithya Kulkarni, Qi Li
- **URL**: <http://arxiv.org/abs/2507.00330v1>
- **Submitted**: 2025-07-01 00:01:50
- **Topic Keywords**: rag
- **Reason**: The paper focuses on a specific problem in natural language processing (NLP), namely joint instance and verbalizer selection in cold-start scenarios, which is not directly related to information retrieval, search technologies, or query understanding. While it leverages pre-trained language models, the approach is not applicable to ranking models or user behavior modeling, and the paper does not explore deep semantic understanding or real-time relevance optimization.

#### Abstract
> Prompt-based methods leverage the knowledge of pre-trained language models
(PLMs) trained with a masked language modeling (MLM) objective; however, these
methods are sensitive to template, verbalizer, and few-shot instance selection,
particularly in cold-start settings with no labeled data. Existing studies
overlook the dependency between instances and verbalizers, where instance-label
probabilities depend on verbalizer token proximity in the embedding space. To
address this, we propose COLDSELECT, a joint verbalizer and instance selection
approach that models data diversity. COLDSELECT maps PLM vocabulary and
$h_{[MASK]}$ embeddings into a shared space, applying dimensionality reduction
and clustering to ensure efficient and diverse selection. By optimizing for
minimal uncertainty and maximal diversity, COLDSELECT captures data
relationships effectively. Experiments on eight benchmarks demonstrate
COLDSELECT's superiority in reducing uncertainty and enhancing generalization,
outperforming baselines in verbalizer and few-shot instance selection for
cold-start scenarios.

### 37. Developing Lightweight DNN Models With Limited Data For Real-Time Sign Language Recognition

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Nikita Nikitin, Eugene Fomin
- **URL**: <http://arxiv.org/abs/2507.00248v1>
- **Submitted**: 2025-06-30 20:34:54
- **Comment**: 7 pages, 2 figures, 2 tables, for associated mpeg file, see
  https://slait.app/static/Screen_Recording.mp4
- **Topic Keywords**: rag
- **Reason**: The paper focuses on developing a lightweight DNN model for real-time sign language recognition, which is not directly related to information retrieval, search technologies, or query understanding. Although it involves deep learning and data processing, the application domain is distinct from the user's primary research interests.

#### Abstract
> We present a novel framework for real-time sign language recognition using
lightweight DNNs trained on limited data. Our system addresses key challenges
in sign language recognition, including data scarcity, high computational
costs, and discrepancies in frame rates between training and inference
environments. By encoding sign language specific parameters, such as handshape,
palm orientation, movement, and location into vectorized inputs, and leveraging
MediaPipe for landmark extraction, we achieve highly separable input data
representations. Our DNN architecture, optimized for sub 10MB deployment,
enables accurate classification of 343 signs with less than 10ms latency on
edge devices. The data annotation platform 'slait data' facilitates structured
labeling and vector extraction. Our model achieved 92% accuracy in isolated
sign recognition and has been integrated into the 'slait ai' web application,
where it demonstrates stable inference.

### 38. Mathematics Isn't Culture-Free: Probing Cultural Gaps via Entity and Scenario Perturbations

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Aditya Tomar, Nihar Ranjan Sahoo, Ashish Mittal, Rudra Murthy, Pushpak Bhattacharyya
- **URL**: <http://arxiv.org/abs/2507.00883v1>
- **Submitted**: 2025-07-01 15:51:46
- **Topic Keywords**: korea
- **Reason**: The paper is not directly related to Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling. The focus on mathematics and cultural adaptation of datasets is outside the scope of the user's research interests.

#### Abstract
> Although mathematics is often considered culturally neutral, the way
mathematical problems are presented can carry implicit cultural context.
Existing benchmarks like GSM8K are predominantly rooted in Western norms,
including names, currencies, and everyday scenarios. In this work, we create
culturally adapted variants of the GSM8K test set for five regions Africa,
India, China, Korea, and Japan using prompt-based transformations followed by
manual verification. We evaluate six large language models (LLMs), ranging from
8B to 72B parameters, across five prompting strategies to assess their
robustness to cultural variation in math problem presentation. Our findings
reveal a consistent performance gap: models perform best on the original
US-centric dataset and comparatively worse on culturally adapted versions.
However, models with reasoning capabilities are more resilient to these shifts,
suggesting that deeper reasoning helps bridge cultural presentation gaps in
mathematical tasks

### 39. Contrasting Cognitive Styles in Vision-Language Models: Holistic Attention in Japanese Versus Analytical Focus in English

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Ahmed Sabir, Azinoviƒç Gasper, Mengsay Loem, Rajesh Sharma
- **URL**: <http://arxiv.org/abs/2507.00700v1>
- **Submitted**: 2025-07-01 11:56:45
- **Topic Keywords**: search
- **Reason**: The paper explores the cultural differences in visual processing and attention patterns in Vision-Language Models, which is not directly related to Information Retrieval, Search technologies, or query understanding. The focus on language and cultural cognition is more relevant to NLP and cognitive science, but the abstract does not mention any relevance to ranking models, user behavior modeling, or real-time relevance optimization.

#### Abstract
> Cross-cultural research in perception and cognition has shown that
individuals from different cultural backgrounds process visual information in
distinct ways. East Asians, for example, tend to adopt a holistic perspective,
attending to contextual relationships, whereas Westerners often employ an
analytical approach, focusing on individual objects and their attributes. In
this study, we investigate whether Vision-Language Models (VLMs) trained
predominantly on different languages, specifically Japanese and English,
exhibit similar culturally grounded attentional patterns. Using comparative
analysis of image descriptions, we examine whether these models reflect
differences in holistic versus analytic tendencies. Our findings suggest that
VLMs not only internalize the structural properties of language but also
reproduce cultural behaviors embedded in the training data, indicating that
cultural cognition may implicitly shape model outputs.

### 40. Methodological Rigour in Algorithm Application: An Illustration of Topic Modelling Algorithm

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Malmi Amadoru
- **URL**: <http://arxiv.org/abs/2507.00547v1>
- **Submitted**: 2025-07-01 08:11:07
- **Topic Keywords**: search
- **Reason**: The paper focuses on methodological rigour in algorithm application, specifically in topic modelling, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on computational algorithms, it does not address query understanding, ranking models, or user behavior modeling, which are core areas of interest.

#### Abstract
> The rise of advanced computational algorithms has opened new avenues for
computationally intensive research approaches to theory development. However,
the opacity of these algorithms and lack of transparency and rigour in their
application pose methodological challenges, potentially undermining trust in
research. The discourse on methodological rigour in this new genre of research
is still emerging. Against this backdrop, I attempt to offer guidance on
methodological rigour, particularly in the context of topic modelling
algorithms. By illustrating the application of the structural topic modelling
algorithm and presenting a set of guidelines, I discuss how to ensure rigour in
topic modelling studies. Although the guidelines are for the application of
topic modelling algorithms, they can be applied to other algorithms with
context-specific adjustments. The guidelines are helpful, especially for novice
researchers applying topic modelling, and editors and reviewers handling topic
modelling manuscripts. I contribute to the literature on topic modelling and
join the emerging dialogue on methodological rigour in computationally
intensive theory construction research.

### 41. Exploring Large Action Sets with Hyperspherical Embeddings using von Mises-Fisher Sampling

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Walid Bendada, Guillaume Salha-Galvan, Romain Hennequin, Th√©o Bontempelli, Thomas Bouab√ßa, Tristan Cazenave
- **URL**: <http://arxiv.org/abs/2507.00518v1>
- **Submitted**: 2025-07-01 07:32:54
- **Comment**: 42nd International Conference on Machine Learning (ICML 2025)
- **Topic Keywords**: recommend
- **Reason**: The paper explores reinforcement learning and hyperspherical embeddings, which is not directly related to the user's primary focus on Information Retrieval, Search technologies, and query understanding. While the paper mentions recommender systems, it is not specifically focused on information retrieval or deep semantic understanding.

#### Abstract
> This paper introduces von Mises-Fisher exploration (vMF-exp), a scalable
method for exploring large action sets in reinforcement learning problems where
hyperspherical embedding vectors represent these actions. vMF-exp involves
initially sampling a state embedding representation using a von Mises-Fisher
distribution, then exploring this representation's nearest neighbors, which
scales to virtually unlimited numbers of candidate actions. We show that, under
theoretical assumptions, vMF-exp asymptotically maintains the same probability
of exploring each action as Boltzmann Exploration (B-exp), a popular
alternative that, nonetheless, suffers from scalability issues as it requires
computing softmax values for each action. Consequently, vMF-exp serves as a
scalable alternative to B-exp for exploring large action sets with
hyperspherical embeddings. Experiments on simulated data, real-world public
data, and the successful large-scale deployment of vMF-exp on the recommender
system of a global music streaming service empirically validate the key
properties of the proposed method.

### 42. Gregorian melody, modality, and memory: Segmenting chant with Bayesian nonparametrics

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Vojtƒõch Lanz, Jan Hajiƒç jr
- **URL**: <http://arxiv.org/abs/2507.00380v1>
- **Submitted**: 2025-07-01 02:28:09
- **Topic Keywords**: search
- **Reason**: The paper is not related to Information Retrieval, Search technologies, or Natural Language Processing, and does not involve query understanding, ranking models, or user behavior modeling. The topic is musicology and focuses on segmenting Gregorian chant melodies using Bayesian nonparametrics, which is unrelated to the user's research interests.

#### Abstract
> The idea that Gregorian melodies are constructed from some vocabulary of
segments has long been a part of chant scholarship. This so-called
"centonisation" theory has received much musicological criticism, but frequent
re-use of certain melodic segments has been observed in chant melodies, and the
intractable number of possible segmentations allowed the option that some
undiscovered segmentation exists that will yet prove the value of
centonisation, and recent empirical results have shown that segmentations can
outperform music-theoretical features in mode classification. Inspired by the
fact that Gregorian chant was memorised, we search for an optimal unsupervised
segmentation of chant melody using nested hierarchical Pitman-Yor language
models. The segmentation we find achieves state-of-the-art performance in mode
classification. Modeling a monk memorising the melodies from one liturgical
manuscript, we then find empirical evidence for the link between mode
classification and memory efficiency, and observe more formulaic areas at the
beginnings and ends of melodies corresponding to the practical role of modality
in performance. However, the resulting segmentations themselves indicate that
even such a memory-optimal segmentation is not what is understood as
centonisation.

### 43. Open-ended Scientific Discovery via Bayesian Surprise

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Dhruv Agarwal, Bodhisattwa Prasad Majumder, Reece Adamson, Megha Chakravorty, Satvika Reddy Gavireddy, Aditya Parashar, Harshit Surana, Bhavana Dalvi Mishra, Andrew McCallum, Ashish Sabharwal, Peter Clark
- **URL**: <http://arxiv.org/abs/2507.00310v1>
- **Submitted**: 2025-06-30 22:53:59
- **Topic Keywords**: search
- **Reason**: This paper is not directly related to information retrieval, search technologies, or query understanding, which are the user's primary research interests. The paper focuses on autonomous scientific discovery, using Bayesian surprise as a reward function, which is outside the user's area of expertise.

#### Abstract
> The promise of autonomous scientific discovery (ASD) hinges not only on
answering questions, but also on knowing which questions to ask. Most recent
works in ASD explore the use of large language models (LLMs) in goal-driven
settings, relying on human-specified research questions to guide hypothesis
generation. However, scientific discovery may be accelerated further by
allowing the AI system to drive exploration by its own criteria. The few
existing approaches in open-ended ASD select hypotheses based on diversity
heuristics or subjective proxies for human interestingness, but the former
struggles to meaningfully navigate the typically vast hypothesis space, and the
latter suffers from imprecise definitions. This paper presents AutoDS -- a
method for open-ended ASD that instead drives scientific exploration using
Bayesian surprise. Here, we quantify the epistemic shift from the LLM's prior
beliefs about a hypothesis to its posterior beliefs after gathering
experimental results. To efficiently explore the space of nested hypotheses,
our method employs a Monte Carlo tree search (MCTS) strategy with progressive
widening using surprisal as the reward function. We evaluate AutoDS in the
setting of data-driven discovery across 21 real-world datasets spanning domains
such as biology, economics, finance, and behavioral science. Our results
demonstrate that under a fixed budget, AutoDS substantially outperforms
competitors by producing 5--29\% more discoveries deemed surprising by the LLM.
Our human evaluation further finds that two-thirds of AutoDS discoveries are
surprising to the domain experts, suggesting this is an important step forward
towards building open-ended ASD systems.

### 44. Natural language processing for African languages

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: David Ifeoluwa Adelani
- **URL**: <http://arxiv.org/abs/2507.00297v1>
- **Submitted**: 2025-06-30 22:26:36
- **Comment**: PhD thesis
- **Topic Keywords**: search
- **Reason**: The paper focuses on Natural Language Processing (NLP) for African languages, which is not directly related to Information Retrieval (IR) and Search technologies, the user's primary research interests. Although the paper mentions word embeddings and language models, which are relevant to NLP, the context and application are not aligned with the user's research themes.

#### Abstract
> Recent advances in word embeddings and language models use large-scale,
unlabelled data and self-supervised learning to boost NLP performance.
Multilingual models, often trained on web-sourced data like Wikipedia, face
challenges: few low-resource languages are included, their data is often noisy,
and lack of labeled datasets makes it hard to evaluate performance outside
high-resource languages like English. In this dissertation, we focus on
languages spoken in Sub-Saharan Africa where all the indigenous languages in
this region can be regarded as low-resourced in terms of the availability of
labelled data for NLP tasks and unlabelled data found on the web. We analyse
the noise in the publicly available corpora, and curate a high-quality corpus,
demonstrating that the quality of semantic representations learned in word
embeddings does not only depend on the amount of data but on the quality of
pre-training data. We demonstrate empirically the limitations of word
embeddings, and the opportunities the multilingual pre-trained language model
(PLM) offers especially for languages unseen during pre-training and
low-resource scenarios. We further study how to adapt and specialize
multilingual PLMs to unseen African languages using a small amount of
monolingual texts. To address the under-representation of the African languages
in NLP research, we developed large scale human-annotated labelled datasets for
21 African languages in two impactful NLP tasks: named entity recognition and
machine translation. We conduct an extensive empirical evaluation using
state-of-the-art methods across supervised, weakly-supervised, and transfer
learning settings.

### 45. EfficientXLang: Towards Improving Token Efficiency Through Cross-Lingual Reasoning

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Sanchit Ahuja, Praneetha Vaddamanu, Barun Patra
- **URL**: <http://arxiv.org/abs/2507.00246v1>
- **Submitted**: 2025-06-30 20:29:52
- **Comment**: 15 pages, 5 figures, 9 tables
- **Topic Keywords**: search
- **Reason**: The paper focuses on Language Reasoning Models, which is a topic in NLP, but it does not seem to be directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling, which are the core research themes of the user. The paper's emphasis on multilingual language models and token efficiency is not a central match for the user's interests.

#### Abstract
> Despite recent advances in Language Reasoning Models (LRMs), most research
focuses solely on English, even though many models are pretrained on
multilingual data. In this work, we investigate: Is English the most
token-efficient language for reasoning? We evaluate three open-source RLMs:
DeepSeek R1, Qwen 2.5 and Qwen 3, across four math datasets and seven
typologically diverse languages. We find that reasoning in non-English
languages not only reduces token usage, but also preserves accuracy. These
gains persist even after translating the reasoning traces into English,
suggesting genuine shifts in reasoning behavior rather than surface-level
linguistic effects. The extent of improvement, however, depends on the models
multilingual strength. Our findings motivate a broader view of reasoning in
language models, highlighting the potential of multilingual reasoning and the
importance of strong multilingual foundations. The code for our work can be
found: https://github.com/microsoft/EfficientXLang.

### 46. The Cognate Data Bottleneck in Language Phylogenetics

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Luise H√§user, Alexandros Stamatakis
- **URL**: <http://arxiv.org/abs/2507.00911v1>
- **Submitted**: 2025-07-01 16:14:20
- **Topic Keywords**: rag
- **Reason**: The paper is unrelated to Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling. It appears to be focused on computational phylogenetics and language, which is outside the scope of the user's research interests.

#### Abstract
> To fully exploit the potential of computational phylogenetic methods for
cognate data one needs to leverage specific (complex) models an machine
learning-based techniques. However, both approaches require datasets that are
substantially larger than the manually collected cognate data currently
available. To the best of our knowledge, there exists no feasible approach to
automatically generate larger cognate datasets. We substantiate this claim by
automatically extracting datasets from BabelNet, a large multilingual
encyclopedic dictionary. We demonstrate that phylogenetic inferences on the
respective character matrices yield trees that are largely inconsistent with
the established gold standard ground truth trees. We also discuss why we
consider it as being unlikely to be able to extract more suitable character
matrices from other multilingual resources. Phylogenetic data analysis
approaches that require larger datasets can therefore not be applied to cognate
data. Thus, it remains an open question how, and if these computational
approaches can be applied in historical linguistics.

---

