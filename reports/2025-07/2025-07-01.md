# Daily Papers Report - 2025-07-01

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. KiseKloset: Comprehensive System For Outfit Retrieval, Recommendation, And Try-On

- **LLM Score**: 6
- **Keyword Score**: 9
- **Authors**: Thanh-Tung Phan-Nguyen, Khoi-Nguyen Nguyen-Ngoc, Tam V. Nguyen, Minh-Triet Tran, Trung-Nghia Le
- **URL**: <http://arxiv.org/abs/2506.23471v1>
- **Submitted**: 2025-06-30 02:25:39
- **Topic Keywords**: rag, retrieval, recommend, shopping, commerce, e-commerce, search
- **Reason**: The paper proposes a comprehensive system for outfit retrieval, recommendation, and try-on, which is relevant to your interest in Information Retrieval and Search technologies, particularly in the e-commerce domain. The system's focus on personalized shopping experiences and real-time relevance optimization aligns with your research themes. However, the paper's primary focus on fashion e-commerce and outfit recommendation is not directly related to your core interests in query understanding, ranking models, and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Personalized Outfit Retrieval and Virtual Try-On for E-Commerce
- **Aim**: Improve customers' online shopping experience in the fashion industry by providing personalized outfit retrieval, recommendation, and try-on
- **Rationale**: Address the challenges of e-commerce, where the lack of in-store shopping experience and the need for intelligent fashion technologies to replicate it are significant concerns
- **Ground**: KiseKloset system, which combines transformer architecture, CLIP model, and approximate searching algorithms for efficient and realistic outfit retrieval and virtual try-on
- **Experiment**: User study and ablation study to evaluate the system's performance, demonstrating its effectiveness in enhancing the online shopping experience and identifying areas for improvement
- **Takeaway**: KiseKloset is the first system to support both outfit retrieval and recommendation and virtual try-on for real-world applications, bridging the gap between the physical and digital realms of fashion retail

#### Abstract
> The global fashion e-commerce industry has become integral to people's daily
lives, leveraging technological advancements to offer personalized shopping
experiences, primarily through recommendation systems that enhance customer
engagement through personalized suggestions. To improve customers' experience
in online shopping, we propose a novel comprehensive KiseKloset system for
outfit retrieval, recommendation, and try-on. We explore two approaches for
outfit retrieval: similar item retrieval and text feedback-guided item
retrieval. Notably, we introduce a novel transformer architecture designed to
recommend complementary items from diverse categories. Furthermore, we enhance
the overall performance of the search pipeline by integrating approximate
algorithms to optimize the search process. Additionally, addressing the crucial
needs of online shoppers, we employ a lightweight yet efficient virtual try-on
framework capable of real-time operation, memory efficiency, and maintaining
realistic outputs compared to its predecessors. This virtual try-on module
empowers users to visualize specific garments on themselves, enhancing the
customers' experience and reducing costs associated with damaged items for
retailers. We deployed our end-to-end system for online users to test and
provide feedback, enabling us to measure their satisfaction levels. The results
of our user study revealed that 84% of participants found our comprehensive
system highly useful, significantly improving their online shopping experience.

---

### 2. Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent

- **LLM Score**: 6
- **Keyword Score**: 4
- **Authors**: Haocheng Yu, Yaxiong Wu, Hao Wang, Wei Guo, Yong Liu, Yawen Li, Yuyang Ye, Junping Du, Enhong Chen
- **URL**: <http://arxiv.org/abs/2506.23485v1>
- **Submitted**: 2025-06-30 03:15:50
- **Topic Keywords**: queries, recommend
- **Reason**: The paper proposes a novel thought-augmented interactive recommender agent system (TAIRA) that addresses complex user intents through distilled thought patterns. While it's related to information retrieval and search technologies, the focus is on recommender systems, which is not the primary area of interest. The paper's emphasis on LLM-powered agents and thought pattern distillation is somewhat relevant to query understanding and ranking models, but it's not a central match.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Thought-Augmented Interactive Recommender Agent System (TAIRA)
- **Aim**: Address complex user intents in large language model-powered interactive recommender agents
- **Rationale**: TAIRA's thought-augmentation method, Thought Pattern Distillation (TPD), strengthens planning capacity by extracting high-level thoughts from agent and human experts' experiences
- **Ground**: TAIRA consists of three main modules: Manager Agent, Executor Agents, and Thought Pattern Distillation, with a Hierarchical Planning approach to refine plans iteratively
- **Experiment**: Comprehensive experiments on multiple datasets, benchmarking TAIRA against existing state-of-the-art approaches, with evaluation metrics including Hit Ratio, Normalized Discounted Cumulative Gain, and Success Rate
- **Takeaway**: TAIRA outperforms existing methods, particularly on more challenging tasks, and generalizes effectively on novel tasks, making it a promising approach for interactive recommender systems

#### Abstract
> Interactive recommendation is a typical information-seeking task that allows
users to interactively express their needs through natural language and obtain
personalized recommendations. Large language model-powered (LLM-powered) agents
have become a new paradigm in interactive recommendations, effectively
capturing users' real-time needs and enhancing personalized experiences.
However, due to limited planning and generalization capabilities, existing
formulations of LLM-powered interactive recommender agents struggle to
effectively address diverse and complex user intents, such as intuitive,
unrefined, or occasionally ambiguous requests. To tackle this challenge, we
propose a novel thought-augmented interactive recommender agent system (TAIRA)
that addresses complex user intents through distilled thought patterns.
Specifically, TAIRA is designed as an LLM-powered multi-agent system featuring
a manager agent that orchestrates recommendation tasks by decomposing user
needs and planning subtasks, with its planning capacity strengthened through
Thought Pattern Distillation (TPD), a thought-augmentation method that extracts
high-level thoughts from the agent's and human experts' experiences. Moreover,
we designed a set of user simulation schemes to generate personalized queries
of different difficulties and evaluate the recommendations based on specific
datasets. Through comprehensive experiments conducted across multiple datasets,
TAIRA exhibits significantly enhanced performance compared to existing methods.
Notably, TAIRA shows a greater advantage on more challenging tasks while
generalizing effectively on novel tasks, further validating its superiority in
managing complex user intents within interactive recommendation systems. The
code is publicly available at:https://github.com/Alcein/TAIRA.

---

### 3. Machine Understanding of Scientific Language

- **LLM Score**: 6
- **Keyword Score**: 1
- **Authors**: Dustin Wright
- **URL**: <http://arxiv.org/abs/2506.23990v1>
- **Submitted**: 2025-06-30 15:55:10
- **Comment**: PhD Thesis, 210 pages
- **Topic Keywords**: search
- **Reason**: The paper explores machine understanding of scientific language, which is related to information retrieval and natural language processing. The focus on automatic fact checking, learning with limited data, and scientific text processing is somewhat relevant to query understanding and ranking models. However, the paper's primary focus on scientific language understanding and science communication is not directly aligned with the user's core research themes.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Faithfulness of Scientific Text
- **Aim**: Cultivate datasets, methods, and tools for machine understanding of scientific language to analyze and understand science communication at scale
- **Rationale**: Importance of identifying faithfulness of scientific text in the digital age
- **Ground**: Natural language processing and machine learning
- **Experiment**: New methods and resources for tasks such as identifying check-worthy claims, detecting exaggerated scientific claims, and modeling degrees of information change in science communication
- **Takeaway**: Research outputs are useful for learning from limited amounts of scientific text to identify misinformative scientific statements and generate new insights into the science communication process

#### Abstract
> Scientific information expresses human understanding of nature. This
knowledge is largely disseminated in different forms of text, including
scientific papers, news articles, and discourse among people on social media.
While important for accelerating our pursuit of knowledge, not all scientific
text is faithful to the underlying science. As the volume of this text has
burgeoned online in recent years, it has become a problem of societal
importance to be able to identify the faithfulness of a given piece of
scientific text automatically. This thesis is concerned with the cultivation of
datasets, methods, and tools for machine understanding of scientific language,
in order to analyze and understand science communication at scale. To arrive at
this, I present several contributions in three areas of natural language
processing and machine learning: automatic fact checking, learning with limited
data, and scientific text processing. These contributions include new methods
and resources for identifying check-worthy claims, adversarial claim
generation, multi-source domain adaptation, learning from crowd-sourced labels,
cite-worthiness detection, zero-shot scientific fact checking, detecting
exaggerated scientific claims, and modeling degrees of information change in
science communication. Critically, I demonstrate how the research outputs of
this thesis are useful for effectively learning from limited amounts of
scientific text in order to identify misinformative scientific statements and
generate new insights into the science communication process

---

### 4. Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Philip Lippmann, Jie Yang
- **URL**: <http://arxiv.org/abs/2506.23662v1>
- **Submitted**: 2025-06-30 09:38:50
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper presents a method for generating synthetic context corpora, which is related to information retrieval and query understanding. However, the focus is on contextual embeddings rather than ranking models or user behavior modeling, which are key areas of interest for the user. While the method is applicable to various domains, the e-commerce background of the user is not directly relevant to this paper.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Zero-shot contextual adaptation for natural language processing
- **Aim**: To develop a novel framework for generating compact proxy corpora for zero-shot contextual adaptation, enabling domain-adapted embeddings without target corpus access
- **Rationale**: Traditional methods require access to the target corpus during inference, posing practical barriers in privacy-sensitive or resource-constrained settings
- **Ground**: Dense neural retrieval and context-aware embedding architectures, with limitations of context-agnostic embeddings and the need for context-aware approaches
- **Experiment**: Validation on relevant retrieval benchmarks, comparing ZEST to strong context-agnostic baselines and context-aware models that utilize full corpus access
- **Takeaway**: ZEST achieves high-performance, adaptable embeddings in constrained environments, enabling domain signals to be injected at inference without requiring access to the full corpus

#### Abstract
> Context-aware embedding methods boost retrieval accuracy by conditioning on
corpus statistics (e.g., term co-occurrence and topical patterns) extracted
from neighboring documents. However, this context-aware approach requires
access to the target corpus or requires domain-specific finetuning, posing
practical barriers in privacy-sensitive or resource-constrained settings. We
present ZEST, a zero-shot contextual adaptation framework that replaces real
corpus access with a one-time offline synthesis of a compact proxy. Given only
a handful exemplar documents representative of the general target domain, we
use a multi-step hierarchical procedure to generate a synthetic context corpus
of several hundred documents that aims to emulate key domain-specific
distributions. At inference, the frozen context-aware encoder uses this proxy
corpus -- without any finetuning or target corpus access -- to produce
domain-adapted embeddings. Across the MTEB benchmark, ZEST's zero-shot
synthetic context adaptation using only five example documents performs within
0.5% of models leveraging full target corpus access -- demonstrating remarkable
efficacy without any retraining. ZEST thus provides a practical method for
deploying high-performance, adaptable embeddings in constrained environments.

---

### 5. AutoEvoEval: An Automated Framework for Evolving Close-Ended LLM Evaluation Data

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: JiaRu Wu, Mingwei Liu
- **URL**: <http://arxiv.org/abs/2506.23735v1>
- **Submitted**: 2025-06-30 11:18:56
- **Topic Keywords**: rag, search
- **Reason**: The paper proposes an evaluation framework for large language models, focusing on close-ended tasks and robustness analysis. While it touches on the topic of evaluation, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval and Search technologies.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Evaluating the Robustness of Large Language Models (LLMs) using AutoEvoEval Framework
- **Aim**: To develop an automated framework for evolving close-ended LLM evaluation data that simulates realistic semantic, syntactic, and structural perturbations
- **Rationale**: Traditional evaluation approaches are often static and close-ended, and may overestimate true model generalization, hence the need for evolution-aware robustness evaluation in LLMs
- **Ground**: The proposed AutoEvoEval framework introduces 22 interpretable atomic evolution operations that can be composed into multi-round evolution chains to generate diverse, challenging, and realistic test samples
- **Experiment**: Extensive experiments were conducted to evaluate the effects of different types and lengths of evolutionary transformations on a diverse set of LLMs, and to compare the proposed framework with a baseline method
- **Takeaway**: The study highlights the importance of structured prompts, evolution-aware robustness evaluation, and dynamic and adaptive evaluation approaches to assess deep and nuanced knowledge capabilities of LLMs

#### Abstract
> Large language models (LLMs) have shown remarkable performance on various
tasks, but existing evaluation benchmarks are often static and insufficient to
fully assess their robustness and generalization in realistic scenarios. Prior
work using evolutionary or adversarial data augmentation has improved
evaluation diversity but lacks systematic control over perturbation types and
multi-step complexity, limiting comprehensive robustness analysis. To address
these gaps, we propose AutoEvoEval, an evolution-based evaluation framework for
close-ended tasks such as multi-choice question answering. AutoEvoEval
introduces 22 interpretable atomic evolution operations and supports
multi-round compositions, enabling controlled generation of diverse,
challenging, and realistic test samples. We conduct extensive experiments
addressing four research questions on a broad set of open- and closed-source
LLMs. Our results show that atomic operations cause an average accuracy drop of
7.283\%, with structure-disrupting or misleading semantic edits causing the
largest declines. Model sensitivities vary significantly for the same
perturbation, and combining multiple evolution steps amplifies adversarial
effects by up to 52.932\%. These findings suggest current benchmarks may
overestimate true model generalization and emphasize the need for
evolution-aware robustness evaluation. Code and resources are available at:
https://github.com/SYSUSELab/AutoEvoEval.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Towards an Automated Multimodal Approach for Video Summarization: Building a Bridge Between Text, Audio and Facial Cue-Based Summarization

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Md Moinul Islam, Sofoklis Kakouros, Janne Heikkil√§, Mourad Oussalah
- **URL**: <http://arxiv.org/abs/2506.23714v1>
- **Submitted**: 2025-06-30 10:41:33
- **Comment**: Accepted to HHAI WS 2025: Workshops at the Fourth International
  Conference on Hybrid Human-Artificial Intelligence (HHAI)
- **Topic Keywords**: relevance
- **Reason**: The paper proposes a multimodal video summarization framework that integrates textual, audio, and visual cues, which is somewhat related to information retrieval and search technologies. However, the focus on video summarization and multimodal integration is not directly aligned with the user's primary research interests in query understanding, ranking models, and user behavior modeling. The paper's relevance to the user's interests is limited, but it may still be of interest due to its connection to natural language processing and data mining.

#### Abstract
> The increasing volume of video content in educational, professional, and
social domains necessitates effective summarization techniques that go beyond
traditional unimodal approaches. This paper proposes a behaviour-aware
multimodal video summarization framework that integrates textual, audio, and
visual cues to generate timestamp-aligned summaries. By extracting prosodic
features, textual cues and visual indicators, the framework identifies
semantically and emotionally important moments. A key contribution is the
identification of bonus words, which are terms emphasized across multiple
modalities and used to improve the semantic relevance and expressive clarity of
the summaries. The approach is evaluated against pseudo-ground truth (pGT)
summaries generated using LLM-based extractive method. Experimental results
demonstrate significant improvements over traditional extractive method, such
as the Edmundson method, in both text and video-based evaluation metrics.
Text-based metrics show ROUGE-1 increasing from 0.4769 to 0.7929 and BERTScore
from 0.9152 to 0.9536, while in video-based evaluation, our proposed framework
improves F1-Score by almost 23%. The findings underscore the potential of
multimodal integration in producing comprehensive and behaviourally informed
video summaries.

### 7. Act-With-Think: Chunk Auto-Regressive Modeling for Generative Recommendation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Yifan Wang, Weinan Gan, Longtao Xiao, Jieming Zhu, Heng Chang, Haozhao Wang, Rui Zhang, Zhenhua Dong, Ruiming Tang, Ruixuan Li
- **URL**: <http://arxiv.org/abs/2506.23643v1>
- **Submitted**: 2025-06-30 09:13:54
- **Comment**: 9 pages, 2 figures
- **Topic Keywords**: rag, recommend
- **Reason**: The paper presents a novel approach to generative recommendation, incorporating semantic and behavioral aspects into a single autoregressive transformer. While it touches on some aspects of user behavior modeling, the focus is primarily on the generation paradigm rather than query understanding, ranking models, or real-time relevance optimization, which are core areas of interest in Information Retrieval.

#### Abstract
> Generative recommendation (GR) typically encodes behavioral or semantic
aspects of item information into discrete tokens, leveraging the standard
autoregressive (AR) generation paradigm to make predictions. However, existing
methods tend to overlook their intrinsic relationship, that is, the semantic
usually provides some reasonable explainability "$\textbf{why}$" for the
behavior "$\textbf{what}$", which may constrain the full potential of GR. To
this end, we present Chunk AutoRegressive Modeling (CAR), a new generation
paradigm following the decision pattern that users usually think semantic
aspects of items (e.g. brand) and then take actions on target items (e.g.
purchase). Our CAR, for the $\textit{first time}$, incorporates semantics
(SIDs) and behavior (UID) into a single autoregressive transformer from an
``act-with-think'' dual perspective via chunk-level autoregression.
Specifically, CAR packs SIDs and UID into a conceptual chunk for item unified
representation, allowing each decoding step to make a holistic prediction.
Experiments show that our CAR significantly outperforms existing methods based
on traditional AR, improving Recall@5 by 7.93% to 22.30%. Furthermore, we
verify the scaling effect between model performance and SIDs bit number,
demonstrating that CAR preliminary emulates a kind of slow-thinking style
mechanism akin to the reasoning processes observed in large language models
(LLMs).

### 8. Semantic-guided Diverse Decoding for Large Language Model

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Weijie Shi, Yue Cui, Yaguang Wu, Jingzhi Fang, Shibo Zhang, Mengze Li, Sirui Han, Jia Zhu, Jiajie Xu, Xiaofang Zhou
- **URL**: <http://arxiv.org/abs/2506.23601v1>
- **Submitted**: 2025-06-30 08:06:49
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on diverse decoding for large language models, which is related to query understanding and ranking models in Information Retrieval. However, the paper's primary concern is semantic diversity in language generation, which is not directly aligned with the user's interests in search technologies and user behavior modeling.

#### Abstract
> Diverse decoding of large language models is crucial for applications
requiring multiple semantically distinct responses, yet existing methods
primarily achieve lexical rather than semantic diversity. This limitation
significantly constrains Best-of-N strategies, group-based reinforcement
learning, and data synthesis. While temperature sampling and diverse beam
search modify token distributions or apply n-gram penalties, they fail to
ensure meaningful semantic differentiation. We introduce Semantic-guided
Diverse Decoding (SemDiD), operating directly in embedding space that balances
quality with diversity through three complementary mechanisms: orthogonal
directional guidance, dynamic inter-group repulsion, and position-debiased
probability assessment. SemDiD harmonizes these competing objectives using
adaptive gain functions and constraint optimization, ensuring both quality
thresholds and maximal semantic differentiation. Experiments show SemDiD
consistently outperforms existing methods, improving Best-of-N coverage by
1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15%
while increasing accuracy by up to 2.1%.

### 9. Unveiling Decision-Making in LLMs for Text Classification : Extraction of influential and interpretable concepts with Sparse Autoencoders

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Mathis Le Bail, J√©r√©mie Dentan, Davide Buscaldi, Sonia Vanier
- **URL**: <http://arxiv.org/abs/2506.23951v1>
- **Submitted**: 2025-06-30 15:18:50
- **Topic Keywords**: rag
- **Reason**: The paper explores the application of Sparse Autoencoders to extract interpretable concepts from Large Language Models for text classification, which is a topic in Natural Language Processing. While it touches on the idea of extracting features, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval.

#### Abstract
> Sparse Autoencoders (SAEs) have been successfully used to probe Large
Language Models (LLMs) and extract interpretable concepts from their internal
representations. These concepts are linear combinations of neuron activations
that correspond to human-interpretable features. In this paper, we investigate
the effectiveness of SAE-based explainability approaches for sentence
classification, a domain where such methods have not been extensively explored.
We present a novel SAE-based architecture tailored for text classification,
leveraging a specialized classifier head and incorporating an activation rate
sparsity loss. We benchmark this architecture against established methods such
as ConceptShap, Independent Component Analysis, and other SAE-based concept
extraction techniques. Our evaluation covers two classification benchmarks and
four fine-tuned LLMs from the Pythia family. We further enrich our analysis
with two novel metrics for measuring the precision of concept-based
explanations, using an external sentence encoder. Our empirical results show
that our architecture improves both the causality and interpretability of the
extracted features.

### 10. Evaluating the Simulation of Human Personality-Driven Susceptibility to Misinformation with LLMs

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Manuel Pratelli, Marinella Petrocchi
- **URL**: <http://arxiv.org/abs/2506.23610v1>
- **Submitted**: 2025-06-30 08:16:07
- **Comment**: pre-print version - paper actually under submission
- **Topic Keywords**: rag
- **Reason**: The paper evaluates the simulation of human personality-driven susceptibility to misinformation using Large Language Models (LLMs), which is a topic in Natural Language Processing (NLP). Although it's not directly related to Information Retrieval (IR) or Search technologies, it touches on the theme of understanding human behavior, which is a related topic. However, the focus on personality-driven susceptibility to misinformation is not directly aligned with the user's primary research interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large language models (LLMs) make it possible to generate synthetic
behavioural data at scale, offering an ethical and low-cost alternative to
human experiments. Whether such data can faithfully capture psychological
differences driven by personality traits, however, remains an open question. We
evaluate the capacity of LLM agents, conditioned on Big-Five profiles, to
reproduce personality-based variation in susceptibility to misinformation,
focusing on news discernment, the ability to judge true headlines as true and
false headlines as false. Leveraging published datasets in which human
participants with known personality profiles rated headline accuracy, we create
matching LLM agents and compare their responses to the original human patterns.
Certain trait-misinformation associations, notably those involving
Agreeableness and Conscientiousness, are reliably replicated, whereas others
diverge, revealing systematic biases in how LLMs internalize and express
personality. The results underscore both the promise and the limits of
personality-aligned LLMs for behavioral simulation, and offer new insight into
modeling cognitive diversity in artificial agents.

### 11. Teaching a Language Model to Speak the Language of Tools

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Simeon Emanuilov
- **URL**: <http://arxiv.org/abs/2506.23394v1>
- **Submitted**: 2025-06-29 20:47:27
- **Topic Keywords**: search
- **Reason**: The paper focuses on adapting language models for tool-use capabilities in non-English languages, which is related to query understanding and ranking models in Information Retrieval. However, the paper's primary focus is on language models and tool integration, rather than search technologies or user behavior modeling, making it only loosely relevant to the user's research interests.

#### Abstract
> External tool integration through function-calling is essential for practical
language model applications, yet most multilingual models lack reliable
tool-use capabilities in non-English languages. Even state-of-the-art
multilingual models struggle with determining when to use tools and generating
the structured outputs required for function calls, often exhibiting language
confusion when prompted in lower-resource languages. This work presents a
methodology for adapting existing language models to enable robust tool use in
any target language, using Bulgarian as a case study. The approach involves
continued training of the BgGPT model series (2.6B, 9B, 27B parameters) on a
novel bilingual dataset of 10,035 function-calling examples designed to support
standardized protocols like MCP (Model Context Protocol). The research
introduces TUCAN (Tool-Using Capable Assistant Navigator), which achieves up to
28.75% improvement in function-calling accuracy over base models while
preserving core language understanding, as verified on established Bulgarian
benchmarks. Beyond accuracy gains, TUCAN models demonstrate production-ready
response formatting with clean, parsable function calls, contrasting with the
verbose and inconsistent outputs of base models. The models, evaluation
framework, and dataset are released to enable replication for other languages.
This work demonstrates a practical approach for extending tool-augmented
capabilities beyond English-centric systems.

### 12. NaviX: A Native Vector Index Design for Graph DBMSs With Robust Predicate-Agnostic Search Performance

- **LLM Score**: 2
- **Keyword Score**: 9
- **Authors**: Gaurav Sehgal, Semih Salihoglu
- **URL**: <http://arxiv.org/abs/2506.23397v1>
- **Submitted**: 2025-06-29 21:16:07
- **Topic Keywords**: query, queries, rag, search
- **Reason**: The paper focuses on designing a native vector index for graph DBMSs, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions search queries, the context is different from the user's interests in IR and NLP.

#### Abstract
> There is an increasing demand for extending existing DBMSs with vector
indices so that they become unified systems capable of supporting modern
predictive applications, which require joint querying of vector embeddings
together with the structured properties and connections of objects. We present
NaviX, a native vector index for graph DBMSs (GDBMSs) that has two main design
goals. First, we aim to implement a disk-based vector index that leverages the
core storage and query-processing capabilities of the underlying GDBMS. To this
end, NaviX is built on the Hierarchical Navigable Small-World (HNSW) graph,
which itself is a graph-based structure. Second, we aim to support
predicate-agnostic filtered vector search queries, in which the k nearest
neighbors (kNNs) of a query vector vQ are searched only within an arbitrary
subset S of vectors defined by an ad-hoc selection sub-query QS. We adopt a
prefiltering approach that evaluates QS first and passes the full description
of subset S to the kNN search operator. We study how to design a prefiltering
search algorithm that remains robust under varying selectivities and under
different correlations between subset S and query vector vQ. We propose an
adaptive algorithm that uses the local selectivity of each vector in the HNSW
graph to choose an appropriate heuristic at every iteration of the kNN search.
Finally, We demonstrate NaviX's robustness and efficiency through extensive
experiments against both existing prefiltering- and postfiltering-based
baselines.

### 13. On the Predictive Power of Representation Dispersion in Language Models

- **LLM Score**: 2
- **Keyword Score**: 8
- **Authors**: Yanhong Li, Ming Li, Karen Livescu, Jiawei Zhou
- **URL**: <http://arxiv.org/abs/2506.24106v1>
- **Submitted**: 2025-06-30 17:53:50
- **Topic Keywords**: pairwise, rag, retrieval, search
- **Reason**: The paper focuses on the predictive power of representation dispersion in language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on the idea of using dispersion for model selection and retrieval-based methods, the connection to the user's research interests is loose and indirect.

#### Abstract
> We show that a language model's ability to predict text is tightly linked to
the breadth of its embedding space: models that spread their contextual
representations more widely tend to achieve lower perplexity. Concretely, we
find that representation dispersion - the average pairwise cosine distance
among hidden vectors - strongly and negatively correlates with perplexity
across diverse model families (LLaMA, Qwen, and others) and domains (Wikipedia,
news, scientific abstracts). Beyond illustrating this link, we show how
dispersion can be leveraged for a range of practical tasks without requiring
labeled data. First, measuring dispersion on unlabeled text allows us to
predict downstream accuracy in new domains, offering a data-efficient tool for
model selection. Next, we find that identifying layers with higher dispersion
pinpoints the best representations for retrieval-based methods such as kNN-LM,
bypassing exhaustive layer-by-layer searches. Finally, we integrate a simple
push-away objective into training, which increases dispersion in both
single-domain and cross-domain scenarios and directly improves perplexity in
each.

### 14. Emergent musical properties of a transformer under contrastive self-supervised learning

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Yuexuan Kong, Gabriel Meseguer-Brocal, Vincent Lostanlen, Mathieu Lagrange, Romain Hennequin
- **URL**: <http://arxiv.org/abs/2506.23873v1>
- **Submitted**: 2025-06-30 14:04:59
- **Comment**: Accepted at ISMIR 2025
- **Topic Keywords**: information retrieval, rag, retrieval
- **Reason**: This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on music information retrieval and the application of transformers in music, which is outside the user's primary research areas.

#### Abstract
> In music information retrieval (MIR), contrastive self-supervised learning
for general-purpose representation models is effective for global tasks such as
automatic tagging. However, for local tasks such as chord estimation, it is
widely assumed that contrastively trained general-purpose self-supervised
models are inadequate and that more sophisticated SSL is necessary; e.g.,
masked modeling. Our paper challenges this assumption by revealing the
potential of contrastive SSL paired with a transformer in local MIR tasks. We
consider a lightweight vision transformer with one-dimensional patches in the
time--frequency domain (ViT-1D) and train it with simple contrastive SSL
through normalized temperature-scaled cross-entropy loss (NT-Xent). Although
NT-Xent operates only over the class token, we observe that, potentially thanks
to weight sharing, informative musical properties emerge in ViT-1D's sequence
tokens. On global tasks, the temporal average of class and sequence tokens
offers a performance increase compared to the class token alone, showing useful
properties in the sequence tokens. On local tasks, sequence tokens perform
unexpectedly well, despite not being specifically trained for. Furthermore,
high-level musical features such as onsets emerge from layer-wise attention
maps and self-similarity matrices show different layers capture different
musical dimensions. Our paper does not focus on improving performance but
advances the musical interpretation of transformers and sheds light on some
overlooked abilities of contrastive SSL paired with transformers for sequence
modeling in MIR.

### 15. Leveraging the Potential of Prompt Engineering for Hate Speech Detection in Low-Resource Languages

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Ruhina Tabasshum Prome, Tarikul Islam Tamiti, Anomadarshi Barua
- **URL**: <http://arxiv.org/abs/2506.23930v1>
- **Submitted**: 2025-06-30 14:59:25
- **Topic Keywords**: rag, ctr
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topic of hate speech detection in low-resource languages is outside your primary focus on query understanding, ranking models, and user behavior modeling. Although the paper mentions large language models, it does not relate to your specific areas of interest.

#### Abstract
> The rapid expansion of social media leads to a marked increase in hate
speech, which threatens personal lives and results in numerous hate crimes.
Detecting hate speech presents several challenges: diverse dialects, frequent
code-mixing, and the prevalence of misspelled words in user-generated content
on social media platforms. Recent progress in hate speech detection is
typically concentrated on high-resource languages. However, low-resource
languages still face significant challenges due to the lack of large-scale,
high-quality datasets. This paper investigates how we can overcome this
limitation via prompt engineering on large language models (LLMs) focusing on
low-resource Bengali language. We investigate six prompting strategies -
zero-shot prompting, refusal suppression, flattering the classifier, multi-shot
prompting, role prompting, and finally our innovative metaphor prompting to
detect hate speech effectively in low-resource languages. We pioneer the
metaphor prompting to circumvent the built-in safety mechanisms of LLMs that
marks a significant departure from existing jailbreaking methods. We
investigate all six different prompting strategies on the Llama2-7B model and
compare the results extensively with three pre-trained word embeddings - GloVe,
Word2Vec, and FastText for three different deep learning models - multilayer
perceptron (MLP), convolutional neural network (CNN), and bidirectional gated
recurrent unit (BiGRU). To prove the effectiveness of our metaphor prompting in
the low-resource Bengali language, we also evaluate it in another low-resource
language - Hindi, and two high-resource languages - English and German. The
performance of all prompting techniques is evaluated using the F1 score, and
environmental impact factor (IF), which measures CO$_2$ emissions, electricity
usage, and computational time.

### 16. EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Hyunjong Kim, Sangyeop Kim, Jongheon Jeong, Yeongjae Cho, Sungzoon Cho
- **URL**: <http://arxiv.org/abs/2506.24016v1>
- **Submitted**: 2025-06-30 16:20:51
- **Comment**: Accepted at ACL 2025 Findings
- **Topic Keywords**: relevance
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it touches on Natural Language Processing (NLP) and vision-language models, the focus is on image captioning evaluation metrics, which is a specific application in NLP rather than a broader topic in IR or NLP.

#### Abstract
> Recent advances in large language models and vision-language models have led
to growing interest in explainable evaluation metrics for image captioning.
However, these metrics generate explanations without standardized criteria, and
the overall quality of the generated explanations remains unverified. In this
paper, we propose EXPERT, a reference-free evaluation metric that provides
structured explanations based on three fundamental criteria: fluency,
relevance, and descriptiveness. By constructing large-scale datasets of
high-quality structured explanations, we develop a two-stage evaluation
template to effectively supervise a vision-language model for both scoring and
explanation generation. EXPERT achieves state-of-the-art results on benchmark
datasets while providing significantly higher-quality explanations than
existing metrics, as validated through comprehensive human evaluation. Our code
and datasets are available at https://github.com/hjkim811/EXPERT.

### 17. Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Seungjun Yi, Joakim Nguyen, Huimin Xu, Terence Lim, Andrew Well, Mia Markey, Ying Ding
- **URL**: <http://arxiv.org/abs/2506.23998v1>
- **Submitted**: 2025-06-30 16:02:28
- **Comment**: Presented at ACL 2025 SRW
- **Topic Keywords**: relevance
- **Reason**: This paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on automated thematic analysis in the medical domain, which is outside the user's primary focus areas.

#### Abstract
> Congenital heart disease (CHD) presents complex, lifelong challenges often
underrepresented in traditional clinical metrics. While unstructured narratives
offer rich insights into patient and caregiver experiences, manual thematic
analysis (TA) remains labor-intensive and unscalable. We propose a fully
automated large language model (LLM) pipeline that performs end-to-end TA on
clinical narratives, which eliminates the need for manual coding or full
transcript review. Our system employs a novel multi-agent framework, where
specialized LLM agents assume roles to enhance theme quality and alignment with
human analysis. To further improve thematic relevance, we optionally integrate
reinforcement learning from human feedback (RLHF). This supports scalable,
patient-centered analysis of large qualitative datasets and allows LLMs to be
fine-tuned for specific clinical contexts.

### 18. Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yang Dai, Jianxiang An, Tianwei Lin, Hongyang He, Hongzhe Huang, Wenqiao Zhang, Zheqi Lv, Siliang Tang, Yueting Zhuang
- **URL**: <http://arxiv.org/abs/2506.23940v2>
- **Submitted**: 2025-06-30 15:07:41
- **Topic Keywords**: rag, rank
- **Reason**: The paper focuses on integrating domain knowledge in Multimodal Large Language Models (MLLMs), which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on the concept of knowledge sharing, the context is different from the user's primary research interests.

#### Abstract
> Multimodal Large Language Models (MLLMs) have achieved success across various
domains. However, their applicability tends to degrade when confronted with
different types of data inputs, especially for MLLMs that have been fine-tuned
for specific tasks. Despite its importance, the study of knowledge sharing
among domain-specific MLLMs--such as those trained for mathematics or
code--remains largely underexplored. To address the fragmentation of knowledge
across domain-specialized MLLMs, we propose a unified parameter integration
framework that enables modular composition of expert capabilities. Our method
is grounded in a novel Compatibility-Aware Parameter Splicing (CAPS) strategy,
which leverages both local functional attribution and global
information-theoretic signals to guide selective parameter fusion. By extending
this mechanism to the low-rank adaptation layer granularity, we ensure
efficient integration with minimal inference overhead. Furthermore, we
introduce a domain compatibility scoring mechanism that quantifies inter-expert
alignment at the activation level and correlates with downstream task utility.
This principled fusion protocol allows the final model to synergize
heterogeneous expertise while preserving structural modularity. Extensive
evaluations across diverse multimodal benchmarks validate the effectiveness of
our framework, offering a scalable path toward compositional, domain-adaptive
MLLMs.

### 19. NEU-ESC: A Comprehensive Vietnamese dataset for Educational Sentiment analysis and topic Classification toward multitask learning

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Phan Quoc Hung Mai, Quang Hung Nguyen, Phuong Giang Duong, Hong Hanh Nguyen, Nguyen Tuan Long
- **URL**: <http://arxiv.org/abs/2506.23524v1>
- **Submitted**: 2025-06-30 05:19:04
- **Topic Keywords**: relevance
- **Reason**: The paper focuses on a specific domain (education) and language (Vietnamese), with a narrow scope on sentiment analysis and topic classification. While it uses a language model (BERT), the context is not related to information retrieval, search technologies, or query understanding, which are the user's primary research interests.

#### Abstract
> In the field of education, understanding students' opinions through their
comments is crucial, especially in the Vietnamese language, where resources
remain limited. Existing educational datasets often lack domain relevance and
student slang. To address these gaps, we introduce NEU-ESC, a new Vietnamese
dataset for Educational Sentiment Classification and Topic Classification,
curated from university forums, which offers more samples, richer class
diversity, longer texts, and broader vocabulary. In addition, we explore
multitask learning using encoder-only language models (BERT), in which we
showed that it achieves performance up to 83.7% and 79.8% accuracy for
sentiment and topic classification tasks. We also benchmark our dataset and
model with other datasets and models, including Large Language Models, and
discuss these benchmarks. The dataset is publicly available at:
https://huggingface.co/datasets/hung20gg/NEU-ESC.

### 20. Datasets for Fairness in Language Models: An In-Depth Survey

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jiale Zhang, Zichong Wang, Avash Palikhe, Zhipeng Yin, Wenbin Zhang
- **URL**: <http://arxiv.org/abs/2506.23411v1>
- **Submitted**: 2025-06-29 22:11:58
- **Topic Keywords**: rag, search
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The focus on fairness in language models and datasets is outside your primary areas of interest, and the paper does not address topics like real-time relevance optimization or deep semantic understanding.

#### Abstract
> Fairness benchmarks play a central role in shaping how we evaluate language
models, yet surprisingly little attention has been given to examining the
datasets that these benchmarks rely on. This survey addresses that gap by
presenting a broad and careful review of the most widely used fairness datasets
in current language model research, characterizing them along several key
dimensions including their origin, scope, content, and intended use to help
researchers better appreciate the assumptions and limitations embedded in these
resources. To support more meaningful comparisons and analyses, we introduce a
unified evaluation framework that reveals consistent patterns of demographic
disparities across datasets and scoring methods. Applying this framework to
twenty four common benchmarks, we highlight the often overlooked biases that
can influence conclusions about model fairness and offer practical guidance for
selecting, combining, and interpreting these datasets. We also point to
opportunities for creating new fairness benchmarks that reflect more diverse
social contexts and encourage more thoughtful use of these tools going forward.
All code, data, and detailed results are publicly available at
https://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets
to promote transparency and reproducibility across the research community.

### 21. Density, asymmetry and citation dynamics in scientific literature

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Nathaniel Imel, Zachary Hafen
- **URL**: <http://arxiv.org/abs/2506.23366v1>
- **Submitted**: 2025-06-29 18:55:04
- **Topic Keywords**: rag, search
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on scientometrics, citation dynamics, and document embeddings, which are not central to your areas of interest.

#### Abstract
> Scientific behavior is often characterized by a tension between building upon
established knowledge and introducing novel ideas. Here, we investigate whether
this tension is reflected in the relationship between the similarity of a
scientific paper to previous research and its eventual citation rate. To
operationalize similarity to previous research, we introduce two complementary
metrics to characterize the local geometry of a publication's semantic
neighborhood: (1) \emph{density} ($\rho$), defined as the ratio between a fixed
number of previously-published papers and the minimum distance enclosing those
papers in a semantic embedding space, and (2) asymmetry ($\alpha$), defined as
the average directional difference between a paper and its nearest neighbors.
We tested the predictive relationship between these two metrics and its
subsequent citation rate using a Bayesian hierarchical regression approach,
surveying $\sim 53,000$ publications across nine academic disciplines and five
different document embeddings. While the individual effects of $\rho$ on
citation count are small and variable, incorporating density-based predictors
consistently improves out-of-sample prediction when added to baseline models.
These results suggest that the density of a paper's surrounding scientific
literature may carry modest but informative signals about its eventual impact.
Meanwhile, we find no evidence that publication asymmetry improves model
predictions of citation rates. Our work provides a scalable framework for
linking document embeddings to scientometric outcomes and highlights new
questions regarding the role that semantic similarity plays in shaping the
dynamics of scientific reward.

### 22. SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Bo Liu, Leon Guertler, Simon Yu, Zichen Liu, Penghui Qi, Daniel Balcells, Mickel Liu, Cheston Tan, Weiyan Shi, Min Lin, Wee Sun Lee, Natasha Jaques
- **URL**: <http://arxiv.org/abs/2506.24119v2>
- **Submitted**: 2025-06-30 17:58:13
- **Comment**: Work in Progress
- **Topic Keywords**: rag
- **Reason**: The paper focuses on reinforcement learning and multi-agent systems, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions language models, the context is different from the user's interests in NLP and IR. The paper's emphasis on zero-sum games and self-play training is not relevant to the user's research themes.

#### Abstract
> Recent advances in reinforcement learning have shown that language models can
develop sophisticated reasoning through training on tasks with verifiable
rewards, but these approaches depend on human-curated problem-answer pairs and
domain-specific reward engineering. We introduce SPIRAL, a self-play framework
where models learn by playing multi-turn, zero-sum games against continuously
improving versions of themselves, eliminating the need for human supervision.
Through self-play, SPIRAL generates an infinite curriculum of progressively
challenging problems as models must constantly adapt to stronger opponents. To
enable this self-play training at scale, We implement a fully online,
multi-turn, multi-agent reinforcement learning system for LLMs and propose
role-conditioned advantage estimation (RAE) to stabilize multi-agent training.
Using SPIRAL, self-play on zero-sum games produces reasoning capabilities that
transfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%
improvement on math and 8.4% on general reasoning, outperforming SFT on 25,000
expert game trajectories. Analysis reveals that this transfer occurs through
three cognitive patterns: systematic decomposition, expected value calculation,
and case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple
Negotiation) further enhances performance as each game develops distinct
reasoning strengths. Applying SPIRAL to a strong reasoning model
(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These
results demonstrate that zero-sum games naturally develop transferable
reasoning capabilities, highlighting a promising direction for autonomous
reasoning development.

### 23. TaP: A Taxonomy-Guided Framework for Automated and Scalable Preference Data Generation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Renren Jin, Tianhao Shen, Xinwei Wu, Dan Shi, Haoran Sun, Wuwei Huang, Quandong Wang, Wei Liu, Jian Luan, Bin Wang, Deyi Xiong
- **URL**: <http://arxiv.org/abs/2506.23979v1>
- **Submitted**: 2025-06-30 15:45:28
- **Comment**: 33 pages, 15 tables, 11 figures
- **Topic Keywords**: rag
- **Reason**: The paper focuses on preference data generation and fine-tuning of large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on NLP, the topic is more specific to language models and dataset construction, which is not a central match for your research interests.

#### Abstract
> Conducting supervised fine-tuning and preference fine-tuning on large
language models (LLMs) requires high-quality datasets to improve their ability
to follow instructions and align with human preferences and values. However,
constructing such datasets is resource-intensive, and most available datasets
for supervised and preference fine-tuning are in English. To address these
challenges, we propose the \underline{\textbf{Ta}}xonomy-Guided
\underline{\textbf{P}}reference Data Generation (TaP) framework, which
facilitates automated and scalable construction of preference datasets across
various languages. TaP is grounded in a structured taxonomy that allows
fine-grained control over dataset composition, thereby ensuring both diversity
and comprehensive coverage. We employ TaP-generated datasets to perform
supervised and preference fine-tuning on various LLMs. Experimental results
demonstrate that LLMs trained on TaP-generated datasets outperform those
trained on existing open-source datasets. Remarkably, LLMs trained on
TaP-generated datasets surpass the performance of those trained on an
open-source dataset that is 180 times larger.

### 24. Garbage In, Reasoning Out? Why Benchmark Scores are Unreliable and What to Do About It

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Seyed Mahed Mousavi, Edoardo Cecchinato, Lucia Hornikova, Giuseppe Riccardi
- **URL**: <http://arxiv.org/abs/2506.23864v1>
- **Submitted**: 2025-06-30 13:57:28
- **Topic Keywords**: rag
- **Reason**: The paper's focus on benchmarking and evaluation methodology in natural language processing (NLP) is not directly related to the user's interests in information retrieval, query understanding, ranking models, and user behavior modeling. While the paper touches on topics like language models and reasoning, the context is not relevant to the user's primary research areas.

#### Abstract
> We conduct a systematic audit of three widely used reasoning benchmarks,
SocialIQa, FauxPas-EAI, and ToMi, and uncover pervasive flaws in both benchmark
items and evaluation methodology. Using five LLMs (GPT-{3, 3.5, 4, o1}, and
LLaMA 3.1) as diagnostic tools, we identify structural, semantic, and pragmatic
issues in benchmark design (e.g., duplicated items, ambiguous wording, and
implausible answers), as well as scoring procedures that prioritize output form
over reasoning process. Through systematic human annotation and re-evaluation
on cleaned benchmark subsets, we find that model scores often improve not due
to due to erratic surface wording variations and not to improved reasoning.
Infact, further analyses show that model performance is highly sensitive to
minor input variations such as context availability and phrasing, revealing
that high scores may reflect alignment with format-specific cues rather than
consistent inference based on the input. These findings challenge the validity
of current benchmark-based claims about reasoning in LLMs, and highlight the
need for evaluation protocols that assess reasoning as a process of drawing
inference from available information, rather than as static output selection.
We release audited data and evaluation tools to support more interpretable and
diagnostic assessments of model reasoning.

### 25. Towards the "Digital Me": A vision of authentic Conversational Agents powered by personal Human Digital Twins

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Llu√≠s C. Coll, Martin W. Lauer-Schmaltz, Philip Cash, John P. Hansen, Anja Maier
- **URL**: <http://arxiv.org/abs/2506.23826v1>
- **Submitted**: 2025-06-30 13:18:31
- **Comment**: 24 pages, 9 figures
- **Topic Keywords**: retrieval
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it touches on conversational AI, the focus is on Human Digital Twins and their applications, which is outside the scope of the user's primary research interests.

#### Abstract
> Human Digital Twins (HDTs) have traditionally been conceptualized as
data-driven models designed to support decision-making across various domains.
However, recent advancements in conversational AI open new possibilities for
HDTs to function as authentic, interactive digital counterparts of individuals.
This paper introduces a novel HDT system architecture that integrates large
language models with dynamically updated personal data, enabling it to mirror
an individual's conversational style, memories, and behaviors. To achieve this,
our approach implements context-aware memory retrieval, neural
plasticity-inspired consolidation, and adaptive learning mechanisms, creating a
more natural and evolving digital persona. The resulting system does not only
replicate an individual's unique conversational style depending on who they are
speaking with, but also enriches responses with dynamically captured personal
experiences, opinions, and memories. While this marks a significant step toward
developing authentic virtual counterparts, it also raises critical ethical
concerns regarding privacy, accountability, and the long-term implications of
persistent digital identities. This study contributes to the field of HDTs by
describing our novel system architecture, demonstrating its capabilities, and
discussing future directions and emerging challenges to ensure the responsible
and ethical development of HDTs.

### 26. Hierarchical Memory Organization for Wikipedia Generation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Eugene J. Yu, Dawei Zhu, Yifan Song, Xiangyu Wong, Jiebin Zhang, Wenxuan Shi, Xiaoguang Li, Qun Liu, Sujian Li
- **URL**: <http://arxiv.org/abs/2506.23393v1>
- **Submitted**: 2025-06-29 20:22:49
- **Comment**: ACL 2025 Main Conference
- **Topic Keywords**: rag
- **Reason**: This paper focuses on generating Wikipedia articles using a hierarchical memory architecture, which is not directly related to information retrieval, search technologies, or query understanding. While it involves processing and organizing information, the context is different from the user's primary research interests.

#### Abstract
> Generating Wikipedia articles autonomously is a challenging task requiring
the integration of accurate, comprehensive, and well-structured information
from diverse sources. This paper introduces the Memory Organization-based
Generation (MOG) framework, a novel approach to address these challenges by
leveraging a hierarchical memory architecture. MOG extracts fine-grained memory
units from web documents, recursively organizes them into a Wikipedia-style
hierarchical structure, and uses this structure to guide the generation
process. This ensures alignment between memory and the article outline,
improving both informativeness and verifiability while minimizing
hallucinations. Additionally, a citation module is implemented to enhance
traceability by linking every generated sentence to specific memory units.
Evaluations on our newly created WikiStart dataset demonstrate that MOG
outperforms baseline methods in producing informative and reliable articles,
making it particularly robust in real-world scenarios.

### 27. You Sound a Little Tense: L2 Tailored Clear TTS Using Durational Vowel Properties

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Paige Tutt√∂s√≠, H. Henny Yeung, Yue Wang, Jean-Julien Aucouturier, Angelica Lim
- **URL**: <http://arxiv.org/abs/2506.23367v1>
- **Submitted**: 2025-06-29 18:55:05
- **Comment**: Accepted to ISCA Speech Synthesis Workshop, 2025
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The topic of text-to-speech systems for second language speakers is outside your primary focus on information retrieval and real-time relevance optimization.

#### Abstract
> We present the first text-to-speech (TTS) system tailored to second language
(L2) speakers. We use duration differences between American English tense
(longer) and lax (shorter) vowels to create a "clarity mode" for Matcha-TTS.
Our perception studies showed that French-L1, English-L2 listeners had fewer
(at least 9.15%) transcription errors when using our clarity mode, and found it
more encouraging and respectful than overall slowed down speech. Remarkably,
listeners were not aware of these effects: despite the decreased word error
rate in clarity mode, listeners still believed that slowing all target words
was the most intelligible, suggesting that actual intelligibility does not
correlate with perceived intelligibility. Additionally, we found that
Whisper-ASR did not use the same cues as L2 speakers to differentiate difficult
vowels and is not sufficient to assess the intelligibility of TTS systems for
these individuals.

### 28. Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Anselm R. Strohmaier, Wim Van Dooren, Kathrin Se√üler, Brian Greer, Lieven Verschaffel
- **URL**: <http://arxiv.org/abs/2506.24006v1>
- **Submitted**: 2025-06-30 16:10:42
- **Topic Keywords**: search
- **Reason**: The paper is not related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. It focuses on the application of Large Language Models in mathematics education, which is outside the scope of the user's research interests.

#### Abstract
> The progress of Large Language Models (LLMs) like ChatGPT raises the question
of how they can be integrated into education. One hope is that they can support
mathematics learning, including word-problem solving. Since LLMs can handle
textual input with ease, they appear well-suited for solving mathematical word
problems. Yet their real competence, whether they can make sense of the
real-world context, and the implications for classrooms remain unclear. We
conducted a scoping review from a mathematics-education perspective, including
three parts: a technical overview, a systematic review of word problems used in
research, and a state-of-the-art empirical evaluation of LLMs on mathematical
word problems. First, in the technical overview, we contrast the
conceptualization of word problems and their solution processes between LLMs
and students. In computer-science research this is typically labeled
mathematical reasoning, a term that does not align with usage in mathematics
education. Second, our literature review of 213 studies shows that the most
popular word-problem corpora are dominated by s-problems, which do not require
a consideration of realities of their real-world context. Finally, our
evaluation of GPT-3.5-turbo, GPT-4o-mini, GPT-4.1, and o3 on 287 word problems
shows that most recent LLMs solve these s-problems with near-perfect accuracy,
including a perfect score on 20 problems from PISA. LLMs still showed
weaknesses in tackling problems where the real-world context is problematic or
non-sensical. In sum, we argue based on all three aspects that LLMs have
mastered a superficial solution process but do not make sense of word problems,
which potentially limits their value as instructional tools in mathematics
classrooms.

### 29. IMPACT: Inflectional Morphology Probes Across Complex Typologies

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Mohammed J. Saeed, Tommi Vehvilainen, Evgeny Fedoseev, Sevil Caliskan, Tatiana Vodolazova
- **URL**: <http://arxiv.org/abs/2506.23929v1>
- **Submitted**: 2025-06-30 14:58:23
- **Topic Keywords**: search
- **Reason**: The paper focuses on evaluating the performance of Large Language Models on inflectional morphology in five languages, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on the topic of linguistic complexity, it does not address the specific areas of interest in query understanding, ranking models, or user behavior modeling.

#### Abstract
> Large Language Models (LLMs) have shown significant progress on various
multilingual benchmarks and are increasingly used to generate and evaluate text
in non-English languages. However, while they may produce fluent outputs, it
remains unclear to what extent these models truly grasp the underlying
linguistic complexity of those languages, particularly in morphology. To
investigate this, we introduce IMPACT, a synthetically generated evaluation
framework focused on inflectional morphology, which we publicly release,
designed to evaluate LLM performance across five morphologically rich
languages: Arabic, Russian, Finnish, Turkish, and Hebrew. IMPACT includes
unit-test-style cases covering both shared and language-specific phenomena,
from basic verb inflections (e.g., tense, number, gender) to unique features
like Arabic's reverse gender agreement and vowel harmony in Finnish and
Turkish. We assess eight multilingual LLMs that, despite strong English
performance, struggle with other languages and uncommon morphological patterns,
especially when judging ungrammatical examples. We also show that Chain of
Thought and Thinking Models can degrade performance. Our work exposes gaps in
LLMs' handling of linguistic complexity, pointing to clear room for
improvement. To support further research, we publicly release the IMPACT
framework.

### 30. Efficient Interleaved Speech Modeling through Knowledge Distillation

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Mohammadmahdi Nouriborji, Morteza Rohanian
- **URL**: <http://arxiv.org/abs/2506.23670v1>
- **Submitted**: 2025-06-30 09:47:37
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on speech language models, knowledge distillation, and compact speech generation, which are not directly related to your areas of interest.

#### Abstract
> Current speech language models exceed the size and latency constraints of
many deployment environments. We build compact, expressive speech generation
models through layer-aligned distillation, matching hidden states, attention
maps, and softened logits to compress large multimodal transformers by 3x with
minimal loss in performance. We introduce TinyWave, a family of 2B-parameter
models for speech-to-speech and interleaved speech-text generation, trained on
50,000 hours of public audio. TinyWave supports (i) speech-only generation
using phonetic or expressive tokens and (ii) mixed speech-text continuations.
Evaluation on Libri-Light shows TinyWave within 1.4 normalized perplexity
points of its teacher. Accuracy on spoken StoryCloze and SALMon reaches 93-97%
of the teacher's performance, outperforming size-matched baselines. These
models are optimized for deployment on commodity hardware, enabling
applications in real-time conversational agents, assistive technologies, and
low-resource environments. We release models, training code, and evaluation
scripts to support reproducible research on compact, expressive speech
generation.

### 31. Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Arnisa Fazla, Lucas Krauter, David Guzman Piedrahita, Andrianos Michail
- **URL**: <http://arxiv.org/abs/2506.23661v1>
- **Submitted**: 2025-06-30 09:37:19
- **Comment**: 12 pages main text, 27 pages total including references and
  appendices. 13 figures, 10 tables. Accepted for publication in the LNCS
  proceedings of CLEF 2025 (Best-of-Labs track)
- **Topic Keywords**: search
- **Reason**: The paper focuses on adversarial attacks on text classification systems, which is not directly related to the user's interests in Information Retrieval, Search technologies, and query understanding. While it touches on NLP, the specific topic of robustness to adversarial examples is not a central match for the user's research themes.

#### Abstract
> We extend BeamAttack, an adversarial attack algorithm designed to evaluate
the robustness of text classification systems through word-level modifications
guided by beam search. Our extensions include support for word deletions and
the option to skip substitutions, enabling the discovery of minimal
modifications that alter model predictions. We also integrate LIME to better
prioritize word replacements. Evaluated across multiple datasets and victim
models (BiLSTM, BERT, and adversarially trained RoBERTa) within the BODEGA
framework, our approach achieves over a 99\% attack success rate while
preserving the semantic and lexical similarity of the original texts. Through
both quantitative and qualitative analysis, we highlight BeamAttack's
effectiveness and its limitations. Our implementation is available at
https://github.com/LucK1Y/BeamAttack

### 32. MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Huanjin Yao, Jiaxing Huang, Yawen Qiu, Michael K. Chen, Wenzheng Liu, Wei Zhang, Wenjie Zeng, Xikun Zhang, Jingyi Zhang, Yuxin Song, Wenhao Wu, Dacheng Tao
- **URL**: <http://arxiv.org/abs/2506.23563v1>
- **Submitted**: 2025-06-30 07:14:38
- **Comment**: Technical report
- **Topic Keywords**: search
- **Reason**: The paper focuses on multimodal large language models and their ability to perform long-chain reasoning, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on the topic of evaluating AI models, it does not address the specific areas of interest in the user's research, such as ranking models, user behavior modeling, or deep semantic understanding.

#### Abstract
> Reasoning plays a crucial role in advancing Multimodal Large Language Models
(MLLMs) toward Artificial General Intelligence. However, existing MLLM
benchmarks often fall short in precisely and comprehensively evaluating
long-chain reasoning abilities from three key aspects: (1) lack of difficulty
and diversity, (2) susceptibility to guessability and memorization, (3)
inadequate assessment of intermediate reasoning steps. To fill this gap, we
introduce MMReason, a new benchmark designed to precisely and comprehensively
evaluate MLLM long-chain reasoning capability with diverse, open-ended,
challenging questions. First, we curate challenging questions requiring
multi-step reasoning from various fields (i.e., 6 disciplines) and multiple
difficulty levels (i.e., from pre-university to university, and from
foundational to competition tiers). Second, these questions are reformulated
into an open-ended format and filtered using a multi-model voting technique to
eliminate shortcut cases related to guessing and memorization, ensuring robust
reasoning evaluations. Third, we annotate the questions with detailed
step-by-step solutions, and design a reference-based ternary scoring mechanism
to reliably assess intermediate reasoning steps. With MMReason, we benchmark
popular leading MLLMs and provide an in-depth analysis of their reasoning
capabilities. We hope MMReason will serve as a valuable resource for advancing
MLLM reasoning research. Code will be available at
https://github.com/HJYao00/MMReason.

---

