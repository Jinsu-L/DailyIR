# Daily Papers Report - 2026-01-20

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Rules, Resources, and Restrictions: A Taxonomy of Task-Based Information Request Intents

- **LLM Score**: 8
- **Keyword Score**: 9
- **Authors**: Melanie A. Kilian, David Elsweiler
- **URL**: <http://arxiv.org/abs/2601.12985v1>
- **Submitted**: 2026-01-19 11:59:23
- **Comment**: 11 pages, 1 figure, to be published in: 2026 ACM SIGIR Conference on Human Information Interaction and Retrieval (CHIIR '26), March 22-26, 2026, Seattle, WA, USA. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3786304.3787863
- **Topic Keywords**: query, queries, retrieval, search
- **Reason**: This paper is highly relevant to Information Retrieval, particularly in the area of query understanding and intent classification. The focus on task-based information request intents and the proposed taxonomy aligns with your interests in deep semantic understanding and real-time relevance optimization. The connection to Large Language Models and AI-driven task-oriented search further strengthens the relevance.

#### Abstract
> Understanding and classifying query intents can improve retrieval effectiveness by helping align search results with the motivations behind user queries. However, existing intent taxonomies are typically derived from system log data and capture mostly isolated information needs, while the broader task context often remains unaddressed. This limitation becomes increasingly relevant as interactions with Large Language Models (LLMs) expand user expectations from simple query answering toward comprehensive task support, for example, with purchasing decisions or in travel planning. At the same time, current LLMs still struggle to fully interpret complex and multifaceted tasks. To address this gap, we argue for a stronger task-based perspective on query intent. Drawing on a grounded-theory-based interview study with airport information clerks, we present a taxonomy of task-based information request intents that bridges the gap between traditional query-focused approaches and the emerging demands of AI-driven task-oriented search.

---

### 2. Augmenting Question Answering with A Hybrid RAG Approach

- **LLM Score**: 8
- **Keyword Score**: 7
- **Authors**: Tianyi Yang, Nashrah Haque, Vaishnave Jonnalagadda, Yuya Jeremy Ong, Zhehui Chen, Yanzhao Wu, Lei Yu, Divyesh Jadav, Wenqi Wei
- **URL**: <http://arxiv.org/abs/2601.12658v1>
- **Submitted**: 2026-01-19 02:08:47
- **Comment**: 10 pages, 5 tables, 2 figures; presented at IEEE CogMI 2025
- **Topic Keywords**: query, rag, retrieval
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The focus on Retrieval-Augmented Generation (RAG) and its application to Question-Answering tasks aligns with your interests in deep semantic understanding and real-time relevance optimization. However, the specific domain of Question-Answering is somewhat different from your e-commerce background, which slightly reduces the score.

#### Abstract
> Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.

---

### 3. Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph

- **LLM Score**: 8
- **Keyword Score**: 6
- **Authors**: Ebubekir Tosun, Mehmet Emin Buldur, √ñzay Ezerceli, Mahmoud ElHussieni
- **URL**: <http://arxiv.org/abs/2601.13251v1>
- **Submitted**: 2026-01-19 17:37:25
- **Topic Keywords**: semantic search, retrieval, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of query understanding and ranking models, as it tackles the problem of semantic drift and antonym intrusion in a large-scale semantic clustering system. The proposed approach employs a novel soft-to-hard clustering algorithm and a three-way semantic relation discriminator, which are both relevant to your interests in deep semantic understanding and real-time relevance optimization. However, the focus on a specific language (Turkish) and the use of a large-scale lexical item dataset may limit its generalizability to other domains.

#### Abstract
> Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.

---

### 4. Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning

- **LLM Score**: 8
- **Keyword Score**: 6
- **Authors**: Fengran Mo, Yifan Gao, Sha Li, Hansi Zeng, Xin Liu, Zhaoxuan Tan, Xian Li, Jianshu Chen, Dakuo Wang, Meng Jiang
- **URL**: <http://arxiv.org/abs/2601.13115v1>
- **Submitted**: 2026-01-19 14:55:54
- **Topic Keywords**: query, retrieval, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of conversational search and query understanding. The use of reinforcement learning for contextualized reasoning and dynamic coordination between retrieval and generation aligns with your focus on real-time relevance optimization and deep semantic understanding. However, the paper's primary focus on conversational search and dialogue systems is somewhat outside your core e-commerce domain expertise.

#### Abstract
> Large Language Models (LLMs) have become a popular interface for human-AI interaction, supporting information seeking and task assistance through natural, multi-turn dialogue. To respond to users within multi-turn dialogues, the context-dependent user intent evolves across interactions, requiring contextual interpretation, query reformulation, and dynamic coordination between retrieval and generation. Existing studies usually follow static rewrite, retrieve, and generate pipelines, which optimize different procedures separately and overlook the mixed-initiative action optimization simultaneously. Although the recent developments in deep search agents demonstrate the effectiveness in jointly optimizing retrieval and generation via reasoning, these approaches focus on single-turn scenarios, which might lack the ability to handle multi-turn interactions. We introduce a conversational agent that interleaves search and reasoning across turns, enabling exploratory and adaptive behaviors learned through reinforcement learning (RL) training with tailored rewards towards evolving user goals. The experimental results across four widely used conversational benchmarks demonstrate the effectiveness of our methods by surpassing several existing strong baselines.

---

### 5. HyFormer: Revisiting the Roles of Sequence Modeling and Feature Interaction in CTR Prediction

- **LLM Score**: 7
- **Keyword Score**: 9
- **Authors**: Yunwen Huang, Shiyong Hong, Xijun Xiao, Jinqiu Jin, Xuanyuan Luo, Zhe Wang, Zheng Chai, Shikang Wu, Yuchao Zheng, Jingjian Lin
- **URL**: <http://arxiv.org/abs/2601.12681v1>
- **Submitted**: 2026-01-19 02:55:05
- **Topic Keywords**: query, user behavior, ctr, recommend, rank
- **Reason**: This paper presents a novel architecture, HyFormer, for CTR prediction in large-scale recommendation models. While it primarily focuses on recommender systems, it involves sequence modeling and feature interaction, which are relevant to information retrieval and search technologies. However, the specific application domain and task differ from the user's core research themes.

#### Abstract
> Industrial large-scale recommendation models (LRMs) face the challenge of jointly modeling long-range user behavior sequences and heterogeneous non-sequential features under strict efficiency constraints. However, most existing architectures employ a decoupled pipeline: long sequences are first compressed with a query-token based sequence compressor like LONGER, followed by fusion with dense features through token-mixing modules like RankMixer, which thereby limits both the representation capacity and the interaction flexibility. This paper presents HyFormer, a unified hybrid transformer architecture that tightly integrates long-sequence modeling and feature interaction into a single backbone. From the perspective of sequence modeling, we revisit and redesign query tokens in LRMs, and frame the LRM modeling task as an alternating optimization process that integrates two core components: Query Decoding which expands non-sequential features into Global Tokens and performs long sequence decoding over layer-wise key-value representations of long behavioral sequences; and Query Boosting which enhances cross-query and cross-sequence heterogeneous interactions via efficient token mixing. The two complementary mechanisms are performed iteratively to refine semantic representations across layers. Extensive experiments on billion-scale industrial datasets demonstrate that HyFormer consistently outperforms strong LONGER and RankMixer baselines under comparable parameter and FLOPs budgets, while exhibiting superior scaling behavior with increasing parameters and FLOPs. Large-scale online A/B tests in high-traffic production systems further validate its effectiveness, showing significant gains over deployed state-of-the-art models. These results highlight the practicality and scalability of HyFormer as a unified modeling framework for industrial LRMs.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. SciHorizon-GENE: Benchmarking LLM for Life Sciences Inference from Gene Knowledge to Functional Understanding

- **LLM Score**: 7
- **Keyword Score**: 4
- **Authors**: Xiaohan Huang, Meng Xiao, Chuan Qin, Qingqing Long, Jinmiao Chen, Yuanchun Zhou, Hengshu Zhu
- **URL**: <http://arxiv.org/abs/2601.12805v1>
- **Submitted**: 2026-01-19 08:06:35
- **Comment**: 16 pages
- **Topic Keywords**: relevance, search
- **Reason**: This paper explores the application of Large Language Models (LLMs) in the life sciences domain, specifically for gene-level knowledge to functional understanding. While it is not directly related to Information Retrieval or Search technologies, it touches on the topic of query understanding and ranking models through the lens of LLMs. The paper's focus on evaluating LLMs for their ability to reason and provide accurate functional interpretations aligns with the user's interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> Large language models (LLMs) have shown growing promise in biomedical research, particularly for knowledge-driven interpretation tasks. However, their ability to reliably reason from gene-level knowledge to functional understanding, However, their ability to reliably reason from gene-level knowledge to functional understanding, a core requirement for knowledge-enhanced cell atlas interpretation, remains largely underexplored. To address this gap, we introduce SciHorizon-GENE, a large-scale gene-centric benchmark constructed from authoritative biological databases. The benchmark integrates curated knowledge for over 190K human genes and comprises more than 540K questions covering diverse gene-to-function reasoning scenarios relevant to cell type annotation, functional interpretation, and mechanism-oriented analysis. Motivated by behavioral patterns observed in preliminary examinations, SciHorizon-GENE evaluates LLMs along four biologically critical perspectives: research attention sensitivity, hallucination tendency, answer completeness, and literature influence, explicitly targeting failure modes that limit the safe adoption of LLMs in biological interpretation pipelines. We systematically evaluate a wide range of state-of-the-art general-purpose and biomedical LLMs, revealing substantial heterogeneity in gene-level reasoning capabilities and persistent challenges in generating faithful, complete, and literature-grounded functional interpretations. Our benchmark establishes a systematic foundation for analyzing LLM behavior at the gene scale and offers insights for model selection and development, with direct relevance to knowledge-enhanced biological interpretation.

### 7. Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios

- **LLM Score**: 6
- **Keyword Score**: 7
- **Authors**: Hongyang Ma, Tiantian Gu, Huaiyuan Sun, Huilin Zhu, Yongxin Wang, Jie Li, Wubin Sun, Zeliang Lian, Yinghong Zhou, Yi Gao, Shirui Wang, Zhihui Tang
- **URL**: <http://arxiv.org/abs/2601.12974v1>
- **Submitted**: 2026-01-19 11:36:39
- **Comment**: 29 pages, 15 figures
- **Topic Keywords**: retriever, rag, retrieval
- **Reason**: The paper explores the application of Large Language Models (LLMs) in dynamic dental clinical scenarios, which involves query understanding and ranking models. However, the focus is more on the evaluation of LLMs in clinical settings rather than the core IR and NLP topics you're interested in. The paper does touch on retrieval-augmented generation, which is somewhat related to your interests, but it's not the primary focus.

#### Abstract
> The transition of Large Language Models (LLMs) from passive knowledge retrievers to autonomous clinical agents demands a shift in evaluation-from static accuracy to dynamic behavioral reliability. To explore this boundary in dentistry, a domain where high-quality AI advice uniquely empowers patient-participatory decision-making, we present the Standardized Clinical Management & Performance Evaluation (SCMPE) benchmark, which comprehensively assesses performance from knowledge-oriented evaluations (static objective tasks) to workflow-based simulations (multi-turn simulated patient interactions). Our analysis reveals that while models demonstrate high proficiency in static objective tasks, their performance precipitates in dynamic clinical dialogues, identifying that the primary bottleneck lies not in knowledge retention, but in the critical challenges of active information gathering and dynamic state tracking. Mapping "Guideline Adherence" versus "Decision Quality" reveals a prevalent "High Efficacy, Low Safety" risk in general models. Furthermore, we quantify the impact of Retrieval-Augmented Generation (RAG). While RAG mitigates hallucinations in static tasks, its efficacy in dynamic workflows is limited and heterogeneous, sometimes causing degradation. This underscores that external knowledge alone cannot bridge the reasoning gap without domain-adaptive pre-training. This study empirically charts the capability boundaries of dental LLMs, providing a roadmap for bridging the gap between standardized knowledge and safe, autonomous clinical practice.

### 8. From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation

- **LLM Score**: 6
- **Keyword Score**: 4
- **Authors**: Jiahao Wang, Weiyu Xie, Mingxing Zhang, Boxing Zhang, Jianwei Dong, Yuening Zhu, Chen Lin, Jinqi Tang, Yaochen Han, Zhiyuan Ai, Xianglin Chen, Yongwei Wu, Congfeng Jiang
- **URL**: <http://arxiv.org/abs/2601.12904v1>
- **Submitted**: 2026-01-19 09:59:39
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of query understanding and ranking models. However, the focus on Large Language Models and Retrieval-Augmented Generation is not a central match to your primary interests in e-commerce and deep semantic understanding. The paper's relevance to your interests in NLP and data mining is also limited.

#### Abstract
> Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.

### 9. Medical Triage as Pairwise Ranking: A Benchmark for Urgency in Patient Portal Messages

- **LLM Score**: 4
- **Keyword Score**: 11
- **Authors**: Joseph Gatto, Parker Seegmiller, Timothy Burdick, Philip Resnik, Roshnik Rahat, Sarah DeLozier, Sarah M. Preum
- **URL**: <http://arxiv.org/abs/2601.13178v1>
- **Submitted**: 2026-01-19 16:05:31
- **Comment**: 19 Pages, 5 Figures
- **Topic Keywords**: ranking, pairwise, rag, ctr, rank
- **Reason**: This paper introduces a novel task formulation for medical triage using pairwise ranking, which is somewhat related to the user's interest in ranking models. However, the focus on medical triage and patient portal messages is not directly aligned with the user's core research themes in information retrieval and search technologies. The use of LLMs and data annotation strategies is relevant to the user's interest in NLP, but the application is specific to the medical domain.

#### Abstract
> Medical triage is the task of allocating medical resources and prioritizing patients based on medical need. This paper introduces the first large-scale public dataset for studying medical triage in the context of asynchronous outpatient portal messages. Our novel task formulation views patient message triage as a pairwise inference problem, where we train LLMs to choose `"which message is more medically urgent" in a head-to-head tournament-style re-sort of a physician's inbox. Our novel benchmark PMR-Bench contains 1569 unique messages and 2,000+ high-quality test pairs for pairwise medical urgency assessment alongside a scalable training data generation pipeline. PMR-Bench includes samples that contain both unstructured patient-written messages alongside real electronic health record (EHR) data, emulating a real-world medical triage scenario.
  We develop a novel automated data annotation strategy to provide LLMs with in-domain guidance on this task. The resulting data is used to train two model classes, UrgentReward and UrgentSFT, leveraging Bradley-Terry and next token prediction objective, respectively to perform pairwise urgency classification. We find that UrgentSFT achieves top performance on PMR-Bench, with UrgentReward showing distinct advantages in low-resource settings. For example, UrgentSFT-8B and UrgentReward-8B provide a 15- and 16-point boost, respectively, on inbox sorting metrics over off-the-shelf 8B models. Paper resources can be found at https://tinyurl.com/Patient-Message-Triage

### 10. CORE-T: COherent REtrieval of Tables for Text-to-SQL

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Hassan Soliman, Vivek Gupta, Dan Roth, Iryna Gurevych
- **URL**: <http://arxiv.org/abs/2601.13111v1>
- **Submitted**: 2026-01-19 14:51:23
- **Comment**: Preprint under review. Code and data available at: https://github.com/UKPLab/arxiv2026-core-t
- **Topic Keywords**: dense retrieval, queries, retrieval
- **Reason**: The paper focuses on table retrieval for text-to-SQL tasks, which is somewhat related to information retrieval and query understanding. However, the specific application domain and task are not directly aligned with the user's core research themes, which are primarily focused on search technologies and user behavior modeling in e-commerce and other domains.

#### Abstract
> Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.

### 11. Incorporating Q&A Nuggets into Retrieval-Augmented Generation

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Laura Dietz, Bryan Li, Gabrielle Liu, Jia-Huei Ju, Eugene Yang, Dawn Lawrie, William Walden, James Mayfield
- **URL**: <http://arxiv.org/abs/2601.13222v1>
- **Submitted**: 2026-01-19 16:57:33
- **Topic Keywords**: rag, retrieval, trec
- **Reason**: This paper is somewhat related to the user's interests in Information Retrieval, specifically in the context of Retrieval-Augmented Generation. However, the focus on Q&A nuggets and citation provenance is not directly aligned with the user's core research themes in query understanding, ranking models, and user behavior modeling. While it touches on aspects of search technologies, it is not a central match for the user's research interests.

#### Abstract
> RAGE systems integrate ideas from automatic evaluation (E) into Retrieval-augmented Generation (RAG). As one such example, we present Crucible, a Nugget-Augmented Generation System that preserves explicit citation provenance by constructing a bank of Q&A nuggets from retrieved documents and uses them to guide extraction, selection, and report generation. Reasoning on nuggets avoids repeated information through clear and interpretable Q&A semantics - instead of opaque cluster abstractions - while maintaining citation provenance throughout the entire generation process. Evaluated on the TREC NeuCLIR 2024 collection, our Crucible system substantially outperforms Ginger, a recent nugget-based RAG system, in nugget recall, density, and citation grounding.

### 12. A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Miao Xie, Siguang Chen, Chunli Lv
- **URL**: <http://arxiv.org/abs/2601.12945v1>
- **Submitted**: 2026-01-19 10:53:57
- **Comment**: 27 pages, 6 table
- **Topic Keywords**: rag, retrieval, personalization, search
- **Reason**: This paper explores the intersection of Large Language Models and Multi-Armed Bandits, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the focus on language models and decision-making under uncertainty is not directly aligned with your core research themes, such as query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large language models (LLMs) have become powerful and widely used systems for language understanding and generation, while multi-armed bandit (MAB) algorithms provide a principled framework for adaptive decision-making under uncertainty. This survey explores the potential at the intersection of these two fields. As we know, it is the first survey to systematically review the bidirectional interaction between large language models and multi-armed bandits at the component level. We highlight the bidirectional benefits: MAB algorithms address critical LLM challenges, spanning from pre-training to retrieval-augmented generation (RAG) and personalization. Conversely, LLMs enhance MAB systems by redefining core components such as arm definition and environment modeling, thereby improving decision-making in sequential tasks. We analyze existing LLM-enhanced bandit systems and bandit-enhanced LLM systems, providing insights into their design, methodologies, and performance. Key challenges and representative findings are identified to help guide future research. An accompanying GitHub repository that indexes relevant literature is available at https://github.com/bucky1119/Awesome-LLM-Bandit-Interaction.

### 13. Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Yihong Liu, Bingyu Xiong, Hinrich Sch√ºtze
- **URL**: <http://arxiv.org/abs/2601.12555v1>
- **Submitted**: 2026-01-18 19:38:55
- **Comment**: preprint
- **Topic Keywords**: queries, retrieval
- **Reason**: The paper explores factual recall in multilingual large language models, focusing on context-dependent language understanding. While it touches on aspects of query understanding and model performance, it doesn't directly address ranking models or user behavior modeling, which are core areas of interest. The paper's relevance to information retrieval is somewhat tangential, but its connection to natural language processing and deep semantic understanding is notable.

#### Abstract
> Large language models (LLMs) can recall a wide range of factual knowledge across languages. However, existing factual recall evaluations primarily assess fact retrieval in isolation, where the queried entity is explicitly named and the fact is requested directly. In natural language use, facts are often accessed through context, where the relevant entity is introduced only indirectly. In this work, we study contextually mediated factual recall, asking whether LLMs can reliably retrieve factual knowledge when the target entity is embedded in a naturalistic context rather than queried explicitly, across languages. We construct controlled prompts that preserve the underlying fact while introducing referential mediation through contextual sentences. To disentangle contextual effects from name-specific associations, we further compare performance using synthetic names and real names across languages. Evaluating multiple model families in five languages, we find that contextual mediation consistently degrades factual recall, with substantial variation across relations. Larger models are more robust to contextual mediation, exhibiting a reduced performance gap relative to direct queries, while the effect of real names and name origin is mixed and unsystematic. These findings highlight a gap between isolated factual recall and context-dependent language understanding in multilingual LLMs.

### 14. Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Liu Kaipeng, Wu Ling
- **URL**: <http://arxiv.org/abs/2601.13105v1>
- **Submitted**: 2026-01-19 14:43:11
- **Comment**: 19pages, 1figure
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper explores the use of LoRA fine-tuning and knowledge bases for construction identification, which is related to query understanding and deep semantic understanding in Information Retrieval. However, the focus on language model fine-tuning and construction identification is not directly aligned with the user's primary research themes in IR and Search technologies. The connection to NLP is relevant, but the paper's specific application is not a central match for the user's interests.

#### Abstract
> This study investigates the automatic identification of the English ditransitive construction by integrating LoRA-based fine-tuning of a large language model with a Retrieval-Augmented Generation (RAG) framework.A binary classification task was conducted on annotated data from the British National Corpus. Results demonstrate that a LoRA-fine-tuned Qwen3-8B model significantly outperformed both a native Qwen3-MAX model and a theory-only RAG system. Detailed error analysis reveals that fine-tuning shifts the model's judgment from a surface-form pattern matching towards a more semantically grounded understanding based.

### 15. Benchmarking Concept-Spilling Across Languages in LLMs

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Ilia Badanin, Daniil Dzenhaliou, Imanol Schlag
- **URL**: <http://arxiv.org/abs/2601.12549v1>
- **Submitted**: 2026-01-18 19:28:26
- **Topic Keywords**: ranking, rank
- **Reason**: This paper explores the concept of language spilling in multilingual Large Language Models (LLMs), which is somewhat related to query understanding and deep semantic understanding in Information Retrieval. However, the focus on language models and semantic robustness is not directly aligned with the user's primary research interests in IR, ranking models, and user behavior modeling.

#### Abstract
> Multilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often exhibit a systematic bias toward the representations from other languages, resulting in semantic interference when generating content in non-English languages$-$a phenomenon we define as language spilling. This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. Our methodology provides a relative measure of model performance: when required to generate exactly five meanings, both strong and weak models may resort to meanings from dominant languages, but semantically stronger models do so later in the generation sequence, producing more true meanings from the target language before failing, while weaker models resort to dominant-language meanings earlier in the sequence. We evaluate a diverse set of open and closed multilingual LLMs using a structured meaning generation task across nine languages, employing a carefully curated benchmark of 100 high-polysemy English words. Our findings reveal significant variation in semantic robustness across both models and languages, providing a principled ranking system for model comparison without requiring definitive causal attribution of error sources. We contribute both a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline$-$critical tools for developing more linguistically balanced AI systems.

### 16. KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Xue Jiang, Jiaru Qian, Xianjie Shi, Chenjie Li, Hao Zhu, Ziyu Wang, Jielun Zhang, Zheyu Zhao, Kechi Zhang, Jia Li, Wenpin Jiao, Zhi Jin, Ge Li, Yihong Dong
- **URL**: <http://arxiv.org/abs/2601.13240v1>
- **Submitted**: 2026-01-19 17:20:16
- **Topic Keywords**: rag, search
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and related topics, as it involves large language models and domain knowledge. However, it is not directly related to your primary focus on Information Retrieval, especially in areas that require deep semantic understanding and real-time relevance optimization.

#### Abstract
> Large language models (LLMs) excel at general programming but struggle with domain-specific software development, necessitating domain specialization methods for LLMs to learn and utilize domain knowledge and data. However, existing domain-specific code benchmarks cannot evaluate the effectiveness of domain specialization methods, which focus on assessing what knowledge LLMs possess rather than how they acquire and apply new knowledge, lacking explicit knowledge corpora for developing domain specialization methods. To this end, we present KOCO-BENCH, a novel benchmark designed for evaluating domain specialization methods in real-world software development. KOCO-BENCH contains 6 emerging domains with 11 software frameworks and 25 projects, featuring curated knowledge corpora alongside multi-granularity evaluation tasks including domain code generation (from function-level to project-level with rigorous test suites) and domain knowledge understanding (via multiple-choice Q&A). Unlike previous benchmarks that only provide test sets for direct evaluation, KOCO-BENCH requires acquiring and applying diverse domain knowledge (APIs, rules, constraints, etc.) from knowledge corpora to solve evaluation tasks. Our evaluations reveal that KOCO-BENCH poses significant challenges to state-of-the-art LLMs. Even with domain specialization methods (e.g., SFT, RAG, kNN-LM) applied, improvements remain marginal. Best-performing coding agent, Claude Code, achieves only 34.2%, highlighting the urgent need for more effective domain specialization methods. We release KOCO-BENCH, evaluation code, and baselines to advance further research at https://github.com/jiangxxxue/KOCO-bench.

### 17. Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Laura Dietz, Bryan Li, Eugene Yang, Dawn Lawrie, William Walden, James Mayfield
- **URL**: <http://arxiv.org/abs/2601.13227v1>
- **Submitted**: 2026-01-19 17:03:20
- **Topic Keywords**: rag, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of evaluation and optimization of Retrieval-Augmented Generation (RAG) systems. However, the focus on Large Language Model (LLM) judges and evaluation metrics is not directly aligned with your primary interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is limited to the broader IR field.

#### Abstract
> RAG systems are increasingly evaluated and optimized using LLM judges, an approach that is rapidly becoming the dominant paradigm for system assessment. Nugget-based approaches in particular are now embedded not only in evaluation frameworks but also in the architectures of RAG systems themselves. While this integration can lead to genuine improvements, it also creates a risk of faulty measurements due to circularity. In this paper, we investigate this risk through comparative experiments with nugget-based RAG systems, including Ginger and Crucible, against strong baselines such as GPT-Researcher. By deliberately modifying Crucible to generate outputs optimized for an LLM judge, we show that near-perfect evaluation scores can be achieved when elements of the evaluation - such as prompt templates or gold nuggets - are leaked or can be predicted. Our results highlight the importance of blind evaluation settings and methodological diversity to guard against mistaking metric overfitting for genuine system progress.

### 18. TVWorld: Foundations for Remote-Control TV Agents

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Zhantao Ma, Quanfeng Lu, Shuai Zhong, Dahai Yu, Ping Luo, Michael K. Ng
- **URL**: <http://arxiv.org/abs/2601.13142v1>
- **Submitted**: 2026-01-19 15:24:32
- **Topic Keywords**: click, search
- **Reason**: The paper explores remote-control TV interaction, which is somewhat related to information retrieval and search technologies. However, the focus on device control and TV navigation is not directly aligned with the user's core research themes of query understanding, ranking models, and user behavior modeling. The connection to natural language processing is also limited, making it only loosely relevant to the user's interests.

#### Abstract
> Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce \textbf{TVWorld}, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: \textbf{TVWorld-N} for topology-aware navigation and \textbf{TVWorld-G} for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a \emph{Topology-Aware Training} framework that injects topology awareness into LVLMs. Using this framework, we develop \textbf{TVTheseus}, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of $68.3\%$ on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance. Additional analyses further provide valuable insights into the development of effective TV-use agents.

### 19. Information Farming: From Berry Picking to Berry Growing

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Leif Azzopardi, Adam Roegiest
- **URL**: <http://arxiv.org/abs/2601.12544v1>
- **Submitted**: 2026-01-18 19:16:15
- **Comment**: ACM CHIIR 2026
- **Topic Keywords**: rag, search
- **Reason**: This paper discusses a new conceptual framework called Information Farming, which explores how people interact with information in the era of Generative AI. While it touches on search and information retrieval, its focus is more on the user behavior and the shift in how people engage with information, which is somewhat related to your interests in query understanding and user behavior modeling. However, the paper's emphasis on the broader implications of GenAI and the historical analogy used to explain the concept makes it less directly relevant to your core research themes.

#### Abstract
> The classic paradigms of Berry Picking and Information Foraging Theory have framed users as gatherers, opportunistically searching across distributed sources to satisfy evolving information needs. However, the rise of GenAI is driving a fundamental transformation in how people produce, structure, and reuse information - one that these paradigms no longer fully capture. This transformation is analogous to the Neolithic Revolution, when societies shifted from hunting and gathering to cultivation. Generative technologies empower users to "farm" information by planting seeds in the form of prompts, cultivating workflows over time, and harvesting richly structured, relevant yields within their own plots, rather than foraging across others people's patches. In this perspectives paper, we introduce the notion of Information Farming as a conceptual framework and argue that it represents a natural evolution in how people engage with information. Drawing on historical analogy and empirical evidence, we examine the benefits and opportunities of information farming, its implications for design and evaluation, and the accompanying risks posed by this transition. We hypothesize that as GenAI technologies proliferate, cultivating information will increasingly supplant transient, patch-based foraging as a dominant mode of engagement, marking a broader shift in human-information interaction and its study.

### 20. MemeLens: Multilingual Multitask VLMs for Memes

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Ali Ezzat Shahroor, Mohamed Bayan Kmainasi, Abul Hasnat, Dimitar Dimitrov, Giovanni Da San Martino, Preslav Nakov, Firoj Alam
- **URL**: <http://arxiv.org/abs/2601.12539v1>
- **Submitted**: 2026-01-18 19:01:03
- **Comment**: disinformation, misinformation, factuality, harmfulness, fake news, propaganda, hateful meme, multimodality, text, images
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on meme understanding using a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM). While it involves multimodal training and NLP, it is not directly related to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Memes are a dominant medium for online communication and manipulation because meaning emerges from interactions between embedded text, imagery, and cultural context. Existing meme research is distributed across tasks (hate, misogyny, propaganda, sentiment, humour) and languages, which limits cross-domain generalization. To address this gap we propose MemeLens, a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM) for meme understanding. We consolidate 38 public meme datasets, filter and map dataset-specific labels into a shared taxonomy of $20$ tasks spanning harm, targets, figurative/pragmatic intent, and affect. We present a comprehensive empirical analysis across modeling paradigms, task categories, and datasets. Our findings suggest that robust meme understanding requires multimodal training, exhibits substantial variation across semantic categories, and remains sensitive to over-specialization when models are fine-tuned on individual datasets rather than trained in a unified setting. We will make the experimental resources and datasets publicly available for the community.

### 21. OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Yow-Fu Liou, Yu-Chien Tang, Yu-Hsiang Liu, An-Zi Yen
- **URL**: <http://arxiv.org/abs/2601.13300v1>
- **Submitted**: 2026-01-19 18:56:08
- **Topic Keywords**: rag
- **Reason**: This paper introduces a benchmarking approach for evaluating large language models' susceptibility to directive interference, which is somewhat related to query understanding and ranking models in the context of search technologies. However, the focus on language models and their robustness to interference is not directly aligned with the user's core research themes in Information Retrieval and Search technologies. The paper's relevance to the user's interests in NLP and data mining is also limited.

#### Abstract
> Benchmarking large language models (LLMs) is critical for understanding their capabilities, limitations, and robustness. In addition to interface artifacts, prior studies have shown that LLM decisions can be influenced by directive signals such as social cues, framing, and instructions. In this work, we introduce option injection, a benchmarking approach that augments the multiple-choice question answering (MCQA) interface with an additional option containing a misleading directive, leveraging standardized choice structure and scalable evaluation. We construct OI-Bench, a benchmark of 3,000 questions spanning knowledge, reasoning, and commonsense tasks, with 16 directive types covering social compliance, bonus framing, threat framing, and instructional interference. This setting combines manipulation of the choice interface with directive-based interference, enabling systematic assessment of model susceptibility. We evaluate 12 LLMs to analyze attack success rates, behavioral responses, and further investigate mitigation strategies ranging from inference-time prompting to post-training alignment. Experimental results reveal substantial vulnerabilities and heterogeneous robustness across models. OI-Bench is expected to support more systematic evaluation of LLM robustness to directive interference within choice-based interfaces.

### 22. Gated Differentiable Working Memory for Long-Context Language Modeling

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Lingrui Mei, Shenghua Liu, Yiwei Wang, Yuyao Ge, Baolong Bi, Jiayu Yao, Jun Wan, Ziling Yin, Jiafeng Guo, Xueqi Cheng
- **URL**: <http://arxiv.org/abs/2601.12906v1>
- **Submitted**: 2026-01-19 10:00:33
- **Topic Keywords**: rag
- **Reason**: The paper focuses on improving long-context language modeling using a working memory framework, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on language modeling and working memory does not directly align with the user's core research themes in IR and Search technologies. The use of differentiable working memory and contextual utility measures may be of interest in NLP, but the connection to the user's research interests is not strong.

#### Abstract
> Long contexts challenge transformers: attention scores dilute across thousands of tokens, critical information is often lost in the middle, and models struggle to adapt to novel patterns at inference time. Recent work on test-time adaptation addresses this by maintaining a form of working memory -- transient parameters updated on the current context -- but existing approaches rely on uniform write policies that waste computation on low-utility regions and suffer from high gradient variance across semantically heterogeneous contexts. In this work, we reframe test-time adaptation as a budget-constrained memory consolidation problem, focusing on which parts of the context should be consolidated into working memory under limited computation. We propose Gdwm (Gated Differentiable Working Memory), a framework that introduces a write controller to gate the consolidation process. The controller estimates Contextual Utility, an information-theoretic measure of long-range contextual dependence, and allocates gradient steps accordingly while maintaining global coverage. Experiments on ZeroSCROLLS and LongBench v2 demonstrate that Gdwm achieves comparable or superior performance with 4$\times$ fewer gradient steps than uniform baselines, establishing a new efficiency-performance Pareto frontier for test-time adaptation.

### 23. Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Sushant Kumar Ray, Gautam Siddharth Kashyap, Sahil Tripathi, Nipun Joshi, Vijay Govindarajan, Rafiq Ali, Jiechao Gao, Usman Naseem
- **URL**: <http://arxiv.org/abs/2601.12812v1>
- **Submitted**: 2026-01-19 08:17:55
- **Comment**: Accepted at EACL 2026 (Industry Track)
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, particularly in the context of query understanding and real-time relevance optimization. However, the focus on Clinical Question-Answering Systems and medical fine-tuning is not directly aligned with your primary interests in e-commerce and deep semantic understanding. The paper's emphasis on Large Language Models and fine-tuning is relevant, but the specific domain of medicine is not a central match for your research.

#### Abstract
> Clinical Question-Answering (CQA) industry systems are increasingly rely on Large Language Models (LLMs), yet their deployment is often guided by the assumption that domain-specific fine-tuning is essential. Although specialised medical LLMs such as BioBERT, BioGPT, and PubMedBERT remain popular, they face practical limitations including narrow coverage, high retraining costs, and limited adaptability. Efforts based on Supervised Fine-Tuning (SFT) have attempted to address these assumptions but continue to reinforce what we term the SPECIALISATION FALLACY-the belief that specialised medical LLMs are inherently superior for CQA. To address this assumption, we introduce MEDASSESS-X, a deployment-industry-oriented CQA framework that applies alignment at inference time rather than through SFT. MEDASSESS-X uses lightweight steering vectors to guide model activations toward medically consistent reasoning without updating model weights or requiring domain-specific retraining. This inference-time alignment layer stabilises CQA performance across both general-purpose and specialised medical LLMs, thereby resolving the SPECIALISATION FALLACY. Empirically, MEDASSESS-X delivers consistent gains across all LLM families, improving Accuracy by up to +6%, Factual Consistency by +7%, and reducing Safety Error Rate by as much as 50%.

### 24. Who Does This Name Remind You of? Nationality Prediction via Large Language Model Associative Memory

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Keito Inoshita
- **URL**: <http://arxiv.org/abs/2601.12771v1>
- **Submitted**: 2026-01-19 06:59:53
- **Topic Keywords**: rag
- **Reason**: The paper explores the use of large language models for nationality prediction, leveraging their world knowledge through associative memory. While it touches on query understanding and knowledge retrieval, it is more focused on NLP and knowledge aggregation, which is somewhat related to your research interests in IR and NLP, but not a central match.

#### Abstract
> Large language models (LLMs) possess extensive world knowledge, yet methods for effectively eliciting this knowledge remain underexplored. Nationality and region prediction tasks require understanding of not only linguistic features but also cultural and historical background, making LLM world knowledge particularly valuable. However, conventional LLM prompting methods rely on direct reasoning approaches, which have limitations in applying abstract linguistic rules. We propose LLM Associative Memory Agents (LAMA), a novel framework that leverages LLM world knowledge as associative memory. Rather than directly inferring nationality from names, LAMA recalls famous individuals with the same name and aggregates their nationalities through indirect reasoning. A dual-agent architecture comprising a Person Agent and a Media Agent, specialized in different knowledge domains, recalls famous individuals in parallel, generating Top-1 predictions through voting and Top-K predictions through conditional completion. On a 99-country nationality prediction task, LAMA achieved 0.817 accuracy, substantially outperforming conventional LLM prompting methods and neural models. Our experiments reveal that LLMs exhibit higher reliability in recalling concrete examples than in abstract reasoning, that recall-based approaches are robust to low-frequency nationalities independent of data frequency distributions, and that the dual-agent architecture functions complementarily to produce synergistic effects. These results demonstrate the effectiveness of a new multi-agent system that retrieves and aggregates LLM knowledge rather than prompting reasoning.

### 25. Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Zimeng Wu, Donghao Wang, Chaozhe Jin, Jiaxin Chen, Yunhong Wang
- **URL**: <http://arxiv.org/abs/2601.13155v1>
- **Submitted**: 2026-01-19 15:34:29
- **Topic Keywords**: rank
- **Reason**: This paper focuses on efficient inference for Large Language Models (LLMs), proposing a self-predictive token skipping framework. While it touches on aspects of model performance and optimization, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user. The paper's relevance to information retrieval and search technologies is indirect, but it may be of interest to researchers exploring the intersection of NLP and IR.

#### Abstract
> Long-context inference enhances the reasoning capability of Large Language Models (LLMs) while incurring significant computational overhead. Token-oriented methods, such as pruning and skipping, have shown promise in reducing inference latency, but still suffer from inherently limited acceleration potential, outdated proxy signals, and redundancy interference, thus yielding suboptimal speed-accuracy trade-offs. To address these challenges, we propose SPTS (Self-Predictive Token Skipping), a training-free framework for efficient long-context LLM inference. Specifically, motivated by the thought of probing the influence of targeted skipping layers, we design two component-specific strategies for selective token skipping: Partial Attention Probing (PAP) for multi-head attention, which selects informative tokens by performing partial forward attention computation, and Low-rank Transformation Probing (LTP) for feed forward network, which constructs a low-rank proxy network to predict token transformations. Furthermore, a Multi-Stage Delayed Pruning (MSDP) strategy reallocates the skipping budget and progressively prunes redundant tokens across layers. Extensive experiments demonstrate the effectiveness of our method, achieving up to 2.46$\times$ and 2.29$\times$ speedups for prefilling and end-to-end generation, respectively, while maintaining state-of-the-art model performance. The source code will be publicly available upon paper acceptance.

### 26. The Unfairness of Multifactorial Bias in Recommendation

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Masoud Mansoury, Jin Huang, Mykola Pechenizkiy, Herke van Hoof, Maarten de Rijke
- **URL**: <http://arxiv.org/abs/2601.12828v1>
- **Submitted**: 2026-01-19 08:37:43
- **Topic Keywords**: recommend
- **Reason**: The paper explores multifactorial bias in recommender systems, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the focus on recommender systems and fairness is not a central match with your primary focus on query understanding, ranking models, and user behavior modeling. The connection to NLP and data mining is also limited.

#### Abstract
> Popularity bias and positivity bias are two prominent sources of bias in recommender systems. Both arise from input data, propagate through recommendation models, and lead to unfair or suboptimal outcomes. Popularity bias occurs when a small subset of items receives most interactions, while positivity bias stems from the over-representation of high rating values. Although each bias has been studied independently, their combined effect, to which we refer to as multifactorial bias, remains underexplored. In this work, we examine how multifactorial bias influences item-side fairness, focusing on exposure bias, which reflects the unequal visibility of items in recommendation outputs. Through simulation studies, we find that positivity bias is disproportionately concentrated on popular items, further amplifying their over-exposure. Motivated by this insight, we adapt a percentile-based rating transformation as a pre-processing strategy to mitigate multifactorial bias. Experiments using six recommendation algorithms across four public datasets show that this approach improves exposure fairness with negligible accuracy loss. We also demonstrate that integrating this pre-processing step into post-processing fairness pipelines enhances their effectiveness and efficiency, enabling comparable or better fairness with reduced computational cost. These findings highlight the importance of addressing multifactorial bias and demonstrate the practical value of simple, data-driven pre-processing methods for improving fairness in recommender systems.

### 27. Injecting Knowledge from Social Science Journals to Improve Indonesian Cultural Understanding by LLMs

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Adimulya Kartiyasa, Bao Gia Cao, Boyang Li
- **URL**: <http://arxiv.org/abs/2601.12921v1>
- **Submitted**: 2026-01-19 10:22:50
- **Topic Keywords**: queries, rag, retrieval
- **Reason**: This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves text retrieval and large language models, its focus on cultural understanding and social science journals is not aligned with the user's interests.

#### Abstract
> Recently there have been intensifying efforts to improve the understanding of Indonesian cultures by large language models (LLMs). An attractive source of cultural knowledge that has been largely overlooked is local journals of social science, which likely contain substantial cultural studies from a native perspective. We present a novel text dataset of journal article passages, created from 151 open-source Indonesian social science journals, called IndoSoSci. We demonstrate an effective recipe for injecting Indonesian cultural knowledge therein into LLMs: extracting the facts related to Indonesian culture, and apply retrieval-augmented generation (RAG) with LLM-generated hypothetical documents as queries during retrieval. The proposed recipe yields strong performance gains over several strong baselines on the IndoCulture benchmark. Additionally, by combining IndoSoSci with Indonesian Wikipedia, we set a new state-of-the-art accuracy on the IndoCulture benchmark.

### 28. UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Tassallah Abdullahi, Macton Mgonzo, Mardiyyah Oduwole, Paul Okewunmi, Abraham Owodunni, Ritambhara Singh, Carsten Eickhoff
- **URL**: <http://arxiv.org/abs/2601.12696v1>
- **Submitted**: 2026-01-19 03:37:56
- **Comment**: 12 pages
- **Topic Keywords**: queries, rag
- **Reason**: This paper focuses on AI safety and policy benchmarking for African languages, which is outside the primary scope of your research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on related topics like language and cultural understanding, the context and application are distinct from your core areas of focus.

#### Abstract
> Current guardian models are predominantly Western-centric and optimized for high-resource languages, leaving low-resource African languages vulnerable to evolving harms, cross-lingual safety failures, and cultural misalignment. Moreover, most guardian models rely on rigid, predefined safety categories that fail to generalize across diverse linguistic and sociocultural contexts. Robust safety, therefore, requires flexible, runtime-enforceable policies and benchmarks that reflect local norms, harm scenarios, and cultural expectations. We introduce UbuntuGuard, the first African policy-based safety benchmark built from adversarial queries authored by 155 domain experts across sensitive fields, including healthcare. From these expert-crafted queries, we derive context-specific safety policies and reference responses that capture culturally grounded risk signals, enabling policy-aligned evaluation of guardian models. We evaluate 13 models, comprising six general-purpose LLMs and seven guardian models across three distinct variants: static, dynamic, and multilingual. Our findings reveal that existing English-centric benchmarks overestimate real-world multilingual safety, cross-lingual transfer provides partial but insufficient coverage, and dynamic models, while better equipped to leverage policies at inference time, still struggle to fully localize African-language contexts. These findings highlight the urgent need for multilingual, culturally grounded safety benchmarks to enable the development of reliable and equitable guardian models for low-resource languages. Our code can be found online.\footnote{Code repository available at https://github.com/hemhemoh/UbuntuGuard.

### 29. RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Drishti Goel, Jeongah Lee, Qiuyue Joy Zhong, Violeta J. Rodriguez, Daniel S. Brown, Ravi Karkar, Dong Whi Yoo, Koustuv Saha
- **URL**: <http://arxiv.org/abs/2601.13235v1>
- **Submitted**: 2026-01-19 17:10:49
- **Topic Keywords**: queries, search
- **Reason**: This paper appears to be unrelated to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on risk mitigation in AI-mediated caregiving interactions, while interesting, does not align with your primary areas of focus.

#### Abstract
> Caregivers seeking AI-mediated support express complex needs -- information-seeking, emotional validation, and distress cues -- that warrant careful evaluation of response safety and appropriateness. Existing AI evaluation frameworks, primarily focused on general risks (toxicity, hallucinations, policy violations, etc), may not adequately capture the nuanced risks of LLM-responses in caregiving-contexts. We introduce RubRIX (Rubric-based Risk Index), a theory-driven, clinician-validated framework for evaluating risks in LLM caregiving responses. Grounded in the Elements of an Ethic of Care, RubRIX operationalizes five empirically-derived risk dimensions: Inattention, Bias & Stigma, Information Inaccuracy, Uncritical Affirmation, and Epistemic Arrogance. We evaluate six state-of-the-art LLMs on over 20,000 caregiver queries from Reddit and ALZConnected. Rubric-guided refinement consistently reduced risk-components by 45-98% after one iteration across models. This work contributes a methodological approach for developing domain-sensitive, user-centered evaluation frameworks for high-burden contexts. Our findings highlight the importance of domain-sensitive, interactional risk evaluation for the responsible deployment of LLMs in caregiving support contexts. We release benchmark datasets to enable future research on contextual risk evaluation in AI-mediated support.

### 30. RAGExplorer: A Visual Analytics System for the Comparative Diagnosis of RAG Systems

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Haoyu Tian, Yingchaojie Feng, Zhen Wen, Haoxuan Li, Minfeng Zhu, Wei Chen
- **URL**: <http://arxiv.org/abs/2601.12991v1>
- **Submitted**: 2026-01-19 12:09:56
- **Comment**: 11 pages, 7 figures. Accepted to IEEE TVCG (PacificVis 2026)
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper appears to be focused on visual analytics for Retrieval-Augmented Generation systems, which is a specific application of IR. However, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user. The paper's focus on a particular domain (RAG systems) and its emphasis on visual analytics also make it less relevant to the user's broader interests in NLP, data mining, and recommender systems.

#### Abstract
> The advent of Retrieval-Augmented Generation (RAG) has significantly enhanced the ability of Large Language Models (LLMs) to produce factually accurate and up-to-date responses. However, the performance of a RAG system is not determined by a single component but emerges from a complex interplay of modular choices, such as embedding models and retrieval algorithms. This creates a vast and often opaque configuration space, making it challenging for developers to understand performance trade-offs and identify optimal designs. To address this challenge, we present RAGExplorer, a visual analytics system for the systematic comparison and diagnosis of RAG configurations. RAGExplorer guides users through a seamless macro-to-micro analytical workflow. Initially, it empowers developers to survey the performance landscape across numerous configurations, allowing for a high-level understanding of which design choices are most effective. For a deeper analysis, the system enables users to drill down into individual failure cases, investigate how differences in retrieved information contribute to errors, and interactively test hypotheses by manipulating the provided context to observe the resulting impact on the generated answer. We demonstrate the effectiveness of RAGExplorer through detailed case studies and user studies, validating its ability to empower developers in navigating the complex RAG design space. Our code and user guide are publicly available at https://github.com/Thymezzz/RAGExplorer.

### 31. CooperBench: Why Coding Agents Cannot be Your Teammates Yet

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Arpandeep Khatua, Hao Zhu, Peter Tran, Arya Prabhudesai, Frederic Sadrieh, Johann K. Lieberwirth, Xinkai Yu, Yicheng Fu, Michael J. Ryan, Jiaxin Pei, Diyi Yang
- **URL**: <http://arxiv.org/abs/2601.13295v1>
- **Submitted**: 2026-01-19 18:48:37
- **Comment**: https://cooperbench.com
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on collaborative coding and the limitations of current AI agents in team coordination, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Resolving team conflicts requires not only task-specific competence, but also social intelligence to find common ground and build consensus. As AI agents increasingly collaborate on complex work, they must develop coordination capabilities to function as effective teammates. Yet we hypothesize that current agents lack these capabilities. To test this, we introduce CooperBench, a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. Tasks are grounded in real open-source repositories with expert-written tests. Evaluating state-of-the-art coding agents, we observe the curse of coordination: agents achieve on average 30% lower success rates when working together compared to performing both tasks individually. This contrasts sharply with human teams, where adding teammates typically improves productivity. Our analysis reveals three key issues: (1) communication channels become jammed with vague, ill-timed, and inaccurate messages; (2) even with effective communication, agents deviate from their commitments; and (3) agents often hold incorrect expectations about others' plans and communication. Through large-scale simulation, we also observe rare but interesting emergent coordination behavior including role division, resource division, and negotiation. Our research presents a novel benchmark for collaborative coding and calls for a shift from pursuing individual agent capability to developing social intelligence.

### 32. CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Eric Onyame, Akash Ghosh, Subhadip Baidya, Sriparna Saha, Xiuying Chen, Chirag Agarwal
- **URL**: <http://arxiv.org/abs/2601.13262v1>
- **Submitted**: 2026-01-19 17:51:00
- **Topic Keywords**: queries
- **Reason**: This paper focuses on multilingual medical reasoning using large language models, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the application domain is specific to healthcare and does not align with the user's broader interests in e-commerce and real-time relevance optimization.

#### Abstract
> While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/

### 33. Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yuan Gao, Zhigang Liu, Xinyu Yao, Bo Chen, Xiaobing Zhao
- **URL**: <http://arxiv.org/abs/2601.13137v1>
- **Submitted**: 2026-01-19 15:21:26
- **Comment**: 13 pages, 5 figures
- **Topic Keywords**: queries
- **Reason**: This paper focuses on large language models, bias, and value consistency in sensitive domains, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves NLP, the context and application are quite different from the user's areas of focus.

#### Abstract
> With the wide application of large language models (LLMs), the problems of bias and value inconsistency in sensitive domains have gradually emerged, especially in terms of race, society and politics. In this paper, we propose an adversarial alignment framework, which enhances the value consistency of the model in sensitive domains through continued pre-training, instruction fine-tuning and adversarial training. In adversarial training, we use the Attacker to generate controversial queries, the Actor to generate responses with value consistency, and the Critic to filter and ensure response quality. Furthermore, we train a Value-Consistent Large Language Model, VC-LLM, for sensitive domains, and construct a bilingual evaluation dataset in Chinese and English. The experimental results show that VC-LLM performs better than the existing mainstream models in both Chinese and English tests, verifying the effectiveness of the method. Warning: This paper contains examples of LLMs that are offensive or harmful in nature.

### 34. Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Mohammed Mudassir Uddin, Shahnawaz Alam, Mohammed Kaif Pasha
- **URL**: <http://arxiv.org/abs/2601.12879v1>
- **Submitted**: 2026-01-19 09:34:10
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on neural network interpretability and attribution graph decomposition, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on deep semantic understanding, the context is more aligned with model interpretability rather than real-time relevance optimization or query understanding.

#### Abstract
> Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation ($\pm$2.3\% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.

### 35. A Two-Stage GPU Kernel Tuner Combining Semantic Refactoring and Search-Based Optimization

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Qiuyi Qu, Yicheng Sui, Yufei Sun, Rui Chen, Xiaofei Zhang, Yuzhi Zhang, Haofeng Wang, Ge Lan, Ning Zhang
- **URL**: <http://arxiv.org/abs/2601.12698v1>
- **Submitted**: 2026-01-19 03:40:12
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on GPU kernel optimization, which is outside your primary research interests in Information Retrieval and Search technologies. While it involves search-based optimization, the context is specific to GPU kernel tuning and does not align with your core themes of query understanding, ranking models, or user behavior modeling.

#### Abstract
> GPU code optimization is a key performance bottleneck for HPC workloads as well as large-model training and inference. Although compiler optimizations and hand-written kernels can partially alleviate this issue, achieving near-hardware-limit performance still relies heavily on manual code refactoring and parameter tuning. Recent progress in LLM-agent-based kernel generation and optimization has been reported, yet many approaches primarily focus on direct code rewriting, where parameter choices are often implicit and hard to control, or require human intervention, leading to unstable performance gains. This paper introduces a template-based rewriting layer on top of an agent-driven iterative loop: kernels are semantically refactored into explicitly parameterizable templates, and template parameters are then optimized via search-based autotuning, yielding more stable and higher-quality speedups. Experiments on a set of real-world kernels demonstrate speedups exceeding 3x in the best case. We extract representative CUDA kernels from SGLang as evaluation targets; the proposed agentic tuner iteratively performs templating, testing, analysis, and planning, and leverages profiling feedback to execute constrained parameter search under hardware resource limits. Compared to agent-only direct rewriting, the template-plus-search design significantly reduces the randomness of iterative optimization, making the process more interpretable and enabling a more systematic approach toward high-performance configurations. The proposed method can be further extended to OpenCL, HIP, and other backends to deliver automated performance optimization for real production workloads.

### 36. A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ebubekir Tosun, Mehmet Emin Buldur, √ñzay Ezerceli, Mahmoud ElHussieni
- **URL**: <http://arxiv.org/abs/2601.13253v1>
- **Submitted**: 2026-01-19 17:38:52
- **Topic Keywords**: retrieval
- **Reason**: This paper is primarily focused on dataset generation for low-resource languages, which is not directly related to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific application and methodology are not aligned with your interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> We present a hybrid methodology for generating large-scale semantic relationship datasets in low-resource languages, demonstrated through a comprehensive Turkish semantic relations corpus. Our approach integrates three phases: (1) FastText embeddings with Agglomerative Clustering to identify semantic clusters, (2) Gemini 2.5-Flash for automated semantic relationship classification, and (3) integration with curated dictionary sources. The resulting dataset comprises 843,000 unique Turkish semantic pairs across three relationship types (synonyms, antonyms, co-hyponyms) representing a 10x scale increase over existing resources at minimal cost ($65). We validate the dataset through two downstream tasks: an embedding model achieving 90% top-1 retrieval accuracy and a classification model attaining 90% F1-macro. Our scalable protocol addresses critical data scarcity in Turkish NLP and demonstrates applicability to other low-resource languages. We publicly release the dataset and models.

### 37. Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Chongyuan Dai, Yaling Shen, Jinpeng Hu, Zihan Gao, Jia Li, Yishun Jiang, Yaxiong Wang, Liu Liu, Zongyuan Ge
- **URL**: <http://arxiv.org/abs/2601.13024v1>
- **Submitted**: 2026-01-19 13:04:26
- **Comment**: 24 pages, 10 figures, 9 Tables
- **Topic Keywords**: rag
- **Reason**: This paper appears to be primarily focused on evaluating the cultural alignment of Large Language Models (LLMs) using a novel benchmark, CEDAR. While it touches on the topic of affective understanding, which is related to user behavior modeling, its primary focus is on cultural alignment and affective processing, which is not directly aligned with your core research themes in Information Retrieval and Search technologies.

#### Abstract
> Culture serves as a fundamental determinant of human affective processing and profoundly shapes how individuals perceive and interpret emotional stimuli. Despite this intrinsic link extant evaluations regarding cultural alignment within Large Language Models primarily prioritize declarative knowledge such as geographical facts or established societal customs. These benchmarks remain insufficient to capture the subjective interpretative variance inherent to diverse sociocultural lenses. To address this limitation, we introduce CEDAR, a multimodal benchmark constructed entirely from scenarios capturing Culturally \underline{\textsc{E}}licited \underline{\textsc{D}}istinct \underline{\textsc{A}}ffective \underline{\textsc{R}}esponses. To construct CEDAR, we implement a novel pipeline that leverages LLM-generated provisional labels to isolate instances yielding cross-cultural emotional distinctions, and subsequently derives reliable ground-truth annotations through rigorous human evaluation. The resulting benchmark comprises 10,962 instances across seven languages and 14 fine-grained emotion categories, with each language including 400 multimodal and 1,166 text-only samples. Comprehensive evaluations of 17 representative multilingual models reveal a dissociation between language consistency and cultural alignment, demonstrating that culturally grounded affective understanding remains a significant challenge for current models.

### 38. Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Runxuan Liu, Xianhao Ou, Xinyan Ma, Jiyuan Wang, Jiafeng Liang, Jiaqi Li, Tao He, Zheng Chu, Rongchuan Mu, Zekun Wang, Baoxin Wang, Dayong Wu, Ming Liu, Shijin Wang, Guoping Hu, Bing Qin
- **URL**: <http://arxiv.org/abs/2601.12995v1>
- **Submitted**: 2026-01-19 12:23:00
- **Topic Keywords**: rag
- **Reason**: This paper focuses on enhancing the reasoning capabilities of Large Language Models using a Graph Reasoning Paradigm, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves NLP, the primary focus is on structured and symbolic reasoning, which is not a central match to the user's research interests.

#### Abstract
> Long Chain-of-Thought (LCoT), achieved by Reinforcement Learning with Verifiable Rewards (RLVR), has proven effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, reasoning in current LLMs is primarily generated as plain text, where performing semantic evaluation on such unstructured data creates a computational bottleneck during training. Despite RLVR-based optimization, existing methods still suffer from coarse-grained supervision, reward hacking, high training costs, and poor generalization. To address these issues, we propose the Graph Reasoning Paradigm (GRP), which realizes structured and symbolic reasoning, implemented via graph-structured representations with step-level cognitive labels. Building upon GRP, we further design Process-Aware Stratified Clipping Group Relative Policy Optimization (PASC-GRPO), which leverages structured evaluation to replace semantic evaluation, achieves process-aware verification through graph-structured outcome rewards, and mitigates reward hacking via stratified clipping advantage estimation. Experiments demonstrate significant improvements across mathematical reasoning and code generation tasks. Data, models, and code will be released later.

### 39. ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jesus-German Ortiz-Barajas, Jonathan Tonglet, Vivek Gupta, Iryna Gurevych
- **URL**: <http://arxiv.org/abs/2601.12983v1>
- **Submitted**: 2026-01-19 11:57:48
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves large language models, the focus is on chart generation and malicious prompting, which is not a central match to your research themes.

#### Abstract
> Multimodal large language models (MLLMs) are increasingly used to automate chart generation from data tables, enabling efficient data analysis and reporting but also introducing new misuse risks. In this work, we introduce ChartAttack, a novel framework for evaluating how MLLMs can be misused to generate misleading charts at scale. ChartAttack injects misleaders into chart designs, aiming to induce incorrect interpretations of the underlying data. Furthermore, we create AttackViz, a chart question-answering (QA) dataset where each (chart specification, QA) pair is labeled with effective misleaders and their induced incorrect answers. Experiments in in-domain and cross-domain settings show that ChartAttack significantly degrades the QA performance of MLLM readers, reducing accuracy by an average of 19.6 points and 14.9 points, respectively. A human study further shows an average 20.2 point drop in accuracy for participants exposed to misleading charts generated by ChartAttack. Our findings highlight an urgent need for robustness and security considerations in the design, evaluation, and deployment of MLLM-based chart generation systems. We make our code and data publicly available.

### 40. Trustworthy Data-driven Chronological Age Estimation from Panoramic Dental Images

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ainhoa Vivel-Couso, Nicol√°s Vila-Blanco, Mar√≠a J. Carreira, Alberto Bugar√≠n-Diz, Inmaculada Tom√°s, Jose M. Alonso-Moral
- **URL**: <http://arxiv.org/abs/2601.12960v1>
- **Submitted**: 2026-01-19 11:15:52
- **Comment**: This paper is a preliminary version of an accepted article in Information Systems Frontiers, Springer, Special Issue "Explainability in Human-Centric AI". Please cite the final published version of the paper, not this preprint. The final published version can be found at https://link.springer.com/article/10.1007/s10796-025-10682-3
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus is on dental age estimation from panoramic images and trustworthy AI assessment, which does not align with your core research themes.

#### Abstract
> Integrating deep learning into healthcare enables personalized care but raises trust issues due to model opacity. To improve transparency, we propose a system for dental age estimation from panoramic images that combines an opaque and a transparent method within a natural language generation (NLG) module. This module produces clinician-friendly textual explanations about the age estimations, designed with dental experts through a rule-based approach. Following the best practices in the field, the quality of the generated explanations was manually validated by dental experts using a questionnaire. The results showed a strong performance, since the experts rated 4.77+/-0.12 (out of 5) on average across the five dimensions considered. We also performed a trustworthy self-assessment procedure following the ALTAI checklist, in which it scored 4.40+/-0.27 (out of 5) across seven dimensions of the AI Trustworthiness Assessment List.

### 41. VISPA: Pluralistic Alignment via Automatic Value Selection and Activation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Shenyan Zheng, Jiayou Zhong, Anudeex Shetty, Heng Ji, Preslav Nakov, Usman Naseem
- **URL**: <http://arxiv.org/abs/2601.12758v1>
- **Submitted**: 2026-01-19 06:38:52
- **Comment**: WIP
- **Topic Keywords**: rag
- **Reason**: This paper appears to be focused on pluralistic alignment in large language models, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on the use of language models, the primary focus is on value expression and pluralistic alignment, which does not align with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.

### 42. Towards Robust Process Reward Modeling via Noise-aware Learning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Bin Xie, Bingbing Xu, Xueyun Tian, Yilin Chen, Huawei Shen
- **URL**: <http://arxiv.org/abs/2601.12748v1>
- **Submitted**: 2026-01-19 06:03:58
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Process Reward Models and Monte Carlo Estimation, which are not directly related to Information Retrieval or Search technologies. While it involves a large language model, the context is not about query understanding, ranking models, or user behavior modeling, but rather about robust process reward modeling.

#### Abstract
> Process Reward Models (PRMs) have achieved strong results in complex reasoning, but are bottlenecked by costly process-level supervision. A widely used alternative, Monte Carlo Estimation (MCE), defines process rewards as the probability that a policy model reaches the correct final answer from a given reasoning step. However, step correctness is an intrinsic property of the reasoning trajectory, and should be invariant to policy choice. Our empirical findings show that MCE producing policy-dependent rewards that induce label noise, including false positives that reward incorrect steps and false negatives that penalize correct ones. To address above challenges, we propose a two-stage framework to mitigate noisy supervision. In the labeling stage, we introduce a reflection-aware label correction mechanism that uses a large language model (LLM) as a judge to detect reflection and self-correction behaviors related to the current reasoning step, thereby suppressing overestimated rewards. In the training stage, we further propose a \underline{\textbf{N}}oise-\underline{\textbf{A}}ware \underline{\textbf{I}}terative \underline{\textbf{T}}raining framework that enables the PRM to progressively refine noisy labels based on its own confidence. Extensive Experiments show that our method substantially improves step-level correctness discrimination, achieving up to a 27\% absolute gain in average F1 over PRMs trained with noisy supervision.

### 43. Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Bingsen Chen, Boyan Li, Ping Nie, Yuyu Zhang, Xi Ye, Chen Zhao
- **URL**: <http://arxiv.org/abs/2601.13217v1>
- **Submitted**: 2026-01-19 16:48:45
- **Topic Keywords**: search
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves Deep Research Agents and report generation, the focus is on multi-turn report revision and evaluation, which is not a central match to your core research themes.

#### Abstract
> Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports via self-reflection or peer feedback. Whether DRAs can reliably revise reports with user feedback remains unexplored. We introduce Mr Dre, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. Mr Dre consists of (1) a unified long-form report evaluation protocol spanning comprehensiveness, factuality, and presentation, and (2) a human-verified feedback simulation pipeline for multi-turn revision. Our analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16-27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. We further show that these issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.

### 44. OpenExempt: A Diagnostic Benchmark for Legal Reasoning and a Framework for Creating Custom Benchmarks on Demand

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Sergio Servantez, Sarah B. Lawsky, Rajiv Jain, Daniel W. Linna, Kristian Hammond
- **URL**: <http://arxiv.org/abs/2601.13183v1>
- **Submitted**: 2026-01-19 16:07:47
- **Comment**: 25 pages, 9 Figures, 15 tables
- **Topic Keywords**: search
- **Reason**: This paper appears to be primarily focused on legal reasoning and benchmarking, which is not a central match to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context is specific to legal reasoning and does not seem to align with your interests in query understanding, ranking models, or user behavior modeling.

#### Abstract
> Reasoning benchmarks have played a crucial role in the progress of language models. Yet rigorous evaluation remains a significant challenge as static question-answer pairs provide only a snapshot of performance, compressing complex behavior into a single accuracy metric. This limitation is especially true in complex, rule-bound domains such as law, where existing benchmarks are costly to build and ill suited for isolating specific failure modes. To address this, we introduce OpenExempt, a framework and benchmark for diagnostic evaluation of legal reasoning. The OpenExempt Framework uses expert-crafted symbolic representations of U.S. Bankruptcy Code statutes to dynamically generate a large space of natural language reasoning tasks and their machine-computable solutions on demand. This gives users fine-grained control over task complexity and scope, allowing individual reasoning skills to be probed in isolation. Using this system, we construct the OpenExempt Benchmark, a diagnostic benchmark for legal reasoning with 9,765 samples across nine evaluation suites designed to carefully probe model capabilities. Experiments on 13 diverse language models reveal sharp performance cliffs that emerge only under longer reasoning paths and in the presence of obfuscating statements. We release the framework and benchmark publicly to support research aimed at understanding and improving the next generation of reasoning systems.

### 45. Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Warit Sirichotedumrong, Adisai Na-Thalang, Potsawee Manakul, Pittawat Taveekitworachai, Sittipong Sripaisarnmongkol, Kunat Pipatanakul
- **URL**: <http://arxiv.org/abs/2601.13044v1>
- **Submitted**: 2026-01-19 13:28:17
- **Comment**: Models and datasets are publicly available on https://huggingface.co/collections/typhoon-ai/typhoon-asr-technical-report ; Project Page: https://opentyphoon.ai/model/typhoon-asr-realtime
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests as it focuses on Automatic Speech Recognition (ASR) and Thai language processing, which is outside your primary areas of interest in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Large encoder-decoder models like Whisper achieve strong offline transcription but remain impractical for streaming applications due to high latency. However, due to the accessibility of pre-trained checkpoints, the open Thai ASR landscape remains dominated by these offline architectures, leaving a critical gap in efficient streaming solutions. We present Typhoon ASR Real-time, a 115M-parameter FastConformer-Transducer model for low-latency Thai speech recognition. We demonstrate that rigorous text normalization can match the impact of model scaling: our compact model achieves a 45x reduction in computational cost compared to Whisper Large-v3 while delivering comparable accuracy. Our normalization pipeline resolves systemic ambiguities in Thai transcription --including context-dependent number verbalization and repetition markers (mai yamok) --creating consistent training targets. We further introduce a two-stage curriculum learning approach for Isan (north-eastern) dialect adaptation that preserves Central Thai performance. To address reproducibility challenges in Thai ASR, we release the Typhoon ASR Benchmark, a gold-standard human-labeled datasets with transcriptions following established Thai linguistic conventions, providing standardized evaluation protocols for the research community.

### 46. Rapport du Projet de Recherche TRAIMA

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Julie Ran√ßon, Jean-Fran√ßois Cerisier, Emilie Remond, Aur√©lien Nguyen, Andrew Peterson, Ladjel Bellatreche
- **URL**: <http://arxiv.org/abs/2601.12844v1>
- **Submitted**: 2026-01-19 08:55:50
- **Comment**: in French language
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests as it focuses on the automatic processing of multimodal interactions in educational settings, which is outside the scope of information retrieval, search technologies, and natural language processing. The project's goal of establishing a methodological framework for automatic processing of multimodal pedagogical interactions does not align with your primary focus on deep semantic understanding and real-time relevance optimization in information retrieval.

#### Abstract
> The TRAIMA project (TRaitement Automatique des Interactions Multimodales en Apprentissage), conducted between March 2019 and June 2020, investigates the potential of automatic processing of multimodal interactions in educational settings. The project addresses a central methodological challenge in educational and interactional research: the analysis of verbal, paraverbal, and non-verbal data is currently carried out manually, making it extremely time-consuming and difficult to scale. TRAIMA explores how machine learning approaches could contribute to the categorisation and classification of such interactions. The project focuses specifically on explanatory and collaborative sequences occurring in classroom interactions, particularly in French as a Foreign Language (FLE) and French as a First Language (FLM) contexts. These sequences are analysed as inherently multimodal phenomena, combining spoken language with prosody, gestures, posture, gaze, and spatial positioning. A key theoretical contribution of the project is the precise linguistic and interactional definition of explanatory discourse as a tripartite sequence (opening, explanatory core, closure), drawing on discourse analysis and interactional linguistics. A substantial part of the research is devoted to the methodological foundations of transcription, which constitute a critical bottleneck for any form of automation. The report provides a detailed state of the art of existing transcription conventions (ICOR, Mondada, GARS, VALIBEL, Ferr{√©}), highlighting their respective strengths and limitations when applied to multimodal classroom data. Through comparative analyses of manually transcribed sequences, the project demonstrates the inevitable variability and interpretative dimension of transcription practices, depending on theoretical positioning and analytical goals. Empirical work is based on several corpora, notably the INTER-EXPLIC corpus (approximately 30 hours of classroom interaction) and the EXPLIC-LEXIC corpus, which serve both as testing grounds for manual annotation and as reference datasets for future automation. Particular attention is paid to teacher gestures (kin{√©}sic and proxemic resources), prosodic features, and their functional role in meaning construction and learner comprehension. The project also highlights the strategic role of the Techn{√©}LAB platform, which provides advanced multimodal data capture (multi-camera video, synchronized audio, eye-tracking, digital interaction traces) and constitutes both a research infrastructure and a test environment for the development of automated tools. In conclusion, TRAIMA does not aim to deliver a fully operational automated system, but rather to establish a rigorous methodological framework for the automatic processing of multimodal pedagogical interactions. The project identifies transcription conventions, annotation categories, and analytical units that are compatible with machine learning approaches, while emphasizing the need for theoretical explicitness and researcher reflexivity. TRAIMA thus lays the groundwork for future interdisciplinary research at the intersection of didactics, discourse analysis, multimodality, and artificial intelligence in education.

### 47. Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Elham Tajik, Conrad Borchers, Bahar Shahrokhian, Sebastian Simon, Ali Keramati, Sonika Pal, Sreecharan Sankaranarayanan
- **URL**: <http://arxiv.org/abs/2601.12618v1>
- **Submitted**: 2026-01-18 23:19:49
- **Comment**: LAK 2026 conference paper, 7 pages
- **Topic Keywords**: search
- **Reason**: This paper focuses on learning analytics and multi-agent systems, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves large language models, the context is educational research and methodological standards, rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> Learning analytics researchers often analyze qualitative student data such as coded annotations or interview transcripts to understand learning processes. With the rise of generative AI, fully automated and human-AI workflows have emerged as promising methods for analysis. However, methodological standards to guide such workflows remain limited. In this study, we propose that reasoning traces generated by large language model (LLM) agents, especially within multi-agent systems, constitute a novel and rich form of process data to enhance interpretive practices in qualitative coding. We apply cosine similarity to LLM reasoning traces to systematically detect, quantify, and interpret disagreements among agents, reframing disagreement as a meaningful analytic signal. Analyzing nearly 10,000 instances of agent pairs coding human tutoring dialog segments, we show that LLM agents' semantic reasoning similarity robustly differentiates consensus from disagreement and correlates with human coding reliability. Qualitative analysis guided by this metric reveals nuanced instructional sub-functions within codes and opportunities for conceptual codebook refinement. By integrating quantitative similarity metrics with qualitative review, our method has the potential to improve and accelerate establishing inter-rater reliability during coding by surfacing interpretive ambiguity, especially when LLMs collaborate with humans. We discuss how reasoning-trace disagreements represent a valuable new class of analytic signals advancing methodological rigor and interpretive depth in educational research.

### 48. Open Vocabulary Panoptic Segmentation With Retrieval Augmentation

- **LLM Score**: 0
- **Keyword Score**: 5
- **Authors**: Nafis Sadeq, Qingfeng Liu, Mostafa El-Khamy
- **URL**: <http://arxiv.org/abs/2601.12779v1>
- **Submitted**: 2026-01-19 07:16:45
- **Topic Keywords**: query, retrieval
- **Reason**: This paper focuses on Open Vocabulary Panoptic Segmentation with a retrieval-augmented method, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Given an input image and set of class names, panoptic segmentation aims to label each pixel in an image with class labels and instance labels. In comparison, Open Vocabulary Panoptic Segmentation aims to facilitate the segmentation of arbitrary classes according to user input. The challenge is that a panoptic segmentation system trained on a particular dataset typically does not generalize well to unseen classes beyond the training data. In this work, we propose RetCLIP, a retrieval-augmented panoptic segmentation method that improves the performance of unseen classes. In particular, we construct a masked segment feature database using paired image-text data. At inference time, we use masked segment features from the input image as query keys to retrieve similar features and associated class labels from the database. Classification scores for the masked segment are assigned based on the similarity between query features and retrieved features. The retrieval-based classification scores are combined with CLIP-based scores to produce the final output. We incorporate our solution with a previous SOTA method (FC-CLIP). When trained on COCO, the proposed method demonstrates 30.9 PQ, 19.3 mAP, 44.0 mIoU on the ADE20k dataset, achieving +4.5 PQ, +2.5 mAP, +10.0 mIoU absolute improvement over the baseline.

### 49. Lombard Speech Synthesis for Any Voice with Controllable Style Embeddings

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Seymanur Akti, Alexander Waibel
- **URL**: <http://arxiv.org/abs/2601.12966v1>
- **Submitted**: 2026-01-19 11:25:19
- **Topic Keywords**: rag
- **Reason**: This paper is not related to Information Retrieval, Search technologies, or any of the user's core research themes. It focuses on speech synthesis and natural language processing, but in a different context.

#### Abstract
> The Lombard effect plays a key role in natural communication, particularly in noisy environments or when addressing hearing-impaired listeners. We present a controllable text-to-speech (TTS) system capable of synthesizing Lombard speech for any speaker without requiring explicit Lombard data during training. Our approach leverages style embeddings learned from a large, prosodically diverse dataset and analyzes their correlation with Lombard attributes using principal component analysis (PCA). By shifting the relevant PCA components, we manipulate the style embeddings and incorporate them into our TTS model to generate speech at desired Lombard levels. Evaluations demonstrate that our method preserves naturalness and speaker identity, enhances intelligibility under noise, and provides fine-grained control over prosody, offering a robust solution for controllable Lombard TTS for any speaker.

### 50. FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Peng Li, Zihan Zhuang, Yangfan Gao, Yi Dong, Sixian Li, Changhao Jiang, Shihan Dou, Zhiheng Xi, Enyu Zhou, Jixuan Huang, Hui Li, Jingjing Gong, Xingjun Ma, Tao Gui, Zuxuan Wu, Qi Zhang, Xuanjing Huang, Yu-Gang Jiang, Xipeng Qiu
- **URL**: <http://arxiv.org/abs/2601.12799v1>
- **Submitted**: 2026-01-19 07:59:32
- **Comment**: Project Page: https://openmoss.github.io/FRoM-W1
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, or data mining. The paper focuses on humanoid robot control using natural language instructions, which is outside your areas of expertise.

#### Abstract
> Humanoid robots are capable of performing various actions such as greeting, dancing and even backflipping. However, these motions are often hard-coded or specifically trained, which limits their versatility. In this work, we present FRoM-W1, an open-source framework designed to achieve general humanoid whole-body motion control using natural language. To universally understand natural language and generate corresponding motions, as well as enable various humanoid robots to stably execute these motions in the physical world under gravity, FRoM-W1 operates in two stages: (a) H-GPT: utilizing massive human data, a large-scale language-driven human whole-body motion generation model is trained to generate diverse natural behaviors. We further leverage the Chain-of-Thought technique to improve the model's generalization in instruction understanding. (b) H-ACT: After retargeting generated human whole-body motions into robot-specific actions, a motion controller that is pretrained and further fine-tuned through reinforcement learning in physical simulation enables humanoid robots to accurately and stably perform corresponding actions. It is then deployed on real robots via a modular simulation-to-reality module. We extensively evaluate FRoM-W1 on Unitree H1 and G1 robots. Results demonstrate superior performance on the HumanML3D-X benchmark for human whole-body motion generation, and our introduced reinforcement learning fine-tuning consistently improves both motion tracking accuracy and task success rates of these humanoid robots. We open-source the entire FRoM-W1 framework and hope it will advance the development of humanoid intelligence.

---

