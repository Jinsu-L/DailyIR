[
    {
        "title": "ComLQ: Benchmarking Complex Logical Queries in Information Retrieval",
        "abstract": "Information retrieval (IR) systems play a critical role in navigating information overload across various applications. Existing IR benchmarks primarily focus on simple queries that are semantically analogous to single- and multi-hop relations, overlooking \\emph{complex logical queries} involving first-order logic operations such as conjunction ($\\land$), disjunction ($\\lor$), and negation ($\\lnot$). Thus, these benchmarks can not be used to sufficiently evaluate the performance of IR models on complex queries in real-world scenarios. To address this problem, we propose a novel method leveraging large language models (LLMs) to construct a new IR dataset \\textbf{ComLQ} for \\textbf{Com}plex \\textbf{L}ogical \\textbf{Q}ueries, which comprises 2,909 queries and 11,251 candidate passages. A key challenge in constructing the dataset lies in capturing the underlying logical structures within unstructured text. Therefore, by designing the subgraph-guided prompt with the subgraph indicator, an LLM (such as GPT-4o) is guided to generate queries with specific logical structures based on selected passages. All query-passage pairs in ComLQ are ensured \\emph{structure conformity} and \\emph{evidence distribution} through expert annotation. To better evaluate whether retrievers can handle queries with negation, we further propose a new evaluation metric, \\textbf{Log-Scaled Negation Consistency} (\\textbf{LSNC@$K$}). As a supplement to standard relevance-based metrics (such as nDCG and mAP), LSNC@$K$ measures whether top-$K$ retrieved passages violate negation conditions in queries. Our experimental results under zero-shot settings demonstrate existing retrieval models' limited performance on complex logical queries, especially on queries with negation, exposing their inferior capabilities of modeling exclusion.",
        "url": "http://arxiv.org/abs/2511.12004v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12004v1",
        "arxiv_id": "2511.12004v1",
        "authors": [
            "Ganlin Xu",
            "Zhitao Yin",
            "Linghao Zhang",
            "Jiaqing Liang",
            "Weijia Lu",
            "Xiaodong Zhang",
            "Zhifei Yang",
            "Sihang Jiang",
            "Deqing Yang"
        ],
        "submitted": "2025-11-15 02:58:21",
        "source": "arxiv",
        "comment": "Accepted by AAAI 2026",
        "score": 19,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retriever' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 9,
        "llm_reason": "The paper focuses on complex logical query understanding in IR, directly addressing query semantics—a core interest of the user. It leverages LLMs and introduces new evaluation metrics, aligning with NLP and data‑mining aspects of the user’s research. While it does not cover ranking models or click models, its contribution to query understanding and IR benchmarking is highly relevant."
    },
    {
        "title": "Task-Aware Retrieval Augmentation for Dynamic Recommendation",
        "abstract": "Dynamic recommendation systems aim to provide personalized suggestions by modeling temporal user-item interactions across time-series behavioral data. Recent studies have leveraged pre-trained dynamic graph neural networks (GNNs) to learn user-item representations over temporal snapshot graphs. However, fine-tuning GNNs on these graphs often results in generalization issues due to temporal discrepancies between pre-training and fine-tuning stages, limiting the model's ability to capture evolving user preferences. To address this, we propose TarDGR, a task-aware retrieval-augmented framework designed to enhance generalization capability by incorporating task-aware model and retrieval-augmentation. Specifically, TarDGR introduces a Task-Aware Evaluation Mechanism to identify semantically relevant historical subgraphs, enabling the construction of task-specific datasets without manual labeling. It also presents a Graph Transformer-based Task-Aware Model that integrates semantic and structural encodings to assess subgraph relevance. During inference, TarDGR retrieves and fuses task-aware subgraphs with the query subgraph, enriching its representation and mitigating temporal generalization issues. Experiments on multiple large-scale dynamic graph datasets demonstrate that TarDGR consistently outperforms state-of-the-art methods, with extensive empirical evidence underscoring its superior accuracy and generalization capabilities.",
        "url": "http://arxiv.org/abs/2511.12495v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12495v1",
        "arxiv_id": "2511.12495v1",
        "authors": [
            "Zhen Tao",
            "Xinke Jiang",
            "Qingshuai Feng",
            "Haoyu Zhang",
            "Lun Du",
            "Yuchen Fang",
            "Hao Miao",
            "Bangquan Xie",
            "Qingqiang Sun"
        ],
        "submitted": "2025-11-16 08:14:52",
        "source": "arxiv",
        "comment": "AAAI 2026",
        "score": 11,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on dynamic recommendation systems, leveraging graph neural networks and task-aware retrieval augmentation. While it touches on user behavior modeling, it primarily deals with recommender systems, which is a related but secondary interest. The paper's emphasis on graph neural networks and dynamic graph datasets makes it somewhat relevant to the user's interests in information retrieval and NLP."
    },
    {
        "title": "Probing Preference Representations: A Multi-Dimensional Evaluation and Analysis Method for Reward Models",
        "abstract": "Previous methods evaluate reward models by testing them on a fixed pairwise ranking test set, but they typically do not provide performance information on each preference dimension. In this work, we address the evaluation challenge of reward models by probing preference representations. To confirm the effectiveness of this evaluation method, we construct a Multi-dimensional Reward Model Benchmark (MRMBench), a collection of six probing tasks for different preference dimensions. We design it to favor and encourage reward models that better capture preferences across different dimensions. Furthermore, we introduce an analysis method, inference-time probing, which identifies the dimensions used during the reward prediction and enhances its interpretability. Through extensive experiments, we find that MRMBench strongly correlates with the alignment performance of large language models (LLMs), making it a reliable reference for developing advanced reward models. Our analysis of MRMBench evaluation results reveals that reward models often struggle to capture preferences across multiple dimensions, highlighting the potential of multi-objective optimization in reward modeling. Additionally, our findings show that the proposed inference-time probing method offers a reliable metric for assessing the confidence of reward predictions, which ultimately improves the alignment of LLMs.",
        "url": "http://arxiv.org/abs/2511.12464v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12464v1",
        "arxiv_id": "2511.12464v1",
        "authors": [
            "Chenglong Wang",
            "Yifu Huo",
            "Yang Gan",
            "Yongyu Mu",
            "Qiaozhi He",
            "Murun Yang",
            "Bei Li",
            "Chunliang Zhang",
            "Tongran Liu",
            "Anxiang Ma",
            "Zhengtao Yu",
            "Jingbo Zhu",
            "Tong Xiao"
        ],
        "submitted": "2025-11-16 05:29:29",
        "source": "arxiv",
        "comment": "Accepted by AAAI 2026",
        "score": 9,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'pairwise' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of ranking models and user behavior modeling. The focus on reward models and their evaluation methods aligns with your interests in query understanding and real-time relevance optimization. However, the paper's primary focus on recommender systems and large language models limits its direct connection to your core research themes."
    },
    {
        "title": "A Multimodal Manufacturing Safety Chatbot: Knowledge Base Design, Benchmark Development, and Evaluation of Multiple RAG Approaches",
        "abstract": "Ensuring worker safety remains a critical challenge in modern manufacturing environments. Industry 5.0 reorients the prevailing manufacturing paradigm toward more human-centric operations. Using a design science research methodology, we identify three essential requirements for next-generation safety training systems: high accuracy, low latency, and low cost. We introduce a multimodal chatbot powered by large language models that meets these design requirements. The chatbot uses retrieval-augmented generation to ground its responses in curated regulatory and technical documentation. To evaluate our solution, we developed a domain-specific benchmark of expert-validated question and answer pairs for three representative machines: a Bridgeport manual mill, a Haas TL-1 CNC lathe, and a Universal Robots UR5e collaborative robot. We tested 24 RAG configurations using a full-factorial design and assessed them with automated evaluations of correctness, latency, and cost. Our top 2 configurations were then evaluated by ten industry experts and academic researchers. Our results show that retrieval strategy and model configuration have a significant impact on performance. The top configuration (selected for chatbot deployment) achieved an accuracy of 86.66%, an average latency of 10.04 seconds, and an average cost of $0.005 per query. Overall, our work provides three contributions: an open-source, domain-grounded safety training chatbot; a validated benchmark for evaluating AI-assisted safety instruction; and a systematic methodology for designing and assessing AI-enabled instructional and immersive safety training systems for Industry 5.0 environments.",
        "url": "http://arxiv.org/abs/2511.11847v1",
        "pdf_url": "https://arxiv.org/pdf/2511.11847v1",
        "arxiv_id": "2511.11847v1",
        "authors": [
            "Ryan Singh",
            "Austin Hamilton",
            "Amanda White",
            "Michael Wise",
            "Ibrahim Yousif",
            "Arthur Carvalho",
            "Zhe Shan",
            "Reza Abrisham Baf",
            "Mohammad Mayyas",
            "Lora A. Cavuoto",
            "Fadel M. Megahed"
        ],
        "submitted": "2025-11-14 20:10:23",
        "source": "arxiv",
        "comment": "25 pages, 5 figures",
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves a chatbot and large language models, the focus is on manufacturing safety and Industry 5.0, which is not a primary area of interest for the user."
    },
    {
        "title": "MME-RAG: Multi-Manager-Expert Retrieval-Augmented Generation for Fine-Grained Entity Recognition in Task-Oriented Dialogues",
        "abstract": "Fine-grained entity recognition is crucial for reasoning and decision-making in task-oriented dialogues, yet current large language models (LLMs) continue to face challenges in domain adaptation and retrieval controllability. We introduce MME-RAG, a Multi-Manager-Expert Retrieval-Augmented Generation framework that decomposes entity recognition into two coordinated stages: type-level judgment by lightweight managers and span-level extraction by specialized experts. Each expert is supported by a KeyInfo retriever that injects semantically aligned, few-shot exemplars during inference, enabling precise and domain-adaptive extraction without additional training. Experiments on CrossNER, MIT-Movie, MIT-Restaurant, and our newly constructed multi-domain customer-service dataset demonstrate that MME-RAG performs better than recent baselines in most domains. Ablation studies further show that both the hierarchical decomposition and KeyInfo-guided retrieval are key drivers of robustness and cross-domain generalization, establishing MME-RAG as a scalable and interpretable solution for adaptive dialogue understanding.",
        "url": "http://arxiv.org/abs/2511.12213v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12213v1",
        "arxiv_id": "2511.12213v1",
        "authors": [
            "Liang Xue",
            "Haoyu Liu",
            "Yajun Tian",
            "Xinyu Zhong",
            "Yang Liu"
        ],
        "submitted": "2025-11-15 13:35:55",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, particularly in the context of task-oriented dialogues and fine-grained entity recognition. However, it does not directly focus on query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user. The paper's emphasis on retrieval-augmented generation and domain adaptation is relevant, but not central to the user's research themes."
    },
    {
        "title": "From Scaling to Structured Expressivity: Rethinking Transformers for CTR Prediction",
        "abstract": "Despite massive investments in scale, deep models for click-through rate (CTR) prediction often exhibit rapidly diminishing returns - a stark contrast to the smooth, predictable gains seen in large language models. We identify the root cause as a structural misalignment: Transformers assume sequential compositionality, while CTR data demand combinatorial reasoning over high-cardinality semantic fields. Unstructured attention spreads capacity indiscriminately, amplifying noise under extreme sparsity and breaking scalable learning. To restore alignment, we introduce the Field-Aware Transformer (FAT), which embeds field-based interaction priors into attention through decomposed content alignment and cross-field modulation. This design ensures model complexity scales with the number of fields F, not the total vocabulary size n >> F, leading to tighter generalization and, critically, observed power-law scaling in AUC as model width increases. We present the first formal scaling law for CTR models, grounded in Rademacher complexity, that explains and predicts this behavior. On large-scale benchmarks, FAT improves AUC by up to +0.51% over state-of-the-art methods. Deployed online, it delivers +2.33% CTR and +0.66% RPM. Our work establishes that effective scaling in recommendation arises not from size, but from structured expressivity-architectural coherence with data semantics.",
        "url": "http://arxiv.org/abs/2511.12081v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12081v1",
        "arxiv_id": "2511.12081v1",
        "authors": [
            "Bencheng Yan",
            "Yuejie Lei",
            "Zhiyuan Zeng",
            "Di Wang",
            "Kaiyi Lin",
            "Pengjie Wang",
            "Jian Xu",
            "Bo Zheng"
        ],
        "submitted": "2025-11-15 07:55:50",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'click' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'click-through rate' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper aligns well with your research interests in Information Retrieval, particularly in the area of click-through rate prediction and ranking models. The proposed Field-Aware Transformer (FAT) model addresses the issue of scalable learning in high-cardinality semantic fields, which is a key challenge in real-time relevance optimization. The paper's focus on structured expressivity and architectural coherence with data semantics is also relevant to your interests in deep semantic understanding."
    },
    {
        "title": "DualGR: Generative Retrieval with Long and Short-Term Interests Modeling",
        "abstract": "In large-scale industrial recommendation systems, retrieval must produce high-quality candidates from massive corpora under strict latency. Recently, Generative Retrieval (GR) has emerged as a viable alternative to Embedding-Based Retrieval (EBR), which quantizes items into a finite token space and decodes candidates autoregressively, providing a scalable path that explicitly models target-history interactions via cross-attention. However, three challenges persist: 1) how to balance users' long-term and short-term interests , 2) noise interference when generating hierarchical semantic IDs (SIDs), 3) the absence of explicit modeling for negative feedback such as exposed items without clicks. To address these challenges, we propose DualGR, a generative retrieval framework that explicitly models dual horizons of user interests with selective activation. Specifically, DualGR utilizes Dual-Branch Long/Short-Term Router (DBR) to cover both stable preferences and transient intents by explicitly modeling users' long- and short-term behaviors. Meanwhile, Search-based SID Decoding (S2D) is presented to control context-induced noise and enhance computational efficiency by constraining candidate interactions to the current coarse (level-1) bucket during fine-grained (level-2/3) SID prediction. % also reinforcing intra-class consistency. Finally, we propose an Exposure-aware Next-Token Prediction Loss (ENTP-Loss) that treats \"exposed-but-unclicked\" items as hard negatives at level-1, enabling timely interest fade-out. On the large-scale Kuaishou short-video recommendation system, DualGR has achieved outstanding performance. Online A/B testing shows +0.527% video views and +0.432% watch time lifts, validating DualGR as a practical and effective paradigm for industrial generative retrieval.",
        "url": "http://arxiv.org/abs/2511.12518v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12518v1",
        "arxiv_id": "2511.12518v1",
        "authors": [
            "Zhongchao Yi",
            "Kai Feng",
            "Xiaojian Ma",
            "Yalong Wang",
            "Yongqi Liu",
            "Han Li",
            "Zhengyang Zhou",
            "Yang Wang"
        ],
        "submitted": "2025-11-16 09:20:54",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'click' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper focuses on generative retrieval for recommendation, which shares techniques with IR such as ranking and user behavior modeling. It addresses click‑based negative feedback and user interest modeling, aligning with the user’s interest in click models and ranking. However, it is more recommendation‑centric than core IR research, so it is only somewhat related."
    },
    {
        "title": "Assessing LLMs for Serendipity Discovery in Knowledge Graphs: A Case for Drug Repurposing",
        "abstract": "Large Language Models (LLMs) have greatly advanced knowledge graph question answering (KGQA), yet existing systems are typically optimized for returning highly relevant but predictable answers. A missing yet desired capacity is to exploit LLMs to suggest surprise and novel (\"serendipitious\") answers. In this paper, we formally define the serendipity-aware KGQA task and propose the SerenQA framework to evaluate LLMs' ability to uncover unexpected insights in scientific KGQA tasks. SerenQA includes a rigorous serendipity metric based on relevance, novelty, and surprise, along with an expert-annotated benchmark derived from the Clinical Knowledge Graph, focused on drug repurposing. Additionally, it features a structured evaluation pipeline encompassing three subtasks: knowledge retrieval, subgraph reasoning, and serendipity exploration. Our experiments reveal that while state-of-the-art LLMs perform well on retrieval, they still struggle to identify genuinely surprising and valuable discoveries, underscoring a significant room for future improvements. Our curated resources and extended version are released at: https://cwru-db-group.github.io/serenQA.",
        "url": "http://arxiv.org/abs/2511.12472v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12472v1",
        "arxiv_id": "2511.12472v1",
        "authors": [
            "Mengying Wang",
            "Chenhui Ma",
            "Ao Jiao",
            "Tuo Liang",
            "Pengjun Lu",
            "Shrinidhi Hegde",
            "Yu Yin",
            "Evren Gurkan-Cavusoglu",
            "Yinghui Wu"
        ],
        "submitted": "2025-11-16 06:19:53",
        "source": "arxiv",
        "comment": "The 40th AAAI Conference on Artificial Intelligence (AAAI-26)",
        "score": 5,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper explores the application of Large Language Models (LLMs) in knowledge graph question answering (KGQA) with a focus on serendipity discovery. While it touches on aspects of query understanding and ranking models, its primary focus is on a specific domain (drug repurposing) and a novel task definition, which is somewhat related to the user's interests in IR and NLP."
    },
    {
        "title": "TAdaRAG: Task Adaptive Retrieval-Augmented Generation via On-the-Fly Knowledge Graph Construction",
        "abstract": "Retrieval-Augmented Generation (RAG) improves large language models by retrieving external knowledge, often truncated into smaller chunks due to the input context window, which leads to information loss, resulting in response hallucinations and broken reasoning chains. Moreover, traditional RAG retrieves unstructured knowledge, introducing irrelevant details that hinder accurate reasoning. To address these issues, we propose TAdaRAG, a novel RAG framework for on-the-fly task-adaptive knowledge graph construction from external sources. Specifically, we design an intent-driven routing mechanism to a domain-specific extraction template, followed by supervised fine-tuning and a reinforcement learning-based implicit extraction mechanism, ensuring concise, coherent, and non-redundant knowledge integration. Evaluations on six public benchmarks and a real-world business benchmark (NowNewsQA) across three backbone models demonstrate that TAdaRAG outperforms existing methods across diverse domains and long-text tasks, highlighting its strong generalization and practical effectiveness.",
        "url": "http://arxiv.org/abs/2511.12520v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12520v1",
        "arxiv_id": "2511.12520v1",
        "authors": [
            "Jie Zhang",
            "Bo Tang",
            "Wanzi Shao",
            "Wenqiang Wei",
            "Jihao Zhao",
            "Jianqing Zhu",
            "Zhiyu li",
            "Wen Xi",
            "Zehao Lin",
            "Feiyu Xiong",
            "Yanchao Tan"
        ],
        "submitted": "2025-11-16 09:23:09",
        "source": "arxiv",
        "comment": "Accepted by AAAI 2026",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper proposes a novel framework for Retrieval-Augmented Generation (RAG) that addresses issues of information loss and irrelevant details. Although primarily focused on NLP, it involves query understanding and ranking models, which are relevant to your IR interests. The paper's emphasis on knowledge graph construction and real-time relevance optimization also aligns with your research themes."
    },
    {
        "title": "MOON2.0: Dynamic Modality-balanced Multimodal Representation Learning for E-commerce Product Understanding",
        "abstract": "The rapid growth of e-commerce calls for multimodal models that comprehend rich visual and textual product information. Although recent multimodal large language models (MLLMs) for product understanding exhibit strong capability in representation learning for e-commerce, they still face three challenges: (i) the modality imbalance induced by modality mixed training; (ii) underutilization of the intrinsic alignment relationships among visual and textual information within a product; and (iii) limited handling of noise in e-commerce multimodal data. To address these, we propose MOON2.0, a dynamic modality-balanced multimodal representation learning framework for e-commerce product understanding. MOON2.0 comprises: (1) a Modality-driven Mixture-of-Experts (MoE) module that adaptively processes input samples by their modality composition, enabling Multimodal Joint Learning to mitigate the modality imbalance; (2) a Dual-level Alignment method to better leverage semantic alignment properties inside individual products; and (3) an MLLM-based Image-text Co-augmentation strategy that integrates textual enrichment with visual expansion, coupled with Dynamic Sample Filtering to improve training data quality. We further introduce MBE2.0, a co-augmented multimodal representation benchmark for e-commerce representation learning and evaluation. Experiments show that MOON2.0 delivers state-of-the-art zero-shot performance on MBE2.0 and multiple public datasets. Furthermore, attention-based heatmap visualization provides qualitative evidence of improved multimodal alignment of MOON2.0.",
        "url": "http://arxiv.org/abs/2511.12449v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12449v1",
        "arxiv_id": "2511.12449v1",
        "authors": [
            "Zhanheng Nie",
            "Chenghan Fu",
            "Daoze Zhang",
            "Junxian Wu",
            "Wanxian Guan",
            "Pengjie Wang",
            "Jian Xu",
            "Bo Zheng"
        ],
        "submitted": "2025-11-16 04:29:35",
        "source": "arxiv",
        "comment": "11 pages, 7 figures",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of e-commerce product understanding. The focus on multimodal representation learning and addressing modality imbalance is relevant, but the primary application domain is e-commerce, which is not your core focus. The paper's emphasis on deep semantic understanding and real-time relevance optimization is also relevant, but not a central match."
    },
    {
        "title": "Mobile-Agent-RAG: Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation",
        "abstract": "Mobile agents show immense potential, yet current state-of-the-art (SoTA) agents exhibit inadequate success rates on real-world, long-horizon, cross-application tasks. We attribute this bottleneck to the agents' excessive reliance on static, internal knowledge within MLLMs, which leads to two critical failure points: 1) strategic hallucinations in high-level planning and 2) operational errors during low-level execution on user interfaces (UI). The core insight of this paper is that high-level planning and low-level UI operations require fundamentally distinct types of knowledge. Planning demands high-level, strategy-oriented experiences, whereas operations necessitate low-level, precise instructions closely tied to specific app UIs. Motivated by these insights, we propose Mobile-Agent-RAG, a novel hierarchical multi-agent framework that innovatively integrates dual-level retrieval augmentation. At the planning stage, we introduce Manager-RAG to reduce strategic hallucinations by retrieving human-validated comprehensive task plans that provide high-level guidance. At the execution stage, we develop Operator-RAG to improve execution accuracy by retrieving the most precise low-level guidance for accurate atomic actions, aligned with the current app and subtask. To accurately deliver these knowledge types, we construct two specialized retrieval-oriented knowledge bases. Furthermore, we introduce Mobile-Eval-RAG, a challenging benchmark for evaluating such agents on realistic multi-app, long-horizon tasks. Extensive experiments demonstrate that Mobile-Agent-RAG significantly outperforms SoTA baselines, improving task completion rate by 11.0% and step efficiency by 10.2%, establishing a robust paradigm for context-aware, reliable multi-agent mobile automation.",
        "url": "http://arxiv.org/abs/2511.12254v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12254v1",
        "arxiv_id": "2511.12254v1",
        "authors": [
            "Yuxiang Zhou",
            "Jichang Li",
            "Yanhao Zhang",
            "Haonan Lu",
            "Guanbin Li"
        ],
        "submitted": "2025-11-15 15:22:42",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multi-agent coordination and knowledge empowerment for mobile automation, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves retrieval-oriented knowledge bases, the context is distinct from the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Evolving Prompts for Toxicity Search in Large Language Models",
        "abstract": "Large Language Models remain vulnerable to adversarial prompts that elicit toxic content even after safety alignment. We present ToxSearch, a black-box evolutionary framework that tests model safety by evolving prompts in a synchronous steady-state loop. The system employs a diverse set of operators, including lexical substitutions, negation, back-translation, paraphrasing, and two semantic crossover operators, while a moderation oracle provides fitness guidance. Operator-level analysis shows heterogeneous behavior: lexical substitutions offer the best yield-variance trade-off, semantic-similarity crossover acts as a precise low-throughput inserter, and global rewrites exhibit high variance with elevated refusal costs. Using elite prompts evolved on LLaMA 3.1 8B, we observe practically meaningful but attenuated cross-model transfer, with toxicity roughly halving on most targets, smaller LLaMA 3.2 variants showing the strongest resistance, and some cross-architecture models retaining higher toxicity. These results suggest that small, controllable perturbations are effective vehicles for systematic red-teaming and that defenses should anticipate cross-model reuse of adversarial prompts rather than focusing only on single-model hardening.",
        "url": "http://arxiv.org/abs/2511.12487v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12487v1",
        "arxiv_id": "2511.12487v1",
        "authors": [
            "Onkar Shelar",
            "Travis Desell"
        ],
        "submitted": "2025-11-16 07:47:31",
        "source": "arxiv",
        "comment": "pre-print",
        "score": 3,
        "keyword_reasons": [
            "Found 'search' (score: +1)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, particularly in the context of query understanding and model safety. However, the focus on evolving prompts for toxicity search in Large Language Models is not directly aligned with your primary interests in query ranking models and user behavior modeling. The connection to recommender systems is also tenuous."
    },
    {
        "title": "AugAbEx : Way Forward for Extractive Case Summarization",
        "abstract": "Summarization of legal judgments poses a heavy cognitive burden on law practitioners due to the complexity of the language, context-sensitive legal jargon, and the length of the document. Therefore, the automatic summarization of legal documents has attracted serious attention from natural language processing researchers. Since the abstractive summaries of legal documents generated by deep neural methods remain prone to the risk of misrepresenting nuanced legal jargon or overlooking key contextual details, we envisage a rising trend toward the use of extractive case summarizers.\n  Given the high cost of human annotation for gold standard extractive summaries, we engineer a light and transparent pipeline that leverages existing abstractive gold standard summaries to create the corresponding extractive gold standard versions. The approach ensures that the experts` opinions ensconced in the original gold standard abstractive summaries are carried over to the transformed extractive summaries. We aim to augment seven existing case summarization datasets, which include abstractive summaries, by incorporating corresponding extractive summaries and create an enriched data resource for case summarization research community. To ensure the quality of the augmented extractive summaries, we perform an extensive comparative evaluation with the original abstractive gold standard summaries covering structural, lexical, and semantic dimensions. We also compare the domain-level information of the two summaries. We commit to release the augmented datasets in the public domain for use by the research community and believe that the resource will offer opportunities to advance the field of automatic summarization of legal documents.",
        "url": "http://arxiv.org/abs/2511.12290v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12290v1",
        "arxiv_id": "2511.12290v1",
        "authors": [
            "Purnima Bindal",
            "Vikas Kumar",
            "Sagar Rathore",
            "Vasudha Bhatnagar"
        ],
        "submitted": "2025-11-15 16:49:42",
        "source": "arxiv",
        "comment": "30 pages, under review in a Journal",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on extractive case summarization in the legal domain, which is not a primary area of interest for you. While it involves natural language processing, it does not directly relate to your core research themes in information retrieval, query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "PRISM of Opinions: A Persona-Reasoned Multimodal Framework for User-centric Conversational Stance Detection",
        "abstract": "The rapid proliferation of multimodal social media content has driven research in Multimodal Conversational Stance Detection (MCSD), which aims to interpret users' attitudes toward specific targets within complex discussions. However, existing studies remain limited by: **1) pseudo-multimodality**, where visual cues appear only in source posts while comments are treated as text-only, misaligning with real-world multimodal interactions; and **2) user homogeneity**, where diverse users are treated uniformly, neglecting personal traits that shape stance expression. To address these issues, we introduce **U-MStance**, the first user-centric MCSD dataset, containing over 40k annotated comments across six real-world targets. We further propose **PRISM**, a **P**ersona-**R**easoned mult**I**modal **S**tance **M**odel for MCSD. PRISM first derives longitudinal user personas from historical posts and comments to capture individual traits, then aligns textual and visual cues within conversational context via Chain-of-Thought to bridge semantic and pragmatic gaps across modalities. Finally, a mutual task reinforcement mechanism is employed to jointly optimize stance detection and stance-aware response generation for bidirectional knowledge transfer. Experiments on U-MStance demonstrate that PRISM yields significant gains over strong baselines, underscoring the effectiveness of user-centric and context-grounded multimodal reasoning for realistic stance understanding.",
        "url": "http://arxiv.org/abs/2511.12130v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12130v1",
        "arxiv_id": "2511.12130v1",
        "authors": [
            "Bingbing Wang",
            "Zhixin Bai",
            "Zhengda Jin",
            "Zihan Wang",
            "Xintong Song",
            "Jingjie Lin",
            "Sixuan Li",
            "Jing Li",
            "Ruifeng Xu"
        ],
        "submitted": "2025-11-15 09:35:58",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and related topics, particularly in the area of conversational stance detection. However, it does not directly align with the user's primary focus on Information Retrieval, especially in areas that require deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "LLMLagBench: Identifying Temporal Training Boundaries in Large Language Models",
        "abstract": "Large Language Models (LLMs) are pretrained on textual data up to a specific temporal cutoff. This creates a strict knowledge boundary beyond which models cannot provide accurate information without querying external sources. More subtly, when this limitation is unknown or ignored, LLMs may inadvertently blend outdated time-sensitive information with general knowledge during reasoning tasks, potentially compromising response accuracy. We introduce LLMLagBench, an LLM freshness benchmark, as a systematic approach for identifying the earliest probable temporal boundaries of an LLM's training data by evaluating its knowledge of recent events. We then apply this benchmark to evaluate a large set of LLMs, including models with both explicitly declared and undeclared training cutoffs. The reliability of the benchmark is assessed by manual validation and comparison with publicly released information about LLM pretraining.",
        "url": "http://arxiv.org/abs/2511.12116v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12116v1",
        "arxiv_id": "2511.12116v1",
        "authors": [
            "Piotr Pęzik",
            "Konrad Kaczyński",
            "Maria Szymańska",
            "Filip Żarnecki",
            "Zuzanna Deckert",
            "Jakub Kwiatkowski",
            "Wojciech Janowski"
        ],
        "submitted": "2025-11-15 09:08:10",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it deals with Large Language Models and their limitations in providing accurate information. However, it focuses more on the temporal knowledge boundaries of LLMs rather than query understanding, ranking models, or user behavior modeling, which are your primary areas of interest."
    },
    {
        "title": "Continuous-time Discrete-space Diffusion Model for Recommendation",
        "abstract": "In the era of information explosion, Recommender Systems (RS) are essential for alleviating information overload and providing personalized user experiences. Recent advances in diffusion-based generative recommenders have shown promise in capturing the dynamic nature of user preferences. These approaches explore a broader range of user interests by progressively perturbing the distribution of user-item interactions and recovering potential preferences from noise, enabling nuanced behavioral understanding. However, existing diffusion-based approaches predominantly operate in continuous space through encoded graph-based historical interactions, which may compromise potential information loss and suffer from computational inefficiency. As such, we propose CDRec, a novel Continuous-time Discrete-space Diffusion Recommendation framework, which models user behavior patterns through discrete diffusion on historical interactions over continuous time. The discrete diffusion algorithm operates via discrete element operations (e.g., masking) while incorporating domain knowledge through transition matrices, producing more meaningful diffusion trajectories. Furthermore, the continuous-time formulation enables flexible adaptive sampling. To better adapt discrete diffusion models to recommendations, CDRec introduces: (1) a novel popularity-aware noise schedule that generates semantically meaningful diffusion trajectories, and (2) an efficient training framework combining consistency parameterization for fast sampling and a contrastive learning objective guided by multi-hop collaborative signals for personalized recommendation. Extensive experiments on real-world datasets demonstrate CDRec's superior performance in both recommendation accuracy and computational efficiency.",
        "url": "http://arxiv.org/abs/2511.12114v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12114v1",
        "arxiv_id": "2511.12114v1",
        "authors": [
            "Chengyi Liu",
            "Xiao Chen",
            "Shijie Wang",
            "Wenqi Fan",
            "Qing Li"
        ],
        "submitted": "2025-11-15 09:06:57",
        "source": "arxiv",
        "comment": "Accepted by WSDM 2026",
        "score": 3,
        "keyword_reasons": [
            "Found 'user behavior' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores a novel recommendation framework, CDRec, which combines discrete-space diffusion with continuous-time modeling. While it touches on user behavior patterns and diffusion-based recommenders, its primary focus is on improving recommendation accuracy and efficiency, which is somewhat related to information retrieval but not directly aligned with your core research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Leveraging Large Language Models for Career Mobility Analysis: A Study of Gender, Race, and Job Change Using U.S. Online Resume Profiles",
        "abstract": "We present a large-scale analysis of career mobility of college-educated U.S. workers using online resume profiles to investigate how gender, race, and job change options are associated with upward mobility. This study addresses key research questions of how the job changes affect their upward career mobility, and how the outcomes of upward career mobility differ by gender and race. We address data challenges -- such as missing demographic attributes, missing wage data, and noisy occupation labels -- through various data processing and Artificial Intelligence (AI) methods. In particular, we develop a large language models (LLMs) based occupation classification method known as FewSOC that achieves accuracy significantly higher than the original occupation labels in the resume dataset. Analysis of 228,710 career trajectories reveals that intra-firm occupation change has been found to facilitate upward mobility most strongly, followed by inter-firm occupation change and inter-firm lateral move. Women and Black college graduates experience significantly lower returns from job changes than men and White peers. Multilevel sensitivity analyses confirm that these disparities are robust to cluster-level heterogeneity and reveal additional intersectional patterns.",
        "url": "http://arxiv.org/abs/2511.12010v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12010v1",
        "arxiv_id": "2511.12010v1",
        "authors": [
            "Palakorn Achananuparp",
            "Connie Xu",
            "Yao Lu",
            "Xavier Jayaraj Siddarth Ashok",
            "Ee-Peng Lim"
        ],
        "submitted": "2025-11-15 03:26:57",
        "source": "arxiv",
        "comment": "Submitted to EPJ Data Science",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on career mobility analysis using large language models, which is unrelated to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves AI methods, the context and application are distinct from the user's areas of expertise."
    },
    {
        "title": "Context-Emotion Aware Therapeutic Dialogue Generation: A Multi-component Reinforcement Learning Approach to Language Models for Mental Health Support",
        "abstract": "Mental health illness represents a substantial global socioeconomic burden, with COVID-19 further exacerbating accessibility challenges and driving increased demand for telehealth mental health support. While large language models (LLMs) offer promising solutions through 24/7 availability and non-judgmental interactions, pre-trained models often lack the contextual and emotional awareness necessary for appropriate therapeutic responses. This paper investigated the application of supervised fine-tuning (SFT) and reinforcement learning (RL) techniques to enhance GPT-2's capacity for therapeutic dialogue generation. The methodology restructured input formats to enable simultaneous processing of contextual information and emotional states alongside user input, employing a multi-component reward function that aligned model outputs with professional therapist responses and annotated emotions. Results demonstrated improvements through reinforcement learning over baseline GPT-2 across multiple evaluation metrics: BLEU (0.0111), ROUGE-1 (0.1397), ROUGE-2 (0.0213), ROUGE-L (0.1317), and METEOR (0.0581). LLM evaluation confirmed high contextual relevance and professionalism, while reinforcement learning achieved 99.34% emotion accuracy compared to 66.96% for baseline GPT-2. These findings demonstrate reinforcement learning's effectiveness in developing therapeutic dialogue systems that can serve as valuable assistive tools for therapists while maintaining essential human clinical oversight.",
        "url": "http://arxiv.org/abs/2511.11884v1",
        "pdf_url": "https://arxiv.org/pdf/2511.11884v1",
        "arxiv_id": "2511.11884v1",
        "authors": [
            "Eric Hua Qing Zhang",
            "Julia Ive"
        ],
        "submitted": "2025-11-14 21:32:10",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves language models and reinforcement learning, the focus is on therapeutic dialogue generation for mental health support, which is not a primary area of interest for the user."
    },
    {
        "title": "MedPT: A Massive Medical Question Answering Dataset for Brazilian-Portuguese Speakers",
        "abstract": "While large language models (LLMs) show transformative potential in healthcare, their development remains focused on high-resource languages, creating a critical barrier for others as simple translation fails to capture unique clinical and cultural nuances, such as endemic diseases. To address this, we introduce MedPT, the first large-scale, real-world corpus for Brazilian Portuguese, comprising 384,095 authentic question-answer pairs from patient-doctor interactions. The dataset underwent a meticulous multi-stage curation protocol, using a hybrid quantitative-qualitative analysis to filter noise and contextually enrich thousands of ambiguous queries. We further augmented the corpus via LLM-driven annotation, classifying questions into seven semantic types to capture user intent. Our analysis reveals its thematic breadth (3,200 topics) and unique linguistic properties, like the natural asymmetry in patient-doctor communication. To validate its utility, we benchmark a medical specialty routing task: fine-tuning a 1.7B parameter model achieves an outstanding 94\\% F1-score on a 20-class setup. Furthermore, our qualitative error analysis shows misclassifications are not random but reflect genuine clinical ambiguities (e.g., between comorbid conditions), proving the dataset's deep semantic richness. We publicly release MedPT to foster the development of more equitable, accurate, and culturally-aware medical technologies for the Portuguese-speaking world.",
        "url": "http://arxiv.org/abs/2511.11878v1",
        "pdf_url": "https://arxiv.org/pdf/2511.11878v1",
        "arxiv_id": "2511.11878v1",
        "authors": [
            "Fernanda Bufon Färber",
            "Iago Alves Brito",
            "Julia Soares Dollis",
            "Pedro Schindler Freire Brasil Ribeiro",
            "Rafael Teixeira Sousa",
            "Arlindo Rodrigues Galvão Filho"
        ],
        "submitted": "2025-11-14 21:13:28",
        "source": "arxiv",
        "comment": "11 pages, 3 tables, 2 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, particularly in the context of query understanding and deep semantic understanding. However, the focus on a medical question answering dataset for Brazilian-Portuguese speakers is not directly aligned with your primary interests in e-commerce and real-time relevance optimization."
    },
    {
        "title": "Accepted with Minor Revisions: Value of AI-Assisted Scientific Writing",
        "abstract": "Large Language Models have seen expanding application across domains, yet their effectiveness as assistive tools for scientific writing -- an endeavor requiring precision, multimodal synthesis, and domain expertise -- remains insufficiently understood. We examine the potential of LLMs to support domain experts in scientific writing, with a focus on abstract composition. We design an incentivized randomized controlled trial with a hypothetical conference setup where participants with relevant expertise are split into an author and reviewer pool. Inspired by methods in behavioral science, our novel incentive structure encourages authors to edit the provided abstracts to an acceptable quality for a peer-reviewed submission. Our 2x2 between-subject design expands into two dimensions: the implicit source of the provided abstract and the disclosure of it. We find authors make most edits when editing human-written abstracts compared to AI-generated abstracts without source attribution, often guided by higher perceived readability in AI generation. Upon disclosure of source information, the volume of edits converges in both source treatments. Reviewer decisions remain unaffected by the source of the abstract, but bear a significant correlation with the number of edits made. Careful stylistic edits, especially in the case of AI-generated abstracts, in the presence of source information, improve the chance of acceptance. We find that AI-generated abstracts hold potential to reach comparable levels of acceptability to human-written ones with minimal revision, and that perceptions of AI authorship, rather than objective quality, drive much of the observed editing behavior. Our findings reverberate the significance of source disclosure in collaborative scientific writing.",
        "url": "http://arxiv.org/abs/2511.12529v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12529v1",
        "arxiv_id": "2511.12529v1",
        "authors": [
            "Sanchaita Hazra",
            "Doeun Lee",
            "Bodhisattwa Prasad Majumder",
            "Sachin Kumar"
        ],
        "submitted": "2025-11-16 09:49:01",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. While it involves AI and language models, its focus is on scientific writing and the effectiveness of AI-assisted tools, which is outside your primary areas of interest."
    },
    {
        "title": "QA-Noun: Representing Nominal Semantics via Natural Language Question-Answer Pairs",
        "abstract": "Decomposing sentences into fine-grained meaning units is increasingly used to model semantic alignment. While QA-based semantic approaches have shown effectiveness for representing predicate-argument relations, they have so far left noun-centered semantics largely unaddressed. We introduce QA-Noun, a QA-based framework for capturing noun-centered semantic relations. QA-Noun defines nine question templates that cover both explicit syntactical and implicit contextual roles for nouns, producing interpretable QA pairs that complement verbal QA-SRL. We release detailed guidelines, a dataset of over 2,000 annotated noun mentions, and a trained model integrated with QA-SRL to yield a unified decomposition of sentence meaning into individual, highly fine-grained, facts. Evaluation shows that QA-Noun achieves near-complete coverage of AMR's noun arguments while surfacing additional contextually implied relations, and that combining QA-Noun with QA-SRL yields over 130\\% higher granularity than recent fact-based decomposition methods such as FactScore and DecompScore. QA-Noun thus complements the broader QA-based semantic framework, forming a comprehensive and scalable approach to fine-grained semantic decomposition for cross-text alignment.",
        "url": "http://arxiv.org/abs/2511.12504v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12504v1",
        "arxiv_id": "2511.12504v1",
        "authors": [
            "Maria Tseytlin",
            "Paul Roit",
            "Omri Abend",
            "Ido Dagan",
            "Ayal Klein"
        ],
        "submitted": "2025-11-16 08:32:38",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper introduces a novel framework, QA-Noun, for capturing noun-centered semantic relations using natural language question-answer pairs. Although primarily focused on NLP and semantic decomposition, it touches on query understanding and representation, which aligns with your interests in Information Retrieval and deep semantic understanding. However, the specific application and scope of the paper are somewhat narrower than your core research themes."
    },
    {
        "title": "From Phonemes to Meaning: Evaluating Large Language Models on Tamil",
        "abstract": "Large Language Models (LLMs) have shown strong generalization across tasks in high-resource languages; however, their linguistic competence in low-resource and morphologically rich languages such as Tamil remains largely unexplored. Existing multilingual benchmarks often rely on translated English datasets, failing to capture the linguistic and cultural nuances of the target language. To address this gap, we introduce ILAKKANAM, the first Tamil-specific linguistic evaluation benchmark manually curated using 820 questions from Sri Lankan school-level Tamil subject examination papers. Each question is annotated by trained linguists under five linguistic categories and a factual knowledge category, spanning Grades 1--13 to ensure broad linguistic coverage. We evaluate both closed-source and open-source LLMs using a standardized evaluation framework. Our results show that Gemini 2.5 achieves the highest overall performance, while open-source models lag behind, highlighting the gap in linguistic grounding. Category- and grade-wise analyses reveal that all models perform well on lower-grade questions but show a clear decline as linguistic complexity increases. Further, no strong correlation is observed between a model's overall performance and its ability to identify linguistic categories, suggesting that performance may be driven by exposure rather than genuine understanding.",
        "url": "http://arxiv.org/abs/2511.12387v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12387v1",
        "arxiv_id": "2511.12387v1",
        "authors": [
            "Jeyarajalingam Varsha",
            "Menan Velayuthan",
            "Sumirtha Karunakaran",
            "Rasan Nivethiga",
            "Kengatharaiyer Sarveswaran"
        ],
        "submitted": "2025-11-15 23:41:16",
        "source": "arxiv",
        "comment": "11 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Large Language Models, but it focuses on a specific language (Tamil) and does not directly address query understanding, ranking models, or user behavior modeling. While it touches on the evaluation of LLMs, it is not directly relevant to your core research themes in Information Retrieval and Search technologies."
    },
    {
        "title": "Consistency Is the Key: Detecting Hallucinations in LLM Generated Text By Checking Inconsistencies About Key Facts",
        "abstract": "Large language models (LLMs), despite their remarkable text generation capabilities, often hallucinate and generate text that is factually incorrect and not grounded in real-world knowledge. This poses serious risks in domains like healthcare, finance, and customer support. A typical way to use LLMs is via the APIs provided by LLM vendors where there is no access to model weights or options to fine-tune the model. Existing methods to detect hallucinations in such settings where the model access is restricted or constrained by resources typically require making multiple LLM API calls, increasing latency and API cost. We introduce CONFACTCHECK, an efficient hallucination detection approach that does not leverage any external knowledge base and works on the simple intuition that responses to factual probes within the generated text should be consistent within a single LLM and across different LLMs. Rigorous empirical evaluation on multiple datasets that cover both the generation of factual texts and the open generation shows that CONFACTCHECK can detect hallucinated facts efficiently using fewer resources and achieves higher accuracy scores compared to existing baselines that operate under similar conditions. Our code is available here.",
        "url": "http://arxiv.org/abs/2511.12236v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12236v1",
        "arxiv_id": "2511.12236v1",
        "authors": [
            "Raavi Gupta",
            "Pranav Hari Panicker",
            "Sumit Bhatia",
            "Ganesh Ramakrishnan"
        ],
        "submitted": "2025-11-15 14:33:02",
        "source": "arxiv",
        "comment": "To appear at International Joint Conference on Natural Language Processing & Asia-Pacific Chapter of the Association for Computational Linguistics (IJCNLP-AACL), 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Large Language Models (LLMs), but it does not directly focus on Information Retrieval (IR) or Search technologies. The paper's emphasis on detecting hallucinations in LLM-generated text is relevant to your interests in deep semantic understanding, but it is not a central match for your primary research focus."
    },
    {
        "title": "Seeing is Believing: Rich-Context Hallucination Detection for MLLMs via Backward Visual Grounding",
        "abstract": "Multimodal Large Language Models (MLLMs) have unlocked powerful cross-modal capabilities, but still significantly suffer from hallucinations. As such, accurate detection of hallucinations in MLLMs is imperative for ensuring their reliability in practical applications. To this end, guided by the principle of \"Seeing is Believing\", we introduce VBackChecker, a novel reference-free hallucination detection framework that verifies the consistency of MLLMgenerated responses with visual inputs, by leveraging a pixellevel Grounding LLM equipped with reasoning and referring segmentation capabilities. This reference-free framework not only effectively handles rich-context scenarios, but also offers interpretability. To facilitate this, an innovative pipeline is accordingly designed for generating instruction-tuning data (R-Instruct), featuring rich-context descriptions, grounding masks, and hard negative samples. We further establish R^2 -HalBench, a new hallucination benchmark for MLLMs, which, unlike previous benchmarks, encompasses real-world, rich-context descriptions from 18 MLLMs with high-quality annotations, spanning diverse object-, attribute, and relationship-level details. VBackChecker outperforms prior complex frameworks and achieves state-of-the-art performance on R^2 -HalBench, even rivaling GPT-4o's capabilities in hallucination detection. It also surpasses prior methods in the pixel-level grounding task, achieving over a 10% improvement. All codes, data, and models are available at https://github.com/PinxueGuo/VBackChecker.",
        "url": "http://arxiv.org/abs/2511.12140v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12140v1",
        "arxiv_id": "2511.12140v1",
        "authors": [
            "Pinxue Guo",
            "Chongruo Wu",
            "Xinyu Zhou",
            "Lingyi Hong",
            "Zhaoyu Chen",
            "Jinglun Li",
            "Kaixun Jiang",
            "Sen-ching Samson Cheung",
            "Wei Zhang",
            "Wenqiang Zhang"
        ],
        "submitted": "2025-11-15 10:11:13",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on hallucination detection in Multimodal Large Language Models (MLLMs) using visual inputs, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves multimodal capabilities, the context is more aligned with computer vision and multimodal understanding rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "AI-Salesman: Towards Reliable Large Language Model Driven Telemarketing",
        "abstract": "Goal-driven persuasive dialogue, exemplified by applications like telemarketing, requires sophisticated multi-turn planning and strict factual faithfulness, which remains a significant challenge for even state-of-the-art Large Language Models (LLMs). A lack of task-specific data often limits previous works, and direct LLM application suffers from strategic brittleness and factual hallucination. In this paper, we first construct and release TeleSalesCorpus, the first real-world-grounded dialogue dataset for this domain. We then propose AI-Salesman, a novel framework featuring a dual-stage architecture. For the training stage, we design a Bayesian-supervised reinforcement learning algorithm that learns robust sales strategies from noisy dialogues. For the inference stage, we introduce the Dynamic Outline-Guided Agent (DOGA), which leverages a pre-built script library to provide dynamic, turn-by-turn strategic guidance. Moreover, we design a comprehensive evaluation framework that combines fine-grained metrics for key sales skills with the LLM-as-a-Judge paradigm. Experimental results demonstrate that our proposed AI-Salesman significantly outperforms baseline models in both automatic metrics and comprehensive human evaluations, showcasing its effectiveness in complex persuasive scenarios.",
        "url": "http://arxiv.org/abs/2511.12133v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12133v1",
        "arxiv_id": "2511.12133v1",
        "authors": [
            "Qingyu Zhang",
            "Chunlei Xin",
            "Xuanang Chen",
            "Yaojie Lu",
            "Hongyu Lin",
            "Xianpei Han",
            "Le Sun",
            "Qing Ye",
            "Qianlong Xie",
            "Xingxing Wang"
        ],
        "submitted": "2025-11-15 09:44:42",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of Large Language Models in telemarketing, which involves goal-driven persuasive dialogue and multi-turn planning. While it touches on aspects of query understanding and user behavior modeling, its primary focus is on dialogue systems and persuasive scenarios, which is somewhat related to information retrieval but not a central match to your core research themes."
    },
    {
        "title": "CURE: Cultural Understanding and Reasoning Evaluation - A Framework for \"Thick\" Culture Alignment Evaluation in LLMs",
        "abstract": "Large language models (LLMs) are increasingly deployed in culturally diverse environments, yet existing evaluations of cultural competence remain limited. Existing methods focus on de-contextualized correctness or forced-choice judgments, overlooking the need for cultural understanding and reasoning required for appropriate responses. To address this gap, we introduce a set of benchmarks that, instead of directly probing abstract norms or isolated statements, present models with realistic situational contexts that require culturally grounded reasoning. In addition to the standard Exact Match metric, we introduce four complementary metrics (Coverage, Specificity, Connotation, and Coherence) to capture different dimensions of model's response quality. Empirical analysis across frontier models reveals that thin evaluation systematically overestimates cultural competence and produces unstable assessments with high variance. In contrast, thick evaluation exposes differences in reasoning depth, reduces variance, and provides more stable, interpretable signals of cultural understanding.",
        "url": "http://arxiv.org/abs/2511.12014v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12014v1",
        "arxiv_id": "2511.12014v1",
        "authors": [
            "Truong Vo",
            "Sanmi Koyejo"
        ],
        "submitted": "2025-11-15 03:39:13",
        "source": "arxiv",
        "comment": "7 pages, 5 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat relevant to your research interests in Natural Language Processing (NLP) and Large Language Models (LLMs), but it does not directly align with your primary focus on Information Retrieval (IR), query understanding, ranking models, or user behavior modeling. The paper's focus on cultural understanding and evaluation metrics is interesting, but not directly applicable to your core research themes."
    },
    {
        "title": "Critical or Compliant? The Double-Edged Sword of Reasoning in Chain-of-Thought Explanations",
        "abstract": "Explanations are often promoted as tools for transparency, but they can also foster confirmation bias; users may assume reasoning is correct whenever outputs appear acceptable. We study this double-edged role of Chain-of-Thought (CoT) explanations in multimodal moral scenarios by systematically perturbing reasoning chains and manipulating delivery tones. Specifically, we analyze reasoning errors in vision language models (VLMs) and how they impact user trust and the ability to detect errors. Our findings reveal two key effects: (1) users often equate trust with outcome agreement, sustaining reliance even when reasoning is flawed, and (2) the confident tone suppresses error detection while maintaining reliance, showing that delivery styles can override correctness. These results highlight how CoT explanations can simultaneously clarify and mislead, underscoring the need for NLP systems to provide explanations that encourage scrutiny and critical thinking rather than blind trust. All code will be released publicly.",
        "url": "http://arxiv.org/abs/2511.12001v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12001v1",
        "arxiv_id": "2511.12001v1",
        "authors": [
            "Eunkyu Park",
            "Wesley Hanwen Deng",
            "Vasudha Varadarajan",
            "Mingxi Yan",
            "Gunhee Kim",
            "Maarten Sap",
            "Motahhare Eslami"
        ],
        "submitted": "2025-11-15 02:38:49",
        "source": "arxiv",
        "comment": "Under review; 16 pages, 15 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or related topics. It focuses on Chain-of-Thought explanations in multimodal moral scenarios, which is a topic in Natural Language Processing, but does not align with your core research themes."
    },
    {
        "title": "Improving LLM's Attachment to External Knowledge In Dialogue Generation Tasks Through Entity Anonymization",
        "abstract": "Knowledge graph-based dialogue generation (KG-DG) is a challenging task requiring models to effectively incorporate external knowledge into conversational responses. While large language models (LLMs) have achieved impressive results across various NLP tasks, their ability to utilize external knowledge in KG-DG remains under-explored. We observe that LLMs often rely on internal knowledge, leading to detachment from provided knowledge graphs, even when they are given a flawlessly retrieved knowledge graph. First, we introduce LLM-KAT, an evaluation procedure for measuring knowledge attachment in generated responses. Second, we propose a simple yet effective entity anonymization technique to encourage LLMs to better leverage external knowledge. Experiments on the OpenDialKG dataset demonstrate that our approach improves LLMs' attachment on external knowledge.",
        "url": "http://arxiv.org/abs/2511.11946v1",
        "pdf_url": "https://arxiv.org/pdf/2511.11946v1",
        "arxiv_id": "2511.11946v1",
        "authors": [
            "Hadi Sheikhi",
            "Chenyang Huang",
            "Osmar R. Zaïane"
        ],
        "submitted": "2025-11-14 23:37:35",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on dialogue generation and knowledge graph-based tasks, which are related to NLP. However, it does not directly address information retrieval, query understanding, or ranking models, which are core areas of your research interests. The paper's emphasis on entity anonymization and knowledge attachment in dialogue generation is somewhat relevant to your interests in deep semantic understanding, but it is not a central match."
    },
    {
        "title": "ClinStructor: AI-Powered Structuring of Unstructured Clinical Texts",
        "abstract": "Clinical notes contain valuable, context-rich information, but their unstructured format introduces several challenges, including unintended biases (e.g., gender or racial bias), and poor generalization across clinical settings (e.g., models trained on one EHR system may perform poorly on another due to format differences) and poor interpretability. To address these issues, we present ClinStructor, a pipeline that leverages large language models (LLMs) to convert clinical free-text into structured, task-specific question-answer pairs prior to predictive modeling. Our method substantially enhances transparency and controllability and only leads to a modest reduction in predictive performance (a 2-3% drop in AUC), compared to direct fine-tuning, on the ICU mortality prediction task. ClinStructor lays a strong foundation for building reliable, interpretable, and generalizable machine learning models in clinical environments.",
        "url": "http://arxiv.org/abs/2511.11883v1",
        "pdf_url": "https://arxiv.org/pdf/2511.11883v1",
        "arxiv_id": "2511.11883v1",
        "authors": [
            "Karthikeyan K",
            "Raghuveer Thirukovalluru",
            "David Carlson"
        ],
        "submitted": "2025-11-14 21:21:16",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, particularly in the area of text structuring and question-answer pair generation. However, the focus on clinical text and predictive modeling in healthcare settings is not a central match to your interests in e-commerce and real-time relevance optimization."
    },
    {
        "title": "SGuard-v1: Safety Guardrail for Large Language Models",
        "abstract": "We present SGuard-v1, a lightweight safety guardrail for Large Language Models (LLMs), which comprises two specialized models to detect harmful content and screen adversarial prompts in human-AI conversational settings. The first component, ContentFilter, is trained to identify safety risks in LLM prompts and responses in accordance with the MLCommons hazard taxonomy, a comprehensive framework for trust and safety assessment of AI. The second component, JailbreakFilter, is trained with a carefully designed curriculum over integrated datasets and findings from prior work on adversarial prompting, covering 60 major attack types while mitigating false-unsafe classification. SGuard-v1 is built on the 2B-parameter Granite-3.3-2B-Instruct model that supports 12 languages. We curate approximately 1.4 million training instances from both collected and synthesized data and perform instruction tuning on the base model, distributing the curated data across the two component according to their designated functions. Through extensive evaluation on public and proprietary safety benchmarks, SGuard-v1 achieves state-of-the-art safety performance while remaining lightweight, thereby reducing deployment overhead. SGuard-v1 also improves interpretability for downstream use by providing multi-class safety predictions and their binary confidence scores. We release the SGuard-v1 under the Apache-2.0 License to enable further research and practical deployment in AI safety.",
        "url": "http://arxiv.org/abs/2511.12497v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12497v1",
        "arxiv_id": "2511.12497v1",
        "authors": [
            "JoonHo Lee",
            "HyeonMin Cho",
            "Jaewoong Yun",
            "Hyunjae Lee",
            "JunKyu Lee",
            "Juree Seok"
        ],
        "submitted": "2025-11-16 08:15:54",
        "source": "arxiv",
        "comment": "Technical Report",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on safety guardrails for Large Language Models, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves Natural Language Processing, the context is more centered on AI safety and trust assessment, making it less relevant to the user's primary research interests."
    },
    {
        "title": "DenseAnnotate: Enabling Scalable Dense Caption Collection for Images and 3D Scenes via Spoken Descriptions",
        "abstract": "With the rapid adoption of multimodal large language models (MLLMs) across diverse applications, there is a pressing need for task-centered, high-quality training data. A key limitation of current training datasets is their reliance on sparse annotations mined from the Internet or entered via manual typing that capture only a fraction of an image's visual content. Dense annotations are more valuable but remain scarce. Traditional text-based annotation pipelines are poorly suited for creating dense annotations: typing limits expressiveness, slows annotation speed, and underrepresents nuanced visual features, especially in specialized areas such as multicultural imagery and 3D asset annotation. In this paper, we present DenseAnnotate, an audio-driven online annotation platform that enables efficient creation of dense, fine-grained annotations for images and 3D assets. Annotators narrate observations aloud while synchronously linking spoken phrases to image regions or 3D scene parts. Our platform incorporates speech-to-text transcription and region-of-attention marking. To demonstrate the effectiveness of DenseAnnotate, we conducted case studies involving over 1,000 annotators across two domains: culturally diverse images and 3D scenes. We curate a human-annotated multi-modal dataset of 3,531 images, 898 3D scenes, and 7,460 3D objects, with audio-aligned dense annotations in 20 languages, including 8,746 image captions, 2,000 scene captions, and 19,000 object captions. Models trained on this dataset exhibit improvements of 5% in multilingual, 47% in cultural alignment, and 54% in 3D spatial capabilities. Our results show that our platform offers a feasible approach for future vision-language research and can be applied to various tasks and diverse types of data.",
        "url": "http://arxiv.org/abs/2511.12452v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12452v1",
        "arxiv_id": "2511.12452v1",
        "authors": [
            "Xiaoyu Lin",
            "Aniket Ghorpade",
            "Hansheng Zhu",
            "Justin Qiu",
            "Dea Rrozhani",
            "Monica Lama",
            "Mick Yang",
            "Zixuan Bian",
            "Ruohan Ren",
            "Alan B. Hong",
            "Jiatao Gu",
            "Chris Callison-Burch"
        ],
        "submitted": "2025-11-16 04:46:06",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multimodal large language models and dense annotation of images and 3D scenes, which is not directly related to your primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context is more focused on multimodal data and annotation rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "VoiceCraft-X: Unifying Multilingual, Voice-Cloning Speech Synthesis and Speech Editing",
        "abstract": "We introduce VoiceCraft-X, an autoregressive neural codec language model which unifies multilingual speech editing and zero-shot Text-to-Speech (TTS) synthesis across 11 languages: English, Mandarin, Korean, Japanese, Spanish, French, German, Dutch, Italian, Portuguese, and Polish. VoiceCraft-X utilizes the Qwen3 large language model for phoneme-free cross-lingual text processing and a novel token reordering mechanism with time-aligned text and speech tokens to handle both tasks as a single sequence generation problem. The model generates high-quality, natural-sounding speech, seamlessly creating new audio or editing existing recordings within one framework. VoiceCraft-X shows robust performance in diverse linguistic settings, even with limited per-language data, underscoring the power of unified autoregressive approaches for advancing complex, real-world multilingual speech applications. Audio samples are available at https://zhishengzheng.com/voicecraft-x/.",
        "url": "http://arxiv.org/abs/2511.12347v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12347v1",
        "arxiv_id": "2511.12347v1",
        "authors": [
            "Zhisheng Zheng",
            "Puyuan Peng",
            "Anuj Diwan",
            "Cong Phuoc Huynh",
            "Xiaohang Sun",
            "Zhu Liu",
            "Vimal Bhat",
            "David Harwath"
        ],
        "submitted": "2025-11-15 20:27:25",
        "source": "arxiv",
        "comment": "EMNLP 2025. Demo and code are available at https://zhishengzheng.com/voicecraft-x/",
        "score": 1,
        "keyword_reasons": [
            "Found 'korea' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on speech synthesis and editing, which is not directly related to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language models, the application domain is speech synthesis rather than text understanding or retrieval."
    },
    {
        "title": "CriticSearch: Fine-Grained Credit Assignment for Search Agents via a Retrospective Critic",
        "abstract": "Tool-Integrated Reasoning (TIR) with search engines enables large language models to iteratively retrieve up-to-date external knowledge, enhancing adaptability and generalization in complex question-answering tasks. However, existing search agent pipelines typically depend on reinforcement learning based optimization, which often suffers from sparse outcome rewards, leading to inefficient exploration and unstable training. We introduce CriticSearch, a fine-grained credit-assignment framework that supplies dense, turn-level feedback via a retrospective critic mechanism. During training, a frozen, asymmetric critique LLM retrospectively evaluates each turn using privileged information from the full trajectory and gold answers, converting these assessments into stable, dense rewards that guide policy improvement. Experimental results across diverse multi-hop reasoning benchmarks demonstrate that CriticSearch consistently outperforms existing baselines, achieving faster convergence, improved training stability, and higher performance.",
        "url": "http://arxiv.org/abs/2511.12159v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12159v1",
        "arxiv_id": "2511.12159v1",
        "authors": [
            "Yaocheng Zhang",
            "Haohuan Huang",
            "Zijun Song",
            "Yuanheng Zhu",
            "Qichao Zhang",
            "Zijie Zhao",
            "Dongbin Zhao"
        ],
        "submitted": "2025-11-15 11:06:57",
        "source": "arxiv",
        "comment": "17 pages, 10 figures",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper introduces a new framework for search agents, CriticSearch, which uses a retrospective critic mechanism to provide dense feedback. While it's related to search technologies, it doesn't directly focus on query understanding, ranking models, or user behavior modeling, which are core areas of interest. However, it does involve complex question-answering tasks and multi-hop reasoning, which may be of interest to researchers in the IR and NLP domains."
    },
    {
        "title": "A Reasoning Paradigm for Named Entity Recognition",
        "abstract": "Generative LLMs typically improve Named Entity Recognition (NER) performance through instruction tuning. They excel at generating entities by semantic pattern matching but lack an explicit, verifiable reasoning mechanism. This \"cognitive shortcutting\" leads to suboptimal performance and brittle generalization, especially in zero-shot and lowresource scenarios where reasoning from limited contextual cues is crucial. To address this issue, a reasoning framework is proposed for NER, which shifts the extraction paradigm from implicit pattern matching to explicit reasoning. This framework consists of three stages: Chain of Thought (CoT) generation, CoT tuning, and reasoning enhancement. First, a dataset annotated with NER-oriented CoTs is generated, which contain task-relevant reasoning chains. Then, they are used to tune the NER model to generate coherent rationales before deriving the final answer. Finally, a reasoning enhancement stage is implemented to optimize the reasoning process using a comprehensive reward signal. This stage ensures explicit and verifiable extractions. Experiments show that ReasoningNER demonstrates impressive cognitive ability in the NER task, achieving competitive performance. In zero-shot settings, it achieves state-of-the-art (SOTA) performance, outperforming GPT-4 by 12.3 percentage points on the F1 score. Analytical results also demonstrate its great potential to advance research in reasoningoriented information extraction. Our codes are available at https://github.com/HuiResearch/ReasoningIE.",
        "url": "http://arxiv.org/abs/2511.11978v1",
        "pdf_url": "https://arxiv.org/pdf/2511.11978v1",
        "arxiv_id": "2511.11978v1",
        "authors": [
            "Hui Huang",
            "Yanping Chen",
            "Ruizhang Huang",
            "Chuan Lin",
            "Yongbin Qin"
        ],
        "submitted": "2025-11-15 01:31:43",
        "source": "arxiv",
        "comment": "Accepted at AAAI 2026",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores Named Entity Recognition (NER) using a reasoning framework, which aligns with the NLP aspect of your research interests. However, it is not directly related to your primary focus on Information Retrieval, query understanding, and ranking models. The paper's emphasis on explicit reasoning and cognitive ability is somewhat relevant to user behavior modeling, but the connection is not strong enough to warrant a higher score."
    },
    {
        "title": "Additive Large Language Models for Semi-Structured Text",
        "abstract": "Large Language Models have advanced clinical text classification, but their opaque predictions remain a critical barrier to practical adoption in research and clinical settings where investigators and physicians need to understand which parts of a patient's record drive risk signals. To address this challenge, we introduce \\textbf{CALM}, short for \\textbf{Classification with Additive Large Language Models}, an interpretable framework for semi-structured text where inputs are composed of semantically meaningful components, such as sections of an admission note or question-answer fields from an intake form. CALM predicts outcomes as the additive sum of each component's contribution, making these contributions part of the forward computation itself and enabling faithful explanations at both the patient and population level. The additive structure also enables clear visualizations, such as component-level risk curves similar to those used in generalized additive models, making the learned relationships easier to inspect and communicate. Although CALM expects semi-structured inputs, many clinical documents already have this form, and similar structure can often be automatically extracted from free-text notes. CALM achieves performance comparable to conventional LLM classifiers while improving trust, supporting quality-assurance checks, and revealing clinically meaningful patterns during model development and auditing.",
        "url": "http://arxiv.org/abs/2511.11922v1",
        "pdf_url": "https://arxiv.org/pdf/2511.11922v1",
        "arxiv_id": "2511.11922v1",
        "authors": [
            "Karthikeyan K",
            "Raghuveer Thirukovalluru",
            "David Carlson"
        ],
        "submitted": "2025-11-14 23:06:16",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper introduces an interpretable framework for semi-structured text classification, leveraging large language models. While it touches on query understanding and ranking models indirectly through the concept of 'component-level risk curves', its primary focus is on clinical text classification and interpretability. The connection to information retrieval is not direct, but the use of additive models could be relevant to ranking models."
    },
    {
        "title": "Identifying Imaging Follow-Up in Radiology Reports: A Comparative Analysis of Traditional ML and LLM Approaches",
        "abstract": "Large language models (LLMs) have shown considerable promise in clinical natural language processing, yet few domain-specific datasets exist to rigorously evaluate their performance on radiology tasks. In this work, we introduce an annotated corpus of 6,393 radiology reports from 586 patients, each labeled for follow-up imaging status, to support the development and benchmarking of follow-up adherence detection systems. Using this corpus, we systematically compared traditional machine-learning classifiers, including logistic regression (LR), support vector machines (SVM), Longformer, and a fully fine-tuned Llama3-8B-Instruct, with recent generative LLMs. To evaluate generative LLMs, we tested GPT-4o and the open-source GPT-OSS-20B under two configurations: a baseline (Base) and a task-optimized (Advanced) setting that focused inputs on metadata, recommendation sentences, and their surrounding context. A refined prompt for GPT-OSS-20B further improved reasoning accuracy. Performance was assessed using precision, recall, and F1 scores with 95% confidence intervals estimated via non-parametric bootstrapping. Inter-annotator agreement was high (F1 = 0.846). GPT-4o (Advanced) achieved the best performance (F1 = 0.832), followed closely by GPT-OSS-20B (Advanced; F1 = 0.828). LR and SVM also performed strongly (F1 = 0.776 and 0.775), underscoring that while LLMs approach human-level agreement through prompt optimization, interpretable and resource-efficient models remain valuable baselines.",
        "url": "http://arxiv.org/abs/2511.11867v1",
        "pdf_url": "https://arxiv.org/pdf/2511.11867v1",
        "arxiv_id": "2511.11867v1",
        "authors": [
            "Namu Park",
            "Giridhar Kaushik Ramachandran",
            "Kevin Lybarger",
            "Fei Xia",
            "Ozlem Uzuner",
            "Meliha Yetisgen",
            "Martin Gunn"
        ],
        "submitted": "2025-11-14 20:55:44",
        "source": "arxiv",
        "comment": "Submitted to LREC 2026",
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, and query understanding. While it involves Natural Language Processing (NLP) and machine learning, its focus on radiology reports and clinical natural language processing is outside your primary areas of interest."
    },
    {
        "title": "On the Notion that Language Models Reason",
        "abstract": "Language models (LMs) are said to be exhibiting reasoning, but what does this entail? We assess definitions of reasoning and how key papers in the field of natural language processing (NLP) use the notion and argue that the definitions provided are not consistent with how LMs are trained, process information, and generate new tokens. To illustrate this incommensurability we assume the view that transformer-based LMs implement an \\textit{implicit} finite-order Markov kernel mapping contexts to conditional token distributions. In this view, reasoning-like outputs correspond to statistical regularities and approximate statistical invariances in the learned kernel rather than the implementation of explicit logical mechanisms. This view is illustrative of the claim that LMs are \"statistical pattern matchers\"\" and not genuine reasoners and provides a perspective that clarifies why reasoning-like outputs arise in LMs without any guarantees of logical consistency. This distinction is fundamental to how epistemic uncertainty is evaluated in LMs. We invite a discussion on the importance of how the computational processes of the systems we build and analyze in NLP research are described.",
        "url": "http://arxiv.org/abs/2511.11810v1",
        "pdf_url": "https://arxiv.org/pdf/2511.11810v1",
        "arxiv_id": "2511.11810v1",
        "authors": [
            "Bertram Højer"
        ],
        "submitted": "2025-11-14 19:04:24",
        "source": "arxiv",
        "comment": "Accepted at the 1st Workshop on Epistemic Intelligence in Machine Learning, EurIPS 2025",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and deep semantic understanding. However, its focus on the notion of language models 'reasoning' and the distinction between statistical pattern matching and genuine reasoning is not directly aligned with your primary focus on Information Retrieval, query understanding, and ranking models."
    }
]