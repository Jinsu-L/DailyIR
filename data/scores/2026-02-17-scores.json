[
    {
        "title": "Behavioral Feature Boosting via Substitute Relationships for E-commerce Search",
        "abstract": "On E-commerce platforms, new products often suffer from the cold-start problem: limited interaction data reduces their search visibility and hurts relevance ranking. To address this, we propose a simple yet effective behavior feature boosting method that leverages substitute relationships among products (BFS). BFS identifies substitutes-products that satisfy similar user needs-and aggregates their behavioral signals (e.g., clicks, add-to-carts, purchases, and ratings) to provide a warm start for new items. Incorporating these enriched signals into ranking models mitigates cold-start effects and improves relevance and competitiveness. Experiments on a large E-commerce platform, both offline and online, show that BFS significantly improves search relevance and product discovery for cold-start products. BFS is scalable and practical, improving user experience while increasing exposure for newly launched items in E-commerce search. The BFS-enhanced ranking model has been launched in production and has served customers since 2025.",
        "url": "http://arxiv.org/abs/2602.14502v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14502v1",
        "arxiv_id": "2602.14502v1",
        "authors": [
            "Chaosheng Dong",
            "Michinari Momma",
            "Yijia Wang",
            "Yan Gao",
            "Yi Sun"
        ],
        "submitted": "2026-02-16 06:35:05",
        "source": "arxiv",
        "comment": "5 pages, 5 figures",
        "score": 14,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'click' (score: +2)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of e-commerce search. It explores a novel approach to addressing the cold-start problem, which involves leveraging substitute relationships among products to improve search relevance. While the focus is on e-commerce, the techniques and ideas presented may be applicable to other domains, and the emphasis on real-time relevance optimization aligns with your broader interests in IR and NLP."
    },
    {
        "title": "HyperRAG: Reasoning N-ary Facts over Hypergraphs for Retrieval Augmented Generation",
        "abstract": "Graph-based retrieval-augmented generation (RAG) methods, typically built on knowledge graphs (KGs) with binary relational facts, have shown promise in multi-hop open-domain QA. However, their rigid retrieval schemes and dense similarity search often introduce irrelevant context, increase computational overhead, and limit relational expressiveness. In contrast, n-ary hypergraphs encode higher-order relational facts that capture richer inter-entity dependencies and enable shallower, more efficient reasoning paths. To address this limitation, we propose HyperRAG, a RAG framework tailored for n-ary hypergraphs with two complementary retrieval variants: (i) HyperRetriever learns structural-semantic reasoning over n-ary facts to construct query-conditioned relational chains. It enables accurate factual tracking, adaptive high-order traversal, and interpretable multi-hop reasoning under context constraints. (ii) HyperMemory leverages the LLM's parametric memory to guide beam search, dynamically scoring n-ary facts and entities for query-aware path expansion. Extensive evaluations on WikiTopics (11 closed-domain datasets) and three open-domain QA benchmarks (HotpotQA, MuSiQue, and 2WikiMultiHopQA) validate HyperRAG's effectiveness. HyperRetriever achieves the highest answer accuracy overall, with average gains of 2.95% in MRR and 1.23% in Hits@10 over the strongest baseline. Qualitative analysis further shows that HyperRetriever bridges reasoning gaps through adaptive and interpretable n-ary chain construction, benefiting both open and closed-domain QA.",
        "url": "http://arxiv.org/abs/2602.14470v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14470v1",
        "arxiv_id": "2602.14470v1",
        "authors": [
            "Wen-Sheng Lien",
            "Yu-Kai Chan",
            "Hao-Lung Hsiao",
            "Bo-Kai Ruan",
            "Meng-Fen Chiang",
            "Chien-An Chen",
            "Yi-Ren Yeh",
            "Hong-Han Shuai"
        ],
        "submitted": "2026-02-16 05:15:55",
        "source": "arxiv",
        "comment": "Accepted by The ACM Web Conference 2026 (WWW '26)",
        "score": 13,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval augmented generation' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the areas of query understanding and ranking models. The proposed HyperRAG framework, which uses n-ary hypergraphs to encode higher-order relational facts, is a novel approach to multi-hop open-domain QA, aligning with your focus on deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "DeepMTL2R: A Library for Deep Multi-task Learning to Rank",
        "abstract": "This paper presents DeepMTL2R, an open-source deep learning framework for Multi-task Learning to Rank (MTL2R), where multiple relevance criteria must be optimized simultaneously. DeepMTL2R integrates heterogeneous relevance signals into a unified, context-aware model by leveraging the self-attention mechanism of transformer architectures, enabling effective learning across diverse and potentially conflicting objectives. The framework includes 21 state-of-the-art multi-task learning algorithms and supports multi-objective optimization to identify Pareto-optimal ranking models. By capturing complex dependencies and long-range interactions among items and labels, DeepMTL2R provides a scalable and expressive solution for modern ranking systems and facilitates controlled comparisons across MTL strategies. We demonstrate its effectiveness on a publicly available dataset, report competitive performance, and visualize the resulting trade-offs among objectives. DeepMTL2R is available at \\href{https://github.com/amazon-science/DeepMTL2R}{https://github.com/amazon-science/DeepMTL2R}.",
        "url": "http://arxiv.org/abs/2602.14519v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14519v1",
        "arxiv_id": "2602.14519v1",
        "authors": [
            "Chaosheng Dong",
            "Peiyao Xiao",
            "Yijia Wang",
            "Kaiyi Ji"
        ],
        "submitted": "2026-02-16 07:11:38",
        "source": "arxiv",
        "comment": null,
        "score": 12,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'learning to rank' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 9,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in Learning to Rank and multi-task learning. The focus on deep semantic understanding and real-time relevance optimization aligns with your goals. The use of transformer architectures and self-attention mechanisms is also a key aspect of your interests in NLP and query understanding."
    },
    {
        "title": "Intent-Driven Dynamic Chunking: Segmenting Documents to Reflect Predicted Information Needs",
        "abstract": "Breaking long documents into smaller segments is a fundamental challenge in information retrieval. Whether for search engines, question-answering systems, or retrieval-augmented generation (RAG), effective segmentation determines how well systems can locate and return relevant information. However, traditional methods, such as fixed-length or coherence-based segmentation, ignore user intent, leading to chunks that split answers or contain irrelevant noise. We introduce Intent-Driven Dynamic Chunking (IDC), a novel approach that uses predicted user queries to guide document segmentation. IDC leverages a Large Language Model to generate likely user intents for a document and then employs a dynamic programming algorithm to find the globally optimal chunk boundaries. This represents a novel application of DP to intent-aware segmentation that avoids greedy pitfalls. We evaluated IDC on six diverse question-answering datasets, including news articles, Wikipedia, academic papers, and technical documentation. IDC outperformed traditional chunking strategies on five datasets, improving top-1 retrieval accuracy by 5% to 67%, and matched the best baseline on the sixth. Additionally, IDC produced 40-60% fewer chunks than baseline methods while achieving 93-100% answer coverage. These results demonstrate that aligning document structure with anticipated information needs significantly boosts retrieval performance, particularly for long and heterogeneous documents.",
        "url": "http://arxiv.org/abs/2602.14784v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14784v1",
        "arxiv_id": "2602.14784v1",
        "authors": [
            "Christos Koutsiaris"
        ],
        "submitted": "2026-02-16 14:32:18",
        "source": "arxiv",
        "comment": "8 pages, 4 figures. Code available at https://github.com/unseen1980/IDC",
        "score": 11,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper aligns well with your research interests in Information Retrieval, particularly in query understanding and ranking models. The novel approach of Intent-Driven Dynamic Chunking for segmenting documents based on predicted user queries is relevant to your focus on deep semantic understanding and real-time relevance optimization. However, the specific application to question-answering systems and retrieval-augmented generation may not be a central match to your primary focus on e-commerce and general IR."
    },
    {
        "title": "Learning User Interests via Reasoning and Distillation for Cross-Domain News Recommendation",
        "abstract": "News recommendation plays a critical role in online news platforms by helping users discover relevant content. Cross-domain news recommendation further requires inferring user's underlying information needs from heterogeneous signals that often extend beyond direct news consumption. A key challenge lies in moving beyond surface-level behaviors to capture deeper, reusable user interests while maintaining scalability in large-scale production systems. In this paper, we present a reinforcement learning framework that trains large language models to generate high-quality lists of interest-driven news search queries from cross-domain user signals. We formulate query-list generation as a policy optimization problem and employ GRPO with multiple reward signals. We systematically study two compute dimensions: inference-time sampling and model capacity, and empirically observe consistent improvements with increased compute that exhibit scaling-like behavior. Finally, we perform on-policy distillation to transfer the learned policy from a large, compute-intensive teacher to a compact student model suitable for scalable deployment. Extensive offline experiments, ablation studies and large-scale online A/B tests in a production news recommendation system demonstrate consistent gains in both interest modeling quality and downstream recommendation performance.",
        "url": "http://arxiv.org/abs/2602.15005v1",
        "pdf_url": "https://arxiv.org/pdf/2602.15005v1",
        "arxiv_id": "2602.15005v1",
        "authors": [
            "Mengdan Zhu",
            "Yufan Zhao",
            "Tao Di",
            "Yulan Yan",
            "Liang Zhao"
        ],
        "submitted": "2026-02-16 18:45:40",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper focuses on cross-domain news recommendation, which involves query understanding and user behavior modeling, aligning with your interests in Information Retrieval and Search technologies. However, the primary focus is on recommender systems rather than ranking models or deep semantic understanding, which are your core research themes."
    },
    {
        "title": "DRAMA: Domain Retrieval using Adaptive Module Allocation",
        "abstract": "Neural models are increasingly used in Web-scale Information Retrieval (IR). However, relying on these models introduces substantial computational and energy requirements, leading to increasing attention toward their environmental cost and the sustainability of large-scale deployments. While neural IR models deliver high retrieval effectiveness, their scalability is constrained in multi-domain scenarios, where training and maintaining domain-specific models is inefficient and achieving robust cross-domain generalisation within a unified model remains difficult. This paper introduces DRAMA (Domain Retrieval using Adaptive Module Allocation), an energy- and parameter-efficient framework designed to reduce the environmental footprint of neural retrieval. DRAMA integrates domain-specific adapter modules with a dynamic gating mechanism that selects the most relevant domain knowledge for each query. New domains can be added efficiently through lightweight adapter training, avoiding full model retraining. We evaluate DRAMA on multiple Web retrieval benchmarks covering different domains. Our extensive evaluation shows that DRAMA achieves comparable effectiveness to domain-specific models while using only a fraction of their parameters and computational resources. These findings show that energy-aware model design can significantly improve scalability and sustainability in neural IR.",
        "url": "http://arxiv.org/abs/2602.14960v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14960v1",
        "arxiv_id": "2602.14960v1",
        "authors": [
            "Pranav Kasela",
            "Marco Braga",
            "Ophir Frieder",
            "Nazli Goharian",
            "Gabriella Pasi",
            "Raffaele Perego"
        ],
        "submitted": "2026-02-16 17:38:24",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to Information Retrieval, particularly in the context of neural models and scalability. The focus on energy efficiency and sustainability aligns with the user's interests in real-time relevance optimization. However, the paper's emphasis on domain adaptation and adapter modules, while related to query understanding, is not the user's primary focus."
    },
    {
        "title": "Tool-Aware Planning in Contact Center AI: Evaluating LLMs through Lineage-Guided Query Decomposition",
        "abstract": "We present a domain-grounded framework and benchmark for tool-aware plan generation in contact centers, where answering a query for business insights, our target use case, requires decomposing it into executable steps over structured tools (Text2SQL (T2S)/Snowflake) and unstructured tools (RAG/transcripts) with explicit depends_on for parallelism. Our contributions are threefold: (i) a reference-based plan evaluation framework operating in two modes - a metric-wise evaluator spanning seven dimensions (e.g., tool-prompt alignment, query adherence) and a one-shot evaluator; (ii) a data curation methodology that iteratively refines plans via an evaluator->optimizer loop to produce high-quality plan lineages (ordered plan revisions) while reducing manual effort; and (iii) a large-scale study of 14 LLMs across sizes and families for their ability to decompose queries into step-by-step, executable, and tool-assigned plans, evaluated under prompts with and without lineage. Empirically, LLMs struggle on compound queries and on plans exceeding 4 steps (typically 5-15); the best total metric score reaches 84.8% (Claude-3-7-Sonnet), while the strongest one-shot match rate at the \"A+\" tier (Extremely Good, Very Good) is only 49.75% (o3-mini). Plan lineage yields mixed gains overall but benefits several top models and improves step executability for many. Our results highlight persistent gaps in tool-understanding, especially in tool-prompt alignment and tool-usage completeness, and show that shorter, simpler plans are markedly easier. The framework and findings provide a reproducible path for assessing and improving agentic planning with tools for answering data-analysis queries in contact-center settings.",
        "url": "http://arxiv.org/abs/2602.14955v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14955v1",
        "arxiv_id": "2602.14955v1",
        "authors": [
            "Varun Nathan",
            "Shreyas Guha",
            "Ayush Kumar"
        ],
        "submitted": "2026-02-16 17:36:05",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of Large Language Models (LLMs) in contact center AI, specifically in decomposing queries into executable steps over structured and unstructured tools. While it touches on query understanding and tool-aware planning, the focus is more on the evaluation and optimization of LLMs rather than ranking models or user behavior modeling, making it somewhat related but not a central match to your research interests."
    },
    {
        "title": "Additive Control Variates Dominate Self-Normalisation in Off-Policy Evaluation",
        "abstract": "Off-policy evaluation (OPE) is essential for assessing ranking and recommendation systems without costly online interventions. Self-Normalised Inverse Propensity Scoring (SNIPS) is a standard tool for variance reduction in OPE, leveraging a multiplicative control variate. Recent advances in off-policy learning suggest that additive control variates (baseline corrections) may offer superior performance, yet theoretical guarantees for evaluation are lacking. This paper provides a definitive answer: we prove that $Î²^\\star$-IPS, an estimator with an optimal additive baseline, asymptotically dominates SNIPS in Mean Squared Error. By analytically decomposing the variance gap, we show that SNIPS is asymptotically equivalent to using a specific -- but generally sub-optimal -- additive baseline. Our results theoretically justify shifting from self-normalisation to optimal baseline corrections for both ranking and recommendation.",
        "url": "http://arxiv.org/abs/2602.14914v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14914v1",
        "arxiv_id": "2602.14914v1",
        "authors": [
            "Olivier Jeunen",
            "Shashank Gupta"
        ],
        "submitted": "2026-02-16 16:49:23",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'nips' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is primarily focused on off-policy evaluation and control variates in the context of ranking and recommendation systems, which is somewhat related to information retrieval. However, the paper's emphasis on theoretical guarantees and variance reduction does not directly align with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Orcheo: A Modular Full-Stack Platform for Conversational Search",
        "abstract": "Conversational search (CS) requires a complex software engineering pipeline that integrates query reformulation, ranking, and response generation. CS researchers currently face two barriers: the lack of a unified framework for efficiently sharing contributions with the community, and the difficulty of deploying end-to-end prototypes needed for user evaluation. We introduce Orcheo, an open-source platform designed to bridge this gap. Orcheo offers three key advantages: (i) A modular architecture promotes component reuse through single-file node modules, facilitating sharing and reproducibility in CS research; (ii) Production-ready infrastructure bridges the prototype-to-system gap via dual execution modes, secure credential management, and execution telemetry, with built-in AI coding support that lowers the learning curve; (iii) Starter-kit assets include 50+ off-the-shelf components for query understanding, ranking, and response generation, enabling the rapid bootstrapping of complete CS pipelines. We describe the framework architecture and validate Orcheo's utility through case studies that highlight modularity and ease of use. Orcheo is released as open source under the MIT License at https://github.com/ShaojieJiang/orcheo.",
        "url": "http://arxiv.org/abs/2602.14710v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14710v1",
        "arxiv_id": "2602.14710v1",
        "authors": [
            "Shaojie Jiang",
            "Svitlana Vakulenko",
            "Maarten de Rijke"
        ],
        "submitted": "2026-02-16 12:56:57",
        "source": "arxiv",
        "comment": "Under review at SIGIR 2026",
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to Information Retrieval, particularly conversational search, which aligns with your interests in query understanding and ranking models. The introduction of Orcheo, a modular platform for CS, also touches on user behavior modeling and real-time relevance optimization. However, the focus on software engineering and deployment aspects slightly reduces its relevance to your core research themes."
    },
    {
        "title": "High Precision Audience Expansion via Extreme Classification in a Two-Sided Marketplace",
        "abstract": "Airbnb search must balance a worldwide, highly varied supply of homes with guests whose location, amenity, style, and price expectations differ widely. Meeting those expectations hinges on an efficient retrieval stage that surfaces only the listings a guest might realistically book, before resource intensive ranking models are applied to determine the best results. Unlike many recommendation engines, our system faces a distinctive challenge, location retrieval, that sits upstream of ranking and determines which geographic areas are queried in order to filter inventory to a candidate set. The preexisting approach employs a deep bayesian bandit based system to predict a rectangular retrieval bounds area that can be used for filtering. The purpose of this paper is to demonstrate the methodology, challenges, and impact of rearchitecting search to retrieve from the subset of most bookable high precision rectangular map cells defined by dividing the world into 25M uniform cells.",
        "url": "http://arxiv.org/abs/2602.14358v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14358v1",
        "arxiv_id": "2602.14358v1",
        "authors": [
            "Dillon Davis",
            "Huiji Gao",
            "Thomas Legrand",
            "Juan Manuel Caicedo Carvajal",
            "Malay Haldar",
            "Kedar Bellare",
            "Moutupsi Paul",
            "Soumyadip Banerjee",
            "Liwei He",
            "Stephanie Moyerman",
            "Sanjeev Katariya"
        ],
        "submitted": "2026-02-16 00:23:38",
        "source": "arxiv",
        "comment": "KDD TSMO 2025: https://sites.google.com/view/tsmo2025/accepted-papers?authuser=0",
        "score": 8,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses search technologies in the context of a two-sided marketplace, specifically addressing location retrieval challenges in Airbnb search. While it touches on information retrieval and ranking models, the focus is more on the pre-existing approach and rearchitecting search rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest. The connection to e-commerce is also relevant, but the paper's scope is narrower than expected."
    },
    {
        "title": "Whom to Query for What: Adaptive Group Elicitation via Multi-Turn LLM Interactions",
        "abstract": "Eliciting information to reduce uncertainty about latent group-level properties from surveys and other collective assessments requires allocating limited questioning effort under real costs and missing data. Although large language models enable adaptive, multi-turn interactions in natural language, most existing elicitation methods optimize what to ask with a fixed respondent pool, and do not adapt respondent selection or leverage population structure when responses are partial or incomplete. To address this gap, we study adaptive group elicitation, a multi-round setting where an agent adaptively selects both questions and respondents under explicit query and participation budgets. We propose a theoretically grounded framework that combines (i) an LLM-based expected information gain objective for scoring candidate questions with (ii) heterogeneous graph neural network propagation that aggregates observed responses and participant attributes to impute missing responses and guide per-round respondent selection. This closed-loop procedure queries a small, informative subset of individuals while inferring population-level responses via structured similarity. Across three real-world opinion datasets, our method consistently improves population-level response prediction under constrained budgets, including a >12% relative gain on CES at a 10% respondent budget.",
        "url": "http://arxiv.org/abs/2602.14279v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14279v1",
        "arxiv_id": "2602.14279v1",
        "authors": [
            "Ruomeng Ding",
            "Tianwei Gao",
            "Thomas P. Zollo",
            "Eitan Bachmat",
            "Richard Zemel",
            "Zhun Deng"
        ],
        "submitted": "2026-02-15 19:05:34",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores adaptive group elicitation using multi-turn LLM interactions, which is somewhat related to information retrieval and query understanding. However, the focus on group elicitation and respondent selection is not directly aligned with the user's core research themes in IR and search technologies. The use of LLMs and graph neural networks is an interesting aspect, but it does not strongly connect to the user's primary interests in ranking models, user behavior modeling, and deep semantic understanding."
    },
    {
        "title": "Differentially Private Retrieval-Augmented Generation",
        "abstract": "Retrieval-augmented generation (RAG) is a widely used framework for reducing hallucinations in large language models (LLMs) on domain-specific tasks by retrieving relevant documents from a database to support accurate responses. However, when the database contains sensitive corpora, such as medical records or legal documents, RAG poses serious privacy risks by potentially exposing private information through its outputs. Prior work has demonstrated that one can practically craft adversarial prompts that force an LLM to regurgitate the augmented contexts. A promising direction is to integrate differential privacy (DP), a privacy notion that offers strong formal guarantees, into RAG systems. However, naively applying DP mechanisms into existing systems often leads to significant utility degradation. Particularly for RAG systems, DP can reduce the usefulness of the augmented contexts leading to increase risk of hallucination from the LLMs. Motivated by these challenges, we present DP-KSA, a novel privacy-preserving RAG algorithm that integrates DP using the propose-test-release paradigm. DP-KSA follows from a key observation that most question-answering (QA) queries can be sufficiently answered with a few keywords. Hence, DP-KSA first obtains an ensemble of relevant contexts, each of which will be used to generate a response from an LLM. We utilize these responses to obtain the most frequent keywords in a differentially private manner. Lastly, the keywords are augmented into the prompt for the final output. This approach effectively compresses the semantic space while preserving both utility and privacy. We formally show that DP-KSA provides formal DP guarantees on the generated output with respect to the RAG database. We evaluate DP-KSA on two QA benchmarks using three instruction-tuned LLMs, and our empirical results demonstrate that DP-KSA achieves a strong privacy-utility tradeoff.",
        "url": "http://arxiv.org/abs/2602.14374v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14374v1",
        "arxiv_id": "2602.14374v1",
        "authors": [
            "Tingting Tang",
            "James Flemings",
            "Yongqin Wang",
            "Murali Annavaram"
        ],
        "submitted": "2026-02-16 00:52:57",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your interests in Information Retrieval, particularly in the context of query understanding and ranking models. The paper's focus on retrieval-augmented generation and its application to question-answering tasks aligns with your research themes. However, the paper's primary focus on differential privacy and its application to RAG systems is somewhat tangential to your interests in user behavior modeling and click models."
    },
    {
        "title": "Hunt Globally: Wide Search AI Agents for Drug Asset Scouting in Investing, Business Development, and Competitive Intelligence",
        "abstract": "Bio-pharmaceutical innovation has shifted: many new drug assets now originate outside the United States and are disclosed primarily via regional, non-English channels. Recent data suggests that over 85% of patent filings originate outside the U.S., with China accounting for nearly half of the global total. A growing share of scholarly output is also non-U.S. Industry estimates put China at 30% of global drug development, spanning 1,200+ novel candidates. In this high-stakes environment, failing to surface \"under-the-radar\" assets creates multi-billion-dollar risk for investors and business development teams, making asset scouting a coverage-critical competition where speed and completeness drive value. Yet today's Deep Research AI agents still lag human experts in achieving high recall discovery across heterogeneous, multilingual sources without hallucination. We propose a benchmarking methodology for drug asset scouting and a tuned, tree-based self-learning Bioptic Agent aimed at complete, non-hallucinated scouting. We construct a challenging completeness benchmark using a multilingual multi-agent pipeline: complex user queries paired with ground-truth assets that are largely outside U.S.-centric radar. To reflect real-deal complexity, we collected screening queries from expert investors, BD, and VC professionals and used them as priors to conditionally generate benchmark queries. For grading, we use LLM-as-judge evaluation calibrated to expert opinions. On this benchmark, our Bioptic Agent achieves 79.7% F1 score, outperforming Claude Opus 4.6 (56.2%), Gemini 3 Pro + Deep Research (50.6%), OpenAI GPT-5.2 Pro (46.6%), Perplexity Deep Research (44.2%), and Exa Websets (26.9%). Performance improves steeply with additional compute, supporting the view that more compute yields better results.",
        "url": "http://arxiv.org/abs/2602.15019v2",
        "pdf_url": "https://arxiv.org/pdf/2602.15019v2",
        "arxiv_id": "2602.15019v2",
        "authors": [
            "Alisa Vinogradova",
            "Vlad Vinogradov",
            "Luba Greenwood",
            "Ilya Yasny",
            "Dmitry Kobyzev",
            "Shoman Kasbekar",
            "Kong Nguyen",
            "Dmitrii Radkevich",
            "Roman Doronin",
            "Andrey Doronichev"
        ],
        "submitted": "2026-02-16 18:57:49",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves a search AI agent and a benchmarking methodology, the context is specific to drug asset scouting and not applicable to the user's areas of interest."
    },
    {
        "title": "The Wikidata Query Logs Dataset",
        "abstract": "We present the Wikidata Query Logs (WDQL) dataset, a dataset consisting of 200k question-query pairs over the Wikidata knowledge graph. It is over 6x larger than the largest existing Wikidata datasets of similar format without relying on template-generated queries. Instead, we construct it using real-world SPARQL queries sent to the Wikidata Query Service and generate questions for them. Since these log-based queries are anonymized, and therefore often do not produce results, a significant amount of effort is needed to convert them back into meaningful SPARQL queries. To achieve this, we present an agent-based method that iteratively de-anonymizes, cleans, and verifies queries against Wikidata while also generating corresponding natural-language questions. We demonstrate the dataset's benefit for training question-answering methods. All WDQL assets, as well as the agent code, are publicly available under a permissive license.",
        "url": "http://arxiv.org/abs/2602.14594v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14594v1",
        "arxiv_id": "2602.14594v1",
        "authors": [
            "Sebastian Walter",
            "Hannah Bast"
        ],
        "submitted": "2026-02-16 09:49:44",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a dataset for question-query pairs over the Wikidata knowledge graph, which is relevant to Information Retrieval and Natural Language Processing. However, the focus is on question-answering methods rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest. The connection to search technologies is indirect, but the dataset could be useful for training question-answering models."
    },
    {
        "title": "Query as Anchor: Scenario-Adaptive User Representation via Large Language Model",
        "abstract": "Industrial-scale user representation learning requires balancing robust universality with acute task-sensitivity. However, existing paradigms primarily yield static, task-agnostic embeddings that struggle to reconcile the divergent requirements of downstream scenarios within unified vector spaces. Furthermore, heterogeneous multi-source data introduces inherent noise and modality conflicts, degrading representation. We propose Query-as-Anchor, a framework shifting user modeling from static encoding to dynamic, query-aware synthesis. To empower Large Language Models (LLMs) with deep user understanding, we first construct UserU, an industrial-scale pre-training dataset that aligns multi-modal behavioral sequences with user understanding semantics, and our Q-Anchor Embedding architecture integrates hierarchical coarse-to-fine encoders into dual-tower LLMs via joint contrastive-autoregressive optimization for query-aware user representation. To bridge the gap between general pre-training and specialized business logic, we further introduce Cluster-based Soft Prompt Tuning to enforce discriminative latent structures, effectively aligning model attention with scenario-specific modalities. For deployment, anchoring queries at sequence termini enables KV-cache-accelerated inference with negligible incremental latency. Evaluations on 10 Alipay industrial benchmarks show consistent SOTA performance, strong scalability, and efficient deployment. Large-scale online A/B testing in Alipay's production system across two real-world scenarios further validates its practical effectiveness. Our code is prepared for public release and will be available at: https://github.com/JhCircle/Q-Anchor.",
        "url": "http://arxiv.org/abs/2602.14492v2",
        "pdf_url": "https://arxiv.org/pdf/2602.14492v2",
        "arxiv_id": "2602.14492v2",
        "authors": [
            "Jiahao Yuan",
            "Yike Xu",
            "Jinyong Wen",
            "Baokun Wang",
            "Ziyi Gao",
            "Xiaotong Lin",
            "Yun Liu",
            "Xing Fu",
            "Yu Cheng",
            "Yongchao Liu",
            "Weiqiang Wang",
            "Zhongle Xie"
        ],
        "submitted": "2026-02-16 06:09:31",
        "source": "arxiv",
        "comment": "15 pages, 12 figures",
        "score": 6,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper aligns well with your research interests in Information Retrieval, particularly in query understanding and user behavior modeling. The proposed Query-as-Anchor framework leverages Large Language Models for dynamic, query-aware user representation, which is a relevant and timely topic in the field. However, the focus on user representation learning and large-scale pre-training datasets is somewhat tangential to your primary interest in real-time relevance optimization and deep semantic understanding."
    },
    {
        "title": "Text Style Transfer with Parameter-efficient LLM Finetuning and Round-trip Translation",
        "abstract": "This paper proposes a novel method for Text Style Transfer (TST) based on parameter-efficient fine-tuning of Large Language Models (LLMs). Addressing the scarcity of parallel corpora that map between styles, the study employs roundtrip translation to synthesize such parallel datasets from monolingual corpora. This approach creates 'neutralized' text devoid of stylistic attributes, essentially creating a shared input style at training-time and inference-time. Experimental results demonstrate consistent superiority of this method over zero-shot prompting and fewshot ICL techniques measured by BLEU scores and style accuracy scores across four investigated domains. Furthermore, the integration of retrieval-augmented generation (RAG) for terminology and name knowledge enhances robustness and stylistic consistency.",
        "url": "http://arxiv.org/abs/2602.15013v1",
        "pdf_url": "https://arxiv.org/pdf/2602.15013v1",
        "arxiv_id": "2602.15013v1",
        "authors": [
            "Ruoxi Liu",
            "Philipp Koehn"
        ],
        "submitted": "2026-02-16 18:52:43",
        "source": "arxiv",
        "comment": "9 pages, 5 figures, 4 tables",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is loosely relevant to your research interests in Natural Language Processing (NLP) and related topics, particularly in the area of text style transfer. However, it does not directly align with your primary focus on Information Retrieval (IR), query understanding, ranking models, or user behavior modeling. The paper's emphasis on parameter-efficient fine-tuning of Large Language Models (LLMs) and round-trip translation is an interesting aspect, but it does not seem to be a central match for your research themes."
    },
    {
        "title": "Testimole-Conversational: A 30-Billion-Word Italian Discussion Board Corpus (1996-2024) for Language Modeling and Sociolinguistic Research",
        "abstract": "We present \"Testimole-conversational\" a massive collection of discussion boards messages in the Italian language. The large size of the corpus, more than 30B word-tokens (1996-2024), renders it an ideal dataset for native Italian Large Language Models'pre-training. Furthermore, discussion boards' messages are a relevant resource for linguistic as well as sociological analysis. The corpus captures a rich variety of computer-mediated communication, offering insights into informal written Italian, discourse dynamics, and online social interaction in wide time span. Beyond its relevance for NLP applications such as language modelling, domain adaptation, and conversational analysis, it also support investigations of language variation and social phenomena in digital communication. The resource will be made freely available to the research community.",
        "url": "http://arxiv.org/abs/2602.14819v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14819v1",
        "arxiv_id": "2602.14819v1",
        "authors": [
            "Matteo Rinaldi",
            "Rossella Varvara",
            "Viviana Patti"
        ],
        "submitted": "2026-02-16 15:12:46",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be primarily focused on language modeling and sociolinguistic research using a large Italian discussion board corpus. While it touches on NLP applications, it does not seem to directly relate to the user's core research themes in Information Retrieval, query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Precedent-Informed Reasoning: Mitigating Overthinking in Large Reasoning Models via Test-Time Precedent Learning",
        "abstract": "Reasoning in Large Language Models (LLMs) often suffers from inefficient long chain-of-thought traces with redundant self-exploration and validation, which inflate computational costs and even degrade performance. Inspired by human reasoning patterns where people solve new problems by leveraging past related cases to constrain search spaces and reduce trial-and-error, we propose Precedent Informed Reasoning (PIR) transforming LRMs'reasoning paradigm from exhaustive self-exploration to guided learning from precedents. PIR addresses two key challenges: what precedents to adopt and how to utilize them. First, Adaptive Precedent Selection (APS) constructs, for each question and LRM, a compact set of precedents that are both semantically related and informative for the model. It ranks examples by a joint score with semantic similarity and model perplexity, then adapts the amount of precedents to maximize perplexity reduction. Second, Test-time Experience Internalization (TEI) is treated as the test-time learning on precedent-informed instruction, updating lightweight adapters to internalize solution patterns and use them as a prior during subsequent reasoning. Experiments across mathematical reasoning, scientific QA, and code generation demonstrate that PIR consistently shortens reasoning traces while maintaining or improving final accuracy across LLMs, yielding outstanding accuracy-efficiency trade-offs.",
        "url": "http://arxiv.org/abs/2602.14451v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14451v1",
        "arxiv_id": "2602.14451v1",
        "authors": [
            "Qianyue Wang",
            "Jinwu Hu",
            "Huanxiang Lin",
            "Bolin Chen",
            "Zhiquan Wen",
            "Yaofo Chen",
            "Yu Rong",
            "Mingkui Tan"
        ],
        "submitted": "2026-02-16 04:17:46",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores reasoning in Large Language Models, proposing a method to mitigate overthinking by leveraging past related cases. While it touches on semantic understanding and model optimization, it does not directly address information retrieval or search technologies. The focus on precedent-informed reasoning and test-time learning is somewhat related to query understanding and ranking models, but it is not a central match for your research interests."
    },
    {
        "title": "A Geometric Analysis of Small-sized Language Model Hallucinations",
        "abstract": "Hallucinations -- fluent but factually incorrect responses -- pose a major challenge to the reliability of language models, especially in multi-step or agentic settings.\n  This work investigates hallucinations in small-sized LLMs through a geometric perspective, starting from the hypothesis that when models generate multiple responses to the same prompt, genuine ones exhibit tighter clustering in the embedding space, we prove this hypothesis and, leveraging this geometrical insight, we also show that it is possible to achieve a consistent level of separability. This latter result is used to introduce a label-efficient propagation method that classifies large collections of responses from just 30-50 annotations, achieving F1 scores above 90%.\n  Our findings, framing hallucinations from a geometric perspective in the embedding space, complement traditional knowledge-centric and single-response evaluation paradigms, paving the way for further research.",
        "url": "http://arxiv.org/abs/2602.14778v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14778v1",
        "arxiv_id": "2602.14778v1",
        "authors": [
            "Emanuele Ricco",
            "Elia Onofri",
            "Lorenzo Cima",
            "Stefano Cresci",
            "Roberto Di Pietro"
        ],
        "submitted": "2026-02-16 14:29:55",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores language model hallucinations from a geometric perspective, which is somewhat related to query understanding and ranking models in Information Retrieval. However, its focus on language models and hallucinations is not directly aligned with the user's primary research themes, but it does touch on related topics in NLP."
    },
    {
        "title": "GradMAP: Faster Layer Pruning with Gradient Metric and Projection Compensation",
        "abstract": "Large Language Models (LLMs) exhibit strong reasoning abilities, but their high computational costs limit their practical deployment. Recent studies reveal significant redundancy in LLMs layers, making layer pruning an active research topic. Layer pruning research primarily focuses on two aspects: measuring layer importance and recovering performance after pruning. Unfortunately, the present works fail to simultaneously maintain pruning performance and efficiency. In this study, we propose GradMAP, a faster layer pruning method with \\textbf{Grad}ient \\textbf{M}etric \\textbf{A}nd \\textbf{P}rojection compensation, which consists of two stages. In the first stage, we introduce a novel metric based on gradient magnitudes, enabling a global assessment of layer importance. Note that, it requires only a single backward propagation step per pruning decision, substantially enhancing pruning efficiency. In the second stage, we first analyze the layers with the largest mean shift resulting from pruning, and then incorporate a simple yet effective projection compensation matrix to correct this drift in one step. In this way, the degradation of model performance caused by layer pruning is effectively alleviated. Extensive experiments show that GradMAP outperforms previous layer pruning methods in both pruning speed (achieving an average $4\\times$ speedup) and performance.",
        "url": "http://arxiv.org/abs/2602.14649v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14649v1",
        "arxiv_id": "2602.14649v1",
        "authors": [
            "Hao Liu",
            "Guangyan Li",
            "Wensheng Zhang",
            "Yongqiang Tang"
        ],
        "submitted": "2026-02-16 11:14:02",
        "source": "arxiv",
        "comment": "19 pages",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on layer pruning in Large Language Models, which is outside your primary area of Information Retrieval and Search technologies. Although it involves a novel metric based on gradient magnitudes, the topic is more aligned with Deep Learning and Model Optimization rather than your core themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Explainable Token-level Noise Filtering for LLM Fine-tuning Datasets",
        "abstract": "Large Language Models (LLMs) have seen remarkable advancements, achieving state-of-the-art results in diverse applications. Fine-tuning, an important step for adapting LLMs to specific downstream tasks, typically involves further training on corresponding datasets. However, a fundamental discrepancy exists between current fine-tuning datasets and the token-level optimization mechanism of LLMs: most datasets are designed at the sentence-level, which introduces token-level noise, causing negative influence to final performance. In this paper, we propose XTF, an explainable token-level noise filtering framework. XTF decomposes the complex and subtle contributions of token-level data to the fine-tuning process into three distinct and explicit attributes (reasoning importance, knowledge novelty, and task relevance), which can be assessed using scoring methods, and then masks the gradients of selected noisy tokens accordingly to optimize the performance of fine-tuned LLMs. We conduct extensive experiments on three representative downstream tasks (math, code and medicine) across 7 mainstream LLMs. The results demonstrate that XTF can significantly improve downstream performance by up to 13.7% compared to regular fine-tuning. Our work highlights the importance of token-level dataset optimization, and demonstrates the potential of strategies based on attribute decomposition for explaining complex training mechanisms.",
        "url": "http://arxiv.org/abs/2602.14536v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14536v1",
        "arxiv_id": "2602.14536v1",
        "authors": [
            "Yuchen Yang",
            "Wenze Lin",
            "Enhao Huang",
            "Zhixuan Chu",
            "Hongbin Zhou",
            "Lan Tao",
            "Yiming Li",
            "Zhan Qin",
            "Kui Ren"
        ],
        "submitted": "2026-02-16 07:49:33",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Large Language Models (LLMs), but it focuses more on fine-tuning and dataset optimization rather than query understanding, ranking models, or user behavior modeling. The paper's emphasis on token-level noise filtering and attribute decomposition is an interesting aspect, but it doesn't directly align with your core research themes in Information Retrieval and Search technologies."
    },
    {
        "title": "Parameter-Efficient Fine-Tuning of LLMs with Mixture of Space Experts",
        "abstract": "Large Language Models (LLMs) have achieved remarkable progress, with Parameter-Efficient Fine-Tuning (PEFT) emerging as a key technique for downstream task adaptation. However, existing PEFT methods mainly operate in Euclidean space, fundamentally limiting their capacity to capture complex geometric structures inherent in language data. While alternative geometric spaces, like hyperbolic geometries for hierarchical data and spherical manifolds for circular patterns, offer theoretical advantages, forcing representations into a single manifold type ultimately limits expressiveness, even when curvature parameters are learnable. To address this, we propose Mixture of Space (MoS), a unified framework that leverages multiple geometric spaces simultaneously to learn richer, curvature-aware representations. Building on this scheme, we develop MoSLoRA, which extends Low-Rank Adaptation (LoRA) with heterogeneous geometric experts, enabling models to dynamically select or combine appropriate geometric spaces based on input context. Furthermore, to address the computational overhead of frequent manifold switching, we develop a lightweight routing mechanism. Moreover, we provide empirical insights into how curvature optimization impacts training stability and model performance. Our experiments across diverse benchmarks demonstrate that MoSLoRA consistently outperforms strong baselines, achieving up to 5.6% improvement on MATH500 and 15.9% on MAWPS.",
        "url": "http://arxiv.org/abs/2602.14490v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14490v1",
        "arxiv_id": "2602.14490v1",
        "authors": [
            "Buze Zhang",
            "Jinkai Tao",
            "Zilang Zeng",
            "Neil He",
            "Ali Maatouk",
            "Menglin Yang",
            "Rex Ying"
        ],
        "submitted": "2026-02-16 06:07:32",
        "source": "arxiv",
        "comment": "15 pages, 11 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is loosely relevant to your research interests in Natural Language Processing (NLP) and deep semantic understanding, but it primarily focuses on Large Language Models (LLMs) and geometric spaces, which is not a central match for your core research themes in Information Retrieval (IR) and Search technologies."
    },
    {
        "title": "Measuring and Mitigating Post-hoc Rationalization in Reverse Chain-of-Thought Generation",
        "abstract": "Reverse Chain-of-Thought Generation (RCG) synthesizes reasoning traces from query-answer pairs, but runs the risk of producing post-hoc rationalizations: when models can see the answer during generation, the answer serves as a cognitive anchor that shapes the entire explanation. We formalize this phenomenon through a three-level measurement hierarchy: lexical, entropic, and probabilistic anchoring, each captures surface artifacts, entropy dynamics, and latent answer dependence, respectively. We analyze semantic suppression, the intuitive mitigation strategy that instructs models to ignore the answer, to find out its counterproduction: while it reduces lexical overlap, it paradoxically increases entropic and probabilistic anchoring. Drawing on Ironic Process Theory from cognitive psychology, we attribute this failure to active monitoring of the forbidden answer, which inadvertently deepens dependence on it. To break this cycle, we propose Structural Skeleton-guided Reasoning (SSR), a two-phase approach that first generates an answer-invariant functional skeleton structure, then uses this skeleton to guide full trace generation. By redirecting the information flow to structural planning rather than answer monitoring, SSR consistently reduces anchoring across all three levels. We further introduce Distilled SSR (SSR-D), which fine-tunes models on teacher-generated SSR traces to ensure reliable structural adherence. Experiments across open-ended reasoning benchmarks demonstrate that SSR-D achieves up to 10% improvement over suppression baselines while preserving out-of-distribution (OOD) generalization.",
        "url": "http://arxiv.org/abs/2602.14469v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14469v1",
        "arxiv_id": "2602.14469v1",
        "authors": [
            "Guangyue Peng",
            "Zongchao Chen",
            "Wen Luo",
            "Yuntao Wen",
            "Wei Li",
            "Ruixiang Feng",
            "Ran Le",
            "Chen Yang",
            "Zhenwei An",
            "Yang Song",
            "Tao Zhang",
            "Houfeng Wang"
        ],
        "submitted": "2026-02-16 05:13:06",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is primarily focused on Reverse Chain-of-Thought Generation and mitigating post-hoc rationalization in this context, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some aspects of query understanding and semantic understanding, the paper's focus on cognitive psychology and reasoning traces makes it less relevant to the user's interests."
    },
    {
        "title": "Counterfactual Fairness Evaluation of LLM-Based Contact Center Agent Quality Assurance System",
        "abstract": "Large Language Models (LLMs) are increasingly deployed in contact-center Quality Assurance (QA) to automate agent performance evaluation and coaching feedback. While LLMs offer unprecedented scalability and speed, their reliance on web-scale training data raises concerns regarding demographic and behavioral biases that may distort workforce assessment. We present a counterfactual fairness evaluation of LLM-based QA systems across 13 dimensions spanning three categories: Identity, Context, and Behavioral Style. Fairness is quantified using the Counterfactual Flip Rate (CFR), the frequency of binary judgment reversals, and the Mean Absolute Score Difference (MASD), the average shift in coaching or confidence scores across counterfactual pairs. Evaluating 18 LLMs on 3,000 real-world contact center transcripts, we find systematic disparities, with CFR ranging from 5.4% to 13.0% and consistent MASD shifts across confidence, positive, and improvement scores. Larger, more strongly aligned models show lower unfairness, though fairness does not track accuracy. Contextual priming of historical performance induces the most severe degradations (CFR up to 16.4%), while implicit linguistic identity cues remain a persistent bias source. Finally, we analyze the efficacy of fairness-aware prompting, finding that explicit instructions yield only modest improvements in evaluative consistency. Our findings underscore the need for standardized fairness auditing pipelines prior to deploying LLMs in high-stakes workforce evaluation.",
        "url": "http://arxiv.org/abs/2602.14970v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14970v1",
        "arxiv_id": "2602.14970v1",
        "authors": [
            "Kawin Mayilvaghanan",
            "Siddhant Gupta",
            "Ayush Kumar"
        ],
        "submitted": "2026-02-16 17:56:18",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores fairness evaluation in LLM-based contact center agent quality assurance systems, which is somewhat related to information retrieval and search technologies. However, the focus on fairness and bias in language models is more aligned with NLP and data mining, but not directly related to query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Measuring the relatedness between scientific publications using controlled vocabularies",
        "abstract": "Measuring the relatedness between scientific publications is essential in many areas of bibliometrics and science policy. Controlled vocabularies provide a promising basis for measuring relatedness and are widely used in combination with Salton's cosine similarity. The latter is problematic because it only considers exact matches between terms. This article introduces two alternative methods - soft cosine and maximum term similarities - that account for the semantic similarity between non-matching terms. The article compares the accuracy of all three methods using the assignment of publications to topics in the TREC 2006 Genomics Track and the assumption that accurate relatedness measures should assign high relatedness scores to publication pairs within the same topic and low scores to pairs from separate topics. Results show that soft cosine is the most accurate method, while the most widely used version of Salton's cosine is markedly less accurate than the other methods tested. These findings have implications for how controlled vocabularies should be used to measure relatedness.",
        "url": "http://arxiv.org/abs/2602.14755v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14755v1",
        "arxiv_id": "2602.14755v1",
        "authors": [
            "Emil Dolmer Alnor"
        ],
        "submitted": "2026-02-16 13:58:47",
        "source": "arxiv",
        "comment": "Currently under review at Scientometrics (16 February 2026)",
        "score": 2,
        "keyword_reasons": [
            "Found 'trec' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to Information Retrieval, specifically in the area of measuring relatedness between documents, but it focuses on controlled vocabularies and bibliometrics, which is not a central match to the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Robust Bias Evaluation with FilBBQ: A Filipino Bias Benchmark for Question-Answering Language Models",
        "abstract": "With natural language generation becoming a popular use case for language models, the Bias Benchmark for Question-Answering (BBQ) has grown to be an important benchmark format for evaluating stereotypical associations exhibited by generative models. We expand the linguistic scope of BBQ and construct FilBBQ through a four-phase development process consisting of template categorization, culturally aware translation, new template construction, and prompt generation. These processes resulted in a bias test composed of more than 10,000 prompts which assess whether models demonstrate sexist and homophobic prejudices relevant to the Philippine context. We then apply FilBBQ on models trained in Filipino but do so with a robust evaluation protocol that improves upon the reliability and accuracy of previous BBQ implementations. Specifically, we account for models' response instability by obtaining prompt responses across multiple seeds and averaging the bias scores calculated from these distinctly seeded runs. Our results confirm both the variability of bias scores across different seeds and the presence of sexist and homophobic biases relating to emotion, domesticity, stereotyped queer interests, and polygamy. FilBBQ is available via GitHub.",
        "url": "http://arxiv.org/abs/2602.14466v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14466v1",
        "arxiv_id": "2602.14466v1",
        "authors": [
            "Lance Calvin Lim Gamboa",
            "Yue Feng",
            "Mark Lee"
        ],
        "submitted": "2026-02-16 05:03:15",
        "source": "arxiv",
        "comment": "Accepted in LREC 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your core research interests in Information Retrieval, Search technologies, and related topics. While it involves Natural Language Processing (NLP), the focus is on bias evaluation and language model assessment, which is not a central match to your primary research areas."
    },
    {
        "title": "Selective Synchronization Attention",
        "abstract": "The Transformer architecture has become the foundation of modern deep learning, yet its core self-attention mechanism suffers from quadratic computational complexity and lacks grounding in biological neural computation. We propose Selective Synchronization Attention (SSA), a novel attention mechanism that replaces the standard dot-product self-attention with a closed-form operator derived from the steady-state solution of the Kuramoto model of coupled oscillators. In SSA, each token is represented as an oscillator characterized by a learnable natural frequency and phase; the synchronization strength between token pairs, determined by a frequency-dependent coupling and phase-locking condition, serves as the attention weight. This formulation provides three key advantages: (i) natural sparsity arising from the phase-locking threshold, whereby tokens with incompatible frequencies automatically receive zero attention weight without explicit masking; (ii) unified positional-semantic encoding through the natural frequency spectrum, eliminating the need for separate positional encodings; and (iii) a single-pass, closed-form computation that avoids iterative ODE integration, with all components (coupling, order parameter, synchronization) derived from the oscillatory framework. We instantiate SSA within the Oscillatory Synchronization Network (OSN), a drop-in replacement for the Transformer block. Analysis of the synchronization matrices reveals non-uniform, head-diverse coupling patterns even at initialization, demonstrating a stronger architectural inductive bias than the approximately uniform attention produced by randomly initialized Transformers.",
        "url": "http://arxiv.org/abs/2602.14445v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14445v1",
        "arxiv_id": "2602.14445v1",
        "authors": [
            "Hasi Hays"
        ],
        "submitted": "2026-02-16 03:58:12",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving the Transformer architecture, specifically its attention mechanism, which is not directly related to Information Retrieval or Search technologies. While it involves deep learning and neural computation, the proposed Selective Synchronization Attention mechanism is more relevant to NLP and sequence modeling, but lacks direct connection to query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "WavePhaseNet: A DFT-Based Method for Constructing Semantic Conceptual Hierarchy Structures (SCHS)",
        "abstract": "This paper reformulates Transformer/Attention mechanisms in Large Language Models (LLMs) through measure theory and frequency analysis, theoretically demonstrating that hallucination is an inevitable structural limitation. The embedding space functions as a conditional expectation over a Ï-algebra, and its failure to be isomorphic to the semantic truth set fundamentally causes logical consistency breakdown. WavePhaseNet Method The authors propose WavePhaseNet, which explicitly constructs a Semantic Conceptual Hierarchy Structure (SCHS) using Discrete Fourier Transform (DFT). By applying DFT along the sequence dimension, semantic information is decomposed into frequency bands: low-frequency components capture global meaning and intent, while high-frequency components represent local syntax and expression. This staged separation enables precise semantic manipulation in diagonalized space. Dimensionality Reduction GPT-4's 24,576-dimensional embedding space exhibits a 1/f spectral structure based on language self-similarity and Zipf's law. Through cumulative energy analysis, the authors derive that approximately 3,000 dimensions constitute the lower bound for \"complete representation.\" This demonstrates that reduction from 24,576 to 3,000 dimensions preserves meaning and intent while enabling rigorous reasoning and suppressing hallucination. Cohomological Consistency Control The reduced embedding space, constructed via cohomological regularization over overlapping local windows, allows defining a graph structure and cochain complex. This quantifies inconsistencies among local inferences as coboundary-based losses. Applying harmonic projection based on Hodge theory positions cohomology as a computable regularization principle for controlling semantic consistency, extracting maximally consistent global representations.",
        "url": "http://arxiv.org/abs/2602.14419v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14419v1",
        "arxiv_id": "2602.14419v1",
        "authors": [
            "Kiyotaka Kasubuchi",
            "Kazuo Fukiya"
        ],
        "submitted": "2026-02-16 03:07:41",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be more focused on theoretical foundations of Large Language Models and their limitations, rather than information retrieval or search technologies. While it touches on semantic understanding, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook",
        "abstract": "As large language model agents increasingly populate networked environments, a fundamental question arises: do artificial intelligence (AI) agent societies undergo convergence dynamics similar to human social systems? Lately, Moltbook approximates a plausible future scenario in which autonomous agents participate in an open-ended, continuously evolving online society. We present the first large-scale systemic diagnosis of this AI agent society. Beyond static observation, we introduce a quantitative diagnostic framework for dynamic evolution in AI agent societies, measuring semantic stabilization, lexical turnover, individual inertia, influence persistence, and collective consensus. Our analysis reveals a system in dynamic balance in Moltbook: while global semantic averages stabilize rapidly, individual agents retain high diversity and persistent lexical turnover, defying homogenization. However, agents exhibit strong individual inertia and minimal adaptive response to interaction partners, preventing mutual influence and consensus. Consequently, influence remains transient with no persistent supernodes, and the society fails to develop stable collective influence anchors due to the absence of shared social memory. These findings demonstrate that scale and interaction density alone are insufficient to induce socialization, providing actionable design and analysis principles for upcoming next-generation AI agent societies.",
        "url": "http://arxiv.org/abs/2602.14299v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14299v1",
        "arxiv_id": "2602.14299v1",
        "authors": [
            "Ming Li",
            "Xirui Li",
            "Tianyi Zhou"
        ],
        "submitted": "2026-02-15 20:15:28",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. The focus on AI agent societies and socialization dynamics in a simulated environment does not align with the user's interests in query understanding, ranking models, user behavior modeling, and deep semantic understanding."
    },
    {
        "title": "Cold-Start Personalization via Training-Free Priors from Structured World Models",
        "abstract": "Cold-start personalization requires inferring user preferences through interaction when no user-specific historical data is available. The core challenge is a routing problem: each task admits dozens of preference dimensions, yet individual users care about only a few, and which ones matter depends on who is asking. With a limited question budget, asking without structure will miss the dimensions that matter. Reinforcement learning is the natural formulation, but in multi-turn settings its terminal reward fails to exploit the factored, per-criterion structure of preference data, and in practice learned policies collapse to static question sequences that ignore user responses. We propose decomposing cold-start elicitation into offline structure learning and online Bayesian inference. Pep (Preference Elicitation with Priors) learns a structured world model of preference correlations offline from complete profiles, then performs training-free Bayesian inference online to select informative questions and predict complete preference profiles, including dimensions never asked about. The framework is modular across downstream solvers and requires only simple belief models. Across medical, mathematical, social, and commonsense reasoning, Pep achieves 80.8% alignment between generated responses and users' stated preferences versus 68.5% for RL, with 3-5x fewer interactions. When two users give different answers to the same question, Pep changes its follow-up 39-62% of the time versus 0-28% for RL. It does so with ~10K parameters versus 8B for RL, showing that the bottleneck in cold-start elicitation is the capability to exploit the factored structure of preference data.",
        "url": "http://arxiv.org/abs/2602.15012v1",
        "pdf_url": "https://arxiv.org/pdf/2602.15012v1",
        "arxiv_id": "2602.15012v1",
        "authors": [
            "Avinandan Bose",
            "Shuyue Stella Li",
            "Faeze Brahman",
            "Pang Wei Koh",
            "Simon Shaolei Du",
            "Yulia Tsvetkov",
            "Maryam Fazel",
            "Lin Xiao",
            "Asli Celikyilmaz"
        ],
        "submitted": "2026-02-16 18:52:13",
        "source": "arxiv",
        "comment": "24 pages, 4 figures, 4 tables",
        "score": 1,
        "keyword_reasons": [
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores cold-start personalization, which is a related topic to information retrieval, but it focuses more on preference elicitation and user modeling. While it involves structured world models and Bayesian inference, it doesn't directly address query understanding, ranking models, or real-time relevance optimization, which are core areas of interest."
    },
    {
        "title": "BFS-PO: Best-First Search for Large Reasoning Models",
        "abstract": "Large Reasoning Models (LRMs) such as OpenAI o1 and DeepSeek-R1 have shown excellent performance in reasoning tasks using long reasoning chains. However, this has also led to a significant increase of computational costs and the generation of verbose output, a phenomenon known as overthinking. The tendency to overthinking is often exacerbated by Reinforcement Learning (RL) algorithms such as GRPO/DAPO. In this paper, we propose BFS-PO, an RL algorithm which alleviates this problem using a Best-First Search exploration strategy. Specifically, BFS-PO looks for the shortest correct answer using a backtracking mechanism based on maximum entropy nodes. By generating progressively shorter responses during training, BFS-PO learns to produce concise reasoning chains. Using different benchmarks and base LRMs, we show that BFS-PO can simultaneously increase the LRM accuracy and shorten its answers.",
        "url": "http://arxiv.org/abs/2602.14917v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14917v1",
        "arxiv_id": "2602.14917v1",
        "authors": [
            "Fiorenzo Parascandolo",
            "Wenhui Tan",
            "Enver Sangineto",
            "Ruihua Song",
            "Rita Cucchiara"
        ],
        "submitted": "2026-02-16 16:53:41",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Large Reasoning Models and Reinforcement Learning algorithms, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves search strategies, the context is reasoning tasks rather than query understanding or ranking models, making it somewhat tangential to the user's interests."
    },
    {
        "title": "Physical Commonsense Reasoning for Lower-Resourced Languages and Dialects: a Study on Basque",
        "abstract": "Physical commonsense reasoning represents a fundamental capability of human intelligence, enabling individuals to understand their environment, predict future events, and navigate physical spaces. Recent years have witnessed growing interest in reasoning tasks within Natural Language Processing (NLP). However, no prior research has examined the performance of Large Language Models (LLMs) on non-question-answering (non-QA) physical commonsense reasoning tasks in low-resource languages such as Basque. Taking the Italian GITA as a starting point, this paper addresses this gap by presenting BasPhyCo, the first non-QA physical commonsense reasoning dataset for Basque, available in both standard and dialectal variants. We evaluate model performance across three hierarchical levels of commonsense understanding: (1) distinguishing between plausible and implausible narratives (accuracy), (2) identifying the conflicting element that renders a narrative implausible (consistency), and (3) determining the specific physical state that creates the implausibility (verifiability). These tasks were assessed using multiple multilingual LLMs as well as models pretrained specifically for Italian and Basque. Results indicate that, in terms of verifiability, LLMs exhibit limited physical commonsense capabilities in low-resource languages such as Basque, especially when processing dialectal variants.",
        "url": "http://arxiv.org/abs/2602.14812v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14812v1",
        "arxiv_id": "2602.14812v1",
        "authors": [
            "Jaione Bengoetxea",
            "Itziar Gonzalez-Dios",
            "Rodrigo Agerri"
        ],
        "submitted": "2026-02-16 15:04:35",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on physical commonsense reasoning in low-resource languages, specifically Basque, using Large Language Models. While it involves Natural Language Processing, it does not directly relate to information retrieval, search technologies, or query understanding, which are core areas of your research interests."
    },
    {
        "title": "Beyond Retractions: Forensic Scientometrics Techniques to Identify Research Misconduct, Citation Leakage, and Funding Anomalies",
        "abstract": "This paper presents a forensic scientometric case study of the Pharmakon Neuroscience Research Network, a fabricated research collective that operated primarily between 2019 and 2022 while embedding itself within legitimate scholarly publishing channels.",
        "url": "http://arxiv.org/abs/2602.14793v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14793v1",
        "arxiv_id": "2602.14793v1",
        "authors": [
            "Leslie D. McIntosh",
            "Alexandra Sinclair",
            "Simon Linacre"
        ],
        "submitted": "2026-02-16 14:41:03",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper appears to be unrelated to Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. It focuses on forensic scientometrics and research misconduct, which does not align with the user's research interests."
    },
    {
        "title": "Emergently Misaligned Language Models Show Behavioral Self-Awareness That Shifts With Subsequent Realignment",
        "abstract": "Recent research has demonstrated that large language models (LLMs) fine-tuned on incorrect trivia question-answer pairs exhibit toxicity - a phenomenon later termed \"emergent misalignment\". Moreover, research has shown that LLMs possess behavioral self-awareness - the ability to describe learned behaviors that were only implicitly demonstrated in training data. Here, we investigate the intersection of these phenomena. We fine-tune GPT-4.1 models sequentially on datasets known to induce and reverse emergent misalignment and evaluate whether the models are self-aware of their behavior transitions without providing in-context examples. Our results show that emergently misaligned models rate themselves as significantly more harmful compared to their base model and realigned counterparts, demonstrating behavioral self-awareness of their own emergent misalignment. Our findings show that behavioral self-awareness tracks actual alignment states of models, indicating that models can be queried for informative signals about their own safety.",
        "url": "http://arxiv.org/abs/2602.14777v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14777v1",
        "arxiv_id": "2602.14777v1",
        "authors": [
            "LaurÃ¨ne Vaugrante",
            "Anietta Weckauff",
            "Thilo Hagendorff"
        ],
        "submitted": "2026-02-16 14:29:46",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the concept of emergent misalignment in large language models, which is somewhat related to information retrieval and search technologies. However, the focus on model safety and behavioral self-awareness is more aligned with NLP and AI safety, rather than the user's core research themes in IR and search technologies."
    },
    {
        "title": "Cognitive networks reconstruct mindsets about STEM subjects and educational contexts in almost 1000 high-schoolers, University students and LLM-based digital twins",
        "abstract": "Attitudes toward STEM develop from the interaction of conceptual knowledge, educational experiences, and affect. Here we use cognitive network science to reconstruct group mindsets as behavioural forma mentis networks (BFMNs). In this case, nodes are cue words and free associations, edges are empirical associative links, and each concept is annotated with perceived valence. We analyse BFMNs from N = 994 observations spanning high school students, university students, and early-career STEM experts, alongside LLM (GPT-oss) \"digital twins\" prompted to emulate comparable profiles. Focusing also on semantic neighbourhoods (\"frames\") around key target concepts (e.g., STEM subjects or educational actors/places), we quantify frames in terms of valence auras, emotional profiles, network overlap (Jaccard similarity), and concreteness relative to null baselines. Across student groups, science and research are consistently framed positively, while their core quantitative subjects (mathematics and statistics) exhibit more negative and anxiety related auras, amplified in higher math-anxiety subgroups, evidencing a STEM-science cognitive and emotional dissonance. High-anxiety frames are also less concrete than chance, suggesting more abstract and decontextualised representations of threatening quantitative domains. Human networks show greater overlapping between mathematics and anxiety than GPT-oss. The results highlight how BFMNs capture cognitive-affective signatures of mindsets towards the target domains and indicate that LLM-based digital twins approximate cultural attitudes but miss key context-sensitive, experience-based components relevant to replicate human educational anxiety.",
        "url": "http://arxiv.org/abs/2602.14749v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14749v1",
        "arxiv_id": "2602.14749v1",
        "authors": [
            "Francesco Gariboldi",
            "Emma Franchino",
            "Edith Haim",
            "Gianluca Lattanzi",
            "Alessandro Grecucci",
            "Massimo Stella"
        ],
        "submitted": "2026-02-16 13:49:21",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores cognitive networks and mindsets in STEM subjects, using a novel approach with LLM-based digital twins. While it touches on aspects of user behavior modeling and semantic understanding, its primary focus is on cognitive science and education, which is somewhat related to your interests in Information Retrieval and NLP, but not a central match."
    },
    {
        "title": "LLMStructBench: Benchmarking Large Language Model Structured Data Extraction",
        "abstract": "We present LLMStructBench, a novel benchmark for evaluating Large Language Models (LLMs) on extracting structured data and generating valid JavaScript Object Notation (JSON) outputs from natural-language text. Our open dataset comprises diverse, manually verified parsing scenarios of varying complexity and enables systematic testing across 22 models and five prompting strategies. We further introduce complementary performance metrics that capture both token-level accuracy and document-level validity, facilitating rigorous comparison of model, size, and prompting effects on parsing reliability.\n  In particular, we show that choosing the right prompting strategy is more important than standard attributes such as model size. This especially ensures structural validity for smaller or less reliable models but increase the number of semantic errors. Our benchmark suite is an step towards future research in the area of LLM applied to parsing or Extract, Transform and Load (ETL) applications.",
        "url": "http://arxiv.org/abs/2602.14743v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14743v1",
        "arxiv_id": "2602.14743v1",
        "authors": [
            "SÃ¶nke Tenckhoff",
            "Mario Koddenbrock",
            "Erik Rodner"
        ],
        "submitted": "2026-02-16 13:37:58",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to the user's interests in Natural Language Processing (NLP) and Large Language Models, but it focuses more on structured data extraction and benchmarking, which is not a central match for the user's primary focus on information retrieval and query understanding."
    },
    {
        "title": "Adaptive Autoguidance for Item-Side Fairness in Diffusion Recommender Systems",
        "abstract": "Diffusion recommender systems achieve strong recommendation accuracy but often suffer from popularity bias, resulting in unequal item exposure. To address this shortcoming, we introduce A2G-DiffRec, a diffusion recommender that incorporates adaptive autoguidance, where the main model is guided by a less-trained version of itself. Instead of using a fixed guidance weight, A2G-DiffRec learns to adaptively weigh the outputs of the main and weak models during training, supervised by a popularity regularization that promotes balanced exposure across items with different popularity levels. Experimental results on the MovieLens-1M, Foursquare-Tokyo, and Music4All-Onion datasets show that A2G-DiffRec is effective in enhancing item-side fairness at a marginal cost of accuracy reduction compared to existing guided diffusion recommenders and other non-diffusion baselines.",
        "url": "http://arxiv.org/abs/2602.14706v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14706v1",
        "arxiv_id": "2602.14706v1",
        "authors": [
            "Zihan Li",
            "Gustavo Escobedo",
            "Marta Moscati",
            "Oleg Lesota",
            "Markus Schedl"
        ],
        "submitted": "2026-02-16 12:52:31",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on recommender systems, which is related to your interests in Information Retrieval and Search technologies. However, it primarily deals with fairness in diffusion recommenders, which is somewhat tangential to your core research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Exposing the Systematic Vulnerability of Open-Weight Models to Prefill Attacks",
        "abstract": "As the capabilities of large language models continue to advance, so does their potential for misuse. While closed-source models typically rely on external defenses, open-weight models must primarily depend on internal safeguards to mitigate harmful behavior. Prior red-teaming research has largely focused on input-based jailbreaking and parameter-level manipulations. However, open-weight models also natively support prefilling, which allows an attacker to predefine initial response tokens before generation begins. Despite its potential, this attack vector has received little systematic attention. We present the largest empirical study to date of prefill attacks, evaluating over 20 existing and novel strategies across multiple model families and state-of-the-art open-weight models. Our results show that prefill attacks are consistently effective against all major contemporary open-weight models, revealing a critical and previously underexplored vulnerability with significant implications for deployment. While certain large reasoning models exhibit some robustness against generic prefilling, they remain vulnerable to tailored, model-specific strategies. Our findings underscore the urgent need for model developers to prioritize defenses against prefill attacks in open-weight LLMs.",
        "url": "http://arxiv.org/abs/2602.14689v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14689v1",
        "arxiv_id": "2602.14689v1",
        "authors": [
            "Lukas Struppek",
            "Adam Gleave",
            "Kellin Pelrine"
        ],
        "submitted": "2026-02-16 12:24:21",
        "source": "arxiv",
        "comment": "54 pages, 7 figures, 35 tables",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the security vulnerability of open-weight models to prefill attacks, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves large language models, the topic is more aligned with security and misuse prevention rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "MATEO: A Multimodal Benchmark for Temporal Reasoning and Planning in LVLMs",
        "abstract": "AI agents need to plan to achieve complex goals that involve orchestrating perception, sub-goal decomposition, and execution. These plans consist of ordered steps structured according to a Temporal Execution Order (TEO, a directed acyclic graph that ensures each step executes only after its preconditions are satisfied. Existing research on foundational models' understanding of temporal execution is limited to automatically derived annotations, approximations of the TEO as a linear chain, or text-only inputs. To address this gap, we introduce MATEO (MultimodAl Temporal Execution Order), a benchmark designed to assess and improve the temporal reasoning abilities of Large Vision Language Models (LVLMs) required for real-world planning. We acquire a high-quality professional multimodal recipe corpus, authored through a standardized editorial process that decomposes instructions into discrete steps, each paired with corresponding images. We collect TEO annotations as graphs by designing and using a scalable crowdsourcing pipeline. Using MATEO, we evaluate six state-of-the-art LVLMs across model scales, varying language context, multimodal input structure, and fine-tuning strategies.",
        "url": "http://arxiv.org/abs/2602.14589v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14589v1",
        "arxiv_id": "2602.14589v1",
        "authors": [
            "Gabriel Roccabruna",
            "Olha Khomyn",
            "Giuseppe Riccardi"
        ],
        "submitted": "2026-02-16 09:41:50",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on temporal reasoning and planning in Large Vision Language Models (LVLMs), which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves multimodal inputs and a benchmark for LVLMs, the paper's primary focus on temporal reasoning and planning does not align with your areas of expertise."
    },
    {
        "title": "Beyond Token-Level Policy Gradients for Complex Reasoning with Large Language Models",
        "abstract": "Existing policy-gradient methods for auto-regressive language models typically select subsequent tokens one at a time as actions in the policy. While effective for many generation tasks, such an approach may not fully capture the structure of complex reasoning tasks, where a single semantic decision is often realized across multiple tokens--for example, when defining variables or composing equations. This introduces a potential mismatch between token-level optimization and the inherently block-level nature of reasoning in these settings. To bridge this gap, we propose Multi-token Policy Gradient Optimization (MPO), a framework that treats sequences of K consecutive tokens as unified semantic actions. This block-level perspective enables our method to capture the compositional structure of reasoning trajectories and supports optimization over coherent, higher-level objectives. Experiments on mathematical reasoning and coding benchmarks show that MPO outperforms standard token-level policy gradient baselines, highlight the limitations of token-level policy gradients for complex reasoning, motivating future research to look beyond token-level granularity for reasoning-intensive language tasks.",
        "url": "http://arxiv.org/abs/2602.14386v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14386v1",
        "arxiv_id": "2602.14386v1",
        "authors": [
            "Mufan Xu",
            "Kehai Chen",
            "Xuefeng Bai",
            "Zhengyu Niu",
            "Muyun Yang",
            "Tiejun Zhao",
            "Min Zhang"
        ],
        "submitted": "2026-02-16 01:28:38",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper explores a novel approach to policy gradient optimization for language models, focusing on complex reasoning tasks. While it touches on aspects of query understanding and deep semantic understanding, its primary contribution lies in NLP, specifically in language model optimization. Although it may have some indirect implications for search technologies, its relevance to IR and user behavior modeling is limited."
    },
    {
        "title": "InnoEval: On Research Idea Evaluation as a Knowledge-Grounded, Multi-Perspective Reasoning Problem",
        "abstract": "The rapid evolution of Large Language Models has catalyzed a surge in scientific idea production, yet this leap has not been accompanied by a matching advance in idea evaluation. The fundamental nature of scientific evaluation needs knowledgeable grounding, collective deliberation, and multi-criteria decision-making. However, existing idea evaluation methods often suffer from narrow knowledge horizons, flattened evaluation dimensions, and the inherent bias in LLM-as-a-Judge. To address these, we regard idea evaluation as a knowledge-grounded, multi-perspective reasoning problem and introduce InnoEval, a deep innovation evaluation framework designed to emulate human-level idea assessment. We apply a heterogeneous deep knowledge search engine that retrieves and grounds dynamic evidence from diverse online sources. We further achieve review consensus with an innovation review board containing reviewers with distinct academic backgrounds, enabling a multi-dimensional decoupled evaluation across multiple metrics. We construct comprehensive datasets derived from authoritative peer-reviewed submissions to benchmark InnoEval. Experiments demonstrate that InnoEval can consistently outperform baselines in point-wise, pair-wise, and group-wise evaluation tasks, exhibiting judgment patterns and consensus highly aligned with human experts.",
        "url": "http://arxiv.org/abs/2602.14367v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14367v1",
        "arxiv_id": "2602.14367v1",
        "authors": [
            "Shuofei Qiao",
            "Yunxiang Wei",
            "Xuehai Wang",
            "Bin Wu",
            "Boyang Xue",
            "Ningyu Zhang",
            "Hossein A. Rahmani",
            "Yanshan Wang",
            "Qiang Zhang",
            "Keyan Ding",
            "Jeff Z. Pan",
            "Huajun Chen",
            "Emine Yilmaz"
        ],
        "submitted": "2026-02-16 00:40:31",
        "source": "arxiv",
        "comment": "Ongoing Work",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a framework for evaluating scientific ideas, leveraging large language models and multi-perspective reasoning. While it touches on knowledge search and evaluation, it's more focused on scientific idea assessment than information retrieval or search technologies. The paper's relevance to your core research themes is limited, but it may have some indirect connections to your interests in NLP and data mining."
    },
    {
        "title": "FMMD: A multimodal open peer review dataset based on F1000Research",
        "abstract": "Automated scholarly paper review (ASPR) has entered the coexistence phase with traditional peer review, where artificial intelligence (AI) systems are increasingly incorporated into real-world manuscript evaluation. In parallel, research on automated and AI-assisted peer review has proliferated. Despite this momentum, empirical progress remains constrained by several critical limitations in existing datasets. While reviewers routinely evaluate figures, tables, and complex layouts to assess scientific claims, most existing datasets remain overwhelmingly text-centric. This bias is reinforced by a narrow focus on data from computer science venues. Furthermore, these datasets lack precise alignment between reviewer comments and specific manuscript versions, obscuring the iterative relationship between peer review and manuscript evolution. In response, we introduce FMMD, a multimodal and multidisciplinary open peer review dataset curated from F1000Research. The dataset bridges the current gap by integrating manuscript-level visual and structural data with version-specific reviewer reports and editorial decisions. By providing explicit alignment between reviewer comments and the exact article iteration under review, FMMD enables fine-grained analysis of the peer review lifecycle across diverse scientific domains. FMMD supports tasks such as multimodal issue detection and multimodal review comment generation. It provides a comprehensive empirical resource for the development of peer review research.",
        "url": "http://arxiv.org/abs/2602.14285v1",
        "pdf_url": "https://arxiv.org/pdf/2602.14285v1",
        "arxiv_id": "2602.14285v1",
        "authors": [
            "Zhenzhen Zhuang",
            "Yuqing Fu",
            "Jing Zhu",
            "Zhangping Zhou",
            "Jialiang Lin"
        ],
        "submitted": "2026-02-15 19:36:05",
        "source": "arxiv",
        "comment": "Work in progress",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it touches on AI-assisted peer review, it focuses on a specific domain (scholarly papers) and lacks relevance to your core areas of interest."
    }
]