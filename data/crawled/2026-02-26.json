[
    {
        "title": "Recovered in Translation: Efficient Pipeline for Automated Translation of Benchmarks and Datasets",
        "abstract": "The reliability of multilingual Large Language Model (LLM) evaluation is currently compromised by the inconsistent quality of translated benchmarks. Existing resources often suffer from semantic drift and context loss, which can lead to misleading performance metrics. In this work, we present a fully automated framework designed to address these challenges by enabling scalable, high-quality translation of datasets and benchmarks. We demonstrate that adapting test-time compute scaling strategies, specifically Universal Self-Improvement (USI) and our proposed multi-round ranking method, T-RANK, allows for significantly higher quality outputs compared to traditional pipelines. Our framework ensures that benchmarks preserve their original task structure and linguistic nuances during localization. We apply this approach to translate popular benchmarks and datasets into eight Eastern and Southern European languages (Ukrainian, Bulgarian, Slovak, Romanian, Lithuanian, Estonian, Turkish, Greek). Evaluations using both reference-based metrics and LLM-as-a-judge show that our translations surpass existing resources, resulting in more accurate downstream model assessment. We release both the framework and the improved benchmarks to facilitate robust and reproducible multilingual AI development.",
        "url": "http://arxiv.org/abs/2602.22207v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22207v1",
        "arxiv_id": "2602.22207v1",
        "authors": [
            "Hanna Yukhymenko",
            "Anton Alexandrov",
            "Martin Vechev"
        ],
        "submitted": "2026-02-25 18:58:25",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "SumTablets: A Transliteration Dataset of Sumerian Tablets",
        "abstract": "Sumerian transliteration is a conventional system for representing a scholar's interpretation of a tablet in the Latin script. Thanks to visionary digital Assyriology projects such as ETCSL, CDLI, and Oracc, a large number of Sumerian transliterations have been published online, and these data are well-structured for a variety of search and analysis tasks. However, the absence of a comprehensive, accessible dataset pairing transliterations with a digital representation of the tablet's cuneiform glyphs has prevented the application of modern Natural Language Processing (NLP) methods to the task of Sumerian transliteration.\n  To address this gap, we present SumTablets, a dataset pairing Unicode representations of 91,606 Sumerian cuneiform tablets (totaling 6,970,407 glyphs) with the associated transliterations published by Oracc. We construct SumTablets by first preprocessing and standardizing the Oracc transliterations before mapping each reading back to the Unicode representation of the source glyph. Further, we retain parallel structural information (e.g., surfaces, newlines, broken segments) through the use of special tokens. We release SumTablets as a Hugging Face Dataset (CC BY 4.0) and open source data preparation code via GitHub.\n  Additionally, we leverage SumTablets to implement and evaluate two transliteration baselines: (1) weighted sampling from a glyph's possible readings, and (2) fine-tuning an autoregressive language model. Our fine-tuned language model achieves an average transliteration character-level F-score (chrF) of 97.55, demonstrating the immediate potential of transformer-based transliteration models in allowing experts to rapidly verify generated transliterations rather than manually transliterating tablets one-by-one.",
        "url": "http://arxiv.org/abs/2602.22200v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22200v1",
        "arxiv_id": "2602.22200v1",
        "authors": [
            "Cole Simmons",
            "Richard Diehl Martinez",
            "Dan Jurafsky"
        ],
        "submitted": "2026-02-25 18:50:42",
        "source": "arxiv",
        "comment": "11 pages with 3 figures"
    },
    {
        "title": "Improving Parametric Knowledge Access in Reasoning Language Models",
        "abstract": "We study reasoning for accessing world knowledge stored in a language model's parameters. For example, recalling that Canberra is Australia's capital may benefit from thinking through major cities and the concept of purpose-built capitals. While reasoning language models are trained via reinforcement learning to produce reasoning traces on tasks such as mathematics, they may not reason well for accessing their own world knowledge. We first find that models do not generate their best world knowledge reasoning by default: adding a simple \"think step-by-step\" cue demonstrates statistically significant improvement in knowledge recall but not math. Motivated by this, we propose training models to reason over their parametric knowledge using world-knowledge question answering as a verifiable reward. After reinforcement learning on TriviaQA (+9.9%), performance also improves on Natural Questions, HotpotQA, SimpleQA, and StrategyQA by 4.2%, 2.1%, 0.6%, and 3.0%, respectively. Reasoning models are under-optimized for parametric knowledge access, but can be easily trained to reason better.",
        "url": "http://arxiv.org/abs/2602.22193v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22193v1",
        "arxiv_id": "2602.22193v1",
        "authors": [
            "Melody Ma",
            "John Hewitt"
        ],
        "submitted": "2026-02-25 18:43:01",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "GUI-Libra: Training Native GUI Agents to Reason and Act with Action-aware Supervision and Partially Verifiable RL",
        "abstract": "Open-source native GUI agents still lag behind closed-source systems on long-horizon navigation tasks. This gap stems from two limitations: a shortage of high-quality, action-aligned reasoning data, and the direct adoption of generic post-training pipelines that overlook the unique challenges of GUI agents. We identify two fundamental issues in these pipelines: (i) standard SFT with CoT reasoning often hurts grounding, and (ii) step-wise RLVR-tyle training faces partial verifiability, where multiple actions can be correct but only a single demonstrated action is used for verification. This makes offline step-wise metrics weak predictors of online task success. In this work, we present GUI-Libra, a tailored training recipe that addresses these challenges. First, to mitigate the scarcity of action-aligned reasoning data, we introduce a data construction and filtering pipeline and release a curated 81K GUI reasoning dataset. Second, to reconcile reasoning with grounding, we propose action-aware SFT that mixes reasoning-then-action and direct-action data and reweights tokens to emphasize action and grounding. Third, to stabilize RL under partial verifiability, we identify the overlooked importance of KL regularization in RLVR and show that a KL trust region is critical for improving offline-to-online predictability; we further introduce success-adaptive scaling to downweight unreliable negative gradients. Across diverse web and mobile benchmarks, GUI-Libra consistently improves both step-wise accuracy and end-to-end task completion. Our results suggest that carefully designed post-training and data curation can unlock significantly stronger task-solving capabilities without costly online data collection. We release our dataset, code, and models to facilitate further research on data-efficient post-training for reasoning-capable GUI agents.",
        "url": "http://arxiv.org/abs/2602.22190v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22190v1",
        "arxiv_id": "2602.22190v1",
        "authors": [
            "Rui Yang",
            "Qianhui Wu",
            "Zhaoyang Wang",
            "Hanyang Chen",
            "Ke Yang",
            "Hao Cheng",
            "Huaxiu Yao",
            "Baoling Peng",
            "Huan Zhang",
            "Jianfeng Gao",
            "Tong Zhang"
        ],
        "submitted": "2026-02-25 18:34:57",
        "source": "arxiv",
        "comment": "57 pages, 17 figures"
    },
    {
        "title": "LiCQA : A Lightweight Complex Question Answering System",
        "abstract": "Over the last twenty years, significant progress has been made in designing and implementing Question Answering (QA) systems. However, addressing complex questions, the answers to which are spread across multiple documents, remains a challenging problem. Recent QA systems that are designed to handle complex questions work either on the basis of knowledge graphs, or utilise contem- porary neural models that are expensive to train, in terms of both computational resources and the volume of training data required. In this paper, we present LiCQA, an unsupervised question answer- ing model that works primarily on the basis of corpus evidence. We empirically compare the effectiveness and efficiency of LiCQA with two recently presented QA systems, which are based on different underlying principles. The results of our experiments show that LiCQA significantly outperforms these two state-of-the-art systems on benchmark data with noteworthy reduction in latency.",
        "url": "http://arxiv.org/abs/2602.22182v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22182v1",
        "arxiv_id": "2602.22182v1",
        "authors": [
            "Sourav Saha",
            "Dwaipayan Roy",
            "Mandar Mitra"
        ],
        "submitted": "2026-02-25 18:28:38",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Decoding the Hook: A Multimodal LLM Framework for Analyzing the Hooking Period of Video Ads",
        "abstract": "Video-based ads are a vital medium for brands to engage consumers, with social media platforms leveraging user data to optimize ad delivery and boost engagement. A crucial but under-explored aspect is the 'hooking period', the first three seconds that capture viewer attention and influence engagement metrics. Analyzing this brief window is challenging due to the multimodal nature of video content, which blends visual, auditory, and textual elements. Traditional methods often miss the nuanced interplay of these components, requiring advanced frameworks for thorough evaluation.\n  This study presents a framework using transformer-based multimodal large language models (MLLMs) to analyze the hooking period of video ads. It tests two frame sampling strategies, uniform random sampling and key frame selection, to ensure balanced and representative acoustic feature extraction, capturing the full range of design elements. The hooking video is processed by state-of-the-art MLLMs to generate descriptive analyses of the ad's initial impact, which are distilled into coherent topics using BERTopic for high-level abstraction. The framework also integrates features such as audio attributes and aggregated ad targeting information, enriching the feature set for further analysis.\n  Empirical validation on large-scale real-world data from social media platforms demonstrates the efficacy of our framework, revealing correlations between hooking period features and key performance metrics like conversion per investment. The results highlight the practical applicability and predictive power of the approach, offering valuable insights for optimizing video ad strategies. This study advances video ad analysis by providing a scalable methodology for understanding and enhancing the initial moments of video advertisements.",
        "url": "http://arxiv.org/abs/2602.22299v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22299v1",
        "arxiv_id": "2602.22299v1",
        "authors": [
            "Kunpeng Zhang",
            "Poppy Zhang",
            "Shawndra Hill",
            "Amel Awadelkarim"
        ],
        "submitted": "2026-02-25 18:24:06",
        "source": "arxiv",
        "comment": "11 pages, 5 figures, 3 tables"
    },
    {
        "title": "DySCO: Dynamic Attention-Scaling Decoding for Long-Context LMs",
        "abstract": "Understanding and reasoning over long contexts is a crucial capability for language models (LMs). Although recent models support increasingly long context windows, their accuracy often deteriorates as input length grows. In practice, models often struggle to keep attention aligned with the most relevant context throughout decoding. In this work, we propose DySCO, a novel decoding algorithm for improving long-context reasoning. DySCO leverages retrieval heads--a subset of attention heads specialized for long-context retrieval--to identify task-relevant tokens at each decoding step and explicitly up-weight them. By doing so, DySCO dynamically adjusts attention during generation to better utilize relevant context. The method is training-free and can be applied directly to any off-the-shelf LMs. Across multiple instruction-tuned and reasoning models, DySCO consistently improves performance on challenging long-context reasoning benchmarks, yielding relative gains of up to 25% on MRCR and LongBenchV2 at 128K context length with modest additional compute. Further analysis highlights the importance of both dynamic attention rescaling and retrieval-head-guided selection for the effectiveness of the method, while providing interpretability insights into decoding-time attention behavior. Our code is available at https://github.com/princeton-pli/DySCO.",
        "url": "http://arxiv.org/abs/2602.22175v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22175v1",
        "arxiv_id": "2602.22175v1",
        "authors": [
            "Xi Ye",
            "Wuwei Zhang",
            "Fangcong Yin",
            "Howard Yen",
            "Danqi Chen"
        ],
        "submitted": "2026-02-25 18:21:35",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Dynamic Personality Adaptation in Large Language Models via State Machines",
        "abstract": "The inability of Large Language Models (LLMs) to modulate their personality expression in response to evolving dialogue dynamics hinders their performance in complex, interactive contexts. We propose a model-agnostic framework for dynamic personality simulation that employs state machines to represent latent personality states, where transition probabilities are dynamically adapted to the conversational context. Part of our architecture is a modular pipeline for continuous personality scoring that evaluates dialogues along latent axes while remaining agnostic to the specific personality models, their dimensions, transition mechanisms, or LLMs used. These scores function as dynamic state variables that systematically reconfigure the system prompt, steering behavioral alignment throughout the interaction.We evaluate this framework by operationalizing the Interpersonal Circumplex (IPC) in a medical education setting. Results demonstrate that the system successfully adapts its personality state to user inputs, but also influences user behavior, thereby facilitating de-escalation training. Notably, the scoring pipeline maintains comparable precision even when utilizing lightweight, fine-tuned classifiers instead of large-scale LLMs. This work demonstrates the feasibility of modular, personality-adaptive architectures for education, customer support, and broader human-computer interaction.",
        "url": "http://arxiv.org/abs/2602.22157v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22157v1",
        "arxiv_id": "2602.22157v1",
        "authors": [
            "Leon Pielage",
            "Ole Hätscher",
            "Mitja Back",
            "Bernhard Marschall",
            "Benjamin Risse"
        ],
        "submitted": "2026-02-25 18:05:11",
        "source": "arxiv",
        "comment": "22 pages, 5 figures, submitted to ICPR 2026"
    },
    {
        "title": "When AI Writes, Whose Voice Remains? Quantifying Cultural Marker Erasure Across World English Varieties in Large Language Models",
        "abstract": "Large Language Models (LLMs) are increasingly used to ``professionalize'' workplace communication, often at the cost of linguistic identity. We introduce \"Cultural Ghosting\", the systematic erasure of linguistic markers unique to non-native English varieties during text processing. Through analysis of 22,350 LLM outputs generated from 1,490 culturally marked texts (Indian, Singaporean,& Nigerian English) processed by five models under three prompt conditions, we quantify this phenomenon using two novel metrics: Identity Erasure Rate (IER) & Semantic Preservation Score (SPS). Across all prompts, we find an overall IER of 10.26%, with model-level variation from 3.5% to 20.5% (5.9x range). Crucially, we identify a Semantic Preservation Paradox: models maintain high semantic similarity (mean SPS = 0.748) while systematically erasing cultural markers. Pragmatic markers (politeness conventions) are 1.9x more vulnerable than lexical markers (71.5% vs. 37.1% erasure). Our experiments demonstrate that explicit cultural-preservation prompts reduce erasure by 29% without sacrificing semantic quality.",
        "url": "http://arxiv.org/abs/2602.22145v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22145v1",
        "arxiv_id": "2602.22145v1",
        "authors": [
            "Satyam Kumar Navneet",
            "Joydeep Chandra",
            "Yong Zhang"
        ],
        "submitted": "2026-02-25 17:54:42",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "NoLan: Mitigating Object Hallucinations in Large Vision-Language Models via Dynamic Suppression of Language Priors",
        "abstract": "Object hallucination is a critical issue in Large Vision-Language Models (LVLMs), where outputs include objects that do not appear in the input image. A natural question arises from this phenomenon: Which component of the LVLM pipeline primarily contributes to object hallucinations? The vision encoder to perceive visual information, or the language decoder to generate text responses? In this work, we strive to answer this question through designing a systematic experiment to analyze the roles of the vision encoder and the language decoder in hallucination generation. Our observations reveal that object hallucinations are predominantly associated with the strong priors from the language decoder. Based on this finding, we propose a simple and training-free framework, No-Language-Hallucination Decoding, NoLan, which refines the output distribution by dynamically suppressing language priors, modulated based on the output distribution difference between multimodal and text-only inputs. Experimental results demonstrate that NoLan effectively reduces object hallucinations across various LVLMs on different tasks. For instance, NoLan achieves substantial improvements on POPE, enhancing the accuracy of LLaVA-1.5 7B and Qwen-VL 7B by up to 6.45 and 7.21, respectively. The code is publicly available at: https://github.com/lingfengren/NoLan.",
        "url": "http://arxiv.org/abs/2602.22144v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22144v1",
        "arxiv_id": "2602.22144v1",
        "authors": [
            "Lingfeng Ren",
            "Weihao Yu",
            "Runpeng Yu",
            "Xinchao Wang"
        ],
        "submitted": "2026-02-25 17:50:41",
        "source": "arxiv",
        "comment": "Code: https://github.com/lingfengren/NoLan"
    },
    {
        "title": "IndicIFEval: A Benchmark for Verifiable Instruction-Following Evaluation in 14 Indic Languages",
        "abstract": "Instruction-following benchmarks remain predominantly English-centric, leaving a critical evaluation gap for the hundreds of millions of Indic language speakers. We introduce IndicIFEval, a benchmark evaluating constrained generation of LLMs across 14 Indic languages using automatically verifiable, rule-based instructions. It comprises around 800 human-verified examples per language spread across two complementary subsets: IndicIFEval-Ground, translated prompts from IFEval (Zhou et al., 2023) carefully localized for Indic contexts, and IndicIFEval-Ground, synthetically generated instructions grounded in native Indic content. We conduct a comprehensive evaluation of major open-weight and proprietary models spanning both reasoning and non-reasoning models. While models maintain strong adherence to formatting constraints, they struggle significantly with lexical and cross-lingual tasks -- and despite progress in high-resource languages, instruction-following across the broader Indic family lags significantly behind English. We release IndicIFEval and its evaluation scripts to support progress on multilingual constrained generation (http://github.com/ai4bharat/IndicIFEval).",
        "url": "http://arxiv.org/abs/2602.22125v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22125v1",
        "arxiv_id": "2602.22125v1",
        "authors": [
            "Thanmay Jayakumar",
            "Mohammed Safi Ur Rahman Khan",
            "Raj Dabre",
            "Ratish Puduppully",
            "Anoop Kunchukuttan"
        ],
        "submitted": "2026-02-25 17:12:37",
        "source": "arxiv",
        "comment": "8 pages + Appendix"
    },
    {
        "title": "SWE-Protégé: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents",
        "abstract": "Small language models (SLMs) offer compelling advantages in cost, latency, and adaptability, but have so far lagged behind larger models on long-horizon software engineering tasks such as SWE-bench, where they suffer from pervasive action looping and low resolution rates. We introduce SWE-Protégé, a post-training framework that reframes software repair as an expert-protégé collaboration problem. In SWE-Protégé, an SLM remains the sole decision-maker while learning to selectively seek guidance from a strong expert model, recognize stalled states, and follow through on expert feedback. Our approach combines supervised fine-tuning on expert-augmented trajectories with agentic reinforcement learning that explicitly discourages degenerative looping and unproductive expert collaboration. We lightly post-train Qwen2.5-Coder-7B-Instruct to achieve 42.4% Pass@1 on SWE-bench Verified, a +25.4% improvement over the prior SLM state of the art, while using expert assistance sparsely (~4 calls per task and 11% of total tokens).",
        "url": "http://arxiv.org/abs/2602.22124v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22124v1",
        "arxiv_id": "2602.22124v1",
        "authors": [
            "Patrick Tser Jern Kon",
            "Archana Pradeep",
            "Ang Chen",
            "Alexander P. Ellis",
            "Warren Hunt",
            "Zijian Wang",
            "John Yang",
            "Samuel Thompson"
        ],
        "submitted": "2026-02-25 17:11:49",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Confidence-Driven Multi-Scale Model Selection for Cost-Efficient Inference",
        "abstract": "Large Language Models (LLMs) have revolutionized inference across diverse natural language tasks, with larger models performing better but at higher computational costs. We propose a confidence-driven strategy that dynamically selects the most suitable model based on confidence estimates. By assessing a model's confidence in handling the task and response accuracy, tasks that are likely to be solved correctly are retained, while more uncertain or complex cases are delegated to a larger model, ensuring reliability while minimizing computation. Specifically, we evaluate a model's likelihood of knowing the correct answer and the probability that its response is accurate. Experiments on the Massive Multitask Language Understanding (MMLU) benchmark show that our approach achieves accuracy comparable to the largest model while reducing computational costs by 20\\% to 40\\%. When applied to GPT-4o API calls, it reduces token usage by approximately 60\\%, further improving cost efficiency. These findings indicate the potential of confidence-based model selection to enhance real-world LLM deployment, particularly in resource-constrained settings such as edge devices and commercial API applications.",
        "url": "http://arxiv.org/abs/2602.22090v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22090v1",
        "arxiv_id": "2602.22090v1",
        "authors": [
            "Bo-Wei Chen",
            "Chung-Chi Chen",
            "An-Zi Yen"
        ],
        "submitted": "2026-02-25 16:38:03",
        "source": "arxiv",
        "comment": "Accepted by EACL 2026 Findings"
    },
    {
        "title": "Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models",
        "abstract": "Theory of Mind (ToM) refers to an agent's ability to model the internal states of others. Contributing to the debate whether large language models (LLMs) exhibit genuine ToM capabilities, our study investigates their ToM robustness using perturbations on false-belief tasks and examines the potential of Chain-of-Thought prompting (CoT) to enhance performance and explain the LLM's decision. We introduce a handcrafted, richly annotated ToM dataset, including classic and perturbed false belief tasks, the corresponding spaces of valid reasoning chains for correct task completion, subsequent reasoning faithfulness, task solutions, and propose metrics to evaluate reasoning chain correctness and to what extent final answers are faithful to reasoning traces of the generated CoT. We show a steep drop in ToM capabilities under task perturbation for all evaluated LLMs, questioning the notion of any robust form of ToM being present. While CoT prompting improves the ToM performance overall in a faithful manner, it surprisingly degrades accuracy for some perturbation classes, indicating that selective application is necessary.",
        "url": "http://arxiv.org/abs/2602.22072v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22072v1",
        "arxiv_id": "2602.22072v1",
        "authors": [
            "Christian Nickel",
            "Laura Schrewe",
            "Florian Mai",
            "Lucie Flek"
        ],
        "submitted": "2026-02-25 16:24:35",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "DLT-Corpus: A Large-Scale Text Collection for the Distributed Ledger Technology Domain",
        "abstract": "We introduce DLT-Corpus, the largest domain-specific text collection for Distributed Ledger Technology (DLT) research to date: 2.98 billion tokens from 22.12 million documents spanning scientific literature (37,440 publications), United States Patent and Trademark Office (USPTO) patents (49,023 filings), and social media (22 million posts). Existing Natural Language Processing (NLP) resources for DLT focus narrowly on cryptocurrencies price prediction and smart contracts, leaving domain-specific language under explored despite the sector's ~$3 trillion market capitalization and rapid technological evolution.\n  We demonstrate DLT-Corpus' utility by analyzing technology emergence patterns and market-innovation correlations. Findings reveal that technologies originate in scientific literature before reaching patents and social media, following traditional technology transfer patterns. While social media sentiment remains overwhelmingly bullish even during crypto winters, scientific and patent activity grow independently of market fluctuations, tracking overall market expansion in a virtuous cycle where research precedes and enables economic growth that funds further innovation.\n  We publicly release the full DLT-Corpus; LedgerBERT, a domain-adapted model achieving 23% improvement over BERT-base on a DLT-specific Named Entity Recognition (NER) task; and all associated tools and code.",
        "url": "http://arxiv.org/abs/2602.22045v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22045v1",
        "arxiv_id": "2602.22045v1",
        "authors": [
            "Walter Hernandez Cruz",
            "Peter Devine",
            "Nikhil Vadgama",
            "Paolo Tasca",
            "Jiahua Xu"
        ],
        "submitted": "2026-02-25 15:53:41",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "TG-ASR: Translation-Guided Learning with Parallel Gated Cross Attention for Low-Resource Automatic Speech Recognition",
        "abstract": "Low-resource automatic speech recognition (ASR) continues to pose significant challenges, primarily due to the limited availability of transcribed data for numerous languages. While a wealth of spoken content is accessible in television dramas and online videos, Taiwanese Hokkien exemplifies this issue, with transcriptions often being scarce and the majority of available subtitles provided only in Mandarin. To address this deficiency, we introduce TG-ASR for Taiwanese Hokkien drama speech recognition, a translation-guided ASR framework that utilizes multilingual translation embeddings to enhance recognition performance in low-resource environments. The framework is centered around the parallel gated cross-attention (PGCA) mechanism, which adaptively integrates embeddings from various auxiliary languages into the ASR decoder. This mechanism facilitates robust cross-linguistic semantic guidance while ensuring stable optimization and minimizing interference between languages. To support ongoing research initiatives, we present YT-THDC, a 30-hour corpus of Taiwanese Hokkien drama speech with aligned Mandarin subtitles and manually verified Taiwanese Hokkien transcriptions. Comprehensive experiments and analyses identify the auxiliary languages that most effectively enhance ASR performance, achieving a 14.77% relative reduction in character error rate and demonstrating the efficacy of translation-guided learning for underrepresented languages in practical applications.",
        "url": "http://arxiv.org/abs/2602.22039v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22039v1",
        "arxiv_id": "2602.22039v1",
        "authors": [
            "Cheng-Yeh Yang",
            "Chien-Chun Wang",
            "Li-Wei Chen",
            "Hung-Shin Lee",
            "Hsin-Min Wang",
            "Berlin Chen"
        ],
        "submitted": "2026-02-25 15:47:34",
        "source": "arxiv",
        "comment": "Accepted to LREC 2026"
    },
    {
        "title": "A Diversity Diet for a Healthier Model: A Case Study of French ModernBERT",
        "abstract": "Diversity has been gaining interest in the NLP community in recent years. At the same time, state-of-the-art transformer models such as ModernBERT use very large pre-training datasets, which are driven by size rather than by diversity. This summons for an investigation of the impact of diversity on the ModernBERT pre-training. We do so in this study, with the express intent of reducing pre-training dataset size, while retaining at least comparable performance. We compare diversity-driven sampling algorithms, so as to pick the best one. We find that diversity-driven sampling allows in some tasks to gain 10 points relative to randomly-sampled pre-training data of commensurate size. We also see that a model pre-trained for 483h on a diversity-driven dataset of 150M tokens can yield a commensurate performance to a model pre-trained for 1,775h on a randomly-driven dataset of 2.4B tokens.",
        "url": "http://arxiv.org/abs/2602.22014v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22014v1",
        "arxiv_id": "2602.22014v1",
        "authors": [
            "Louis Estève",
            "Christophe Servan",
            "Thomas Lavergne",
            "Agata Savary"
        ],
        "submitted": "2026-02-25 15:29:30",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "CxMP: A Linguistic Minimal-Pair Benchmark for Evaluating Constructional Understanding in Language Models",
        "abstract": "Recent work has examined language models from a linguistic perspective to better understand how they acquire language. Most existing benchmarks focus on judging grammatical acceptability, whereas the ability to interpret meanings conveyed by grammatical forms has received much less attention. We introduce the Linguistic Minimal-Pair Benchmark for Evaluating Constructional Understanding in Language Models (CxMP), a benchmark grounded in Construction Grammar that treats form-meaning pairings, or constructions, as fundamental linguistic units. CxMP evaluates whether models can interpret the semantic relations implied by constructions, using a controlled minimal-pair design across nine construction types, including the let-alone, caused motion, and ditransitive constructions. Our results show that while syntactic competence emerges early, constructional understanding develops more gradually and remains limited even in large language models (LLMs). CxMP thus reveals persistent gaps in how language models integrate form and meaning, providing a framework for studying constructional understanding and learning trajectories in language models.",
        "url": "http://arxiv.org/abs/2602.21978v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21978v1",
        "arxiv_id": "2602.21978v1",
        "authors": [
            "Miyu Oba",
            "Saku Sugawara"
        ],
        "submitted": "2026-02-25 14:57:23",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Learning to Collaborate via Structures: Cluster-Guided Item Alignment for Federated Recommendation",
        "abstract": "Federated recommendation facilitates collaborative model training across distributed clients while keeping sensitive user interaction data local. Conventional approaches typically rely on synchronizing high-dimensional item representations between the server and clients. This paradigm implicitly assumes that precise geometric alignment of embedding coordinates is necessary for collaboration across clients. We posit that establishing relative semantic relationships among items is more effective than enforcing shared representations. Specifically, global semantic relations serve as structural constraints for items. Within these constraints, the framework allows item representations to vary locally on each client, which flexibility enables the model to capture fine-grained user personalization while maintaining global consistency. To this end, we propose Cluster-Guided FedRec framework (CGFedRec), a framework that transforms uploaded embeddings into compact cluster labels. In this framework, the server functions as a global structure discoverer to learn item clusters and distributes only the resulting labels. This mechanism explicitly cuts off the downstream transmission of item embeddings, relieving clients from maintaining global shared item embeddings. Consequently, CGFedRec achieves the effective injection of global collaborative signals into local item representations without transmitting full embeddings. Extensive experiments demonstrate that our approach significantly improves communication efficiency while maintaining superior recommendation accuracy across multiple datasets.",
        "url": "http://arxiv.org/abs/2602.21957v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21957v1",
        "arxiv_id": "2602.21957v1",
        "authors": [
            "Yuchun Tu",
            "Zhiwei Li",
            "Bingli Sun",
            "Yixuan Li",
            "Xiao Song"
        ],
        "submitted": "2026-02-25 14:39:47",
        "source": "arxiv",
        "comment": "18 pages, 9 figures"
    },
    {
        "title": "RADAR: Reasoning as Discrimination with Aligned Representations for LLM-based Knowledge Graph Reasoning",
        "abstract": "Knowledge graph reasoning (KGR) infers missing facts, with recent advances increasingly harnessing the semantic priors and reasoning abilities of Large Language Models (LLMs). However, prevailing generative paradigms are prone to memorizing surface-level co-occurrences rather than learning genuine relational semantics, limiting out-of-distribution generalization. To address this, we propose RADAR, which reformulates KGR from generative pattern matching to discriminative relational reasoning. We recast KGR as discriminative entity selection, where reinforcement learning enforces relative entity separability beyond token-likelihood imitation. Leveraging this separability, inference operates directly in representation space, ensuring consistency with the discriminative optimization and bypassing generation-induced hallucinations. Across four benchmarks, RADAR achieves 5-6% relative gains on link prediction and triple classification over strong LLM baselines, while increasing task-relevant mutual information in intermediate representations by 62.9%, indicating more robust and transferable relational reasoning.",
        "url": "http://arxiv.org/abs/2602.21951v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21951v1",
        "arxiv_id": "2602.21951v1",
        "authors": [
            "Bo Xue",
            "Yuan Jin",
            "Luoyi Fu",
            "Jiaxin Ding",
            "Xinbing Wang"
        ],
        "submitted": "2026-02-25 14:34:02",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "MEDSYN: Benchmarking Multi-EviDence SYNthesis in Complex Clinical Cases for Multimodal Large Language Models",
        "abstract": "Multimodal large language models (MLLMs) have shown great potential in medical applications, yet existing benchmarks inadequately capture real-world clinical complexity. We introduce MEDSYN, a multilingual, multimodal benchmark of highly complex clinical cases with up to 7 distinct visual clinical evidence (CE) types per case. Mirroring clinical workflow, we evaluate 18 MLLMs on differential diagnosis (DDx) generation and final diagnosis (FDx) selection. While top models often match or even outperform human experts on DDx generation, all MLLMs exhibit a much larger DDx--FDx performance gap compared to expert clinicians, indicating a failure mode in synthesis of heterogeneous CE types. Ablations attribute this failure to (i) overreliance on less discriminative textual CE ($\\it{e.g.}$, medical history) and (ii) a cross-modal CE utilization gap. We introduce Evidence Sensitivity to quantify the latter and show that a smaller gap correlates with higher diagnostic accuracy. Finally, we demonstrate how it can be used to guide interventions to improve model performance. We will open-source our benchmark and code.",
        "url": "http://arxiv.org/abs/2602.21950v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21950v1",
        "arxiv_id": "2602.21950v1",
        "authors": [
            "Boqi Chen",
            "Xudong Liu",
            "Jiachuan Peng",
            "Marianne Frey-Marti",
            "Bang Zheng",
            "Kyle Lam",
            "Lin Li",
            "Jianing Qiu"
        ],
        "submitted": "2026-02-25 14:33:33",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Large Language Models are Algorithmically Blind",
        "abstract": "Large language models (LLMs) demonstrate remarkable breadth of knowledge, yet their ability to reason about computational processes remains poorly understood. Closing this gap matters for practitioners who rely on LLMs to guide algorithm selection and deployment. We address this limitation using causal discovery as a testbed and evaluate eight frontier LLMs against ground truth derived from large-scale algorithm executions and find systematic, near-total failure. Models produce ranges far wider than true confidence intervals yet still fail to contain the true algorithmic mean in the majority of instances; most perform worse than random guessing and the marginal above-random performance of the best model is most consistent with benchmark memorization rather than principled reasoning. We term this failure algorithmic blindness and argue it reflects a fundamental gap between declarative knowledge about algorithms and calibrated procedural prediction.",
        "url": "http://arxiv.org/abs/2602.21947v2",
        "pdf_url": "https://arxiv.org/pdf/2602.21947v2",
        "arxiv_id": "2602.21947v2",
        "authors": [
            "Sohan Venkatesh",
            "Ashish Mahendran Kurapath",
            "Tejas Melkote"
        ],
        "submitted": "2026-02-25 14:32:15",
        "source": "arxiv",
        "comment": "19 pages, 8 figures, 15 tables"
    },
    {
        "title": "Small Wins Big: Comparing Large Language Models and Domain Fine-Tuned Models for Sarcasm Detection in Code-Mixed Hinglish Text",
        "abstract": "Sarcasm detection in multilingual and code-mixed environments remains a challenging task for natural language processing models due to structural variations, informal expressions, and low-resource linguistic availability. This study compares four large language models, Llama 3.1, Mistral, Gemma 3, and Phi-4, with a fine-tuned DistilBERT model for sarcasm detection in code-mixed Hinglish text. The results indicate that the smaller, sequentially fine-tuned DistilBERT model achieved the highest overall accuracy of 84%, outperforming all of the LLMs in zero and few-shot set ups, using minimal LLM generated code-mixed data used for fine-tuning. These findings indicate that domain-adaptive fine-tuning of smaller transformer based models may significantly improve sarcasm detection over general LLM inference, in low-resource and data scarce settings.",
        "url": "http://arxiv.org/abs/2602.21933v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21933v1",
        "arxiv_id": "2602.21933v1",
        "authors": [
            "Bitan Majumder",
            "Anirban Sen"
        ],
        "submitted": "2026-02-25 14:12:16",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "ExpLang: Improved Exploration and Exploitation in LLM Reasoning with On-Policy Thinking Language Selection",
        "abstract": "Current large reasoning models (LRMs) have shown strong ability on challenging tasks after reinforcement learning (RL) based post-training. However, previous work mainly focuses on English reasoning in expectation of the strongest performance, despite the demonstrated potential advantage of multilingual thinking, as well as the requirement for native thinking traces by global users. In this paper, we propose ExpLang, a novel LLM post-training pipeline that enables on-policy thinking language selection to improve exploration and exploitation during RL with the use of multiple languages. The results show that our method steadily outperforms English-only training with the same training budget, while showing high thinking language compliance for both seen and unseen languages. Analysis shows that, by enabling on-policy thinking language selection as an action during RL, ExpLang effectively extends the RL exploration space with diversified language preference and improves the RL exploitation outcome with leveraged non-English advantage. The method is orthogonal to most RL algorithms and opens up a new perspective on using multilinguality to improve LRMs.",
        "url": "http://arxiv.org/abs/2602.21887v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21887v1",
        "arxiv_id": "2602.21887v1",
        "authors": [
            "Changjiang Gao",
            "Zixian Huang",
            "Kaichen Yang",
            "Jiajun Chen",
            "Jixing Li",
            "Shujian Huang"
        ],
        "submitted": "2026-02-25 13:10:58",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "DynamicGTR: Leveraging Graph Topology Representation Preferences to Boost VLM Capabilities on Graph QAs",
        "abstract": "Vision-Language Models (VLMs) have emerged as versatile solutions for zero-shot question answering (QA) across various domains. However, enabling VLMs to effectively comprehend structured graphs and perform accurate, efficient QA remains challenging. Existing approaches typically rely on one single graph topology representation (GTR), such as fixed-style visual images or unified text descriptions. This ``one-size-fits-all'' strategy often neglects model-specific and task-specific preferences, resulting in inaccurate or over-lengthy responses to graph-related queries. To address this, we propose the $\\mbox{DynamicGTR}$ framework, which dynamically selects the optimal GTR for each query during inference, thereby enhancing the zero-shot graph QA capabilities of VLMs with a customizable accuracy and brevity trade-off. Extensive experiments show that DynamicGTR not only improves VLM-based graph algorithm QA performance but also successfully transfers the experience trained from synthetic graph algorithm tasks to real-world applications like link prediction and node classification, without any additional training. Additionally, DynamicGTR demonstrates strong transferability across tasks, domains, and models, suggesting its potential as a flexible solution for broad graph scenarios.",
        "url": "http://arxiv.org/abs/2602.21864v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21864v1",
        "arxiv_id": "2602.21864v1",
        "authors": [
            "Yanbin Wei",
            "Jiangyue Yan",
            "Chun Kang",
            "Yang Chen",
            "Hua Liu",
            "James Kwok",
            "Yu Zhang"
        ],
        "submitted": "2026-02-25 12:45:45",
        "source": "arxiv",
        "comment": "CVPR 2026"
    },
    {
        "title": "Personalized Graph-Empowered Large Language Model for Proactive Information Access",
        "abstract": "Since individuals may struggle to recall all life details and often confuse events, establishing a system to assist users in recalling forgotten experiences is essential. While numerous studies have proposed memory recall systems, these primarily rely on deep learning techniques that require extensive training and often face data scarcity due to the limited availability of personal lifelogs. As lifelogs grow over time, systems must also adapt quickly to newly accumulated data. Recently, large language models (LLMs) have demonstrated remarkable capabilities across various tasks, making them promising for personalized applications. In this work, we present a framework that leverages LLMs for proactive information access, integrating personal knowledge graphs to enhance the detection of access needs through a refined decision-making process. Our framework offers high flexibility, enabling the replacement of base models and the modification of fact retrieval methods for continuous improvement. Experimental results demonstrate that our approach effectively identifies forgotten events, supporting users in recalling past experiences more efficiently.",
        "url": "http://arxiv.org/abs/2602.21862v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21862v1",
        "arxiv_id": "2602.21862v1",
        "authors": [
            "Chia Cheng Chang",
            "An-Zi Yen",
            "Hen-Hsen Huang",
            "Hsin-Hsi Chen"
        ],
        "submitted": "2026-02-25 12:43:25",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Distill and Align Decomposition for Enhanced Claim Verification",
        "abstract": "Complex claim verification requires decomposing sentences into verifiable subclaims, yet existing methods struggle to align decomposition quality with verification performance. We propose a reinforcement learning (RL) approach that jointly optimizes decomposition quality and verifier alignment using Group Relative Policy Optimization (GRPO). Our method integrates: (i) structured sequential reasoning; (ii) supervised finetuning on teacher-distilled exemplars; and (iii) a multi-objective reward balancing format compliance, verifier alignment, and decomposition quality. Across six evaluation settings, our trained 8B decomposer improves downstream verification performance to (71.75%) macro-F1, outperforming prompt-based approaches ((+1.99), (+6.24)) and existing RL methods ((+5.84)). Human evaluation confirms the high quality of the generated subclaims. Our framework enables smaller language models to achieve state-of-the-art claim verification by jointly optimising for verification accuracy and decomposition quality.",
        "url": "http://arxiv.org/abs/2602.21857v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21857v1",
        "arxiv_id": "2602.21857v1",
        "authors": [
            "Jabez Magomere",
            "Elena Kochkina",
            "Samuel Mensah",
            "Simerjot Kaur",
            "Fernando Acero",
            "Arturo Oncevay",
            "Charese H. Smiley",
            "Xiaomo Liu",
            "Manuela Veloso"
        ],
        "submitted": "2026-02-25 12:32:04",
        "source": "arxiv",
        "comment": "EACL Findings 2026"
    },
    {
        "title": "FewMMBench: A Benchmark for Multimodal Few-Shot Learning",
        "abstract": "As multimodal large language models (MLLMs) advance in handling interleaved image-text data, assessing their few-shot learning capabilities remains an open challenge. In this paper, we introduce FewMMBench, a comprehensive benchmark designed to evaluate MLLMs under few-shot conditions, with a focus on In-Context Learning (ICL) and Chain-of-Thought (CoT) prompting. Covering a diverse suite of multimodal understanding tasks, from attribute recognition to temporal reasoning, FewMMBench enables systematic analysis across task types, model families, and prompting strategies. We evaluate 26 open-weight MLLMs from six model families across zero-shot, few-shot, and CoT-augmented few-shot settings. Our findings reveal that instruction-tuned models exhibit strong zero-shot performance but benefit minimally, or even regress, with additional demonstrations or CoT reasoning. Retrieval-based demonstrations and increased context size also yield limited gains. These results highlight FewMMBench as a rigorous testbed for diagnosing and advancing few-shot capabilities in multimodal LLMs. The data is available at: https://huggingface.co/datasets/mustafaa/FewMMBench",
        "url": "http://arxiv.org/abs/2602.21854v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21854v1",
        "arxiv_id": "2602.21854v1",
        "authors": [
            "Mustafa Dogan",
            "Ilker Kesen",
            "Iacer Calixto",
            "Aykut Erdem",
            "Erkut Erdem"
        ],
        "submitted": "2026-02-25 12:30:18",
        "source": "arxiv",
        "comment": "Preprint. 49 pages, 38 Figures, 5 Tables"
    },
    {
        "title": "Prompt Architecture Determines Reasoning Quality: A Variable Isolation Study on the Car Wash Problem",
        "abstract": "Large language models consistently fail the \"car wash problem,\" a viral reasoning benchmark requiring implicit physical constraint inference. We present a variable isolation study (n=20 per condition, 6 conditions, 120 total trials) examining which prompt architecture layers in a production system enable correct reasoning. Using Claude 3.5 Sonnet with controlled hyperparameters (temperature 0.7, top_p 1.0), we find that the STAR (Situation-Task-Action-Result) reasoning framework alone raises accuracy from 0% to 85% (p=0.001, Fisher's exact test, odds ratio 13.22). Adding user profile context via vector database retrieval provides a further 10 percentage point gain, while RAG context contributes an additional 5 percentage points, achieving 100% accuracy in the full-stack condition. These results suggest that structured reasoning scaffolds -- specifically, forced goal articulation before inference -- matter substantially more than context injection for implicit constraint reasoning tasks.",
        "url": "http://arxiv.org/abs/2602.21814v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21814v1",
        "arxiv_id": "2602.21814v1",
        "authors": [
            "Heejin Jo"
        ],
        "submitted": "2026-02-25 11:40:15",
        "source": "arxiv",
        "comment": "9 pages, 4 tables"
    },
    {
        "title": "D-COT: Disciplined Chain-of-Thought Learning for Efficient Reasoning in Small Language Models",
        "abstract": "Chain-of-Thought (CoT) distillation from Large Language Models (LLMs) often induces \"overthinking\" in Small Language Models (SLMs), leading to performance degradation and excessive token consumption. In this study, we propose Disciplined Chain-of-Thought (D-CoT), a novel framework that enforces a structured reasoning process using control tags -- such as <TEMP_LOW> for fact-checking and <TEMP_HIGH> for multi-perspective exploration -- as auxiliary scaffolding during training. By optimizing the CoT trajectory, D-CoT suppresses reasoning drift and simultaneously achieves token reduction and performance improvement. We demonstrate the efficacy of our approach on Qwen3-8B: with only 5,000 training samples, D-CoT significantly boosts accuracy on GPQA-diamond by 9.9% and MMLU-Pro (0-shot) by 9.1%, while drastically reducing computational costs. Furthermore, we confirm that the model internalizes this disciplined thought structure, maintaining high performance even without explicit control tags during inference.",
        "url": "http://arxiv.org/abs/2602.21786v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21786v1",
        "arxiv_id": "2602.21786v1",
        "authors": [
            "Shunsuke Ubukata"
        ],
        "submitted": "2026-02-25 11:08:38",
        "source": "arxiv",
        "comment": "9 pages, 3 figures. Code: https://github.com/gitpullpull/DisciplinedChainOfThought | Benchmarks: https://huggingface.co/datasets/gitpullpull/D-CoT-Benchmarks | Dataset: https://huggingface.co/datasets/gitpullpull/D-CoT-datasets"
    },
    {
        "title": "RETLLM: Training and Data-Free MLLMs for Multimodal Information Retrieval",
        "abstract": "Multimodal information retrieval (MMIR) has gained attention for its flexibility in handling text, images, or mixed queries and candidates. Recent breakthroughs in multimodal large language models (MLLMs) boost MMIR performance by incorporating MLLM knowledge under the contrastive finetuning framework. However, they suffer from pre-training inconsistency and require large datasets. In this work, we introduce a novel framework, RetLLM, designed to query MLLMs for MMIR in a training- and data-free manner. Specifically, we formulate MMIR as a similarity score generation task and prompt MLLMs to directly predict retrieval scores in a coarse-then-fine pipeline. At the coarse stage, a top-k filtering strategy builds a small yet high-quality candidate pool for each query, enabling MLLMs to focus on semantically relevant candidates. Subsequently, the retrieval score is predicted by feeding both the query and candidate into MLLMs at the fine stage. Importantly, we propose a visual enhancement module during reasoning to help MLLMs re-pick forgotten visuals, improving retrieval. Extensive experiments on MMIR benchmarks show that RetLLM outperforms fine-tuned models. Ablation studies further verify each component. Our work demonstrates that MLLMs can achieve strong MMIR performance without any training, highlighting their inherent multimodal reasoning ability in a simple, scalable framework. We release our code at: https://github.com/alivecat05/RETLLM",
        "url": "http://arxiv.org/abs/2602.22278v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22278v1",
        "arxiv_id": "2602.22278v1",
        "authors": [
            "Dawei Su",
            "Dongsheng Wang"
        ],
        "submitted": "2026-02-25 10:31:32",
        "source": "arxiv",
        "comment": "5 pages, 2 figure"
    },
    {
        "title": "Improving Implicit Discourse Relation Recognition with Natural Language Explanations from LLMs",
        "abstract": "Implicit Discourse Relation Recognition (IDRR) remains a challenging task due to the requirement for deep semantic understanding in the absence of explicit discourse markers. A further limitation is that existing methods only predict relations without providing any supporting explanations. Recent advances in large language models (LLMs) have shown strong reasoning capabilities in both deep language understanding and natural language explanation generation. In this work, we propose a simple yet effective approach to distill the reasoning capabilities of LLMs into lightweight IDRR models to improve both performance and interpretability. Specifically, we first prompt an LLM to generate explanations for each training instance conditioned on its gold label. Then, we introduce a novel classification-generation framework that jointly performs relation prediction and explanation generation, and train it with the additional supervision of LLM-generated explanations. Our framework is plug-and-play, enabling easy integration with most existing IDRR models. Experimental results on PDTB demonstrate that our approach significantly improves IDRR performance, while human evaluation further confirms that the generated explanations enhance model interpretability. Furthermore, we validate the generality of our approach on sentiment classification and natural language inference",
        "url": "http://arxiv.org/abs/2602.21763v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21763v1",
        "arxiv_id": "2602.21763v1",
        "authors": [
            "Heng Wang",
            "Changxing Wu"
        ],
        "submitted": "2026-02-25 10:28:45",
        "source": "arxiv",
        "comment": "AAAI26'0ral"
    },
    {
        "title": "Offline Reasoning for Efficient Recommendation: LLM-Empowered Persona-Profiled Item Indexing",
        "abstract": "Recent advances in large language models (LLMs) offer new opportunities for recommender systems by capturing the nuanced semantics of user interests and item characteristics through rich semantic understanding and contextual reasoning. In particular, LLMs have been employed as rerankers that reorder candidate items based on inferred user-item relevance. However, these approaches often require expensive online inference-time reasoning, leading to high latency that hampers real-world deployment. In this work, we introduce Persona4Rec, a recommendation framework that performs offline reasoning to construct interpretable persona representations of items, enabling lightweight and scalable real-time inference. In the offline stage, Persona4Rec leverages LLMs to reason over item reviews, inferring diverse user motivations that explain why different types of users may engage with an item; these inferred motivations are materialized as persona representations, providing multiple, human-interpretable views of each item. Unlike conventional approaches that rely on a single item representation, Persona4Rec learns to align user profiles with the most plausible item-side persona through a dedicated encoder, effectively transforming user-item relevance into user-persona relevance. At the online stage, this persona-profiled item index allows fast relevance computation without invoking expensive LLM reasoning. Extensive experiments show that Persona4Rec achieves performance comparable to recent LLM-based rerankers while substantially reducing inference time. Moreover, qualitative analysis confirms that persona representations not only drive efficient scoring but also provide intuitive, review-grounded explanations. These results demonstrate that Persona4Rec offers a practical and interpretable solution for next-generation recommender systems.",
        "url": "http://arxiv.org/abs/2602.21756v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21756v1",
        "arxiv_id": "2602.21756v1",
        "authors": [
            "Deogyong Kim",
            "Junseong Lee",
            "Jeongeun Lee",
            "Changhoe Kim",
            "Junguel Lee",
            "Jungseok Lee",
            "Dongha Lee"
        ],
        "submitted": "2026-02-25 10:14:30",
        "source": "arxiv",
        "comment": "Under review"
    },
    {
        "title": "Robust Long-Form Bangla Speech Processing: Automatic Speech Recognition and Speaker Diarization",
        "abstract": "We describe our end-to-end system for Bengali long-form speech recognition (ASR) and speaker diarization submitted to the DL Sprint 4.0 competition on Kaggle. Bengali presents substantial challenges for both tasks: a large phoneme inventory, significant dialectal variation, frequent code-mixing with English, and a relative scarcity of large-scale labelled corpora. For ASR we achieve a best private Word Error Rate (WER) of 0.37738 and public WER of 0.36137, combining a BengaliAI fine-tuned Whisper medium model with Demucs source separation for vocal isolation, silence-boundary chunking, and carefully tuned generation hyperparameters. For speaker diarization we reach a best private Diarization Error Rate (DER) of 0.27671 and public DER of 0.20936 by replacing the default segmentation model inside the pyannote.audio pipeline with a Bengali-fine-tuned variant, pairing it with wespeaker-voxceleb-resnet34-LM embeddings and centroid-based agglomerative clustering. Our experiments demonstrate that domain-specific fine-tuning of the segmentation component, vocal source separation, and natural silence-aware chunking are the three most impactful design choices for low-resource Bengali speech processing.",
        "url": "http://arxiv.org/abs/2602.21741v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21741v1",
        "arxiv_id": "2602.21741v1",
        "authors": [
            "MD. Sagor Chowdhury",
            "Adiba Fairooz Chowdhury"
        ],
        "submitted": "2026-02-25 09:52:32",
        "source": "arxiv",
        "comment": "6 pages, 5 figures, 3 tables; system paper submitted to DL Sprint 4.0 (Kaggle)"
    },
    {
        "title": "Explore-on-Graph: Incentivizing Autonomous Exploration of Large Language Models on Knowledge Graphs with Path-refined Reward Modeling",
        "abstract": "The reasoning process of Large Language Models (LLMs) is often plagued by hallucinations and missing facts in question-answering tasks. A promising solution is to ground LLMs' answers in verifiable knowledge sources, such as Knowledge Graphs (KGs). Prevailing KG-enhanced methods typically constrained LLM reasoning either by enforcing rules during generation or by imitating paths from a fixed set of demonstrations. However, they naturally confined the reasoning patterns of LLMs within the scope of prior experience or fine-tuning data, limiting their generalizability to out-of-distribution graph reasoning problems. To tackle this problem, in this paper, we propose Explore-on-Graph (EoG), a novel framework that encourages LLMs to autonomously explore a more diverse reasoning space on KGs. To incentivize exploration and discovery of novel reasoning paths, we propose to introduce reinforcement learning during training, whose reward is the correctness of the reasoning paths' final answers. To enhance the efficiency and meaningfulness of the exploration, we propose to incorporate path information as additional reward signals to refine the exploration process and reduce futile efforts. Extensive experiments on five KGQA benchmark datasets demonstrate that, to the best of our knowledge, our method achieves state-of-the-art performance, outperforming not only open-source but also even closed-source LLMs.",
        "url": "http://arxiv.org/abs/2602.21728v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21728v1",
        "arxiv_id": "2602.21728v1",
        "authors": [
            "Shiqi Yan",
            "Yubo Chen",
            "Ruiqi Zhou",
            "Zhengxi Yao",
            "Shuai Chen",
            "Tianyi Zhang",
            "Shijie Zhang",
            "Wei Qiang Zhang",
            "Yongfeng Huang",
            "Haixin Duan",
            "Yunqi Zhang"
        ],
        "submitted": "2026-02-25 09:35:18",
        "source": "arxiv",
        "comment": "Published as a conference paper at ICLR 2026"
    },
    {
        "title": "Evaluating the relationship between regularity and learnability in recursive numeral systems using Reinforcement Learning",
        "abstract": "Human recursive numeral systems (i.e., counting systems such as English base-10 numerals), like many other grammatical systems, are highly regular. Following prior work that relates cross-linguistic tendencies to biases in learning, we ask whether regular systems are common because regularity facilitates learning. Adopting methods from the Reinforcement Learning literature, we confirm that highly regular human(-like) systems are easier to learn than unattested but possible irregular systems. This asymmetry emerges under the natural assumption that recursive numeral systems are designed for generalisation from limited data to represent all integers exactly. We also find that the influence of regularity on learnability is absent for unnatural, highly irregular systems, whose learnability is influenced instead by signal length, suggesting that different pressures may influence learnability differently in different parts of the space of possible numeral systems. Our results contribute to the body of work linking learnability to cross-linguistic prevalence.",
        "url": "http://arxiv.org/abs/2602.21720v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21720v1",
        "arxiv_id": "2602.21720v1",
        "authors": [
            "Andrea Silvi",
            "Ponrawee Prasertsom",
            "Jennifer Culbertson",
            "Devdatt Dubhashi",
            "Moa Johansson",
            "Kenny Smith"
        ],
        "submitted": "2026-02-25 09:27:02",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Trie-Aware Transformers for Generative Recommendation",
        "abstract": "Generative recommendation (GR) aligns with advances in generative AI by casting next-item prediction as token-level generation rather than score-based ranking. Most GR methods adopt a two-stage pipeline: (i) \\textit{item tokenization}, which maps each item to a sequence of discrete, hierarchically organized tokens; and (ii) \\textit{autoregressive generation}, which predicts the next item's tokens conditioned on the tokens of user's interaction history. Although hierarchical tokenization induces a prefix tree (trie) over items, standard autoregressive modeling with conventional Transformers often flattens item tokens into a linear stream and overlooks the underlying topology.\n  To address this, we propose TrieRec, a trie-aware generative recommendation method that augments Transformers with structural inductive biases via two positional encodings. First, a \\textit{trie-aware absolute positional encoding} aggregates a token's (node's) local structural context (\\eg depth, ancestors, and descendants) into the token representation. Second, a \\textit{topology-aware relative positional encoding} injects pairwise structural relations into self-attention to capture topology-induced semantic relatedness. TrieRec is also model-agnostic, efficient, and hyperparameter-free. In our experiments, we implement TrieRec within three representative GR backbones, achieving notably improvements of 8.83\\% on average across four real-world datasets.",
        "url": "http://arxiv.org/abs/2602.21677v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21677v1",
        "arxiv_id": "2602.21677v1",
        "authors": [
            "Zhenxiang Xu",
            "Jiawei Chen",
            "Sirui Chen",
            "Yong He",
            "Jieyu Yang",
            "Chuan Yuan",
            "Ke Ding",
            "Can Wang"
        ],
        "submitted": "2026-02-25 08:25:16",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "DWA-KD: Dual-Space Weighting and Time-Warped Alignment for Cross-Tokenizer Knowledge Distillation",
        "abstract": "Knowledge Distillation (KD) has emerged as a crucial technique for compressing Large Language Models (LLMs). Although existing cross-tokenizer KD methods have made notable progress, their effectiveness remains constrained by suboptimal alignment across sequence and vocabulary levels. To address these limitations, we introduce Dual-Space Weighting and Time-Warped Alignment (DWA-KD), a novel cross-tokenizer distillation framework that enhances token-wise distillation through dual-space entropy-based weighting and achieves precise sequence-level alignment by leveraging both lexical and semantic information. At the token level, DWA-KD maps teacher representations into the student space and vice versa, performing dual-space KD via Kullback-Leibler divergence (KL). The process is modulated by dual-space weights that up-weight tokens where the student is uncertain and the teacher is confident, thereby focusing learning on informative tokens rather than treating all positions equally. At the sequence level, DWA-KD applies Soft Dynamic Time Warping (Soft-DTW) to both the embedding and final hidden-state layers, enabling robust alignment of lexical and contextual semantics between teacher and student sequences. Extensive experiments across diverse NLP benchmarks demonstrate that DWA-KD outperforms state-of-the-art KD baselines, while ablation studies confirm the complementary contributions of entropy-based token weighting and embedding and final hidden state layer Soft-DTW alignment.",
        "url": "http://arxiv.org/abs/2602.21669v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21669v1",
        "arxiv_id": "2602.21669v1",
        "authors": [
            "Duc Trung Vu",
            "Pham Khanh Chi",
            "Dat Phi Van",
            "Linh Ngo Van",
            "Sang Dinh",
            "Trung Le"
        ],
        "submitted": "2026-02-25 08:04:44",
        "source": "arxiv",
        "comment": "EACL Findings"
    },
    {
        "title": "Sparsity Induction for Accurate Post-Training Pruning of Large Language Models",
        "abstract": "Large language models have demonstrated capabilities in text generation, while their increasing parameter scales present challenges in computational and memory efficiency. Post-training sparsity (PTS), which reduces model cost by removing weights from dense networks, is an effective approach. However, native dense matrices lack high sparsity, making existing approaches that directly remove weights disrupt model states, resulting in unsatisfactory performance recovery even with post-tuning. We propose Sparsity Induction, which promotes models toward higher sparsity at both distribution and feature levels before pruning, to push the limits of PTS. At the distribution level, we enhance distributional sparsity through mathematically equivalent scaling transformations, which are fully absorbable and incur no extra parameters or inference-time overhead. At the feature level, we introduce Spectral Norm Loss to promote feature sparsity from a low-rank perspective. Experiments across diverse model architectures and tasks demonstrate that our method further enhances sparsity-friendliness, achieving superior pruning performance over existing approaches.",
        "url": "http://arxiv.org/abs/2602.21652v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21652v1",
        "arxiv_id": "2602.21652v1",
        "authors": [
            "Minhao Jiang",
            "Zhikai Li",
            "Xuewen Liu",
            "Jing Zhang",
            "Mengjuan Chen",
            "Qingyi Gu"
        ],
        "submitted": "2026-02-25 07:25:01",
        "source": "arxiv",
        "comment": "5 pages, 1 figure, 4 tables"
    },
    {
        "title": "Mitigating Structural Noise in Low-Resource S2TT: An Optimized Cascaded Nepali-English Pipeline with Punctuation Restoration",
        "abstract": "This paper presents and evaluates an optimized cascaded Nepali speech-to-English text translation (S2TT) system, focusing on mitigating structural noise introduced by Automatic Speech Recognition (ASR). We first establish highly proficient ASR and NMT components: a Wav2Vec2-XLS-R-300m model achieved a state-of-the-art 2.72% CER on OpenSLR-54, and a multi-stage fine-tuned MarianMT model reached a 28.32 BLEU score on the FLORES-200 benchmark. We empirically investigate the influence of punctuation loss, demonstrating that unpunctuated ASR output significantly degrades translation quality, causing a massive 20.7% relative BLEU drop on the FLORES benchmark. To overcome this, we propose and evaluate an intermediate Punctuation Restoration Module (PRM). The final S2TT pipeline was tested across three configurations on a custom dataset. The optimal configuration, which applied the PRM directly to ASR output, achieved a 4.90 BLEU point gain over the direct ASR-to-NMT baseline (BLEU 36.38 vs. 31.48). This improvement was validated by human assessment, which confirmed the optimized pipeline's superior Adequacy (3.673) and Fluency (3.804). This work validates that targeted punctuation restoration is the most effective intervention for mitigating structural noise in the Nepali S2TT pipeline. It establishes an optimized baseline and demonstrates a critical architectural insight for developing cascaded speech translation systems for similar low-resource languages.",
        "url": "http://arxiv.org/abs/2602.21647v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21647v1",
        "arxiv_id": "2602.21647v1",
        "authors": [
            "Tangsang Chongbang",
            "Pranesh Pyara Shrestha",
            "Amrit Sarki",
            "Anku Jaiswal"
        ],
        "submitted": "2026-02-25 07:20:23",
        "source": "arxiv",
        "comment": "13 pages, 4 figures, 12 tables"
    },
    {
        "title": "Scalable Multilingual Multimodal Machine Translation with Speech-Text Fusion",
        "abstract": "Multimodal Large Language Models (MLLMs) have achieved notable success in enhancing translation performance by integrating multimodal information. However, existing research primarily focuses on image-guided methods, whose applicability is constrained by the scarcity of multilingual image-text pairs. The speech modality overcomes this limitation due to its natural alignment with text and the abundance of existing speech datasets, which enable scalable language coverage. In this paper, we propose a Speech-guided Machine Translation (SMT) framework that integrates speech and text as fused inputs into an MLLM to improve translation quality. To mitigate reliance on low-resource data, we introduce a Self-Evolution Mechanism. The core components of this framework include a text-to-speech model, responsible for generating synthetic speech, and an MLLM capable of classifying synthetic speech samples and iteratively optimizing itself using positive samples. Experimental results demonstrate that our framework surpasses all existing methods on the Multi30K multimodal machine translation benchmark, achieving new state-of-the-art results. Furthermore, on general machine translation datasets, particularly the FLORES-200, it achieves average state-of-the-art performance in 108 translation directions. Ablation studies on CoVoST-2 confirms that differences between synthetic and authentic speech have negligible impact on translation quality. The code and models are released at https://github.com/yxduir/LLM-SRT.",
        "url": "http://arxiv.org/abs/2602.21646v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21646v1",
        "arxiv_id": "2602.21646v1",
        "authors": [
            "Yexing Du",
            "Youcheng Pan",
            "Zekun Wang",
            "Zheng Chu",
            "Yichong Huang",
            "Kaiyuan Liu",
            "Bo Yang",
            "Yang Xiang",
            "Ming Liu",
            "Bing Qin"
        ],
        "submitted": "2026-02-25 07:19:34",
        "source": "arxiv",
        "comment": "Accepted in ICLR 2026"
    },
    {
        "title": "Multi-dimensional Assessment and Explainable Feedback for Counselor Responses to Client Resistance in Text-based Counseling with LLMs",
        "abstract": "Effectively addressing client resistance is a sophisticated clinical skill in psychological counseling, yet practitioners often lack timely and scalable supervisory feedback to refine their approaches. Although current NLP research has examined overall counseling quality and general therapeutic skills, it fails to provide granular evaluations of high-stakes moments where clients exhibit resistance. In this work, we present a comprehensive pipeline for the multi-dimensional evaluation of human counselors' interventions specifically targeting client resistance in text-based therapy. We introduce a theory-driven framework that decomposes counselor responses into four distinct communication mechanisms. Leveraging this framework, we curate and share an expert-annotated dataset of real-world counseling excerpts, pairing counselor-client interactions with professional ratings and explanatory rationales. Using this data, we perform full-parameter instruction tuning on a Llama-3.1-8B-Instruct backbone to model fine-grained evaluative judgments of response quality and generate explanations underlying. Experimental results show that our approach can effectively distinguish the quality of different communication mechanisms (77-81% F1), substantially outperforming GPT-4o and Claude-3.5-Sonnet (45-59% F1). Moreover, the model produces high-quality explanations that closely align with expert references and receive near-ceiling ratings from human experts (2.8-2.9/3.0). A controlled experiment with 43 counselors further confirms that receiving these AI-generated feedback significantly improves counselors' ability to respond effectively to client resistance.",
        "url": "http://arxiv.org/abs/2602.21638v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21638v1",
        "arxiv_id": "2602.21638v1",
        "authors": [
            "Anqi Li",
            "Ruihan Wang",
            "Zhaoming Chen",
            "Yuqian Chen",
            "Yu Lu",
            "Yi Zhu",
            "Yuan Xie",
            "Zhenzhong Lan"
        ],
        "submitted": "2026-02-25 07:05:05",
        "source": "arxiv",
        "comment": "8 pages"
    },
    {
        "title": "RuCL: Stratified Rubric-Based Curriculum Learning for Multimodal Large Language Model Reasoning",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a prevailing paradigm for enhancing reasoning in Multimodal Large Language Models (MLLMs). However, relying solely on outcome supervision risks reward hacking, where models learn spurious reasoning patterns to satisfy final answer checks. While recent rubric-based approaches offer fine-grained supervision signals, they suffer from high computational costs of instance-level generation and inefficient training dynamics caused by treating all rubrics as equally learnable. In this paper, we propose Stratified Rubric-based Curriculum Learning (RuCL), a novel framework that reformulates curriculum learning by shifting the focus from data selection to reward design. RuCL generates generalized rubrics for broad applicability and stratifies them based on the model's competence. By dynamically adjusting rubric weights during training, RuCL guides the model from mastering foundational perception to tackling advanced logical reasoning. Extensive experiments on various visual reasoning benchmarks show that RuCL yields a remarkable +7.83% average improvement over the Qwen2.5-VL-7B model, achieving a state-of-the-art accuracy of 60.06%.",
        "url": "http://arxiv.org/abs/2602.21628v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21628v1",
        "arxiv_id": "2602.21628v1",
        "authors": [
            "Yukun Chen",
            "Jiaming Li",
            "Longze Chen",
            "Ze Gong",
            "Jingpeng Li",
            "Zhen Qin",
            "Hengyu Chang",
            "Ancheng Xu",
            "Zhihao Yang",
            "Hamid Alinejad-Rokny",
            "Qiang Qu",
            "Bo Zheng",
            "Min Yang"
        ],
        "submitted": "2026-02-25 06:46:24",
        "source": "arxiv",
        "comment": "8 pages"
    },
    {
        "title": "When More Is Less: A Systematic Analysis of Spatial and Commonsense Information for Visual Spatial Reasoning",
        "abstract": "Visual spatial reasoning (VSR) remains challenging for modern vision-language models (VLMs), despite advances in multimodal architectures. A common strategy is to inject additional information at inference time, such as explicit spatial cues, external commonsense knowledge, or chain-of-thought (CoT) reasoning instructions. However, it remains unclear when such information genuinely improves reasoning and when it introduces noise. In this paper, we conduct a hypothesis-driven analysis of information injection for VSR across three representative VLMs and two public benchmarks. We examine (i) the type and number of spatial contexts, (ii) the amount and relevance of injected commonsense knowledge, and (iii) the interaction between spatial grounding and CoT prompting. Our results reveal a consistent pattern: more information does not necessarily yield better reasoning. Targeted single spatial cues outperform multi-context aggregation, excessive or weakly relevant commonsense knowledge degrades performance, and CoT prompting improves accuracy only when spatial grounding is sufficiently precise. These findings highlight the importance of selective, task-aligned information injection and provide practical guidance for designing reliable multimodal reasoning pipelines.",
        "url": "http://arxiv.org/abs/2602.21619v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21619v1",
        "arxiv_id": "2602.21619v1",
        "authors": [
            "Muku Akasaka",
            "Soyeon Caren Han"
        ],
        "submitted": "2026-02-25 06:22:48",
        "source": "arxiv",
        "comment": "5 pages, 6 figures, Under review"
    },
    {
        "title": "MixSarc: A Bangla-English Code-Mixed Corpus for Implicit Meaning Identification",
        "abstract": "Bangla-English code-mixing is widespread across South Asian social media, yet resources for implicit meaning identification in this setting remain scarce. Existing sentiment and sarcasm models largely focus on monolingual English or high-resource languages and struggle with transliteration variation, cultural references, and intra-sentential language switching. To address this gap, we introduce MixSarc, the first publicly available Bangla-English code-mixed corpus for implicit meaning identification. The dataset contains 9,087 manually annotated sentences labeled for humor, sarcasm, offensiveness, and vulgarity. We construct the corpus through targeted social media collection, systematic filtering, and multi-annotator validation. We benchmark transformer-based models and evaluate zero-shot large language models under structured prompting. Results show strong performance on humor detection but substantial degradation on sarcasm, offense, and vulgarity due to class imbalance and pragmatic complexity. Zero-shot models achieve competitive micro-F1 scores but low exact match accuracy. Further analysis reveals that over 42\\% of negative sentiment instances in an external dataset exhibit sarcastic characteristics. MixSarc provides a foundational resource for culturally aware NLP and supports more reliable multi-label modeling in code-mixed environments.",
        "url": "http://arxiv.org/abs/2602.21608v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21608v1",
        "arxiv_id": "2602.21608v1",
        "authors": [
            "Kazi Samin Yasar Alam",
            "Md Tanbir Chowdhury",
            "Tamim Ahmed",
            "Ajwad Abrar",
            "Md Rafid Haque"
        ],
        "submitted": "2026-02-25 06:12:06",
        "source": "arxiv",
        "comment": "Under Review"
    },
    {
        "title": "AQR-HNSW: Accelerating Approximate Nearest Neighbor Search via Density-aware Quantization and Multi-stage Re-ranking",
        "abstract": "Approximate Nearest Neighbor (ANN) search has become fundamental to modern AI infrastructure, powering recommendation systems, search engines, and large language models across industry leaders from Google to OpenAI. Hierarchical Navigable Small World (HNSW) graphs have emerged as the dominant ANN algorithm, widely adopted in production systems due to their superior recall versus latency balance. However, as vector databases scale to billions of embeddings, HNSW faces critical bottlenecks: memory consumption expands, distance computation overhead dominates query latency, and it suffers suboptimal performance on heterogeneous data distributions. This paper presents Adaptive Quantization and Rerank HNSW (AQR-HNSW), a novel framework that synergistically integrates three strategies to enhance HNSW scalability. AQR-HNSW introduces (1) density-aware adaptive quantization, achieving 4x compression while preserving distance relationships; (2) multi-state re-ranking that reduces unnecessary computations by 35%; and (3) quantization-optimized SIMD implementations delivering 16-64 operations per cycle across architectures. Evaluation on standard benchmarks demonstrates 2.5-3.3x higher queries per second (QPS) than state-of-the-art HNSW implementations while maintaining over 98% recall, with 75% memory reduction for the index graph and 5x faster index construction.",
        "url": "http://arxiv.org/abs/2602.21600v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21600v1",
        "arxiv_id": "2602.21600v1",
        "authors": [
            "Ganap Ashit Tewary",
            "Nrusinga Charan Gantayat",
            "Jeff Zhang"
        ],
        "submitted": "2026-02-25 05:58:16",
        "source": "arxiv",
        "comment": "Accepted at DAC 2026"
    },
    {
        "title": "Retrieval Challenges in Low-Resource Public Service Information: A Case Study on Food Pantry Access",
        "abstract": "Public service information systems are often fragmented, inconsistently formatted, and outdated. These characteristics create low-resource retrieval environments that hinder timely access to critical services. We investigate retrieval challenges in such settings through the domain of food pantry access, a socially urgent problem given persistent food insecurity. We develop an AI-powered conversational retrieval system that scrapes and indexes publicly available pantry data and employs a Retrieval-Augmented Generation (RAG) pipeline to support natural language queries via a web interface. We conduct a pilot evaluation study using community-sourced queries to examine system behavior in realistic scenarios. Our analysis reveals key limitations in retrieval robustness, handling underspecified queries, and grounding over inconsistent knowledge bases. This ongoing work exposes fundamental IR challenges in low-resource environments and motivates future research on robust conversational retrieval to improve access to critical public resources.",
        "url": "http://arxiv.org/abs/2602.21598v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21598v1",
        "arxiv_id": "2602.21598v1",
        "authors": [
            "Touseef Hasan",
            "Laila Cure",
            "Souvika Sarkar"
        ],
        "submitted": "2026-02-25 05:48:15",
        "source": "arxiv",
        "comment": "3 pages, 1 figure"
    },
    {
        "title": "Duel-Evolve: Reward-Free Test-Time Scaling via LLM Self-Preferences",
        "abstract": "Many applications seek to optimize LLM outputs at test time by iteratively proposing, scoring, and refining candidates over a discrete output space. Existing methods use a calibrated scalar evaluator for the target objective to guide search, but for many tasks such scores are unavailable, too sparse, or unreliable. Pairwise comparisons, by contrast, are often easier to elicit, still provide useful signal on improvement directions, and can be obtained from the LLM itself without external supervision. Building on this observation, we introduce Duel-Evolve, an evolutionary optimization algorithm that replaces external scalar rewards with pairwise preferences elicited from the same LLM used to generate candidates. Duel-Evolve aggregates these noisy candidate comparisons via a Bayesian Bradley-Terry model, yielding uncertainty-aware estimates of candidate quality. These quality estimates guide allocation of the comparison budget toward plausible optima using Double Thompson Sampling, as well as selection of high-quality parents to generate improved candidates. We evaluate Duel-Evolve on MathBench, where it achieves 20 percentage points higher accuracy over existing methods and baselines, and on LiveCodeBench, where it improves over comparable iterative methods by over 12 percentage points. Notably, the method requires no reward model, no ground-truth labels during search, and no hand-crafted scoring function. Results show that pairwise self-preferences provide strong optimization signal for test-time improvement over large, discrete output spaces.",
        "url": "http://arxiv.org/abs/2602.21585v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21585v1",
        "arxiv_id": "2602.21585v1",
        "authors": [
            "Sweta Karlekar",
            "Carolina Zheng",
            "Magnus Saebo",
            "Nicolas Beltran-Velez",
            "Shuyang Yu",
            "John Bowlan",
            "Michal Kucer",
            "David Blei"
        ],
        "submitted": "2026-02-25 05:16:11",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Revisiting RAG Retrievers: An Information Theoretic Benchmark",
        "abstract": "Retrieval-Augmented Generation (RAG) systems rely critically on the retriever module to surface relevant context for large language models. Although numerous retrievers have recently been proposed, each built on different ranking principles such as lexical matching, dense embeddings, or graph citations, there remains a lack of systematic understanding of how these mechanisms differ and overlap. Existing benchmarks primarily compare entire RAG pipelines or introduce new datasets, providing little guidance on selecting or combining retrievers themselves. Those that do compare retrievers directly use a limited set of evaluation tools which fail to capture complementary and overlapping strengths. This work presents MIGRASCOPE, a Mutual Information based RAG Retriever Analysis Scope. We revisit state-of-the-art retrievers and introduce principled metrics grounded in information and statistical estimation theory to quantify retrieval quality, redundancy, synergy, and marginal contribution. We further show that if chosen carefully, an ensemble of retrievers outperforms any single retriever. We leverage the developed tools over major RAG corpora to provide unique insights on contribution levels of the state-of-the-art retrievers. Our findings provide a fresh perspective on the structure of modern retrieval techniques and actionable guidance for designing robust and efficient RAG systems.",
        "url": "http://arxiv.org/abs/2602.21553v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21553v1",
        "arxiv_id": "2602.21553v1",
        "authors": [
            "Wenqing Zheng",
            "Dmitri Kalaev",
            "Noah Fatsi",
            "Daniel Barcklow",
            "Owen Reinert",
            "Igor Melnyk",
            "Senthil Kumar",
            "C. Bayan Bruss"
        ],
        "submitted": "2026-02-25 04:19:06",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Enhancing Multilingual Embeddings via Multi-Way Parallel Text Alignment",
        "abstract": "Multilingual pretraining typically lacks explicit alignment signals, leading to suboptimal cross-lingual alignment in the representation space. In this work, we show that training standard pretrained models for cross-lingual alignment with a multi-way parallel corpus in a diverse pool of languages can substantially improve multilingual and cross-lingual representations for NLU tasks. We construct a multi-way parallel dataset using translations of English text from an off-the-shelf NMT model for a pool of six target languages and achieve strong cross-lingual alignment through contrastive learning. This leads to substantial performance gains across both seen and unseen languages for multiple tasks from the MTEB benchmark evaluated for XLM-Roberta and multilingual BERT base models. Using a multi-way parallel corpus for contrastive training yields substantial gains on bitext mining (21.3%), semantic similarity (5.3%), and classification (28.4%) compared to English-centric (En-X) bilingually parallel data, where X is sampled from a pool of multiple target languages. Furthermore, finetuning mE5 model on a small dataset with multi-way parallelism significantly improves bitext mining compared to one without, underscoring the importance of multi-way cross-lingual supervision even for models already pretrained for high-quality sentence embeddings.",
        "url": "http://arxiv.org/abs/2602.21543v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21543v1",
        "arxiv_id": "2602.21543v1",
        "authors": [
            "Barah Fazili",
            "Koustava Goswami"
        ],
        "submitted": "2026-02-25 03:58:24",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "One Brain, Omni Modalities: Towards Unified Non-Invasive Brain Decoding with Large Language Models",
        "abstract": "Deciphering brain function through non-invasive recordings requires synthesizing complementary high-frequency electromagnetic (EEG/MEG) and low-frequency metabolic (fMRI) signals. However, despite their shared neural origins, extreme discrepancies have traditionally confined these modalities to isolated analysis pipelines, hindering a holistic interpretation of brain activity. To bridge this fragmentation, we introduce \\textbf{NOBEL}, a \\textbf{n}euro-\\textbf{o}mni-modal \\textbf{b}rain-\\textbf{e}ncoding \\textbf{l}arge language model (LLM) that unifies these heterogeneous signals within the LLM's semantic embedding space. Our architecture integrates a unified encoder for EEG and MEG with a novel dual-path strategy for fMRI, aligning non-invasive brain signals and external sensory stimuli into a shared token space, then leverages an LLM as a universal backbone. Extensive evaluations demonstrate that NOBEL serves as a robust generalist across standard single-modal tasks. We also show that the synergistic fusion of electromagnetic and metabolic signals yields higher decoding accuracy than unimodal baselines, validating the complementary nature of multiple neural modalities. Furthermore, NOBEL exhibits strong capabilities in stimulus-aware decoding, effectively interpreting visual semantics from multi-subject fMRI data on the NSD and HAD datasets while uniquely leveraging direct stimulus inputs to verify causal links between sensory signals and neural responses. NOBEL thus takes a step towards unifying non-invasive brain decoding, demonstrating the promising potential of omni-modal brain understanding.",
        "url": "http://arxiv.org/abs/2602.21522v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21522v1",
        "arxiv_id": "2602.21522v1",
        "authors": [
            "Changli Tang",
            "Shurui Li",
            "Junliang Wang",
            "Qinfan Xiao",
            "Zhonghao Zhai",
            "Lei Bai",
            "Yu Qiao",
            "Bowen Zhou",
            "Wen Wu",
            "Yuanning Li",
            "Chao Zhang"
        ],
        "submitted": "2026-02-25 03:24:54",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "GradAlign: Gradient-Aligned Data Selection for LLM Reinforcement Learning",
        "abstract": "Reinforcement learning (RL) has become a central post-training paradigm for large language models (LLMs), but its performance is highly sensitive to the quality of training problems. This sensitivity stems from the non-stationarity of RL: rollouts are generated by an evolving policy, and learning is shaped by exploration and reward feedback, unlike supervised fine-tuning (SFT) with fixed trajectories. As a result, prior work often relies on manual curation or simple heuristic filters (e.g., accuracy), which can admit incorrect or low-utility problems. We propose GradAlign, a gradient-aligned data selection method for LLM reinforcement learning that uses a small, trusted validation set to prioritize training problems whose policy gradients align with validation gradients, yielding an adaptive curriculum. We evaluate GradAlign across three challenging data regimes: unreliable reward signals, distribution imbalance, and low-utility training corpus, showing that GradAlign consistently outperforms existing baselines, underscoring the importance of directional gradient signals in navigating non-stationary policy optimization and yielding more stable training and improved final performance. We release our implementation at https://github.com/StigLidu/GradAlign",
        "url": "http://arxiv.org/abs/2602.21492v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21492v1",
        "arxiv_id": "2602.21492v1",
        "authors": [
            "Ningyuan Yang",
            "Weihua Du",
            "Weiwei Sun",
            "Sean Welleck",
            "Yiming Yang"
        ],
        "submitted": "2026-02-25 01:54:50",
        "source": "arxiv",
        "comment": "14 pages. Preliminary work"
    },
    {
        "title": "Evaluating the Usage of African-American Vernacular English in Large Language Models",
        "abstract": "In AI, most evaluations of natural language understanding tasks are conducted in standardized dialects such as Standard American English (SAE). In this work, we investigate how accurately large language models (LLMs) represent African American Vernacular English (AAVE). We analyze three LLMs to compare their usage of AAVE to the usage of humans who natively speak AAVE. We first analyzed interviews from the Corpus of Regional African American Language and TwitterAAE to identify the typical contexts where people use AAVE grammatical features such as ain't. We then prompted the LLMs to produce text in AAVE and compared the model-generated text to human usage patterns. We find that, in many cases, there are substantial differences between AAVE usage in LLMs and humans: LLMs usually underuse and misuse grammatical features characteristic of AAVE. Furthermore, through sentiment analysis and manual inspection, we found that the models replicated stereotypes about African Americans. These results highlight the need for more diversity in training data and the incorporation of fairness methods to mitigate the perpetuation of stereotypes.",
        "url": "http://arxiv.org/abs/2602.21485v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21485v1",
        "arxiv_id": "2602.21485v1",
        "authors": [
            "Deja Dunlap",
            "R. Thomas McCoy"
        ],
        "submitted": "2026-02-25 01:28:01",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Both Ends Count! Just How Good are LLM Agents at \"Text-to-Big SQL\"?",
        "abstract": "Text-to-SQL and Big Data are both extensively benchmarked fields, yet there is limited research that evaluates them jointly. In the real world, Text-to-SQL systems are often embedded with Big Data workflows, such as large-scale data processing or interactive data analytics. We refer to this as \"Text-to-Big SQL\". However, existing text-to-SQL benchmarks remain narrowly scoped and overlook the cost and performance implications that arise at scale. For instance, translation errors that are minor on small datasets lead to substantial cost and latency overheads as data scales, a relevant issue completely ignored by text-to-SQL metrics.\n  In this paper, we overcome this overlooked challenge by introducing novel and representative metrics for evaluating Text-to-Big SQL. Our study focuses on production-level LLM agents, a database-agnostic system adaptable to diverse user needs. Via an extensive evaluation of frontier models, we show that text-to-SQL metrics are insufficient for Big Data. In contrast, our proposed text-to-Big SQL metrics accurately reflect execution efficiency, cost, and the impact of data scale. Furthermore, we provide LLM-specific insights, including fine-grained, cross-model comparisons of latency and cost.",
        "url": "http://arxiv.org/abs/2602.21480v2",
        "pdf_url": "https://arxiv.org/pdf/2602.21480v2",
        "arxiv_id": "2602.21480v2",
        "authors": [
            "Germán T. Eizaguirre",
            "Lars Tissen",
            "Marc Sánchez-Artigas"
        ],
        "submitted": "2026-02-25 01:12:35",
        "source": "arxiv",
        "comment": "11 pages, 4 figures"
    },
    {
        "title": "iMiGUE-Speech: A Spontaneous Speech Dataset for Affective Analysis",
        "abstract": "This work presents iMiGUE-Speech, an extension of the iMiGUE dataset that provides a spontaneous affective corpus for studying emotional and affective states. The new release focuses on speech and enriches the original dataset with additional metadata, including speech transcripts, speaker-role separation between interviewer and interviewee, and word-level forced alignments. Unlike existing emotional speech datasets that rely on acted or laboratory-elicited emotions, iMiGUE-Speech captures spontaneous affect arising naturally from real match outcomes. To demonstrate the utility of the dataset and establish initial benchmarks, we introduce two evaluation tasks for comparative assessment: speech emotion recognition and transcript-based sentiment analysis. These tasks leverage state-of-the-art pre-trained representations to assess the dataset's ability to capture spontaneous affective states from both acoustic and linguistic modalities. iMiGUE-Speech can also be synchronously paired with micro-gesture annotations from the original iMiGUE dataset, forming a uniquely multimodal resource for studying speech-gesture affective dynamics. The extended dataset is available at https://github.com/CV-AC/imigue-speech.",
        "url": "http://arxiv.org/abs/2602.21464v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21464v1",
        "arxiv_id": "2602.21464v1",
        "authors": [
            "Sofoklis Kakouros",
            "Fang Kang",
            "Haoyu Chen"
        ],
        "submitted": "2026-02-25 00:38:19",
        "source": "arxiv",
        "comment": "Accepted to Speech Prosody 2026"
    },
    {
        "title": "VecGlypher: Unified Vector Glyph Generation with Language Models",
        "abstract": "Vector glyphs are the atomic units of digital typography, yet most learning-based pipelines still depend on carefully curated exemplar sheets and raster-to-vector postprocessing, which limits accessibility and editability. We introduce VecGlypher, a single multimodal language model that generates high-fidelity vector glyphs directly from text descriptions or image exemplars. Given a style prompt, optional reference glyph images, and a target character, VecGlypher autoregressively emits SVG path tokens, avoiding raster intermediates and producing editable, watertight outlines in one pass. A typography-aware data and training recipe makes this possible: (i) a large-scale continuation stage on 39K noisy Envato fonts to master SVG syntax and long-horizon geometry, followed by (ii) post-training on 2.5K expert-annotated Google Fonts with descriptive tags and exemplars to align language and imagery with geometry; preprocessing normalizes coordinate frames, canonicalizes paths, de-duplicates families, and quantizes coordinates for stable long-sequence decoding. On cross-family OOD evaluation, VecGlypher substantially outperforms both general-purpose LLMs and specialized vector-font baselines for text-only generation, while image-referenced generation reaches a state-of-the-art performance, with marked gains over DeepVecFont-v2 and DualVector. Ablations show that model scale and the two-stage recipe are critical and that absolute-coordinate serialization yields the best geometry. VecGlypher lowers the barrier to font creation by letting users design with words or exemplars, and provides a scalable foundation for future multimodal design tools.",
        "url": "http://arxiv.org/abs/2602.21461v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21461v1",
        "arxiv_id": "2602.21461v1",
        "authors": [
            "Xiaoke Huang",
            "Bhavul Gauri",
            "Kam Woh Ng",
            "Tony Ng",
            "Mengmeng Xu",
            "Zhiheng Liu",
            "Weiming Ren",
            "Zhaochong An",
            "Zijian Zhou",
            "Haonan Qiu",
            "Yuyin Zhou",
            "Sen He",
            "Ziheng Wang",
            "Tao Xiang",
            "Xiao Han"
        ],
        "submitted": "2026-02-25 00:27:23",
        "source": "arxiv",
        "comment": "Accepted to CVPR'26. Project page: https://xk-huang.github.io/VecGlypher/"
    },
    {
        "title": "Revisiting Text Ranking in Deep Research",
        "abstract": "Deep research has emerged as an important task that aims to address hard queries through extensive open-web exploration. To tackle it, most prior work equips large language model (LLM)-based agents with opaque web search APIs, enabling agents to iteratively issue search queries, retrieve external evidence, and reason over it. Despite search's essential role in deep research, black-box web search APIs hinder systematic analysis of search components, leaving the behaviour of established text ranking methods in deep research largely unclear. To fill this gap, we reproduce a selection of key findings and best practices for IR text ranking methods in the deep research setting. In particular, we examine their effectiveness from three perspectives: (i) retrieval units (documents vs. passages), (ii) pipeline configurations (different retrievers, re-rankers, and re-ranking depths), and (iii) query characteristics (the mismatch between agent-issued queries and the training queries of text rankers). We perform experiments on BrowseComp-Plus, a deep research dataset with a fixed corpus, evaluating 2 open-source agents, 5 retrievers, and 3 re-rankers across diverse setups. We find that agent-issued queries typically follow web-search-style syntax (e.g., quoted exact matches), favouring lexical, learned sparse, and multi-vector retrievers; passage-level units are more efficient under limited context windows, and avoid the difficulties of document length normalisation in lexical retrieval; re-ranking is highly effective; translating agent-issued queries into natural-language questions significantly bridges the query mismatch.",
        "url": "http://arxiv.org/abs/2602.21456v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21456v1",
        "arxiv_id": "2602.21456v1",
        "authors": [
            "Chuan Meng",
            "Litu Ou",
            "Sean MacAvaney",
            "Jeff Dalton"
        ],
        "submitted": "2026-02-25 00:18:07",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Adversarial Intent is a Latent Variable: Stateful Trust Inference for Securing Multimodal Agentic RAG",
        "abstract": "Current stateless defences for multimodal agentic RAG fail to detect adversarial strategies that distribute malicious semantics across retrieval, planning, and generation components. We formulate this security challenge as a Partially Observable Markov Decision Process (POMDP), where adversarial intent is a latent variable inferred from noisy multi-stage observations. We introduce MMA-RAG^T, an inference-time control framework governed by a Modular Trust Agent (MTA) that maintains an approximate belief state via structured LLM reasoning. Operating as a model-agnostic overlay, MMA-RAGT mediates a configurable set of internal checkpoints to enforce stateful defence-in-depth. Extensive evaluation on 43,774 instances demonstrates a 6.50x average reduction factor in Attack Success Rate relative to undefended baselines, with negligible utility cost. Crucially, a factorial ablation validates our theoretical bounds: while statefulness and spatial coverage are individually necessary (26.4 pp and 13.6 pp gains respectively), stateless multi-point intervention can yield zero marginal benefit under homogeneous stateless filtering when checkpoint detections are perfectly correlated.",
        "url": "http://arxiv.org/abs/2602.21447v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21447v1",
        "arxiv_id": "2602.21447v1",
        "authors": [
            "Inderjeet Singh",
            "Vikas Pahuja",
            "Aishvariya Priya Rathina Sabapathy",
            "Chiara Picardi",
            "Amit Giloni",
            "Roman Vainshtein",
            "Andrés Murillo",
            "Hisashi Kojima",
            "Motoyoshi Sekiya",
            "Yuki Unno",
            "Junichi Suga"
        ],
        "submitted": "2026-02-24 23:52:27",
        "source": "arxiv",
        "comment": "13 pages, 2 figures, 5 tables"
    },
    {
        "title": "MrBERT: Modern Multilingual Encoders via Vocabulary, Domain, and Dimensional Adaptation",
        "abstract": "We introduce MrBERT, a family of 150M-300M parameter encoders built on the ModernBERT architecture and pre-trained on 35 languages and code. Through targeted adaptation, this model family achieves state-of-the-art results on Catalan- and Spanish-specific tasks, while establishing robust performance across specialized biomedical and legal domains. To bridge the gap between research and production, we incorporate Matryoshka Representation Learning (MRL), enabling flexible vector sizing that significantly reduces inference and storage costs. Ultimately, the MrBERT family demonstrates that modern encoder architectures can be optimized for both localized linguistic excellence and efficient, high-stakes domain specialization. We open source the complete model family on Huggingface.",
        "url": "http://arxiv.org/abs/2602.21379v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21379v1",
        "arxiv_id": "2602.21379v1",
        "authors": [
            "Daniel Tamayo",
            "Iñaki Lacunza",
            "Paula Rivera-Hidalgo",
            "Severino Da Dalt",
            "Javier Aula-Blasco",
            "Aitor Gonzalez-Agirre",
            "Marta Villegas"
        ],
        "submitted": "2026-02-24 21:19:40",
        "source": "arxiv",
        "comment": "24 pages, 14 tables and 4 figures"
    },
    {
        "title": "Beyond Subtokens: A Rich Character Embedding for Low-resource and Morphologically Complex Languages",
        "abstract": "Tokenization and sub-tokenization based models like word2vec, BERT and the GPTs are the state-of-the-art in natural language processing. Typically, these approaches have limitations with respect to their input representation. They fail to fully capture orthographic similarities and morphological variations, especially in highly inflected and under-resource languages. To mitigate this problem, we propose to computes word vectors directly from character strings, integrating both semantic and syntactic information. We denote this transformer-based approach Rich Character Embeddings (RCE). Furthermore, we propose a hybrid model that combines transformer and convolutional mechanisms. Both vector representations can be used as a drop-in replacement for dictionary- and subtoken-based word embeddings in existing model architectures. It has the potential to improve performance for both large context-based language models like BERT and small models like word2vec for under-resourced and morphologically rich languages. We evaluate our approach on various tasks like the SWAG, declension prediction for inflected languages, metaphor and chiasmus detection for various languages. Our experiments show that it outperforms traditional token-based approaches on limited data using OddOneOut and TopK metrics.",
        "url": "http://arxiv.org/abs/2602.21377v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21377v1",
        "arxiv_id": "2602.21377v1",
        "authors": [
            "Felix Schneider",
            "Maria Gogolev",
            "Sven Sickert",
            "Joachim Denzler"
        ],
        "submitted": "2026-02-24 21:16:08",
        "source": "arxiv",
        "comment": "12 content pages, 2 figures, 8 tables, one example textbox"
    },
    {
        "title": "Small Language Models for Privacy-Preserving Clinical Information Extraction in Low-Resource Languages",
        "abstract": "Extracting clinical information from medical transcripts in low-resource languages remains a significant challenge in healthcare natural language processing (NLP). This study evaluates a two-step pipeline combining Aya-expanse-8B as a Persian-to-English translation model with five open-source small language models (SLMs) -- Qwen2.5-7B-Instruct, Llama-3.1-8B-Instruct, Llama-3.2-3B-Instruct, Qwen2.5-1.5B-Instruct, and Gemma-3-1B-it -- for binary extraction of 13 clinical features from 1,221 anonymized Persian transcripts collected at a cancer palliative care call center. Using a few-shot prompting strategy without fine-tuning, models were assessed on macro-averaged F1-score, Matthews Correlation Coefficient (MCC), sensitivity, and specificity to account for class imbalance. Qwen2.5-7B-Instruct achieved the highest overall performance (median macro-F1: 0.899; MCC: 0.797), while Gemma-3-1B-it showed the weakest results. Larger models (7B--8B parameters) consistently outperformed smaller counterparts in sensitivity and MCC. A bilingual analysis of Aya-expanse-8B revealed that translating Persian transcripts to English improved sensitivity, reduced missing outputs, and boosted metrics robust to class imbalance, though at the cost of slightly lower specificity and precision. Feature-level results showed reliable extraction of physiological symptoms across most models, whereas psychological complaints, administrative requests, and complex somatic features remained challenging. These findings establish a practical, privacy-preserving blueprint for deploying open-source SLMs in multilingual clinical NLP settings with limited infrastructure and annotation resources, and highlight the importance of jointly optimizing model scale and input language strategy for sensitive healthcare applications.",
        "url": "http://arxiv.org/abs/2602.21374v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21374v1",
        "arxiv_id": "2602.21374v1",
        "authors": [
            "Mohammadreza Ghaffarzadeh-Esfahani",
            "Nahid Yousefian",
            "Ebrahim Heidari-Farsani",
            "Ali Akbar Omidvarian",
            "Sepehr Ghahraei",
            "Atena Farangi",
            "AmirBahador Boroumand"
        ],
        "submitted": "2026-02-24 21:10:29",
        "source": "arxiv",
        "comment": "16 pages, 3 figures, 2 supplementary files"
    },
    {
        "title": "Black-Box Reliability Certification for AI Agents via Self-Consistency Sampling and Conformal Calibration",
        "abstract": "Given a black-box AI system and a task, at what confidence level can a practitioner trust the system's output? We answer with a reliability level -- a single number per system-task pair, derived from self-consistency sampling and conformal calibration, that serves as a black-box deployment gate with exact, finite-sample, distribution-free guarantees. Self-consistency sampling reduces uncertainty exponentially; conformal calibration guarantees correctness within 1/(n+1) of the target level, regardless of the system's errors -- made transparently visible through larger answer sets for harder questions. Weaker models earn lower reliability levels (not accuracy -- see Definition 2.4): GPT-4.1 earns 94.6% on GSM8K and 96.8% on TruthfulQA, while GPT-4.1-nano earns 89.8% on GSM8K and 66.5% on MMLU. We validate across five benchmarks, five models from three families, and both synthetic and real data. Conditional coverage on solvable items exceeds 0.93 across all configurations; sequential stopping reduces API costs by around 50%.",
        "url": "http://arxiv.org/abs/2602.21368v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21368v1",
        "arxiv_id": "2602.21368v1",
        "authors": [
            "Charafeddine Mouzouni"
        ],
        "submitted": "2026-02-24 21:03:50",
        "source": "arxiv",
        "comment": "41 pages, 11 figures, 10 tables, including appendices"
    },
    {
        "title": "A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives",
        "abstract": "The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture implements a centralized Supervisor-Worker topology with strict data-type-aware routing, sandboxed deterministic code execution, and self-correction via execution feedback, enabling agents to diagnose and resolve runtime errors. Through use-case scenarios spanning physical oceanography and ecology, we demonstrate the system's capacity to execute complex, multi-step workflows with minimal human intervention. This framework provides a methodology for querying and analyzing heterogeneous repository data through coordinated agent workflows.",
        "url": "http://arxiv.org/abs/2602.21351v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21351v1",
        "arxiv_id": "2602.21351v1",
        "authors": [
            "Dmitrii Pantiukhin",
            "Ivan Kuznetsov",
            "Boris Shapkin",
            "Antonia Anna Jost",
            "Thomas Jung",
            "Nikolay Koldunov"
        ],
        "submitted": "2026-02-24 20:37:38",
        "source": "arxiv",
        "comment": "20 pages, 6 figures, 7 tables, supplementary material included"
    },
    {
        "title": "Alignment-Weighted DPO: A principled reasoning approach to improve safety alignment",
        "abstract": "Recent advances in alignment techniques such as Supervised Fine-Tuning (SFT), Reinforcement Learning from Human Feedback (RLHF), and Direct Preference Optimization (DPO) have improved the safety of large language models (LLMs). However, these LLMs remain vulnerable to jailbreak attacks that disguise harmful intent through indirect or deceptive phrasing. Using causal intervention, we empirically demonstrate that this vulnerability stems from shallow alignment mechanisms that lack deep reasoning, often rejecting harmful prompts without truly understanding why they are harmful. To mitigate this vulnerability, we propose enhancing alignment through reasoning-aware post-training. We construct and release a novel Chain-of-Thought (CoT) fine-tuning dataset that includes both utility-oriented and safety-critical prompts with step-by-step rationales. Fine-tuning on this dataset encourages models to produce principled refusals grounded in reasoning, outperforming standard SFT baselines. Furthermore, inspired by failure patterns in CoT fine-tuning, we introduce Alignment-Weighted DPO, which targets the most problematic parts of an output by assigning different preference weights to the reasoning and final-answer segments. This produces finer-grained, targeted updates than vanilla DPO and improves robustness to diverse jailbreak strategies. Extensive experiments across multiple safety and utility benchmarks show that our method consistently improves alignment robustness while maintaining overall model utility.",
        "url": "http://arxiv.org/abs/2602.21346v1",
        "pdf_url": "https://arxiv.org/pdf/2602.21346v1",
        "arxiv_id": "2602.21346v1",
        "authors": [
            "Mengxuan Hu",
            "Vivek V. Datla",
            "Anoop Kumar",
            "Zihan Guan",
            "Sheng Li",
            "Alfy Samuel",
            "Daben Liu"
        ],
        "submitted": "2026-02-24 20:30:51",
        "source": "arxiv",
        "comment": null
    }
]