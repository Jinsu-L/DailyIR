[
    {
        "title": "Semantic Chunking and the Entropy of Natural Language",
        "abstract": "The entropy rate of printed English is famously estimated to be about one bit per character, a benchmark that modern large language models (LLMs) have only recently approached. This entropy rate implies that English contains nearly 80 percent redundancy relative to the five bits per character expected for random text. We introduce a statistical model that attempts to capture the intricate multi-scale structure of natural language, providing a first-principles account of this redundancy level. Our model describes a procedure of self-similarly segmenting text into semantically coherent chunks down to the single-word level. The semantic structure of the text can then be hierarchically decomposed, allowing for analytical treatment. Numerical experiments with modern LLMs and open datasets suggest that our model quantitatively captures the structure of real texts at different levels of the semantic hierarchy. The entropy rate predicted by our model agrees with the estimated entropy rate of printed English. Moreover, our theory further reveals that the entropy rate of natural language is not fixed but should increase systematically with the semantic complexity of corpora, which are captured by the only free parameter in our model.",
        "url": "http://arxiv.org/abs/2602.13194v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13194v1",
        "arxiv_id": "2602.13194v1",
        "authors": [
            "Weishun Zhong",
            "Doron Sivan",
            "Tankut Can",
            "Mikhail Katkov",
            "Misha Tsodyks"
        ],
        "submitted": "2026-02-13 18:58:10",
        "source": "arxiv",
        "comment": "29 pages, 9 figures"
    },
    {
        "title": "CoPE-VideoLM: Codec Primitives For Efficient Video Language Models",
        "abstract": "Video Language Models (VideoLMs) empower AI systems to understand temporal dynamics in videos. To fit to the maximum context window constraint, current methods use keyframe sampling which can miss both macro-level events and micro-level details due to the sparse temporal coverage. Furthermore, processing full images and their tokens for each frame incurs substantial computational overhead. To address these limitations, we propose to leverage video codec primitives (specifically motion vectors and residuals) which natively encode video redundancy and sparsity without requiring expensive full-image encoding for most frames. To this end, we introduce lightweight transformer-based encoders that aggregate codec primitives and align their representations with image encoder embeddings through a pre-training strategy that accelerates convergence during end-to-end fine-tuning. Our approach reduces the time-to-first-token by up to $86\\%$ and token usage by up to $93\\%$ compared to standard VideoLMs. Moreover, by varying the keyframe and codec primitive densities we are able to maintain or exceed performance on $14$ diverse video understanding benchmarks spanning general question answering, temporal reasoning, long-form understanding, and spatial scene understanding.",
        "url": "http://arxiv.org/abs/2602.13191v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13191v1",
        "arxiv_id": "2602.13191v1",
        "authors": [
            "Sayan Deb Sarkar",
            "Rémi Pautrat",
            "Ondrej Miksik",
            "Marc Pollefeys",
            "Iro Armeni",
            "Mahdi Rad",
            "Mihai Dusmanu"
        ],
        "submitted": "2026-02-13 18:57:31",
        "source": "arxiv",
        "comment": "Project Page: https://sayands.github.io/cope/"
    },
    {
        "title": "Fix Before Search: Benchmarking Agentic Query Visual Pre-processing in Multimodal Retrieval-augmented Generation",
        "abstract": "Multimodal Retrieval-Augmented Generation (MRAG) has emerged as a key paradigm for grounding MLLMs with external knowledge. While query pre-processing (e.g., rewriting) is standard in text-based RAG, existing MRAG pipelines predominantly treat visual inputs as static and immutable, implicitly assuming they are noise-free. However, real-world visual queries are often ``imperfect'' -- suffering from geometric distortions, quality degradation, or semantic ambiguity -- leading to catastrophic retrieval failures. To address this gap, we propose V-QPP-Bench, the first comprehensive benchmark dedicated to Visual Query Pre-processing (V-QPP). We formulate V-QPP as an agentic decision-making task where MLLMs must autonomously diagnose imperfections and deploy perceptual tools to refine queries. Our extensive evaluation across 46,700 imperfect queries and diverse MRAG paradigms reveals three critical insights: (1) Vulnerability -- visual imperfections severely degrade both retrieval recall and end-to-end MRAG performance; (2) Restoration Potential \\& Bottleneck -- while oracle preprocessing recovers near-perfect performance, off-the-shelf MLLMs struggle with tool selection and parameter prediction without specialized training; and (3) Training Enhancement -- supervised fine-tuning enables compact models to achieve comparable or superior performance to larger proprietary models, demonstrating the benchmark's value for developing robust MRAG systems The code is available at https://github.com/phycholosogy/VQQP_Bench",
        "url": "http://arxiv.org/abs/2602.13179v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13179v1",
        "arxiv_id": "2602.13179v1",
        "authors": [
            "Jiankun Zhang",
            "Shenglai Zeng",
            "Kai Guo",
            "Xinnan Dai",
            "Hui Liu",
            "Jiliang Tang",
            "Yi Chang"
        ],
        "submitted": "2026-02-13 18:39:48",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Asynchronous Verified Semantic Caching for Tiered LLM Architectures",
        "abstract": "Large language models (LLMs) now sit in the critical path of search, assistance, and agentic workflows, making semantic caching essential for reducing inference cost and latency. Production deployments typically use a tiered static-dynamic design: a static cache of curated, offline vetted responses mined from logs, backed by a dynamic cache populated online. In practice, both tiers are commonly governed by a single embedding similarity threshold, which induces a hard tradeoff: conservative thresholds miss safe reuse opportunities, while aggressive thresholds risk serving semantically incorrect responses. We introduce \\textbf{Krites}, an asynchronous, LLM-judged caching policy that expands static coverage without changing serving decisions. On the critical path, Krites behaves exactly like a standard static threshold policy. When the nearest static neighbor of the prompt falls just below the static threshold, Krites asynchronously invokes an LLM judge to verify whether the static response is acceptable for the new prompt. Approved matches are promoted into the dynamic cache, allowing future repeats and paraphrases to reuse curated static answers and expanding static reach over time. In trace-driven simulations on conversational and search workloads, Krites increases the fraction of requests served with curated static answers (direct static hits plus verified promotions) by up to $\\textbf{3.9}$ times for conversational traffic and search-style queries relative to tuned baselines, with unchanged critical path latency.",
        "url": "http://arxiv.org/abs/2602.13165v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13165v1",
        "arxiv_id": "2602.13165v1",
        "authors": [
            "Asmit Kumar Singh",
            "Haozhe Wang",
            "Laxmi Naga Santosh Attaluri",
            "Tak Chiam",
            "Weihua Zhu"
        ],
        "submitted": "2026-02-13 18:25:00",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Quantization-Robust LLM Unlearning via Low-Rank Adaptation",
        "abstract": "Large Language Model (LLM) unlearning aims to remove targeted knowledge from a trained model, but practical deployments often require post-training quantization (PTQ) for efficient inference. However, aggressive low-bit PTQ can mask or erase unlearning updates, causing quantized models to revert to pre-unlearning behavior. We show that standard full-parameter fine-tuning often induce parameter changes that are too small to survive 4-bit quantization. We propose quantization-robust unlearning via low-rank adaptation (LoRA): we freeze the base model and concentrate unlearning into trainable adapters so that the effective update is preserved after quantization. On Llama-2-7B evaluated with MUSE dataset (BOOKS and NEWS), LoRA improves 4-bit utility by up to 7.93 points (NPO+GDR on BOOKS: 50.17 to 58.10) and yields higher 4-bit utility on NEWS for GA+GDR (40.06 to 44.82, increase of 4.76). LoRA also substantially reduces privacy leakage under 4-bit PTQ, e.g., for GA+KLR on BOOKS, PrivLeak moves from -25.68 to -5.86 (closer to ideal 0), while maintaining strong forgetting (VerMem and KnowMem near 0). Thus, using LoRA for Machine Unlearning is beneficial for scenarios where quantization is necessary for model deployment.",
        "url": "http://arxiv.org/abs/2602.13151v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13151v1",
        "arxiv_id": "2602.13151v1",
        "authors": [
            "João Vitor Boer Abitante",
            "Joana Meneguzzo Pasquali",
            "Luan Fonseca Garcia",
            "Ewerton de Oliveira",
            "Thomas da Silva Paula",
            "Rodrigo C. Barros",
            "Lucas S. Kupssinskü"
        ],
        "submitted": "2026-02-13 18:01:40",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "OpenLID-v3: Improving the Precision of Closely Related Language Identification -- An Experience Report",
        "abstract": "Language identification (LID) is an essential step in building high-quality multilingual datasets from web data. Existing LID tools (such as OpenLID or GlotLID) often struggle to identify closely related languages and to distinguish valid natural language from noise, which contaminates language-specific subsets, especially for low-resource languages. In this work we extend the OpenLID classifier by adding more training data, merging problematic language variant clusters, and introducing a special label for marking noise. We call this extended system OpenLID-v3 and evaluate it against GlotLID on multiple benchmarks. During development, we focus on three groups of closely related languages (Bosnian, Croatian, and Serbian; Romance varieties of Northern Italy and Southern France; and Scandinavian languages) and contribute new evaluation datasets where existing ones are inadequate. We find that ensemble approaches improve precision but also substantially reduce coverage for low-resource languages. OpenLID-v3 is available on https://huggingface.co/HPLT/OpenLID-v3.",
        "url": "http://arxiv.org/abs/2602.13139v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13139v1",
        "arxiv_id": "2602.13139v1",
        "authors": [
            "Mariia Fedorova",
            "Nikolay Arefyev",
            "Maja Buljan",
            "Jindřich Helcl",
            "Stephan Oepen",
            "Egil Rønningstad",
            "Yves Scherrer"
        ],
        "submitted": "2026-02-13 17:47:08",
        "source": "arxiv",
        "comment": "VarDial'26 workshop at the EACL 2026 conference"
    },
    {
        "title": "Awakening Dormant Users: Generative Recommendation with Counterfactual Functional Role Reasoning",
        "abstract": "Awakening dormant users, who remain engaged but exhibit low conversion, is a pivotal driver for incremental GMV growth in large-scale e-commerce platforms. However, existing approaches often yield suboptimal results since they typically rely on single-step estimation of an item's intrinsic value (e.g., immediate click probability). This mechanism overlooks the instrumental effect of items, where specific interactions act as triggers to shape latent intent and drive subsequent decisions along a conversion trajectory. To bridge this gap, we propose RoleGen, a novel framework that synergizes a Conversion Trajectory Reasoner with a Generative Behavioral Backbone. Specifically, the LLM-based Reasoner explicitly models the context-dependent Functional Role of items to reconstruct intent evolution. It further employs counterfactual inference to simulate diverse conversion paths, effectively mitigating interest collapse. These reasoned candidate items are integrated into the generative backbone, which is optimized via a collaborative \"Reasoning-Execution-Feedback-Reflection\" closed-loop strategy to ensure grounded execution. Extensive offline experiments and online A/B testing on the Kuaishou e-commerce platform demonstrate that RoleGen achieves a 6.2% gain in Recall@1 and a 7.3% increase in online order volume, confirming its effectiveness in activating the dormant user base.",
        "url": "http://arxiv.org/abs/2602.13134v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13134v1",
        "arxiv_id": "2602.13134v1",
        "authors": [
            "Huishi Luo",
            "Shuokai Li",
            "Hanchen Yang",
            "Zhongbo Sun",
            "Haojie Ding",
            "Boheng Zhang",
            "Zijia Cai",
            "Renliang Qian",
            "Fan Yang",
            "Tingting Gao",
            "Chenyi Lei",
            "Wenwu Ou",
            "Fuzhen Zhuang"
        ],
        "submitted": "2026-02-13 17:33:48",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "From sunblock to softblock: Analyzing the correlates of neology in published writing and on social media",
        "abstract": "Living languages are shaped by a host of conflicting internal and external evolutionary pressures. While some of these pressures are universal across languages and cultures, others differ depending on the social and conversational context: language use in newspapers is subject to very different constraints than language use on social media. Prior distributional semantic work on English word emergence (neology) identified two factors correlated with creation of new words by analyzing a corpus consisting primarily of historical published texts (Ryskina et al., 2020, arXiv:2001.07740). Extending this methodology to contextual embeddings in addition to static ones and applying it to a new corpus of Twitter posts, we show that the same findings hold for both domains, though the topic popularity growth factor may contribute less to neology on Twitter than in published writing. We hypothesize that this difference can be explained by the two domains favouring different neologism formation mechanisms.",
        "url": "http://arxiv.org/abs/2602.13123v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13123v1",
        "arxiv_id": "2602.13123v1",
        "authors": [
            "Maria Ryskina",
            "Matthew R. Gormley",
            "Kyle Mahowald",
            "David R. Mortensen",
            "Taylor Berg-Kirkpatrick",
            "Vivek Kulkarni"
        ],
        "submitted": "2026-02-13 17:19:28",
        "source": "arxiv",
        "comment": "Accepted to LChange 2026"
    },
    {
        "title": "SCOPE: Selective Conformal Optimized Pairwise LLM Judging",
        "abstract": "Large language models (LLMs) are increasingly used as judges to replace costly human preference labels in pairwise evaluation. Despite their practicality, LLM judges remain prone to miscalibration and systematic biases. This paper proposes SCOPE (Selective Conformal Optimized Pairwise Evaluation), a framework for selective pairwise judging with finite-sample statistical guarantees. Under exchangeability, SCOPE calibrates an acceptance threshold such that the error rate among non-abstained judgments is at most a user-specified level $α$. To provide SCOPE with a bias-neutral uncertainty signal, we introduce Bidirectional Preference Entropy (BPE), which queries the judge under both response positions, aggregates the implied preference probabilities to enforce invariance to response order, and converts the aggregated probability into an entropy-based uncertainty score. Across MT-Bench, RewardBench, and Chatbot Arena, BPE improves uncertainty quality over standard confidence proxies, providing a stronger selection signal that enables SCOPE to consistently meet the target risk level while retaining good coverage across judge scales. In particular, at $α= 0.10$, \\textsc{Scope} consistently satisfies the risk bound across all benchmarks and judge scales (empirical risk $\\approx 0.097$ to $0.099$), while retaining substantial coverage, reaching $0.89$ on RewardBench with Qwen-14B and $0.98$ on RewardBench with Qwen-32B. Compared to naïve baselines, \\textsc{Scope} accepts up to $2.4\\times$ more judgments on MT-Bench with Qwen-7B under the same target risk constraint, demonstrating that BPE enables reliable and high-coverage LLM-based evaluation.",
        "url": "http://arxiv.org/abs/2602.13110v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13110v1",
        "arxiv_id": "2602.13110v1",
        "authors": [
            "Sher Badshah",
            "Ali Emami",
            "Hassan Sajjad"
        ],
        "submitted": "2026-02-13 17:10:43",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Towards interpretable models for language proficiency assessment: Predicting the CEFR level of Estonian learner texts",
        "abstract": "Using NLP to analyze authentic learner language helps to build automated assessment and feedback tools. It also offers new and extensive insights into the development of second language production. However, there is a lack of research explicitly combining these aspects. This study aimed to classify Estonian proficiency examination writings (levels A2-C1), assuming that careful feature selection can lead to more explainable and generalizable machine learning models for language testing. Various linguistic properties of the training data were analyzed to identify relevant proficiency predictors associated with increasing complexity and correctness, rather than the writing task. Such lexical, morphological, surface, and error features were used to train classification models, which were compared to models that also allowed for other features. The pre-selected features yielded a similar test accuracy but reduced variation in the classification of different text types. The best classifiers achieved an accuracy of around 0.9. Additional evaluation on an earlier exam sample revealed that the writings have become more complex over a 7-10-year period, while accuracy still reached 0.8 with some feature sets. The results have been implemented in the writing evaluation module of an Estonian open-source language learning environment.",
        "url": "http://arxiv.org/abs/2602.13102v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13102v1",
        "arxiv_id": "2602.13102v1",
        "authors": [
            "Kais Allkivi"
        ],
        "submitted": "2026-02-13 17:06:17",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Consistency of Large Reasoning Models Under Multi-Turn Attacks",
        "abstract": "Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial attacks. Our findings reveal that reasoning confers meaningful but incomplete robustness: most reasoning models studied significantly outperform instruction-tuned baselines, yet all exhibit distinct vulnerability profiles, with misleading suggestions universally effective and social pressure showing model-specific efficacy. Through trajectory analysis, we identify five failure modes (Self-Doubt, Social Conformity, Suggestion Hijacking, Emotional Susceptibility, and Reasoning Fatigue) with the first two accounting for 50% of failures. We further demonstrate that Confidence-Aware Response Generation (CARG), effective for standard LLMs, fails for reasoning models due to overconfidence induced by extended reasoning traces; counterintuitively, random confidence embedding outperforms targeted extraction. Our results highlight that reasoning capabilities do not automatically confer adversarial robustness and that confidence-based defenses require fundamental redesign for reasoning models.",
        "url": "http://arxiv.org/abs/2602.13093v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13093v1",
        "arxiv_id": "2602.13093v1",
        "authors": [
            "Yubo Li",
            "Ramayya Krishnan",
            "Rema Padman"
        ],
        "submitted": "2026-02-13 16:58:47",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Exploring a New Competency Modeling Process with Large Language Models",
        "abstract": "Competency modeling is widely used in human resource management to select, develop, and evaluate talent. However, traditional expert-driven approaches rely heavily on manual analysis of large volumes of interview transcripts, making them costly and prone to randomness, ambiguity, and limited reproducibility. This study proposes a new competency modeling process built on large language models (LLMs). Instead of merely automating isolated steps, we reconstruct the workflow by decomposing expert practices into structured computational components. Specifically, we leverage LLMs to extract behavioral and psychological descriptions from raw textual data and map them to predefined competency libraries through embedding-based similarity. We further introduce a learnable parameter that adaptively integrates different information sources, enabling the model to determine the relative importance of behavioral and psychological signals. To address the long-standing challenge of validation, we develop an offline evaluation procedure that allows systematic model selection without requiring additional large-scale data collection. Empirical results from a real-world implementation in a software outsourcing company demonstrate strong predictive validity, cross-library consistency, and structural robustness. Overall, our framework transforms competency modeling from a largely qualitative and expert-dependent practice into a transparent, data-driven, and evaluable analytical process.",
        "url": "http://arxiv.org/abs/2602.13084v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13084v1",
        "arxiv_id": "2602.13084v1",
        "authors": [
            "Silin Du",
            "Manqing Xin",
            "Raymond Jia Wang"
        ],
        "submitted": "2026-02-13 16:46:51",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "LCSB: Layer-Cyclic Selective Backpropagation for Memory-Efficient On-Device LLM Fine-Tuning",
        "abstract": "Memory-efficient backpropagation (MeBP) has enabled first-order fine-tuning of large language models (LLMs) on mobile devices with less than 1GB memory. However, MeBP requires backward computation through all transformer layers at every step, where weight decompression alone accounts for 32--42% of backward time. We propose Layer-Cyclic Selective Backpropagation (LCSB), which computes gradients for only a subset of layers per step. Our key insight is that residual connections guarantee gradient flow through identity paths, while AdamW momentum provides implicit updates for non-selected layers. We interpret LCSB as Block Coordinate Descent on the LoRA parameter space, providing theoretical justification for convergence. LCSB achieves up to 1.40$\\times$ speedup with less than 2\\% quality degradation across five models and three tasks. Surprisingly, in 4-bit quantized settings, LCSB exhibits superior stability: a 3B model that completely diverges under full backpropagation converges smoothly with LCSB, suggesting an implicit regularization effect from selective gradient computation.",
        "url": "http://arxiv.org/abs/2602.13073v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13073v1",
        "arxiv_id": "2602.13073v1",
        "authors": [
            "Juneyoung Park",
            "Eunbeen Yoon",
            "Seongwan Kim. Jaeho Lee"
        ],
        "submitted": "2026-02-13 16:32:53",
        "source": "arxiv",
        "comment": "Under the review, 13 pages"
    },
    {
        "title": "Memory-Efficient Structured Backpropagation for On-Device LLM Fine-Tuning",
        "abstract": "On-device fine-tuning enables privacy-preserving personalization of large language models, but mobile devices impose severe memory constraints, typically 6--12GB shared across all workloads. Existing approaches force a trade-off between exact gradients with high memory (MeBP) and low memory with noisy estimates (MeZO). We propose Memory-efficient Structured Backpropagation (MeSP), which bridges this gap by manually deriving backward passes that exploit LoRA's low-rank structure. Our key insight is that the intermediate projection $h = xA$ can be recomputed during backward at minimal cost since rank $r \\ll d_{in}$, eliminating the need to store it. MeSP achieves 49\\% average memory reduction compared to MeBP on Qwen2.5 models (0.5B--3B) while computing mathematically identical gradients. Our analysis also reveals that MeZO's gradient estimates show near-zero correlation with true gradients (cosine similarity $\\approx$0.001), explaining its slow convergence. MeSP reduces peak memory from 361MB to 136MB for Qwen2.5-0.5B, enabling fine-tuning scenarios previously infeasible on memory-constrained devices.",
        "url": "http://arxiv.org/abs/2602.13069v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13069v1",
        "arxiv_id": "2602.13069v1",
        "authors": [
            "Juneyoung Park",
            "Yuri Hong",
            "Seongwan Kim",
            "Jaeho Lee"
        ],
        "submitted": "2026-02-13 16:24:33",
        "source": "arxiv",
        "comment": "Under the review, 11 pages"
    },
    {
        "title": "TraceBack: Multi-Agent Decomposition for Fine-Grained Table Attribution",
        "abstract": "Question answering (QA) over structured tables requires not only accurate answers but also transparency about which cells support them. Existing table QA systems rarely provide fine-grained attribution, so even correct answers often lack verifiable grounding, limiting trust in high-stakes settings. We address this with TraceBack, a modular multi-agent framework for scalable, cell-level attribution in single-table QA. TraceBack prunes tables to relevant rows and columns, decomposes questions into semantically coherent sub-questions, and aligns each answer span with its supporting cells, capturing both explicit and implicit evidence used in intermediate reasoning steps. To enable systematic evaluation, we release CITEBench, a benchmark with phrase-to-cell annotations drawn from ToTTo, FetaQA, and AITQA. We further propose FairScore, a reference-less metric that compares atomic facts derived from predicted cells and answers to estimate attribution precision and recall without human cell labels. Experiments show that TraceBack substantially outperforms strong baselines across datasets and granularities, while FairScore closely tracks human judgments and preserves relative method rankings, supporting interpretable and scalable evaluation of table-based QA.",
        "url": "http://arxiv.org/abs/2602.13059v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13059v1",
        "arxiv_id": "2602.13059v1",
        "authors": [
            "Tejas Anvekar",
            "Junha Park",
            "Rajat Jha",
            "Devanshu Gupta",
            "Poojah Ganesan",
            "Puneeth Mathur",
            "Vivek Gupta"
        ],
        "submitted": "2026-02-13 16:13:36",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Can we trust AI to detect healthy multilingual English speakers among the cognitively impaired cohort in the UK? An investigation using real-world conversational speech",
        "abstract": "Conversational speech often reveals early signs of cognitive decline, such as dementia and MCI. In the UK, one in four people belongs to an ethnic minority, and dementia prevalence is expected to rise most rapidly among Black and Asian communities. This study examines the trustworthiness of AI models, specifically the presence of bias, in detecting healthy multilingual English speakers among the cognitively impaired cohort, to make these tools clinically beneficial. For experiments, monolingual participants were recruited nationally (UK), and multilingual speakers were enrolled from four community centres in Sheffield and Bradford. In addition to a non-native English accent, multilinguals spoke Somali, Chinese, or South Asian languages, who were further divided into two Yorkshire accents (West and South) to challenge the efficiency of the AI tools thoroughly. Although ASR systems showed no significant bias across groups, classification and regression models using acoustic and linguistic features exhibited bias against multilingual speakers, particularly in memory, fluency, and reading tasks. This bias was more pronounced when models were trained on the publicly available DementiaBank dataset. Moreover, multilinguals were more likely to be misclassified as having cognitive decline. This study is the first of its kind to discover that, despite their strong overall performance, current AI models show bias against multilingual individuals from ethnic minority backgrounds in the UK, and they are also more likely to misclassify speakers with a certain accent (South Yorkshire) as living with a more severe cognitive decline. In this pilot study, we conclude that the existing AI tools are therefore not yet reliable for diagnostic use in these populations, and we aim to address this in future work by developing more generalisable, bias-mitigated models.",
        "url": "http://arxiv.org/abs/2602.13047v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13047v1",
        "arxiv_id": "2602.13047v1",
        "authors": [
            "Madhurananda Pahar",
            "Caitlin Illingworth",
            "Dorota Braun",
            "Bahman Mirheidari",
            "Lise Sproson",
            "Daniel Blackburn",
            "Heidi Christensen"
        ],
        "submitted": "2026-02-13 16:03:37",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Look Inward to Explore Outward: Learning Temperature Policy from LLM Internal States via Hierarchical RL",
        "abstract": "Reinforcement Learning from Verifiable Rewards (RLVR) trains large language models (LLMs) from sampled trajectories, making decoding strategy a core component of learning rather than a purely inference-time choice. Sampling temperature directly controls the exploration--exploitation trade-off by modulating policy entropy, yet existing methods rely on static values or heuristic adaptations that are decoupled from task-level rewards. We propose Introspective LLM, a hierarchical reinforcement learning framework that learns to control sampling temperature during generation. At each decoding step, the model selects a temperature based on its hidden state and samples the next token from the resulting distribution. Temperature and token policies are jointly optimized from downstream rewards using a coordinate ascent scheme. Experiments on mathematical reasoning benchmarks show that learned temperature policies outperform fixed and heuristic baselines, while exhibiting interpretable exploration behaviors aligned with reasoning uncertainty.",
        "url": "http://arxiv.org/abs/2602.13035v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13035v1",
        "arxiv_id": "2602.13035v1",
        "authors": [
            "Yixiao Zhou",
            "Yang Li",
            "Dongzhou Cheng",
            "Hehe Fan",
            "Yu Cheng"
        ],
        "submitted": "2026-02-13 15:42:59",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Buy versus Build an LLM: A Decision Framework for Governments",
        "abstract": "Large Language Models (LLMs) represent a new frontier of digital infrastructure that can support a wide range of public-sector applications, from general purpose citizen services to specialized and sensitive state functions. When expanding AI access, governments face a set of strategic choices over whether to buy existing services, build domestic capabilities, or adopt hybrid approaches across different domains and use cases. These are critical decisions especially when leading model providers are often foreign corporations, and LLM outputs are increasingly treated as trusted inputs to public decision-making and public discourse. In practice, these decisions are not intended to mandate a single approach across all domains; instead, national AI strategies are typically pluralistic, with sovereign, commercial and open-source models coexisting to serve different purposes. Governments may rely on commercial models for non-sensitive or commodity tasks, while pursuing greater control for critical, high-risk or strategically important applications.\n  This paper provides a strategic framework for making this decision by evaluating these options across dimensions including sovereignty, safety, cost, resource capability, cultural fit, and sustainability. Importantly, \"building\" does not imply that governments must act alone: domestic capabilities may be developed through public research institutions, universities, state-owned enterprises, joint ventures, or broader national ecosystems. By detailing the technical requirements and practical challenges of each pathway, this work aims to serve as a reference for policy-makers to determine whether a buy or build approach best aligns with their specific national needs and societal goals.",
        "url": "http://arxiv.org/abs/2602.13033v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13033v1",
        "arxiv_id": "2602.13033v1",
        "authors": [
            "Jiahao Lu",
            "Ziwei Xu",
            "William Tjhi",
            "Junnan Li",
            "Antoine Bosselut",
            "Pang Wei Koh",
            "Mohan Kankanhalli"
        ],
        "submitted": "2026-02-13 15:39:31",
        "source": "arxiv",
        "comment": "The short version of this document is published as an ACM TechBrief, and this document is published as an ACM Technology Policy Council white paper"
    },
    {
        "title": "Human-Aligned MLLM Judges for Fine-Grained Image Editing Evaluation: A Benchmark, Framework, and Analysis",
        "abstract": "Evaluating image editing models remains challenging due to the coarse granularity and limited interpretability of traditional metrics, which often fail to capture aspects important to human perception and intent. Such metrics frequently reward visually plausible outputs while overlooking controllability, edit localization, and faithfulness to user instructions. In this work, we introduce a fine-grained Multimodal Large Language Model (MLLM)-as-a-Judge framework for image editing that decomposes common evaluation notions into twelve fine-grained interpretable factors spanning image preservation, edit quality, and instruction fidelity. Building on this formulation, we present a new human-validated benchmark that integrates human judgments, MLLM-based evaluations, model outputs, and traditional metrics across diverse image editing tasks. Through extensive human studies, we show that the proposed MLLM judges align closely with human evaluations at a fine granularity, supporting their use as reliable and scalable evaluators. We further demonstrate that traditional image editing metrics are often poor proxies for these factors, failing to distinguish over-edited or semantically imprecise outputs, whereas our judges provide more intuitive and informative assessments in both offline and online settings. Together, this work introduces a benchmark, a principled factorization, and empirical evidence positioning fine-grained MLLM judges as a practical foundation for studying, comparing, and improving image editing approaches.",
        "url": "http://arxiv.org/abs/2602.13028v1",
        "pdf_url": "https://arxiv.org/pdf/2602.13028v1",
        "arxiv_id": "2602.13028v1",
        "authors": [
            "Runzhou Liu",
            "Hailey Weingord",
            "Sejal Mittal",
            "Prakhar Dungarwal",
            "Anusha Nandula",
            "Bo Ni",
            "Samyadeep Basu",
            "Hongjie Chen",
            "Nesreen K. Ahmed",
            "Li Li",
            "Jiayi Zhang",
            "Koustava Goswami",
            "Subhojyoti Mukherjee",
            "Branislav Kveton",
            "Puneet Mathur",
            "Franck Dernoncourt",
            "Yue Zhao",
            "Yu Wang",
            "Ryan A. Rossi",
            "Zhengzhong Tu",
            "Hongru Du"
        ],
        "submitted": "2026-02-13 15:34:32",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Know More, Know Clearer: A Meta-Cognitive Framework for Knowledge Augmentation in Large Language Models",
        "abstract": "Knowledge augmentation has significantly enhanced the performance of Large Language Models (LLMs) in knowledge-intensive tasks. However, existing methods typically operate on the simplistic premise that model performance equates with internal knowledge, overlooking the knowledge-confidence gaps that lead to overconfident errors or uncertain truths. To bridge this gap, we propose a novel meta-cognitive framework for reliable knowledge augmentation via differentiated intervention and alignment. Our approach leverages internal cognitive signals to partition the knowledge space into mastered, confused, and missing regions, guiding targeted knowledge expansion. Furthermore, we introduce a cognitive consistency mechanism to synchronize subjective certainty with objective accuracy, ensuring calibrated knowledge boundaries. Extensive experiments demonstrate the our framework consistently outperforms strong baselines, validating its rationality in not only enhancing knowledge capabilities but also fostering cognitive behaviors that better distinguish knowns from unknowns.",
        "url": "http://arxiv.org/abs/2602.12996v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12996v1",
        "arxiv_id": "2602.12996v1",
        "authors": [
            "Hao Chen",
            "Ye He",
            "Yuchun Fan",
            "Yukun Yan",
            "Zhenghao Liu",
            "Qingfu Zhu",
            "Maosong Sun",
            "Wanxiang Che"
        ],
        "submitted": "2026-02-13 15:07:35",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Evaluating the Homogeneity of Keyphrase Prediction Models",
        "abstract": "Keyphrases which are useful in several NLP and IR applications are either extracted from text or predicted by generative models. Contrarily to keyphrase extraction approaches, keyphrase generation models can predict keyphrases that do not appear in a document's text called `absent keyphrases`. This ability means that keyphrase generation models can associate a document to a notion that is not explicitly mentioned in its text. Intuitively, this suggests that for two documents treating the same subjects, a keyphrase generation model is more likely to be homogeneous in their indexing i.e. predict the same keyphrase for both documents, regardless of those keyphrases appearing in their respective text or not; something a keyphrase extraction model would fail to do. Yet, homogeneity of keyphrase prediction models is not covered by current benchmarks. In this work, we introduce a method to evaluate the homogeneity of keyphrase prediction models and study if absent keyphrase generation capabilities actually help the model to be more homogeneous. To our surprise, we show that keyphrase extraction methods are competitive with generative models, and that the ability to generate absent keyphrases can actually have a negative impact on homogeneity. Our data, code and prompts are available on huggingface and github.",
        "url": "http://arxiv.org/abs/2602.12989v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12989v1",
        "arxiv_id": "2602.12989v1",
        "authors": [
            "Maël Houbre",
            "Florian Boudin",
            "Beatrice Daille"
        ],
        "submitted": "2026-02-13 15:00:35",
        "source": "arxiv",
        "comment": "Accepted to LREC 2026"
    },
    {
        "title": "SciAgentGym: Benchmarking Multi-Step Scientific Tool-use in LLM Agents",
        "abstract": "Scientific reasoning inherently demands integrating sophisticated toolkits to navigate domain-specific knowledge. Yet, current benchmarks largely overlook agents' ability to orchestrate tools for such rigorous workflows. To bridge this gap, we introduce SciAgentGym, a scalable interactive environment featuring 1,780 domain-specific tools across four natural science disciplines, supported by a robust execution infrastructure. Complementing this, we present SciAgentBench, a tiered evaluation suite designed to stress-test agentic capabilities from elementary actions to long-horizon workflows. Our evaluation identifies a critical bottleneck: state-of-the-art models struggle with complex scientific tool-use. Even for a leading model like GPT-5, success rates drop sharply from 60.6% to 30.9% as interaction horizons extend, primarily due to failures in multi-step workflow execution. To address this, we propose SciForge, a data synthesis method that models the tool action space as a dependency graph to generate logic-aware training trajectories. By fine-tuning on these trajectories, our SciAgent-8B outperforms the significantly larger Qwen3-VL-235B-Instruct while exhibiting positive cross-domain transfer of scientific tool-use capabilities. These results underscore the promising potential of next-generation autonomous scientific agents.",
        "url": "http://arxiv.org/abs/2602.12984v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12984v1",
        "arxiv_id": "2602.12984v1",
        "authors": [
            "Yujiong Shen",
            "Yajie Yang",
            "Zhiheng Xi",
            "Binze Hu",
            "Huayu Sha",
            "Jiazheng Zhang",
            "Qiyuan Peng",
            "Junlin Shang",
            "Jixuan Huang",
            "Yutao Fan",
            "Jingqi Tong",
            "Shihan Dou",
            "Ming Zhang",
            "Lei Bai",
            "Zhenfei Yin",
            "Tao Gui",
            "Xingjun Ma",
            "Qi Zhang",
            "Xuanjing Huang",
            "Yu-Gang Jiang"
        ],
        "submitted": "2026-02-13 14:58:18",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "RGAlign-Rec: Ranking-Guided Alignment for Latent Query Reasoning in Recommendation Systems",
        "abstract": "Proactive intent prediction is a critical capability in modern e-commerce chatbots, enabling \"zero-query\" recommendations by anticipating user needs from behavioral and contextual signals. However, existing industrial systems face two fundamental challenges: (1) the semantic gap between discrete user features and the semantic intents within the chatbot's Knowledge Base, and (2) the objective misalignment between general-purpose LLM outputs and task-specific ranking utilities. To address these issues, we propose RGAlign-Rec, a closed-loop alignment framework that integrates an LLM-based semantic reasoner with a Query-Enhanced (QE) ranking model. We also introduce Ranking-Guided Alignment (RGA), a multi-stage training paradigm that utilizes downstream ranking signals as feedback to refine the LLM's latent reasoning. Extensive experiments on a large-scale industrial dataset from Shopee demonstrate that RGAlign-Rec achieves a 0.12% gain in GAUC, leading to a significant 3.52% relative reduction in error rate, and a 0.56% improvement in Recall@3. Online A/B testing further validates the cumulative effectiveness of our framework: the Query-Enhanced model (QE-Rec) initially yields a 0.98% improvement in CTR, while the subsequent Ranking-Guided Alignment stage contributes an additional 0.13% gain. These results indicate that ranking-aware alignment effectively synchronizes semantic reasoning with ranking objectives, significantly enhancing both prediction accuracy and service quality in real-world proactive recommendation systems.",
        "url": "http://arxiv.org/abs/2602.12968v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12968v1",
        "arxiv_id": "2602.12968v1",
        "authors": [
            "Junhua Liu",
            "Yang Jihao",
            "Cheng Chang",
            "Kunrong LI",
            "Bin Fu",
            "Kwan Hui Lim"
        ],
        "submitted": "2026-02-13 14:38:02",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "ProbeLLM: Automating Principled Diagnosis of LLM Failures",
        "abstract": "Understanding how and why large language models (LLMs) fail is becoming a central challenge as models rapidly evolve and static evaluations fall behind. While automated probing has been enabled by dynamic test generation, existing approaches often discover isolated failure cases, lack principled control over exploration, and provide limited insight into the underlying structure of model weaknesses. We propose ProbeLLM, a benchmark-agnostic automated probing framework that elevates weakness discovery from individual failures to structured failure modes. ProbeLLM formulates probing as a hierarchical Monte Carlo Tree Search, explicitly allocating limited probing budgets between global exploration of new failure regions and local refinement of recurring error patterns. By restricting probing to verifiable test cases and leveraging tool-augmented generation and verification, ProbeLLM grounds failure discovery in reliable evidence. Discovered failures are further consolidated into interpretable failure modes via failure-aware embeddings and boundary-aware induction. Across diverse benchmarks and LLMs, ProbeLLM reveals substantially broader, cleaner, and more fine-grained failure landscapes than static benchmarks and prior automated methods, supporting a shift from case-centric evaluation toward principled weakness discovery.",
        "url": "http://arxiv.org/abs/2602.12966v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12966v1",
        "arxiv_id": "2602.12966v1",
        "authors": [
            "Yue Huang",
            "Zhengzhe Jiang",
            "Yuchen Ma",
            "Yu Jiang",
            "Xiangqi Wang",
            "Yujun Zhou",
            "Yuexing Hao",
            "Kehan Guo",
            "Pin-Yu Chen",
            "Stefan Feuerriegel",
            "Xiangliang Zhang"
        ],
        "submitted": "2026-02-13 14:33:13",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "JARVIS: An Evidence-Grounded Retrieval System for Interpretable Deceptive Reviews Adjudication",
        "abstract": "Deceptive reviews, refer to fabricated feedback designed to artificially manipulate the perceived quality of products. Within modern e-commerce ecosystems, these reviews remain a critical governance challenge. Despite advances in review-level and graph-based detection methods, two pivotal limitations remain: inadequate generalization and lack of interpretability. To address these challenges, we propose JARVIS, a framework providing Judgment via Augmented Retrieval and eVIdence graph Structures. Starting from the review to be evaluated, it retrieves semantically similar evidence via hybrid dense-sparse multimodal retrieval, expands relational signals through shared entities, and constructs a heterogeneous evidence graph. Large language model then performs evidence-grounded adjudication to produce interpretable risk assessments. Offline experiments demonstrate that JARVIS enhances performance on our constructed review dataset, achieving a precision increase from 0.953 to 0.988 and a recall boost from 0.830 to 0.901. In the production environment, our framework achieves a 27% increase in the recall volume and reduces manual inspection time by 75%. Furthermore, the adoption rate of the model-generated analysis reaches 96.4%.",
        "url": "http://arxiv.org/abs/2602.12941v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12941v1",
        "arxiv_id": "2602.12941v1",
        "authors": [
            "Nan Lu",
            "Leyang Li",
            "Yurong Hu",
            "Rui Lin",
            "Shaoyi Xu"
        ],
        "submitted": "2026-02-13 13:57:45",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "When Words Don't Mean What They Say: Figurative Understanding in Bengali Idioms",
        "abstract": "Figurative language understanding remains a significant challenge for Large Language Models (LLMs), especially for low-resource languages. To address this, we introduce a new idiom dataset, a large-scale, culturally-grounded corpus of 10,361 Bengali idioms. Each idiom is annotated under a comprehensive 19-field schema, established and refined through a deliberative expert consensus process, that captures its semantic, syntactic, cultural, and religious dimensions, providing a rich, structured resource for computational linguistics. To establish a robust benchmark for Bangla figurative language understanding, we evaluate 30 state-of-the-art multilingual and instruction-tuned LLMs on the task of inferring figurative meaning. Our results reveal a critical performance gap, with no model surpassing 50% accuracy, a stark contrast to significantly higher human performance (83.4%). This underscores the limitations of existing models in cross-linguistic and cultural reasoning. By releasing the new idiom dataset and benchmark, we provide foundational infrastructure for advancing figurative language understanding and cultural grounding in LLMs for Bengali and other low-resource languages.",
        "url": "http://arxiv.org/abs/2602.12921v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12921v1",
        "arxiv_id": "2602.12921v1",
        "authors": [
            "Adib Sakhawat",
            "Shamim Ara Parveen",
            "Md Ruhul Amin",
            "Shamim Al Mahmud",
            "Md Saiful Islam",
            "Tahera Khatun"
        ],
        "submitted": "2026-02-13 13:26:11",
        "source": "arxiv",
        "comment": "9 pages, 5 figures. Accepted for presentation at LREC 2026 (Language Resources and Evaluation Conference)"
    },
    {
        "title": "ViMedCSS: A Vietnamese Medical Code-Switching Speech Dataset & Benchmark",
        "abstract": "Code-switching (CS), which is when Vietnamese speech uses English words like drug names or procedures, is a common phenomenon in Vietnamese medical communication. This creates challenges for Automatic Speech Recognition (ASR) systems, especially in low-resource languages like Vietnamese. Current most ASR systems struggle to recognize correctly English medical terms within Vietnamese sentences, and no benchmark addresses this challenge. In this paper, we construct a 34-hour \\textbf{Vi}etnamese \\textbf{Med}ical \\textbf{C}ode-\\textbf{S}witching \\textbf{S}peech dataset (ViMedCSS) containing 16,576 utterances. Each utterance includes at least one English medical term drawn from a curated bilingual lexicon covering five medical topics. Using this dataset, we evaluate several state-of-the-art ASR models and examine different specific fine-tuning strategies for improving medical term recognition to investigate the best approach to solve in the dataset. Experimental results show that Vietnamese-optimized models perform better on general segments, while multilingual pretraining helps capture English insertions. The combination of both approaches yields the best balance between overall and code-switched accuracy. This work provides the first benchmark for Vietnamese medical code-switching and offers insights into effective domain adaptation for low-resource, multilingual ASR systems.",
        "url": "http://arxiv.org/abs/2602.12911v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12911v1",
        "arxiv_id": "2602.12911v1",
        "authors": [
            "Tung X. Nguyen",
            "Nhu Vo",
            "Giang-Son Nguyen",
            "Duy Mai Hoang",
            "Chien Dinh Huynh",
            "Inigo Jauregi Unanue",
            "Massimo Piccardi",
            "Wray Buntine",
            "Dung D. Le"
        ],
        "submitted": "2026-02-13 13:17:16",
        "source": "arxiv",
        "comment": "Accepted at LREC 2026"
    },
    {
        "title": "RADAR: Revealing Asymmetric Development of Abilities in MLLM Pre-training",
        "abstract": "Pre-trained Multi-modal Large Language Models (MLLMs) provide a knowledge-rich foundation for post-training by leveraging their inherent perception and reasoning capabilities to solve complex tasks. However, the lack of an efficient evaluation framework impedes the diagnosis of their performance bottlenecks. Current evaluation primarily relies on testing after supervised fine-tuning, which introduces laborious additional training and autoregressive decoding costs. Meanwhile, common pre-training metrics cannot quantify a model's perception and reasoning abilities in a disentangled manner. Furthermore, existing evaluation benchmarks are typically limited in scale or misaligned with pre-training objectives. Thus, we propose RADAR, an efficient ability-centric evaluation framework for Revealing Asymmetric Development of Abilities in MLLM pRe-training. RADAR involves two key components: (1) Soft Discrimination Score, a novel metric for robustly tracking ability development without fine-tuning, based on quantifying nuanced gradations of the model preference for the correct answer over distractors; and (2) Multi-Modal Mixture Benchmark, a new 15K+ sample benchmark for comprehensively evaluating pre-trained MLLMs' perception and reasoning abilities in a 0-shot manner, where we unify authoritative benchmark datasets and carefully collect new datasets, extending the evaluation scope and addressing the critical gaps in current benchmarks. With RADAR, we comprehensively reveal the asymmetric development of perceptual and reasoning capabilities in pretrained MLLMs across diverse factors, including data volume, model size, and pretraining strategy. Our RADAR underscores the need for a decomposed perspective on pre-training ability bottlenecks, informing targeted interventions to advance MLLMs efficiently. Our code is publicly available at https://github.com/Nieysh/RADAR.",
        "url": "http://arxiv.org/abs/2602.12892v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12892v1",
        "arxiv_id": "2602.12892v1",
        "authors": [
            "Yunshuang Nie",
            "Bingqian Lin",
            "Minzhe Niu",
            "Kun Xiang",
            "Jianhua Han",
            "Guowei Huang",
            "Xingyue Quan",
            "Hang Xu",
            "Bokui Chen",
            "Xiaodan Liang"
        ],
        "submitted": "2026-02-13 12:56:31",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "BaziQA-Benchmark: Evaluating Symbolic and Temporally Compositional Reasoning in Large Language Models",
        "abstract": "We present BaziQA-Benchmark, a standardized benchmark for evaluating symbolic and temporally compositional reasoning in large language models. The benchmark is derived from 200 professionally curated, multiple-choice problems from the Global Fortune-teller Competition (2021--2025), where each instance requires structured inference over a fixed symbolic chart and interacting temporal conditions. Unlike anecdotal or prompt-driven evaluations, BaziQA-Benchmark enables objective scoring and controlled comparison across years, domains, and model families. We evaluate contemporary language models under a multi-turn setting and analyze performance variation across temporal difficulty, reasoning domains, and inference protocols.To further probe reasoning behavior, we introduce a lightweight Structured Reasoning Protocol that constrains inference order without adding domain knowledge. Results show that models consistently outperform chance but remain far from saturation, exhibiting pronounced sensitivity to temporal composition and reasoning order, as well as systematic failures on precise temporal localization and multi-condition symbolic judgments.",
        "url": "http://arxiv.org/abs/2602.12889v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12889v1",
        "arxiv_id": "2602.12889v1",
        "authors": [
            "Jiangxi Chen",
            "Qian Liu"
        ],
        "submitted": "2026-02-13 12:45:42",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Semantic Communities and Boundary-Spanning Lyrics in K-pop: A Graph-Based Unsupervised Analysis",
        "abstract": "Large-scale lyric corpora present unique challenges for data-driven analysis, including the absence of reliable annotations, multilingual content, and high levels of stylistic repetition. Most existing approaches rely on supervised classification, genre labels, or coarse document-level representations, limiting their ability to uncover latent semantic structure. We present a graph-based framework for unsupervised discovery and evaluation of semantic communities in K-pop lyrics using line-level semantic representations. By constructing a similarity graph over lyric texts and applying community detection, we uncover stable micro-theme communities without genre, artist, or language supervision. We further identify boundary-spanning songs via graph-theoretic bridge metrics and analyse their structural properties. Across multiple robustness settings, boundary-spanning lyrics exhibit higher lexical diversity and lower repetition compared to core community members, challenging the assumption that hook intensity or repetition drives cross-theme connectivity. Our framework is language-agnostic and applicable to unlabeled cultural text corpora.",
        "url": "http://arxiv.org/abs/2602.12881v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12881v1",
        "arxiv_id": "2602.12881v1",
        "authors": [
            "Oktay Karakuş"
        ],
        "submitted": "2026-02-13 12:31:30",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "MentalBench: A Benchmark for Evaluating Psychiatric Diagnostic Capability of Large Language Models",
        "abstract": "We introduce MentalBench, a benchmark for evaluating psychiatric diagnostic decision-making in large language models (LLMs). Existing mental health benchmarks largely rely on social media data, limiting their ability to assess DSM-grounded diagnostic judgments. At the core of MentalBench is MentalKG, a psychiatrist-built and validated knowledge graph encoding DSM-5 diagnostic criteria and differential diagnostic rules for 23 psychiatric disorders. Using MentalKG as a golden-standard logical backbone, we generate 24,750 synthetic clinical cases that systematically vary in information completeness and diagnostic complexity, enabling low-noise and interpretable evaluation. Our experiments show that while state-of-the-art LLMs perform well on structured queries probing DSM-5 knowledge, they struggle to calibrate confidence in diagnostic decision-making when distinguishing between clinically overlapping disorders. These findings reveal evaluation gaps not captured by existing benchmarks.",
        "url": "http://arxiv.org/abs/2602.12871v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12871v1",
        "arxiv_id": "2602.12871v1",
        "authors": [
            "Hoyun Song",
            "Migyeong Kang",
            "Jisu Shin",
            "Jihyun Kim",
            "Chanbi Park",
            "Hangyeol Yoo",
            "Jihyun An",
            "Alice Oh",
            "Jinyoung Han",
            "KyungTae Lim"
        ],
        "submitted": "2026-02-13 12:21:33",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "WISE: A Multimodal Search Engine for Visual Scenes, Audio, Objects, Faces, Speech, and Metadata",
        "abstract": "In this paper, we present WISE, an open-source audiovisual search engine which integrates a range of multimodal retrieval capabilities into a single, practical tool accessible to users without machine learning expertise. WISE supports natural-language and reverse-image queries at both the scene level (e.g. empty street) and object level (e.g. horse) across images and videos; face-based search for specific individuals; audio retrieval of acoustic events using text (e.g. wood creak) or an audio file; search over automatically transcribed speech; and filtering by user-provided metadata. Rich insights can be obtained by combining queries across modalities -- for example, retrieving German trains from a historical archive by applying the object query \"train\" and the metadata query \"Germany\", or searching for a face in a place. By employing vector search techniques, WISE can scale to support efficient retrieval over millions of images or thousands of hours of video. Its modular architecture facilitates the integration of new models. WISE can be deployed locally for private or sensitive collections, and has been applied to various real-world use cases. Our code is open-source and available at https://gitlab.com/vgg/wise/wise.",
        "url": "http://arxiv.org/abs/2602.12819v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12819v1",
        "arxiv_id": "2602.12819v1",
        "authors": [
            "Prasanna Sridhar",
            "Horace Lee",
            "David M. S. Pinto",
            "Andrew Zisserman",
            "Abhishek Dutta"
        ],
        "submitted": "2026-02-13 11:03:06",
        "source": "arxiv",
        "comment": "Software: https://www.robots.ox.ac.uk/~vgg/software/wise/ , Online demos: https://www.robots.ox.ac.uk/~vgg/software/wise/demo/ , Example Queries: https://www.robots.ox.ac.uk/~vgg/software/wise/examples/"
    },
    {
        "title": "AIWizards at MULTIPRIDE: A Hierarchical Approach to Slur Reclamation Detection",
        "abstract": "Detecting reclaimed slurs represents a fundamental challenge for hate speech detection systems, as the same lexcal items can function either as abusive expressions or as in-group affirmations depending on social identity and context. In this work, we address Subtask B of the MultiPRIDE shared task at EVALITA 2026 by proposing a hierarchical approach to modeling the slur reclamation process. Our core assumption is that members of the LGBTQ+ community are more likely, on average, to employ certain slurs in a eclamatory manner. Based on this hypothesis, we decompose the task into two stages. First, using a weakly supervised LLM-based annotation, we assign fuzzy labels to users indicating the likelihood of belonging to the LGBTQ+ community, inferred from the tweet and the user bio. These soft labels are then used to train a BERT-like model to predict community membership, encouraging the model to learn latent representations associated with LGBTQ+ identity. In the second stage, we integrate this latent space with a newly initialized model for the downstream slur reclamation detection task. The intuition is that the first model encodes user-oriented sociolinguistic signals, which are then fused with representations learned by a model pretrained for hate speech detection. Experimental results on Italian and Spanish show that our approach achieves performance statistically comparable to a strong BERT-based baseline, while providing a modular and extensible framework for incorporating sociolinguistic context into hate speech modeling. We argue that more fine-grained hierarchical modeling of user identity and discourse context may further improve the detection of reclaimed language. We release our code at https://github.com/LucaTedeschini/multipride.",
        "url": "http://arxiv.org/abs/2602.12818v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12818v1",
        "arxiv_id": "2602.12818v1",
        "authors": [
            "Luca Tedeschini",
            "Matteo Fasulo"
        ],
        "submitted": "2026-02-13 11:01:19",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Left-right asymmetry in predicting brain activity from LLMs' representations emerges with their formal linguistic competence",
        "abstract": "When humans and large language models (LLMs) process the same text, activations in the LLMs correlate with brain activity measured, e.g., with functional magnetic resonance imaging (fMRI). Moreover, it has been shown that, as the training of an LLM progresses, the performance in predicting brain activity from its internal activations improves more in the left hemisphere than in the right one. The aim of the present work is to understand which kind of competence acquired by the LLMs underlies the emergence of this left-right asymmetry. Using the OLMo-2 7B language model at various training checkpoints and fMRI data from English participants, we compare the evolution of the left-right asymmetry in brain scores alongside performance on several benchmarks. We observe that the asymmetry co-emerges with the formal linguistic abilities of the LLM. These abilities are demonstrated in two ways: by the model's capacity to assign a higher probability to an acceptable sentence than to a grammatically unacceptable one within a minimal contrasting pair, or its ability to produce well-formed text. On the opposite, the left-right asymmetry does not correlate with the performance on arithmetic or Dyck language tasks; nor with text-based tasks involving world knowledge and reasoning. We generalize these results to another family of LLMs (Pythia) and another language, namely French. Our observations indicate that the left-right asymmetry in brain predictivity matches the progress in formal linguistic competence (knowledge of linguistic patterns).",
        "url": "http://arxiv.org/abs/2602.12811v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12811v1",
        "arxiv_id": "2602.12811v1",
        "authors": [
            "Laurent Bonnasse-Gahot",
            "Christophe Pallier"
        ],
        "submitted": "2026-02-13 10:46:09",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "RAT-Bench: A Comprehensive Benchmark for Text Anonymization",
        "abstract": "Data containing personal information is increasingly used to train, fine-tune, or query Large Language Models (LLMs). Text is typically scrubbed of identifying information prior to use, often with tools such as Microsoft's Presidio or Anthropic's PII purifier. These tools have traditionally been evaluated on their ability to remove specific identifiers (e.g., names), yet their effectiveness at preventing re-identification remains unclear. We introduce RAT-Bench, a comprehensive benchmark for text anonymization tools based on re-identification risk. Using U.S. demographic statistics, we generate synthetic text containing various direct and indirect identifiers across domains, languages, and difficulty levels. We evaluate a range of NER- and LLM-based text anonymization tools and, based on the attributes an LLM-based attacker is able to correctly infer from the anonymized text, we report the risk of re-identification in the U.S. population, while properly accounting for the disparate impact of identifiers. We find that, while capabilities vary widely, even the best tools are far from perfect in particular when direct identifiers are not written in standard ways and when indirect identifiers enable re-identification. Overall we find LLM-based anonymizers, including new iterative anonymizers, to provide a better privacy-utility trade-off albeit at a higher computational cost. Importantly, we also find them to work well across languages. We conclude with recommendations for future anonymization tools and will release the benchmark and encourage community efforts to expand it, in particular to other geographies.",
        "url": "http://arxiv.org/abs/2602.12806v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12806v1",
        "arxiv_id": "2602.12806v1",
        "authors": [
            "Nataša Krčo",
            "Zexi Yao",
            "Matthieu Meeus",
            "Yves-Alexandre de Montjoye"
        ],
        "submitted": "2026-02-13 10:41:44",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "SQuTR: A Robustness Benchmark for Spoken Query to Text Retrieval under Acoustic Noise",
        "abstract": "Spoken query retrieval is an important interaction mode in modern information retrieval. However, existing evaluation datasets are often limited to simple queries under constrained noise conditions, making them inadequate for assessing the robustness of spoken query retrieval systems under complex acoustic perturbations. To address this limitation, we present SQuTR, a robustness benchmark for spoken query retrieval that includes a large-scale dataset and a unified evaluation protocol. SQuTR aggregates 37,317 unique queries from six commonly used English and Chinese text retrieval datasets, spanning multiple domains and diverse query types. We synthesize speech using voice profiles from 200 real speakers and mix 17 categories of real-world environmental noise under controlled SNR levels, enabling reproducible robustness evaluation from quiet to highly noisy conditions. Under the unified protocol, we conduct large-scale evaluations on representative cascaded and end-to-end retrieval systems. Experimental results show that retrieval performance decreases as noise increases, with substantially different drops across systems. Even large-scale retrieval models struggle under extreme noise, indicating that robustness remains a critical bottleneck. Overall, SQuTR provides a reproducible testbed for benchmarking and diagnostic analysis, and facilitates future research on robustness in spoken query to text retrieval.",
        "url": "http://arxiv.org/abs/2602.12783v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12783v1",
        "arxiv_id": "2602.12783v1",
        "authors": [
            "Yuejie Li",
            "Ke Yang",
            "Yueying Hua",
            "Berlin Chen",
            "Jianhao Nie",
            "Yueping He",
            "Caixin Kang"
        ],
        "submitted": "2026-02-13 10:08:27",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Aspect-Based Sentiment Analysis for Future Tourism Experiences: A BERT-MoE Framework for Persian User Reviews",
        "abstract": "This study advances aspect-based sentiment analysis (ABSA) for Persian-language user reviews in the tourism domain, addressing challenges of low-resource languages. We propose a hybrid BERT-based model with Top-K routing and auxiliary losses to mitigate routing collapse and improve efficiency. The pipeline includes: (1) overall sentiment classification using BERT on 9,558 labeled reviews, (2) multi-label aspect extraction for six tourism-related aspects (host, price, location, amenities, cleanliness, connectivity), and (3) integrated ABSA with dynamic routing. The dataset consists of 58,473 preprocessed reviews from the Iranian accommodation platform Jabama, manually annotated for aspects and sentiments. The proposed model achieves a weighted F1-score of 90.6% for ABSA, outperforming baseline BERT (89.25%) and a standard hybrid approach (85.7%). Key efficiency gains include a 39% reduction in GPU power consumption compared to dense BERT, supporting sustainable AI deployment in alignment with UN SDGs 9 and 12. Analysis reveals high mention rates for cleanliness and amenities as critical aspects. This is the first ABSA study focused on Persian tourism reviews, and we release the annotated dataset to facilitate future multilingual NLP research in tourism.",
        "url": "http://arxiv.org/abs/2602.12778v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12778v1",
        "arxiv_id": "2602.12778v1",
        "authors": [
            "Hamidreza Kazemi Taskooh",
            "Taha Zare Harofte"
        ],
        "submitted": "2026-02-13 10:01:33",
        "source": "arxiv",
        "comment": "25 pages, 12 figures, 4 tables"
    },
    {
        "title": "Towards a Diagnostic and Predictive Evaluation Methodology for Sequence Labeling Tasks",
        "abstract": "Standard evaluation in NLP typically indicates that system A is better on average than system B, but it provides little info on how to improve performance and, what is worse, it should not come as a surprise if B ends up being better than A on outside data. We propose an evaluation methodology for sequence labeling tasks grounded on error analysis that provides both quantitative and qualitative information on where systems must be improved and predicts how models will perform on a different distribution. The key is to create test sets that, contrary to common practice, do not rely on gathering large amounts of real-world in-distribution scraped data, but consists in handcrafting a small set of linguistically motivated examples that exhaustively cover the range of span attributes (such as shape, length, casing, sentence position, etc.) a system may encounter in the wild. We demonstrate this methodology on a benchmark for anglicism identification in Spanish. Our methodology provides results that are diagnostic (because they help identify systematic weaknesses in performance), actionable (because they can inform which model is better suited for a given scenario) and predictive: our method predicts model performance on external datasets with a median correlation of 0.85.",
        "url": "http://arxiv.org/abs/2602.12759v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12759v1",
        "arxiv_id": "2602.12759v1",
        "authors": [
            "Elena Alvarez-Mellado",
            "Julio Gonzalo"
        ],
        "submitted": "2026-02-13 09:39:10",
        "source": "arxiv",
        "comment": "Accepted at LREC 2026"
    },
    {
        "title": "Lamer-SSL: Layer-aware Mixture of LoRA Experts for Continual Multilingual Expansion of Self-supervised Models without Forgetting",
        "abstract": "Despite their impressive performance, self-supervised speech models often struggle to generalize to new languages and tend to forget previously acquired knowledge during continual training. To address this, we propose Lamer-SSL, a parameter-efficient framework that integrates a Layer-Aware MixturE of LoRA Experts (Lamer) module with a replay strategy. The Lamer module enables flexible balancing between shared and language-specific representations, while layer-aware expert allocation assigns more experts to deeper layers where semantic information is richer. Meanwhile, the replay strategy retains prior knowledge using minimal data, mitigating forgetting during continual training. Experiments on automatic speech recognition (ASR) and language identification (LID) demonstrate that Lamer-SSL extends self-supervised models to new languages effectively while maintaining strong performance on previously learned languages with only 2.14% parameters being trainable.",
        "url": "http://arxiv.org/abs/2602.12746v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12746v1",
        "arxiv_id": "2602.12746v1",
        "authors": [
            "Jing Xu",
            "Minglin Wu",
            "Xueyuan Chen",
            "Xixin Wu",
            "Helen Meng"
        ],
        "submitted": "2026-02-13 09:22:22",
        "source": "arxiv",
        "comment": "Accepted by ICASSP 2026"
    },
    {
        "title": "VimRAG: Navigating Massive Visual Context in Retrieval-Augmented Generation via Multimodal Memory Graph",
        "abstract": "Effectively retrieving, reasoning, and understanding multimodal information remains a critical challenge for agentic systems. Traditional Retrieval-augmented Generation (RAG) methods rely on linear interaction histories, which struggle to handle long-context tasks, especially those involving information-sparse yet token-heavy visual data in iterative reasoning scenarios. To bridge this gap, we introduce VimRAG, a framework tailored for multimodal Retrieval-augmented Reasoning across text, images, and videos. Inspired by our systematic study, we model the reasoning process as a dynamic directed acyclic graph that structures the agent states and retrieved multimodal evidence. Building upon this structured memory, we introduce a Graph-Modulated Visual Memory Encoding mechanism, with which the significance of memory nodes is evaluated via their topological position, allowing the model to dynamically allocate high-resolution tokens to pivotal evidence while compressing or discarding trivial clues. To implement this paradigm, we propose a Graph-Guided Policy Optimization strategy. This strategy disentangles step-wise validity from trajectory-level rewards by pruning memory nodes associated with redundant actions, thereby facilitating fine-grained credit assignment. Extensive experiments demonstrate that VimRAG consistently achieves state-of-the-art performance on diverse multimodal RAG benchmarks. The code is available at https://github.com/Alibaba-NLP/VRAG.",
        "url": "http://arxiv.org/abs/2602.12735v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12735v1",
        "arxiv_id": "2602.12735v1",
        "authors": [
            "Qiuchen Wang",
            "Shihang Wang",
            "Yu Zeng",
            "Qiang Zhang",
            "Fanrui Zhang",
            "Zhuoning Guo",
            "Bosi Zhang",
            "Wenxuan Huang",
            "Lin Chen",
            "Zehui Chen",
            "Pengjun Xie",
            "Ruixue Ding"
        ],
        "submitted": "2026-02-13 09:05:09",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Training Dense Retrievers with Multiple Positive Passages",
        "abstract": "Modern knowledge-intensive systems, such as retrieval-augmented generation (RAG), rely on effective retrievers to establish the performance ceiling for downstream modules. However, retriever training has been bottlenecked by sparse, single-positive annotations, which lead to false-negative noise and suboptimal supervision. While the advent of large language models (LLMs) makes it feasible to collect comprehensive multi-positive relevance labels at scale, the optimal strategy for incorporating these dense signals into training remains poorly understood. In this paper, we present a systematic study of multi-positive optimization objectives for retriever training. We unify representative objectives, including Joint Likelihood (JointLH), Summed Marginal Likelihood (SumMargLH), and Log-Sum-Exp Pairwise (LSEPair) loss, under a shared contrastive learning framework. Our theoretical analysis characterizes their distinct gradient behaviors, revealing how each allocates probability mass across positive document sets. Empirically, we conduct extensive evaluations on Natural Questions, MS MARCO, and the BEIR benchmark across two realistic regimes: homogeneous LLM-annotated data and heterogeneous mixtures of human and LLM labels. Our results show that LSEPair consistently achieves superior robustness and performance across settings, while JointLH and SumMargLH exhibit high sensitivity to the quality of positives. Furthermore, we find that the simple strategy of random sampling (Rand1LH) serves as a reliable baseline. By aligning theoretical insights with empirical findings, we provide practical design principles for leveraging dense, LLM-augmented supervision to enhance retriever effectiveness.",
        "url": "http://arxiv.org/abs/2602.12727v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12727v1",
        "arxiv_id": "2602.12727v1",
        "authors": [
            "Benben Wang",
            "Minghao Tang",
            "Hengran Zhang",
            "Jiafeng Guo",
            "Keping Bi"
        ],
        "submitted": "2026-02-13 08:56:52",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "ReFilter: Improving Robustness of Retrieval-Augmented Generation via Gated Filter",
        "abstract": "Retrieval-augmented generation (RAG) has become a dominant paradigm for grounding large language models (LLMs) with external evidence in knowledge-intensive question answering. A core design choice is how to fuse retrieved samples into the LLMs, where existing internal fusion approaches broadly fall into query-based fusion, parametric fusion, and latent-based fusion. Despite their effectiveness at modest retrieval scales, these methods often fail to scale gracefully as the number of retrieved candidates k increases: Larger k improves evidence coverage, yet realistic top-k retrieval inevitably contains irrelevant or redundant content and increases the inference cost.\n  To address these limitations, we propose ReFilter, a novel latent-based fusion framework that performs token-level filtering and fusion. ReFilter consists of three key components: a context encoder for encoding context features, a gated filter for weighting each token, and a token fusion module for integrating the weighted token feature into the LLM's hidden states. Our experiments across four general-domain QA benchmarks show that ReFilter consistently achieves the best average performance under both in-domain adaptation and out-of-domain transfer. ReFilter further generalizes to five biomedical QA benchmarks in zero-shot transfer without domain fine-tuning, reaching 70.01% average accuracy with Qwen2.5-14B-Instruct.",
        "url": "http://arxiv.org/abs/2602.12709v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12709v1",
        "arxiv_id": "2602.12709v1",
        "authors": [
            "Yixin Chen",
            "Ying Xiong",
            "Shangyu Wu",
            "Xiangrui Ke",
            "Nan Guan",
            "Chun Jason Xue"
        ],
        "submitted": "2026-02-13 08:25:26",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs",
        "abstract": "We present MedXIAOHE, a medical vision-language foundation model designed to advance general-purpose medical understanding and reasoning in real-world clinical applications. MedXIAOHE achieves state-of-the-art performance across diverse medical benchmarks and surpasses leading closed-source multimodal systems on multiple capabilities. To achieve this, we propose an entity-aware continual pretraining framework that organizes heterogeneous medical corpora to broaden knowledge coverage and reduce long-tail gaps (e.g., rare diseases). For medical expert-level reasoning and interaction, MedXIAOHE incorporates diverse medical reasoning patterns via reinforcement learning and tool-augmented agentic training, enabling multi-step diagnostic reasoning with verifiable decision traces. To improve reliability in real-world use, MedXIAOHE integrates user-preference rubrics, evidence-grounded reasoning, and low-hallucination long-form report generation, with improved adherence to medical instructions. We release this report to document our practical design choices, scaling insights, and evaluation framework, hoping to inspire further research.",
        "url": "http://arxiv.org/abs/2602.12705v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12705v1",
        "arxiv_id": "2602.12705v1",
        "authors": [
            "Baorong Shi",
            "Bo Cui",
            "Boyuan Jiang",
            "Deli Yu",
            "Fang Qian",
            "Haihua Yang",
            "Huichao Wang",
            "Jiale Chen",
            "Jianfei Pan",
            "Jieqiong Cao",
            "Jinghao Lin",
            "Kai Wu",
            "Lin Yang",
            "Shengsheng Yao",
            "Tao Chen",
            "Xiaojun Xiao",
            "Xiaozhong Ji",
            "Xu Wang",
            "Yijun He",
            "Zhixiong Yang"
        ],
        "submitted": "2026-02-13 08:19:38",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "$\\mathcal{X}$-KD: General Experiential Knowledge Distillation for Large Language Models",
        "abstract": "Knowledge Distillation (KD) for Large Language Models (LLMs) has become increasingly important as models grow in size and complexity. While existing distillation approaches focus on imitating teacher behavior, they often overlook the original learning environment that shaped the teacher's knowledge. Inspired by the experiential learning theory and inverse reinforcement learning, we propose Experiential Knowledge Distillation ($\\mathcal{X}$-KD), a novel and general framework that enables student models to learn in the teacher's original learning environment. $\\mathcal{X}$-KD adopts the Approximated Variational Reward Imitation Learning (AVRIL) framework to jointly model the teacher's original reward function and perform policy distillation, encouraging consistency between the student policy and the original reward function. Our derivation demonstrates that $\\mathcal{X}$-KD follows the supervised learning framework and applies to both sequence-level and divergence-based distillation methods, underlining the simplicity and flexibility of our approach. Empirical results show that $\\mathcal{X}$-KD outperforms the generalized KD and MiniLLM baselines on abstractive summarization, machine translation, and arithmetic reasoning tasks. Additionally, $\\mathcal{X}$-KD achieves better performance-diversity trade-off and data efficiency than baseline KD approaches.",
        "url": "http://arxiv.org/abs/2602.12674v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12674v1",
        "arxiv_id": "2602.12674v1",
        "authors": [
            "Yuang Cai",
            "Yuyu Yuan"
        ],
        "submitted": "2026-02-13 07:15:10",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents",
        "abstract": "Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses, while thinking models engage in deep reasoning uniformly. This rigidity is inefficient for long-horizon tasks, where cognitive demands vary significantly from step to step, with some requiring strategic planning and others only routine execution. In this paper, we introduce CogRouter, a framework that trains agents to dynamically adapt cognitive depth at each step. Grounded in ACT-R theory, we design four hierarchical cognitive levels ranging from instinctive responses to strategic planning. Our two-stage training approach includes Cognition-aware Supervised Fine-tuning (CoSFT) to instill stable level-specific patterns, and Cognition-aware Policy Optimization (CoPO) for step-level credit assignment via confidence-aware advantage reweighting. The key insight is that appropriate cognitive depth should maximize the confidence of the resulting action. Experiments on ALFWorld and ScienceWorld demonstrate that CogRouter achieves state-of-the-art performance with superior efficiency. With Qwen2.5-7B, it reaches an 82.3% success rate, outperforming GPT-4o (+40.3%), OpenAI-o3 (+18.3%), and GRPO (+14.0%), while using 62% fewer tokens.",
        "url": "http://arxiv.org/abs/2602.12662v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12662v1",
        "arxiv_id": "2602.12662v1",
        "authors": [
            "Ruihan Yang",
            "Fanghua Ye",
            "Xiang We",
            "Ruoqing Zhao",
            "Kang Luo",
            "Xinbo Xu",
            "Bo Zhao",
            "Ruotian Ma",
            "Shanyi Wang",
            "Zhaopeng Tu",
            "Xiaolong Li",
            "Deqing Yang",
            "Linus"
        ],
        "submitted": "2026-02-13 06:52:09",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Learning Ordinal Probabilistic Reward from Preferences",
        "abstract": "Reward models are crucial for aligning large language models (LLMs) with human values and intentions. Existing approaches follow either Generative (GRMs) or Discriminative (DRMs) paradigms, yet both suffer from limitations: GRMs typically demand costly point-wise supervision, while DRMs produce uncalibrated relative scores that lack probabilistic interpretation. To address these challenges, we introduce a novel reward modeling paradigm: Probabilistic Reward Model (PRM). Instead of modeling reward as a deterministic scalar, our approach treats it as a random variable, learning a full probability distribution for the quality of each response. To make this paradigm practical, we present its closed-form, discrete realization: the Ordinal Probabilistic Reward Model (OPRM), which discretizes the quality score into a finite set of ordinal ratings. Building on OPRM, we propose a data-efficient training strategy called Region Flooding Tuning (RgFT). It enables rewards to better reflect absolute text quality by incorporating quality-level annotations, which guide the model to concentrate the probability mass within corresponding rating sub-regions. Experiments on various reward model benchmarks show that our method improves accuracy by $\\textbf{2.9%}\\sim\\textbf{7.4%}$ compared to prior reward models, demonstrating strong performance and data efficiency. Analysis of the score distribution provides evidence that our method captures not only relative rankings but also absolute quality.",
        "url": "http://arxiv.org/abs/2602.12660v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12660v1",
        "arxiv_id": "2602.12660v1",
        "authors": [
            "Longze Chen",
            "Lu Wang",
            "Renke Shan",
            "Ze Gong",
            "Run Luo",
            "Jiaming Li",
            "Jing Luo",
            "Qiyao Wang",
            "Min Yang"
        ],
        "submitted": "2026-02-13 06:43:02",
        "source": "arxiv",
        "comment": "28 pages, 5 figures, ICLR 2026"
    },
    {
        "title": "Beyond Normalization: Rethinking the Partition Function as a Difficulty Scheduler for RLVR",
        "abstract": "Reward-maximizing RL methods enhance the reasoning performance of LLMs, but often reduce the diversity among outputs. Recent works address this issue by adopting GFlowNets, training LLMs to match a target distribution while jointly learning its partition function. In contrast to prior works that treat this partition function solely as a normalizer, we reinterpret it as a per-prompt expected-reward (i.e., online accuracy) signal, leveraging this unused information to improve sample efficiency. Specifically, we first establish a theoretical relationship between the partition function and per-prompt accuracy estimates. Building on this key insight, we propose Partition Function-Guided RL (PACED-RL), a post-training framework that leverages accuracy estimates to prioritize informative question prompts during training, and further improves sample efficiency through an accuracy estimate error-prioritized replay. Crucially, both components reuse information already produced during GFlowNet training, effectively amortizing the compute overhead into the existing optimization process. Extensive experiments across diverse benchmarks demonstrate strong performance improvements over GRPO and prior GFlowNet approaches, highlighting PACED-RL as a promising direction for a more sample efficient distribution-matching training for LLMs.",
        "url": "http://arxiv.org/abs/2602.12642v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12642v1",
        "arxiv_id": "2602.12642v1",
        "authors": [
            "Dohyung Kim",
            "Minbeom Kim",
            "Jeonghye Kim",
            "Sangmook Lee",
            "Sojeong Rhee",
            "Kyomin Jung"
        ],
        "submitted": "2026-02-13 06:04:14",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "CLASE: A Hybrid Method for Chinese Legalese Stylistic Evaluation",
        "abstract": "Legal text generated by large language models (LLMs) can usually achieve reasonable factual accuracy, but it frequently fails to adhere to the specialised stylistic norms and linguistic conventions of legal writing. In order to improve stylistic quality, a crucial first step is to establish a reliable evaluation method. However, having legal experts manually develop such a metric is impractical, as the implicit stylistic requirements in legal writing practice are difficult to formalise into explicit rubrics. Meanwhile, existing automatic evaluation methods also fall short: reference-based metrics conflate semantic accuracy with stylistic fidelity, and LLM-as-a-judge evaluations suffer from opacity and inconsistency. To address these challenges, we introduce CLASE (Chinese LegAlese Stylistic Evaluation), a hybrid evaluation method that focuses on the stylistic performance of legal text. The method incorporates a hybrid scoring mechanism that combines 1) linguistic feature-based scores and 2) experience-guided LLM-as-a-judge scores. Both the feature coefficients and the LLM scoring experiences are learned from contrastive pairs of authentic legal documents and their LLM-restored counterparts. This hybrid design captures both surface-level features and implicit stylistic norms in a transparent, reference-free manner. Experiments on 200 Chinese legal documents show that CLASE achieves substantially higher alignment with human judgments than traditional metrics and pure LLM-as-a-judge methods. Beyond improved alignment, CLASE provides interpretable score breakdowns and suggestions for improvements, offering a scalable and practical solution for professional stylistic evaluation in legal text generation (Code and data for CLASE is available at: https://github.com/rexera/CLASE).",
        "url": "http://arxiv.org/abs/2602.12639v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12639v1",
        "arxiv_id": "2602.12639v1",
        "authors": [
            "Yiran Rex Ma",
            "Yuxiao Ye",
            "Huiyuan Xie"
        ],
        "submitted": "2026-02-13 05:51:56",
        "source": "arxiv",
        "comment": "Accepted at LREC 2026"
    },
    {
        "title": "Unleashing Low-Bit Inference on Ascend NPUs: A Comprehensive Evaluation of HiFloat Formats",
        "abstract": "As LLMs scale, low-bit floating-point formats like MXFP and NVFP4 offer new opportunities for precision and efficiency. In this work, we evaluate HiFloat (HiF8 and HiF4), a family of formats tailored for Ascend NPUs. Through rigorous comparison across weight-activation and KV-cache tasks, we provide three key insights: (1) INT8 suits narrow-range data, while floating-point formats excel with high-variance data; (2) in 4-bit regimes, HiF4's hierarchical scaling prevents the accuracy collapse seen in integer formats; and (3) HiFloat is fully compatible with state-of-the-art post-training quantization frameworks. Overall, HiFloat provides a solution for high-efficiency LLM inference on NPUs.",
        "url": "http://arxiv.org/abs/2602.12635v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12635v1",
        "arxiv_id": "2602.12635v1",
        "authors": [
            "Pengxiang Zhao",
            "Hui-Ling Zhen",
            "Xing Li",
            "Han Bao",
            "Weizhe Lin",
            "Zhiyuan Yang",
            "Ziwei Yu",
            "Xin Wang",
            "Mingxuan Yuan",
            "Xianzhi Yu",
            "Zhenhua Dong"
        ],
        "submitted": "2026-02-13 05:41:31",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Vision Token Reduction via Attention-Driven Self-Compression for Efficient Multimodal Large Language Models",
        "abstract": "Multimodal Large Language Models (MLLMs) incur significant computational cost from processing numerous vision tokens through all LLM layers. Prior pruning methods operate either before the LLM, limiting generality due to diverse encoder-projector designs or within the LLM using heuristics that are incompatible with FlashAttention. We take a different approach: rather than identifying unimportant tokens, we treat the LLM itself as the optimal guide for compression. Observing that deeper layers naturally transmit vision-to-text information, we introduce Attention-Driven Self-Compression (ADSC), a simple, broadly applicable method that progressively reduces vision tokens using only the LLM's attention mechanism. Our method applies uniform token downsampling at selected layers, forming bottlenecks that encourage the model to reorganize and compress information into the remaining tokens. It requires no score computation, auxiliary modules, or attention modification, and remains fully compatible with FlashAttention. Applied to LLaVA-1.5, ADSC reduces FLOPs by 53.7% and peak KV-cache memory by 56.7%, while preserving 98.2% of the original model performance. Across multiple benchmarks, it outperforms prior pruning approaches in both efficiency and accuracy. Crucially, under high compression ratios, our method remains robust while heuristic-based techniques degrade sharply.",
        "url": "http://arxiv.org/abs/2602.12618v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12618v1",
        "arxiv_id": "2602.12618v1",
        "authors": [
            "Omer Faruk Deniz",
            "Ruiyu Mao",
            "Ruochen Li",
            "Yapeng Tian",
            "Latifur Khan"
        ],
        "submitted": "2026-02-13 04:49:27",
        "source": "arxiv",
        "comment": "2025 IEEE International Conference on Big Data (BigData)"
    },
    {
        "title": "Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback",
        "abstract": "Traditional methods for automating recommender system design, such as Neural Architecture Search (NAS), are often constrained by a fixed search space defined by human priors, limiting innovation to pre-defined operators. While recent LLM-driven code evolution frameworks shift fixed search space target to open-ended program spaces, they primarily rely on scalar metrics (e.g., NDCG, Hit Ratio) that fail to provide qualitative insights into model failures or directional guidance for improvement. To address this, we propose Self-EvolveRec, a novel framework that establishes a directional feedback loop by integrating a User Simulator for qualitative critiques and a Model Diagnosis Tool for quantitative internal verification. Furthermore, we introduce a Diagnosis Tool - Model Co-Evolution strategy to ensure that evaluation criteria dynamically adapt as the recommendation architecture evolves. Extensive experiments demonstrate that Self-EvolveRec significantly outperforms state-of-the-art NAS and LLM-driven code evolution baselines in both recommendation performance and user satisfaction. Our code is available at https://github.com/Sein-Kim/self_evolverec.",
        "url": "http://arxiv.org/abs/2602.12612v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12612v1",
        "arxiv_id": "2602.12612v1",
        "authors": [
            "Sein Kim",
            "Sangwu Park",
            "Hongseok Kang",
            "Wonjoong Kim",
            "Jimin Seo",
            "Yeonjun In",
            "Kanghoon Yoon",
            "Chanyoung Park"
        ],
        "submitted": "2026-02-13 04:38:32",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "HyperMLP: An Integrated Perspective for Sequence Modeling",
        "abstract": "Self-attention is often viewed as probabilistic query-key lookup, motivating designs that preserve normalized attention scores and fixed positional semantics. We advocate a simpler and more unified perspective: an autoregressive attention head can be viewed as a dynamic two-layer MLP whose weights are instantiated from the context history. From this view, attention scores form an ever-growing hidden representation, and standard MLP activations such as ReLU or GLU naturally implement input-conditioned selection over a context-dependent memory pool rather than a probability distribution. Based on this formulation, we introduce HyperMLP and HyperGLU, which learn dynamic mixing in both feature space and sequence space, using a reverse-offset (lag) layout to align temporal mixing with autoregressive semantics. We provide theoretical characterizations of the expressivity and implications of this structure, and empirically show that HyperMLP/HyperGLU consistently outperform strong softmax-attention baselines under matched parameter budgets.",
        "url": "http://arxiv.org/abs/2602.12601v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12601v1",
        "arxiv_id": "2602.12601v1",
        "authors": [
            "Jiecheng Lu",
            "Shihao Yang"
        ],
        "submitted": "2026-02-13 04:20:10",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "RQ-GMM: Residual Quantized Gaussian Mixture Model for Multimodal Semantic Discretization in CTR Prediction",
        "abstract": "Multimodal content is crucial for click-through rate (CTR) prediction. However, directly incorporating continuous embeddings from pre-trained models into CTR models yields suboptimal results due to misaligned optimization objectives and convergence speed inconsistency during joint training. Discretizing embeddings into semantic IDs before feeding them into CTR models offers a more effective solution, yet existing methods suffer from limited codebook utilization, reconstruction accuracy, and semantic discriminability. We propose RQ-GMM (Residual Quantized Gaussian Mixture Model), which introduces probabilistic modeling to better capture the statistical structure of multimodal embedding spaces. Through Gaussian Mixture Models combined with residual quantization, RQ-GMM achieves superior codebook utilization and reconstruction accuracy. Experiments on public datasets and online A/B tests on a large-scale short-video platform serving hundreds of millions of users demonstrate substantial improvements: RQ-GMM yields a 1.502% gain in Advertiser Value over strong baselines. The method has been fully deployed, serving daily recommendations for hundreds of millions of users.",
        "url": "http://arxiv.org/abs/2602.12593v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12593v1",
        "arxiv_id": "2602.12593v1",
        "authors": [
            "Ziye Tong",
            "Jiahao Liu",
            "Weimin Zhang",
            "Hongji Ruan",
            "Derick Tang",
            "Zhanpeng Zeng",
            "Qinsong Zeng",
            "Peng Zhang",
            "Tun Lu",
            "Ning Gu"
        ],
        "submitted": "2026-02-13 04:11:24",
        "source": "arxiv",
        "comment": "Under review"
    },
    {
        "title": "Discovering Semantic Latent Structures in Psychological Scales: A Response-Free Pathway to Efficient Simplification",
        "abstract": "Psychological scale refinement traditionally relies on response-based methods such as factor analysis, item response theory, and network psychometrics to optimize item composition. Although rigorous, these approaches require large samples and may be constrained by data availability and cross-cultural comparability. Recent advances in natural language processing suggest that the semantic structure of questionnaire items may encode latent construct organization, offering a complementary response-free perspective. We introduce a topic-modeling framework that operationalizes semantic latent structure for scale simplification. Items are encoded using contextual sentence embeddings and grouped via density-based clustering to discover latent semantic factors without predefining their number. Class-based term weighting derives interpretable topic representations that approximate constructs and enable merging of semantically adjacent clusters. Representative items are selected using membership criteria within an integrated reduction pipeline. We benchmarked the framework across DASS, IPIP, and EPOCH, evaluating structural recovery, internal consistency, factor congruence, correlation preservation, and reduction efficiency. The proposed method recovered coherent factor-like groupings aligned with established constructs. Selected items reduced scale length by 60.5% on average while maintaining psychometric adequacy. Simplified scales showed high concordance with original factor structures and preserved inter-factor correlations, indicating that semantic latent organization provides a response-free approximation of measurement structure. Our framework formalizes semantic structure as an inspectable front-end for scale construction and reduction. To facilitate adoption, we provide a visualization-supported tool enabling one-click semantic analysis and structured simplification.",
        "url": "http://arxiv.org/abs/2602.12575v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12575v1",
        "arxiv_id": "2602.12575v1",
        "authors": [
            "Bo Wang",
            "Yuxuan Zhang",
            "Yueqin Hu",
            "Hanchao Hou",
            "Kaiping Peng",
            "Shiguang Ni"
        ],
        "submitted": "2026-02-13 03:37:15",
        "source": "arxiv",
        "comment": "78 pages, 20 figures"
    },
    {
        "title": "CAPTS: Channel-Aware, Preference-Aligned Trigger Selection for Multi-Channel Item-to-Item Retrieval",
        "abstract": "Large-scale industrial recommender systems commonly adopt multi-channel retrieval for candidate generation, combining direct user-to-item (U2I) retrieval with two-hop user-to-item-to-item (U2I2I) pipelines. In U2I2I, the system selects a small set of historical interactions as triggers to seed downstream item-to-item (I2I) retrieval across multiple channels. In production, triggers are often selected using rule-based policies or learned scorers and tuned in a channel-by-channel manner. However, these practices face two persistent challenges: biased value attribution that values triggers by on-trigger feedback rather than their downstream utility as retrieval seeds, and uncoordinated multi-channel routing where channels select triggers independently under a shared quota, increasing cross-channel overlap. To address these challenges, we propose Channel-Aware, Preference-Aligned Trigger Selection (CAPTS), a unified and flexible framework that treats multi-channel trigger selection as a learnable routing problem. CAPTS introduces a Value Attribution Module (VAM) that provides look-ahead supervision by crediting each trigger with the subsequent engagement generated by items retrieved from it on each I2I channel, and a Channel-Adaptive Trigger Routing (CATR) module that coordinates trigger-to-channel assignment to maximize the overall value of multi-channel retrieval. Extensive offline experiments and large-scale online A/B tests on Kwai, Kuaishou's international short-video platform, show that CAPTS consistently improves multi-channel recall offline and delivers a +0.351% lift in average time spent per device online.",
        "url": "http://arxiv.org/abs/2602.12564v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12564v1",
        "arxiv_id": "2602.12564v1",
        "authors": [
            "Xiaoyou Zhou",
            "Yuqi Liu",
            "Zhao Liu",
            "Xiao Lv",
            "Bo Chen",
            "Ruiming Tang",
            "Guorui Zhou"
        ],
        "submitted": "2026-02-13 03:23:12",
        "source": "arxiv",
        "comment": "10 pages, 6 figures"
    },
    {
        "title": "Decoder-only Conformer with Modality-aware Sparse Mixtures of Experts for ASR",
        "abstract": "We present a decoder-only Conformer for automatic speech recognition (ASR) that processes speech and text in a single stack without external speech encoders or pretrained large language models (LLM). The model uses a modality-aware sparse mixture of experts (MoE): disjoint expert pools for speech and text with hard routing and top-1 selection, embedded in hybrid-causality Conformer blocks (bidirectional for speech, causal for text). Training combines CTC on speech positions with label-smoothed cross-entropy for text generation. Our 113M-parameter model consistently improves WER over a 139M AED baseline on Librispeech (2.8% vs. 3.2% test-clean; 5.6% vs. 6.0% test-other). On Common Voice 16.1 with a single multilingual model across five languages, our approach reduces average WER from 12.2% to 10.6%. To our knowledge, this is the first randomly initialized decoder-only ASR that surpasses strong AED baselines via modality-aware routing and sparse MoE, achieving better accuracy with fewer active parameters and without alignment/adaptation modules.",
        "url": "http://arxiv.org/abs/2602.12546v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12546v1",
        "arxiv_id": "2602.12546v1",
        "authors": [
            "Jaeyoung Lee",
            "Masato Mimura"
        ],
        "submitted": "2026-02-13 02:53:54",
        "source": "arxiv",
        "comment": "Accepted to ICASSP 2026"
    },
    {
        "title": "Reasoning to Rank: An End-to-End Solution for Exploiting Large Language Models for Recommendation",
        "abstract": "Recommender systems are tasked to infer users' evolving preferences and rank items aligned with their intents, which calls for in-depth reasoning beyond pattern-based scoring. Recent efforts start to leverage large language models (LLMs) for recommendation, but how to effectively optimize the model for improved recommendation utility is still under explored. In this work, we propose Reasoning to Rank, an end-to-end training framework that internalizes recommendation utility optimization into the learning of step-by-step reasoning in LLMs. To avoid position bias in LLM reasoning and enable direct optimization of the reasoning process, our framework performs reasoning at the user-item level and employs reinforcement learning for end-to-end training of the LLM. Experiments on three Amazon datasets and a large-scale industrial dataset showed consistent gains over strong conventional and LLM-based solutions. Extensive in-depth analyses validate the necessity of the key components in the proposed framework and shed lights on the future developments of this line of work.",
        "url": "http://arxiv.org/abs/2602.12530v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12530v1",
        "arxiv_id": "2602.12530v1",
        "authors": [
            "Kehan Zheng",
            "Deyao Hong",
            "Qian Li",
            "Jun Zhang",
            "Huan Yu",
            "Jie Jiang",
            "Hongning Wang"
        ],
        "submitted": "2026-02-13 02:22:48",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "DiffuRank: Effective Document Reranking with Diffusion Language Models",
        "abstract": "Recent advances in large language models (LLMs) have inspired new paradigms for document reranking. While this paradigm better exploits the reasoning and contextual understanding capabilities of LLMs, most existing LLM-based rerankers rely on autoregressive generation, which limits their efficiency and flexibility. In particular, token-by-token decoding incurs high latency, while the fixed left-to-right generation order causes early prediction errors to propagate and is difficult to revise. To address these limitations, we explore the use of diffusion language models (dLLMs) for document reranking and propose DiffuRank, a reranking framework built upon dLLMs. Unlike autoregressive models, dLLMs support more flexible decoding and generation processes that are not constrained to a left-to-right order, and enable parallel decoding, which may lead to improved efficiency and controllability. Specifically, we investigate three reranking strategies based on dLLMs: (1) a pointwise approach that uses dLLMs to estimate the relevance of each query-document pair; (2) a logit-based listwise approach that prompts dLLMs to jointly assess the relevance of multiple documents and derives ranking lists directly from model logits; and (3) a permutation-based listwise approach that adapts the canonical decoding process of dLLMs to the reranking tasks. For each approach, we design corresponding training methods to fully exploit the advantages of dLLMs. We evaluate both zero-shot and fine-tuned reranking performance on multiple benchmarks. Experimental results show that dLLMs achieve performance comparable to, and in some cases exceeding, that of autoregressive LLMs with similar model sizes. These findings demonstrate the promise of diffusion-based language models as a compelling alternative to autoregressive architectures for document reranking.",
        "url": "http://arxiv.org/abs/2602.12528v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12528v1",
        "arxiv_id": "2602.12528v1",
        "authors": [
            "Qi Liu",
            "Kun Ai",
            "Jiaxin Mao",
            "Yanzhao Zhang",
            "Mingxin Li",
            "Dingkun Long",
            "Pengjun Xie",
            "Fengbin Zhu",
            "Ji-Rong Wen"
        ],
        "submitted": "2026-02-13 02:18:14",
        "source": "arxiv",
        "comment": "The code is available at https://github.com/liuqi6777/DiffusionRank"
    },
    {
        "title": "Constraint-Rectified Training for Efficient Chain-of-Thought",
        "abstract": "Chain-of-Thought (CoT) has significantly enhanced the reasoning capabilities of Large Language Models (LLMs), especially when combined with reinforcement learning (RL) based post-training methods. While longer reasoning traces can improve answer quality and unlock abilities such as self-correction, they also incur high inference costs and often introduce redundant steps, known as overthinking. Recent research seeks to develop efficient reasoning strategies that balance reasoning length and accuracy, either through length-aware reward design or prompt-based calibration. However, these heuristic-based approaches may suffer from severe accuracy drop and be very sensitive to hyperparameters. To address these problems, we introduce CRT (Constraint-Rectified Training), a principled post-training framework based on reference-guarded constrained optimization, yielding a more stable and interpretable formulation for efficient reasoning. CRT alternates between minimizing reasoning length and rectifying accuracy only when performance falls below the reference, enabling stable and effective pruning of redundant reasoning. We further extend CRT with a two-stage training scheme that first discovers the shortest reliable reasoning patterns and then refines accuracy under a learnt length budget, preventing the re-emergence of verbose CoT. Our comprehensive evaluation shows that this framework consistently reduces token usage while maintaining answer quality at a robust and reliable level. Further analysis reveals that CRT improves reasoning efficiency not only by shortening responses but also by reducing internal language redundancy, leading to a new evaluation metric. Moreover, CRT-based training naturally yields a sequence of intermediate checkpoints that span a spectrum of explanation lengths while preserving correctness, enabling fine-grained control over reasoning verbosity without retraining.",
        "url": "http://arxiv.org/abs/2602.12526v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12526v1",
        "arxiv_id": "2602.12526v1",
        "authors": [
            "Qinhang Wu",
            "Sen Lin",
            "Ming Zhang",
            "Yingbin Liang",
            "Ness B. Shroff"
        ],
        "submitted": "2026-02-13 02:13:45",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Visual RAG Toolkit: Scaling Multi-Vector Visual Retrieval with Training-Free Pooling and Multi-Stage Search",
        "abstract": "Multi-vector visual retrievers (e.g., ColPali-style late interaction models) deliver strong accuracy, but scale poorly because each page yields thousands of vectors, making indexing and search increasingly expensive. We present Visual RAG Toolkit, a practical system for scaling visual multi-vector retrieval with training-free, model-aware pooling and multi-stage retrieval. Motivated by Matryoshka Embeddings, our method performs static spatial pooling - including a lightweight sliding-window averaging variant - over patch embeddings to produce compact tile-level and global representations for fast candidate generation, followed by exact MaxSim reranking using full multi-vector embeddings.\n  Our design yields a quadratic reduction in vector-to-vector comparisons by reducing stored vectors per page from thousands to dozens, notably without requiring post-training, adapters, or distillation. Across experiments with interaction-style models such as ColPali and ColSmol-500M, we observe that over the limited ViDoRe v2 benchmark corpus 2-stage retrieval typically preserves NDCG and Recall @ 5/10 with minimal degradation, while substantially improving throughput (approximately 4x QPS); with sensitivity mainly at very large k. The toolkit additionally provides robust preprocessing - high resolution PDF to image conversion, optional margin/empty-region cropping and token hygiene (indexing only visual tokens) - and a reproducible evaluation pipeline, enabling rapid exploration of two-, three-, and cascaded retrieval variants. By emphasizing efficiency at common cutoffs (e.g., k <= 10), the toolkit lowers hardware barriers and makes state-of-the-art visual retrieval more accessible in practice.",
        "url": "http://arxiv.org/abs/2602.12510v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12510v1",
        "arxiv_id": "2602.12510v1",
        "authors": [
            "Ara Yeroyan"
        ],
        "submitted": "2026-02-13 01:27:39",
        "source": "arxiv",
        "comment": "4 pages, 3 figures. Submitted to SIGIR 2026 Demonstrations Track. Project website: https://github.com/Ara-Yeroyan/visual-rag-toolkit"
    },
    {
        "title": "Latent Customer Segmentation and Value-Based Recommendation Leveraging a Two-Stage Model with Missing Labels",
        "abstract": "The success of businesses depends on their ability to convert consumers into loyal customers. A customer's value proposition is a primary determinant in this process, requiring a balance between affordability and long-term brand equity. Broad marketing campaigns can erode perceived brand value and reduce return on investment, while existing economic algorithms often misidentify highly engaged customers as ideal targets, leading to inefficient engagement and conversion outcomes.\n  This work introduces a two-stage multi-model architecture employing Self-Paced Loss to improve customer categorization. The first stage uses a multi-class neural network to distinguish customers influenced by campaigns, organically engaged customers, and low-engagement customers. The second stage applies a binary label correction model to identify true campaign-driven intent using a missing-label framework, refining customer segmentation during training.\n  By separating prompted engagement from organic behavior, the system enables more precise campaign targeting, reduces exposure costs, and improves conversion efficiency. A/B testing demonstrates over 100 basis points improvement in key success metrics, highlighting the effectiveness of intent-aware segmentation for value-driven marketing strategies.",
        "url": "http://arxiv.org/abs/2602.12485v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12485v1",
        "arxiv_id": "2602.12485v1",
        "authors": [
            "Keerthi Gopalakrishnan",
            "Tianning Dong",
            "Chia-Yen Ho",
            "Yokila Arora",
            "Topojoy Biswas",
            "Jason Cho",
            "Sushant Kumar",
            "Kannan Achan"
        ],
        "submitted": "2026-02-12 23:59:32",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "RBCorr: Response Bias Correction in Language Models",
        "abstract": "Language models (LMs) are known to be prone to response biases, which present as option preference biases in fixed-response questions. It is therefore imperative to develop low-cost and effective response bias correction methods to improve LM performance and enable more accurate evaluations of model abilities. Here, we propose a simple response bias correction strategy ($\\texttt{RBCorr}$) and test it on 12 open-weight language models using yes-no, entailment, and multiple choice questions. We show that response bias is prevalent in LMs pre-correction and that $\\texttt{RBCorr}$ effectively eliminates bias and boosts model performance. We also explore the generalizability of bias behavior across models, datasets, and prompt formats, showing that LogProbs-based correction is highly dependent on all three of these aspects. Overall, $\\texttt{RBCorr}$ is an easy-to-use method that can boost the performance of smaller LMs and ensure that LM performance on closed-response benchmarks aligns more closely with their true capabilities.",
        "url": "http://arxiv.org/abs/2602.12445v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12445v1",
        "arxiv_id": "2602.12445v1",
        "authors": [
            "Om Bhatt",
            "Anna A. Ivanova"
        ],
        "submitted": "2026-02-12 22:05:04",
        "source": "arxiv",
        "comment": "12 pages (8 pages main text), 4 figures"
    },
    {
        "title": "RankLLM: Weighted Ranking of LLMs by Quantifying Question Difficulty",
        "abstract": "Benchmarks establish a standardized evaluation framework to systematically assess the performance of large language models (LLMs), facilitating objective comparisons and driving advancements in the field. However, existing benchmarks fail to differentiate question difficulty, limiting their ability to effectively distinguish models' capabilities. To address this limitation, we propose RankLLM, a novel framework designed to quantify both question difficulty and model competency. RankLLM introduces difficulty as the primary criterion for differentiation, enabling a more fine-grained evaluation of LLM capabilities. RankLLM's core mechanism facilitates bidirectional score propagation between models and questions. The core intuition of RankLLM is that a model earns a competency score when it correctly answers a question, while a question's difficulty score increases when it challenges a model. Using this framework, we evaluate 30 models on 35,550 questions across multiple domains. RankLLM achieves 90% agreement with human judgments and consistently outperforms strong baselines such as IRT. It also exhibits strong stability, fast convergence, and high computational efficiency, making it a practical solution for large-scale, difficulty-aware LLM evaluation.",
        "url": "http://arxiv.org/abs/2602.12424v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12424v1",
        "arxiv_id": "2602.12424v1",
        "authors": [
            "Ziqian Zhang",
            "Xingjian Hu",
            "Yue Huang",
            "Kai Zhang",
            "Ruoxi Chen",
            "Yixin Liu",
            "Qingsong Wen",
            "Kaidi Xu",
            "Xiangliang Zhang",
            "Neil Zhenqiang Gong",
            "Lichao Sun"
        ],
        "submitted": "2026-02-12 21:28:46",
        "source": "arxiv",
        "comment": "32 pages, 9 figures. Accepted by ICLR 2026"
    },
    {
        "title": "Sparse Autoencoders are Capable LLM Jailbreak Mitigators",
        "abstract": "Jailbreak attacks remain a persistent threat to large language model safety. We propose Context-Conditioned Delta Steering (CC-Delta), an SAE-based defense that identifies jailbreak-relevant sparse features by comparing token-level representations of the same harmful request with and without jailbreak context. Using paired harmful/jailbreak prompts, CC-Delta selects features via statistical testing and applies inference-time mean-shift steering in SAE latent space. Across four aligned instruction-tuned models and twelve jailbreak attacks, CC-Delta achieves comparable or better safety-utility tradeoffs than baseline defenses operating in dense latent space. In particular, our method clearly outperforms dense mean-shift steering on all four models, and particularly against out-of-distribution attacks, showing that steering in sparse SAE feature space offers advantages over steering in dense activation space for jailbreak mitigation. Our results suggest off-the-shelf SAEs trained for interpretability can be repurposed as practical jailbreak defenses without task-specific training.",
        "url": "http://arxiv.org/abs/2602.12418v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12418v1",
        "arxiv_id": "2602.12418v1",
        "authors": [
            "Yannick Assogba",
            "Jacopo Cortellazzi",
            "Javier Abad",
            "Pau Rodriguez",
            "Xavier Suau",
            "Arno Blaas"
        ],
        "submitted": "2026-02-12 21:17:32",
        "source": "arxiv",
        "comment": "26 pages, 14 figures, 3 tables"
    },
    {
        "title": "propella-1: Multi-Property Document Annotation for LLM Data Curation at Scale",
        "abstract": "Since FineWeb-Edu, data curation for LLM pretraining has predominantly relied on single scalar quality scores produced by small classifiers. A single score conflates multiple quality dimensions, prevents flexible filtering, and offers no interpretability. We introduce propella-1, a family of small multilingual LLMs (0.6B, 1.7B, 4B parameters) that annotate text documents across 18 properties organized into six categories: core content, classification, quality and value, audience and purpose, safety and compliance, and geographic relevance. The models support 57 languages and produce structured JSON annotations conforming to a predefined schema. Evaluated against a frontier commercial LLM as a reference annotator, the 4B model achieves higher agreement than much larger general-purpose models. We release propella-annotations, a dataset of over three billion document annotations covering major pretraining corpora including data from FineWeb-2, FinePDFs, HPLT 3.0, and Nemotron-CC. Using these annotations, we present a multi-dimensional compositional analysis of widely used pretraining datasets, revealing substantial differences in quality, reasoning depth, and content composition that single-score approaches cannot capture. All model weights and annotations are released under permissive, commercial-use licenses.",
        "url": "http://arxiv.org/abs/2602.12414v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12414v1",
        "arxiv_id": "2602.12414v1",
        "authors": [
            "Maximilian Idahl",
            "Benedikt Droste",
            "Björn Plüster",
            "Jan Philipp Harries"
        ],
        "submitted": "2026-02-12 21:13:08",
        "source": "arxiv",
        "comment": "Release: https://hf.co/collections/ellamind/propella-1"
    },
    {
        "title": "Evolving Beyond Snapshots: Harmonizing Structure and Sequence via Entity State Tuning for Temporal Knowledge Graph Forecasting",
        "abstract": "Temporal knowledge graph (TKG) forecasting requires predicting future facts by jointly modeling structural dependencies within each snapshot and temporal evolution across snapshots. However, most existing methods are stateless: they recompute entity representations at each timestamp from a limited query window, leading to episodic amnesia and rapid decay of long-term dependencies. To address this limitation, we propose Entity State Tuning (EST), an encoder-agnostic framework that endows TKG forecasters with persistent and continuously evolving entity states. EST maintains a global state buffer and progressively aligns structural evidence with sequential signals via a closed-loop design. Specifically, a topology-aware state perceiver first injects entity-state priors into structural encoding. Then, a unified temporal context module aggregates the state-enhanced events with a pluggable sequence backbone. Subsequently, a dual-track evolution mechanism writes the updated context back to the global entity state memory, balancing plasticity against stability. Experiments on multiple benchmarks show that EST consistently improves diverse backbones and achieves state-of-the-art performance, highlighting the importance of state persistence for long-horizon TKG forecasting. The code is published at https://github.com/yuanwuyuan9/Evolving-Beyond-Snapshots",
        "url": "http://arxiv.org/abs/2602.12389v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12389v1",
        "arxiv_id": "2602.12389v1",
        "authors": [
            "Siyuan Li",
            "Yunjia Wu",
            "Yiyong Xiao",
            "Pingyang Huang",
            "Peize Li",
            "Ruitong Liu",
            "Yan Wen",
            "Te Sun",
            "Fangyi Pei"
        ],
        "submitted": "2026-02-12 20:33:35",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "An Industrial-Scale Sequential Recommender for LinkedIn Feed Ranking",
        "abstract": "LinkedIn Feed enables professionals worldwide to discover relevant content, build connections, and share knowledge at scale. We present Feed Sequential Recommender (Feed-SR), a transformer-based sequential ranking model for LinkedIn Feed that replaces a DCNv2-based ranker and meets strict production constraints. We detail the modeling choices, training techniques, and serving optimizations that enable deployment at LinkedIn scale. Feed-SR is currently the primary member experience on LinkedIn's Feed and shows significant improvements in member engagement (+2.10% time spent) in online A/B tests compared to the existing production model. We also describe our deployment experience with alternative sequential and LLM-based ranking architectures and why Feed-SR provided the best combination of online metrics and production efficiency.",
        "url": "http://arxiv.org/abs/2602.12354v1",
        "pdf_url": "https://arxiv.org/pdf/2602.12354v1",
        "arxiv_id": "2602.12354v1",
        "authors": [
            "Lars Hertel",
            "Gaurav Srivastava",
            "Syed Ali Naqvi",
            "Satyam Kumar",
            "Yue Zhang",
            "Borja Ocejo",
            "Benjamin Zelditch",
            "Adrian Englhardt",
            "Hailing Cheng",
            "Andy Hu",
            "Antonio Alonso",
            "Daming Li",
            "Siddharth Dangi",
            "Chen Zhu",
            "Mingzhou Zhou",
            "Wanning Li",
            "Tao Huang",
            "Fedor Borisyuk",
            "Ganesh Parameswaran",
            "Birjodh Singh Tiwana",
            "Sriram Sankar",
            "Qing Lan",
            "Julie Choi",
            "Souvik Ghosh"
        ],
        "submitted": "2026-02-12 19:27:15",
        "source": "arxiv",
        "comment": null
    }
]