# Daily Papers Report - 2025-11-06

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature

- **LLM Score**: 8
- **Keyword Score**: 11
- **Authors**: Ranul Dayarathne, Uvini Ranaweera, Upeksha Ganegoda
- **URL**: <http://arxiv.org/abs/2511.03261v1>
- **Submitted**: 2025-11-05 07:45:53
- **Comment**: 18 pages, 4 figures, 5 tables, presented at the 5th International
  Conference on Artificial Intelligence in Education Technology
- **Topic Keywords**: ranking, rag, retrieval augmented generation, retrieval, rank, search
- **Reason**: This paper is relevant to your research interests in Information Retrieval, particularly in the context of question-answering and ranking models. The use of Retrieval Augmented Generation (RAG) and Large Language Models (LLMs) aligns with your focus on deep semantic understanding and real-time relevance optimization. However, the paper's primary focus on question-answering and LLMs is somewhat tangential to your broader interests in user behavior modeling and click models.

#### Abstract
> Retrieval Augmented Generation (RAG) is emerging as a powerful technique to
enhance the capabilities of Generative AI models by reducing hallucination.
Thus, the increasing prominence of RAG alongside Large Language Models (LLMs)
has sparked interest in comparing the performance of different LLMs in
question-answering (QA) in diverse domains. This study compares the performance
of four open-source LLMs, Mistral-7b-instruct, LLaMa2-7b-chat,
Falcon-7b-instruct and Orca-mini-v3-7b, and OpenAI's trending GPT-3.5 over QA
tasks within the computer science literature leveraging RAG support. Evaluation
metrics employed in the study include accuracy and precision for binary
questions and ranking by a human expert, ranking by Google's AI model Gemini,
alongside cosine similarity for long-answer questions. GPT-3.5, when paired
with RAG, effectively answers binary and long-answer questions, reaffirming its
status as an advanced LLM. Regarding open-source LLMs, Mistral AI's
Mistral-7b-instruct paired with RAG surpasses the rest in answering both binary
and long-answer questions. However, among the open-source LLMs, Orca-mini-v3-7b
reports the shortest average latency in generating responses, whereas
LLaMa2-7b-chat by Meta reports the highest average latency. This research
underscores the fact that open-source LLMs, too, can go hand in hand with
proprietary models like GPT-3.5 with better infrastructure.

---

### 2. Discourse-Aware Scientific Paper Recommendation via QA-Style Summarization and Multi-Level Contrastive Learning

- **LLM Score**: 8
- **Keyword Score**: 10
- **Authors**: Shenghua Wang, Zhen Yin
- **URL**: <http://arxiv.org/abs/2511.03330v1>
- **Submitted**: 2025-11-05 09:55:12
- **Topic Keywords**: information retrieval, ranking, retrieval, recommend, rank
- **Reason**: This paper is highly relevant to Information Retrieval, particularly in the area of scholarly recommendation and content-based recommendation. The use of QA-style summarization and multi-level contrastive learning aligns with the user's interest in deep semantic understanding and real-time relevance optimization. However, the focus on scientific papers and scholarly recommendation is somewhat specific, limiting its generalizability to the user's broader interests in e-commerce and other domains.

#### Abstract
> The rapid growth of open-access (OA) publications has intensified the
challenge of identifying relevant scientific papers. Due to privacy constraints
and limited access to user interaction data, recent efforts have shifted toward
content-based recommendation, which relies solely on textual information.
However, existing models typically treat papers as unstructured text,
neglecting their discourse organization and thereby limiting semantic
completeness and interpretability. To address these limitations, we propose
OMRC-MR, a hierarchical framework that integrates QA-style OMRC (Objective,
Method, Result, Conclusion) summarization, multi-level contrastive learning,
and structure-aware re-ranking for scholarly recommendation. The QA-style
summarization module converts raw papers into structured and
discourse-consistent representations, while multi-level contrastive objectives
align semantic representations across metadata, section, and document levels.
The final re-ranking stage further refines retrieval precision through
contextual similarity calibration. Experiments on DBLP, S2ORC, and the newly
constructed Sci-OMRC dataset demonstrate that OMRC-MR consistently surpasses
state-of-the-art baselines, achieving up to 7.2% and 3.8% improvements in
Precision@10 and Recall@10, respectively. Additional evaluations confirm that
QA-style summarization produces more coherent and factually complete
representations. Overall, OMRC-MR provides a unified and interpretable
content-based paradigm for scientific paper recommendation, advancing
trustworthy and privacy-aware scholarly information retrieval.

---

### 3. LGM: Enhancing Large Language Models with Conceptual Meta-Relations and Iterative Retrieval

- **LLM Score**: 8
- **Keyword Score**: 4
- **Authors**: Wenchang Lei, Ping Zou, Yue Wang, Feng Sun, Lei Zhao
- **URL**: <http://arxiv.org/abs/2511.03214v1>
- **Submitted**: 2025-11-05 06:04:38
- **Comment**: 30 pages, 5 figures
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper combines concepts from Information Retrieval (IR) and Natural Language Processing (NLP), specifically addressing query understanding and semantic understanding in large language models. The proposed Language Graph Model (LGM) leverages iterative retrieval to enhance conceptual clarity, which aligns with your interests in IR and NLP. However, the focus on large language models and text generation might not be a central match to your primary focus on IR and real-time relevance optimization.

#### Abstract
> Large language models (LLMs) exhibit strong semantic understanding, yet
struggle when user instructions involve ambiguous or conceptually misaligned
terms. We propose the Language Graph Model (LGM) to enhance conceptual clarity
by extracting meta-relations-inheritance, alias, and composition-from natural
language. The model further employs a reflection mechanism to validate these
meta-relations. Leveraging a Concept Iterative Retrieval Algorithm, these
relations and related descriptions are dynamically supplied to the LLM,
improving its ability to interpret concepts and generate accurate responses.
Unlike conventional Retrieval-Augmented Generation (RAG) approaches that rely
on extended context windows, our method enables large language models to
process texts of any length without the need for truncation. Experiments on
standard benchmarks demonstrate that the LGM consistently outperforms existing
RAG baselines.

---

### 4. CLAX: Fast and Flexible Neural Click Models in JAX

- **LLM Score**: 6
- **Keyword Score**: 16
- **Authors**: Philipp Hager, Onno Zoeter, Maarten de Rijke
- **URL**: <http://arxiv.org/abs/2511.03620v1>
- **Submitted**: 2025-11-05 16:39:10
- **Topic Keywords**: ranking, ltr, rag, user behavior, click model, click, rank, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, specifically click models and ranking performance. However, it focuses on the implementation of click models using JAX, which is a more technical contribution rather than a deep semantic understanding or real-time relevance optimization.

#### Abstract
> CLAX is a JAX-based library that implements classic click models using modern
gradient-based optimization. While neural click models have emerged over the
past decade, complex click models based on probabilistic graphical models
(PGMs) have not systematically adopted gradient-based optimization, preventing
practitioners from leveraging modern deep learning frameworks while preserving
the interpretability of classic models. CLAX addresses this gap by replacing
EM-based optimization with direct gradient-based optimization in a numerically
stable manner. The framework's modular design enables the integration of any
component, from embeddings and deep networks to custom modules, into classic
click models for end-to-end optimization. We demonstrate CLAX's efficiency by
running experiments on the full Baidu-ULTR dataset comprising over a billion
user sessions in $\approx$ 2 hours on a single GPU, orders of magnitude faster
than traditional EM approaches. CLAX implements ten classic click models,
serving both industry practitioners seeking to understand user behavior and
improve ranking performance at scale and researchers developing new click
models. CLAX is available at: https://github.com/philipphager/clax

---

### 5. One Battle After Another: Probing LLMs' Limits on Multi-Turn Instruction Following with a Benchmark Evolving Framework

- **LLM Score**: 6
- **Keyword Score**: 2
- **Authors**: Qi Jia, Kaiwei Zhang, Xiujie Song, Ye Shen, Xiangyang Zhu, Guangtao Zhai
- **URL**: <http://arxiv.org/abs/2511.03508v1>
- **Submitted**: 2025-11-05 14:39:59
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and conversational applications. However, it focuses on the evaluation of large language models' ability to follow instructions, which is not directly related to your core interests in Information Retrieval and query understanding. The paper's emphasis on multi-turn instruction-following and user intent simulation is somewhat relevant to your interests in user behavior modeling, but it is not a central match.

#### Abstract
> Understanding how well large language models can follow users' instructions
throughout a dialogue spanning multiple topics is of great importance for
data-intensive conversational applications. Existing benchmarks are often
limited to a fixed number of turns, making them susceptible to saturation and
failing to account for the user's interactive experience. In this work, we
propose an extensible framework for assessing multi-turn instruction-following
ability. At its core, our framework decouples linguistic surface forms from
user intent simulation through a three-layer mechanism that tracks constraints,
instructions, and topics. This framework mimics User-LLM interaction by
enabling the dynamic construction of benchmarks with state changes and
tracebacks, terminating a conversation only when the model exhausts a simulated
user's patience. We define a suite of metrics capturing the quality of the
interaction process. Using this framework, we construct EvolIF, an evolving
instruction-following benchmark incorporating nine distinct constraint types.
Our results indicate that GPT-5 exhibits superior instruction-following
performance. It sustains an average of 18.54 conversational turns and
demonstrates 70.31% robustness, outperforming Gemini-2.5-Pro by a significant
margin of 11.41%, while other models lag far behind. All of the data and code
will be made publicly available online.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Towards Transparent Stance Detection: A Zero-Shot Approach Using Implicit and Explicit Interpretability

- **LLM Score**: 4
- **Keyword Score**: 15
- **Authors**: Apoorva Upadhyaya, Wolfgang Nejdl, Marco Fisichella
- **URL**: <http://arxiv.org/abs/2511.03635v1>
- **Submitted**: 2025-11-05 16:54:10
- **Comment**: Accepted in AAAI CONFERENCE ON WEB AND SOCIAL MEDIA (ICWSM 2026)
- **Topic Keywords**: information retrieval, ranking, relevance, rag, retrieval, rank, search
- **Reason**: The paper explores stance detection using a novel interpretable framework, IRIS, which considers stance detection as an information retrieval ranking task. While it touches on IR concepts, the primary focus is on stance detection and interpretability, which is somewhat related to your interests in query understanding and ranking models, but not a central match.

#### Abstract
> Zero-Shot Stance Detection (ZSSD) identifies the attitude of the post toward
unseen targets. Existing research using contrastive, meta-learning, or data
augmentation suffers from generalizability issues or lack of coherence between
text and target. Recent works leveraging large language models (LLMs) for ZSSD
focus either on improving unseen target-specific knowledge or generating
explanations for stance analysis. However, most of these works are limited by
their over-reliance on explicit reasoning, provide coarse explanations that
lack nuance, and do not explicitly model the reasoning process, making it
difficult to interpret the model's predictions. To address these issues, in our
study, we develop a novel interpretable ZSSD framework, IRIS. We provide an
interpretable understanding of the attitude of the input towards the target
implicitly based on sequences within the text (implicit rationales) and
explicitly based on linguistic measures (explicit rationales). IRIS considers
stance detection as an information retrieval ranking task, understanding the
relevance of implicit rationales for different stances to guide the model
towards correct predictions without requiring the ground-truth of rationales,
thus providing inherent interpretability. In addition, explicit rationales
based on communicative features help decode the emotional and cognitive
dimensions of stance, offering an interpretable understanding of the author's
attitude towards the given target. Extensive experiments on the benchmark
datasets of VAST, EZ-STANCE, P-Stance, and RFD using 50%, 30%, and even 10%
training data prove the generalizability of our model, benefiting from the
proposed architecture and interpretable design.

### 7. Cache Mechanism for Agent RAG Systems

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Shuhang Lin, Zhencan Peng, Lingyao Li, Xiao Lin, Xi Zhu, Yongfeng Zhang
- **URL**: <http://arxiv.org/abs/2511.02919v1>
- **Submitted**: 2025-11-04 19:02:29
- **Topic Keywords**: query, relevance, rag, retrieval
- **Reason**: The paper discusses a caching mechanism for Retrieval-Augmented Generation (RAG) systems, which is related to information retrieval. However, the focus is on caching and efficiency rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest. The connection to information retrieval is somewhat tangential, but the paper's emphasis on real-time relevance optimization is a partial match.

#### Abstract
> Recent advances in Large Language Model (LLM)-based agents have been
propelled by Retrieval-Augmented Generation (RAG), which grants the models
access to vast external knowledge bases. Despite RAG's success in improving
agent performance, agent-level cache management, particularly constructing,
maintaining, and updating a compact, relevant corpus dynamically tailored to
each agent's need, remains underexplored. Therefore, we introduce ARC (Agent
RAG Cache Mechanism), a novel, annotation-free caching framework that
dynamically manages small, high-value corpora for each agent. By synthesizing
historical query distribution patterns with the intrinsic geometry of cached
items in the embedding space, ARC automatically maintains a high-relevance
cache. With comprehensive experiments on three retrieval datasets, our
experimental results demonstrate that ARC reduces storage requirements to
0.015% of the original corpus while offering up to 79.8% has-answer rate and
reducing average retrieval latency by 80%. Our results demonstrate that ARC can
drastically enhance efficiency and effectiveness in RAG-powered LLM agents.

### 8. Beyond Ranked Lists: The SARAL Framework for Cross-Lingual Document Set Retrieval

- **LLM Score**: 4
- **Keyword Score**: 9
- **Authors**: Shantanu Agarwal, Joel Barry, Elizabeth Boschee, Scott Miller
- **URL**: <http://arxiv.org/abs/2511.03228v1>
- **Submitted**: 2025-11-05 06:35:33
- **Topic Keywords**: information retrieval, query, retrieval, rank
- **Reason**: The paper is somewhat related to Information Retrieval, specifically cross-lingual document set retrieval, but it does not directly focus on query understanding, ranking models, or user behavior modeling, which are core areas of interest. While it involves a novel approach to CLIR, the emphasis on retrieving a document set rather than a ranked list does not align with the user's primary focus on real-time relevance optimization and deep semantic understanding.

#### Abstract
> Machine Translation for English Retrieval of Information in Any Language
(MATERIAL) is an IARPA initiative targeted to advance the state of
cross-lingual information retrieval (CLIR). This report provides a detailed
description of Information Sciences Institute's (ISI's) Summarization and
domain-Adaptive Retrieval Across Language's (SARAL's) effort for MATERIAL.
Specifically, we outline our team's novel approach to handle CLIR with emphasis
in developing an approach amenable to retrieve a query-relevant document
\textit{set}, and not just a ranked document-list. In MATERIAL's Phase-3
evaluations, SARAL exceeded the performance of other teams in five out of six
evaluation conditions spanning three different languages (Farsi, Kazakh, and
Georgian).

### 9. Generative Sequential Recommendation via Hierarchical Behavior Modeling

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Zhefan Wang, Guokai Yan, Jinbei Yu, Siyu Gu, Jingyan Chen, Peng Jiang, Zhiqiang Guo, Min Zhang
- **URL**: <http://arxiv.org/abs/2511.03155v1>
- **Submitted**: 2025-11-05 03:27:01
- **Topic Keywords**: rag, click, recommend, commerce, e-commerce, search
- **Reason**: The paper focuses on recommender systems, leveraging auxiliary behaviors and generative recommendations, which aligns with your interests in Information Retrieval and Search technologies. However, the primary focus is on recommender systems, which is somewhat related but not a central match to your core research themes. The use of hierarchical behavior modeling and generative approaches is also somewhat relevant to your interests in query understanding and ranking models.

#### Abstract
> Recommender systems in multi-behavior domains, such as advertising and
e-commerce, aim to guide users toward high-value but inherently sparse
conversions. Leveraging auxiliary behaviors (e.g., clicks, likes, shares) is
therefore essential. Recent progress on generative recommendations has brought
new possibilities for multi-behavior sequential recommendation. However,
existing generative approaches face two significant challenges: 1) Inadequate
Sequence Modeling: capture the complex, cross-level dependencies within user
behavior sequences, and 2) Lack of Suitable Datasets: publicly available
multi-behavior recommendation datasets are almost exclusively derived from
e-commerce platforms, limiting the validation of feasibility in other domains,
while also lacking sufficient side information for semantic ID generation. To
address these issues, we propose a novel generative framework, GAMER
(Generative Augmentation and Multi-lEvel behavior modeling for Recommendation),
built upon a decoder-only backbone. GAMER introduces a cross-level interaction
layer to capture hierarchical dependencies among behaviors and a sequential
augmentation strategy that enhances robustness in training. To further advance
this direction, we collect and release ShortVideoAD, a large-scale
multi-behavior dataset from a mainstream short-video platform, which differs
fundamentally from existing e-commerce datasets and provides pretrained
semantic IDs for research on generative methods. Extensive experiments show
that GAMER consistently outperforms both discriminative and generative
baselines across multiple metrics.

### 10. ASVRI-Legal: Fine-Tuning LLMs with Retrieval Augmented Generation for Enhanced Legal Regulation

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: One Octadion, Bondan Sapta Prakoso, Nanang Yudi Setiawan, Novanto Yudistira
- **URL**: <http://arxiv.org/abs/2511.03563v1>
- **Submitted**: 2025-11-05 15:45:52
- **Comment**: 11 pages (including references), 2 figures, 4 tables, published in
  Atlantis Press (Open Access under CC BY-NC 4.0 license)
- **Topic Keywords**: rag, retrieval augmented generation, retrieval, search
- **Reason**: The paper explores fine-tuning Large Language Models (LLMs) for legal regulation, which is somewhat related to information retrieval and NLP. However, the focus on legal regulation and policymaking is not a central match to the user's interests in query understanding, ranking models, and user behavior modeling in the e-commerce domain or other areas. While the paper does involve retrieval and generation, it is more focused on the legal domain and does not directly relate to the user's core research themes.

#### Abstract
> In this study, we explore the fine-tuning of Large Language Models (LLMs) to
better support policymakers in their crucial work of understanding, analyzing,
and crafting legal regulations. To equip the model with a deep understanding of
legal texts, we curated a supervised dataset tailored to the specific needs of
the legal domain. Additionally, we integrated the Retrieval-Augmented
Generation (RAG) method, enabling the LLM to access and incorporate up-to-date
legal knowledge from external sources. This combination of fine-tuning and
RAG-based augmentation results in a tool that not only processes legal
information but actively assists policymakers in interpreting regulations and
drafting new ones that align with current needs. The results demonstrate that
this approach can significantly enhance the effectiveness of legal research and
regulation development, offering a valuable resource in the ever-evolving field
of law.

### 11. Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language Models, and Search-Based Retrieval Agents Improves Interpretable Claim Verification

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Shaghayegh Kolli, Richard Rosenbaum, Timo Cavelius, Lasse Strothe, Andrii Lata, Jana Diesner
- **URL**: <http://arxiv.org/abs/2511.03217v1>
- **Submitted**: 2025-11-05 06:10:05
- **Comment**: Paper has been accepted at 9th wiNLP workshop at EMNLP
- **Topic Keywords**: rag, retrieval, web search, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of search-based retrieval agents. However, the focus on fact-checking and knowledge graphs is not a central match to your primary interests in query understanding, ranking models, and user behavior modeling. The paper's use of large language models and web search agents is somewhat relevant, but the application is distinct from your typical research areas.

#### Abstract
> Large language models (LLMs) excel in generating fluent utterances but can
lack reliable grounding in verified information. At the same time,
knowledge-graph-based fact-checkers deliver precise and interpretable evidence,
yet suffer from limited coverage or latency. By integrating LLMs with knowledge
graphs and real-time search agents, we introduce a hybrid fact-checking
approach that leverages the individual strengths of each component. Our system
comprises three autonomous steps: 1) a Knowledge Graph (KG) Retrieval for rapid
one-hop lookups in DBpedia, 2) an LM-based classification guided by a
task-specific labeling prompt, producing outputs with internal rule-based
logic, and 3) a Web Search Agent invoked only when KG coverage is insufficient.
Our pipeline achieves an F1 score of 0.93 on the FEVER benchmark on the
Supported/Refuted split without task-specific fine-tuning. To address Not
enough information cases, we conduct a targeted reannotation study showing that
our approach frequently uncovers valid evidence for claims originally labeled
as Not Enough Information (NEI), as confirmed by both expert annotators and LLM
reviewers. With this paper, we present a modular, opensource fact-checking
pipeline with fallback strategies and generalization across datasets.

### 12. Silenced Biases: The Dark Side LLMs Learned to Refuse

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Rom Himelstein, Amit LeVi, Brit Youngmann, Yaniv Nemcovsky, Avi Mendelson
- **URL**: <http://arxiv.org/abs/2511.03369v1>
- **Submitted**: 2025-11-05 11:24:50
- **Topic Keywords**: queries, rag
- **Reason**: The paper explores fairness in large language models, which is a related topic to information retrieval, but it doesn't directly align with the user's core research themes of query understanding, ranking models, and user behavior modeling. The focus on NLP and fairness evaluation is somewhat relevant, but the paper's scope is more narrow and doesn't overlap with the user's interests in e-commerce, recommender systems, or real-time relevance optimization.

#### Abstract
> Safety-aligned large language models (LLMs) are becoming increasingly
widespread, especially in sensitive applications where fairness is essential
and biased outputs can cause significant harm. However, evaluating the fairness
of models is a complex challenge, and approaches that do so typically utilize
standard question-answer (QA) styled schemes. Such methods often overlook
deeper issues by interpreting the model's refusal responses as positive
fairness measurements, which creates a false sense of fairness. In this work,
we introduce the concept of silenced biases, which are unfair preferences
encoded within models' latent space and are effectively concealed by
safety-alignment. Previous approaches that considered similar indirect biases
often relied on prompt manipulation or handcrafted implicit queries, which
present limited scalability and risk contaminating the evaluation process with
additional biases. We propose the Silenced Bias Benchmark (SBB), which aims to
uncover these biases by employing activation steering to reduce model refusals
during QA. SBB supports easy expansion to new demographic groups and subjects,
presenting a fairness evaluation framework that encourages the future
development of fair models and tools beyond the masking effects of alignment
training. We demonstrate our approach over multiple LLMs, where our findings
expose an alarming distinction between models' direct responses and their
underlying fairness issues.

### 13. Watermarking Large Language Models in Europe: Interpreting the AI Act in Light of Technology

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Thomas Souverain
- **URL**: <http://arxiv.org/abs/2511.03641v1>
- **Submitted**: 2025-11-05 17:00:39
- **Comment**: 17 pages, 2 Tables and 2 Pictures
- **Topic Keywords**: rag, recommend, search
- **Reason**: This paper is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, as it deals with Large Language Models. However, the focus on watermarking and the European AI Act makes it less central to the user's core research themes.

#### Abstract
> To foster trustworthy Artificial Intelligence (AI) within the European Union,
the AI Act requires providers to mark and detect the outputs of their
general-purpose models. The Article 50 and Recital 133 call for marking methods
that are ''sufficiently reliable, interoperable, effective and robust''. Yet,
the rapidly evolving and heterogeneous landscape of watermarks for Large
Language Models (LLMs) makes it difficult to determine how these four standards
can be translated into concrete and measurable evaluations. Our paper addresses
this challenge, anchoring the normativity of European requirements in the
multiplicity of watermarking techniques. Introducing clear and distinct
concepts on LLM watermarking, our contribution is threefold. (1) Watermarking
Categorisation: We propose an accessible taxonomy of watermarking methods
according to the stage of the LLM lifecycle at which they are applied - before,
during, or after training, and during next-token distribution or sampling. (2)
Watermarking Evaluation: We interpret the EU AI Act's requirements by mapping
each criterion with state-of-the-art evaluations on robustness and
detectability of the watermark, and of quality of the LLM. Since
interoperability remains largely untheorised in LLM watermarking research, we
propose three normative dimensions to frame its assessment. (3) Watermarking
Comparison: We compare current watermarking methods for LLMs against the
operationalised European criteria and show that no approach yet satisfies all
four standards. Encouraged by emerging empirical tests, we recommend further
research into watermarking directly embedded within the low-level architecture
of LLMs.

### 14. Knowledge-Augmented Question Error Correction for Chinese Question Answer System with QuestionRAG

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Longpeng Qiu, Ting Li, Shuai Mao, Nan Yang, Xiaohui Yan
- **URL**: <http://arxiv.org/abs/2511.03410v1>
- **Submitted**: 2025-11-05 12:24:20
- **Comment**: EMNLP2025 Industry Track
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on question error correction using knowledge augmentation and reinforcement learning, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on question-answering systems and language models limits its direct relevance to the user's core research themes.

#### Abstract
> Input errors in question-answering (QA) systems often lead to incorrect
responses. Large language models (LLMs) struggle with this task, frequently
failing to interpret user intent (misinterpretation) or unnecessarily altering
the original question's structure (over-correction). We propose QuestionRAG, a
framework that tackles these problems. To address misinterpretation, it
enriches the input with external knowledge (e.g., search results, related
entities). To prevent over-correction, it uses reinforcement learning (RL) to
align the model's objective with precise correction, not just paraphrasing. Our
results demonstrate that knowledge augmentation is critical for understanding
faulty questions. Furthermore, RL-based alignment proves significantly more
effective than traditional supervised fine-tuning (SFT), boosting the model's
ability to follow instructions and generalize. By integrating these two
strategies, QuestionRAG unlocks the full potential of LLMs for the question
correction task.

### 15. Measuring Aleatoric and Epistemic Uncertainty in LLMs: Empirical Evaluation on ID and OOD QA Tasks

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Kevin Wang, Subre Abdoul Moktar, Jia Li, Kangshuo Li, Feng Chen
- **URL**: <http://arxiv.org/abs/2511.03166v1>
- **Submitted**: 2025-11-05 04:26:44
- **Comment**: Accepted by UDM-KDD'24
- **Topic Keywords**: rag
- **Reason**: The paper explores uncertainty estimation in Large Language Models (LLMs), which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on LLMs and uncertainty estimation is not directly aligned with the user's core research themes, and the paper's relevance to search technologies and user behavior modeling is limited.

#### Abstract
> Large Language Models (LLMs) have become increasingly pervasive, finding
applications across many industries and disciplines. Ensuring the
trustworthiness of LLM outputs is paramount, where Uncertainty Estimation (UE)
plays a key role. In this work, a comprehensive empirical study is conducted to
examine the robustness and effectiveness of diverse UE measures regarding
aleatoric and epistemic uncertainty in LLMs. It involves twelve different UE
methods and four generation quality metrics including LLMScore from LLM
criticizers to evaluate the uncertainty of LLM-generated answers in
Question-Answering (QA) tasks on both in-distribution (ID) and
out-of-distribution (OOD) datasets. Our analysis reveals that information-based
methods, which leverage token and sequence probabilities, perform exceptionally
well in ID settings due to their alignment with the model's understanding of
the data. Conversely, density-based methods and the P(True) metric exhibit
superior performance in OOD contexts, highlighting their effectiveness in
capturing the model's epistemic uncertainty. Semantic consistency methods,
which assess variability in generated answers, show reliable performance across
different datasets and generation metrics. These methods generally perform well
but may not be optimal for every situation.

### 16. From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Najrin Sultana, Md Rafi Ur Rashid, Kang Gu, Shagufta Mehnaz
- **URL**: <http://arxiv.org/abs/2511.03128v1>
- **Submitted**: 2025-11-05 02:27:56
- **Comment**: Findings of the Association for Computational Linguistics: EMNLP 2025
  (camera-ready)
- **Topic Keywords**: rag
- **Reason**: The paper is somewhat related to the user's interests in Natural Language Processing (NLP) and deep semantic understanding, but it primarily focuses on adversarial text generation and LLM robustness, which is not a central match for the user's core research themes in Information Retrieval and Search technologies.

#### Abstract
> LLMs can provide substantial zero-shot performance on diverse tasks using a
simple task prompt, eliminating the need for training or fine-tuning. However,
when applying these models to sensitive tasks, it is crucial to thoroughly
assess their robustness against adversarial inputs. In this work, we introduce
Static Deceptor (StaDec) and Dynamic Deceptor (DyDec), two innovative attack
frameworks designed to systematically generate dynamic and adaptive adversarial
examples by leveraging the understanding of the LLMs. We produce subtle and
natural-looking adversarial inputs that preserve semantic similarity to the
original text while effectively deceiving the target LLM. By utilizing an
automated, LLM-driven pipeline, we eliminate the dependence on external
heuristics. Our attacks evolve with the advancements in LLMs and demonstrate
strong transferability across models unknown to the attacker. Overall, this
work provides a systematic approach for the self-assessment of an LLM's
robustness. We release our code and data at
https://github.com/Shukti042/AdversarialExample.

### 17. ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Jing Gao, Shutiao Luo, Yumeng Liu, Yuanming Li, Hongji Zeng
- **URL**: <http://arxiv.org/abs/2511.03656v1>
- **Submitted**: 2025-11-05 17:13:14
- **Comment**: 13 pages, 6 tables, 4 figures, accepted by ICANN 2025
- **Topic Keywords**: search
- **Reason**: The paper focuses on Chinese document question-answering, which is related to NLP and query understanding, but it does not directly address ranking models or user behavior modeling. While it involves information retrieval, the context is specific to Chinese language and question-answering, making it somewhat relevant but not a central match for your research interests.

#### Abstract
> With the rapid advancement of natural language processing (NLP) technologies,
the demand for high-quality Chinese document question-answering datasets is
steadily growing. To address this issue, we present the Chinese Multi-Document
Question Answering Dataset(ChiMDQA), specifically designed for downstream
business scenarios across prevalent domains including academic, education,
finance, law, medical treatment, and news. ChiMDQA encompasses long-form
documents from six distinct fields, consisting of 6,068 rigorously curated,
high-quality question-answer (QA) pairs further classified into ten
fine-grained categories. Through meticulous document screening and a systematic
question-design methodology, the dataset guarantees both diversity and high
quality, rendering it applicable to various NLP tasks such as document
comprehension, knowledge extraction, and intelligent QA systems. Additionally,
this paper offers a comprehensive overview of the dataset's design objectives,
construction methodologies, and fine-grained evaluation system, supplying a
substantial foundation for future research and practical applications in
Chinese QA. The code and data are available at:
https://anonymous.4open.science/r/Foxit-CHiMDQA/.

### 18. A systematic review of relation extraction task since the emergence of Transformers

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Ringwald Celian, Gandon, Fabien, Faron Catherine, Michel Franck, Abi Akl Hanna
- **URL**: <http://arxiv.org/abs/2511.03610v1>
- **Submitted**: 2025-11-05 16:28:48
- **Comment**: Submited at ACM-Computing Surveys + The resulting annotated Zotero
  bibliography :
  https://www.zotero.org/groups/6070963/scilex_re_systlitreview/library +
  SciLEx software: https://github.com/Wimmics/SciLEx
- **Topic Keywords**: search
- **Reason**: The paper is somewhat related to the user's interests in Natural Language Processing (NLP) and related topics, but it focuses on relation extraction, which is not a central match with the user's primary focus on information retrieval and query understanding. The paper's emphasis on deep semantic understanding is relevant, but it does not directly address ranking models or user behavior modeling.

#### Abstract
> This article presents a systematic review of relation extraction (RE)
research since the advent of Transformer-based models. Using an automated
framework to collect and annotate publications, we analyze 34 surveys, 64
datasets, and 104 models published between 2019 and 2024. The review highlights
methodological advances, benchmark resources, and the integration of semantic
web technologies. By consolidating results across multiple dimensions, the
study identifies current trends, limitations, and open challenges, offering
researchers and practitioners a comprehensive reference for understanding the
evolution and future directions of RE.

### 19. Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Yan Cathy Hua, Paul Denny, J√∂rg Wicker, Katerina Ta≈°kova
- **URL**: <http://arxiv.org/abs/2511.03034v1>
- **Submitted**: 2025-11-04 22:11:10
- **Topic Keywords**: search
- **Reason**: This paper is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, particularly in the area of aspect-based sentiment analysis. However, the focus on domain adaptation and evaluation methods for ABSA tasks is not directly aligned with the user's primary research themes, such as query understanding, ranking models, and user behavior modeling.

#### Abstract
> Aspect-based Sentiment Analysis (ABSA) is a fine-grained opinion mining
approach that identifies and classifies opinions associated with specific
entities (aspects) or their categories within a sentence. Despite its rapid
growth and broad potential, ABSA research and resources remain concentrated in
commercial domains, leaving analytical needs unmet in high-demand yet
low-resource areas such as education and healthcare. Domain adaptation
challenges and most existing methods' reliance on resource-intensive
in-training knowledge injection further hinder progress in these areas.
Moreover, traditional evaluation methods based on exact matches are overly
rigid for ABSA tasks, penalising any boundary variations which may misrepresent
the performance of generative models. This work addresses these gaps through
three contributions: 1) We propose a novel evaluation method, Flexible Text
Similarity Matching and Optimal Bipartite Pairing (FTS-OBP), which accommodates
realistic extraction boundary variations while maintaining strong correlation
with traditional metrics and offering fine-grained diagnostics. 2) We present
the first ABSA study of small decoder-only generative language models (SLMs;
<7B parameters), examining resource lower bounds via a case study in education
review ABSA. We systematically explore data-free (in-context learning and
weight merging) and data-light fine-tuning methods, and propose a multitask
fine-tuning strategy that significantly enhances SLM performance, enabling
1.5-3.8 B models to surpass proprietary large models and approach benchmark
results with only 200-1,000 examples on a single GPU. 3) We release the first
public set of education review ABSA resources to support future research in
low-resource domains.

### 20. KScaNN: Scalable Approximate Nearest Neighbor Search on Kunpeng

- **LLM Score**: 2
- **Keyword Score**: 12
- **Authors**: Oleg Senkevich, Siyang Xu, Tianyi Jiang, Alexander Radionov, Jan Tabaszewski, Dmitriy Malyshev, Zijian Li, Daihao Xue, Licheng Yu, Weidi Zeng, Meiling Wang, Xin Yao, Siyu Huang, Gleb Neshchetkin, Qiuling Pan, Yaoyao Fu
- **URL**: <http://arxiv.org/abs/2511.03298v1>
- **Submitted**: 2025-11-05 09:01:32
- **Topic Keywords**: information retrieval, query, rag, retrieval, recommend, search
- **Reason**: This paper focuses on Approximate Nearest Neighbor Search (ANNS) on ARM architectures, which is a specific problem in the broader field of Information Retrieval. While ANNS is related to IR, the paper's focus on hardware optimization and ARM architectures makes it less relevant to the user's core research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Approximate Nearest Neighbor Search (ANNS) is a cornerstone algorithm for
information retrieval, recommendation systems, and machine learning
applications. While x86-based architectures have historically dominated this
domain, the increasing adoption of ARM-based servers in industry presents a
critical need for ANNS solutions optimized on ARM architectures. A naive port
of existing x86 ANNS algorithms to ARM platforms results in a substantial
performance deficit, failing to leverage the unique capabilities of the
underlying hardware. To address this challenge, we introduce KScaNN, a novel
ANNS algorithm co-designed for the Kunpeng 920 ARM architecture. KScaNN
embodies a holistic approach that synergizes sophisticated, data aware
algorithmic refinements with carefully-designed hardware specific
optimizations. Its core contributions include: 1) novel algorithmic techniques,
including a hybrid intra-cluster search strategy and an improved PQ residual
calculation method, which optimize the search process at a higher level; 2) an
ML-driven adaptive search module that provides adaptive, per-query tuning of
search parameters, eliminating the inefficiencies of static configurations; and
3) highly-optimized SIMD kernels for ARM that maximize hardware utilization for
the critical distance computation workloads. The experimental results
demonstrate that KScaNN not only closes the performance gap but establishes a
new standard, achieving up to a 1.63x speedup over the fastest x86-based
solution. This work provides a definitive blueprint for achieving
leadership-class performance for vector search on modern ARM architectures and
underscores

### 21. HaluMem: Evaluating Hallucinations in Memory Systems of Agents

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Ding Chen, Simin Niu, Kehang Li, Peng Liu, Xiangping Zheng, Bo Tang, Xinchi Li, Feiyu Xiong, Zhiyu Li
- **URL**: <http://arxiv.org/abs/2511.03506v1>
- **Submitted**: 2025-11-05 14:37:34
- **Topic Keywords**: rag, retrieval, search
- **Reason**: This paper focuses on memory systems and hallucinations in AI agents, which is not directly related to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on the concept of AI systems, it does not explore query understanding, ranking models, or user behavior modeling, making it only loosely relevant to your interests.

#### Abstract
> Memory systems are key components that enable AI systems such as LLMs and AI
agents to achieve long-term learning and sustained interaction. However, during
memory storage and retrieval, these systems frequently exhibit memory
hallucinations, including fabrication, errors, conflicts, and omissions.
Existing evaluations of memory hallucinations are primarily end-to-end question
answering, which makes it difficult to localize the operational stage within
the memory system where hallucinations arise. To address this, we introduce the
Hallucination in Memory Benchmark (HaluMem), the first operation level
hallucination evaluation benchmark tailored to memory systems. HaluMem defines
three evaluation tasks (memory extraction, memory updating, and memory question
answering) to comprehensively reveal hallucination behaviors across different
operational stages of interaction. To support evaluation, we construct
user-centric, multi-turn human-AI interaction datasets, HaluMem-Medium and
HaluMem-Long. Both include about 15k memory points and 3.5k multi-type
questions. The average dialogue length per user reaches 1.5k and 2.6k turns,
with context lengths exceeding 1M tokens, enabling evaluation of hallucinations
across different context scales and task complexities. Empirical studies based
on HaluMem show that existing memory systems tend to generate and accumulate
hallucinations during the extraction and updating stages, which subsequently
propagate errors to the question answering stage. Future research should focus
on developing interpretable and constrained memory operation mechanisms that
systematically suppress hallucinations and improve memory reliability.

### 22. The Curved Spacetime of Transformer Architectures

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Riccardo Di Sipio, Jairo Diaz-Rodriguez, Luis Serrano
- **URL**: <http://arxiv.org/abs/2511.03060v1>
- **Submitted**: 2025-11-04 22:58:40
- **Topic Keywords**: queries, rag
- **Reason**: This paper appears to be primarily focused on the geometric framework of Transformer architectures, drawing an analogy to General Relativity. While it involves language models, which are related to NLP, the topic does not align with the user's core research themes in Information Retrieval, query understanding, ranking models, or user behavior modeling. The paper's focus on the geometric properties of Transformer architectures seems more relevant to the field of machine learning and neural networks.

#### Abstract
> We present a geometric framework for understanding Transformer-based language
models, drawing an explicit analogy to General Relativity. Queries and keys
induce an effective metric on representation space, and attention acts as a
discrete connection that implements parallel transport of value vectors across
tokens. Stacked layers provide discrete time-slices through which token
representations evolve on this curved manifold, while backpropagation plays the
role of a least-action principle that shapes loss-minimizing trajectories in
parameter space. If this analogy is correct, token embeddings should not
traverse straight paths in feature space; instead, their layer-wise steps
should bend and reorient as interactions mediated by embedding space curvature.
To test this prediction, we design experiments that expose both the presence
and the consequences of curvature: (i) we visualize a curvature landscape for a
full paragraph, revealing how local turning angles vary across tokens and
layers; (ii) we show through simulations that excess counts of sharp/flat
angles and longer length-to-chord ratios are not explainable by dimensionality
or chance; and (iii) inspired by Einstein's eclipse experiment, we probe
deflection under controlled context edits, demonstrating measurable,
meaning-consistent bends in embedding trajectories that confirm
attention-induced curvature.

### 23. SOLVE-Med: Specialized Orchestration for Leading Vertical Experts across Medical Specialties

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Roberta Di Marino, Giovanni Dioguardi, Antonio Romano, Giuseppe Riccio, Mariano Barone, Marco Postiglione, Flora Amato, Vincenzo Moscato
- **URL**: <http://arxiv.org/abs/2511.03542v1>
- **Submitted**: 2025-11-05 15:15:35
- **Topic Keywords**: queries
- **Reason**: This paper appears to be focused on a medical question answering system, which is not directly related to the user's core research themes in Information Retrieval and Search technologies. While it involves NLP and multi-agent architecture, the context and application are quite different from the user's interests.

#### Abstract
> Medical question answering systems face deployment challenges including
hallucinations, bias, computational demands, privacy concerns, and the need for
specialized expertise across diverse domains. Here, we present SOLVE-Med, a
multi-agent architecture combining domain-specialized small language models for
complex medical queries. The system employs a Router Agent for dynamic
specialist selection, ten specialized models (1B parameters each) fine-tuned on
specific medical domains, and an Orchestrator Agent that synthesizes responses.
Evaluated on Italian medical forum data across ten specialties, SOLVE-Med
achieves superior performance with ROUGE-1 of 0.301 and BERTScore F1 of 0.697,
outperforming standalone models up to 14B parameters while enabling local
deployment. Our code is publicly available on GitHub:
https://github.com/PRAISELab-PicusLab/SOLVE-Med.

### 24. Segmentation Beyond Defaults: Asymmetrical Byte Pair Encoding for Optimal Machine Translation Performance

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Saumitra Yadav, Manish Shrivastava
- **URL**: <http://arxiv.org/abs/2511.03383v1>
- **Submitted**: 2025-11-05 11:40:16
- **Comment**: Accepted at WAT 2025
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on Machine Translation and Byte Pair Encoding, which is outside your primary research interests in Information Retrieval and Search technologies. While it involves NLP, the specific application and methodology are not directly related to your core themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> Existing Machine Translation (MT) research often suggests a single, fixed set
of hyperparameters for word segmentation models, symmetric Byte Pair Encoding
(BPE), which applies the same number of merge operations (NMO) to train
tokenizers for both source and target languages. However, we demonstrate that
this uniform approach doesn't guarantee optimal MT performance across different
language pairs and data sizes. This work investigates BPE segmentation recipes
across various data volumes and language pairs to evaluate MT system
performance. We find that utilizing asymmetric BPE, where the source and target
languages have different NMOs, significantly improves results over the
symmetric approach, especially in low-resource settings (50K, 100K, and 500K
sentence pairs). Specifically, asymmetric BPE yield statistically significant
($p<0.05$) average gains of 5.32, 4.46, and 0.7 CHRF++ on English-Hindi in
low-resource setups. We validated this trend across six additional language
pairs (English and Telugu, Shona, Norwegian, Kyrgyz, Hausa, and Inuktitut),
observing statistically significant improvement in 10 out of 12 systems
compared to symmetric BPE. Our findings indicate a high NMO for the source (4K
to 32K) and a low NMO for the target (0.5K to 2K) provides optimal results,
particularly benefiting low-resource MT.

### 25. CARMA: Comprehensive Automatically-annotated Reddit Mental Health Dataset for Arabic

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Saad Mankarious, Ayah Zirikly
- **URL**: <http://arxiv.org/abs/2511.03102v1>
- **Submitted**: 2025-11-05 01:17:43
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on a dataset for mental health detection in Arabic, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves text analysis and classification, the context and application are quite different from the user's interests.

#### Abstract
> Mental health disorders affect millions worldwide, yet early detection
remains a major challenge, particularly for Arabic-speaking populations where
resources are limited and mental health discourse is often discouraged due to
cultural stigma. While substantial research has focused on English-language
mental health detection, Arabic remains significantly underexplored, partly due
to the scarcity of annotated datasets. We present CARMA, the first
automatically annotated large-scale dataset of Arabic Reddit posts. The dataset
encompasses six mental health conditions, such as Anxiety, Autism, and
Depression, and a control group. CARMA surpasses existing resources in both
scale and diversity. We conduct qualitative and quantitative analyses of
lexical and semantic differences between users, providing insights into the
linguistic markers of specific mental health conditions. To demonstrate the
dataset's potential for further mental health analysis, we perform
classification experiments using a range of models, from shallow classifiers to
large language models. Our results highlight the promise of advancing mental
health detection in underrepresented languages such as Arabic.

### 26. PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Michel Wong, Ali Alshehri, Sophia Kao, Haotian He
- **URL**: <http://arxiv.org/abs/2511.03080v1>
- **Submitted**: 2025-11-05 00:06:35
- **Comment**: 9 pages including appendix. EMNLP 2025 Industry Track
- **Topic Keywords**: rag, search
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves text processing, its focus on Text-to-Speech systems and text normalization is not a central match for your areas of expertise.

#### Abstract
> Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS)
systems, converting written forms into their canonical spoken equivalents.
Traditional TN systems can exhibit high accuracy, but involve substantial
engineering effort, are difficult to scale, and pose challenges to language
coverage, particularly in low-resource settings. We propose PolyNorm, a
prompt-based approach to TN using Large Language Models (LLMs), aiming to
reduce the reliance on manually crafted rules and enable broader linguistic
applicability with minimal human intervention. Additionally, we present a
language-agnostic pipeline for automatic data curation and evaluation, designed
to facilitate scalable experimentation across diverse languages. Experiments
across eight languages show consistent reductions in the word error rate (WER)
compared to a production-grade-based system. To support further research, we
release PolyNorm-Benchmark, a multilingual data set covering a diverse range of
text normalization phenomena.

### 27. No-Human in the Loop: Agentic Evaluation at Scale for Recommendation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Tao Zhang, Kehui Yao, Luyi Ma, Jiao Chen, Reza Yousefi Maragheh, Kai Zhao, Jianpeng Xu, Evren Korpeoglu, Sushant Kumar, Kannan Achan
- **URL**: <http://arxiv.org/abs/2511.03051v1>
- **Submitted**: 2025-11-04 22:49:39
- **Comment**: 4 page, NeurIPS 2025 Workshop: Evaluating the Evolving LLM Lifecycle
- **Topic Keywords**: ctr, recommend
- **Reason**: This paper focuses on evaluating large language models for recommendation systems, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the paper's primary focus on recommender systems and large language models is not a central match for your research interests, which are more focused on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Evaluating large language models (LLMs) as judges is increasingly critical
for building scalable and trustworthy evaluation pipelines. We present
ScalingEval, a large-scale benchmarking study that systematically compares 36
LLMs, including GPT, Gemini, Claude, and Llama, across multiple product
categories using a consensus-driven evaluation protocol. Our multi-agent
framework aggregates pattern audits and issue codes into ground-truth labels
via scalable majority voting, enabling reproducible comparison of LLM
evaluators without human annotation. Applied to large-scale complementary-item
recommendation, the benchmark reports four key findings: (i) Anthropic Claude
3.5 Sonnet achieves the highest decision confidence; (ii) Gemini 1.5 Pro offers
the best overall performance across categories; (iii) GPT-4o provides the most
favorable latency-accuracy-cost tradeoff; and (iv) GPT-OSS 20B leads among
open-source models. Category-level analysis shows strong consensus in
structured domains (Electronics, Sports) but persistent disagreement in
lifestyle categories (Clothing, Food). These results establish ScalingEval as a
reproducible benchmark and evaluation protocol for LLMs as judges, with
actionable guidance on scaling, reliability, and model family tradeoffs.

### 28. ROBoto2: An Interactive System and Dataset for LLM-assisted Clinical Trial Risk of Bias Assessment

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Anthony Hevia, Sanjana Chintalapati, Veronica Ka Wai Lai, Thanh Tam Nguyen, Wai-Tat Wong, Terry Klassen, Lucy Lu Wang
- **URL**: <http://arxiv.org/abs/2511.03048v1>
- **Submitted**: 2025-11-04 22:45:06
- **Comment**: EMNLP 2025 System Demonstration
- **Topic Keywords**: retrieval, search
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves large language models, the focus is on clinical trial risk of bias assessment, which is not a central theme in your research.

#### Abstract
> We present ROBOTO2, an open-source, web-based platform for large language
model (LLM)-assisted risk of bias (ROB) assessment of clinical trials. ROBOTO2
streamlines the traditionally labor-intensive ROB v2 (ROB2) annotation process
via an interactive interface that combines PDF parsing, retrieval-augmented LLM
prompting, and human-in-the-loop review. Users can upload clinical trial
reports, receive preliminary answers and supporting evidence for ROB2 signaling
questions, and provide real-time feedback or corrections to system suggestions.
ROBOTO2 is publicly available at https://roboto2.vercel.app/, with code and
data released to foster reproducibility and adoption. We construct and release
a dataset of 521 pediatric clinical trial reports (8954 signaling questions
with 1202 evidence passages), annotated using both manually and LLM-assisted
methods, serving as a benchmark and enabling future research. Using this
dataset, we benchmark ROB2 performance for 4 LLMs and provide an analysis into
current model capabilities and ongoing challenges in automating this critical
aspect of systematic review.

### 29. LiveTradeBench: Seeking Real-World Alpha with Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Haofei Yu, Fenghai Li, Jiaxuan You
- **URL**: <http://arxiv.org/abs/2511.03628v1>
- **Submitted**: 2025-11-05 16:47:26
- **Comment**: 16 pages
- **Topic Keywords**: rag
- **Reason**: The paper focuses on evaluating large language models in a live trading environment, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves sequential decision making, the context is financial trading rather than information retrieval or search.

#### Abstract
> Large language models (LLMs) achieve strong performance across
benchmarks--from knowledge quizzes and math reasoning to web-agent tasks--but
these tests occur in static settings, lacking real dynamics and uncertainty.
Consequently, they evaluate isolated reasoning or problem-solving rather than
decision-making under uncertainty. To address this, we introduce
LiveTradeBench, a live trading environment for evaluating LLM agents in
realistic and evolving markets. LiveTradeBench follows three design principles:
(i) Live data streaming of market prices and news, eliminating dependence on
offline backtesting and preventing information leakage while capturing
real-time uncertainty; (ii) a portfolio-management abstraction that extends
control from single-asset actions to multi-asset allocation, integrating risk
management and cross-asset reasoning; and (iii) multi-market evaluation across
structurally distinct environments--U.S. stocks and Polymarket prediction
markets--differing in volatility, liquidity, and information flow. At each
step, an agent observes prices, news, and its portfolio, then outputs
percentage allocations that balance risk and return. Using LiveTradeBench, we
run 50-day live evaluations of 21 LLMs across families. Results show that (1)
high LMArena scores do not imply superior trading outcomes; (2) models display
distinct portfolio styles reflecting risk appetite and reasoning dynamics; and
(3) some LLMs effectively leverage live signals to adapt decisions. These
findings expose a gap between static evaluation and real-world competence,
motivating benchmarks that test sequential decision making and consistency
under live uncertainty.

### 30. AILA--First Experiments with Localist Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Joachim Diederich
- **URL**: <http://arxiv.org/abs/2511.03559v1>
- **Submitted**: 2025-11-05 15:43:54
- **Topic Keywords**: ctr
- **Reason**: This paper focuses on localist language models, which is a topic in Natural Language Processing (NLP), but it does not directly relate to the user's core research themes in Information Retrieval (IR) and Search technologies, such as query understanding, ranking models, and user behavior modeling.

#### Abstract
> This paper presents the first empirical demonstration of controllable
locality in transformer language models, a novel architectural framework that
enables continuous control over the degree of representation localization
through a tunable locality dial parameter. Unlike traditional language models
that rely exclusively on distributed representations, our approach allows
dynamic interpolation between highly interpretable localist encodings and
efficient distributed representations without requiring model retraining. We
conducted experiments on the WikiText corpus using a two-layer transformer
architecture, systematically varying the locality parameter {\lambda} across
the full spectrum from 1.0 (fully localist) to 0.0 (fully distributed). Our
results demonstrate that localist configurations achieve dramatically lower
attention entropy, with {\lambda} = 1.0 yielding 5.36 bits compared to 7.18
bits at {\lambda} = 0.0, while maintaining substantially higher pointer
fidelity scores reflecting stronger alignment with rule-specified targets.
Prediction experiments reveal that intermediate locality values optimize the
tradeoff between interpretability and performance, with {\lambda} = 0.6
achieving test perplexity of 4.65 and accuracy of 84.7%. These findings
establish that localist language models provide a practical framework for
applications in regulated domains requiring both transparency and capability,
offering precise mathematical control over the interpretability-performance
spectrum through explicit penalty thresholds and information-theoretic design
principles.

### 31. Kastor: Fine-tuned Small Language Models for Shape-based Active Relation Extraction

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ringwald Celian, Gandon Fabien, Faron Catherine, Michel Franck, Abi Akl Hanna
- **URL**: <http://arxiv.org/abs/2511.03466v1>
- **Submitted**: 2025-11-05 13:43:47
- **Comment**: Accepted at ESWC 2025
- **Topic Keywords**: acl
- **Reason**: Although the paper discusses fine-tuning language models, it focuses on relation extraction and knowledge base refinement, which is somewhat related to information retrieval but not directly aligned with the user's core research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> RDF pattern-based extraction is a compelling approach for fine-tuning small
language models (SLMs) by focusing a relation extraction task on a specified
SHACL shape. This technique enables the development of efficient models trained
on limited text and RDF data. In this article, we introduce Kastor, a framework
that advances this approach to meet the demands for completing and refining
knowledge bases in specialized domains. Kastor reformulates the traditional
validation task, shifting from single SHACL shape validation to evaluating all
possible combinations of properties derived from the shape. By selecting the
optimal combination for each training example, the framework significantly
enhances model generalization and performance. Additionally, Kastor employs an
iterative learning process to refine noisy knowledge bases, enabling the
creation of robust models capable of uncovering new, relevant facts

### 32. Efficient Reasoning via Thought-Training and Thought-Free Inference

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Canhui Wu, Qiong Cao, Chao Xue, Wei Xi, Xiaodong He
- **URL**: <http://arxiv.org/abs/2511.03408v1>
- **Submitted**: 2025-11-05 12:20:45
- **Comment**: 11 pages, 4 figures
- **Topic Keywords**: rag
- **Reason**: This paper focuses on improving the efficiency of large language models through a framework called 3TF, which enables implicit reasoning without explicit step-by-step generation. While it relates to Natural Language Processing (NLP), it doesn't directly align with your core research interests in Information Retrieval (IR), query understanding, ranking models, or user behavior modeling.

#### Abstract
> Recent advances in large language models (LLMs) have leveraged explicit
Chain-of-Thought (CoT) prompting to improve reasoning accuracy. However, most
existing methods primarily compress verbose reasoning outputs. These
Long-to-Short transformations aim to improve efficiency, but still rely on
explicit reasoning during inference. In this work, we introduce \textbf{3TF}
(\textbf{T}hought-\textbf{T}raining and \textbf{T}hought-\textbf{F}ree
inference), a framework for efficient reasoning that takes a Short-to-Long
perspective. We first train a hybrid model that can operate in both reasoning
and non-reasoning modes, and then further train it on CoT-annotated data to
internalize structured reasoning, while enforcing concise, thought-free outputs
at inference time using the no-reasoning mode. Unlike compression-based
approaches, 3TF improves the reasoning quality of non-reasoning outputs,
enabling models to perform rich internal reasoning implicitly while keeping
external outputs short. Empirically, 3TF-trained models obtain large
improvements on reasoning benchmarks under thought-free inference,
demonstrating that high quality reasoning can be learned and executed
implicitly without explicit step-by-step generation.

### 33. Overcoming the Generalization Limits of SLM Finetuning for Shape-Based Extraction of Datatype and Object Properties

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: C√©lian Ringwald, Fabien Gandon, Catherine Faron, Franck Michel, Hanna Abi Akl
- **URL**: <http://arxiv.org/abs/2511.03407v1>
- **Submitted**: 2025-11-05 12:16:51
- **Comment**: Accepted at KCAP 2025
- **Topic Keywords**: acl
- **Reason**: This paper focuses on relation extraction and small language models, which is somewhat related to information retrieval, but it's not directly aligned with your core research themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> Small language models (SLMs) have shown promises for relation extraction (RE)
when extracting RDF triples guided by SHACL shapes focused on common datatype
properties. This paper investigates how SLMs handle both datatype and object
properties for a complete RDF graph extraction. We show that the key bottleneck
is related to long-tail distribution of rare properties. To solve this issue,
we evaluate several strategies: stratified sampling, weighted loss, dataset
scaling, and template-based synthetic data augmentation. We show that the best
strategy to perform equally well over unbalanced target properties is to build
a training set where the number of occurrences of each property exceeds a given
threshold. To enable reproducibility, we publicly released our datasets,
experimental results and code. Our findings offer practical guidance for
training shape-aware SLMs and highlight promising directions for future work in
semantic RE.

### 34. IndicSuperTokenizer: An Optimized Tokenizer for Indic Multilingual LLMs

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Souvik Rana, Arul Menezes, Ashish Kulkarni, Chandra Khatri, Shubham Agarwal
- **URL**: <http://arxiv.org/abs/2511.03237v1>
- **Submitted**: 2025-11-05 06:57:42
- **Topic Keywords**: rag
- **Reason**: This paper focuses on developing a tokenizer for Indic multilingual Large Language Models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, it is more specific to tokenizer design and multilingual language models, which does not align with your primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Tokenizers play a crucial role in determining the performance, training
efficiency, and the inference cost of Large Language Models (LLMs). Designing
effective tokenizers for multilingual LLMs is particularly challenging due to
diverse scripts and rich morphological variation. While subword methods such as
Byte Pair Encoding (BPE) are widely adopted, their effectiveness in
multilingual settings remains underexplored. We present IndicSuperTokenizer, a
tokenizer for Indic multilingual LLMs, that combines both subword and
multi-word tokenization, along with language-specific pre-tokenization, leading
to more linguistically aligned tokens and achieving a new state-of-the-art in
fertility score. Evaluated across English, 22 Indian languages and code data,
our tokenizer improves the average fertility score by 39.5% over LLaMA4 and by
18% over Sutra (the current best). This translates to 44% improvement in
inference throughput over LLaMA4 while maintaining comparable performance on
English and Indic benchmarks. We also present detailed ablations across
tokenizer training data size, vocabulary size, merging techniques, and
pre-tokenization strategies, demonstrating the robustness of our design
choices.

### 35. MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Kaiyuan Zhang, Chenghao Yang, Zhoufutu Wen, Sihang Yuan, Qiuyue Wang, Chaoyi Huang, Guosheng Zhu, He Wang, Huawenyu Lu, Jianing Wen, Jianpeng Jiao, Lishu Luo, Longxiang Liu, Sijin Wu, Xiaolei Zhu, Xuanliang Zhang, Ge Zhang, Yi Lin, Guang Shi, Chaoyou Fu, Wenhao Huang
- **URL**: <http://arxiv.org/abs/2511.03146v1>
- **Submitted**: 2025-11-05 03:09:16
- **Topic Keywords**: rag
- **Reason**: This paper focuses on multimodal evaluation benchmarks for cognitive capacity in Large Language Models (LLMMs), which is not directly related to your primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on aspects of model evaluation, it lacks relevance to your core areas of query understanding, ranking models, and user behavior modeling.

#### Abstract
> As reasoning models scale rapidly, the essential role of multimodality in
human cognition has come into sharp relief, driving a growing need to probe
vision-centric cognitive behaviors. Yet, existing multimodal benchmarks either
overemphasize textual reasoning or fall short of systematically capturing
vision-centric cognitive behaviors, leaving the cognitive capacity of MLLMs
insufficiently assessed. To address this limitation, we introduce MME-CC
(Multi-Modal Evaluation benchmark of Cognitive Capacity), a vision-grounded
benchmark that organizes 11 representative reasoning tasks into three
fundamental categories of visual information: spatial, geometric, and
knowledge-based reasoning, and provides fine-grained analyses of MLLMs'
cognitive capacity across these dimensions. Based on MME-CC, we conduct
extensive experiments over 16 representative MLLMs. Our study reveals that
closed-source models currently lead overall (e.g., 42.66 for Gemini-2.5-Pro vs.
30.45 for GLM-4.5V), while spatial and geometric reasoning remain broadly weak
(less than or equal to 30%). We further identify common error patterns,
including orientation mistakes, fragile cross-view identity persistence, and
poor adherence to counterfactual instructions, and observe that
Chain-of-Thought typically follows a three-stage process (extract -> reason ->
verify) with heavy reliance on visual extraction. We hope this work catalyzes a
shift toward treating the cognitive capacity of MLLMs as central to both
evaluation and model design.

### 36. From Measurement to Expertise: Empathetic Expert Adapters for Context-Based Empathy in Conversational AI Agents

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Erfan Shayegani, Jina Suh, Andy Wilson, Nagu Rangan, Javier Hernandez
- **URL**: <http://arxiv.org/abs/2511.03143v1>
- **Submitted**: 2025-11-05 03:07:27
- **Topic Keywords**: rag
- **Reason**: This paper appears to be focused on developing empathetic conversational AI agents, which is outside the primary scope of information retrieval and search technologies. While it involves natural language processing, the context and application are not directly related to the user's core research themes.

#### Abstract
> Empathy is a critical factor in fostering positive user experiences in
conversational AI. While models can display empathy, it is often generic rather
than tailored to specific tasks and contexts. In this work, we introduce a
novel framework for developing and evaluating context-specific empathetic large
language models (LLMs). We first analyze a real-world conversational dataset
consisting of 672 multi-turn conversations across 8 tasks, revealing
significant differences in terms of expected and experienced empathy before and
after the conversations, respectively. To help minimize this gap, we develop a
synthetic multi-turn conversational generation pipeline and steer responses
toward our defined empathy patterns based on the context that more closely
matches users' expectations. We then train empathetic expert adapters for
context-specific empathy that specialize in varying empathy levels based on the
recognized task. Our empirical results demonstrate a significant gap reduction
of 72.66% between perceived and desired empathy with scores increasing by an
average factor of 2.43 as measured by our metrics and reward models.
Additionally, our trained empathetic expert adapters demonstrate superior
effectiveness in preserving empathy patterns throughout conversation turns,
outperforming system prompts, which tend to dramatically diminish in impact as
conversations lengthen.

### 37. Control Barrier Function for Aligning Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yuya Miyaoka, Masaki Inoue
- **URL**: <http://arxiv.org/abs/2511.03121v2>
- **Submitted**: 2025-11-05 02:12:59
- **Comment**: This work is an extenede version of arXiv:2408.15625 and has been
  submitted to the IEEE for possible publication
- **Topic Keywords**: rag
- **Reason**: This paper focuses on aligning large language models for text generation, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves natural language processing, it's more aligned with language generation and control systems, making it less relevant to the user's core research interests.

#### Abstract
> This paper proposes a control-based framework for aligning large language
models (LLMs) by leveraging a control barrier function (CBF) to ensure
user-desirable text generation. The presented framework applies the CBF safety
filter to the predicted token generated from the baseline LLM, to intervene in
the generated text. The safety filter includes two significant advantages: this
safety filter is an add-on type, allowing it to be used for alignment purposes
without fine-tuning the baseline LLM, and if there is an evaluation model
regarding the desired alignment, it can be directly applied to the filter
design. The overall text-generation system is implemented with open-source
language models, aiming to generate positive text.

### 38. Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Francesco Corso, Francesco Pierri, Gianmarco De Francisci Morales
- **URL**: <http://arxiv.org/abs/2511.03699v1>
- **Submitted**: 2025-11-05 18:28:28
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The focus on Large Language Models and conspiracy mindset is outside your primary areas of interest.

#### Abstract
> In this paper, we investigate whether Large Language Models (LLMs) exhibit
conspiratorial tendencies, whether they display sociodemographic biases in this
domain, and how easily they can be conditioned into adopting conspiratorial
perspectives. Conspiracy beliefs play a central role in the spread of
misinformation and in shaping distrust toward institutions, making them a
critical testbed for evaluating the social fidelity of LLMs. LLMs are
increasingly used as proxies for studying human behavior, yet little is known
about whether they reproduce higher-order psychological constructs such as a
conspiratorial mindset. To bridge this research gap, we administer validated
psychometric surveys measuring conspiracy mindset to multiple models under
different prompting and conditioning strategies. Our findings reveal that LLMs
show partial agreement with elements of conspiracy belief, and conditioning
with socio-demographic attributes produces uneven effects, exposing latent
demographic biases. Moreover, targeted prompts can easily shift model responses
toward conspiratorial directions, underscoring both the susceptibility of LLMs
to manipulation and the potential risks of their deployment in sensitive
contexts. These results highlight the importance of critically evaluating the
psychological dimensions embedded in LLMs, both to advance computational social
science and to inform possible mitigation strategies against harmful uses.

### 39. Beyond Citations: Measuring Idea-level Knowledge Diffusion from Research to Journalism and Policy-making

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yangliu Fan, Kilian Buehling, Volker Stocker
- **URL**: <http://arxiv.org/abs/2511.03378v1>
- **Submitted**: 2025-11-05 11:34:34
- **Topic Keywords**: search
- **Reason**: This paper focuses on measuring knowledge diffusion from research to other domains, using a novel text-based approach. While it touches on the idea of information diffusion, it does not directly relate to information retrieval, search technologies, or query understanding, which are core areas of your research interests.

#### Abstract
> Despite the importance of social science knowledge for various stakeholders,
measuring its diffusion into different domains remains a challenge. This study
uses a novel text-based approach to measure the idea-level diffusion of social
science knowledge from the research domain to the journalism and policy-making
domains. By doing so, we expand the detection of knowledge diffusion beyond the
measurements of direct references. Our study focuses on media effects theories
as key research ideas in the field of communication science. Using 72,703
documents (2000-2019) from three domains (i.e., research, journalism, and
policy-making) that mention these ideas, we count the mentions of these ideas
in each domain, estimate their domain-specific contexts, and track and compare
differences across domains and over time. Overall, we find that diffusion
patterns and dynamics vary considerably between ideas, with some ideas
diffusing between other domains, while others do not. Based on the embedding
regression approach, we compare contextualized meanings across domains and find
that the distances between research and policy are typically larger than
between research and journalism. We also find that ideas largely shift roles
across domains - from being the theories themselves in research to sense-making
in news to applied, administrative use in policy. Over time, we observe
semantic convergence mainly for ideas that are practically oriented. Our
results characterize the cross-domain diffusion patterns and dynamics of social
science knowledge at the idea level, and we discuss the implications for
measuring knowledge diffusion beyond citations.

### 40. LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced Logical Reasoning

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Shenghao Li
- **URL**: <http://arxiv.org/abs/2511.03372v1>
- **Submitted**: 2025-11-05 11:26:38
- **Comment**: 10 pages, 6 figures
- **Topic Keywords**: search
- **Reason**: This paper focuses on logical data augmentation for logical reasoning, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language models, the context is more aligned with formal logic and data augmentation rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> For complex logical data augmentation, heavy reliance on human annotation is
costly, whereas direct generation with large language models yields
uninterpretable and logically homogeneous examples. To address this, we present
LFC-DA, a symbolic-logic-controlled pipeline: logical text is first mapped to
propositional expressions, a compact rule library is compiled, and a bounded
state-space search systematically discovers valid formulas that are then
verbalized back into natural-language questions, ensuring both diversity and
logical rigor under propositional logic. Experiments on ReClor and LogiQA show
significant improvements in the logical-reasoning accuracy of pretrained
models, confirming the effectiveness of LFC-DA for LLM-guided logical data
augmentation.

### 41. Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Riasad Alvi, Sayeem Been Zaman, Wasimul Karim, Arefin Ittesafun Abian, Mohaimenul Azam Khan Raiaan, Saddam Mukta, Md Rafi Ur Rashid, Md Rafiqul Islam, Yakub Sebastian, Sami Azam
- **URL**: <http://arxiv.org/abs/2511.03354v1>
- **Submitted**: 2025-11-05 10:48:36
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests as it focuses on Generative Artificial Intelligence in Bioinformatics, which is outside your primary areas of interest in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Generative artificial intelligence (GenAI) has become a transformative
approach in bioinformatics that often enables advancements in genomics,
proteomics, transcriptomics, structural biology, and drug discovery. To
systematically identify and evaluate these growing developments, this review
proposed six research questions (RQs), according to the preferred reporting
items for systematic reviews and meta-analysis methods. The objective is to
evaluate impactful GenAI strategies in methodological advancement, predictive
performance, and specialization, and to identify promising approaches for
advanced modeling, data-intensive discovery, and integrative biological
analysis. RQ1 highlights diverse applications across multiple bioinformatics
subfields (sequence analysis, molecular design, and integrative data modeling),
which demonstrate superior performance over traditional methods through pattern
recognition and output generation. RQ2 reveals that adapted specialized model
architectures outperformed general-purpose models, an advantage attributed to
targeted pretraining and context-aware strategies. RQ3 identifies significant
benefits in the bioinformatics domains, focusing on molecular analysis and data
integration, which improves accuracy and reduces errors in complex analysis.
RQ4 indicates improvements in structural modeling, functional prediction, and
synthetic data generation, validated by established benchmarks. RQ5 suggests
the main constraints, such as the lack of scalability and biases in data that
impact generalizability, and proposes future directions focused on robust
evaluation and biologically grounded modeling. RQ6 examines that molecular
datasets (such as UniProtKB and ProteinNet12), cellular datasets (such as
CELLxGENE and GTEx) and textual resources (such as PubMedQA and OMIM) broadly
support the training and generalization of GenAI models.

### 42. Benchmarking the Thinking Mode of Multimodal Large Language Models in Clinical Tasks

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jindong Hong, Tianjie Chen, Lingjie Luo, Chuanyang Zheng, Ting Xu, Haibao Yu, Jianing Qiu, Qianzhong Chen, Suning Huang, Yan Xu, Yong Gui, Yijun He, Jiankai Sun
- **URL**: <http://arxiv.org/abs/2511.03328v1>
- **Submitted**: 2025-11-05 09:47:15
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests as it focuses on Multimodal Large Language Models in clinical tasks, which is outside your primary area of Information Retrieval and Search technologies. Although it involves NLP, the specific application and methodology do not align with your core themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> A recent advancement in Multimodal Large Language Models (MLLMs) research is
the emergence of "reasoning MLLMs" that offer explicit control over their
internal thinking processes (normally referred as the "thinking mode")
alongside the standard "non-thinking mode". This capability allows these models
to engage in a step-by-step process of internal deliberation before generating
a final response. With the rapid transition to and adoption of these
"dual-state" MLLMs, this work rigorously evaluated how the enhanced reasoning
processes of these MLLMs impact model performance and reliability in clinical
tasks. This paper evaluates the active "thinking mode" capabilities of two
leading MLLMs, Seed1.5-VL and Gemini-2.5-Flash, for medical applications. We
assessed their performance on four visual medical tasks using VQA-RAD and
ROCOv2 datasets. Our findings reveal that the improvement from activating the
thinking mode remains marginal compared to the standard non-thinking mode for
the majority of the tasks. Their performance on complex medical tasks such as
open-ended VQA and medical image interpretation remains suboptimal,
highlighting the need for domain-specific medical data and more advanced
methods for medical knowledge integration.

### 43. SCALE: Upscaled Continual Learning of Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jin-woo Lee, Junhwa Choi, Bongkyu Hwang, Jinho Choo, Bogun Kim, JeongSeon Yi, Joonseok Lee, DongYoung Jung, Jaeseon Park, Kyoungwon Park, Suk-hoon Jung
- **URL**: <http://arxiv.org/abs/2511.03270v1>
- **Submitted**: 2025-11-05 08:05:50
- **Topic Keywords**: korea
- **Reason**: This paper focuses on large language models and continual learning, which is not directly related to your primary research interests in Information Retrieval and Search technologies. While it touches on scaling and optimization, the context is specific to NLP and not aligned with your background in e-commerce or interests in query understanding and ranking models.

#### Abstract
> We revisit continual pre-training for large language models and argue that
progress now depends more on scaling the right structure than on scaling
parameters alone. We introduce SCALE, a width upscaling architecture that
inserts lightweight expansion into linear modules while freezing all
pre-trained parameters. This preserves the residual and attention topologies
and increases capacity without perturbing the base model's original
functionality. SCALE is guided by two principles: Persistent Preservation,
which maintains the base model's behavior via preservation-oriented
initialization and freezing of the pre-trained weights, and Collaborative
Adaptation, which selectively trains a subset of expansion components to
acquire new knowledge with minimal interference. We instantiate these ideas as
SCALE-Preserve (preservation-first), SCALE-Adapt (adaptation-first), and
SCALE-Route, an optional routing extension that performs token-level routing
between preservation and adaptation heads. On a controlled synthetic biography
benchmark, SCALE mitigates the severe forgetting observed with depth expansion
while still acquiring new knowledge. In continual pre-training on a Korean
corpus, SCALE variants achieve less forgetting on English evaluations and
competitive gains on Korean benchmarks, with these variants offering the best
overall stability-plasticity trade-off. Accompanying analysis clarifies when
preservation provably holds and why the interplay between preservation and
adaptation stabilizes optimization compared to standard continual learning
setups.

### 44. BengaliMoralBench: A Benchmark for Auditing Moral Reasoning in Large Language Models within Bengali Language and Culture

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Shahriyar Zaman Ridoy, Azmine Toushik Wasi, Koushik Ahamed Tonmoy
- **URL**: <http://arxiv.org/abs/2511.03180v1>
- **Submitted**: 2025-11-05 04:55:35
- **Comment**: This manuscript is a preprint currently under review
- **Topic Keywords**: rank
- **Reason**: This paper focuses on auditing moral reasoning in Large Language Models within the Bengali language and culture, which is not directly related to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the primary focus is on ethics and cultural nuances, which does not align with your core research themes.

#### Abstract
> As multilingual Large Language Models (LLMs) gain traction across South Asia,
their alignment with local ethical norms, particularly for Bengali, which is
spoken by over 285 million people and ranked 6th globally, remains
underexplored. Existing ethics benchmarks are largely English-centric and
shaped by Western frameworks, overlooking cultural nuances critical for
real-world deployment. To address this, we introduce BengaliMoralBench, the
first large-scale ethics benchmark for the Bengali language and socio-cultural
contexts. It covers five moral domains, Daily Activities, Habits, Parenting,
Family Relationships, and Religious Activities, subdivided into 50 culturally
relevant subtopics. Each scenario is annotated via native-speaker consensus
using three ethical lenses: Virtue, Commonsense, and Justice ethics. We conduct
systematic zero-shot evaluation of prominent multilingual LLMs, including
Llama, Gemma, Qwen, and DeepSeek, using a unified prompting protocol and
standard metrics. Performance varies widely (50-91% accuracy), with qualitative
analysis revealing consistent weaknesses in cultural grounding, commonsense
reasoning, and moral fairness. BengaliMoralBench provides a foundation for
responsible localization, enabling culturally aligned evaluation and supporting
the deployment of ethically robust AI in diverse, low-resource multilingual
settings such as Bangladesh.

### 45. Two thousand years of the oracle problem. Insights from Ancient Delphi on the future of blockchain oracles

- **LLM Score**: 0
- **Keyword Score**: 7
- **Authors**: Giulio Caldarelli, Massimiliano Ornaghi
- **URL**: <http://arxiv.org/abs/2511.03319v1>
- **Submitted**: 2025-11-05 09:32:01
- **Comment**: Not peer reviewed
- **Topic Keywords**: queries, rag, acl
- **Reason**: This paper is not related to Information Retrieval, Search technologies, or Natural Language Processing. It explores the concept of oracles in the context of blockchain, drawing parallels with ancient Delphi, which is outside the scope of the user's research interests.

#### Abstract
> The oracle problem refers to the inability of an agent to know if the
information coming from an oracle is authentic and unbiased. In ancient times,
philosophers and historians debated on how to evaluate, increase, and secure
the reliability of oracle predictions, particularly those from Delphi, which
pertained to matters of state. Today, we refer to data carriers for automatic
machines as oracles, but establishing a secure channel between these oracles
and the real world still represents a challenge. Despite numerous efforts, this
problem remains mostly unsolved, and the recent advent of blockchain oracles
has added a layer of complexity because of the decentralization of blockchains.
This paper conceptually connects Delphic and modern blockchain oracles,
developing a comparative framework. Leveraging blockchain oracle taxonomy,
lexical analysis is also performed on 167 Delphic queries to shed light on the
relationship between oracle answer quality and question type. The presented
framework aims first at revealing commonalities between classical and
computational oracles and then at enriching the oracle analysis within each
field. This study contributes to the computer science literature by proposing
strategies to improve the reliability of blockchain oracles based on insights
from Delphi and to classical literature by introducing a framework that can
also be applied to interpret and classify other ancient oracular mechanisms.

### 46. Let the Bees Find the Weak Spots: A Path Planning Perspective on Multi-Turn Jailbreak Attacks against LLMs

- **LLM Score**: 0
- **Keyword Score**: 6
- **Authors**: Yize Liu, Yunyun Hou, Aina Sui
- **URL**: <http://arxiv.org/abs/2511.03271v1>
- **Submitted**: 2025-11-05 08:05:58
- **Topic Keywords**: queries, rag, search
- **Reason**: This paper is not relevant to your research interests as it focuses on security risks and vulnerabilities in Large Language Models, which is outside the scope of Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Large Language Models (LLMs) have been widely deployed across various
applications, yet their potential security and ethical risks have raised
increasing concerns. Existing research employs red teaming evaluations,
utilizing multi-turn jailbreaks to identify potential vulnerabilities in LLMs.
However, these approaches often lack exploration of successful dialogue
trajectories within the attack space, and they tend to overlook the
considerable overhead associated with the attack process. To address these
limitations, this paper first introduces a theoretical model based on
dynamically weighted graph topology, abstracting the multi-turn attack process
as a path planning problem. Based on this framework, we propose ABC, an
enhanced Artificial Bee Colony algorithm for multi-turn jailbreaks, featuring a
collaborative search mechanism with employed, onlooker, and scout bees. This
algorithm significantly improves the efficiency of optimal attack path search
while substantially reducing the average number of queries required. Empirical
evaluations on three open-source and two proprietary language models
demonstrate the effectiveness of our approach, achieving attack success rates
above 90\% across the board, with a peak of 98\% on GPT-3.5-Turbo, and
outperforming existing baselines. Furthermore, it achieves comparable success
with only 26 queries on average, significantly reducing red teaming overhead
and highlighting its superior efficiency.

### 47. Step-Audio-EditX Technical Report

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Chao Yan, Boyong Wu, Peng Yang, Pengfei Tan, Guoqiang Hu, Yuxin Zhang, Xiangyu, Zhang, Fei Tian, Xuerui Yang, Xiangyu Zhang, Daxin Jiang, Gang Yu
- **URL**: <http://arxiv.org/abs/2511.03601v1>
- **Submitted**: 2025-11-05 16:22:19
- **Topic Keywords**: rag
- **Reason**: This paper appears to be focused on audio editing and text-to-speech capabilities using large-margin synthetic data, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> We present Step-Audio-EditX, the first open-source LLM-based audio model
excelling at expressive and iterative audio editing encompassing emotion,
speaking style, and paralinguistics alongside robust zero-shot text-to-speech
(TTS) capabilities.Our core innovation lies in leveraging only large-margin
synthetic data, which circumvents the need for embedding-based priors or
auxiliary modules. This large-margin learning approach enables both iterative
control and high expressivity across voices, and represents a fundamental pivot
from the conventional focus on representation-level disentanglement. Evaluation
results demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd and
Doubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.

### 48. Russian Contribution to Coronary Artery Disease Research: A Scientometric Mapping of Publications

- **LLM Score**: 0
- **Keyword Score**: 1
- **Authors**: Muneer Ahmad, M Sadik Batcha
- **URL**: <http://arxiv.org/abs/2511.03215v1>
- **Submitted**: 2025-11-05 06:06:19
- **Comment**: 18 pages, 3 figures, Research Article
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, data mining, or related topics. The paper focuses on a scientometric analysis of coronary artery disease research in Russia, which is outside your areas of expertise.

#### Abstract
> The present study attempts to highlight the research output generated in
Russia in coronary artery disease (CAD) research during the period 1990-2019 to
understand the distribution of research output, top journals for publications,
and most prolific authors, authorship pattern, and citation pattern. This study
is based on secondary data extracted from the Science Citation Index (SCI),
which is an integral component of the Web of Science. Descriptive and
inferential statistical techniques were applied in the study. There were 5058
articles by Russian scholars in coronary artery disease during 1990-2019; they
preferred to publish in Russian journals. The research contributions were in
the form of research articles, meeting abstracts and reviews with a consistent
drop in the number of editorial material and article; proceedings paper with
time. Co-authorship was the norm in coronary artery disease research, with a
steady increase in the number of multi-author documents in recent years.

### 49. A Study on Library Resources with Services Satisfaction based on Library Users Affiliated Colleges to Solapur University

- **LLM Score**: 0
- **Keyword Score**: 1
- **Authors**: Patel Adam Burhansab, M Sadik Batcha, Muneer Ahmad
- **URL**: <http://arxiv.org/abs/2511.03209v1>
- **Submitted**: 2025-11-05 05:53:37
- **Comment**: 8 pages, 1 figure, Research Article
- **Topic Keywords**: search
- **Reason**: This paper appears to be focused on library resources and user satisfaction, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> The main aim of this study was to assess and evaluate user satisfaction with
library resources and services among library users associated with Solapur
University. The current research shows the level of users satisfaction with
different library resources and services offered by college libraries. The
research found that a vast number of respondents were pleased with library
facilities and services. The research is designed to achieve users satisfaction
in the library to investigate the level of satisfaction towards library
resources and services with regards to 26 colleges of Solapur University based
in Maharashtra. Information in the form of data has been collected from
colleges and on the basis of users results; analysis needs to analyze users
satisfaction.

---

