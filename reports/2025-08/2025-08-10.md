# Daily Papers Report - 2025-08-10

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Improving Table Retrieval with Question Generation from Partial Tables

- **LLM Score**: 6
- **Keyword Score**: 13
- **Authors**: Hsing-Ping Liang, Che-Wei Chang, Yao-Chung Fan
- **URL**: <http://arxiv.org/abs/2508.06168v1>
- **Submitted**: 2025-08-08 09:35:56
- **Comment**: TRL@ACL2025
- **Topic Keywords**: retriever, query, queries, rag, retrieval
- **Reason**: The paper explores table retrieval with question generation, leveraging large language models and retriever-reader architecture, which is related to query understanding and ranking models in Information Retrieval. However, the focus on table representation and question generation is not directly aligned with user behavior modeling or click models, which are core interests.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Question Generation from Partial Tables (QGpT) for improving table retrieval in question answering systems
- **Aim**: To develop a novel approach for table retrieval in question answering systems that can adapt to various retrievers and real-world usage scenarios
- **Rationale**: Previous studies on table-based question answering have limitations, including assuming a known target table and operating under controlled evaluation settings that do not reflect real-world usage scenarios
- **Ground**: The proposed QGpT method uses a large language model to generate synthetic questions from partial table segments, enhancing semantic alignment with user queries
- **Experiment**: The authors demonstrate the effectiveness of QGpT using two retrievers on multiple datasets, including MiMoTable, OTT-QA, FeTaQA, E2E-WTQ, and MMQA, and conduct an ablation study to investigate the impact of simulated questions
- **Takeaway**: The QGpT framework provides a model-agnostic and extensible approach to improving table retrieval in question answering systems, with potential applications in real-world scenarios where tables are large, noisy, or complex

#### Abstract
> Recent advances in open-domain question answering over tables have widely
adopted large language models (LLMs) under the Retriever-Reader architecture.
Prior works have effectively leveraged LLMs to tackle the complex reasoning
demands of the Reader component, such as text-to-text, text-to-SQL, and multi
hop reasoning. In contrast, the Retriever component has primarily focused on
optimizing the query representation-training retrievers to retrieve relevant
tables based on questions, or to select keywords from questions for matching
table segments. However, little attention has been given to enhancing how
tables themselves are represented in embedding space to better align with
questions. To address this, we propose QGpT (Question Generation from Partial
Tables), a simple yet effective method that uses an LLM to generate synthetic
questions based on small portions of a table. These questions are generated to
simulate how a user might query the content of the table currently under
consideration. The generated questions are then jointly embedded with the
partial table segments used for generation, enhancing semantic alignment with
user queries. Without the need to embed entire tables, our method significantly
improves retrieval performance across multiple benchmarks for both dense and
late-interaction retrievers.

---

### 2. Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation

- **LLM Score**: 6
- **Keyword Score**: 13
- **Authors**: Zhanghao Hu, Qinglin Zhu, Siya Qi, Yulan He, Hanqi Yan, Lin Gui
- **URL**: <http://arxiv.org/abs/2508.05909v1>
- **Submitted**: 2025-08-08 00:13:48
- **Topic Keywords**: retriever, relevance, rag, ctr, retrieval, rank
- **Reason**: The paper explores retrieval-augmented generation, which is related to information retrieval and search technologies. The focus on semantic alignment and relevance assessment is also relevant to query understanding and ranking models. However, the paper's primary focus is on the interaction between retrieval and generation, which is not a central match with the user's research interests in user behavior modeling and click models.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Evaluation metric for retrieval-based generation models
- **Aim**: To introduce a novel evaluation metric, Spectrum Projection Score (SPS), and a framework, xCompress, to improve the quality of retrieved summaries
- **Rationale**: Traditional likelihood-based metrics have limitations in evaluating summary quality, and SPS addresses these limitations by evaluating the alignment between the summary's representation and the reader's internal geometry
- **Ground**: Retrieval-based generation models, reader models, and internal representation spaces
- **Experiment**: Evaluation of SPS and xCompress on five retrieval-based QA benchmarks, comparison with perplexity-based metrics and baseline methods, and investigation of the impact of different sentence embedding extraction methods and hyperparameters on SPS performance
- **Takeaway**: SPS consistently achieves the highest correlation with answer quality across all datasets, and xCompress improves downstream task performance by leveraging SPS to guide compression at test time

#### Abstract
> Large Language Models (LLMs) have shown improved generation performance
through retrieval-augmented generation (RAG) following the retriever-reader
paradigm, which supplements model inputs with externally retrieved knowledge.
However, prior work often evaluates RAG holistically, assessing the retriever
and reader jointly, making it difficult to isolate the true contribution of
retrieval, particularly given the prompt sensitivity of LLMs used as readers.
We introduce Spectrum Projection Score (SPS), a lightweight, supervision-free
metric that allows the reader to gauge the semantic alignment of a retrieved
summary with its hidden representation by comparing the area formed by
generated tokens from the summary, and the principal directions of subspace in
the reader and to measure the relevance. Building on SPS we present xCompress,
an inference time controller framework that dynamically samples, ranks, and
compresses retrieval summary candidates. Extensive experiments on five QA
benchmarks with four open source LLMs show that SPS not only enhances
performance across a range of tasks but also provides a principled perspective
on the interaction between retrieval and generation.

---

### 3. You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures

- **LLM Score**: 6
- **Keyword Score**: 12
- **Authors**: Shengyuan Chen, Chuang Zhou, Zheng Yuan, Qinggang Zhang, Zeyang Cui, Hao Chen, Yilin Xiao, Jiannong Cao, Xiao Huang
- **URL**: <http://arxiv.org/abs/2508.06105v1>
- **Submitted**: 2025-08-08 08:07:40
- **Topic Keywords**: query, queries, rag, retrieval augmented generation, retrieval
- **Reason**: The paper proposes a retrieval-augmented generation framework that dynamically extracts reasoning structures at inference time, which is related to query understanding and ranking models. However, the focus is on natural language processing and knowledge retrieval, rather than information retrieval or search technologies, which are the user's primary research interests.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: LogicRAG: A Novel Framework for Retrieval-Augmented Generation
- **Aim**: To develop an efficient and effective framework for retrieval-augmented generation (RAG) that addresses the limitations of existing Graph-based RAG methods
- **Rationale**: Existing GraphRAG methods have limitations, and LogicRAG proposes a novel approach that dynamically extracts reasoning structures at inference time to guide adaptive retrieval without pre-constructed graphs
- **Ground**: LogicRAG consists of three stages: decomposing input queries into subproblems, topologically sorting the DAG, and resolving each subproblem in a greedy manner, with additional techniques for efficiency and addressing the 'hesitation' issue
- **Experiment**: Evaluation on three benchmark datasets (MuSiQue, 2WikiMultiHopQA, and HotpotQA) shows superior performance and efficiency compared to state-of-the-art baselines, with a query-time efficiency comparison of various multi-hop QA models
- **Takeaway**: LogicRAG is a novel and efficient framework for RAG that eliminates the need for offline graph construction while maintaining competitive query-time performance with modest latency and moderate token usage

#### Abstract
> Large language models (LLMs) often suffer from hallucination, generating
factually incorrect statements when handling questions beyond their knowledge
and perception. Retrieval-augmented generation (RAG) addresses this by
retrieving query-relevant contexts from knowledge bases to support LLM
reasoning. Recent advances leverage pre-constructed graphs to capture the
relational connections among distributed documents, showing remarkable
performance in complex tasks. However, existing Graph-based RAG (GraphRAG)
methods rely on a costly process to transform the corpus into a graph,
introducing overwhelming token cost and update latency. Moreover, real-world
queries vary in type and complexity, requiring different logic structures for
accurate reasoning. The pre-built graph may not align with these required
structures, resulting in ineffective knowledge retrieval. To this end, we
propose a \textbf{\underline{Logic}}-aware
\textbf{\underline{R}}etrieval-\textbf{\underline{A}}ugmented
\textbf{\underline{G}}eneration framework (\textbf{LogicRAG}) that dynamically
extracts reasoning structures at inference time to guide adaptive retrieval
without any pre-built graph. LogicRAG begins by decomposing the input query
into a set of subproblems and constructing a directed acyclic graph (DAG) to
model the logical dependencies among them. To support coherent multi-step
reasoning, LogicRAG then linearizes the graph using topological sort, so that
subproblems can be addressed in a logically consistent order. Besides, LogicRAG
applies graph pruning to reduce redundant retrieval and uses context pruning to
filter irrelevant context, significantly reducing the overall token cost.
Extensive experiments demonstrate that LogicRAG achieves both superior
performance and efficiency compared to state-of-the-art baselines.

---

### 4. A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Andrew Brown, Muhammad Roman, Barry Devereux
- **URL**: <http://arxiv.org/abs/2508.06401v1>
- **Submitted**: 2025-08-08 15:37:14
- **Comment**: 58 pages
- **Topic Keywords**: retriever, rag, retrieval, search
- **Reason**: The paper is somewhat related to information retrieval, as it discusses retrieval-augmented generation, which combines neural retrievers with generative language models. However, the focus is on the application of this technique in natural language processing, rather than query understanding, ranking models, or user behavior modeling, which are the user's primary research interests.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Retrieval-Augmented Generation (RAG)
- **Aim**: Clarify the current research landscape, identify methodological gaps, and chart priority directions for future research
- **Rationale**: RAG combines a neural retriever with a generative language model, utilizing up-to-date, non-parametric memory and retaining semantic generalization in model weights
- **Ground**: 128 articles published between 2020 and May 2025, retrieved from five academic databases
- **Experiment**: Systematic review following the PRISMA 2020 framework, involving specifying inclusion and exclusion criteria, cataloging datasets, architectures, and evaluation practices, and synthesizing empirical evidence
- **Takeaway**: Identify methodological gaps and chart priority directions for future research on RAG

#### Abstract
> This systematic review of the research literature on retrieval-augmented
generation (RAG) provides a focused analysis of the most highly cited studies
published between 2020 and May 2025. A total of 128 articles met our inclusion
criteria. The records were retrieved from ACM Digital Library, IEEE Xplore,
Scopus, ScienceDirect, and the Digital Bibliography and Library Project (DBLP).
RAG couples a neural retriever with a generative language model, grounding
output in up-to-date, non-parametric memory while retaining the semantic
generalisation stored in model weights. Guided by the PRISMA 2020 framework, we
(i) specify explicit inclusion and exclusion criteria based on citation count
and research questions, (ii) catalogue datasets, architectures, and evaluation
practices, and (iii) synthesise empirical evidence on the effectiveness and
limitations of RAG. To mitigate citation-lag bias, we applied a lower
citation-count threshold to papers published in 2025 so that emerging
breakthroughs with naturally fewer citations were still captured. This review
clarifies the current research landscape, highlights methodological gaps, and
charts priority directions for future research.

---

### 5. Maximum Impact with Fewer Features: Efficient Feature Selection for Cold-Start Recommenders through Collaborative Importance Weighting

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Nikita Sukhorukov, Danil Gusak, Evgeny Frolov
- **URL**: <http://arxiv.org/abs/2508.06455v1>
- **Submitted**: 2025-08-08 16:58:47
- **Topic Keywords**: rag, user behavior, recommend, rank
- **Reason**: The paper focuses on recommender systems, which is a related topic to the user's interests in Information Retrieval and Search technologies. However, the emphasis on feature selection and cold-start challenges in recommender systems is not directly aligned with the user's primary focus on query understanding, ranking models, and user behavior modeling in the context of IR. The paper's abstract does not mention any connections to IR or NLP, which are also important areas of interest for the user.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Feature Selection Strategy for Cold-Start Recommender Systems
- **Aim**: To propose a novel feature selection strategy that prioritizes user behavioral information and incorporates correlations from collaborative behavior data to improve recommendation accuracy and computational efficiency
- **Rationale**: The challenges of feature selection in recommendation algorithms, particularly in cold-start scenarios where data is sparse and noisy, necessitate careful feature selection and alignment with the collaborative signal to ensure high-quality recommendations
- **Ground**: The proposed approach uses a hybrid matrix factorization technique, specifically a generalized SVD-based formulation, to propagate collaborative signals into side features and then ranks features using the maximum volume algorithm (MaxVol)
- **Experiment**: The authors evaluate the performance of their feature selection approach on seven datasets from various domains, including MovieLens-1M, Book Crossing, MTS Library, CiteULike-a, and three Amazon domains, and compare it to several baseline algorithms
- **Takeaway**: The proposed approach demonstrates superior performance and efficiency in cold-start recommender systems, making it a promising solution for real-world applications, and highlights the competitiveness of basic baselines, such as random or popularity-based selection

#### Abstract
> Cold-start challenges in recommender systems necessitate leveraging auxiliary
features beyond user-item interactions. However, the presence of irrelevant or
noisy features can degrade predictive performance, whereas an excessive number
of features increases computational demands, leading to higher memory
consumption and prolonged training times.
  To address this, we propose a feature selection strategy that prioritizes the
user behavioral information. Our method enhances the feature representation by
incorporating correlations from collaborative behavior data using a hybrid
matrix factorization technique and then ranks features using a mechanism based
on the maximum volume algorithm. This approach identifies the most influential
features, striking a balance between recommendation accuracy and computational
efficiency. We conduct an extensive evaluation across various datasets and
hybrid recommendation models, demonstrating that our method excels in
cold-start scenarios by selecting minimal yet highly effective feature subsets.
Even under strict feature reduction, our approach surpasses existing feature
selection techniques while maintaining superior efficiency.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. M2IO-R1: An Efficient RL-Enhanced Reasoning Framework for Multimodal Retrieval Augmented Multimodal Generation

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Zhiyou Xiao, Qinhan Yu, Binghui Li, Geng Chen, Chong Chen, Wentao Zhang
- **URL**: <http://arxiv.org/abs/2508.06328v1>
- **Submitted**: 2025-08-08 14:00:19
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper explores Multimodal Retrieval-Augmented Generation (MRAG), which is a related topic to Information Retrieval. However, the focus on multimodal inputs and outputs, as well as the use of Reinforcement Learning (RL) for reasoning, is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling. While the paper touches on some relevant concepts, it does not seem to be a central match for the user's research themes.

#### Abstract
> Current research on Multimodal Retrieval-Augmented Generation (MRAG) enables
diverse multimodal inputs but remains limited to single-modality outputs,
restricting expressive capacity and practical utility. In contrast, real-world
applications often demand both multimodal inputs and multimodal outputs for
effective communication and grounded reasoning. Motivated by the recent success
of Reinforcement Learning (RL) in complex reasoning tasks for Large Language
Models (LLMs), we adopt RL as a principled and effective paradigm to address
the multi-step, outcome-driven challenges inherent in multimodal output
generation. Here, we introduce M2IO-R1, a novel framework for Multimodal
Retrieval-Augmented Multimodal Generation (MRAMG) that supports both multimodal
inputs and outputs. Central to our framework is an RL-based inserter,
Inserter-R1-3B, trained with Group Relative Policy Optimization to guide image
selection and placement in a controllable and semantically aligned manner.
Empirical results show that our lightweight 3B inserter achieves strong
reasoning capabilities with significantly reduced latency, outperforming
baselines in both quality and efficiency.

### 7. Classification is a RAG problem: A case study on hate speech detection

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Richard Willats, Josh Pennington, Aravind Mohan, Bertie Vidgen
- **URL**: <http://arxiv.org/abs/2508.06204v1>
- **Submitted**: 2025-08-08 10:35:41
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper explores the application of Retrieval-Augmented Generation (RAG) in hate speech detection, which is a classification problem. While it touches on some aspects of query understanding and ranking models, the focus is more on the generation and retrieval of contextual knowledge rather than traditional IR and search technologies. The paper's relevance to the user's interests is somewhat limited, but it does demonstrate some innovative approaches to classification and policy updates.

#### Abstract
> Robust content moderation requires classification systems that can quickly
adapt to evolving policies without costly retraining. We present classification
using Retrieval-Augmented Generation (RAG), which shifts traditional
classification tasks from determining the correct category in accordance with
pre-trained parameters to evaluating content in relation to contextual
knowledge retrieved at inference. In hate speech detection, this transforms the
task from "is this hate speech?" to "does this violate the hate speech policy?"
  Our Contextual Policy Engine (CPE) - an agentic RAG system - demonstrates
this approach and offers three key advantages: (1) robust classification
accuracy comparable to leading commercial systems, (2) inherent explainability
via retrieved policy segments, and (3) dynamic policy updates without model
retraining. Through three experiments, we demonstrate strong baseline
performance and show that the system can apply fine-grained policy control by
correctly adjusting protection for specific identity groups without requiring
retraining or compromising overall performance. These findings establish that
RAG can transform classification into a more flexible, transparent, and
adaptable process for content moderation and wider classification problems.

### 8. Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Hugo Abonizio, Thales Almeida, Roberto Lotufo, Rodrigo Nogueira
- **URL**: <http://arxiv.org/abs/2508.06178v1>
- **Submitted**: 2025-08-08 09:48:32
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper explores knowledge injection methods for large language models in low-resource regimes, which is related to query understanding and ranking models in Information Retrieval. However, the focus on language models and knowledge injection is not directly aligned with the user's primary interests in search technologies, user behavior modeling, and deep semantic understanding.

#### Abstract
> Large language models (LLMs) often require vast amounts of text to
effectively acquire new knowledge. While continuing pre-training on large
corpora or employing retrieval-augmented generation (RAG) has proven
successful, updating an LLM with only a few thousand or million tokens remains
challenging. In this work, we investigate the task of injecting small,
unstructured information into LLMs and its relation to the catastrophic
forgetting phenomenon. We use a dataset of recent news -- ensuring no overlap
with the model's pre-training data -- to evaluate the knowledge acquisition by
probing the model with question-answer pairs related the learned information.
Starting from a continued pre-training baseline, we explored different
augmentation algorithms to generate synthetic data to improve the knowledge
acquisition capabilities. Our experiments show that simply continuing
pre-training on limited data yields modest improvements, whereas exposing the
model to diverse textual variations significantly improves the learning of new
facts -- particularly with methods that induce greater variability through
diverse prompting. Furthermore, we shed light on the forgetting phenomenon in
small-data regimes, illustrating the delicate balance between learning new
content and retaining existing capabilities. We also confirm the sensitivity of
RAG-based approaches for knowledge injection, which often lead to greater
degradation on control datasets compared to parametric methods. Finally, we
demonstrate that models can generate effective synthetic training data
themselves, suggesting a pathway toward self-improving model updates. All code
and generated data used in our experiments are publicly available, providing a
resource for studying efficient knowledge injection in LLMs with limited data
at https://github.com/hugoabonizio/knowledge-injection-methods.

### 9. UR$^2$: Unify RAG and Reasoning through Reinforcement Learning

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Weitao Li, Boran Xiang, Xiaolong Wang, Zhinan Gou, Weizhi Ma, Yang Liu
- **URL**: <http://arxiv.org/abs/2508.06165v1>
- **Submitted**: 2025-08-08 09:33:20
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper proposes a unified framework for retrieval and reasoning through reinforcement learning, which is relevant to the field of Information Retrieval. However, the focus on large language models and their capabilities in open-domain QA, medical, and mathematical reasoning tasks is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large Language Models (LLMs) have shown remarkable capabilities through two
complementary paradigms: Retrieval-Augmented Generation (RAG), which enhances
knowledge grounding, and Reinforcement Learning from Verifiable Rewards (RLVR),
which optimizes complex reasoning abilities. However, these two capabilities
are often developed in isolation, and existing efforts to unify them remain
narrow in scope-typically limited to open-domain QA with fixed retrieval
settings and task-specific assumptions. This lack of integration constrains
generalization and limits the applicability of RAG-RL methods to broader
domains. To bridge this gap, we propose UR2 (Unified RAG and Reasoning), a
general framework that unifies retrieval and reasoning through reinforcement
learning. UR2 introduces two key contributions: a difficulty-aware curriculum
training that selectively invokes retrieval only for challenging problems, and
a hybrid knowledge access strategy combining domain-specific offline corpora
with LLM-generated summaries. These components are designed to enable dynamic
coordination between retrieval and reasoning, improving adaptability across a
diverse range of tasks. Experiments across open-domain QA, MMLU-Pro, medical,
and mathematical reasoning tasks demonstrate that UR2 (built on Qwen2.5-3/7B
and LLaMA-3.1-8B) significantly outperforms existing RAG and RL methods,
achieving comparable performance to GPT-4o-mini and GPT-4.1-mini on several
benchmarks. We have released all code, models, and data at
https://github.com/Tsinghua-dhy/UR2.

### 10. DKG-LLM : A Framework for Medical Diagnosis and Personalized Treatment Recommendations via Dynamic Knowledge Graph and Large Language Model Integration

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Ali Sarabadani, Maryam Abdollahi Shamami, Hamidreza Sadeghsalehi, Borhan Asadi, Saba Hesaraki
- **URL**: <http://arxiv.org/abs/2508.06186v1>
- **Submitted**: 2025-08-08 10:04:40
- **Topic Keywords**: rag, recommend
- **Reason**: The paper presents a framework for medical diagnosis and personalized treatment recommendations using a dynamic knowledge graph and large language model integration. While it leverages language models, the focus is on medical diagnosis and treatment recommendations, which is not directly related to the user's primary research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. The paper's relevance is limited to the user's secondary interest in NLP, but the application domain is distinct from e-commerce and does not require deep semantic understanding and real-time relevance optimization.

#### Abstract
> Large Language Models (LLMs) have grown exponentially since the release of
ChatGPT. These models have gained attention due to their robust performance on
various tasks, including language processing tasks. These models achieve
understanding and comprehension of tasks by training billions of parameters.
The development of these models is a transformative force in enhancing natural
language understanding and has taken a significant step towards artificial
general intelligence (AGI). In this study, we aim to present the DKG-LLM
framework. The DKG-LLM framework introduces a groundbreaking approach to
medical diagnosis and personalized treatment recommendations by integrating a
dynamic knowledge graph (DKG) with the Grok 3 large language model. Using the
Adaptive Semantic Fusion Algorithm (ASFA), heterogeneous medical data
(including clinical reports and PubMed articles) and patient records
dynamically generate a knowledge graph consisting of 15,964 nodes in 13
distinct types (e.g., diseases, symptoms, treatments, patient profiles) and
127,392 edges in 26 relationship types (e.g., causal, therapeutic,
association). ASFA utilizes advanced probabilistic models, Bayesian inference,
and graph optimization to extract semantic information, dynamically updating
the graph with approximately 150 new nodes and edges in each data category
while maintaining scalability with up to 987,654 edges. Real-world datasets,
including MIMIC-III and PubMed, were utilized to evaluate the proposed
architecture. The evaluation results show that DKG-LLM achieves a diagnostic
accuracy of 84.19%. The model also has a treatment recommendation accuracy of
89.63% and a semantic coverage of 93.48%. DKG-LLM is a reliable and
transformative tool that handles noisy data and complex multi-symptom diseases,
along with feedback-based learning from physician input.

### 11. Semantic Item Graph Enhancement for Multimodal Recommendation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Xiaoxiong Zhang, Xin Zhou, Zhiwei Zeng, Dusit Niyato, Zhiqi Shen
- **URL**: <http://arxiv.org/abs/2508.06154v1>
- **Submitted**: 2025-08-08 09:20:50
- **Topic Keywords**: rag, recommend
- **Reason**: The paper focuses on multimodal recommendation systems, which is a related topic to information retrieval. However, the emphasis on multimodal features and collaborative signals among items is not directly aligned with the user's primary interest in query understanding, ranking models, and user behavior modeling. The paper's relevance is somewhat related but not a central match.

#### Abstract
> Multimodal recommendation systems have attracted increasing attention for
their improved performance by leveraging items' multimodal information. Prior
methods often build modality-specific item-item semantic graphs from raw
modality features and use them as supplementary structures alongside the
user-item interaction graph to enhance user preference learning. However, these
semantic graphs suffer from semantic deficiencies, including (1) insufficient
modeling of collaborative signals among items and (2) structural distortions
introduced by noise in raw modality features, ultimately compromising
performance. To address these issues, we first extract collaborative signals
from the interaction graph and infuse them into each modality-specific item
semantic graph to enhance semantic modeling. Then, we design a modulus-based
personalized embedding perturbation mechanism that injects perturbations with
modulus-guided personalized intensity into embeddings to generate contrastive
views. This enables the model to learn noise-robust representations through
contrastive learning, thereby reducing the effect of structural noise in
semantic graphs. Besides, we propose a dual representation alignment mechanism
that first aligns multiple semantic representations via a designed Anchor-based
InfoNCE loss using behavior representations as anchors, and then aligns
behavior representations with the fused semantics by standard InfoNCE, to
ensure representation consistency. Extensive experiments on four benchmark
datasets validate the effectiveness of our framework.

### 12. EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Xinda Wang, Zhengxu Hou, Yangshijie Zhang, Bingren Yan, Zhibo Yang, Xingsheng Zhang, Luxi Xing, Qiang Zhou, Chen Zhang
- **URL**: <http://arxiv.org/abs/2508.06046v1>
- **Submitted**: 2025-08-08 06:10:47
- **Topic Keywords**: pairwise
- **Reason**: The paper explores the application of a novel framework, EvolvR, for story evaluation, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on the topic of language models, it focuses on the evaluation of stories rather than query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's interests.

#### Abstract
> Although the effectiveness of Large Language Models (LLMs) as judges
(LLM-as-a-judge) has been validated, their performance remains limited in
open-ended tasks, particularly in story evaluation. Accurate story evaluation
is crucial not only for assisting human quality judgment but also for providing
key signals to guide story generation. However, existing methods face a
dilemma: prompt engineering for closed-source models suffers from poor
adaptability, while fine-tuning approaches for open-source models lack the
rigorous reasoning capabilities essential for story evaluation. To address
this, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework.
Grounded in pairwise comparison, the framework first self-synthesizes
score-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To
ensure data quality, these raw CoTs undergo a self-filtering process, utilizing
multi-agents to guarantee their logical rigor and robustness. Finally, the
evaluator trained on the refined data is deployed as a reward model to guide
the story generation task. Experimental results demonstrate that our framework
achieves state-of-the-art (SOTA) performance on three evaluation benchmarks
including StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward
model, it significantly enhances the quality of generated stories, thereby
fully validating the superiority of our self-evolving approach.

### 13. InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Keummin Ka, Junhyeong Park, Jahyun Jeon, Youngjae Yu
- **URL**: <http://arxiv.org/abs/2508.06220v1>
- **Submitted**: 2025-08-08 11:03:23
- **Comment**: 14 pages, 9 figures
- **Topic Keywords**: rag
- **Reason**: The paper explores causal reasoning in multimodal settings, using infographics and textual context, which is not directly related to my primary research interests in Information Retrieval and Search technologies. While it touches on multimodal AI systems, the focus on causal inference and reasoning is not a central match for my interests.

#### Abstract
> Recent advances in Vision-Language Models (VLMs) have demonstrated impressive
capabilities in perception and reasoning. However, the ability to perform
causal inference -- a core aspect of human cognition -- remains underexplored,
particularly in multimodal settings. In this study, we introduce InfoCausalQA,
a novel benchmark designed to evaluate causal reasoning grounded in
infographics that combine structured visual data with textual context. The
benchmark comprises two tasks: Task 1 focuses on quantitative causal reasoning
based on inferred numerical trends, while Task 2 targets semantic causal
reasoning involving five types of causal relations: cause, effect,
intervention, counterfactual, and temporal. We manually collected 494
infographic-text pairs from four public sources and used GPT-4o to generate
1,482 high-quality multiple-choice QA pairs. These questions were then
carefully revised by humans to ensure they cannot be answered based on
surface-level cues alone but instead require genuine visual grounding. Our
experimental results reveal that current VLMs exhibit limited capability in
computational reasoning and even more pronounced limitations in semantic causal
reasoning. Their significantly lower performance compared to humans indicates a
substantial gap in leveraging infographic-based information for causal
inference. Through InfoCausalQA, we highlight the need for advancing the causal
reasoning abilities of multimodal AI systems.

### 14. AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Sayantan Adak, Pratyush Chatterjee, Somnath Banerjee, Rima Hazra, Somak Aditya, Animesh Mukherjee
- **URL**: <http://arxiv.org/abs/2508.06124v1>
- **Submitted**: 2025-08-08 08:43:24
- **Topic Keywords**: search
- **Reason**: The paper focuses on the safety and alignment of large language models, introducing a novel framework called AURA. While it touches on the topic of understanding and modeling user behavior, it is not directly related to information retrieval, search technologies, or query understanding. The paper's emphasis on logical coherence and safety-awareness is interesting, but it does not align with the user's primary research interests in IR and NLP.

#### Abstract
> Present day LLMs face the challenge of managing affordance-based safety
risks-situations where outputs inadvertently facilitate harmful actions due to
overlooked logical implications. Traditional safety solutions, such as scalar
outcome-based reward models, parameter tuning, or heuristic decoding
strategies, lack the granularity and proactive nature needed to reliably detect
and intervene during subtle yet crucial reasoning steps. Addressing this
fundamental gap, we introduce AURA, an innovative, multi-layered framework
centered around Process Reward Models (PRMs), providing comprehensive, step
level evaluations across logical coherence and safety-awareness. Our framework
seamlessly combines introspective self-critique, fine-grained PRM assessments,
and adaptive safety-aware decoding to dynamically and proactively guide models
toward safer reasoning trajectories. Empirical evidence clearly demonstrates
that this approach significantly surpasses existing methods, significantly
improving the logical integrity and affordance-sensitive safety of model
outputs. This research represents a pivotal step toward safer, more
responsible, and contextually aware AI, setting a new benchmark for
alignment-sensitive applications.

### 15. Efficient Multimodal Streaming Recommendation via Expandable Side Mixture-of-Experts

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Yunke Qu, Liang Qu, Tong Chen, Quoc Viet Hung Nguyen, Hongzhi Yin
- **URL**: <http://arxiv.org/abs/2508.05993v1>
- **Submitted**: 2025-08-08 04:00:05
- **Comment**: Accepted to CIKM 2025
- **Topic Keywords**: recommend
- **Reason**: The paper focuses on streaming recommender systems, which is related to your interest in information retrieval and search technologies. However, the emphasis on multimodal features, expandable expert networks, and memory efficiency is not directly aligned with your core research themes, such as query understanding, ranking models, and user behavior modeling.

#### Abstract
> Streaming recommender systems (SRSs) are widely deployed in real-world
applications, where user interests shift and new items arrive over time. As a
result, effectively capturing users' latest preferences is challenging, as
interactions reflecting recent interests are limited and new items often lack
sufficient feedback. A common solution is to enrich item representations using
multimodal encoders (e.g., BERT or ViT) to extract visual and textual features.
However, these encoders are pretrained on general-purpose tasks: they are not
tailored to user preference modeling, and they overlook the fact that user
tastes toward modality-specific features such as visual styles and textual
tones can also drift over time. This presents two key challenges in streaming
scenarios: the high cost of fine-tuning large multimodal encoders, and the risk
of forgetting long-term user preferences due to continuous model updates.
  To tackle these challenges, we propose Expandable Side Mixture-of-Experts
(XSMoE), a memory-efficient framework for multimodal streaming recommendation.
XSMoE attaches lightweight side-tuning modules consisting of expandable expert
networks to frozen pretrained encoders and incrementally expands them in
response to evolving user feedback. A gating router dynamically combines expert
and backbone outputs, while a utilization-based pruning strategy maintains
model compactness. By learning new patterns through expandable experts without
overwriting previously acquired knowledge, XSMoE effectively captures both cold
start and shifting preferences in multimodal features. Experiments on three
real-world datasets demonstrate that XSMoE outperforms state-of-the-art
baselines in both recommendation quality and computational efficiency.

### 16. FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Xiangyan Chen, Yufeng Li, Yujian Gan, Arkaitz Zubiaga, Matthew Purver
- **URL**: <http://arxiv.org/abs/2508.05782v1>
- **Submitted**: 2025-08-07 18:51:03
- **Topic Keywords**: search
- **Reason**: The paper focuses on dialogue fact verification, which is related to information retrieval and natural language processing. However, the specific context of dialogue systems and fact verification is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large Language Models (LLMs) are known to produce hallucinations - factually
incorrect or fabricated information - which poses significant challenges for
many Natural Language Processing (NLP) applications, such as dialogue systems.
As a result, detecting hallucinations has become a critical area of research.
Current approaches to hallucination detection in dialogue systems primarily
focus on verifying the factual consistency of generated responses. However,
these responses often contain a mix of accurate, inaccurate or unverifiable
facts, making one factual label overly simplistic and coarse-grained. In this
paper, we introduce a benchmark, FineDialFact, for fine-grained dialogue fact
verification, which involves verifying atomic facts extracted from dialogue
responses. To support this, we construct a dataset based on publicly available
dialogue datasets and evaluate it using various baseline methods. Experimental
results demonstrate that methods incorporating Chain-of-Thought (CoT) reasoning
can enhance performance in dialogue fact verification. Despite this, the best
F1-score achieved on the HybriDialogue, an open-domain dialogue dataset, is
only 0.75, indicating that the benchmark remains a challenging task for future
research. Our dataset and code will be public on GitHub.

### 17. Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Chi Zhang, Changjia Zhu, Junjie Xiong, Xiaoran Xu, Lingyao Li, Yao Liu, Zhuo Lu
- **URL**: <http://arxiv.org/abs/2508.05775v1>
- **Submitted**: 2025-08-07 18:42:16
- **Topic Keywords**: search
- **Reason**: The paper discusses the dual role of Large Language Models (LLMs) in generating both beneficial and harmful content. While it touches on the topic of content creation and understanding, which is related to information retrieval and NLP, the focus is more on the safety and mitigation aspects of LLMs, which is not directly aligned with the user's primary research interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large Language Models (LLMs) have revolutionized content creation across
digital platforms, offering unprecedented capabilities in natural language
generation and understanding. These models enable beneficial applications such
as content generation, question and answering (Q&A), programming, and code
reasoning. Meanwhile, they also pose serious risks by inadvertently or
intentionally producing toxic, offensive, or biased content. This dual role of
LLMs, both as powerful tools for solving real-world problems and as potential
sources of harmful language, presents a pressing sociotechnical challenge. In
this survey, we systematically review recent studies spanning unintentional
toxicity, adversarial jailbreaking attacks, and content moderation techniques.
We propose a unified taxonomy of LLM-related harms and defenses, analyze
emerging multimodal and LLM-assisted jailbreak strategies, and assess
mitigation efforts, including reinforcement learning with human feedback
(RLHF), prompt engineering, and safety alignment. Our synthesis highlights the
evolving landscape of LLM safety, identifies limitations in current evaluation
methodologies, and outlines future research directions to guide the development
of robust and ethically aligned language technologies.

### 18. Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning

- **LLM Score**: 2
- **Keyword Score**: 8
- **Authors**: Sahil Bansal, Sai Shruthi Sistla, Aarti Arikatala, Sebastian Schreiber
- **URL**: <http://arxiv.org/abs/2508.05888v1>
- **Submitted**: 2025-08-07 22:41:12
- **Topic Keywords**: queries, rag, retrieval, rank
- **Reason**: The paper focuses on planning agents and tool retrieval in enterprise task planning, which is not directly related to information retrieval, search technologies, or query understanding. Although it mentions knowledge graphs, the application is specific to tool retrieval and does not align with the user's interests in NLP, data mining, or real-time relevance optimization.

#### Abstract
> Effective tool retrieval is essential for AI agents to select from a vast
array of tools when identifying and planning actions in the context of complex
user queries. Despite its central role in planning, this aspect remains
underexplored in the literature. Traditional approaches rely primarily on
similarities between user queries and tool descriptions, which significantly
limits retrieval accuracy, specifically when handling multi-step user requests.
To address these limitations, we propose a Knowledge Graph (KG)-based tool
retrieval framework that captures the semantic relationships between tools and
their functional dependencies. Our retrieval algorithm leverages ensembles of
1-hop ego tool graphs to model direct and indirect connections between tools,
enabling more comprehensive and contextual tool selection for multi-step tasks.
We evaluate our approach on a synthetically generated internal dataset across
six defined user classes, extending previous work on coherent dialogue
synthesis and too retrieval benchmarks. Results demonstrate that our tool
graph-based method achieves 91.85% tool coverage on the micro-average Complete
Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid
retrieval, the strongest non-KG baseline in our experiments. These findings
support our hypothesis that the structural information in the KG provides
complementary signals to pure similarity matching, particularly for queries
requiring sequential tool composition.

### 19. WebWatcher: Breaking New Frontiers of Vision-Language Deep Research Agent

- **LLM Score**: 2
- **Keyword Score**: 8
- **Authors**: Xinyu Geng, Peng Xia, Zhen Zhang, Xinyu Wang, Qiuchen Wang, Ruixue Ding, Chenxi Wang, Jialong Wu, Yida Zhao, Kuan Li, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou
- **URL**: <http://arxiv.org/abs/2508.05748v1>
- **Submitted**: 2025-08-07 18:03:50
- **Topic Keywords**: information retrieval, rag, retrieval, search
- **Reason**: The paper focuses on multimodal deep research agents, leveraging visual and language information, which is not directly related to the user's interests in Information Retrieval, Search technologies, and query understanding. While the paper mentions information retrieval, it is primarily focused on visual-language reasoning and multimodal agents, which is not a central match for the user's research themes.

#### Abstract
> Web agents such as Deep Research have demonstrated superhuman cognitive
abilities, capable of solving highly challenging information-seeking problems.
However, most research remains primarily text-centric, overlooking visual
information in the real world. This makes multimodal Deep Research highly
challenging, as such agents require much stronger reasoning abilities in
perception, logic, knowledge, and the use of more sophisticated tools compared
to text-based agents. To address this limitation, we introduce WebWatcher, a
multi-modal Agent for Deep Research equipped with enhanced visual-language
reasoning capabilities. It leverages high-quality synthetic multimodal
trajectories for efficient cold start training, utilizes various tools for deep
reasoning, and further enhances generalization through reinforcement learning.
To better evaluate the capabilities of multimodal agents, we propose
BrowseComp-VL, a benchmark with BrowseComp-style that requires complex
information retrieval involving both visual and textual information.
Experimental results show that WebWatcher significantly outperforms proprietary
baseline, RAG workflow and open-source agents in four challenging VQA
benchmarks, which paves the way for solving complex multimodal
information-seeking tasks.

### 20. Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Lingyuan Liu, Mengxiang Zhang
- **URL**: <http://arxiv.org/abs/2508.06135v1>
- **Submitted**: 2025-08-08 08:55:53
- **Topic Keywords**: ranking, rag, rank
- **Reason**: This paper focuses on knowledge distillation in large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on data quality and compatibility, these concepts are not applied to the context of search or retrieval, making it an off-topic paper for your research interests.

#### Abstract
> Knowledge Distillation (KD) is a fundamental technique for compressing large
language models (LLMs) into compact, efficient student models. However,
existing white-box KD methods mainly focus on balancing ground truth and
student-generated responses while overlooking two critical factors: training
data quality and student-model compatibility. To address these limitations, we
propose Selective Reflection Distillation (SRD), a novel data curation
framework that leverages reflections from student models to systematically
refine training data. SRD dynamically evaluates and selects prompt-response
pairs by comparing ground truth data with student model outputs, selectively
curating high-quality, student-compatible training instances through automated
ranking based on difficulty. Furthermore, after selecting the training data, a
curriculum scheduling strategy is employed to incrementally introduce these
curated subsets into the distillation process at fixed intervals. As a
plug-and-play enhancement, SRD consistently improves distillation outcomes
across diverse white-box KD approaches and model architectures, as well as
decreases computational cost significantly during KD training. Experiments on a
range of language model benchmarks demonstrate SRD's consistent improvements in
distilled model performance, as well as a reduction in training runtime by up
to 39%, under diverse KD methods and model families. Notably, SRD operates as a
plug-and-play module, enhancing sample efficiency without modifying underlying
KD algorithms. Our findings highlight that data quality and compatibility are
pivotal to effective and efficient distillation of LLMs, and SRD provides a
principled framework to achieve both. This work advances the understanding of
data-centric factors in KD and offers practical insights for enhancing the
capability and efficiency of compressed LLMs.

### 21. NanoCodec: Towards High-Quality Ultra Fast Speech LLM Inference

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Edresson Casanova, Paarth Neekhara, Ryan Langman, Shehzeen Hussain, Subhankar Ghosh, Xuesong Yang, Ante Jukiƒá, Jason Li, Boris Ginsburg
- **URL**: <http://arxiv.org/abs/2508.05835v1>
- **Submitted**: 2025-08-07 20:20:32
- **Comment**: Accepted to Interspeech 2025
- **Topic Keywords**: ltr, rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus is on audio processing and speech language models, which is outside your primary areas of interest.

#### Abstract
> Large Language Models (LLMs) have significantly advanced audio processing by
leveraging audio codecs to discretize audio into tokens, enabling the
application of language modeling techniques to speech data. However, existing
audio codecs often operate at high frame rates, leading to slow training and
inference, particularly for autoregressive models. To address this, there is
growing interest in low frame-rate audio codecs, which reduce the number of
autoregressive steps required to generate one second of audio. In this paper,
we conduct ablation studies to examine the impact of frame rate, bitrate, and
causality on codec reconstruction quality. Based on our findings, we introduce
NanoCodec, a state-of-the-art audio codec that achieves high-quality
compression at just 12.5 frames per second (FPS). NanoCodec outperforms related
works across various bitrate ranges, establishing a new benchmark for
low-latency and efficient Speech LLM training and inference.

### 22. eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Daria Tikhonovich, Nikita Zelinskiy, Aleksandr V. Petrov, Mayya Spirina, Andrei Semenov, Andrey V. Savchenko, Sergei Kuliev
- **URL**: <http://arxiv.org/abs/2508.06450v1>
- **Submitted**: 2025-08-08 16:49:03
- **Comment**: Accepted at ACM RecSys 2025
- **Topic Keywords**: rag, recommend
- **Reason**: The paper focuses on recommender systems, specifically Transformer-based models, which is not directly related to the user's primary research interests in Information Retrieval and Search technologies. Although the paper mentions the use of a training objective and loss function, it does not address query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user.

#### Abstract
> Since their introduction, Transformer-based models, such as SASRec and
BERT4Rec, have become common baselines for sequential recommendations,
surpassing earlier neural and non-neural methods. A number of following
publications have shown that the effectiveness of these models can be improved
by, for example, slightly updating the architecture of the Transformer layers,
using better training objectives, and employing improved loss functions.
However, the additivity of these modular improvements has not been
systematically benchmarked - this is the gap we aim to close in this paper.
Through our experiments, we identify a very strong model that uses SASRec's
training objective, LiGR Transformer layers, and Sampled Softmax Loss. We call
this combination eSASRec (Enhanced SASRec). While we primarily focus on
realistic, production-like evaluation, in our preliminarily study we find that
common academic benchmarks show eSASRec to be 23% more effective compared to
the most recent state-of-the-art models, such as ActionPiece. In our main
production-like benchmark, eSASRec resides on the Pareto frontier in terms of
the accuracy-coverage tradeoff (alongside the recent industrial models HSTU and
FuXi. As the modifications compared to the original SASRec are relatively
straightforward and no extra features are needed (such as timestamps in HSTU),
we believe that eSASRec can be easily integrated into existing recommendation
pipelines and can can serve as a strong yet very simple baseline for emerging
complicated algorithms. To facilitate this, we provide the open-source
implementations for our models and benchmarks in repository
https://github.com/blondered/transformer_benchmark

### 23. Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Andrea Nasuto, Stefano Maria Iacus, Francisco Rowe, Devika Jain
- **URL**: <http://arxiv.org/abs/2508.06435v1>
- **Submitted**: 2025-08-08 16:23:24
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on the application of Large Language Models (LLMs) in classifying online immigration discourse across languages, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on the topic of language models, it does not explore ranking models, user behavior modeling, or real-time relevance optimization, which are core areas of interest.

#### Abstract
> Large language models (LLMs) are transforming social-science research by
enabling scalable, precise analysis. Their adaptability raises the question of
whether knowledge acquired through fine-tuning in a few languages can transfer
to unseen languages that only appeared during pre-training. To examine this, we
fine-tune lightweight LLaMA 3.2-3B models on monolingual, bilingual, or
multilingual data sets to classify immigration-related tweets from X/Twitter
across 13 languages, a domain characterised by polarised, culturally specific
discourse. We evaluate whether minimal language-specific fine-tuning enables
cross-lingual topic detection and whether adding targeted languages corrects
pre-training biases. Results show that LLMs fine-tuned in one or two languages
can reliably classify immigration-related content in unseen languages. However,
identifying whether a tweet expresses a pro- or anti-immigration stance
benefits from multilingual fine-tuning. Pre-training bias favours dominant
languages, but even minimal exposure to under-represented languages during
fine-tuning (as little as $9.62\times10^{-11}$ of the original pre-training
token volume) yields significant gains. These findings challenge the assumption
that cross-lingual mastery requires extensive multilingual training: limited
language coverage suffices for topic-level generalisation, and structural
biases can be corrected with lightweight interventions. By releasing
4-bit-quantised, LoRA fine-tuned models, we provide an open-source,
reproducible alternative to proprietary LLMs that delivers 35 times faster
inference at just 0.00000989% of the dollar cost of the OpenAI GPT-4o model,
enabling scalable, inclusive research.

### 24. Quantifying Conversation Drift in MCP via Latent Polytope

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Haoran Shi, Hongwei Yao, Shuo Shao, Shaopeng Jiao, Ziqi Peng, Zhan Qin, Cong Wang
- **URL**: <http://arxiv.org/abs/2508.06418v1>
- **Submitted**: 2025-08-08 16:05:27
- **Topic Keywords**: ltr
- **Reason**: The paper focuses on a specific topic of Model Context Protocol (MCP) security, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions large language models (LLMs), the context is not relevant to the user's interests in IR, ranking models, or user behavior modeling.

#### Abstract
> The Model Context Protocol (MCP) enhances large language models (LLMs) by
integrating external tools, enabling dynamic aggregation of real-time data to
improve task execution. However, its non-isolated execution context introduces
critical security and privacy risks. In particular, adversarially crafted
content can induce tool poisoning or indirect prompt injection, leading to
conversation hijacking, misinformation propagation, or data exfiltration.
Existing defenses, such as rule-based filters or LLM-driven detection, remain
inadequate due to their reliance on static signatures, computational
inefficiency, and inability to quantify conversational hijacking. To address
these limitations, we propose SecMCP, a secure framework that detects and
quantifies conversation drift, deviations in latent space trajectories induced
by adversarial external knowledge. By modeling LLM activation vectors within a
latent polytope space, SecMCP identifies anomalous shifts in conversational
dynamics, enabling proactive detection of hijacking, misleading, and data
exfiltration. We evaluate SecMCP on three state-of-the-art LLMs (Llama3,
Vicuna, Mistral) across benchmark datasets (MS MARCO, HotpotQA, FinQA),
demonstrating robust detection with AUROC scores exceeding 0.915 while
maintaining system usability. Our contributions include a systematic
categorization of MCP security threats, a novel latent polytope-based
methodology for quantifying conversation drift, and empirical validation of
SecMCP's efficacy.

### 25. Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yanbin Wei, Jiangyue Yan, Chun Kang, Yang Chen, Hua Liu, James T. Kwok, Yu Zhang
- **URL**: <http://arxiv.org/abs/2508.06345v1>
- **Submitted**: 2025-08-08 14:18:24
- **Topic Keywords**: ctr, rank
- **Reason**: The paper focuses on graph question answering and multimodal models, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions ranking models, it's not in the context of learning to rank or user behavior modeling. The paper's topics are more aligned with natural language processing and data mining, but it doesn't seem to require deep semantic understanding or real-time relevance optimization.

#### Abstract
> Large Multimodal Models (LMMs) have shown generalized zero-shot capabilities
in diverse domain question-answering (QA) tasks, including graph QA that
involves complex graph topologies. However, most current approaches use only a
single type of graph representation, namely Topology Representation Form (TRF),
such as prompt-unified text descriptions or style-fixed visual styles. Those
"one-size-fits-all" approaches fail to consider the specific preferences of
different models or tasks, often leading to incorrect or overly long responses.
To address this, we first analyze the characteristics and weaknesses of
existing TRFs, and then design a set of TRFs, denoted by $F_{ZS}$, tailored to
zero-shot graph QA. We then introduce a new metric, Graph Response Efficiency
(GRE), which measures the balance between the performance and the brevity in
graph QA. Built on these, we develop the DynamicTRF framework, which aims to
improve both the accuracy and conciseness of graph QA. To be specific,
DynamicTRF first creates a TRF Preference (TRFP) dataset that ranks TRFs based
on their GRE scores, to probe the question-specific TRF preferences. Then it
trains a TRF router on the TRFP dataset, to adaptively assign the best TRF from
$F_{ZS}$ for each question during the inference. Extensive experiments across 7
in-domain algorithmic graph QA tasks and 2 out-of-domain downstream tasks show
that DynamicTRF significantly enhances the zero-shot graph QA of LMMs in terms
of accuracy

### 26. EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Nizi Nazar, Ehsaneddin Asgari
- **URL**: <http://arxiv.org/abs/2508.06196v1>
- **Submitted**: 2025-08-08 10:22:19
- **Topic Keywords**: ltr
- **Reason**: This paper focuses on emotional intelligence in large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on natural language processing, the specific application and methodology are not relevant to the user's research interests.

#### Abstract
> Emotional Intelligence (EI) is a critical yet underexplored dimension in the
development of human-aligned LLMs. To address this gap, we introduce a unified,
psychologically grounded four-layer taxonomy of EI tailored for large language
models (LLMs), encompassing emotional tracking, cause inference, appraisal, and
emotionally appropriate response generation. Building on this framework, we
present EICAP-Bench, a novel MCQ style multi-turn benchmark designed to
evaluate EI capabilities in open-source LLMs across diverse linguistic and
cultural contexts. We evaluate six LLMs: LLaMA3 (8B), LLaMA3-Instruct, Gemma
(9B), Gemma-Instruct, Qwen2.5 (7B), and Qwen2.5-Instruct on EmoCap-Bench,
identifying Qwen2.5-Instruct as the strongest baseline. To assess the potential
for enhancing EI capabilities, we fine-tune both Qwen2.5-Base and
Qwen2.5-Instruct using LoRA adapters on UltraChat (UC), a large-scale,
instruction-tuned dialogue dataset, in both English and Arabic. Our statistical
analysis reveals that among the five EI layers, only the Appraisal layer shows
significant improvement through UC-based fine-tuning. These findings highlight
the limitations of existing pretraining and instruction-tuning paradigms in
equipping LLMs with deeper emotional reasoning and underscore the need for
targeted data and modeling strategies for comprehensive EI alignment.

### 27. Dual prototype attentive graph network for cross-market recommendation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Li Fan, Menglin Kong, Yang Xiang, Chong Zhang, Chengtao Ji
- **URL**: <http://arxiv.org/abs/2508.05969v1>
- **Submitted**: 2025-08-08 03:07:44
- **Comment**: Accepted by ICONIP 2025 (Oral)
- **Topic Keywords**: rag, recommend
- **Reason**: The paper focuses on recommender systems, which is a related topic, but it does not address information retrieval, query understanding, ranking models, or user behavior modeling, which are the core research themes in the user's interests. The paper's emphasis on graph representation learning and clustering users from various markets is not directly relevant to the user's background in e-commerce or NLP.

#### Abstract
> Cross-market recommender systems (CMRS) aim to utilize historical data from
mature markets to promote multinational products in emerging markets. However,
existing CMRS approaches often overlook the potential for shared preferences
among users in different markets, focusing primarily on modeling specific
preferences within each market. In this paper, we argue that incorporating both
market-specific and market-shared insights can enhance the generalizability and
robustness of CMRS. We propose a novel approach called Dual Prototype Attentive
Graph Network for Cross-Market Recommendation (DGRE) to address this. DGRE
leverages prototypes based on graph representation learning from both items and
users to capture market-specific and market-shared insights. Specifically, DGRE
incorporates market-shared prototypes by clustering users from various markets
to identify behavioural similarities and create market-shared user profiles.
Additionally, it constructs item-side prototypes by aggregating item features
within each market, providing valuable market-specific insights. We conduct
extensive experiments to validate the effectiveness of DGRE on a real-world
cross-market dataset, and the results show that considering both
market-specific and market-sharing aspects in modelling can improve the
generalization and robustness of CMRS.

### 28. GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: GLM-4. 5 Team, :, Aohan Zeng, Xin Lv, Qinkai Zheng, Zhenyu Hou, Bin Chen, Chengxing Xie, Cunxiang Wang, Da Yin, Hao Zeng, Jiajie Zhang, Kedong Wang, Lucen Zhong, Mingdao Liu, Rui Lu, Shulin Cao, Xiaohan Zhang, Xuancheng Huang, Yao Wei, Yean Cheng, Yifan An, Yilin Niu, Yuanhao Wen, Yushi Bai, Zhengxiao Du, Zihan Wang, Zilin Zhu, Bohan Zhang, Bosi Wen, Bowen Wu, Bowen Xu, Can Huang, Casey Zhao, Changpeng Cai, Chao Yu, Chen Li, Chendi Ge, Chenghua Huang, Chenhui Zhang, Chenxi Xu, Chenzheng Zhu, Chuang Li, Congfeng Yin, Daoyan Lin, Dayong Yang, Dazhi Jiang, Ding Ai, Erle Zhu, Fei Wang, Gengzheng Pan, Guo Wang, Hailong Sun, Haitao Li, Haiyang Li, Haiyi Hu, Hanyu Zhang, Hao Peng, Hao Tai, Haoke Zhang, Haoran Wang, Haoyu Yang, He Liu, He Zhao, Hongwei Liu, Hongxi Yan, Huan Liu, Huilong Chen, Ji Li, Jiajing Zhao, Jiamin Ren, Jian Jiao, Jiani Zhao, Jianyang Yan, Jiaqi Wang, Jiayi Gui, Jiayue Zhao, Jie Liu, Jijie Li, Jing Li, Jing Lu, Jingsen Wang, Jingwei Yuan, Jingxuan Li, Jingzhao Du, Jinhua Du, Jinxin Liu, Junkai Zhi, Junli Gao, Ke Wang, Lekang Yang, Liang Xu, Lin Fan, Lindong Wu, Lintao Ding, Lu Wang, Man Zhang, Minghao Li, Minghuan Xu, Mingming Zhao, Mingshu Zhai, Pengfan Du, Qian Dong, Shangde Lei, Shangqing Tu, Shangtong Yang, Shaoyou Lu, Shijie Li, Shuang Li, Shuang-Li, Shuxun Yang, Sibo Yi, Tianshu Yu, Wei Tian, Weihan Wang, Wenbo Yu, Weng Lam Tam, Wenjie Liang, Wentao Liu, Xiao Wang, Xiaohan Jia, Xiaotao Gu, Xiaoying Ling, Xin Wang, Xing Fan, Xingru Pan, Xinyuan Zhang, Xinze Zhang, Xiuqing Fu, Xunkai Zhang, Yabo Xu, Yandong Wu, Yida Lu, Yidong Wang, Yilin Zhou, Yiming Pan, Ying Zhang, Yingli Wang, Yingru Li, Yinpei Su, Yipeng Geng, Yitong Zhu, Yongkun Yang, Yuhang Li, Yuhao Wu, Yujiang Li, Yunan Liu, Yunqing Wang, Yuntao Li, Yuxuan Zhang, Zezhen Liu, Zhen Yang, Zhengda Zhou, Zhongpei Qiao, Zhuoer Feng, Zhuorui Liu, Zichen Zhang, Zihan Wang, Zijun Yao, Zikang Wang, Ziqiang Liu, Ziwei Chai, Zixuan Li, Zuodong Zhao, Wenguang Chen, Jidong Zhai, Bin Xu, Minlie Huang, Hongning Wang, Juanzi Li, Yuxiao Dong, Jie Tang
- **URL**: <http://arxiv.org/abs/2508.06471v1>
- **Submitted**: 2025-08-08 17:21:06
- **Topic Keywords**: rank, search
- **Reason**: This paper is not relevant to your research interests as it focuses on large language models and reasoning tasks, which do not align with your primary focus on Information Retrieval, Search technologies, and query understanding. The paper's abstract does not mention any concepts related to your interests, such as ranking models, user behavior modeling, or real-time relevance optimization.

#### Abstract
> We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language
model with 355B total parameters and 32B activated parameters, featuring a
hybrid reasoning method that supports both thinking and direct response modes.
Through multi-stage training on 23T tokens and comprehensive post-training with
expert model iteration and reinforcement learning, GLM-4.5 achieves strong
performance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on
TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer
parameters than several competitors, GLM-4.5 ranks 3rd overall among all
evaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B
parameters) and a compact version, GLM-4.5-Air (106B parameters), to advance
research in reasoning and agentic AI systems. Code, models, and more
information are available at https://github.com/zai-org/GLM-4.5.

### 29. Memp: Exploring Agent Procedural Memory

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Runnan Fang, Yuan Liang, Xiaobin Wang, Jialong Wu, Shuofei Qiao, Pengjun Xie, Fei Huang, Huajun Chen, Ningyu Zhang
- **URL**: <http://arxiv.org/abs/2508.06433v1>
- **Submitted**: 2025-08-08 16:20:56
- **Comment**: Work in progress
- **Topic Keywords**: retrieval
- **Reason**: The paper explores procedural memory in large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on agent trajectories and memory updates, the focus is on procedural memory rather than semantic understanding or real-time relevance optimization.

#### Abstract
> Large Language Models (LLMs) based agents excel at diverse tasks, yet they
suffer from brittle procedural memory that is manually engineered or entangled
in static parameters. In this work, we investigate strategies to endow agents
with a learnable, updatable, and lifelong procedural memory. We propose Memp
that distills past agent trajectories into both fine-grained, step-by-step
instructions and higher-level, script-like abstractions, and explore the impact
of different strategies for Build, Retrieval, and Update of procedural memory.
Coupled with a dynamic regimen that continuously updates, corrects, and
deprecates its contents, this repository evolves in lockstep with new
experience. Empirical evaluation on TravelPlanner and ALFWorld shows that as
the memory repository is refined, agents achieve steadily higher success rates
and greater efficiency on analogous tasks. Moreover, procedural memory built
from a stronger model retains its value: migrating the procedural memory to a
weaker model yields substantial performance gains.

### 30. Sample-efficient LLM Optimization with Reset Replay

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zichuan Liu, Jinyu Wang, Lei Song, Jiang Bian
- **URL**: <http://arxiv.org/abs/2508.06412v1>
- **Submitted**: 2025-08-08 15:56:49
- **Topic Keywords**: rag
- **Reason**: The paper focuses on optimizing Large Language Models (LLMs) using Reinforcement Learning and preference optimization methods, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions optimization, the context is different from the user's interests in ranking models and user behavior modeling.

#### Abstract
> Recent advancements in post-training Large Language Models (LLMs),
particularly through Reinforcement Learning (RL) and preference optimization
methods, are key drivers for enhancing their reasoning capabilities. However,
these methods are often plagued by low sample efficiency and a susceptibility
to primacy bias, where overfitting to initial experiences degrades policy
quality and damages the learning process. To address these challenges, we
introduce LLM optimization with Reset Replay (LoRR), a general and powerful
plugin designed to enhance sample efficiency in any preference-based
optimization framework. LoRR core mechanism enables training at a high replay
number, maximizing the utility of each collected data batch. To counteract the
risk of overfitting inherent in high-replay training, LoRR incorporates a
periodic reset strategy with reusing initial data, which preserves network
plasticity. Furthermore, it leverages a hybrid optimization objective,
combining supervised fine-tuning (SFT) and preference-based losses to further
bolster data exploitation. Our extensive experiments demonstrate that LoRR
significantly boosts the performance of various preference optimization methods
on both mathematical and general reasoning benchmarks. Notably, an iterative
DPO approach augmented with LoRR achieves comparable performance on challenging
math tasks, outperforming some complex and computationally intensive RL-based
algorithms. These findings highlight that LoRR offers a practical,
sample-efficient, and highly effective paradigm for LLM finetuning, unlocking
greater performance from limited data.

### 31. Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ruichong Zhang
- **URL**: <http://arxiv.org/abs/2508.06309v1>
- **Submitted**: 2025-08-08 13:35:40
- **Topic Keywords**: rag
- **Reason**: This paper focuses on detecting plagiarism in large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on matrix analysis, it is not applicable to the user's core research themes.

#### Abstract
> In recent years, concerns about intellectual property (IP) in large language
models (LLMs) have grown significantly. Plagiarizing other LLMs (through direct
weight copying, upcycling, pruning, or continual pretraining) and claiming
authorship without properly attributing to the original license, is a serious
misconduct that can lead to significant financial and reputational harm to the
original developers. However, existing methods for detecting LLM plagiarism
fall short in key areas. They fail to accurately reconstruct weight
correspondences, lack the ability to compute statistical significance measures
such as $p$-values, and may mistakenly flag models trained on similar data as
being related. To address these limitations, we propose Matrix-Driven Instant
Review (MDIR), a novel method that leverages matrix analysis and Large
Deviation Theory. MDIR achieves accurate reconstruction of weight
relationships, provides rigorous $p$-value estimation, and focuses exclusively
on weight similarity without requiring full model inference. Experimental
results demonstrate that MDIR reliably detects plagiarism even after extensive
transformations, such as random permutations and continual pretraining with
trillions of tokens. Moreover, all detections can be performed on a single PC
within an hour, making MDIR both efficient and accessible.

### 32. Pragmatics beyond humans: meaning, communication, and LLMs

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: V√≠t Gvo≈ædiak
- **URL**: <http://arxiv.org/abs/2508.06167v1>
- **Submitted**: 2025-08-08 09:34:41
- **Topic Keywords**: rag
- **Reason**: The paper's focus on pragmatics, language models, and human-machine communication is not directly related to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on topics like query understanding and user behavior modeling, the context is vastly different and not applicable to your areas of focus.

#### Abstract
> The paper reconceptualizes pragmatics not as a subordinate, third dimension
of meaning, but as a dynamic interface through which language operates as a
socially embedded tool for action. With the emergence of large language models
(LLMs) in communicative contexts, this understanding needs to be further
refined and methodologically reconsidered. The first section challenges the
traditional semiotic trichotomy, arguing that connectionist LLM architectures
destabilize established hierarchies of meaning, and proposes the Human-Machine
Communication (HMC) framework as a more suitable alternative. The second
section examines the tension between human-centred pragmatic theories and the
machine-centred nature of LLMs. While traditional, Gricean-inspired pragmatics
continue to dominate, it relies on human-specific assumptions ill-suited to
predictive systems like LLMs. Probabilistic pragmatics, particularly the
Rational Speech Act framework, offers a more compatible teleology by focusing
on optimization rather than truth-evaluation. The third section addresses the
issue of substitutionalism in three forms - generalizing, linguistic, and
communicative - highlighting the anthropomorphic biases that distort LLM
evaluation and obscure the role of human communicative subjects. Finally, the
paper introduces the concept of context frustration to describe the paradox of
increased contextual input paired with a collapse in contextual understanding,
emphasizing how users are compelled to co-construct pragmatic conditions both
for the model and themselves. These arguments suggest that pragmatic theory may
need to be adjusted or expanded to better account for communication involving
generative AI.

### 33. One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yingfeng Luo, Dingyang Lin, Junxin Wang, Ziqiang Xu, Kaiyan Chang, Tong Zheng, Bei Li, Anxiang Ma, Tong Xiao, Zhengtao Yu, Jingbo Zhu
- **URL**: <http://arxiv.org/abs/2508.06163v1>
- **Submitted**: 2025-08-08 09:33:08
- **Comment**: Under review
- **Topic Keywords**: rag
- **Reason**: The paper focuses on model merging and sparsification, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions the concept of 'parameter interference', it does not address the specific challenges in IR, such as ranking models or user behavior modeling.

#### Abstract
> Model merging has emerged as a compelling data-free paradigm for multi-task
learning, enabling the fusion of multiple fine-tuned models into a single,
powerful entity. A key technique in merging methods is sparsification, which
prunes redundant parameters from task vectors to mitigate interference.
However, prevailing approaches employ a ``one-size-fits-all'' strategy,
applying a uniform sparsity ratio that overlooks the inherent structural and
statistical heterogeneity of model parameters. This often leads to a suboptimal
trade-off, where critical parameters are inadvertently pruned while less useful
ones are retained. To address this limitation, we introduce \textbf{TADrop}
(\textbf{T}ensor-wise \textbf{A}daptive \textbf{Drop}), an adaptive
sparsification strategy that respects this heterogeneity. Instead of a global
ratio, TADrop assigns a tailored sparsity level to each parameter tensor based
on its distributional properties. The core intuition is that tensors with
denser, more redundant distributions can be pruned aggressively, while sparser,
more critical ones are preserved. As a simple and plug-and-play module, we
validate TADrop by integrating it with foundational, classic, and SOTA merging
methods. Extensive experiments across diverse tasks (vision, language, and
multimodal) and models (ViT, BEiT) demonstrate that TADrop consistently and
significantly boosts their performance. For instance, when enhancing a leading
merging method, it achieves an average performance gain of 2.0\% across 8
ViT-B/32 tasks. TADrop provides a more effective way to mitigate parameter
interference by tailoring sparsification to the model's structure, offering a
new baseline for high-performance model merging.

### 34. ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Morris Alper, Moran Yanuka, Raja Giryes, Ga≈°per Begu≈°
- **URL**: <http://arxiv.org/abs/2508.06094v1>
- **Submitted**: 2025-08-08 07:36:48
- **Comment**: Project page: https://conlangcrafter.github.io
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus is on constructed languages and computational creativity, which is a distinct area that does not align with your primary research themes.

#### Abstract
> Constructed languages (conlangs) such as Esperanto and Quenya have played
diverse roles in art, philosophy, and international communication. Meanwhile,
large-scale foundation models have revolutionized creative generation in text,
images, and beyond. In this work, we leverage modern LLMs as computational
creativity aids for end-to-end conlang creation. We introduce ConlangCrafter, a
multi-hop pipeline that decomposes language design into modular stages --
phonology, morphology, syntax, lexicon generation, and translation. At each
stage, our method leverages LLMs' meta-linguistic reasoning capabilities,
injecting randomness to encourage diversity and leveraging self-refinement
feedback to encourage consistency in the emerging language description. We
evaluate ConlangCrafter on metrics measuring coherence and typological
diversity, demonstrating its ability to produce coherent and varied conlangs
without human linguistic expertise.

### 35. Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Kartik Sharma, Yiqiao Jin, Rakshit Trivedi, Srijan Kumar
- **URL**: <http://arxiv.org/abs/2508.06030v1>
- **Submitted**: 2025-08-08 05:32:31
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on probing knowledge in large language models, which is a topic in Natural Language Processing, but not specifically in IR or Search technologies.

#### Abstract
> Large language models (LLMs) acquire knowledge across diverse domains such as
science, history, and geography encountered during generative pre-training.
However, due to their stochasticity, it is difficult to predict what LLMs have
acquired. Prior work has developed different ways to probe this knowledge by
investigating the hidden representations, crafting specific task prompts,
curating representative samples, and estimating their uncertainty. However,
these methods require making forward passes through the underlying model to
probe the LLM's knowledge about a specific fact, making them computationally
expensive and time-consuming. To bridge this gap, we propose $\textbf{PEEK}$ or
$\textbf{P}$roxy $\textbf{E}$mbeddings to $\textbf{E}$stimate
$\textbf{K}$nowledge of LLMs, by leveraging the pre-trained embedding models
that effectively encode factual knowledge as text or graphs as proxies for
LLMs. First, we identify a training set of facts known by LLMs through various
probing strategies and then adapt embedding models to predict the LLM outputs
with a linear decoder layer. Comprehensive evaluation on $3$ Wikipedia-derived
datasets, $4$ LLMs, and $7$ embedding models shows that embeddings can predict
LLM knowledge on a held-out set with up to 90 % accuracy. Furthermore, we find
that sentence embedding models are more suitable than graph embeddings to
predict LLM knowledge, shedding light on the underlying representation of the
factual landscape. Thus, we believe that knowledge-adapted embeddings can be
used to identify knowledge gaps in LLMs at scale and can provide deeper
insights into LLMs' internal inductive bias. The code and data are made
available at https://github.com/claws-lab/peek.

### 36. Discovering Properties of Inflectional Morphology in Neural Emergent Communication

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Miles Gilberti, Shane Storks, Huteng Dai
- **URL**: <http://arxiv.org/abs/2508.05843v1>
- **Submitted**: 2025-08-07 20:44:50
- **Topic Keywords**: rag
- **Reason**: The paper's focus on emergent communication and neural network-based agents is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The abstract does not mention query understanding, ranking models, or user behavior modeling, and the context of inflectional morphology is not relevant to the user's areas of interest.

#### Abstract
> Emergent communication (EmCom) with deep neural network-based agents promises
to yield insights into the nature of human language, but remains focused
primarily on a few subfield-specific goals and metrics that prioritize
communication schemes which represent attributes with unique characters
one-to-one and compose them syntactically. We thus reinterpret a common EmCom
setting, the attribute-value reconstruction game, by imposing a
small-vocabulary constraint to simulate double articulation, and formulating a
novel setting analogous to naturalistic inflectional morphology (enabling
meaningful comparison to natural language communication schemes). We develop
new metrics and explore variations of this game motivated by real properties of
inflectional morphology: concatenativity and fusionality. Through our
experiments, we discover that simulated phonological constraints encourage
concatenative morphology, and emergent languages replicate the tendency of
natural languages to fuse grammatical attributes.

### 37. HapticLLaMA: A Multimodal Sensory Language Model for Haptic Captioning

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Guimin Hu, Daniel Hershcovich, Hasti Seifi
- **URL**: <http://arxiv.org/abs/2508.06475v1>
- **Submitted**: 2025-08-08 17:25:37
- **Topic Keywords**: search
- **Reason**: The paper focuses on haptic captioning, a topic outside the scope of information retrieval and search technologies. While it involves language models, the application is specific to haptic signals and does not relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest.

#### Abstract
> Haptic captioning is the task of generating natural language descriptions
from haptic signals, such as vibrations, for use in virtual reality,
accessibility, and rehabilitation applications. While previous multimodal
research has focused primarily on vision and audio, haptic signals for the
sense of touch remain underexplored. To address this gap, we formalize the
haptic captioning task and propose HapticLLaMA, a multimodal sensory language
model that interprets vibration signals into descriptions in a given sensory,
emotional, or associative category. We investigate two types of haptic
tokenizers, a frequency-based tokenizer and an EnCodec-based tokenizer, that
convert haptic signals into sequences of discrete units, enabling their
integration with the LLaMA model. HapticLLaMA is trained in two stages: (1)
supervised fine-tuning using the LLaMA architecture with LoRA-based adaptation,
and (2) fine-tuning via reinforcement learning from human feedback (RLHF). We
assess HapticLLaMA's captioning performance using both automated n-gram metrics
and human evaluation. HapticLLaMA demonstrates strong capability in
interpreting haptic vibration signals, achieving a METEOR score of 59.98 and a
BLEU-4 score of 32.06 respectively. Additionally, over 61% of the generated
captions received human ratings above 3.5 on a 7-point scale, with RLHF
yielding a 10% improvement in the overall rating distribution, indicating
stronger alignment with human haptic perception. These findings highlight the
potential of large language models to process and adapt to sensory data.

### 38. LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Lanlan Qiu, Xiao Pu, Yeqi Feng, Tianxing He
- **URL**: <http://arxiv.org/abs/2508.06388v1>
- **Submitted**: 2025-08-08 15:17:24
- **Comment**: 21 pages, 17 figures, 3 tables
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on Large Language Models and emotionally supportive role-playing conversations is not aligned with your areas of interest, and the paper does not address query understanding, ranking models, or user behavior modeling.

#### Abstract
> Large Language Models (LLMs) have demonstrated impressive capabilities in
role-playing conversations and providing emotional support as separate research
directions. However, there remains a significant research gap in combining
these capabilities to enable emotionally supportive interactions with virtual
characters. To address this research gap, we focus on anime characters as a
case study because of their well-defined personalities and large fan bases.
This choice enables us to effectively evaluate how well LLMs can provide
emotional support while maintaining specific character traits. We introduce
ChatAnime, the first Emotionally Supportive Role-Playing (ESRP) dataset. We
first thoughtfully select 20 top-tier characters from popular anime communities
and design 60 emotion-centric real-world scenario questions. Then, we execute a
nationwide selection process to identify 40 Chinese anime enthusiasts with
profound knowledge of specific characters and extensive experience in
role-playing. Next, we systematically collect two rounds of dialogue data from
10 LLMs and these 40 Chinese anime enthusiasts. To evaluate the ESRP
performance of LLMs, we design a user experience-oriented evaluation system
featuring 9 fine-grained metrics across three dimensions: basic dialogue,
role-playing and emotional support, along with an overall metric for response
diversity. In total, the dataset comprises 2,400 human-written and 24,000
LLM-generated answers, supported by over 132,000 human annotations.
Experimental results show that top-performing LLMs surpass human fans in
role-playing and emotional support, while humans still lead in response
diversity. We hope this work can provide valuable resources and insights for
future research on optimizing LLMs in ESRP. Our datasets are available at
https://github.com/LanlanQiu/ChatAnime.

### 39. Evaluating Style-Personalized Text Generation: Challenges and Directions

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Anubhav Jangra, Bahareh Sarrafzadeh, Adrian de Wynter, Silviu Cucerzan, Sujay Kumar Jauhar
- **URL**: <http://arxiv.org/abs/2508.06374v1>
- **Submitted**: 2025-08-08 15:07:31
- **Topic Keywords**: search
- **Reason**: The paper focuses on evaluating style-personalized text generation, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and query understanding. While it touches on evaluation metrics, it does not address ranking models, user behavior modeling, or deep semantic understanding, making it only loosely relevant to the user's interests.

#### Abstract
> While prior research has built tools and benchmarks towards style
personalized text generation, there has been limited exploration of evaluation
in low-resource author style personalized text generation space. Through this
work, we question the effectiveness of the widely adopted evaluation metrics
like BLEU and ROUGE, and explore other evaluation paradigms such as style
embeddings and LLM-as-judge to holistically evaluate the style personalized
text generation task. We evaluate these metrics and their ensembles using our
style discrimination benchmark, that spans eight writing tasks, and evaluates
across three settings, domain discrimination, authorship attribution, and LLM
personalized vs non-personalized discrimination. We provide conclusive evidence
to adopt ensemble of diverse evaluation metrics to effectively evaluate style
personalized text generation.

### 40. Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Lai Jiang, Yuekang Li, Xiaohan Zhang, Youtao Ding, Li Pan
- **URL**: <http://arxiv.org/abs/2508.06194v1>
- **Submitted**: 2025-08-08 10:19:21
- **Topic Keywords**: search
- **Reason**: This paper appears to be unrelated to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on a specific domain (LLM red teaming and jailbreak research) and uses terminology and concepts unfamiliar to the user. The paper's abstract does not mention any of the user's key areas of interest, such as query understanding, ranking models, or user behavior modeling.

#### Abstract
> Precise jailbreak evaluation is vital for LLM red teaming and jailbreak
research. Current approaches employ binary classification ( e.g., string
matching, toxic text classifiers, LLM-driven methods), yielding only "yes/no"
labels without quantifying harm intensity. Existing multi-dimensional
frameworks ( e.g., Security Violation, Relative Truthfulness, Informativeness)
apply uniform evaluation criteria across scenarios, resulting in
scenario-specific mismatches--for instance, "Relative Truthfulness" is
irrelevant to "hate speech"--which compromise evaluation precision. To tackle
these limitations, we introduce SceneJailEval, with key contributions: (1) A
groundbreaking scenario-adaptive multi-dimensional framework for jailbreak
evaluation, overcoming the critical "one-size-fits-all" constraint of existing
multi-dimensional methods, and featuring strong extensibility to flexibly adapt
to customized or emerging scenarios. (2) A comprehensive 14-scenario dataset
with diverse jailbreak variants and regional cases, filling the long-standing
gap in high-quality, holistic benchmarks for scenario-adaptive evaluation. (3)
SceneJailEval achieves state-of-the-art results, with an F1 score of 0.917 on
our full-scenario dataset (+6% over prior SOTA) and 0.995 on JBB (+3% over
prior SOTA), surpassing accuracy limits of existing evaluation methods in
heterogeneous scenarios and confirming its advantage.

### 41. When a Paper Has 1000 Authors: Rethinking Citation Metrics in the Era of LLMs

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Weihang Guo, Zhao Song, Jiahao Zhang
- **URL**: <http://arxiv.org/abs/2508.06004v1>
- **Submitted**: 2025-08-08 04:18:26
- **Topic Keywords**: search
- **Reason**: The paper's focus on citation metrics and large-scale collaborations is not directly related to the user's interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. While the paper touches on the topic of large-scale publications, it does not explore the user's areas of interest in IR, NLP, and data mining.

#### Abstract
> Author-level citation metrics provide a practical, interpretable, and
scalable signal of scholarly influence in a complex research ecosystem. It has
been widely used as a proxy in hiring decisions. However, the past five years
have seen the rapid emergence of large-scale publications in the field of large
language models and foundation models, with papers featuring hundreds to
thousands of co-authors and receiving tens of thousands of citations within
months. For example, Gemini has 1361 authors and has been cited around 4600
times in 19 months. In such cases, traditional metrics, such as total citation
count and the $h$-index, fail to meaningfully distinguish individual
contributions. Therefore, we propose the following research question: How can
one identify standout researchers among thousands of co-authors in large-scale
LLM papers? This question is particularly important in scenarios such as
academic hiring and funding decisions. In this paper, we introduce a novel
citation metric designed to address this challenge by balancing contributions
across large-scale and small-scale publications. We propose the SBCI index,
analyze its theoretical properties, and evaluate its behavior on synthetic
publication datasets. Our results demonstrate that the proposed metric provides
a more robust and discriminative assessment of individual scholarly impact in
the era of large-scale collaborations.

### 42. "Mirror" Language AI Models of Depression are Criterion-Contaminated

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Tong Li, Rasiq Hussain, Mehak Gupta, Joshua R. Oltmanns
- **URL**: <http://arxiv.org/abs/2508.05830v1>
- **Submitted**: 2025-08-07 20:13:00
- **Comment**: 39 pages, 9 figures
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on language AI models of depression, which is a topic outside your primary focus. The concepts and methods discussed in the paper, such as topic modeling and language-based prediction, are not directly applicable to your areas of interest.

#### Abstract
> A growing number of studies show near-perfect LLM language-based prediction
of depression assessment scores (up to R2 of .70). However, many develop these
models directly from language responses to depression assessments. These
"Mirror models" suffer from "criterion contamination", which arises when a
predicted score depends in part on the predictors themselves. This causes
artificial effect size inflation which reduces model generalizability. The
present study compares the performance of Mirror models versus "Non-Mirror
models", which are developed from language that does not mirror the assessment
they are developed to predict. N = 110 research participants completed two
different interviews: structured diagnostic and life history interviews. GPT-4,
GPT-4o and LLaMA3-70B were then prompted to predict structured diagnostic
interview depression scores from the two transcripts separately. Mirror models
(using structured diagnostic data) showed very large effect sizes (e.g., R2 =
.80). As expected, NonMirror models (using life history data) demonstrated
smaller effect sizes, but were relatively large (e.g., R2 = .27). When Mirror
and Non-Mirror model-predicted structured interview depression scores were
correlated with self-reported depression symptoms, Mirror and NonMirror
performed the same (e.g., r = ~.54), indicating that Mirror models contain bias
perhaps due to criterion contamination. Topic modeling identified clusters
across Mirror and Non-Mirror models, as well as between true-positive and
false-positive predictions. In this head-to-head comparison study, Mirror
language AI models of depression showed artificially inflated effect sizes and
less generalizability. As language AI models for depression continue to evolve,
incorporating Non-Mirror models may identify interpretable, and generalizable
semantic features that have unique utility in real-world psychological
assessment.

### 43. Basic interactive algorithms: Preview

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Yuri Gurevich
- **URL**: <http://arxiv.org/abs/2508.05798v1>
- **Submitted**: 2025-08-07 19:13:47
- **Topic Keywords**: acl
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, data mining, or recommender systems. The paper focuses on the axiomatization of basic interactive algorithms, which is a topic in computer science theory, and does not relate to your areas of interest.

#### Abstract
> This dialog paper offers a preview and provides a foretaste of an upcoming
work on the axiomatization of basic interactive algorithms.
  The modern notion of algorithm was elucidated in the 1930s--1950s. It was
axiomatized a quarter of a century ago as the notion of ``sequential
algorithm'' or ``classical algorithm''; we prefer to call it ``basic algorithm"
now. The axiomatization was used to show that for every basic algorithm there
is a behaviorally equivalent abstract state machine. It was also used to prove
the Church-Turing thesis as it has been understood by the logicians.
  Starting from the 1960s, the notion of algorithm has expanded --
probabilistic algorithms, quantum algorithms, etc. -- prompting introduction of
a much more ambitious version of the Church-Turing thesis commonly known as the
``physical thesis.'' We emphasize the difference between the two versions of
the Church-Turing thesis and illustrate how nondeterministic and probabilistic
algorithms can be viewed as basic algorithms with appropriate oracles. The same
view applies to quantum circuit algorithms and many other classes of
algorithms.

---

