# Daily Papers Report - 2025-09-30

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. UniDex: Rethinking Search Inverted Indexing with Unified Semantic Modeling

- **LLM Score**: 9
- **Keyword Score**: 12
- **Authors**: Zan Li, Jiahui Chen, Yuan Chai, Xiaoze Jiang, Xiaohua Qi, Zhiheng Qin, Runbin Zhou, Shun Zuo, Guangchao Hao, Kefeng Wang, Jingshan Lv, Yupeng Huang, Xiao Liang, Han Li
- **URL**: <http://arxiv.org/abs/2509.24632v1>
- **Submitted**: 2025-09-29 11:41:12
- **Comment**: 11 pages, 6 figures and 5 tables
- **Topic Keywords**: queries, relevance, rag, retrieval, rank, search
- **Reason**: This paper aligns closely with your research interests in Information Retrieval, particularly in query understanding and ranking models. The proposed UniDex method, which employs unified semantic modeling for inverted indexing, is a significant advancement in the field. Its focus on semantic generalization and real-time relevance optimization makes it highly relevant to your research.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: None
- **Aim**: None
- **Rationale**: None
- **Ground**: None
- **Experiment**: None
- **Takeaway**: None

#### Abstract
> Inverted indexing has traditionally been a cornerstone of modern search
systems, leveraging exact term matches to determine relevance between queries
and documents. However, this term-based approach often emphasizes surface-level
token overlap, limiting the system's generalization capabilities and retrieval
effectiveness. To address these challenges, we propose UniDex, a novel
model-based method that employs unified semantic modeling to revolutionize
inverted indexing. UniDex replaces complex manual designs with a streamlined
architecture, enhancing semantic generalization while reducing maintenance
overhead. Our approach involves two key components: UniTouch, which maps
queries and documents into semantic IDs for improved retrieval, and UniRank,
which employs semantic matching to rank results effectively. Through
large-scale industrial datasets and real-world online traffic assessments, we
demonstrate that UniDex significantly improves retrieval capabilities, marking
a paradigm shift from term-based to model-based indexing. Our deployment within
Kuaishou's short-video search systems further validates UniDex's practical
effectiveness, serving hundreds of millions of active users efficiently.

---

### 2. Retro*: Optimizing LLMs for Reasoning-Intensive Document Retrieval

- **LLM Score**: 9
- **Keyword Score**: 7
- **Authors**: Junwei Lan, Jianlyu Chen, Zheng Liu, Chaofan Li, Siqi Bao, Defu Lian
- **URL**: <http://arxiv.org/abs/2509.24869v1>
- **Submitted**: 2025-09-29 14:53:05
- **Topic Keywords**: relevance, rag, retrieval
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The focus on reasoning-intensive document retrieval and the use of LLMs aligns with your interests in deep semantic understanding and real-time relevance optimization. The proposed approach, Retro*, also shows potential for scalability and efficiency, which are important considerations in the field.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: None
- **Aim**: None
- **Rationale**: None
- **Ground**: None
- **Experiment**: None
- **Takeaway**: None

#### Abstract
> With the growing popularity of LLM agents and RAG, it has become increasingly
important to retrieve documents that are essential for solving a task, even
when their connection to the task is indirect or implicit. Addressing this
problem requires fine-grained reasoning to accurately assess the relevance
between the task and each candidate document. This capability, however, poses a
significant challenge for existing IR techniques. Despite recent progress in
reasoning-enhanced IR, existing approaches still face significant challenges in
applicability, scalability, and efficiency. In this work, we propose Retro*, a
novel approach for reasoning-intensive document retrieval. Our method
introduces a rubric-based relevance scoring mechanism, enabling the model to
reason about the relationship between a task and a document based on explicitly
defined criteria, whereby producing a fine-grained, interpretable relevance
score. Retro* also supports test-time scaling by combining multiple reasoning
trajectories via score integration, which produces more reliable relevance
estimates. To optimize Retro*'s reasoning capabilities, we introduce a novel
reinforcement learning algorithm tailored for its relevance scoring mechanism,
which employs two composite rewards to fully exploit the trajectories of each
training sample. Our experiments show that Retro* outperforms existing document
retrieval methods with notable advantages, leading to state-of-the-art
performance on the BRIGHT benchmark.

---

### 3. jina-reranker-v3: Last but Not Late Interaction for Document Reranking

- **LLM Score**: 8
- **Keyword Score**: 13
- **Authors**: Feng Wang, Yuqing Li, Han Xiao
- **URL**: <http://arxiv.org/abs/2509.25085v1>
- **Submitted**: 2025-09-29 17:23:54
- **Comment**: early draft, CoIR table needs to be updated
- **Topic Keywords**: query, ranking, rerank, listwise, rank
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, specifically document reranking, with a novel approach that leverages cross-document interactions. The use of causal self-attention and compact architecture aligns with your focus on query understanding and ranking models. However, the paper's focus on document reranking is more specific than your broader interests in query understanding and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: None
- **Aim**: None
- **Rationale**: None
- **Ground**: None
- **Experiment**: None
- **Takeaway**: None

#### Abstract
> jina-reranker-v3 is a 0.6B parameter multilingual document reranker that
introduces a novel last but not late interaction. Unlike late interaction
models such as ColBERT that perform separate encoding followed by multi-vector
matching, our approach conducts causal self-attention between query and
documents within the same context window, enabling rich cross-document
interactions before extracting contextual embeddings from the last token of
each document. This compact architecture achieves state-of-the-art BEIR
performance with 61.94 nDCG@10 while being ten times smaller than generative
listwise rerankers.

---

### 4. Reference-Free Rating of LLM Responses via Latent Information

- **LLM Score**: 8
- **Keyword Score**: 10
- **Authors**: Leander Girrbach, Chi-Ping Su, Tankred Saanum, Richard Socher, Eric Schulz, Zeynep Akata
- **URL**: <http://arxiv.org/abs/2509.24678v1>
- **Submitted**: 2025-09-29 12:15:52
- **Comment**: 21 pages
- **Topic Keywords**: ranking, listwise, pairwise, rank
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of query understanding and ranking models. The paper explores the use of latent information to derive deterministic and more discriminative signals for reference-free evaluation, which aligns with your focus on real-time relevance optimization. While not directly related to e-commerce, the paper's findings have implications for various applications, including search technologies.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: None
- **Aim**: None
- **Rationale**: None
- **Ground**: None
- **Experiment**: None
- **Takeaway**: None

#### Abstract
> How reliable are single-response LLM-as-a-judge ratings without references,
and can we obtain fine-grained, deterministic scores in this setting? We study
the common practice of asking a judge model to assign Likert-scale scores to
free-text responses and show two systematic issues: scores are unstable under
sampling and poorly calibrated, leading to compression near the top of the
scale and frequent ties. We then propose and evaluate Latent Judges, which
derive scalar ratings from internal model signals: (i) probability-weighted
scores over integer ratings, (ii) verifier-style probabilities of "yes", and
(iii) linear probes trained on model activations at the rating position. Across
a broad suite of pairwise and single-rating benchmarks, latent methods match or
surpass standard prompting, with consistent gains on pairwise accuracy and
listwise ranking relevant to Best-of-N selection. Probability-weighted scores
achieve the strongest single-rating correlations, while probes recover useful
signals when output logits are miscalibrated. These results indicate that
latent information provides deterministic and more discriminative signals for
reference-free evaluation, and can improve selection and training approaches
like Best-of-$N$, multi-teacher distillation, and routing.

---

### 5. AceSearcher: Bootstrapping Reasoning and Search for LLMs via Reinforced Self-Play

- **LLM Score**: 8
- **Keyword Score**: 8
- **Authors**: Ran Xu, Yuchen Zhuang, Zihan Dong, Jonathan Wang, Yue Yu, Joyce C. Ho, Linjun Zhang, Haoyu Wang, Wenqi Shi, Carl Yang
- **URL**: <http://arxiv.org/abs/2509.24193v1>
- **Submitted**: 2025-09-29 02:14:30
- **Comment**: Accepted to NeurIPS 2025 (Spotlight)
- **Topic Keywords**: queries, rag, retrieval, search
- **Reason**: This paper proposes a novel framework, AceSearcher, that combines reasoning and search capabilities for large language models. Although it's primarily focused on reasoning tasks, it involves search-augmented LLMs, which aligns with your interests in Information Retrieval and Search technologies. The paper's emphasis on deep semantic understanding and real-time relevance optimization also resonates with your research focus.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: None
- **Aim**: None
- **Rationale**: None
- **Ground**: None
- **Experiment**: None
- **Takeaway**: None

#### Abstract
> Search-augmented LLMs often struggle with complex reasoning tasks due to
ineffective multi-hop retrieval and limited reasoning ability. We propose
AceSearcher, a cooperative self-play framework that trains a single large
language model (LLM) to alternate between two roles: a decomposer that breaks
down complex queries and a solver that integrates retrieved contexts for answer
generation. AceSearcher couples supervised fine-tuning on a diverse mixture of
search, reasoning, and decomposition tasks with reinforcement fine-tuning
optimized for final answer accuracy, eliminating the need for intermediate
annotations. Extensive experiments on three reasoning-intensive tasks across 10
datasets show that AceSearcher outperforms state-of-the-art baselines,
achieving an average exact match improvement of 7.6%. Remarkably, on
document-level finance reasoning tasks, AceSearcher-32B matches the performance
of the DeepSeek-V3 model using less than 5% of its parameters. Even at smaller
scales (1.5B and 8B), AceSearcher often surpasses existing search-augmented
LLMs with up to 9x more parameters, highlighting its exceptional efficiency and
effectiveness in tackling complex reasoning tasks. Our code will be published
at https://github.com/ritaranx/AceSearcher and
https://huggingface.co/AceSearcher.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. PET: Preference Evolution Tracking with LLM-Generated Explainable Distribution

- **LLM Score**: 8
- **Keyword Score**: 5
- **Authors**: Luyang Zhang, Siyuan Peng, Jialu Wang, Shichao Zhu, Beibei Li, Zhongcun Wang, Guangmou Pan, Yan Li, Song Yang
- **URL**: <http://arxiv.org/abs/2509.24189v1>
- **Submitted**: 2025-09-29 02:09:15
- **Topic Keywords**: ranking, personalization, rank
- **Reason**: This paper aligns well with your research interests in Information Retrieval, particularly in query understanding and ranking models. The use of Large Language Models (LLMs) for preference tracking and the focus on improving ranking quality through transparent preference learning are relevant to your work. However, the specific application to user preference evolution and short-video platforms is somewhat outside your primary focus on e-commerce and real-time relevance optimization.

#### Abstract
> Understanding how user preference evolves over time is a fundamental
challenge central to modern digital ecosystems, for which Large Language Models
(LLMs) are an increasingly prominent and popular approach due to their ability
to comprehend the rich semantic context within behavioral data. A common
practice is to use LLMs to predict a user's next action by directly generating
a ranked list of preferred items. Although effective for short-term prediction,
the end-to-end generation paradigm inherently limits personalization. Its
opaque decision-making process obscures holistic user profiling and exacerbates
popularity bias. To address these limitations, we propose Preference Evolution
Tracking (PET), a framework that reframes the task as inferring a dynamic
probability distribution over a stable and interpretable lattice of preference
clusters. By applying logit-probing and generative classification techniques,
PET infers a user's preference as a probability distribution, enabling
transparent preference learning. On public benchmarks (Yelp, MovieLens), PET
improves ranking quality by up to 40% in NDCG over direct generation baselines.
On a large-scale, real-world dataset from a short-video platform, it excels at
ranking long-tail contents, significantly outperforming a SOTA production model
by 7 times in the NDCG score. Ultimately, PET transforms the user profile model
from direct preference list generation to a transparent distributional
preference mapping, paving the way for more explainable, fair, and diverse
personalization systems.

### 7. Investigating Language and Retrieval Bias in Multilingual Previously Fact-Checked Claim Detection

- **LLM Score**: 6
- **Keyword Score**: 8
- **Authors**: Ivan Vykopal, Antonia Karamolegkou, Jaroslav Kopƒçan, Qiwei Peng, Tom√°≈° Jav≈Ørek, Michal Gregor, Mari√°n ≈†imko
- **URL**: <http://arxiv.org/abs/2509.25138v1>
- **Submitted**: 2025-09-29 17:50:32
- **Topic Keywords**: information retrieval, rag, retrieval, recommend
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of multilingual fact-checking and language bias. However, the focus on Large Language Models and fact-checking claim detection is not a central match with your primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Multilingual Large Language Models (LLMs) offer powerful capabilities for
cross-lingual fact-checking. However, these models often exhibit language bias,
performing disproportionately better on high-resource languages such as English
than on low-resource counterparts. We also present and inspect a novel concept
- retrieval bias, when information retrieval systems tend to favor certain
information over others, leaving the retrieval process skewed. In this paper,
we study language and retrieval bias in the context of Previously Fact-Checked
Claim Detection (PFCD). We evaluate six open-source multilingual LLMs across 20
languages using a fully multilingual prompting strategy, leveraging the AMC-16K
dataset. By translating task prompts into each language, we uncover disparities
in monolingual and cross-lingual performance and identify key trends based on
model family, size, and prompting strategy. Our findings highlight persistent
bias in LLM behavior and offer recommendations for improving equity in
multilingual fact-checking. To investigate retrieval bias, we employed
multilingual embedding models and look into the frequency of retrieved claims.
Our analysis reveals that certain claims are retrieved disproportionately
across different posts, leading to inflated retrieval performance for popular
claims while under-representing less common ones.

### 8. MRAG-Suite: A Diagnostic Evaluation Platform for Visual Retrieval-Augmented Generation

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Yuelyu Ji
- **URL**: <http://arxiv.org/abs/2509.24253v1>
- **Submitted**: 2025-09-29 03:55:28
- **Topic Keywords**: query, queries, rag, retrieval
- **Reason**: The paper discusses Visual Retrieval-Augmented Generation, which is a related area to Information Retrieval, but it focuses more on multimodal benchmarks and diagnostic evaluation rather than query understanding, ranking models, or user behavior modeling. While it touches on the importance of query difficulty and ambiguity, it doesn't directly align with the user's core research themes.

#### Abstract
> Multimodal Retrieval-Augmented Generation (Visual RAG) significantly advances
question answering by integrating visual and textual evidence. Yet, current
evaluations fail to systematically account for query difficulty and ambiguity.
We propose MRAG-Suite, a diagnostic evaluation platform integrating diverse
multimodal benchmarks (WebQA, Chart-RAG, Visual-RAG, MRAG-Bench). We introduce
difficulty-based and ambiguity-aware filtering strategies, alongside
MM-RAGChecker, a claim-level diagnostic tool. Our results demonstrate
substantial accuracy reductions under difficult and ambiguous queries,
highlighting prevalent hallucinations. MM-RAGChecker effectively diagnoses
these issues, guiding future improvements in Visual RAG systems.

### 9. Generalist Scanner Meets Specialist Locator: A Synergistic Coarse-to-Fine Framework for Robust GUI Grounding

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Zhecheng Li, Guoxian Song, Yiwei Wang, Zhen Xiong, Junsong Yuan, Yujun Cai
- **URL**: <http://arxiv.org/abs/2509.24133v1>
- **Submitted**: 2025-09-29 00:06:31
- **Topic Keywords**: queries, rag, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of query understanding and user behavior modeling. However, the focus on GUI grounding and graphical user interfaces is not directly aligned with your primary interests in search technologies and deep semantic understanding. The paper's use of vision-language models and hierarchical search is an interesting aspect, but it doesn't strongly connect to your core themes.

#### Abstract
> Grounding natural language queries in graphical user interfaces (GUIs)
presents a challenging task that requires models to comprehend diverse UI
elements across various applications and systems, while also accurately
predicting the spatial coordinates for the intended operation. To tackle this
problem, we propose GMS: Generalist Scanner Meets Specialist Locator, a
synergistic coarse-to-fine framework that effectively improves GUI grounding
performance. GMS leverages the complementary strengths of general
vision-language models (VLMs) and small, task-specific GUI grounding models by
assigning them distinct roles within the framework. Specifically, the general
VLM acts as a 'Scanner' to identify potential regions of interest, while the
fine-tuned grounding model serves as a 'Locator' that outputs precise
coordinates within these regions. This design is inspired by how humans perform
GUI grounding, where the eyes scan the interface and the brain focuses on
interpretation and localization. Our whole framework consists of five stages
and incorporates hierarchical search with cross-modal communication to achieve
promising prediction results. Experimental results on the ScreenSpot-Pro
dataset show that while the 'Scanner' and 'Locator' models achieve only $2.0\%$
and $3.7\%$ accuracy respectively when used independently, their integration
within GMS framework yields an overall accuracy of $35.7\%$, representing a $10
\times$ improvement. Additionally, GMS significantly outperforms other strong
baselines under various settings, demonstrating its robustness and potential
for general-purpose GUI grounding.

### 10. Towards Personalized Deep Research: Benchmarks and Evaluations

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Yuan Liang, Jiaxian Li, Yuqing Wang, Piaohong Wang, Motong Tian, Pai Liu, Shuofei Qiao, Runnan Fang, He Zhu, Ge Zhang, Minghao Liu, Yuchen Eleanor Jiang, Ningyu Zhang, Wangchunshu Zhou
- **URL**: <http://arxiv.org/abs/2509.25106v1>
- **Submitted**: 2025-09-29 17:39:17
- **Topic Keywords**: queries, personalization, search
- **Reason**: The paper discusses Personalized Deep Research Benchmarks and Evaluations, which is somewhat related to information retrieval and search technologies, particularly in the context of user behavior modeling and query understanding. However, the focus on AI research assistants and personalized scenarios is not directly aligned with the user's core research themes in e-commerce and real-time relevance optimization. The paper's relevance to NLP and data mining is also limited.

#### Abstract
> Deep Research Agents (DRAs) can autonomously conduct complex investigations
and generate comprehensive reports, demonstrating strong real-world potential.
However, existing evaluations mostly rely on close-ended benchmarks, while
open-ended deep research benchmarks remain scarce and typically neglect
personalized scenarios. To bridge this gap, we introduce Personalized Deep
Research Bench, the first benchmark for evaluating personalization in DRAs. It
pairs 50 diverse research tasks across 10 domains with 25 authentic user
profiles that combine structured persona attributes with dynamic real-world
contexts, yielding 250 realistic user-task queries. To assess system
performance, we propose the PQR Evaluation Framework, which jointly measures
(P) Personalization Alignment, (Q) Content Quality, and (R) Factual
Reliability. Our experiments on a range of systems highlight current
capabilities and limitations in handling personalized deep research. This work
establishes a rigorous foundation for developing and evaluating the next
generation of truly personalized AI research assistants.

### 11. Latent Visual Reasoning

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Bangzheng Li, Ximeng Sun, Jiang Liu, Ze Wang, Jialian Wu, Xiaodong Yu, Hao Chen, Emad Barsoum, Muhao Chen, Zicheng Liu
- **URL**: <http://arxiv.org/abs/2509.24251v1>
- **Submitted**: 2025-09-29 03:52:01
- **Topic Keywords**: query, rag
- **Reason**: This paper introduces Latent Visual Reasoning (LVR), a paradigm that enables autoregressive reasoning directly in the visual embedding space. While it combines visual and language understanding, the focus is on visual question answering and perception-intensive tasks, which is somewhat related to information retrieval but not directly aligned with your core research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Multimodal Large Language Models (MLLMs) have achieved notable gains in
various tasks by incorporating Chain-of-Thought (CoT) reasoning in language
spaces. Recent work extends this direction by leveraging external tools for
visual editing, thereby enhancing the visual signal along the reasoning
trajectories. Nevertheless, these approaches remain fundamentally constrained:
reasoning is still confined to the language space, with visual information
treated as static preconditions. We introduce Latent Visual Reasoning (LVR), a
new paradigm that enables autoregressive reasoning directly in the visual
embedding space. A visual encoder first projects images into visual tokens
within a joint semantic space shared with the language model. The language
model is then trained to generate latent states that reconstruct key visual
tokens critical for answering the query, constituting the process of latent
visual reasoning. By interleaving LVR with standard text generation, our model
achieves substantial gains on perception-intensive visual question answering
tasks. In addition, we adapt the GRPO algorithm to conduct reinforcement
learning on latent reasoning, further balancing LVR and textual generation. We
show that LVR substantially improves fine-grained visual understanding and
perception, achieving 71.67% on MMVP compared to 66.67% with Qwen2.5-VL. Code
base and model weights will be released later.

### 12. Beyond Overall Accuracy: A Psychometric Deep Dive into the Topic-Specific Medical Capabilities of 80 Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Zhimeng Luo, Lixin Wu, Adam Frisch, Daqing He
- **URL**: <http://arxiv.org/abs/2509.24186v1>
- **Submitted**: 2025-09-29 02:06:13
- **Topic Keywords**: ranking, rank, search
- **Reason**: The paper is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, but it focuses on evaluating Large Language Models in a medical context, which is not a central match to the user's research themes. While it involves deep semantic understanding and ranking models, the application domain is healthcare, and the evaluation framework is psychometric, which is not directly related to the user's interests in search technologies and user behavior modeling.

#### Abstract
> As Large Language Models (LLMs) are increasingly proposed for high-stakes
medical applications, there has emerged a critical need for reliable and
accurate evaluation methodologies. Traditional accuracy metrics fail
inadequately as they neither capture question characteristics nor offer
topic-specific insights. To address this gap, we introduce \textsc{MedIRT}, a
rigorous evaluation framework grounded in Item Response Theory (IRT), the gold
standard in high-stakes educational testing. Unlike previous research relying
on archival data, we prospectively gathered fresh responses from 80 diverse
LLMs on a balanced, 1,100-question USMLE-aligned benchmark. Using one
unidimensional two-parameter logistic IRT model per topic, we estimate LLM's
latent model ability jointly with question difficulty and discrimination,
yielding more stable and nuanced performance rankings than accuracy alone.
Notably, we identify distinctive ``spiky'' ability profiles, where overall
rankings can be misleading due to highly specialized model abilities. While
\texttt{GPT-5} was the top performer in a majority of domains (8 of 11), it was
outperformed in Social Science and Communication by \texttt{Claude-3-opus},
demonstrating that even an overall 23rd-ranked model can hold the top spot for
specific competencies. Furthermore, we demonstrate IRT's utility in auditing
benchmarks by identifying flawed questions. We synthesize these findings into a
practical decision-support framework that integrates our multi-factor
competency profiles with operational metrics. This work establishes a robust,
psychometrically grounded methodology essential for the safe, effective, and
trustworthy deployment of LLMs in healthcare.

### 13. SemanticShield: LLM-Powered Audits Expose Shilling Attacks in Recommender Systems

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Kaihong Li, Huichi Zhou, Bin Ma, Fangjun Huang
- **URL**: <http://arxiv.org/abs/2509.24961v1>
- **Submitted**: 2025-09-29 15:53:47
- **Topic Keywords**: recommend, commerce, e-commerce, rank
- **Reason**: The paper is somewhat related to information retrieval, but its focus on recommender systems and shilling attacks is not a central match to your core research themes. However, the use of large language models and semantic understanding is relevant to your interests in NLP and query understanding.

#### Abstract
> Recommender systems (RS) are widely used in e-commerce for personalized
suggestions, yet their openness makes them susceptible to shilling attacks,
where adversaries inject fake behaviors to manipulate recommendations. Most
existing defenses emphasize user-side behaviors while overlooking item-side
features such as titles and descriptions that can expose malicious intent. To
address this gap, we propose a two-stage detection framework that integrates
item-side semantics via large language models (LLMs). The first stage
pre-screens suspicious users using low-cost behavioral criteria, and the second
stage employs LLM-based auditing to evaluate semantic consistency. Furthermore,
we enhance the auditing model through reinforcement fine-tuning on a
lightweight LLM with carefully designed reward functions, yielding a
specialized detector called SemanticShield. Experiments on six representative
attack strategies demonstrate the effectiveness of SemanticShield against
shilling attacks, and further evaluation on previously unseen attack methods
shows its strong generalization capability. Code is available at
https://github.com/FrankenstLee/SemanticShield.

### 14. Metaphor identification using large language models: A comparison of RAG, prompt engineering, and fine-tuning

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Matteo Fuoli, Weihang Huang, Jeannette Littlemore, Sarah Turner, Ellen Wilding
- **URL**: <http://arxiv.org/abs/2509.24866v1>
- **Submitted**: 2025-09-29 14:50:18
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper explores the application of large language models in metaphor identification, which is a topic related to NLP and deep semantic understanding. However, it doesn't directly align with the user's primary focus on information retrieval, query understanding, and ranking models.

#### Abstract
> Metaphor is a pervasive feature of discourse and a powerful lens for
examining cognition, emotion, and ideology. Large-scale analysis, however, has
been constrained by the need for manual annotation due to the context-sensitive
nature of metaphor. This study investigates the potential of large language
models (LLMs) to automate metaphor identification in full texts. We compare
three methods: (i) retrieval-augmented generation (RAG), where the model is
provided with a codebook and instructed to annotate texts based on its rules
and examples; (ii) prompt engineering, where we design task-specific verbal
instructions; and (iii) fine-tuning, where the model is trained on hand-coded
texts to optimize performance. Within prompt engineering, we test zero-shot,
few-shot, and chain-of-thought strategies. Our results show that
state-of-the-art closed-source LLMs can achieve high accuracy, with fine-tuning
yielding a median F1 score of 0.79. A comparison of human and LLM outputs
reveals that most discrepancies are systematic, reflecting well-known grey
areas and conceptual challenges in metaphor theory. We propose that LLMs can be
used to at least partly automate metaphor identification and can serve as a
testbed for developing and refining metaphor identification protocols and the
theory that underpins them.

### 15. ScenarioBench: Trace-Grounded Compliance Evaluation for Text-to-SQL and RAG

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Zahra Atf, Peter R Lewis
- **URL**: <http://arxiv.org/abs/2509.24212v1>
- **Submitted**: 2025-09-29 02:51:08
- **Comment**: Accepted for presentation at the LLMs Meet Databases (LMD) Workshop,
  35th IEEE International Conference on Collaborative Advances in Software and
  Computing, 2025. Workshop website: https://sites.google.com/view/lmd2025/home
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper introduces a benchmark for evaluating Text-to-SQL and retrieval-augmented generation systems, which is somewhat related to information retrieval and NLP, but not directly focused on query understanding, ranking models, or user behavior modeling. While it touches on aspects of deep semantic understanding, its primary focus is on compliance evaluation and justification quality, which is not a central match for your research interests.

#### Abstract
> ScenarioBench is a policy-grounded, trace-aware benchmark for evaluating
Text-to-SQL and retrieval-augmented generation in compliance contexts. Each
YAML scenario includes a no-peek gold-standard package with the expected
decision, a minimal witness trace, the governing clause set, and the canonical
SQL, enabling end-to-end scoring of both what a system decides and why. Systems
must justify outputs using clause IDs from the same policy canon, making
explanations falsifiable and audit-ready. The evaluator reports decision
accuracy, trace quality (completeness, correctness, order), retrieval
effectiveness, SQL correctness via result-set equivalence, policy coverage,
latency, and an explanation-hallucination rate. A normalized Scenario
Difficulty Index (SDI) and a budgeted variant (SDI-R) aggregate results while
accounting for retrieval difficulty and time. Compared with prior Text-to-SQL
or KILT/RAG benchmarks, ScenarioBench ties each decision to clause-level
evidence under strict grounding and no-peek rules, shifting gains toward
justification quality under explicit time budgets.

### 16. Retrieval-augmented GUI Agents with Generative Guidelines

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Ran Xu, Kaixin Ma, Wenhao Yu, Hongming Zhang, Joyce C. Ho, Carl Yang, Dong Yu
- **URL**: <http://arxiv.org/abs/2509.24183v1>
- **Submitted**: 2025-09-29 02:04:20
- **Comment**: Accepted to EMNLP 2025 (Main Conference)
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper explores the application of vision-language models in GUI agents, which is somewhat related to information retrieval, but the focus is more on NLP and model development. The paper's emphasis on real-world applications and practical plug-and-play capabilities is also relevant, but it does not directly address query understanding, ranking models, or user behavior modeling.

#### Abstract
> GUI agents powered by vision-language models (VLMs) show promise in
automating complex digital tasks. However, their effectiveness in real-world
applications is often limited by scarce training data and the inherent
complexity of these tasks, which frequently require long-tailed knowledge
covering rare, unseen scenarios. We propose RAG-GUI , a lightweight VLM that
leverages web tutorials at inference time. RAG-GUI is first warm-started via
supervised finetuning (SFT) and further refined through self-guided rejection
sampling finetuning (RSF). Designed to be model-agnostic, RAG-GUI functions as
a generic plug-in that enhances any VLM-based agent. Evaluated across three
distinct tasks, it consistently outperforms baseline agents and surpasses other
inference baselines by 2.6% to 13.3% across two model sizes, demonstrating
strong generalization and practical plug-and-play capabilities in real-world
scenarios.

### 17. GateMABSA: Aspect-Image Gated Fusion for Multimodal Aspect-based Sentiment Analysis

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Adamu Lawan, Haruna Yunusa
- **URL**: <http://arxiv.org/abs/2509.25037v1>
- **Submitted**: 2025-09-29 16:56:10
- **Comment**: 6 pages, 2 tables
- **Topic Keywords**: relevance
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and multimodal analysis, but it is not directly focused on Information Retrieval (IR) or query understanding. While it involves deep semantic understanding and multimodal fusion, its primary goal is sentiment analysis, which is a different application area.

#### Abstract
> Aspect-based Sentiment Analysis (ABSA) has recently advanced into the
multimodal domain, where user-generated content often combines text and images.
However, existing multimodal ABSA (MABSA) models struggle to filter noisy
visual signals, and effectively align aspects with opinion-bearing content
across modalities. To address these challenges, we propose GateMABSA, a novel
gated multimodal architecture that integrates syntactic, semantic, and
fusion-aware mLSTM. Specifically, GateMABSA introduces three specialized
mLSTMs: Syn-mLSTM to incorporate syntactic structure, Sem-mLSTM to emphasize
aspect--semantic relevance, and Fuse-mLSTM to perform selective multimodal
fusion. Extensive experiments on two benchmark Twitter datasets demonstrate
that GateMABSA outperforms several baselines.

### 18. Building Benchmarks from the Ground Up: Community-Centered Evaluation of LLMs in Healthcare Chatbot Settings

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Hamna, Gayatri Bhat, Sourabrata Mukherjee, Faisal Lalani, Evan Hadfield, Divya Siddarth, Kalika Bali, Sunayana Sitaram
- **URL**: <http://arxiv.org/abs/2509.24506v1>
- **Submitted**: 2025-09-29 09:20:15
- **Topic Keywords**: queries
- **Reason**: The paper discusses the evaluation of Large Language Models (LLMs) in a specific domain (healthcare), which is somewhat related to information retrieval and search technologies. However, the focus on LLMs and community-driven evaluation is not directly aligned with the user's primary research interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large Language Models (LLMs) are typically evaluated through general or
domain-specific benchmarks testing capabilities that often lack grounding in
the lived realities of end users. Critical domains such as healthcare require
evaluations that extend beyond artificial or simulated tasks to reflect the
everyday needs, cultural practices, and nuanced contexts of communities. We
propose Samiksha, a community-driven evaluation pipeline co-created with
civil-society organizations (CSOs) and community members. Our approach enables
scalable, automated benchmarking through a culturally aware, community-driven
pipeline in which community feedback informs what to evaluate, how the
benchmark is built, and how outputs are scored. We demonstrate this approach in
the health domain in India. Our analysis highlights how current multilingual
LLMs address nuanced community health queries, while also offering a scalable
pathway for contextually grounded and inclusive LLM evaluation.

### 19. Overview of SCIDOCA 2025 Shared Task on Citation Prediction, Discovery, and Placement

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: An Dao, Vu Tran, Le-Minh Nguyen, Yuji Matsumoto
- **URL**: <http://arxiv.org/abs/2509.24283v1>
- **Submitted**: 2025-09-29 04:55:18
- **Comment**: 16 pages, SCIDOCA 2025
- **Topic Keywords**: rag, search
- **Reason**: The paper is somewhat related to the user's interests in Information Retrieval, specifically in the area of citation modeling and scientific document understanding. However, it is not directly focused on query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user. The paper's focus on citation prediction and discovery is somewhat tangential to the user's primary research themes.

#### Abstract
> We present an overview of the SCIDOCA 2025 Shared Task, which focuses on
citation discovery and prediction in scientific documents. The task is divided
into three subtasks: (1) Citation Discovery, where systems must identify
relevant references for a given paragraph; (2) Masked Citation Prediction,
which requires selecting the correct citation for masked citation slots; and
(3) Citation Sentence Prediction, where systems must determine the correct
reference for each cited sentence. We release a large-scale dataset constructed
from the Semantic Scholar Open Research Corpus (S2ORC), containing over 60,000
annotated paragraphs and a curated reference set. The test set consists of
1,000 paragraphs from distinct papers, each annotated with ground-truth
citations and distractor candidates. A total of seven teams registered, with
three submitting results. We report performance metrics across all subtasks and
analyze the effectiveness of submitted systems. This shared task provides a new
benchmark for evaluating citation modeling and encourages future research in
scientific document understanding. The dataset and task materials are publicly
available at https://github.com/daotuanan/scidoca2025-shared-task.

### 20. SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Gyuhyeon Seo, Jungwoo Yang, Junseong Pyo, Nalim Kim, Jonggeun Lee, Yohan Jo
- **URL**: <http://arxiv.org/abs/2509.24282v1>
- **Submitted**: 2025-09-29 04:54:20
- **Topic Keywords**: query
- **Reason**: The paper SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents is somewhat related to your research interests in Information Retrieval and Natural Language Processing, particularly in the context of query understanding and deep semantic understanding. However, the focus on smart home agents and the Matter protocol is not directly aligned with your core research themes, and the paper's emphasis on temporal dependencies and device constraints is more relevant to areas like recommender systems or user behavior modeling.

#### Abstract
> Large Language Model (LLM) agents excel at multi-step, tool-augmented tasks.
However, smart homes introduce distinct challenges, requiring agents to handle
latent user intents, temporal dependencies, device constraints, scheduling, and
more. The main bottlenecks for developing smart home agents with such
capabilities include the lack of a realistic simulation environment where
agents can interact with devices and observe the results, as well as a
challenging benchmark to evaluate them. To address this, we introduce
$\textbf{SimuHome}$, a time-accelerated home environment that simulates smart
devices, supports API calls, and reflects changes in environmental variables.
By building the simulator on the Matter protocol (the global industry standard
for smart home communication), SimuHome provides a high-fidelity environment,
and agents validated in SimuHome can be deployed on real Matter-compliant
devices with minimal adaptation. We provide a challenging benchmark of 600
episodes across twelve user query types that require the aforementioned
capabilities. Our evaluation of 11 agents under a unified ReAct framework
reveals that while models perform well on simple tasks, they struggle with
latent intent inference, state verification, and especially temporal
scheduling. Even the top-performing model, GPT-4.1, reaches only 54% success
rate. These findings highlight a critical need for methods that can reliably
verify the current state via tools before acting and coordinate time-dependent
actions.

### 21. Towards Trustworthy Lexical Simplification: Exploring Safety and Efficiency with Small LLMs

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Akio Hayakawa, Stefan Bott, Horacio Saggion
- **URL**: <http://arxiv.org/abs/2509.25086v1>
- **Submitted**: 2025-09-29 17:25:56
- **Topic Keywords**: rag
- **Reason**: The paper explores lexical simplification using small LLMs, which is related to NLP, but it doesn't directly align with the user's primary focus on information retrieval, query understanding, and ranking models. The paper's emphasis on safety and efficiency in resource-constrained environments is somewhat relevant to the user's e-commerce background, but the connection is not strong enough to warrant a higher score.

#### Abstract
> Despite their strong performance, large language models (LLMs) face
challenges in real-world application of lexical simplification (LS),
particularly in privacy-sensitive and resource-constrained environments.
Moreover, since vulnerable user groups (e.g., people with disabilities) are one
of the key target groups of this technology, it is crucial to ensure the safety
and correctness of the output of LS systems. To address these issues, we
propose an efficient framework for LS systems that utilizes small LLMs
deployable in local environments. Within this framework, we explore knowledge
distillation with synthesized data and in-context learning as baselines. Our
experiments in five languages evaluate model outputs both automatically and
manually. Our manual analysis reveals that while knowledge distillation boosts
automatic metric scores, it also introduces a safety trade-off by increasing
harmful simplifications. Importantly, we find that the model's output
probability is a useful signal for detecting harmful simplifications.
Leveraging this, we propose a filtering strategy that suppresses harmful
simplifications while largely preserving beneficial ones. This work establishes
a benchmark for efficient and safe LS with small LLMs. It highlights the key
trade-offs between performance, efficiency, and safety, and demonstrates a
promising approach for safe real-world deployment.

### 22. Hierarchical Error Correction for Large Language Models: A Systematic Framework for Domain-Specific AI Quality Enhancement

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Zhilong Zhao, Yindi Liu
- **URL**: <http://arxiv.org/abs/2509.24841v1>
- **Submitted**: 2025-09-29 14:21:05
- **Comment**: 10 pages, 4 figures, 4 tables
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Large Language Models and proposes a framework for domain-specific AI quality enhancement. While it touches on error analysis and correction, which is somewhat related to query understanding and ranking models, the primary focus is on NLP and AI quality enhancement, which is not a central match to your research interests in Information Retrieval and Search technologies.

#### Abstract
> Large Language Models face significant performance challenges in specialized
domains, with state-of-the-art models achieving only 45.9% accuracy on medical
coding tasks. This study proposes a Hierarchical Error Correction (HEC)
framework that addresses domain-specific AI limitations through systematic
error analysis and targeted intervention strategies.
  We analyze error patterns across four specialized domains and find that AI
errors follow consistent hierarchical structures: Knowledge-layer errors
(58.4%), Reasoning-layer errors (39.6%), and Complexity-layer errors (2.0%).
Based on these patterns, we develop a three-stage correction framework that
addresses errors according to their hierarchical importance and demonstrates
that framework effectiveness correlates inversely with baseline task
performance.
  Experimental validation across medical transcription (4,921 cases), legal
document classification (1,000 cases), political bias detection (645 cases),
and legal reasoning (1,000 cases) shows consistent improvements. Cross-model
validation across five LLM architectures demonstrates average improvements of
11.2 percentage points (p < 0.001). However, analysis reveals framework
limitations in high-baseline tasks (>75% accuracy), where hierarchical
intervention may interfere with effective reasoning processes.
  The results suggest that systematic error analysis can guide effective AI
enhancement strategies in specialized domains, particularly for
moderate-baseline tasks, while highlighting the importance of understanding
framework boundaries for optimal deployment.

### 23. ProxyAttn: Guided Sparse Attention via Representative Heads

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Yixuan Wang, Huang He, Siqi Bao, Hua Wu, Haifeng Wang, Qingfu Zhu, Wanxiang Che
- **URL**: <http://arxiv.org/abs/2509.24745v1>
- **Submitted**: 2025-09-29 13:10:39
- **Comment**: 14pages, 5figures
- **Topic Keywords**: rag
- **Reason**: This paper proposes a novel sparse attention algorithm, ProxyAttn, which aims to improve the efficiency of Large Language Models. While it touches on attention mechanisms, a key aspect of Information Retrieval, its focus on long-text tasks and language models makes it somewhat relevant to your interests, but not a central match.

#### Abstract
> The quadratic complexity of attention mechanisms limits the efficiency of
Large Language Models (LLMs) on long-text tasks. Recently, methods that
dynamically estimate block importance have enabled efficient block sparse
attention, leading to significant acceleration in long-text pre-filling of
LLMs. However, their coarse-grained estimation inevitably leads to performance
degradation at high sparsity rates. In this work, we propose ProxyAttn, a
training-free sparse attention algorithm that achieves more precise block
estimation by compressing the dimension of attention heads. Based on our
observation of the similarity among multiple attention heads, we use the scores
of pooled representative heads to approximate the scores for all heads. To
account for the varying sparsity among heads, we also propose a block-aware
dynamic budget estimation method. By combining the scores from representative
proxy heads with multi-head dynamic budgets, we achieve a more fine-grained
block importance evaluation at low computational cost. Experiments on a variety
of mainstream models and extensive benchmarks confirm the underlying similarity
among attention heads. Leveraging a fine-grained estimation, the proposed
method achieves substantial gains in performance and efficiency compared to
existing methods. More precisely, ProxyAttn can achieve up to 10.3x attention
acceleration and 2.4x prefilling acceleration without significant performance
loss. Our code is available at https://github.com/wyxstriker/ProxyAttn.

### 24. Do Repetitions Matter? Strengthening Reliability in LLM Evaluations

- **LLM Score**: 2
- **Keyword Score**: 9
- **Authors**: Miguel Angel Alvarado Gonzalez, Michelle Bruno Hernandez, Miguel Angel Pe√±aloza Perez, Bruno Lopez Orozco, Jesus Tadeo Cruz Soto, Sandra Malagon
- **URL**: <http://arxiv.org/abs/2509.24086v1>
- **Submitted**: 2025-09-28 21:45:20
- **Topic Keywords**: ranking, pairwise, rag, rank
- **Reason**: This paper focuses on the reliability of LLM evaluations, specifically the impact of repetition on model rankings. While it touches on aspects of model comparison and evaluation, it doesn't directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest for your research.

#### Abstract
> LLM leaderboards often rely on single stochastic runs, but how many
repetitions are required for reliable conclusions remains unclear. We
re-evaluate eight state-of-the-art models on the AI4Math Benchmark with three
independent runs per setting. Using mixed-effects logistic regression,
domain-level marginal means, rank-instability analysis, and run-to-run
reliability, we assessed the value of additional repetitions. Our findings
shows that Single-run leaderboards are brittle: 10/12 slices (83\%) invert at
least one pairwise rank relative to the three-run majority, despite a zero
sign-flip rate for pairwise significance and moderate overall interclass
correlation. Averaging runs yields modest SE shrinkage ($\sim$5\% from one to
three) but large ranking gains; two runs remove $\sim$83\% of single-run
inversions. We provide cost-aware guidance for practitioners: treat evaluation
as an experiment, report uncertainty, and use $\geq 2$ repetitions under
stochastic decoding. These practices improve robustness while remaining
feasible for small teams and help align model comparisons with real-world
reliability.

### 25. Efficient Sketching and Nearest Neighbor Search Algorithms for Sparse Vector Sets

- **LLM Score**: 2
- **Keyword Score**: 8
- **Authors**: Sebastian Bruch, Franco Maria Nardini, Cosimo Rulli, Rossano Venturini
- **URL**: <http://arxiv.org/abs/2509.24815v1>
- **Submitted**: 2025-09-29 14:02:45
- **Topic Keywords**: query, rag, rank, search, neurips
- **Reason**: This paper focuses on Approximate Nearest Neighbor Search (ANNS) for sparse vector sets, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves efficient algorithms and data structures, the topic is more aligned with data mining and related areas, but not with your primary focus on deep semantic understanding and real-time relevance optimization.

#### Abstract
> Sparse embeddings of data form an attractive class due to their inherent
interpretability: Every dimension is tied to a term in some vocabulary, making
it easy to visually decipher the latent space. Sparsity, however, poses unique
challenges for Approximate Nearest Neighbor Search (ANNS) which finds, from a
collection of vectors, the k vectors closest to a query. To encourage research
on this underexplored topic, sparse ANNS featured prominently in a BigANN
Challenge at NeurIPS 2023, where approximate algorithms were evaluated on large
benchmark datasets by throughput and accuracy. In this work, we introduce a set
of novel data structures and algorithmic methods, a combination of which leads
to an elegant, effective, and highly efficient solution to sparse ANNS. Our
contributions range from a theoretically-grounded sketching algorithm for
sparse vectors to reduce their effective dimensionality while preserving inner
product-induced ranks; a geometric organization of the inverted index; and the
blending of local and global information to improve the efficiency and efficacy
of ANNS. Empirically, our final algorithm, dubbed Seismic, reaches
sub-millisecond per-query latency with high accuracy on a large-scale benchmark
dataset using a single CPU.

### 26. Scaling Generalist Data-Analytic Agents

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Shuofei Qiao, Yanqiu Zhao, Zhisong Qiu, Xiaobin Wang, Jintian Zhang, Zhao Bin, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen
- **URL**: <http://arxiv.org/abs/2509.25084v1>
- **Submitted**: 2025-09-29 17:23:08
- **Comment**: Work in progress
- **Topic Keywords**: queries, rag, search
- **Reason**: This paper focuses on data-analytic agents and their training, which is not directly related to information retrieval, search technologies, or natural language processing. While it involves some AI-related concepts, the paper's primary focus on data analysis and agent training does not align with the user's core research interests.

#### Abstract
> Data-analytic agents are emerging as a key catalyst for automated scientific
discovery and for the vision of Innovating AI. Current approaches, however,
rely heavily on prompt engineering over proprietary models, while open-source
models struggle to face diverse-format, large-scale data files and
long-horizon, multi-step reasoning that real-world analytics demands. This
paper introduces DataMind, a scalable data synthesis and agent training recipe
designed to build generalist data-analytic agents. DataMind tackles three key
challenges in building open-source data-analytic agents, including insufficient
data resources, improper training strategy, and unstable code-based multi-turn
rollout. Concretely, DataMind applies 1) a fine-grained task taxonomy and a
recursive easy-to-hard task composition mechanism to increase the diversity and
difficulty of synthesized queries; 2) a knowledge-augmented trajectory sampling
strategy followed by model-based and rule-based filtering; 3) a dynamically
adjustable training objective combining both SFT and RL losses; 4) a
memory-frugal and stable code-based multi-turn rollout framework. Built on
DataMind, we curate DataMind-12K, a high-quality trajectory set spanning
diverse domains, task categories, and data file formats for data-analytic
tasks. Trained on DataMind-12K, our DataMind-14B achieves state-of-the-art with
an average score of 71.16% on multiple data analysis benchmarks, outperforming
the strongest proprietary baselines DeepSeek-V3.1 and GPT-5. Our DataMind-7B
also performs best among all open-source models with a score of 68.10%. We also
incorporate some empirical insights gained from our exploratory trials into the
analysis experiments, aiming to provide actionable insights about agentic
training for the community. We will release DataMind-12K and DataMind-7B,14B
for the community's future research.

### 27. Agentar-Scale-SQL: Advancing Text-to-SQL through Orchestrated Test-Time Scaling

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Pengfei Wang, Baolin Sun, Xuemei Dong, Yaxun Dai, Hongwei Yuan, Mengdie Chu, Yingqi Gao, Xiang Qi, Peng Zhang, Ying Yan
- **URL**: <http://arxiv.org/abs/2509.24403v2>
- **Submitted**: 2025-09-29 07:50:02
- **Topic Keywords**: ranking, rag, rank
- **Reason**: While the paper discusses advancements in Text-to-SQL, a subfield of Natural Language Processing, it does not directly relate to the user's primary focus on Information Retrieval, query understanding, ranking models, and user behavior modeling. The paper's focus on test-time scaling and internal reasoning process in Text-to-SQL is somewhat tangential to the user's interests.

#### Abstract
> State-of-the-art (SOTA) Text-to-SQL methods still lag significantly behind
human experts on challenging benchmarks like BIRD. Current approaches that
explore test-time scaling lack an orchestrated strategy and neglect the model's
internal reasoning process. To bridge this gap, we introduce Agentar-Scale-SQL,
a novel framework leveraging scalable computation to improve performance.
Agentar-Scale-SQL implements an Orchestrated Test-Time Scaling strategy that
synergistically combines three distinct perspectives: i) Internal Scaling via
RL-enhanced Intrinsic Reasoning, ii) Sequential Scaling through Iterative
Refinement, and iii) Parallel Scaling using Diverse Synthesis and Tournament
Selection. Agentar-Scale-SQL is a general-purpose framework designed for easy
adaptation to new databases and more powerful language models. Extensive
experiments show that Agentar-Scale-SQL achieves SOTA performance on the BIRD
benchmark, reaching 81.67\% execution accuracy on the test set and ranking
first on the official leaderboard, demonstrating an effective path toward
human-level performance.

### 28. Ultra-Fast Language Generation via Discrete Diffusion Divergence Instruct

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Haoyang Zheng, Xinyang Liu, Cindy Xiangrui Kong, Nan Jiang, Zheyuan Hu, Weijian Luo, Wei Deng, Guang Lin
- **URL**: <http://arxiv.org/abs/2509.25035v1>
- **Submitted**: 2025-09-29 16:55:44
- **Comment**: 56 pages, 7 figures, 7 tables
- **Topic Keywords**: ltr, rag
- **Reason**: This paper focuses on ultra-fast language generation using discrete diffusion divergence instruct, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing, the primary application and methodology are not aligned with the user's core research themes.

#### Abstract
> Fast generation of language texts is the holy grail that people pursue in the
AI era. In this work, we introduced Discrete Diffusion Divergence Instruct
(DiDi-Instruct), a training-based method that leads to fast language generation
models by initializing from a pre-trained (masked) discrete diffusion language
model (dLLM). The resulting DiDi-Instruct model outperforms the dLLM
counterparts and the GPT-2 baseline with 64x acceleration. In the theoretical
part of the paper, we build the foundation of DiDi-Instruct in a framework of
integral KL-divergence minimization, with practical training algorithms. We
also introduce techniques like grouped reward normalization, intermediate-state
matching, and the reward-guided ancestral sampler (RGAS) that significantly
improve the training stability, the model coverage, and the inference
performances. On OpenWebText, DiDi-Instruct outperforms all accelerated
language generation models as well as the GPT-2 baseline and the standard
dLLMs, achieving sample perplexities ranging from 62.2 (8 NFEs) to 18.4 (128
NFEs). These performance gains are accomplished with a negligible entropy loss
of about 1% and 20x less additional training wall-clock time. We further
validate the robustness and effectiveness of DiDi-Instruct through extensive
ablation studies, model scaling, and the generation of discrete protein
sequences. In conclusion, DiDi-Instruct is an efficient yet effective
distillation method, enabling language generation in the blink of an eye. We
will release both code and models at github.com/haoyangzheng-ai/didi-instruct.

### 29. KnowGuard: Knowledge-Driven Abstention for Multi-Round Clinical Reasoning

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Xilin Dang, Kexin Chen, Xiaorui Su, Ayush Noori, I√±aki Arango, Lucas Vittor, Xinyi Long, Yuyang Du, Marinka Zitnik, Pheng Ann Heng
- **URL**: <http://arxiv.org/abs/2509.24816v1>
- **Submitted**: 2025-09-29 14:03:01
- **Topic Keywords**: rag, retrieval, rank
- **Reason**: This paper focuses on clinical reasoning and abstention in medical scenarios, using large language models and knowledge graphs. While it involves some aspects of information retrieval and knowledge understanding, it is not directly related to the user's core research themes in information retrieval, search technologies, or e-commerce domain.

#### Abstract
> In clinical practice, physicians refrain from making decisions when patient
information is insufficient. This behavior, known as abstention, is a critical
safety mechanism preventing potentially harmful misdiagnoses. Recent
investigations have reported the application of large language models (LLMs) in
medical scenarios. However, existing LLMs struggle with the abstentions,
frequently providing overconfident responses despite incomplete information.
This limitation stems from conventional abstention methods relying solely on
model self-assessments, which lack systematic strategies to identify knowledge
boundaries with external medical evidences. To address this, we propose
\textbf{KnowGuard}, a novel \textit{investigate-before-abstain} paradigm that
integrates systematic knowledge graph exploration for clinical decision-making.
Our approach consists of two key stages operating on a shared contextualized
evidence pool: 1) an evidence discovery stage that systematically explores the
medical knowledge space through graph expansion and direct retrieval, and 2) an
evidence evaluation stage that ranks evidence using multiple factors to adapt
exploration based on patient context and conversation history. This two-stage
approach enables systematic knowledge graph exploration, allowing models to
trace structured reasoning paths and recognize insufficient medical evidence.
We evaluate our abstention approach using open-ended multi-round clinical
benchmarks that mimic realistic diagnostic scenarios, assessing abstention
quality through accuracy-efficiency trade-offs beyond existing closed-form
evaluations. Experimental evidences clearly demonstrate that KnowGuard
outperforms state-of-the-art abstention approaches, improving diagnostic
accuracy by 3.93\% while reducing unnecessary interaction by 7.27 turns on
average.

### 30. SparseD: Sparse Attention for Diffusion Language Models

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Zeqing Wang, Gongfan Fang, Xinyin Ma, Xingyi Yang, Xinchao Wang
- **URL**: <http://arxiv.org/abs/2509.24014v1>
- **Submitted**: 2025-09-28 18:10:10
- **Comment**: The code is available at https://github.com/INV-WZQ/SparseD
- **Topic Keywords**: query, rag
- **Reason**: This paper focuses on improving the efficiency of diffusion language models through sparse attention, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves natural language processing, the topic is more aligned with deep learning and model optimization.

#### Abstract
> While diffusion language models (DLMs) offer a promising alternative to
autoregressive models (ARs), existing open-source DLMs suffer from high
inference latency. This bottleneck is mainly due to the attention's quadratic
complexity with respect to context length in computing all query-key pairs.
Intuitively, to reduce this complexity, a natural strategy is to restrict
attention to sparse patterns that retain only the most relevant connections.
Such approaches are well-established in ARs, where attention follows fixed and
clearly defined sparse patterns. However, in DLMs, we observe distinct sparsity
behaviors: (1) attention patterns vary across heads, (2) attention patterns in
each head remain highly similar across denoising steps, and (3) early denoising
steps are critical for generation. These findings render sparse attention
methods designed for ARs largely incompatible with DLMs, as they fail to
capture head-specific structures and risk degrading generation when applied in
early denoising steps. To address these challenges, we propose SparseD, a novel
sparse attention method for DLMs. Leveraging the observations, SparseD only
requires pre-computing head-specific sparse patterns one time, and reuses them
across all steps. This prevents recomputing sparse patterns at each denoising
step. Meanwhile, SparseD uses full attention in the early steps, then switches
to sparse attention later to maintain generation quality. Together, these
establish SparseD as a practical and efficient solution for deploying DLMs in
long-context applications. Experimental results demonstrate that SparseD
achieves lossless acceleration, delivering up to $1.50\times$ speedup over
FlashAttention at a 64k context length with 1,024 denoising steps.

### 31. Paired by the Teacher: Turning Unpaired Data into High-Fidelity Pairs for Low-Resource Text Generation

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Yen-Ju Lu, Thomas Thebaud, Laureano Moro-Velazquez, Najim Dehak, Jesus Villalba
- **URL**: <http://arxiv.org/abs/2509.25144v1>
- **Submitted**: 2025-09-29 17:51:55
- **Comment**: Accepted at EMNLP 2025 (Main Conference)
- **Topic Keywords**: rag, acl
- **Reason**: This paper focuses on low-resource text generation using a teacher-student pipeline, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing, the primary application is text generation, which is not a core area of interest.

#### Abstract
> We present Paired by the Teacher (PbT), a two-stage teacher-student pipeline
that synthesizes accurate input-output pairs without human labels or parallel
data. In many low-resource natural language generation (NLG) scenarios,
practitioners may have only raw outputs, like highlights, recaps, or questions,
or only raw inputs, such as articles, dialogues, or paragraphs, but seldom
both. This mismatch forces small models to learn from very few examples or rely
on costly, broad-scope synthetic examples produced by large LLMs. PbT addresses
this by asking a teacher LLM to compress each unpaired example into a concise
intermediate representation (IR), and training a student to reconstruct inputs
from IRs. This enables outputs to be paired with student-generated inputs,
yielding high-quality synthetic data. We evaluate PbT on five
benchmarks-document summarization (XSum, CNNDM), dialogue summarization
(SAMSum, DialogSum), and question generation (SQuAD)-as well as an unpaired
setting on SwitchBoard (paired with DialogSum summaries). An 8B student trained
only on PbT data outperforms models trained on 70 B teacher-generated corpora
and other unsupervised baselines, coming within 1.2 ROUGE-L of human-annotated
pairs and closing 82% of the oracle gap at one-third the annotation cost of
direct synthesis. Human evaluation on SwitchBoard further confirms that only
PbT produces concise, faithful summaries aligned with the target style,
highlighting its advantage of generating in-domain sources that avoid the
mismatch, limiting direct synthesis.

### 32. TemMed-Bench: Evaluating Temporal Medical Image Reasoning in Vision-Language Models

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Junyi Zhang, Jia-Chen Gu, Wenbo Hu, Yu Zhou, Robinson Piramuthu, Nanyun Peng
- **URL**: <http://arxiv.org/abs/2509.25143v1>
- **Submitted**: 2025-09-29 17:51:26
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper is about evaluating vision-language models for temporal medical image reasoning, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on multi-modal retrieval, the focus is on a specific application in the medical domain, and the techniques and models discussed are not directly applicable to your areas of interest.

#### Abstract
> Existing medical reasoning benchmarks for vision-language models primarily
focus on analyzing a patient's condition based on an image from a single visit.
However, this setting deviates significantly from real-world clinical practice,
where doctors typically refer to a patient's historical conditions to provide a
comprehensive assessment by tracking their changes over time. In this paper, we
introduce TemMed-Bench, the first benchmark designed for analyzing changes in
patients' conditions between different clinical visits, which challenges large
vision-language models (LVLMs) to reason over temporal medical images.
TemMed-Bench consists of a test set comprising three tasks - visual
question-answering (VQA), report generation, and image-pair selection - and a
supplementary knowledge corpus of over 17,000 instances. With TemMed-Bench, we
conduct an evaluation of six proprietary and six open-source LVLMs. Our results
show that most LVLMs lack the ability to analyze patients' condition changes
over temporal medical images, and a large proportion perform only at a
random-guessing level in the closed-book setting. In contrast, GPT o3, o4-mini
and Claude 3.5 Sonnet demonstrate comparatively decent performance, though they
have yet to reach the desired level. Furthermore, we explore augmenting the
input with both retrieved visual and textual modalities in the medical domain.
We also show that multi-modal retrieval augmentation yields notably higher
performance gains than no retrieval and textual retrieval alone across most
models on our benchmark, with the VQA task showing an average improvement of
2.59%. Overall, we compose a benchmark grounded on real-world clinical
practice, and it reveals LVLMs' limitations in temporal medical image
reasoning, as well as highlighting the use of multi-modal retrieval
augmentation as a potentially promising direction worth exploring to address
this challenge.

### 33. When Greedy Wins: Emergent Exploitation Bias in Meta-Bandit LLM Training

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Sanxing Chen, Xiaoyin Chen, Yukun Huang, Roy Xie, Bhuwan Dhingra
- **URL**: <http://arxiv.org/abs/2509.24923v1>
- **Submitted**: 2025-09-29 15:25:42
- **Topic Keywords**: rag, acl
- **Reason**: This paper focuses on Large Language Models (LLMs) and their training methods, which is not directly related to your primary research interests in Information Retrieval and Search technologies. While it touches on exploration strategies, it does not address query understanding, ranking models, or user behavior modeling, making it somewhat tangential to your core research themes.

#### Abstract
> While Large Language Models (LLMs) hold promise to become autonomous agents,
they often explore suboptimally in sequential decision-making. Recent work has
sought to enhance this capability via supervised fine-tuning (SFT) or
reinforcement learning (RL), improving regret on the classic multi-armed bandit
task. However, it remains unclear how these learning methods shape exploration
strategies and how well they generalize. We investigate both paradigms by
training LLMs with SFT on expert trajectories and RL with a range of tailored
reward signals including a strategic, regret-shaped reward to reduce variance,
and an algorithmic reward that enables oracle imitation. The resulting agents
outperform pre-trained models and achieve performance comparable to Upper
Confidence Bound (UCB) and Thompson Sampling, with robust generalization to 6x
longer horizons and across bandit families. Behavioral analysis reveals that
gains often stem from more sophisticated but greedier exploitation: RL/SFT
agents are more prone to early catastrophic failure than pre-trained models,
prematurely abandoning exploration. Furthermore, agents trained to imitate UCB
learn to outperform their teacher by adopting more exploitative variants. Our
findings clarify when each training paradigm is preferable and advocate
tailored reward design and evaluation beyond average regret to promote robust
exploratory behavior.

### 34. OrthAlign: Orthogonal Subspace Decomposition for Non-Interfering Multi-Objective Alignment

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Liang Lin, Zhihao Xu, Junhao Dong, Jian Zhao, Yuchen Yuan, Guibin Zhang, Miao Yu, Yiming Zhang, Zhengtao Yao, Huahui Yi, Dongrui Liu, Xinfeng Li, Kun Wang
- **URL**: <http://arxiv.org/abs/2509.24610v2>
- **Submitted**: 2025-09-29 11:16:30
- **Topic Keywords**: rag, ctr
- **Reason**: This paper appears to be focused on large language model alignment, specifically addressing multiple human preferences through orthogonal subspace decomposition. While it touches on optimization and parameter updates, it does not seem to be directly related to information retrieval, search technologies, or query understanding, which are core areas of your research interests.

#### Abstract
> Large language model (LLM) alignment faces a critical dilemma when addressing
multiple human preferences: improvements in one dimension frequently come at
the expense of others, creating unavoidable trade-offs between competing
objectives like helpfulness and harmlessness. While prior work mainly focuses
on constraint-based optimization algorithms and data selection strategies to
mitigate conflicts, these approaches overlook the fundamental issue of
resolving conflicts directly at the parameter level. In this paper, we present
OrthAlign, an innovative approach that pioneers a new paradigm by leveraging
orthogonal subspace decomposition to fundamentally resolve gradient-level
conflicts in multi-objective preference alignment. OrthAlign strategically
decomposes parameter update spaces into orthogonal subspaces, ensuring that
optimization toward different preferences occurs in mathematically
non-interfering directions. Building upon this, we provide theoretical
guarantees demonstrating that when parameter increments satisfy both orthogonal
subspace constraints and spectral norm bounds, the resulting updates exhibit
linear Lipschitz growth rather than exponential instability, ensuring stable
convergence across all preference dimensions. Extensive experiments show that:
I. OrthAlign achieves maximum single-preference improvements ranging from
34.61% to 50.89% after multiple-objective alignment across helpful, harmless,
and truthful dimensions. II. With an average overall reward improvement of
13.96%.

### 35. Multi-Item-Query Attention for Stable Sequential Recommendation

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Mingshi Xu, Haoren Zhu, Wilfred Siu Hung Ng
- **URL**: <http://arxiv.org/abs/2509.24424v1>
- **Submitted**: 2025-09-29 08:11:27
- **Topic Keywords**: query, recommend
- **Reason**: This paper focuses on sequential recommendation systems, which is a related but distinct area from information retrieval. While it touches on attention mechanisms, it does not explicitly address query understanding, ranking models, or user behavior modeling in the context of search technologies.

#### Abstract
> The inherent instability and noise in user interaction data challenge
sequential recommendation systems. Prevailing masked attention models, relying
on a single query from the most recent item, are sensitive to this noise,
reducing prediction reliability. We propose the Multi-Item-Query attention
mechanism (MIQ-Attn) to enhance model stability and accuracy. MIQ-Attn
constructs multiple diverse query vectors from user interactions, effectively
mitigating noise and improving consistency. It is designed for easy adoption as
a drop-in replacement for existing single-query attention. Experiments show
MIQ-Attn significantly improves performance on benchmark datasets.

### 36. PAME-AI: Patient Messaging Creation and Optimization using Agentic AI

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Junjie Luo, Yihong Guo, Anqi Liu, Ritu Agarwal, Gordon Gao
- **URL**: <http://arxiv.org/abs/2509.24263v2>
- **Submitted**: 2025-09-29 04:14:46
- **Topic Keywords**: click, click-through rate
- **Reason**: This paper appears to be focused on patient messaging in healthcare, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some form of optimization, it is more related to healthcare communication rather than deep semantic understanding or real-time relevance optimization.

#### Abstract
> Messaging patients is a critical part of healthcare communication, helping to
improve things like medication adherence and healthy behaviors. However,
traditional mobile message design has significant limitations due to its
inability to explore the high-dimensional design space. We develop PAME-AI, a
novel approach for Patient Messaging Creation and Optimization using Agentic
AI. Built on the Data-Information-Knowledge-Wisdom (DIKW) hierarchy, PAME-AI
offers a structured framework to move from raw data to actionable insights for
high-performance messaging design. PAME-AI is composed of a system of
specialized computational agents that progressively transform raw experimental
data into actionable message design strategies. We demonstrate our approach's
effectiveness through a two-stage experiment, comprising of 444,691 patient
encounters in Stage 1 and 74,908 in Stage 2. The best-performing generated
message achieved 68.76% engagement compared to the 61.27% baseline,
representing a 12.2% relative improvement in click-through rates. This agentic
architecture enables parallel processing, hypothesis validation, and continuous
learning, making it particularly suitable for large-scale healthcare
communication optimization.

### 37. BeyondBench: Benchmark-Free Evaluation of Reasoning in Language Models

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Gaurav Srivastava, Aafiya Hussain, Zhenyu Bi, Swastik Roy, Priya Pitre, Meng Lu, Morteza Ziyadi, Xuan Wang
- **URL**: <http://arxiv.org/abs/2509.24210v1>
- **Submitted**: 2025-09-29 02:49:01
- **Comment**: 113 pages, 5 figures, 30 tables
- **Topic Keywords**: rag, ctr
- **Reason**: This paper focuses on evaluating language models for reasoning capabilities, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on NLP, the context is more about model evaluation rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> Evaluating language models fairly is becoming harder as static benchmarks
available on the internet risk contamination by training data. This makes it
unclear whether models are truly reasoning or just recalling answers. In this
paper, we introduce BeyondBench, an evaluation framework that avoids this
problem by using algorithmic problem generation. Unlike traditional benchmarks
that risk contamination from internet-scale training data, BeyondBench creates
mathematically grounded problems on the fly, ensuring each test remains fresh
and uncontaminated. Our framework covers 44 algorithmic tasks with a total of
117 variations, grouped into three difficulty levels: the Easy Suite (29 tasks)
for basic arithmetic and statistics, the Medium Suite (5 tasks, 49 variations)
for sequence patterns and reasoning, and the Hard Suite (10 tasks, 68
variations) tackling NP-complete and constraint satisfaction problems. Each
task generates problems from a combinatorial space larger than 10^15 unique
instances, with solutions verified deterministically by mathematical proofs. We
evaluated 101 language models, including 85 open-source and 16 closed-source
models, spanning sizes from 0.5B to 141B parameters and multiple quantization
schemes. Our results show consistent reasoning deficiencies across model
families, with performance degrading sharply as problem complexity increases
from polynomial to exponential. In our Hard Suite evaluations, models such as
Gemini-2.5-pro, Llama-3.3-70B, and Qwen2.5-72B achieved average accuracies of
56.38%, 26.91%, and 33.60%, respectively. Moreover, we observe that performance
drops drastically without tool usage, with GPT-5, GPT-5-mini, and GPT-5-nano
showing a decline of 16.81%, 28.05%, and 47.59% accuracy on the hard suite. Our
leaderboard is publicly available at https://ctrl-gaurav.github.io/BeyondBench/

### 38. Multilingual Text-to-SQL: Benchmarking the Limits of Language Models with Collaborative Language Agents

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Khanh Trinh Pham, Thu Huong Nguyen, Jun Jo, Quoc Viet Hung Nguyen, Thanh Tam Nguyen
- **URL**: <http://arxiv.org/abs/2509.24405v1>
- **Submitted**: 2025-09-29 07:50:39
- **Topic Keywords**: queries
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves language models and query refinement, its focus on Text-to-SQL and multilingual benchmarks is not a central match to your areas of expertise.

#### Abstract
> Text-to-SQL enables natural access to databases, yet most benchmarks are
English-only, limiting multilingual progress. We introduce MultiSpider 2.0,
extending Spider 2.0 to eight languages (English, German, French, Spanish,
Portuguese, Japanese, Chinese, Vietnamese). It preserves Spider 2.0's
structural difficulty while adding linguistic and dialectal variability,
demanding deeper reasoning for complex SQL. On this benchmark, state-of-the-art
LLMs (such as DeepSeek-R1 and OpenAI o1) reach only 4\% execution accuracy when
relying on intrinsic reasoning, versus 60\% on MultiSpider 1.0. Therefore, we
provide a collaboration-driven language agents baseline that iteratively
refines queries, improving accuracy to 15\%. These results reveal a substantial
multilingual gap and motivate methods that are robust across languages and
ready for real-world enterprise deployment. Our benchmark is available at
https://github.com/phkhanhtrinh23/Multilingual_Text_to_SQL.

### 39. MAS$^2$: Self-Generative, Self-Configuring, Self-Rectifying Multi-Agent Systems

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Kun Wang, Guibin Zhang, ManKit Ye, Xinyu Deng, Dongxia Wang, Xiaobin Hu, Jinyang Guo, Yang Liu, Yufei Guo
- **URL**: <http://arxiv.org/abs/2509.24323v1>
- **Submitted**: 2025-09-29 06:20:10
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your research interests as it focuses on multi-agent systems and large language models, which do not align with your primary focus on information retrieval, query understanding, and ranking models. While it involves some form of optimization, it is not related to real-time relevance optimization or deep semantic understanding in the context of search technologies.

#### Abstract
> The past two years have witnessed the meteoric rise of Large Language Model
(LLM)-powered multi-agent systems (MAS), which harness collective intelligence
and exhibit a remarkable trajectory toward self-evolution. This paradigm has
rapidly progressed from manually engineered systems that require bespoke
configuration of prompts, tools, roles, and communication protocols toward
frameworks capable of automated orchestration. Yet, dominant automatic
multi-agent systems, whether generated by external modules or a single LLM
agent, largely adhere to a rigid ``\textit{generate-once-and-deploy}''
paradigm, rendering the resulting systems brittle and ill-prepared for the
dynamism and uncertainty of real-world environments. To transcend this
limitation, we introduce MAS$^2$, a paradigm predicated on the principle of
recursive self-generation: a multi-agent system that autonomously architects
bespoke multi-agent systems for diverse problems. Technically, we devise a
``\textit{generator-implementer-rectifier}'' tri-agent team capable of
dynamically composing and adaptively rectifying a target agent system in
response to real-time task demands. Collaborative Tree Optimization is proposed
to train and specialize these meta-agents. Extensive evaluation across seven
benchmarks reveals that MAS$^2$ achieves performance gains of up to $19.6\%$
over state-of-the-art MAS in complex scenarios such as deep research and code
generation. Moreover, MAS$^2$ exhibits superior cross-backbone generalization,
effectively leveraging previously unseen LLMs to yield improvements of up to
$15.1\%$. Crucially, these gains are attained without incurring excessive token
costs, as MAS$^2$ consistently resides on the Pareto frontier of
cost-performance trade-offs. The source codes are available at
https://github.com/yeyeyeah2/MAS2.

### 40. Learning to Ponder: Adaptive Reasoning in Latent Space

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yixin He, Lumingyuan Tang
- **URL**: <http://arxiv.org/abs/2509.24238v1>
- **Submitted**: 2025-09-29 03:21:42
- **Topic Keywords**: queries
- **Reason**: This paper focuses on adaptive reasoning in latent space for Large Language Models (LLMs), which is not directly related to Information Retrieval or Search technologies. While it involves deep semantic understanding, the context is more aligned with NLP and deep learning, rather than IR or Search technologies.

#### Abstract
> Test-time compute has emerged as a key paradigm for enhancing LLM reasoning,
yet prevailing approaches like Best-of-N and majority voting apply uniform
depth across inputs, wasting computation on simple queries while potentially
under-thinking complex ones. We present FR-Ponder, a single-graph,
backbone-training-free framework that allocates instance-adaptive reasoning
compute via latent steering. A less than 1M-param controller observes hidden
states and decides to halt or apply a small ponder step by adding a
pre-computed steering vector to frozen representations. Our method extracts the
latent steering vector associated with deeper reasoning outputs and direct IO
from LLM and re-applies it through a tunable scaling factor, allowing the model
to adapt its reasoning depth to the complexity of each input. To balance
performance and computational cost, we employ Group Relative Policy
Optimization (GRPO) as a reward signal to adaptively regulate reasoning depth,
achieving task accuracy while mitigating overreasoning. Through curriculum
learning and careful reward engineering, FR-Ponder learns calibrated compute
allocation correlated with problem difficulty. On GSM8K and MATH500, FR-Ponder
improves the compute-accuracy frontier, delivering lower FLOPs with better
matched accuracy and comparing favorably to early-exit baselines, without
modifying backbone weights. Analyses visualize interpretable steering
directions and show learned compute allocation correlates with problem
difficulty.

### 41. Pragmatic Inference for Moral Reasoning Acquisition: Generalization via Distributional Semantics

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Guangliang Liu, Xi Chen, Bocheng Chen, Xitong Zhang, Kristen Johnson
- **URL**: <http://arxiv.org/abs/2509.24102v1>
- **Submitted**: 2025-09-28 22:40:58
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on moral reasoning in Large Language Models, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context and application are quite different from the user's areas of focus.

#### Abstract
> Moral reasoning has emerged as a promising research direction for Large
Language Models (LLMs), yet achieving generalization remains a central
challenge. From a linguistic standpoint, this difficulty arises because LLMs
are adept at capturing distributional semantics, which fundamentally differs
from the morals which operate at the pragmatic level. This paper investigates
how LLMs can achieve generalized moral reasoning despite their reliance on
distributional semantics. We propose pragmatic inference methods grounded in
moral foundations theory, which leverage contextual information at each step to
bridge the pragmatic gap and guide LLMs in connecting moral foundations with
moral reasoning objectives. Experimental results demonstrate that our approach
significantly enhances LLMs' generalization in moral reasoning, providing a
foundation for future research grounded in moral foundations theory.

### 42. Rethinking Entropy Regularization in Large Reasoning Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yuxian Jiang, Yafu Li, Guanxu Chen, Dongrui Liu, Yu Cheng, Jing Shao
- **URL**: <http://arxiv.org/abs/2509.25133v1>
- **Submitted**: 2025-09-29 17:49:25
- **Topic Keywords**: rag
- **Reason**: This paper focuses on reinforcement learning and entropy regularization in large reasoning models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on a broader topic of machine learning, the specific context and methodology do not align with your primary areas of focus.

#### Abstract
> Reinforcement learning with verifiable rewards (RLVR) has shown great promise
in enhancing the reasoning abilities of large reasoning models (LRMs). However,
it suffers from a critical issue: entropy collapse and premature convergence.
Naive entropy regularization, a common approach for encouraging exploration in
the traditional RL literature, fails to address this problem in the context of
LRM. Our analysis reveals that this failure stems from the vast action space
and long trajectories in LRMs, which easily trigger a global entropy explosion
as the model indiscriminately explores all possible actions and states. To
address this, we propose SIREN (SelectIve entRopy rEgularizatioN), a method
that confines exploration to a meaningful subset of actions and states. SIREN
achieves this through a two-step entropy masking mechanism, consisting of a
top-p mask and a peak-entropy mask. In addition, regularization is transformed
into a self-anchored form to stabilize training. Across five mathematical
benchmarks, SIREN attains superior average performance over previous
entropy-related RLVR approaches, exemplified by a +6.6 maj@k improvement on
AIME24/25 with Qwen2.5-Math-7B. Further analysis confirms that SIREN promotes
greater response diversity and maintains entropy at an appropriate level, which
helps to preserve the validation pass@k throughout training. This effectively
mitigates the premature convergence problem common in RLVR for LRM.

### 43. DiffTester: Accelerating Unit Test Generation for Diffusion LLMs via Repetitive Pattern

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Lekang Yang, Yuetong Liu, Yitong Zhang, Jia Li
- **URL**: <http://arxiv.org/abs/2509.24975v1>
- **Submitted**: 2025-09-29 16:04:18
- **Topic Keywords**: rag
- **Reason**: This paper focuses on unit test generation for diffusion LLMs, which is outside the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves software development, a related domain, the specific topic of unit test generation for LLMs is not directly relevant to the user's core research themes.

#### Abstract
> Software development relies heavily on extensive unit testing, which makes
the efficiency of automated Unit Test Generation (UTG) particularly important.
However, most existing LLMs generate test cases one token at a time in each
forward pass, which leads to inefficient UTG. Recently, diffusion LLMs (dLLMs)
have emerged, offering promising parallel generation capabilities and showing
strong potential for efficient UTG. Despite this advantage, their application
to UTG is still constrained by a clear trade-off between efficiency and test
quality, since increasing the number of tokens generated in each step often
causes a sharp decline in the quality of test cases. To overcome this
limitation, we present DiffTester, an acceleration framework specifically
tailored for dLLMs in UTG. The key idea of DiffTester is that unit tests
targeting the same focal method often share repetitive structural patterns. By
dynamically identifying these common patterns through abstract syntax tree
analysis during generation, DiffTester adaptively increases the number of
tokens produced at each step without compromising the quality of the output. To
enable comprehensive evaluation, we extend the original TestEval benchmark,
which was limited to Python, by introducing additional programming languages
including Java and C++. Extensive experiments on three benchmarks with two
representative models show that DiffTester delivers significant acceleration
while preserving test coverage. Moreover, DiffTester generalizes well across
different dLLMs and programming languages, providing a practical and scalable
solution for efficient UTG in software development. Code and data are publicly
available at https://github.com/wellbeingyang/DLM4UTG-open .

### 44. How Well Do LLMs Imitate Human Writing Style?

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Rebira Jemama, Rajesh Kumar
- **URL**: <http://arxiv.org/abs/2509.24930v1>
- **Submitted**: 2025-09-29 15:34:40
- **Comment**: IEEE UEMCON 2025, 11 pages, 4 figures, and 4 tables
- **Topic Keywords**: rag
- **Reason**: This paper focuses on authorship verification and style imitation analysis using large language models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific application and methodology are not aligned with your primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large language models (LLMs) can generate fluent text, but their ability to
replicate the distinctive style of a specific human author remains unclear. We
present a fast, training-free framework for authorship verification and style
imitation analysis. The method integrates TF-IDF character n-grams with
transformer embeddings and classifies text pairs through empirical distance
distributions, eliminating the need for supervised training or threshold
tuning. It achieves 97.5\% accuracy on academic essays and 94.5\% in
cross-domain evaluation, while reducing training time by 91.8\% and memory
usage by 59\% relative to parameter-based baselines. Using this framework, we
evaluate five LLMs from three separate families (Llama, Qwen, Mixtral) across
four prompting strategies - zero-shot, one-shot, few-shot, and text completion.
Results show that the prompting strategy has a more substantial influence on
style fidelity than model size: few-shot prompting yields up to 23.5x higher
style-matching accuracy than zero-shot, and completion prompting reaches 99.9\%
agreement with the original author's style. Crucially, high-fidelity imitation
does not imply human-like unpredictability - human essays average a perplexity
of 29.5, whereas matched LLM outputs average only 15.2. These findings
demonstrate that stylistic fidelity and statistical detectability are
separable, establishing a reproducible basis for future work in authorship
modeling, detection, and identity-conditioned generation.

### 45. MASLegalBench: Benchmarking Multi-Agent Systems in Deductive Legal Reasoning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Huihao Jing, Wenbin Hu, Hongyu Luo, Jianhui Yang, Wei Fan, Haoran Li, Yangqiu Song
- **URL**: <http://arxiv.org/abs/2509.24922v2>
- **Submitted**: 2025-09-29 15:24:40
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves Large Language Models, the focus is on Multi-Agent Systems and deductive legal reasoning, which is not a primary area of interest for the user.

#### Abstract
> Multi-agent systems (MAS), leveraging the remarkable capabilities of Large
Language Models (LLMs), show great potential in addressing complex tasks. In
this context, integrating MAS with legal tasks is a crucial step. While
previous studies have developed legal benchmarks for LLM agents, none are
specifically designed to consider the unique advantages of MAS, such as task
decomposition, agent specialization, and flexible training. In fact, the lack
of evaluation methods limits the potential of MAS in the legal domain. To
address this gap, we propose MASLegalBench, a legal benchmark tailored for MAS
and designed with a deductive reasoning approach. Our benchmark uses GDPR as
the application scenario, encompassing extensive background knowledge and
covering complex reasoning processes that effectively reflect the intricacies
of real-world legal situations. Furthermore, we manually design various
role-based MAS and conduct extensive experiments using different
state-of-the-art LLMs. Our results highlight the strengths, limitations, and
potential areas for improvement of existing models and MAS architectures.

### 46. Expanding Computation Spaces of LLMs at Inference Time

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yoonna Jang, Kisu Yang, Isabelle Augenstein
- **URL**: <http://arxiv.org/abs/2509.24884v1>
- **Submitted**: 2025-09-29 14:59:44
- **Topic Keywords**: rag
- **Reason**: This paper focuses on improving the performance of Large Language Models (LLMs) by expanding their computation spaces at inference time. While it touches on aspects of deep semantic understanding, it is primarily concerned with optimizing LLMs' computational capacity, which is not a central match to your research interests in Information Retrieval and Search technologies.

#### Abstract
> Chain-of-thought (CoT) rationale enables language models to use additional
task-related text for problem-solving, benefiting not only from detailed
reasoning steps but also from the expanded computational space of longer
inputs. Prior work has trained filler or special tokens to serve as additional
computation spaces. In this study, we investigate whether language models can
leverage artificially inserted sequences of filler tokens solely at inference.
We first identify effective token types, numbers, and insertion locations, then
examine at what stage of training models begin to exploit the expanded
computation space, and finally analyze dynamics within these spaces via
attention maps. Experiments on models ranging from 1.7B to 32B across
open-domain QA and math tasks show that appropriate token types and counts
vary, but placing filler tokens directly before the final 'Answer:' token is
most effective. Smaller models benefit most, up to 12.372 percentage points in
SmolLM2-1.7B-Instruct, indicating that these spaces act as additional
computational capacity rather than redundant input. Attention maps reveal that
expanded spaces often continue the original attention mechanism and sometimes
focus on questions or answer options, suggesting meaningful computation for
problem-solving.

### 47. SeaPO: Strategic Error Amplification for Robust Preference Optimization of Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jun Rao, Yunjie Liao, Xuebo Liu, Zepeng Lin, Lian Lian, Dong Jin, Shengjun Cheng, Jun Yu, Min Zhang
- **URL**: <http://arxiv.org/abs/2509.24781v1>
- **Submitted**: 2025-09-29 13:42:41
- **Comment**: EMNLP 2025 Findings
- **Topic Keywords**: rag
- **Reason**: This paper appears to be focused on preference optimization of large language models, which is somewhat related to information retrieval, but it does not directly address query understanding, ranking models, or user behavior modeling. The paper's emphasis on error amplification and preference learning is more aligned with NLP and recommender systems, but it does not seem to be a central match for your research interests.

#### Abstract
> Existing alignment methods for preference optimization of large language
models (LLMs) aim to enhance model performance by utilizing pairs of positive
and negative samples. However, due to the limited capacity of models in scoring
or generating responses, the quality of positive and negative samples may
become similar during training, which complicates optimization for preference
learning. To address this issue, we introduce SeaPO, a Strategic Error
Amplification method that leverages three error types commonly occurring in
LLMs to introduce specific error patterns into the model Preference
Optimization. This strategy ensures that negative samples are more erroneous
than positive samples and preference-based training is employed to mitigate the
occurrence of these errors, thereby enhancing model performance. Evaluations
across five capability dimensions and different model scales (1.5B to 14B)
demonstrate that the generated data significantly improved overall model
performance, particularly in terms of truthfulness, with improvements of 5-10
percentage points observed. Further analysis reveals that task performance
varies depending on the error types introduced. Injecting the most common error
types improves performance in related tasks, while a mix of error types leads
to a broader performance enhancement: most tasks show stable improvements,
while a few tasks exhibit significant gains.

### 48. Socratic-Zero : Bootstrapping Reasoning via Data-Free Agent Co-evolution

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Shaobo Wang, Zhengbo Jiao, Zifan Zhang, Yilang Peng, Xu Ze, Boyu Yang, Wei Wang, Hu Wei, Linfeng Zhang
- **URL**: <http://arxiv.org/abs/2509.24726v1>
- **Submitted**: 2025-09-29 12:54:07
- **Comment**: 23 pages, 3 figures
- **Topic Keywords**: rag
- **Reason**: This paper focuses on large language models and data synthesis for reasoning tasks, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on NLP, the context is more aligned with model development and training rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> Recent breakthroughs in large language models (LLMs) on reasoning tasks rely
heavily on massive, high-quality datasets-typically human-annotated and thus
difficult to scale. While data synthesis or distillation offers a promising
alternative, existing methods struggle with inconsistent data quality and an
inability to dynamically adapt to the evolving capabilities of the model,
leading to suboptimal training signals. To address these limitations, we
introduce Socratic-Zero, a fully autonomous framework that generates
high-quality training data from minimal seed examples through the co-evolution
of three agents: the Teacher, the Solver, and the Generator. The Solver
continuously refines its reasoning by learning from preference feedback on both
successful and failed trajectories; the Teacher adaptively crafts increasingly
challenging questions based on the Solver's weaknesses; and the Generator
distills the Teacher's question-design strategy to enable scalable,
high-fidelity curriculum generation. This closed-loop system produces a
self-improving curriculum-requiring no pre-existing tasks or labels.
Remarkably, starting from only 100 seed questions, our Socratic-Solver-8B
achieves an average gain of +20.2 percentage points over prior data synthesis
methods across seven mathematical reasoning benchmarks (AMC23, AIME24-25,
Olympiad, MATH-500, Minerva, and GSM8K), with consistent gains on both Qwen3
and GLM4 series models. Even more surprisingly, synthetic data from
Socratic-Generator-32B enables student LLMs to achieve superior performance
compared to other state-of-the-art (SOTA) commercial LLMs on these benchmarks,
including Qwen3-235B-A22B, DeepSeek-V3.1-671B, GPT-5, Gemini-2.5-Pro, Grok-4,
and Claude-4.1-Opus.

### 49. MemGen: Weaving Generative Latent Memory for Self-Evolving Agents

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Guibin Zhang, Muxin Fu, Shuicheng Yan
- **URL**: <http://arxiv.org/abs/2509.24704v1>
- **Submitted**: 2025-09-29 12:33:13
- **Topic Keywords**: retrieval
- **Reason**: This paper focuses on developing a generative memory framework for self-evolving agents, which is not directly related to information retrieval, search technologies, or natural language processing. While it involves large language models, the primary goal is to enable agents to refine themselves through environment interactions, rather than addressing query understanding, ranking models, or user behavior modeling.

#### Abstract
> Agent memory shapes how Large Language Model (LLM)-powered agents, akin to
the human brain, progressively refine themselves through environment
interactions. Existing paradigms remain constrained: parametric memory forcibly
adjusts model parameters, and retrieval-based memory externalizes experience
into structured databases, yet neither captures the fluid interweaving of
reasoning and memory that underlies human cognition. To address this gap, we
propose MemGen, a dynamic generative memory framework that equips agents with a
human-esque cognitive faculty. It consists of a \textit{memory trigger}, which
monitors the agent's reasoning state to decide explicit memory invocation, and
a \textit{memory weaver}, which takes the agent's current state as stimulus to
construct a latent token sequence as machine-native memory to enrich its
reasoning. In this way, MemGen enables agents to recall and augment latent
memory throughout reasoning, producing a tightly interwoven cycle of memory and
cognition. Extensive experiments across eight benchmarks show that MemGen
surpasses leading external memory systems such as ExpeL and AWM by up to
$38.22\%$, exceeds GRPO by up to $13.44\%$, and exhibits strong cross-domain
generalization ability. More importantly, we find that without explicit
supervision, MemGen spontaneously evolves distinct human-like memory faculties,
including planning memory, procedural memory, and working memory, suggesting an
emergent trajectory toward more naturalistic forms of machine cognition.

### 50. VSSFlow: Unifying Video-conditioned Sound and Speech Generation via Joint Learning

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Xin Cheng, Yuyue Wang, Xihua Wang, Yihan Wu, Kaisi Guan, Yijing Chen, Peng Zhang, Xiaojiang Liu, Meng Cao, Ruihua Song
- **URL**: <http://arxiv.org/abs/2509.24773v2>
- **Submitted**: 2025-09-29 13:38:24
- **Comment**: Paper Under Review
- **Topic Keywords**: rag
- **Reason**: This paper focuses on video-conditioned sound and speech generation, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Video-conditioned sound and speech generation, encompassing video-to-sound
(V2S) and visual text-to-speech (VisualTTS) tasks, are conventionally addressed
as separate tasks, with limited exploration to unify them within a signle
framework. Recent attempts to unify V2S and VisualTTS face challenges in
handling distinct condition types (e.g., heterogeneous video and transcript
conditions) and require complex training stages. Unifying these two tasks
remains an open problem. To bridge this gap, we present VSSFlow, which
seamlessly integrates both V2S and VisualTTS tasks into a unified flow-matching
framework. VSSFlow uses a novel condition aggregation mechanism to handle
distinct input signals. We find that cross-attention and self-attention layer
exhibit different inductive biases in the process of introducing condition.
Therefore, VSSFlow leverages these inductive biases to effectively handle
different representations: cross-attention for ambiguous video conditions and
self-attention for more deterministic speech transcripts. Furthermore, contrary
to the prevailing belief that joint training on the two tasks requires complex
training strategies and may degrade performance, we find that VSSFlow benefits
from the end-to-end joint learning process for sound and speech generation
without extra designs on training stages. Detailed analysis attributes it to
the learned general audio prior shared between tasks, which accelerates
convergence, enhances conditional generation, and stabilizes the
classifier-free guidance process. Extensive experiments demonstrate that
VSSFlow surpasses the state-of-the-art domain-specific baselines on both V2S
and VisualTTS benchmarks, underscoring the critical potential of unified
generative models.

---

