# Daily Papers Report - 2025-10-23

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. ToolDreamer: Instilling LLM Reasoning Into Tool Retrievers

- **LLM Score**: 8
- **Keyword Score**: 12
- **Authors**: Saptarshi Sengupta, Zhengyu Zhou, Jun Araki, Xingbo Wang, Bingqing Wang, Suhang Wang, Zhe Feng
- **URL**: <http://arxiv.org/abs/2510.19791v1>
- **Submitted**: 2025-10-22 17:26:05
- **Topic Keywords**: retriever, query, queries, retrieval, rank
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The proposed framework, ToolDreamer, aims to improve the alignment between user queries and tool descriptions, which is a key aspect of your research focus. The application of ToolDreamer on the ToolRet dataset also aligns with your interest in real-time relevance optimization.

#### Abstract
> Tool calling has become increasingly popular for Large Language Models
(LLMs). However, for large tool sets, the resulting tokens would exceed the
LLM's context window limit, making it impossible to include every tool. Hence,
an external retriever is used to provide LLMs with the most relevant tools for
a query. Existing retrieval models rank tools based on the similarity between a
user query and a tool description (TD). This leads to suboptimal retrieval as
user requests are often poorly aligned with the language of TD. To remedy the
issue, we propose ToolDreamer, a framework to condition retriever models to
fetch tools based on hypothetical (synthetic) TD generated using an LLM, i.e.,
description of tools that the LLM feels will be potentially useful for the
query. The framework enables a more natural alignment between queries and tools
within the language space of TD's. We apply ToolDreamer on the ToolRet dataset
and show that our method improves the performance of sparse and dense
retrievers with and without training, thus showcasing its flexibility. Through
our proposed framework, our aim is to offload a portion of the reasoning burden
to the retriever so that the LLM may effectively handle a large collection of
tools without inundating its context window.

---

### 2. Top-P Masking for Cross Language Information Retrieval

- **LLM Score**: 8
- **Keyword Score**: 5
- **Authors**: Joseph Casale, Andrew Silverschotz, Joseph DeSimone
- **URL**: <http://arxiv.org/abs/2510.19758v1>
- **Submitted**: 2025-10-22 16:47:42
- **Comment**: Unsubmitted
- **Topic Keywords**: information retrieval, retrieval
- **Reason**: This paper is highly relevant to Information Retrieval (IR) and Search technologies, specifically addressing a novel approach to promote sparse representations in IR tasks. The focus on Cross Language Information Retrieval (CLIR) is also a key area of interest. However, the specific application to CLIR limits its broader applicability to the user's research interests.

#### Abstract
> Top-K masking schemes have been proposed as a method to promote sparse
representations in Information Retrieval (IR) tasks, as a simple alternative to
Floating Point Operations per Second (FLOPS) regularization. Algorithms such as
Bilingual Lexical and Document Expansion Model (BLADE), adopt this approach as
a post-processing stage. We propose using Top-P Dynamic Masking similar to
Nucleus Sampling in Large Language Models, and demonstrate better performance
than Top-K masking. Specifically, we evaluate our methods in the domain of
Cross Language Information Retrieval (CLIR)

---

### 3. HSCodeComp: A Realistic and Expert-level Benchmark for Deep Search Agents in Hierarchical Rule Application

- **LLM Score**: 8
- **Keyword Score**: 3
- **Authors**: Yiqian Yang, Tian Lan, Qianghuai Jia, Li Zhu, Hui Jiang, Hang Zhu, Longyue Wang, Weihua Luo, Kaifu Zhang
- **URL**: <http://arxiv.org/abs/2510.19631v1>
- **Submitted**: 2025-10-22 14:28:33
- **Topic Keywords**: commerce, e-commerce, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of deep search agents and hierarchical rule application. The focus on e-commerce and the use of real-world data from large-scale platforms aligns with your background experience. However, the primary focus on search agents and rule application, while related to your interests, is not a central match with your core research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Effective deep search agents must not only access open-domain and
domain-specific knowledge but also apply complex rules-such as legal clauses,
medical manuals and tariff rules. These rules often feature vague boundaries
and implicit logic relationships, making precise application challenging for
agents. However, this critical capability is largely overlooked by current
agent benchmarks.
  To fill this gap, we introduce HSCodeComp, the first realistic, expert-level
e-commerce benchmark designed to evaluate deep search agents in hierarchical
rule application. In this task, the deep reasoning process of agents is guided
by these rules to predict 10-digit Harmonized System Code (HSCode) of products
with noisy but realistic descriptions. These codes, established by the World
Customs Organization, are vital for global supply chain efficiency. Built from
real-world data collected from large-scale e-commerce platforms, our proposed
HSCodeComp comprises 632 product entries spanning diverse product categories,
with these HSCodes annotated by several human experts.
  Extensive experimental results on several state-of-the-art LLMs, open-source,
and closed-source agents reveal a huge performance gap: best agent achieves
only 46.8% 10-digit accuracy, far below human experts at 95.0%. Besides,
detailed analysis demonstrates the challenges of hierarchical rule application,
and test-time scaling fails to improve performance further.

---

### 4. C2T-ID: Converting Semantic Codebooks to Textual Document Identifiers for Generative Search

- **LLM Score**: 7
- **Keyword Score**: 5
- **Authors**: Yingchen Zhang, Ruqing Zhang, Jiafeng Guo, Wenjun Peng, Sen Li, Fuyu Lv, Xueqi Cheng
- **URL**: <http://arxiv.org/abs/2510.19221v1>
- **Submitted**: 2025-10-22 04:05:38
- **Topic Keywords**: rag, retrieval, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the area of generative search and document identifiers. However, it focuses more on the technical aspect of designing document identifiers rather than query understanding, ranking models, or user behavior modeling. The use of natural language understanding and hierarchical clustering is relevant to your background in NLP and data mining.

#### Abstract
> Designing document identifiers (docids) that carry rich semantic information
while maintaining tractable search spaces is a important challenge in
generative retrieval (GR). Popular codebook methods address this by building a
hierarchical semantic tree and constraining generation to its child nodes, yet
their numeric identifiers cannot leverage the large language model's pretrained
natural language understanding. Conversely, using text as docid provides more
semantic expressivity but inflates the decoding space, making the system
brittle to early-step errors. To resolve this trade-off, we propose C2T-ID: (i)
first construct semantic numerical docid via hierarchical clustering; (ii) then
extract high-frequency metadata keywords and iteratively replace each numeric
label with its cluster's top-K keywords; and (iii) an optional two-level
semantic smoothing step further enhances the fluency of C2T-ID. Experiments on
Natural Questions and Taobao's product search demonstrate that C2T-ID
significantly outperforms atomic, semantic codebook, and pure-text docid
baselines, demonstrating its effectiveness in balancing semantic expressiveness
with search space constraints.

---

### 5. Think Straight, Stop Smart: Structured Reasoning for Efficient Multi-Hop RAG

- **LLM Score**: 6
- **Keyword Score**: 10
- **Authors**: Jihwan Bang, Juntae Lee, Seunghan Yang, Sungha Choi
- **URL**: <http://arxiv.org/abs/2510.19171v1>
- **Submitted**: 2025-10-22 02:09:23
- **Comment**: Accepted at NeurIPS 2025 Workshop
- **Topic Keywords**: retriever, queries, rag, retrieval
- **Reason**: This paper proposes a structured multi-hop retrieval-augmented generation framework for efficient reasoning, which is somewhat related to my interests in Information Retrieval and Search technologies. However, the focus on efficiency and structured reasoning, while relevant to query understanding and ranking models, does not directly align with my primary research themes. The paper's emphasis on complex reasoning and real-time relevance optimization is also somewhat tangential to my interests.

#### Abstract
> Multi-hop retrieval-augmented generation (RAG) is a promising strategy for
complex reasoning, yet existing iterative prompting approaches remain
inefficient. They often regenerate predictable token sequences at every step
and rely on stochastic stopping, leading to excessive token usage and unstable
termination. We propose TSSS (Think Straight, Stop Smart), a structured
multi-hop RAG framework designed for efficiency. TSSS introduces (i) a
template-based reasoning that caches recurring prefixes and anchors sub-queries
to the main question, reducing token generation cost while promoting stable
reasoning, and (ii) a retriever-based terminator, which deterministically halts
reasoning once additional sub-queries collapse into repetition. This separation
of structured reasoning and termination control enables both faster inference
and more reliable answers. On HotpotQA, 2WikiMultiHop, and MuSiQue, TSSS
achieves state-of-the-art accuracy and competitive efficiency among RAG-CoT
approaches, highlighting its effectiveness in efficiency-constrained scenarios
such as on-device inference.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Stream: Scaling up Mechanistic Interpretability to Long Context in LLMs via Sparse Attention

- **LLM Score**: 6
- **Keyword Score**: 8
- **Authors**: J Rosser, Jos√© Luis Redondo Garc√≠a, Gustavo Penha, Konstantina Palla, Hugues Bouchard
- **URL**: <http://arxiv.org/abs/2510.19875v1>
- **Submitted**: 2025-10-22 09:42:29
- **Topic Keywords**: query, rag, retrieval, search
- **Reason**: This paper explores a novel technique for analyzing attention patterns in Large Language Models (LLMs), which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on interpretability and attention patterns in LLMs is not a central match to your primary research interests in IR and search technologies. The paper's relevance to your interests is somewhat diminished by its focus on NLP and LLMs rather than traditional IR and search technologies.

#### Abstract
> As Large Language Models (LLMs) scale to million-token contexts, traditional
Mechanistic Interpretability techniques for analyzing attention scale
quadratically with context length, demanding terabytes of memory beyond 100,000
tokens. We introduce Sparse Tracing, a novel technique that leverages dynamic
sparse attention to efficiently analyze long context attention patterns. We
present Stream, a compilable hierarchical pruning algorithm that estimates
per-head sparse attention masks in near-linear time $O(T \log T)$ and linear
space $O(T)$, enabling one-pass interpretability at scale. Stream performs a
binary-search-style refinement to retain only the top-$k$ key blocks per query
while preserving the model's next-token behavior. We apply Stream to long
chain-of-thought reasoning traces and identify thought anchors while pruning
97-99\% of token interactions. On the RULER benchmark, Stream preserves
critical retrieval paths while discarding 90-96\% of interactions and exposes
layer-wise routes from the needle to output. Our method offers a practical
drop-in tool for analyzing attention patterns and tracing information flow
without terabytes of caches. By making long context interpretability feasible
on consumer GPUs, Sparse Tracing helps democratize chain-of-thought monitoring.
Code is available at https://anonymous.4open.science/r/stream-03B8/.

### 7. JointCQ: Improving Factual Hallucination Detection with Joint Claim and Query Generation

- **LLM Score**: 6
- **Keyword Score**: 8
- **Authors**: Fan Xu, Huixuan Zhang, Zhenliang Zhang, Jiahao Wang, Xiaojun Wan
- **URL**: <http://arxiv.org/abs/2510.19310v1>
- **Submitted**: 2025-10-22 07:15:37
- **Topic Keywords**: query, rag, retrieval, search
- **Reason**: The paper addresses a problem related to query generation and claim extraction, which are relevant to information retrieval. However, the focus is on hallucination detection in large language models, which is somewhat tangential to the user's primary interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Current large language models (LLMs) often suffer from hallucination issues,
i,e, generating content that appears factual but is actually unreliable. A
typical hallucination detection pipeline involves response decomposition (i.e.,
claim extraction), query generation, evidence collection (i.e., search or
retrieval), and claim verification. However, existing methods exhibit
limitations in the first two stages, such as context loss during claim
extraction and low specificity in query generation, resulting in degraded
performance across the hallucination detection pipeline. In this work, we
introduce JointCQ https://github.com/pku0xff/JointCQ, a joint claim-and-query
generation framework designed to construct an effective and efficient
claim-query generator. Our framework leverages elaborately designed evaluation
criteria to filter synthesized training data, and finetunes a language model
for joint claim extraction and query generation, providing reliable and
informative inputs for downstream search and verification. Experimental results
demonstrate that our method outperforms previous methods on multiple
open-domain QA hallucination detection benchmarks, advancing the goal of more
trustworthy and transparent language model systems.

### 8. CoRECT: A Framework for Evaluating Embedding Compression Techniques at Scale

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: L. Caspari, M. Dinzinger, K. Ghosh Dastidar, C. Fellicious, J. Mitroviƒá, M. Granitzer
- **URL**: <http://arxiv.org/abs/2510.19340v2>
- **Submitted**: 2025-10-22 08:03:31
- **Topic Keywords**: dense retrieval, ranking, retrieval, rank, search
- **Reason**: This paper is somewhat related to Information Retrieval, specifically dense retrieval systems, but it focuses on embedding compression techniques rather than query understanding, ranking models, or user behavior modeling. While it touches on the optimization of search indices, it doesn't delve into the deep semantic understanding or real-time relevance optimization aspects that are central to your research interests.

#### Abstract
> Dense retrieval systems have proven to be effective across various
benchmarks, but require substantial memory to store large search indices.
Recent advances in embedding compression show that index sizes can be greatly
reduced with minimal loss in ranking quality. However, existing studies often
overlook the role of corpus complexity -- a critical factor, as recent work
shows that both corpus size and document length strongly affect dense retrieval
performance. In this paper, we introduce CoRECT (Controlled Retrieval
Evaluation of Compression Techniques), a framework for large-scale evaluation
of embedding compression methods, supported by a newly curated dataset
collection. To demonstrate its utility, we benchmark eight representative types
of compression methods. Notably, we show that non-learned compression achieves
substantial index size reduction, even on up to 100M passages, with
statistically insignificant performance loss. However, selecting the optimal
compression method remains challenging, as performance varies across models.
Such variability highlights the necessity of CoRECT to enable consistent
comparison and informed selection of compression methods. All code, data, and
results are available on GitHub and HuggingFace.

### 9. Interpretable Question Answering with Knowledge Graphs

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Kartikeya Aneja, Manasvi Srivastava, Subhayan Das, Nagender Aneja
- **URL**: <http://arxiv.org/abs/2510.19181v1>
- **Submitted**: 2025-10-22 02:36:35
- **Topic Keywords**: query, rag, retrieval augmented generation, retrieval, rank
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, specifically in the area of question answering and knowledge graph retrieval. However, it does not directly address your focus on query understanding, ranking models, or user behavior modeling, and its application is more towards question answering rather than general search technologies.

#### Abstract
> This paper presents a question answering system that operates exclusively on
a knowledge graph retrieval without relying on retrieval augmented generation
(RAG) with large language models (LLMs). Instead, a small paraphraser model is
used to paraphrase the entity relationship edges retrieved from querying the
knowledge graph. The proposed pipeline is divided into two main stages. The
first stage involves pre-processing a document to generate sets of
question-answer (QA) pairs. The second stage converts these QAs into a
knowledge graph from which graph-based retrieval is performed using embeddings
and fuzzy techniques. The graph is queried, re-ranked, and paraphrased to
generate a final answer. This work includes an evaluation using LLM-as-a-judge
on the CRAG benchmark, which resulted in accuracies of 71.9% and 54.4% using
LLAMA-3.2 and GPT-3.5-Turbo, respectively.

### 10. Lookahead Routing for Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Canbin Huang, Tianyuan Shi, Yuhua Zhu, Ruijun Chen, Xiaojun Quan
- **URL**: <http://arxiv.org/abs/2510.19506v1>
- **Submitted**: 2025-10-22 12:00:21
- **Topic Keywords**: query, queries, rag
- **Reason**: This paper proposes a routing framework for large language models, which is somewhat related to information retrieval, particularly in the context of query understanding and model selection. However, the focus is on routing and model selection rather than ranking models or user behavior modeling, making it less central to your research interests.

#### Abstract
> Large language model (LLM) routers improve the efficiency of multi-model
systems by directing each query to the most appropriate model while leveraging
the diverse strengths of heterogeneous LLMs. Most existing approaches frame
routing as a classification problem based solely on the input query. While this
reduces overhead by avoiding inference across all models, it overlooks valuable
information that could be gleaned from potential outputs and fails to capture
implicit intent or contextual nuances that often emerge only during response
generation. These limitations can result in suboptimal routing decisions,
particularly for complex or ambiguous queries that require deeper semantic
understanding. To address this challenge, we propose Lookahead, a routing
framework that "foresees" potential model outputs by predicting their latent
representations and uses these predictions to guide model selection, thus
enabling more informed routing without full inference. Within this framework,
we implement two approaches based on causal and masked language models.
Empirical evaluations across seven public benchmarks - spanning instruction
following, mathematical reasoning, and code generation - show that Lookahead
consistently outperforms existing routing baselines, achieving an average
performance gain of 7.7% over the state-of-the-art. Our code is available at
https://github.com/huangcb01/lookahead-routing.

### 11. DiSRouter: Distributed Self-Routing for LLM Selections

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Hang Zheng, Hongshen Xu, Yongkai Lin, Shuai Fan, Lu Chen, Kai Yu
- **URL**: <http://arxiv.org/abs/2510.19208v1>
- **Submitted**: 2025-10-22 03:36:40
- **Topic Keywords**: query, queries, rag
- **Reason**: The paper explores query routing for Large Language Models (LLMs), which is somewhat related to information retrieval and search technologies. However, the focus on LLMs and self-awareness training is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling. While the paper touches on scalability and generalizability, it does not explicitly address real-time relevance optimization or deep semantic understanding.

#### Abstract
> The proliferation of Large Language Models (LLMs) has created a diverse
ecosystem of models with highly varying performance and costs, necessitating
effective query routing to balance performance and expense. Current routing
systems often rely on a centralized external router trained on a fixed set of
LLMs, making them inflexible and prone to poor performance since the small
router can not fully understand the knowledge boundaries of different LLMs. We
introduce DiSRouter (Distributed Self-Router), a novel paradigm that shifts
from centralized control to distributed routing. In DiSRouter, a query
traverses a network of LLM agents, each independently deciding whether to
answer or route to other agents based on its own self-awareness, its ability to
judge its competence. This distributed design offers superior flexibility,
scalability, and generalizability. To enable this, we propose a two-stage
Self-Awareness Training pipeline that enhances each LLM's self-awareness.
Extensive experiments demonstrate that DiSRouter significantly outperforms
existing routing methods in utility across various scenarios, effectively
distinguishes between easy and hard queries, and shows strong generalization to
out-of-domain tasks. Our work validates that leveraging an LLM's intrinsic
self-awareness is more effective than external assessment, paving the way for
more modular and efficient multi-agent systems.

### 12. From Answers to Guidance: A Proactive Dialogue System for Legal Documents

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Ashish Chouhan, Michael Gertz
- **URL**: <http://arxiv.org/abs/2510.19723v1>
- **Submitted**: 2025-10-22 16:08:05
- **Comment**: 21 pages, 3 figures, 2 tables, 2 prompts
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper focuses on a proactive dialogue system for legal documents, which involves information retrieval and natural language processing. However, the specific context and application (legal documents) are not directly related to the user's core research themes in information retrieval and search technologies. The paper's emphasis on proactive dialogue and structured navigation is somewhat relevant to the user's interests in query understanding and ranking models, but the connection is not strong enough to warrant a higher score.

#### Abstract
> The accessibility of legal information remains a constant challenge,
particularly for laypersons seeking to understand and apply complex
institutional texts. While the European Union provides open access to
legislation, parliamentary responses, and regulatory documents, these resources
can be challenging for laypeople to explore. In this paper, we introduce
EUDial, a proactive multi-turn dialogue dataset constructed from 204 blogs
curated by the Citizens' Enquiries Unit (AskEP) of the European Parliamentary
Research Service. EUDial contains 880 dialogue turns (averaging 4.3 turns per
dialogue), where each dialogue includes initial questions, structured answers,
and follow-up questions. Beyond dataset construction, we propose the LexGuide
framework that leverages retrieval-augmented generation with hierarchical topic
organization to structure dialogue progression, ensuring both comprehensive
coverage of legal aspects and coherence across conversational turns. The
results demonstrate that proactive, structured navigation closes the gap
between the availability of legal information and citizen comprehension,
establishing EUDial and LexGuide as practical resources for advancing proactive
legal dialogue systems.

### 13. Do Prompts Reshape Representations? An Empirical Study of Prompting Effects on Embeddings

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Cesar Gonzalez-Gutierrez, Dirk Hovy
- **URL**: <http://arxiv.org/abs/2510.19694v1>
- **Submitted**: 2025-10-22 15:43:40
- **Topic Keywords**: relevance, rag
- **Reason**: The paper explores the effects of prompting on pre-trained language model embeddings, which is related to NLP and deep semantic understanding. However, the focus on zero-shot classification and probing experiments is somewhat distant from the user's primary interests in IR, ranking models, and user behavior modeling.

#### Abstract
> Prompting is a common approach for leveraging LMs in zero-shot settings.
However, the underlying mechanisms that enable LMs to perform diverse tasks
without task-specific supervision remain poorly understood. Studying the
relationship between prompting and the quality of internal representations can
shed light on how pre-trained embeddings may support in-context task solving.
In this empirical study, we conduct a series of probing experiments on prompt
embeddings, analyzing various combinations of prompt templates for zero-shot
classification. Our findings show that while prompting affects the quality of
representations, these changes do not consistently correlate with the relevance
of the prompts to the target task. This result challenges the assumption that
more relevant prompts necessarily lead to better representations. We further
analyze potential factors that may contribute to this unexpected behavior.

### 14. Unraveling Emotions with Pre-Trained Models

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Alejandro Paj√≥n-Sanmart√≠n, Francisco De Arriba-P√©rez, Silvia Garc√≠a-M√©ndez, F√°tima Leal, Benedita Malheiro, Juan Carlos Burguillo-Rial
- **URL**: <http://arxiv.org/abs/2510.19668v1>
- **Submitted**: 2025-10-22 15:13:52
- **Topic Keywords**: queries, user behavior
- **Reason**: The paper explores the application of pre-trained models in emotion recognition, which is related to user behavior modeling and NLP. However, it does not directly focus on information retrieval or search technologies, and its relevance to the e-commerce domain is not explicitly stated. The paper's emphasis on sentiment analysis and human-computer interaction suggests some overlap with user behavior modeling, but it is not a central match for the user's core research themes.

#### Abstract
> Transformer models have significantly advanced the field of emotion
recognition. However, there are still open challenges when exploring open-ended
queries for Large Language Models (LLMs). Although current models offer good
results, automatic emotion analysis in open texts presents significant
challenges, such as contextual ambiguity, linguistic variability, and
difficulty interpreting complex emotional expressions. These limitations make
the direct application of generalist models difficult. Accordingly, this work
compares the effectiveness of fine-tuning and prompt engineering in emotion
detection in three distinct scenarios: (i) performance of fine-tuned
pre-trained models and general-purpose LLMs using simple prompts; (ii)
effectiveness of different emotion prompt designs with LLMs; and (iii) impact
of emotion grouping techniques on these models. Experimental tests attain
metrics above 70% with a fine-tuned pre-trained model for emotion recognition.
Moreover, the findings highlight that LLMs require structured prompt
engineering and emotion grouping to enhance their performance. These
advancements improve sentiment analysis, human-computer interaction, and
understanding of user behavior across various domains.

### 15. Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Jackson Hassell, Dan Zhang, Hannah Kim, Tom Mitchell, Estevam Hruschka
- **URL**: <http://arxiv.org/abs/2510.19897v1>
- **Submitted**: 2025-10-22 17:58:03
- **Comment**: 11 pages
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper explores a novel approach to agent adaptation using semantic and episodic memory, which is somewhat related to our interest in query understanding and ranking models. However, the focus on agent adaptation and large language models is not directly aligned with our core research themes in Information Retrieval and Search technologies.

#### Abstract
> We investigate how agents built on pretrained large language models can learn
target classification functions from labeled examples without parameter
updates. While conventional approaches like fine-tuning are often costly,
inflexible, and opaque, we propose a memory-augmented framework that leverages
both labeled data and LLM-generated critiques. Our framework uses episodic
memory to store instance-level critiques-capturing specific past
experiences-and semantic memory to distill these into reusable, task-level
guidance. Across a diverse set of tasks, incorporating critiques yields up to a
24.8 percent accuracy improvement over retrieval-based (RAG-style) baselines
that rely only on labels. Through extensive empirical evaluation, we uncover
distinct behavioral differences between OpenAI and opensource models,
particularly in how they handle fact-oriented versus preference-based data. To
interpret how models respond to different representations of supervision
encoded in memory, we introduce a novel metric, suggestibility. This helps
explain observed behaviors and illuminates how model characteristics and memory
strategies jointly shape learning dynamics. Our findings highlight the promise
of memory-driven, reflective learning for building more adaptive and
interpretable LLM agents.

### 16. LLavaCode: Compressed Code Representations for Retrieval-Augmented Code Generation

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Daria Cherniuk, Nikita Sukhorukov, Nikita Sushko, Daniil Gusak, Danil Sivtsov, Elena Tutubalina, Evgeny Frolov
- **URL**: <http://arxiv.org/abs/2510.19644v1>
- **Submitted**: 2025-10-22 14:49:21
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of code completion and retrieval-augmented generation. However, the focus on code generation and compression does not directly align with your primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Retrieval-augmented generation has emerged as one of the most effective
approaches for code completion, particularly when context from a surrounding
repository is essential. However, incorporating context significantly extends
sequence length, leading to slower inference - a critical limitation for
interactive settings such as IDEs. In this work, we introduce LlavaCode, a
framework that compresses code into compact, semantically rich representations
interpretable by code LLM, enhancing generation quality while reducing the
retrieved context to only a few compressed single-token vectors. Using a small
projector module we can significantly increase the EM and ES metrics of coding
model with negligible latency increase. Our experiments demonstrate that
compressed context enables 20-38% reduction in Time-to-First-Token (TTFT) on
line completion tasks compared to full-RAG pipelines.

### 17. Algorithmic Fairness in NLP: Persona-Infused LLMs for Human-Centric Hate Speech Detection

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Ewelina Gajewska, Arda Derbent, Jaroslaw A Chudziak, Katarzyna Budzynska
- **URL**: <http://arxiv.org/abs/2510.19331v1>
- **Submitted**: 2025-10-22 07:48:57
- **Comment**: This paper has been accepted for the upcoming 59th Hawaii
  International Conference on System Sciences (HICSS-59), 2026, Hawaii, USA.
  The final published version will appear in the official conference
  proceedings
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper explores algorithmic fairness in NLP, specifically in hate speech detection, using persona-infused LLMs. While it touches on NLP and deep semantic understanding, its focus on hate speech detection and persona-based approaches is somewhat tangential to the user's core research interests in IR and search technologies.

#### Abstract
> In this paper, we investigate how personalising Large Language Models
(Persona-LLMs) with annotator personas affects their sensitivity to hate
speech, particularly regarding biases linked to shared or differing identities
between annotators and targets. To this end, we employ Google's Gemini and
OpenAI's GPT-4.1-mini models and two persona-prompting methods: shallow persona
prompting and a deeply contextualised persona development based on
Retrieval-Augmented Generation (RAG) to incorporate richer persona profiles. We
analyse the impact of using in-group and out-group annotator personas on the
models' detection performance and fairness across diverse social groups. This
work bridges psychological insights on group identity with advanced NLP
techniques, demonstrating that incorporating socio-demographic attributes into
LLMs can address bias in automated hate speech detection. Our results highlight
both the potential and limitations of persona-based approaches in reducing
bias, offering valuable insights for developing more equitable hate speech
detection systems.

### 18. Style Attack Disguise: When Fonts Become a Camouflage for Adversarial Intent

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Yangshijie Zhang, Xinda Wang, Jialin Liu, Wenqiang Wang, Zhicong Ma, Xingxing Jia
- **URL**: <http://arxiv.org/abs/2510.19641v1>
- **Submitted**: 2025-10-22 14:40:24
- **Topic Keywords**: query
- **Reason**: This paper explores a style-based attack on NLP models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on stylistic fonts and font-like emojis as a vulnerability in NLP models does not directly align with the user's primary research interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> With social media growth, users employ stylistic fonts and font-like emoji to
express individuality, creating visually appealing text that remains
human-readable. However, these fonts introduce hidden vulnerabilities in NLP
models: while humans easily read stylistic text, models process these
characters as distinct tokens, causing interference. We identify this
human-model perception gap and propose a style-based attack, Style Attack
Disguise (SAD). We design two sizes: light for query efficiency and strong for
superior attack performance. Experiments on sentiment classification and
machine translation across traditional models, LLMs, and commercial services
demonstrate SAD's strong attack performance. We also show SAD's potential
threats to multimodal tasks including text-to-image and text-to-speech
generation.

### 19. Balancing Rewards in Text Summarization: Multi-Objective Reinforcement Learning via HyperVolume Optimization

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Junjie Song, Yiwen Liu, Dapeng Li, Yin Sun, Shukun Fu, Siqi Chen, Yuji Cao
- **URL**: <http://arxiv.org/abs/2510.19325v1>
- **Submitted**: 2025-10-22 07:39:04
- **Topic Keywords**: relevance
- **Reason**: This paper focuses on text summarization, a task related to information retrieval, but with a strong emphasis on NLP and multi-objective optimization. While it leverages reinforcement learning and large language models, it doesn't directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's relevance is somewhat tangential to the user's primary research themes.

#### Abstract
> Text summarization is a crucial task that requires the simultaneous
optimization of multiple objectives, including consistency, coherence,
relevance, and fluency, which presents considerable challenges. Although large
language models (LLMs) have demonstrated remarkable performance, enhanced by
reinforcement learning (RL), few studies have focused on optimizing the
multi-objective problem of summarization through RL based on LLMs. In this
paper, we introduce hypervolume optimization (HVO), a novel optimization
strategy that dynamically adjusts the scores between groups during the reward
process in RL by using the hypervolume method. This method guides the model's
optimization to progressively approximate the pareto front, thereby generating
balanced summaries across multiple objectives. Experimental results on several
representative summarization datasets demonstrate that our method outperforms
group relative policy optimization (GRPO) in overall scores and shows more
balanced performance across different dimensions. Moreover, a 7B foundation
model enhanced by HVO performs comparably to GPT-4 in the summarization task,
while maintaining a shorter generation length. Our code is publicly available
at https://github.com/ai4business-LiAuto/HVO.git

### 20. CrossNews-UA: A Cross-lingual News Semantic Similarity Benchmark for Ukrainian, Polish, Russian, and English

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Daryna Dementieva, Evgeniya Sukhodolskaya, Alexander Fraser
- **URL**: <http://arxiv.org/abs/2510.19628v1>
- **Submitted**: 2025-10-22 14:23:50
- **Topic Keywords**: rag
- **Reason**: The paper focuses on cross-lingual news semantic similarity, which is somewhat related to information retrieval and natural language processing. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's focus on news analysis and fake news detection is also somewhat tangential to the user's primary research themes.

#### Abstract
> In the era of social networks and rapid misinformation spread, news analysis
remains a critical task. Detecting fake news across multiple languages,
particularly beyond English, poses significant challenges. Cross-lingual news
comparison offers a promising approach to verify information by leveraging
external sources in different languages (Chen and Shu, 2024). However, existing
datasets for cross-lingual news analysis (Chen et al., 2022a) were manually
curated by journalists and experts, limiting their scalability and adaptability
to new languages. In this work, we address this gap by introducing a scalable,
explainable crowdsourcing pipeline for cross-lingual news similarity
assessment. Using this pipeline, we collected a novel dataset CrossNews-UA of
news pairs in Ukrainian as a central language with linguistically and
contextually relevant languages-Polish, Russian, and English. Each news pair is
annotated for semantic similarity with detailed justifications based on the 4W
criteria (Who, What, Where, When). We further tested a range of models, from
traditional bag-of-words, Transformer-based architectures to large language
models (LLMs). Our results highlight the challenges in multilingual news
analysis and offer insights into models performance.

### 21. LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Siyuan Wang, Gaokai Zhang, Li Lyna Zhang, Ning Shang, Fan Yang, Dongyao Chen, Mao Yang
- **URL**: <http://arxiv.org/abs/2510.19363v1>
- **Submitted**: 2025-10-22 08:35:28
- **Topic Keywords**: retrieval
- **Reason**: This paper introduces a reinforcement learning method for advanced long-context reasoning, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on large language models and multi-hop QA accuracy is not directly aligned with the user's primary research interests in IR, search technologies, and user behavior modeling.

#### Abstract
> Reasoning over long contexts is essential for large language models. While
reinforcement learning (RL) enhances short-context reasoning by inducing "Aha"
moments in chain-of-thought, the advanced thinking patterns required for
long-context reasoning remain largely unexplored, and high-difficulty RL data
are scarce. In this paper, we introduce LoongRL, a data-driven RL method for
advanced long-context reasoning. Central to LoongRL is KeyChain, a synthesis
approach that transforms short multi-hop QA into high-difficulty long-context
tasks by inserting UUID chains that hide the true question among large
collections of distracting documents. Solving these tasks requires the model to
trace the correct chain step-by-step, identify the true question, retrieve
relevant facts and reason over them to answer correctly. RL training on
KeyChain data induces an emergent plan-retrieve-reason-recheck reasoning
pattern that generalizes far beyond training length. Models trained at 16K
effectively solve 128K tasks without prohibitive full-length RL rollout costs.
On Qwen2.5-7B and 14B, LoongRL substantially improves long-context multi-hop QA
accuracy by +23.5% and +21.1% absolute gains. The resulting LoongRL-14B reaches
a score of 74.2, rivaling much larger frontier models such as o3-mini (74.5)
and DeepSeek-R1 (74.9). It also improves long-context retrieval, passes all
128K needle-in-a-haystack stress tests, and preserves short-context reasoning
capabilities.

### 22. Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Ling Team, Bin Han, Caizhi Tang, Chen Liang, Donghao Zhang, Fan Yuan, Feng Zhu, Jie Gao, Jingyu Hu, Longfei Li, Meng Li, Mingyang Zhang, Peijie Jiang, Peng Jiao, Qian Zhao, Qingyuan Yang, Wenbo Shen, Xinxing Yang, Yalin Zhang, Yankun Ren, Yao Zhao, Yibo Cao, Yixuan Sun, Yue Zhang, Yuchen Fang, Zibin Lin, Zixuan Cheng, Jun Zhou
- **URL**: <http://arxiv.org/abs/2510.19338v2>
- **Submitted**: 2025-10-22 07:59:38
- **Comment**: 20 pages, 13 figures
- **Topic Keywords**: rag
- **Reason**: The paper discusses an efficient hybrid architecture for long-context reasoning, which is somewhat related to information retrieval and ranking models. However, the focus on attention mechanisms and computational efficiency is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> In this technical report, we present the Ring-linear model series,
specifically including Ring-mini-linear-2.0 and Ring-flash-linear-2.0.
Ring-mini-linear-2.0 comprises 16B parameters and 957M activations, while
Ring-flash-linear-2.0 contains 104B parameters and 6.1B activations. Both
models adopt a hybrid architecture that effectively integrates linear attention
and softmax attention, significantly reducing I/O and computational overhead in
long-context inference scenarios. Compared to a 32 billion parameter dense
model, this series reduces inference cost to 1/10, and compared to the original
Ring series, the cost is also reduced by over 50%. Furthermore, through
systematic exploration of the ratio between different attention mechanisms in
the hybrid architecture, we have identified the currently optimal model
structure. Additionally, by leveraging our self-developed high-performance FP8
operator library-linghe, overall training efficiency has been improved by 50%.
Benefiting from the high alignment between the training and inference engine
operators, the models can undergo long-term, stable, and highly efficient
optimization during the reinforcement learning phase, consistently maintaining
SOTA performance across multiple challenging complex reasoning benchmarks.

### 23. Metadata Extraction Leveraging Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Cuize Han, Sesh Jalagam
- **URL**: <http://arxiv.org/abs/2510.19334v1>
- **Submitted**: 2025-10-22 07:56:36
- **Topic Keywords**: rag
- **Reason**: The paper explores metadata extraction using Large Language Models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on contract review and legal document analysis is not directly aligned with the user's primary research interests in e-commerce, NLP, and IR. The paper's emphasis on practical applications in the legal domain also limits its relevance to the user's broader interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> The advent of Large Language Models has revolutionized tasks across domains,
including the automation of legal document analysis, a critical component of
modern contract management systems. This paper presents a comprehensive
implementation of LLM-enhanced metadata extraction for contract review,
focusing on the automatic detection and annotation of salient legal clauses.
Leveraging both the publicly available Contract Understanding Atticus Dataset
(CUAD) and proprietary contract datasets, our work demonstrates the integration
of advanced LLM methodologies with practical applications. We identify three
pivotal elements for optimizing metadata extraction: robust text conversion,
strategic chunk selection, and advanced LLM-specific techniques, including
Chain of Thought (CoT) prompting and structured tool calling. The results from
our experiments highlight the substantial improvements in clause identification
accuracy and efficiency. Our approach shows promise in reducing the time and
cost associated with contract review while maintaining high accuracy in legal
clause identification. The results suggest that carefully optimized LLM systems
could serve as valuable tools for legal professionals, potentially increasing
access to efficient contract review services for organizations of all sizes.

### 24. Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Nishant Balepur, Dang Nguyen, Dayeon Ki
- **URL**: <http://arxiv.org/abs/2510.19892v1>
- **Submitted**: 2025-10-22 17:21:16
- **Comment**: Accepted as a Spotlight paper at the EMNLP 2025 Wordplay Workshop
- **Topic Keywords**: ranking, pairwise, rank
- **Reason**: This paper focuses on multimodal language models and game-based evaluations, which is not directly related to the user's core research themes in Information Retrieval and Search technologies. While it touches on aspects of language understanding, it does not specifically address query understanding, ranking models, or user behavior modeling, making it somewhat tangential to the user's interests.

#### Abstract
> Multi-modal large language models (MLMs) are often assessed on static,
individual benchmarks -- which cannot jointly assess MLM capabilities in a
single task -- or rely on human or model pairwise comparisons -- which is
highly subjective, expensive, and allows models to exploit superficial
shortcuts (e.g., verbosity) to inflate their win-rates. To overcome these
issues, we propose game-based evaluations to holistically assess MLM
capabilities. Games require multiple abilities for players to win, are
inherently competitive, and are governed by fix, objective rules, and makes
evaluation more engaging, providing a robust framework to address the
aforementioned challenges. We manifest this evaluation specifically through
Dixit, a fantasy card game where players must generate captions for a card that
trick some, but not all players, into selecting the played card. Our
quantitative experiments with five MLMs show Dixit win-rate rankings are
perfectly correlated with those on popular MLM benchmarks, while games between
human and MLM players in Dixit reveal several differences between agent
strategies and areas of improvement for MLM reasoning.

### 25. CoSense-LLM: Semantics at the Edge with Cost- and Uncertainty-Aware Cloud-Edge Cooperation

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Hasan Akgul, Mari Eplik, Javier Rojas, Aina Binti Abdullah, Pieter van der Merwe
- **URL**: <http://arxiv.org/abs/2510.19670v1>
- **Submitted**: 2025-10-22 15:16:56
- **Comment**: 19 pages,8 figures
- **Topic Keywords**: rag, retrieval, personalization
- **Reason**: This paper focuses on edge computing and large language models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve semantic understanding, it is more focused on the technical aspects of edge computing and large model deployments rather than IR and NLP.

#### Abstract
> We present CoSense-LLM, an edge-first framework that turns continuous
multimodal sensor streams (for example Wi-Fi CSI, IMU, audio, RFID, and
lightweight vision) into compact, verifiable semantic tokens and coordinates
with large language models under explicit latency, energy, bandwidth, and
privacy constraints. CoSense-LLM has four parts: (i) SenseFusion, a lightweight
encoder that aligns sensor embeddings with language and compresses them into
short discrete code sequences; (ii) Edge-RAG, a local hybrid retrieval layer
that grounds generation in site specific policies and notes; (iii)
PromptRouter, a cost and uncertainty aware policy that selects edge only
generation, edge plus retrieval, or compact cloud escalation; and (iv) Secure
Execution, an auditable redaction path that enforces data minimization so raw
waveforms never leave the device. The system works with modern serving
optimizations, including paged or streaming KV caches, FlashAttention style
kernels, speculative decoding, and quantized LoRA adapters, and supports on
device personalization and federated updates under non IID drift. Across home,
office, and clinic deployments, CoSense-LLM delivers grounded explanations
while meeting tight service level objectives: it sustains sub second (p95) end
to end latency on edge dominant paths, reduces inter tier token and bandwidth
costs by preferring local retrieval grounded responses, and preserves privacy
by transmitting only discrete codes and redacted metadata. Ablations show that
Edge-RAG improves factual consistency and reduces contradictions, calibrated
uncertainty enables selective abstention and controlled escalations, and KV
plus decoding accelerators lower energy per decision. The results support an
edge first design that treats semantics, privacy, and predictable latency as co
equal goals for large model deployments in interference prone environments.

### 26. Local Obfuscation by GLINER for Impartial Context Aware Lineage: Development and evaluation of PII Removal system

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Prakrithi Shivaprakash, Lekhansh Shukla, Animesh Mukherjee, Prabhat Chand, Pratima Murthy
- **URL**: <http://arxiv.org/abs/2510.19346v1>
- **Submitted**: 2025-10-22 08:12:07
- **Comment**: 30 pages, 15 main text and 15 supplementary material
- **Topic Keywords**: rag, ctr, search
- **Reason**: This paper focuses on a specific task of PII removal from clinical notes, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves a fine-tuned transformer model, the context and application are quite different from the user's areas of focus.

#### Abstract
> Removing Personally Identifiable Information (PII) from clinical notes in
Electronic Health Records (EHRs) is essential for research and AI development.
While Large Language Models (LLMs) are powerful, their high computational costs
and the data privacy risks of API-based services limit their use, especially in
low-resource settings. To address this, we developed LOGICAL (Local Obfuscation
by GLINER for Impartial Context-Aware Lineage), an efficient, locally
deployable PII removal system built on a fine-tuned Generalist and Lightweight
Named Entity Recognition (GLiNER) model. We used 1515 clinical documents from a
psychiatric hospital's EHR system. We defined nine PII categories for removal.
A modern-gliner-bi-large-v1.0 model was fine-tuned on 2849 text instances and
evaluated on a test set of 376 instances using character-level precision,
recall, and F1-score. We compared its performance against Microsoft Azure NER,
Microsoft Presidio, and zero-shot prompting with Gemini-Pro-2.5 and
Llama-3.3-70B-Instruct. The fine-tuned GLiNER model achieved superior
performance, with an overall micro-average F1-score of 0.980, significantly
outperforming Gemini-Pro-2.5 (F1-score: 0.845). LOGICAL correctly sanitised 95%
of documents completely, compared to 64% for the next-best solution. The model
operated efficiently on a standard laptop without a dedicated GPU. However, a
2% entity-level false negative rate underscores the need for human-in-the-loop
validation across all tested systems. Fine-tuned, specialised transformer
models like GLiNER offer an accurate, computationally efficient, and secure
solution for PII removal from clinical notes. This "sanitisation at the source"
approach is a practical alternative to resource-intensive LLMs, enabling the
creation of de-identified datasets for research and AI development while
preserving data privacy, particularly in resource-constrained environments.

### 27. Training-Free Spectral Fingerprints of Voice Processing in Transformers

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Valentin No√´l
- **URL**: <http://arxiv.org/abs/2510.19131v1>
- **Submitted**: 2025-10-21 23:33:43
- **Comment**: Preprint under review (2025). 12 pages, 8 figures
- **Topic Keywords**: relevance, ctr
- **Reason**: This paper focuses on analyzing transformer architectures using spectral analysis and graph signal processing, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Different transformer architectures implement identical linguistic
computations via distinct connectivity patterns, yielding model imprinted
``computational fingerprints'' detectable through spectral analysis. Using
graph signal processing on attention induced token graphs, we track changes in
algebraic connectivity (Fiedler value, $\Delta\lambda_2$) under voice
alternation across 20 languages and three model families, with a prespecified
early window (layers 2--5). Our analysis uncovers clear architectural
signatures: Phi-3-Mini shows a dramatic English specific early layer disruption
($\overline{\Delta\lambda_2}_{[2,5]}\!\approx\!-0.446$) while effects in 19
other languages are minimal, consistent with public documentation that
positions the model primarily for English use. Qwen2.5-7B displays small,
distributed shifts that are largest for morphologically rich languages, and
LLaMA-3.2-1B exhibits systematic but muted responses. These spectral signatures
correlate strongly with behavioral differences (Phi-3: $r=-0.976$) and are
modulated by targeted attention head ablations, linking the effect to early
attention structure and confirming functional relevance. Taken together, the
findings are consistent with the view that training emphasis can leave
detectable computational imprints: specialized processing strategies that
manifest as measurable connectivity patterns during syntactic transformations.
Beyond voice alternation, the framework differentiates reasoning modes,
indicating utility as a simple, training free diagnostic for revealing
architectural biases and supporting model reliability analysis.

### 28. When Can We Trust LLMs in Mental Health? Large-Scale Benchmarks for Reliable LLM Evaluation

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Abeer Badawi, Elahe Rahimi, Md Tahmid Rahman Laskar, Sheri Grach, Lindsay Bertrand, Lames Danok, Jimmy Huang, Frank Rudzicz, Elham Dolatabadi
- **URL**: <http://arxiv.org/abs/2510.19032v1>
- **Submitted**: 2025-10-21 19:21:21
- **Topic Keywords**: relevance, acl
- **Reason**: This paper focuses on the evaluation of Large Language Models (LLMs) in mental health, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. While it involves deep semantic understanding, the context is specific to mental health and not aligned with the user's core research themes.

#### Abstract
> Evaluating Large Language Models (LLMs) for mental health support is
challenging due to the emotionally and cognitively complex nature of
therapeutic dialogue. Existing benchmarks are limited in scale, reliability,
often relying on synthetic or social media data, and lack frameworks to assess
when automated judges can be trusted. To address the need for large-scale
dialogue datasets and judge reliability assessment, we introduce two benchmarks
that provide a framework for generation and evaluation. MentalBench-100k
consolidates 10,000 one-turn conversations from three real scenarios datasets,
each paired with nine LLM-generated responses, yielding 100,000 response pairs.
MentalAlign-70k}reframes evaluation by comparing four high-performing LLM
judges with human experts across 70,000 ratings on seven attributes, grouped
into Cognitive Support Score (CSS) and Affective Resonance Score (ARS). We then
employ the Affective Cognitive Agreement Framework, a statistical methodology
using intraclass correlation coefficients (ICC) with confidence intervals to
quantify agreement, consistency, and bias between LLM judges and human experts.
Our analysis reveals systematic inflation by LLM judges, strong reliability for
cognitive attributes such as guidance and informativeness, reduced precision
for empathy, and some unreliability in safety and relevance. Our contributions
establish new methodological and empirical foundations for reliable,
large-scale evaluation of LLMs in mental health. We release the benchmarks and
codes at: https://github.com/abeerbadawi/MentalBench/

### 29. An Expert-grounded benchmark of General Purpose LLMs in LCA

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Artur Donaldson, Bharathan Balaji, Cajetan Oriekezie, Manish Kumar, Laure Patouillard
- **URL**: <http://arxiv.org/abs/2510.19886v1>
- **Submitted**: 2025-10-22 15:56:54
- **Topic Keywords**: rag, acl
- **Reason**: This paper is not directly related to the user's research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves large language models, the focus is on their application in Life Cycle Assessment, which is not a central theme in the user's research background.

#### Abstract
> Purpose: Artificial intelligence (AI), and in particular large language
models (LLMs), are increasingly being explored as tools to support life cycle
assessment (LCA). While demonstrations exist across environmental and social
domains, systematic evidence on their reliability, robustness, and usability
remains limited. This study provides the first expert-grounded benchmark of
LLMs in LCA, addressing the absence of standardized evaluation frameworks in a
field where no clear ground truth or consensus protocols exist.
  Methods: We evaluated eleven general-purpose LLMs, spanning both commercial
and open-source families, across 22 LCA-related tasks. Seventeen experienced
practitioners reviewed model outputs against criteria directly relevant to LCA
practice, including scientific accuracy, explanation quality, robustness,
verifiability, and adherence to instructions. We collected 168 expert reviews.
  Results: Experts judged 37% of responses to contain inaccurate or misleading
information. Ratings of accuracy and quality of explanation were generally
rated average or good on many models even smaller models, and format adherence
was generally rated favourably. Hallucination rates varied significantly, with
some models producing hallucinated citations at rates of up to 40%. There was
no clear-cut distinction between ratings on open-weight versus closed-weight
LLMs, with open-weight models outperforming or competing on par with
closed-weight models on criteria such as accuracy and quality of explanation.
  Conclusion: These findings highlight the risks of applying LLMs na\"ively in
LCA, such as when LLMs are treated as free-form oracles, while also showing
benefits especially around quality of explanation and alleviating labour
intensiveness of simple tasks. The use of general-purpose LLMs without
grounding mechanisms presents ...

### 30. VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Dunjie Lu, Yiheng Xu, Junli Wang, Haoyuan Wu, Xinyuan Wang, Zekun Wang, Junlin Yang, Hongjin Su, Jixuan Chen, Junda Chen, Yuchen Mao, Jingren Zhou, Junyang Lin, Binyuan Hui, Tao Yu
- **URL**: <http://arxiv.org/abs/2510.19488v1>
- **Submitted**: 2025-10-22 11:25:48
- **Comment**: 8 pages, 6 figures
- **Topic Keywords**: rag, click
- **Reason**: This paper is not directly related to Information Retrieval or Search technologies, but rather focuses on computer-use agents and GUI interaction data mining. While it involves video analysis and action recognition, the context is not aligned with the user's primary research interests in IR and NLP.

#### Abstract
> Training computer-use agents requires massive amounts of GUI interaction
data, but manually annotating action trajectories at scale is prohibitively
expensive. We present VideoAgentTrek, a scalable pipeline that automatically
mines training data from publicly available screen-recorded videos at web
scale, eliminating the need for manual annotation. Our approach addresses a key
challenge: raw videos contain implicit demonstrations but lack explicit action
labels. To solve this, we develop Video2Action, an inverse dynamics module
(IDM) with two components: (1) a video grounding model that detects and
localizes GUI actions with precise temporal boundaries and context, and (2) an
action-content recognizer that extracts structured parameters like click
coordinates and typed text with high fidelity. Applied to 39,000 YouTube
tutorial videos, our pipeline generates 1.52 million interaction steps
automatically. We leverage this data through continued pretraining followed by
supervised fine-tuning. On OSWorld-Verified, our approach improves task success
rates from 9.3% (SFT-only baseline) to 15.8%, a 70% relative improvement. On
AgentNetBench, step accuracy increases from 64.1% to 69.3%. Our results
demonstrate that passive internet videos can be transformed into high-quality
supervision for computer-use agents, providing a scalable alternative to
expensive manual annotation.

### 31. XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Hamed Jelodar, Mohammad Meymani, Roozbeh Razavi-Far, Ali A. Ghorbani
- **URL**: <http://arxiv.org/abs/2510.19006v1>
- **Submitted**: 2025-10-21 18:35:38
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper focuses on applying large language models (LLMs) to software security, specifically malware detection and analysis. While it involves retrieval-augmented generation, which is related to information retrieval, the primary topic is not query understanding, ranking models, or user behavior modeling, making it less relevant to your core research interests.

#### Abstract
> Generative AI and large language models (LLMs) have shown strong capabilities
in code understanding, but their use in cybersecurity, particularly for malware
detection and analysis, remains limited. Existing detection systems often fail
to generalize to obfuscated or previously unseen threats, underscoring the need
for more adaptable and explainable models. To address this challenge, we
introduce XGen-Q, a domain-adapted LLM built on the Qwen-Coder architecture and
pretrained on a large-scale corpus of over one million malware samples,
spanning both source and assembly code. XGen-Q uses a multi-stage prompt
strategy combined with retrieval-augmented generation (RAG) to deliver reliable
malware identification and detailed forensic reporting, even in the presence of
complex code obfuscation. To further enhance generalization, we design a
training pipeline that systematically exposes the model to diverse obfuscation
patterns. Experimental results show that XGen-Q achieves significantly lower
perplexity than competitive baselines and exhibits strong performance on novel
malware samples, demonstrating the promise of LLM-based approaches for
interpretable and robust malware analysis.

### 32. Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yusu Qian, Eli Bocek-Rivele, Liangchen Song, Jialing Tong, Yinfei Yang, Jiasen Lu, Wenze Hu, Zhe Gan
- **URL**: <http://arxiv.org/abs/2510.19808v1>
- **Submitted**: 2025-10-22 17:43:15
- **Topic Keywords**: rag, search
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves text-guided image editing, it's focused on a specific task and dataset, and doesn't align with your primary areas of interest.

#### Abstract
> Recent advances in multimodal models have demonstrated remarkable text-guided
image editing capabilities, with systems like GPT-4o and Nano-Banana setting
new benchmarks. However, the research community's progress remains constrained
by the absence of large-scale, high-quality, and openly accessible datasets
built from real images. We introduce Pico-Banana-400K, a comprehensive
400K-image dataset for instruction-based image editing. Our dataset is
constructed by leveraging Nano-Banana to generate diverse edit pairs from real
photographs in the OpenImages collection. What distinguishes Pico-Banana-400K
from previous synthetic datasets is our systematic approach to quality and
diversity. We employ a fine-grained image editing taxonomy to ensure
comprehensive coverage of edit types while maintaining precise content
preservation and instruction faithfulness through MLLM-based quality scoring
and careful curation. Beyond single turn editing, Pico-Banana-400K enables
research into complex editing scenarios. The dataset includes three specialized
subsets: (1) a 72K-example multi-turn collection for studying sequential
editing, reasoning, and planning across consecutive modifications; (2) a
56K-example preference subset for alignment research and reward model training;
and (3) paired long-short editing instructions for developing instruction
rewriting and summarization capabilities. By providing this large-scale,
high-quality, and task-rich resource, Pico-Banana-400K establishes a robust
foundation for training and benchmarking the next generation of text-guided
image editing models.

### 33. Blackbox Model Provenance via Palimpsestic Membership Inference

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Rohith Kuditipudi, Jing Huang, Sally Zhu, Diyi Yang, Christopher Potts, Percy Liang
- **URL**: <http://arxiv.org/abs/2510.19796v1>
- **Submitted**: 2025-10-22 17:30:39
- **Topic Keywords**: query
- **Reason**: This paper focuses on model provenance and blackbox derivative models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language models, the context is more about model ownership and memorization rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> Suppose Alice trains an open-weight language model and Bob uses a blackbox
derivative of Alice's model to produce text. Can Alice prove that Bob is using
her model, either by querying Bob's derivative model (query setting) or from
the text alone (observational setting)? We formulate this question as an
independence testing problem--in which the null hypothesis is that Bob's model
or text is independent of Alice's randomized training run--and investigate it
through the lens of palimpsestic memorization in language models: models are
more likely to memorize data seen later in training, so we can test whether Bob
is using Alice's model using test statistics that capture correlation between
Bob's model or text and the ordering of training examples in Alice's training
run. If Alice has randomly shuffled her training data, then any significant
correlation amounts to exactly quantifiable statistical evidence against the
null hypothesis, regardless of the composition of Alice's training data. In the
query setting, we directly estimate (via prompting) the likelihood Bob's model
gives to Alice's training examples and order; we correlate the likelihoods of
over 40 fine-tunes of various Pythia and OLMo base models ranging from 1B to
12B parameters with the base model's training data order, achieving a p-value
on the order of at most 1e-8 in all but six cases. In the observational
setting, we try two approaches based on estimating 1) the likelihood of Bob's
text overlapping with spans of Alice's training examples and 2) the likelihood
of Bob's text with respect to different versions of Alice's model we obtain by
repeating the last phase (e.g., 1%) of her training run on reshuffled data. The
second approach can reliably distinguish Bob's text from as little as a few
hundred tokens; the first does not involve any retraining but requires many
more tokens (several hundred thousand) to achieve high power.

### 34. Re-evaluating Minimum Bayes Risk Decoding for Automatic Speech Recognition

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yuu Jinnai
- **URL**: <http://arxiv.org/abs/2510.19471v1>
- **Submitted**: 2025-10-22 11:06:20
- **Topic Keywords**: rag, search
- **Reason**: This paper is primarily focused on automatic speech recognition and speech translation, which are not directly related to the user's core research themes in Information Retrieval and Search technologies. While it does involve some aspects of ranking models, the context and application are quite different from the user's areas of interest.

#### Abstract
> Recent work has shown that sample-based Minimum Bayes Risk (MBR) decoding
outperforms beam search in text-to-text generation tasks, such as machine
translation, text summarization, and image captioning. On the other hand, beam
search is the current practice for speech-to-text tasks such as automatic
speech recognition (ASR) and Speech Translation (ST). Given that MBR decoding
is effective in text-to-text generation tasks, it is reasonable to expect it to
also be effective for speech-to-text tasks. In this paper, we evaluate MBR
decoding for ASR and ST tasks on English and Japanese using Whisper and its
derivative models. We observe that the accuracy of MBR decoding outperforms
that of beam search in most of the experimental settings we have evaluated. The
results show that MBR decoding is a promising method for offline ASR and ST
tasks that require high accuracy. The code is available at
https://github.com/CyberAgentAILab/mbr-for-asr

### 35. The Massive Legal Embedding Benchmark (MLEB)

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Umar Butler, Abdur-Rahman Butler, Adrian Lucas Malec
- **URL**: <http://arxiv.org/abs/2510.19365v1>
- **Submitted**: 2025-10-22 08:38:44
- **Comment**: 15 pages, 2 figures
- **Topic Keywords**: retrieval, search
- **Reason**: While the paper presents a benchmark for legal information retrieval, it does not align with the user's primary focus on information retrieval in areas requiring deep semantic understanding and real-time relevance optimization. The e-commerce domain is not mentioned, and the paper's focus is on legal information retrieval, which is not a central match to the user's research interests.

#### Abstract
> We present the Massive Legal Embedding Benchmark (MLEB), the largest, most
diverse, and most comprehensive open-source benchmark for legal information
retrieval to date. MLEB consists of ten expert-annotated datasets spanning
multiple jurisdictions (the US, UK, EU, Australia, Ireland, and Singapore),
document types (cases, legislation, regulatory guidance, contracts, and
literature), and task types (search, zero-shot classification, and question
answering). Seven of the datasets in MLEB were newly constructed in order to
fill domain and jurisdictional gaps in the open-source legal information
retrieval landscape. We document our methodology in building MLEB and creating
the new constituent datasets, and release our code, results, and data openly to
assist with reproducible evaluations.

### 36. SheetBrain: A Neuro-Symbolic Agent for Accurate Reasoning over Complex and Large Spreadsheets

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Ziwei Wang, Jiayuan Su, Mengyu Zhou, Huaxing Zeng, Mengni Jia, Xiao Lv, Haoyu Dong, Xiaojun Ma, Shi Han, Dongmei Zhang
- **URL**: <http://arxiv.org/abs/2510.19247v1>
- **Submitted**: 2025-10-22 05:09:44
- **Topic Keywords**: query
- **Reason**: This paper focuses on developing a neuro-symbolic agent for reasoning over complex spreadsheets, which is not directly related to Information Retrieval, Search technologies, or Natural Language Processing. While it involves understanding and manipulation of tabular data, the context is spreadsheet-specific and does not align with the user's core research themes.

#### Abstract
> Understanding and reasoning over complex spreadsheets remain fundamental
challenges for large language models (LLMs), which often struggle with
accurately capturing the complex structure of tables and ensuring reasoning
correctness. In this work, we propose SheetBrain, a neuro-symbolic dual
workflow agent framework designed for accurate reasoning over tabular data,
supporting both spreadsheet question answering and manipulation tasks.
SheetBrain comprises three core modules: an understanding module, which
produces a comprehensive overview of the spreadsheet - including sheet summary
and query-based problem insight to guide reasoning; an execution module, which
integrates a Python sandbox with preloaded table-processing libraries and an
Excel helper toolkit for effective multi-turn reasoning; and a validation
module, which verifies the correctness of reasoning and answers, triggering
re-execution when necessary. We evaluate SheetBrain on multiple public tabular
QA and manipulation benchmarks, and introduce SheetBench, a new benchmark
targeting large, multi-table, and structurally complex spreadsheets.
Experimental results show that SheetBrain significantly improves accuracy on
both existing benchmarks and the more challenging scenarios presented in
SheetBench. Our code is publicly available at
https://github.com/microsoft/SheetBrain.

### 37. Tibetan Language and AI: A Comprehensive Survey of Resources, Methods and Challenges

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Cheng Huang, Nyima Tashi, Fan Gao, Yutong Liu, Jiahao Li, Hao Tian, Siyang Jiang, Thupten Tsering, Ban Ma-bao, Renzeg Duojie, Gadeng Luosang, Rinchen Dongrub, Dorje Tashi, Jin Zhang, Xiao Feng, Hao Wang, Jie Tang, Guojie Tang, Xiangxiang Wang, Jia Zhang, Tsengdar Lee, Yongbin Yu
- **URL**: <http://arxiv.org/abs/2510.19144v1>
- **Submitted**: 2025-10-22 00:29:35
- **Topic Keywords**: rag, search
- **Reason**: This paper is primarily focused on Tibetan language and AI, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it does touch on NLP tasks, it is limited to a specific language and does not explore the user's areas of interest in query understanding, ranking models, or user behavior modeling.

#### Abstract
> Tibetan, one of the major low-resource languages in Asia, presents unique
linguistic and sociocultural characteristics that pose both challenges and
opportunities for AI research. Despite increasing interest in developing AI
systems for underrepresented languages, Tibetan has received limited attention
due to a lack of accessible data resources, standardized benchmarks, and
dedicated tools. This paper provides a comprehensive survey of the current
state of Tibetan AI in the AI domain, covering textual and speech data
resources, NLP tasks, machine translation, speech recognition, and recent
developments in LLMs. We systematically categorize existing datasets and tools,
evaluate methods used across different tasks, and compare performance where
possible. We also identify persistent bottlenecks such as data sparsity,
orthographic variation, and the lack of unified evaluation metrics.
Additionally, we discuss the potential of cross-lingual transfer, multi-modal
learning, and community-driven resource creation. This survey aims to serve as
a foundational reference for future work on Tibetan AI research and encourages
collaborative efforts to build an inclusive and sustainable AI ecosystem for
low-resource languages.

### 38. Adapting Multilingual Models to Code-Mixed Tasks via Model Merging

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Prashant Kodali, Vaishnavi Shivkumar, Swarang Joshi, Monojit Choudhary, Ponnurangam Kumaraguru, Manish Shrivastava
- **URL**: <http://arxiv.org/abs/2510.19782v2>
- **Submitted**: 2025-10-22 17:16:23
- **Comment**: 9 pages, 5 tables, CODS 2025
- **Topic Keywords**: rag
- **Reason**: This paper focuses on adapting multilingual models for code-mixed NLP tasks, which is somewhat related to the user's interests in Natural Language Processing (NLP). However, the specific application and approach are not directly aligned with the user's core research themes in Information Retrieval (IR) and Search technologies.

#### Abstract
> We study model merging as a practical alternative to conventional adaptation
strategies for code-mixed NLP. Starting from a multilingual base model, we: (i)
perform continued pre-training (CPT) on unlabeled code-mixed text to obtain an
adapted checkpoint, (ii) merge checkpoint with the base model, and (iii)
fine-tune (FT) on the downstream task data. We evaluate our approach for
sentence classification (sentiment and hate speech) task in English-Hindi
(En-Hi) and English-Spanish (En-Es) using XLM-R and Llama-3.2-1B models. Our
results show that merged models consistently outperform full fine-tuning and
CPT->FT. We observe gains of 2--5 points in F1 over full fine-tuning and ~1-2
points over CPT->FT, indicating that unlabeled data is leveraged more
effectively via merging than via CPT alone. Zero-/few-shot prompting with
larger LLMs (e.g., Llama-3.3-70B) lags behind fine-tuned and merged
checkpoints, underscoring limits of in-context learning for code-mixed inputs.
We further test cross-pair transfer by training on En-Hi and evaluating on
En-Ta and En-Ml: merged checkpoints transfer more strongly than
monolingual-English baselines (e.g., TV/TIES variants reaching 0.65-0.68 F1 vs
0.61-0.63 for full fine-tuning), suggesting that code-mixed knowledge is a more
reliable substrate for low-resource pairs. We conclude with adaptation recipes
matched to common data regimes (labeled only; labeled+unlabeled; transfer-only)
and discuss limitations and scaling considerations for broader tasks and larger
models.

### 39. SmartSwitch: Advancing LLM Reasoning by Overcoming Underthinking via Promoting Deeper Thought Exploration

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xichen Zhang, Sitong Wu, Haoru Tan, Shaozuo Yu, Yinghao Zhu, Ziyi He, Jiaya Jia
- **URL**: <http://arxiv.org/abs/2510.19767v1>
- **Submitted**: 2025-10-22 16:56:01
- **Comment**: Code: https://github.com/dvlab-research/SmartSwitch
- **Topic Keywords**: rag
- **Reason**: This paper focuses on improving large language models' reasoning capabilities by addressing 'underthinking' through a proposed framework called SmartSwitch. While it involves a form of query understanding and ranking models, it's primarily concerned with enhancing language model performance, which doesn't directly align with your core research interests in Information Retrieval and Search technologies.

#### Abstract
> The long chain-of-thought (LongCoT) capability is central to the recent
breakthroughs achieved by large language models in complex reasoning tasks.
However, the accompanying issue of ''underthinking'', where models exhibit
shallow reasoning by frequently switching thoughts without sufficient
exploration, limits both performance and token efficiency. To address this
problem, we propose a simple yet effective reasoning strategy: the SmartSwitch
inference framework. This framework can be easily integrated into any large
language model as a plug-and-play solution, continuously monitoring the model's
reasoning process to detect underthinking and guide it toward deeper
exploration of promising but overlooked thoughts. Specifically, the perception
module identifies points where thoughts switch and evaluates the potential of
the preceding thought using an off-the-shelf process reward model (PRM). If a
high-potential thought is found to be prematurely abandoned, the intervention
module interrupts the ongoing inference, backtracks to the point before the
switch, and inserts a "deepening prompt" to encourage further exploration along
that promising path. Extensive experiments on challenging mathematical
reasoning benchmarks demonstrate that our method significantly enhances the
performance of various large language models of different sizes.

### 40. Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yu Wu, Ke Shu, Jonas Fischer, Lidia Pivovarova, David Rosson, Eetu M√§kel√§, Mikko Tolonen
- **URL**: <http://arxiv.org/abs/2510.19585v1>
- **Submitted**: 2025-10-22 13:37:52
- **Comment**: Under review. Both the dataset and code will be published
- **Topic Keywords**: rag
- **Reason**: This paper appears to be unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. The focus on Latin detection in historical documents and the use of large language models does not align with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> This paper presents a novel task of extracting Latin fragments from
mixed-language historical documents with varied layouts. We benchmark and
evaluate the performance of large foundation models against a multimodal
dataset of 724 annotated pages. The results demonstrate that reliable Latin
detection with contemporary models is achievable. Our study provides the first
comprehensive analysis of these models' capabilities and limits for this task.

### 41. A Matter of Time: Revealing the Structure of Time in Vision-Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Nidham Tekaya, Manuela Waldner, Matthias Zeppelzauer
- **URL**: <http://arxiv.org/abs/2510.19559v1>
- **Submitted**: 2025-10-22 13:14:02
- **Topic Keywords**: rag
- **Reason**: This paper focuses on vision-language models and their temporal awareness, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves multimodal representations, it does not address query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's research.

#### Abstract
> Large-scale vision-language models (VLMs) such as CLIP have gained popularity
for their generalizable and expressive multimodal representations. By
leveraging large-scale training data with diverse textual metadata, VLMs
acquire open-vocabulary capabilities, solving tasks beyond their training
scope. This paper investigates the temporal awareness of VLMs, assessing their
ability to position visual content in time. We introduce TIME10k, a benchmark
dataset of over 10,000 images with temporal ground truth, and evaluate the
time-awareness of 37 VLMs by a novel methodology. Our investigation reveals
that temporal information is structured along a low-dimensional, non-linear
manifold in the VLM embedding space. Based on this insight, we propose methods
to derive an explicit ``timeline'' representation from the embedding space.
These representations model time and its chronological progression and thereby
facilitate temporal reasoning tasks. Our timeline approaches achieve
competitive to superior accuracy compared to a prompt-based baseline while
being computationally efficient. All code and data are available at
https://tekayanidham.github.io/timeline-page/.

### 42. Conditions for Catastrophic Forgetting in Multilingual Translation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Danni Liu, Jan Niehues
- **URL**: <http://arxiv.org/abs/2510.19546v1>
- **Submitted**: 2025-10-22 12:54:00
- **Comment**: Multilingual Representation Learning (MRL) Workshop 2025
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests as it focuses on catastrophic forgetting in multilingual translation, which is outside the scope of information retrieval, search technologies, and natural language processing. While it involves machine learning and fine-tuning, the context is specific to language translation and does not align with your core research themes.

#### Abstract
> Fine-tuning multilingual foundation models on specific languages often
induces catastrophic forgetting, degrading performance on languages unseen in
fine-tuning. While this phenomenon is widely-documented, the literature
presents fragmented results about when forgetting occurs. To address this
ambiguity, we conduct a systematic empirical study using machine translation as
a testbed to identify the conditions that trigger catastrophic forgetting in
multilingual fine-tuning. Through controlled experiments across different model
architectures, data scales, and fine-tuning approaches, we reveal that the
relative scale between model and data size is a primary determinant of
forgetting. Moreover, we demonstrate that a model's instruction-following
ability is more critical for retaining multilingual knowledge than its
architecture. Contrary to assumptions, parameter-efficient fine-tuning offers
no clear advantage over full fine-tuning in mitigating forgetting. Lastly, we
show that cross-lingual alignment can mitigate forgetting while also
facilitating positive transfer to unseen target languages.

### 43. Which Evaluation for Which Model? A Taxonomy for Speech Model Assessment

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Maureen de Seyssel, Eeshan Gunesh Dhekane
- **URL**: <http://arxiv.org/abs/2510.19509v1>
- **Submitted**: 2025-10-22 12:04:32
- **Comment**: 57 pages (26 main, 25 appendix, 6 references)
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it discusses model assessment, it focuses on speech models and evaluation protocols, which is outside your primary areas of focus.

#### Abstract
> Speech foundation models have recently achieved remarkable capabilities
across a wide range of tasks. However, their evaluation remains disjointed
across tasks and model types. Different models excel at distinct aspects of
speech processing and thus require different evaluation protocols. This paper
proposes a unified taxonomy that addresses the question: Which evaluation is
appropriate for which model? The taxonomy defines three orthogonal axes: the
\textbf{evaluation aspect} being measured, the model capabilities required to
attempt the task, and the task or protocol requirements needed to perform it.
We classify a broad set of existing evaluations and benchmarks along these
axes, spanning areas such as representation learning, speech generation, and
interactive dialogue. By mapping each evaluation to the capabilities a model
exposes (e.g., speech generation, real-time processing) and to its
methodological demands (e.g., fine-tuning data, human judgment), the taxonomy
provides a principled framework for aligning models with suitable evaluation
methods. It also reveals systematic gaps, such as limited coverage of prosody,
interaction, or reasoning, that highlight priorities for future benchmark
design. Overall, this work offers a conceptual foundation and practical guide
for selecting, interpreting, and extending evaluations of speech models.

### 44. Machine Text Detectors are Membership Inference Attacks

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ryuto Koike, Liam Dugan, Masahiro Kaneko, Chris Callison-Burch, Naoaki Okazaki
- **URL**: <http://arxiv.org/abs/2510.19492v1>
- **Submitted**: 2025-10-22 11:39:01
- **Topic Keywords**: rank, search
- **Reason**: This paper focuses on machine-generated text detection and membership inference attacks, which, while related to information retrieval, do not directly align with your core research themes of query understanding, ranking models, and user behavior modeling. The paper's emphasis on language models and their probability distributions is somewhat relevant to your NLP interests, but the connection is not strong enough to warrant a higher score.

#### Abstract
> Although membership inference attacks (MIAs) and machine-generated text
detection target different goals, identifying training samples and synthetic
texts, their methods often exploit similar signals based on a language model's
probability distribution. Despite this shared methodological foundation, the
two tasks have been independently studied, which may lead to conclusions that
overlook stronger methods and valuable insights developed in the other task. In
this work, we theoretically and empirically investigate the transferability,
i.e., how well a method originally developed for one task performs on the
other, between MIAs and machine text detection. For our theoretical
contribution, we prove that the metric that achieves the asymptotically highest
performance on both tasks is the same. We unify a large proportion of the
existing literature in the context of this optimal metric and hypothesize that
the accuracy with which a given method approximates this metric is directly
correlated with its transferability. Our large-scale empirical experiments,
including 7 state-of-the-art MIA methods and 5 state-of-the-art machine text
detectors across 13 domains and 10 generators, demonstrate very strong rank
correlation (rho > 0.6) in cross-task performance. We notably find that
Binoculars, originally designed for machine text detection, achieves
state-of-the-art performance on MIA benchmarks as well, demonstrating the
practical impact of the transferability. Our findings highlight the need for
greater cross-task awareness and collaboration between the two research
communities. To facilitate cross-task developments and fair evaluations, we
introduce MINT, a unified evaluation suite for MIAs and machine-generated text
detection, with implementation of 15 recent methods from both tasks.

### 45. MINED: Probing and Updating with Multimodal Time-Sensitive Knowledge for Large Multimodal Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Kailin Jiang, Ning Jiang, Yuchen Ren, Yuchen Li, Yifan Gao, Jinhe Bi, Yunpu Ma, Qingqing Liu, Xianhao Wang, Yifan Jia, Hongbo Jiang, Yaocong Hu, Bin Li, Lei Liu, Yuntao Du
- **URL**: <http://arxiv.org/abs/2510.19457v1>
- **Submitted**: 2025-10-22 10:41:57
- **Comment**: project page:https://mined-lmm.github.io/
- **Topic Keywords**: rag
- **Reason**: This paper focuses on evaluating and updating large multimodal models with time-sensitive knowledge, which is not directly related to information retrieval, query understanding, or ranking models. While it involves natural language processing and knowledge representation, the context is more aligned with knowledge graph updates and multimodal models rather than search technologies or user behavior modeling.

#### Abstract
> Large Multimodal Models (LMMs) encode rich factual knowledge via cross-modal
pre-training, yet their static representations struggle to maintain an accurate
understanding of time-sensitive factual knowledge. Existing benchmarks remain
constrained by static designs, inadequately evaluating LMMs' ability to
understand time-sensitive knowledge. To address this gap, we propose MINED, a
comprehensive benchmark that evaluates temporal awareness along 6 key
dimensions and 11 challenging tasks: cognition, awareness, trustworthiness,
understanding, reasoning, and robustness. MINED is constructed from Wikipedia
by two professional annotators, containing 2,104 time-sensitive knowledge
samples spanning six knowledge types. Evaluating 15 widely used LMMs on MINED
shows that Gemini-2.5-Pro achieves the highest average CEM score of 63.07,
while most open-source LMMs still lack time understanding ability. Meanwhile,
LMMs perform best on organization knowledge, whereas their performance is
weakest on sport. To address these challenges, we investigate the feasibility
of updating time-sensitive knowledge in LMMs through knowledge editing methods
and observe that LMMs can effectively update knowledge via knowledge editing
methods in single editing scenarios.

### 46. ColorAgent: Building A Robust, Personalized, and Interactive OS Agent

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ning Li, Qiqiang Lin, Zheng Wu, Xiaoyun Mo, Weiming Zhang, Yin Zhao, Xiangmou Qu, Jiamu Zhou, Jun Wang, Congmin Zheng, Yuanyi Song, Hongjiang Chen, Heyuan Huang, Jihong Wang, Jiaxin Yin, Jingwei Yu, Junwei Liao, Qiuying Peng, Xingyu Lou, Jun Wang, Weiwen Liu, Zhuosheng Zhang, Weinan Zhang
- **URL**: <http://arxiv.org/abs/2510.19386v1>
- **Submitted**: 2025-10-22 09:02:48
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests as it focuses on building an operating system agent using reinforcement learning and multi-agent framework, which is outside the scope of information retrieval, search technologies, and natural language processing.

#### Abstract
> With the advancements in hardware, software, and large language model
technologies, the interaction between humans and operating systems has evolved
from the command-line interface to the rapidly emerging AI agent interactions.
Building an operating system (OS) agent capable of executing user instructions
and faithfully following user desires is becoming a reality. In this technical
report, we present ColorAgent, an OS agent designed to engage in long-horizon,
robust interactions with the environment while also enabling personalized and
proactive user interaction. To enable long-horizon interactions with the
environment, we enhance the model's capabilities through step-wise
reinforcement learning and self-evolving training, while also developing a
tailored multi-agent framework that ensures generality, consistency, and
robustness. In terms of user interaction, we explore personalized user intent
recognition and proactive engagement, positioning the OS agent not merely as an
automation tool but as a warm, collaborative partner. We evaluate ColorAgent on
the AndroidWorld and AndroidLab benchmarks, achieving success rates of 77.2%
and 50.7%, respectively, establishing a new state of the art. Nonetheless, we
note that current benchmarks are insufficient for a comprehensive evaluation of
OS agents and propose further exploring directions in future work, particularly
in the areas of evaluation paradigms, agent collaboration, and security. Our
code is available at https://github.com/MadeAgents/mobile-use.

### 47. MoE-Prism: Disentangling Monolithic Experts for Elastic MoE Services via Model-System Co-Designs

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xinfeng Xia, Jiacheng Liu, Xiaofeng Hou, Peng Tang, Mingxuan Zhang, Wenfeng Wang, Chao Li
- **URL**: <http://arxiv.org/abs/2510.19366v1>
- **Submitted**: 2025-10-22 08:40:01
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Mixture-of-Experts (MoE) models and their scalability, which is outside the scope of Information Retrieval and Search technologies. While it involves AI services and optimization, the paper's emphasis on model-system co-design and QoS-aware scheduling does not align with the user's primary research interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Mixture-of-Experts (MoE) models, the state-of-the-art in large-scale AI,
achieve high quality by sparsely activating parameters. However, their reliance
on routing between a few monolithic experts via a top-k mechanism creates a
"quality cliff", offering only a few coarse-grained operating points. This
inflexibility forces a difficult trade-off between cost and quality, preventing
adaptation to diverse Service Level Objectives (SLOs) and leading to
significant resource over-provisioning.
  This paper introduces MoE-Prism, a model-system co-design that transforms
rigid MoE models into elastic services. Our methodology is divided into two
phases. First, an \emph{Offline Refactoring Engine} systematically deconstructs
monolithic experts into fine-grained "sub-experts." This engine employs a
partitioning optimization solver that uses a metaheuristic-based approach to
group neurons, preserving functional locality without requiring retraining.
Second, an \emph{Online Scheduling Engine} leverages this new elasticity
through QoS-aware scheduling. It implements specialized policies to solve
complex system problems, including maximizing throughput in cloud deployments
and managing latency-optimized offloading for memory-constrained devices. Our
evaluation across three different MoE models shows that MoE-Prismprovides over
4 times more distinct, stable operating points than the baseline. This allows
an AI service to dynamically improve throughput by up to 19.9\% under a strict
latency budget or reduce latency by up to 10.36\% under limited resources.
MoE-Prism provides the critical "control knob" to bridge the model-system gap,
enabling the next generation of adaptive, efficient, and QoS-aware AI services.

### 48. TheMCPCompany: Creating General-purpose Agents with Task-specific Tools

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Reza Esfandiarpoor, Vishwas Suryanarayanan, Stephen H. Bach, Vishal Chowdhary, Anthony Aue
- **URL**: <http://arxiv.org/abs/2510.19286v1>
- **Submitted**: 2025-10-22 06:42:01
- **Comment**: Code: https://github.com/Reza-esfandiarpoor/the-mcp-company
- **Topic Keywords**: retrieval
- **Reason**: This paper appears to be primarily focused on the development of a benchmark for evaluating tool-calling agents, which is not directly related to information retrieval, search technologies, or natural language processing. While it mentions the use of Large Language Models, the context is not aligned with the user's core research themes.

#### Abstract
> Since the introduction of the Model Context Protocol (MCP), the number of
available tools for Large Language Models (LLMs) has increased significantly.
These task-specific tool sets offer an alternative to general-purpose tools
such as web browsers, while being easier to develop and maintain than GUIs.
However, current general-purpose agents predominantly rely on web browsers for
interacting with the environment. Here, we introduce TheMCPCompany, a benchmark
for evaluating tool-calling agents on tasks that involve interacting with
various real-world services. We use the REST APIs of these services to create
MCP servers, which include over 18,000 tools. We also provide manually
annotated ground-truth tools for each task. In our experiments, we use the
ground truth tools to show the potential of tool-calling agents for both
improving performance and reducing costs assuming perfect tool retrieval. Next,
we explore agent performance using tool retrieval to study the real-world
practicality of tool-based agents. While all models with tool retrieval perform
similarly or better than browser-based agents, smaller models cannot take full
advantage of the available tools through retrieval. On the other hand, GPT-5's
performance with tool retrieval is very close to its performance with
ground-truth tools. Overall, our work shows that the most advanced reasoning
models are effective at discovering tools in simpler environments, but
seriously struggle with navigating complex enterprise environments.
TheMCPCompany reveals that navigating tens of thousands of tools and combining
them in non-trivial ways to solve complex problems is still a challenging task
for current models and requires both better reasoning and better retrieval
models.

### 49. Difficulty-Controllable Multiple-Choice Question Generation Using Large Language Models and Direct Preference Optimization

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yuto Tomikawa, Masaki Uto
- **URL**: <http://arxiv.org/abs/2510.19265v1>
- **Submitted**: 2025-10-22 05:49:31
- **Comment**: This work has been submitted to the IEEE for possible publication
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to your core research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves a large language model, the focus is on question generation for education, which is not a primary area of interest for you.

#### Abstract
> Difficulty-controllable question generation for reading comprehension has
gained significant attention in the field of education as a fundamental tool
for adaptive learning support. Although several neural question generation
methods have recently succeeded in controlling difficulty, conventional
approaches still face two major limitations. First, they cannot directly
generate multiple-choice questions, which are the most widely used question
type in educational contexts. Second, they are not explicitly trained to
optimize the accuracy of difficulty control, leaving room for further
improvement in difficulty controllability. To address these limitations, this
study proposes a novel difficulty-controllable multiple-choice question
generation method for reading comprehension which leverages a large language
model trained using a direct preference optimization technique to improve the
accuracy of difficulty control.

### 50. Automated HIV Screening on Dutch EHR with Large Language Models

- **LLM Score**: 0
- **Keyword Score**: 5
- **Authors**: Lang Zhou, Amrish Jhingoer, Yinghao Luo, Klaske Vliegenthart--Jongbloed, Carlijn Jordans, Ben Werkhoven, Tom Seinen, Erik van Mulligen, Casper Rokx, Yunlei Li
- **URL**: <http://arxiv.org/abs/2510.19879v1>
- **Submitted**: 2025-10-22 11:53:14
- **Comment**: 28 pages, 6 figures
- **Topic Keywords**: rag, ctr, search
- **Reason**: This paper is not relevant to your research interests as it focuses on HIV screening using large language models and Electronic Health Records, which does not align with your areas of expertise in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Efficient screening and early diagnosis of HIV are critical for reducing
onward transmission. Although large scale laboratory testing is not feasible,
the widespread adoption of Electronic Health Records (EHRs) offers new
opportunities to address this challenge. Existing research primarily focuses on
applying machine learning methods to structured data, such as patient
demographics, for improving HIV diagnosis. However, these approaches often
overlook unstructured text data such as clinical notes, which potentially
contain valuable information relevant to HIV risk. In this study, we propose a
novel pipeline that leverages a Large Language Model (LLM) to analyze
unstructured EHR text and determine a patient's eligibility for further HIV
testing. Experimental results on clinical data from Erasmus University Medical
Center Rotterdam demonstrate that our pipeline achieved high accuracy while
maintaining a low false negative rate.

---

