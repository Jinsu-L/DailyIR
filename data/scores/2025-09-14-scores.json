[
    {
        "title": "Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery",
        "abstract": "The growing complexity and volume of climate science literature make it\nincreasingly difficult for researchers to find relevant information across\nmodels, datasets, regions, and variables. This paper introduces a\ndomain-specific Knowledge Graph (KG) built from climate publications and\nbroader scientific texts, aimed at improving how climate knowledge is accessed\nand used. Unlike keyword based search, our KG supports structured, semantic\nqueries that help researchers discover precise connections such as which models\nhave been validated in specific regions or which datasets are commonly used\nwith certain teleconnection patterns. We demonstrate how the KG answers such\nquestions using Cypher queries, and outline its integration with large language\nmodels in RAG systems to improve transparency and reliability in\nclimate-related question answering. This work moves beyond KG construction to\nshow its real world value for climate researchers, model developers, and others\nwho rely on accurate, contextual scientific information.",
        "url": "http://arxiv.org/abs/2509.10087v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10087v1",
        "arxiv_id": "2509.10087v1",
        "authors": [
            "Mustapha Adamu",
            "Qi Zhang",
            "Huitong Pan",
            "Longin Jan Latecki",
            "Eduard C. Dragut"
        ],
        "submitted": "2025-09-12 09:28:29",
        "source": "arxiv",
        "comment": "ACM SIGIR 2025 Workshop MANILA",
        "score": 11,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the area of query understanding and semantic search. Although it focuses on a specific domain (climate science), it explores the use of Knowledge Graphs and semantic queries, which aligns with your interests in deep semantic understanding and real-time relevance optimization. However, the paper's focus on a specific domain and application limits its relevance to your broader interests in e-commerce and NLP."
    },
    {
        "title": "Latency and Token-Aware Test-Time Compute",
        "abstract": "Inference-time scaling has emerged as a powerful way to improve large\nlanguage model (LLM) performance by generating multiple candidate responses and\nselecting among them. However, existing work on dynamic allocation for\ntest-time compute typically considers only parallel generation methods such as\nbest-of-N, overlooking incremental decoding methods like beam search, and has\nlargely ignored latency, focusing only on token usage. We formulate\ninference-time scaling as a problem of dynamic compute allocation and method\nselection, where the system must decide which strategy to apply and how much\ncompute to allocate on a per-query basis. Our framework explicitly incorporates\nboth token cost and wall-clock latency, the latter being critical for user\nexperience and particularly for agentic workflows where models must issue\nmultiple queries efficiently. Experiments on reasoning benchmarks show that our\napproach consistently outperforms static strategies, achieving favorable\naccuracy-cost trade-offs while remaining practical for deployment.",
        "url": "http://arxiv.org/abs/2509.09864v1",
        "pdf_url": "http://arxiv.org/pdf/2509.09864v1",
        "arxiv_id": "2509.09864v1",
        "authors": [
            "Jenny Y. Huang",
            "Mehul Damani",
            "Yousef El-Kurdi",
            "Ramon Astudillo",
            "Wei Sun"
        ],
        "submitted": "2025-09-11 21:35:19",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of large language models and inference-time scaling. However, it primarily focuses on improving the performance of language models, which is not a central match to your interests in query understanding, ranking models, and user behavior modeling. The paper's emphasis on latency and token-aware test-time compute is also not directly related to your core research themes."
    },
    {
        "title": "Error Analysis in a Modular Meeting Transcription System",
        "abstract": "Meeting transcription is a field of high relevance and remarkable progress in\nrecent years. Still, challenges remain that limit its performance. In this\nwork, we extend a previously proposed framework for analyzing leakage in speech\nseparation with proper sensitivity to temporal locality. We show that there is\nsignificant leakage to the cross channel in areas where only the primary\nspeaker is active. At the same time, the results demonstrate that this does not\naffect the final performance much as these leaked parts are largely ignored by\nthe voice activity detection (VAD). Furthermore, different segmentations are\ncompared showing that advanced diarization approaches are able to reduce the\ngap to oracle segmentation by a third compared to a simple energy-based VAD. We\nadditionally reveal what factors contribute to the remaining difference. The\nresults represent state-of-the-art performance on LibriCSS among systems that\ntrain the recognition module on LibriSpeech data only.",
        "url": "http://arxiv.org/abs/2509.10143v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10143v1",
        "arxiv_id": "2509.10143v1",
        "authors": [
            "Peter Vieting",
            "Simon Berger",
            "Thilo von Neumann",
            "Christoph Boeddeker",
            "Ralf Schlüter",
            "Reinhold Haeb-Umbach"
        ],
        "submitted": "2025-09-12 11:10:38",
        "source": "arxiv",
        "comment": "Accepted at ITG Conference on Speech Communication 2025",
        "score": 5,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on meeting transcription, speech separation, and voice activity detection, which are not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some form of data analysis, the context and methodology seem to be specific to the meeting transcription domain and do not align with the user's interests in query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Topic-Guided Reinforcement Learning with LLMs for Enhancing Multi-Document Summarization",
        "abstract": "A key challenge in Multi-Document Summarization (MDS) is effectively\nintegrating information from multiple sources while maintaining coherence and\ntopical relevance. While Large Language Models have shown impressive results in\nsingle-document summarization, their performance on MDS still leaves room for\nimprovement. In this paper, we propose a topic-guided reinforcement learning\napproach to improve content selection in MDS. We first show that explicitly\nprompting models with topic labels enhances the informativeness of the\ngenerated summaries. Building on this insight, we propose a novel topic reward\nwithin the Group Relative Policy Optimization (GRPO) framework to measure topic\nalignment between the generated summary and source documents. Experimental\nresults on the Multi-News and Multi-XScience datasets demonstrate that our\nmethod consistently outperforms strong baselines, highlighting the\neffectiveness of leveraging topical cues in MDS.",
        "url": "http://arxiv.org/abs/2509.09852v1",
        "pdf_url": "http://arxiv.org/pdf/2509.09852v1",
        "arxiv_id": "2509.09852v1",
        "authors": [
            "Chuyuan Li",
            "Austin Xu",
            "Shafiq Joty",
            "Giuseppe Carenini"
        ],
        "submitted": "2025-09-11 21:01:54",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper explores Multi-Document Summarization, which is related to Information Retrieval, but it focuses on summarization rather than search or ranking. The use of Large Language Models and reinforcement learning is relevant to NLP, but the specific application to summarization is not a central match to the user's core research themes."
    },
    {
        "title": "Diversified recommendations of cultural activities with personalized determinantal point processes",
        "abstract": "While optimizing recommendation systems for user engagement is a\nwell-established practice, effectively diversifying recommendations without\nnegatively impacting core business metrics remains a significant industry\nchallenge. In line with our initiative to broaden our audience's cultural\npractices, this study investigates using personalized Determinantal Point\nProcesses (DPPs) to sample diverse and relevant recommendations. We rely on a\nwell-known quality-diversity decomposition of the similarity kernel to give\nmore weight to user preferences. In this paper, we present our implementations\nof the personalized DPP sampling, evaluate the trade-offs between relevance and\ndiversity through both offline and online metrics, and give insights for\npractitioners on their use in a production environment. For the sake of\nreproducibility, we release the full code for our platform and experiments on\nGitHub.",
        "url": "http://arxiv.org/abs/2509.10392v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10392v1",
        "arxiv_id": "2509.10392v1",
        "authors": [
            "Carole Ibrahim",
            "Hiba Bederina",
            "Daniel Cuesta",
            "Laurent Montier",
            "Cyrille Delabre",
            "Jill-Jênn Vie"
        ],
        "submitted": "2025-09-12 16:34:07",
        "source": "arxiv",
        "comment": "7 pages, accepted at RecSys workshop RecSoGood 2025",
        "score": 4,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's research interests in Information Retrieval and Search technologies, but it focuses more on recommender systems and diversification of recommendations. While it touches on user behavior modeling, it doesn't delve into query understanding, ranking models, or deep semantic understanding, which are the user's primary areas of interest."
    },
    {
        "title": "Arabic Large Language Models for Medical Text Generation",
        "abstract": "Efficient hospital management systems (HMS) are critical worldwide to address\nchallenges such as overcrowding, limited resources, and poor availability of\nurgent health care. Existing methods often lack the ability to provide\naccurate, real-time medical advice, particularly for irregular inputs and\nunderrepresented languages. To overcome these limitations, this study proposes\nan approach that fine-tunes large language models (LLMs) for Arabic medical\ntext generation. The system is designed to assist patients by providing\naccurate medical advice, diagnoses, drug recommendations, and treatment plans\nbased on user input. The research methodology required the collection of a\nunique dataset from social media platforms, capturing real-world medical\nconversations between patients and doctors. The dataset, which includes patient\ncomplaints together with medical advice, was properly cleaned and preprocessed\nto account for multiple Arabic dialects. Fine-tuning state-of-the-art\ngenerative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2\nMedium, optimized the system's ability to generate reliable medical text.\nResults from evaluations indicate that the fine-tuned Mistral-7B model\noutperformed the other models, achieving average BERT (Bidirectional Encoder\nRepresentations from Transformers) Score values in precision, recall, and\nF1-scores of 68.5\\%, 69.08\\%, and 68.5\\%, respectively. Comparative\nbenchmarking and qualitative assessments validate the system's ability to\nproduce coherent and relevant medical replies to informal input. This study\nhighlights the potential of generative artificial intelligence (AI) in\nadvancing HMS, offering a scalable and adaptable solution for global healthcare\nchallenges, especially in linguistically and culturally diverse environments.",
        "url": "http://arxiv.org/abs/2509.10095v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10095v1",
        "arxiv_id": "2509.10095v1",
        "authors": [
            "Abdulrahman Allam",
            "Seif Ahmed",
            "Ali Hamdi",
            "Ammar Mohammed"
        ],
        "submitted": "2025-09-12 09:37:26",
        "source": "arxiv",
        "comment": "Published in 2025 4th International Conference on Computer\n  Technologies (ICCTech)",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Arabic Large Language Models for Medical Text Generation, which is not directly related to Information Retrieval, Search technologies, or your other areas of interest. While it involves NLP and generative models, the context is medical text generation and hospital management, which is not a central match to your research themes."
    },
    {
        "title": "Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models",
        "abstract": "Researchers have applied established psychometric questionnaires (e.g., BFI,\nPVQ) to measure the personality traits and values reflected in the responses of\nLarge Language Models (LLMs). However, concerns have been raised about applying\nthese human-designed questionnaires to LLMs. One such concern is their lack of\necological validity--the extent to which survey questions adequately reflect\nand resemble real-world contexts in which LLMs generate texts in response to\nuser queries. However, it remains unclear how established questionnaires and\necologically valid questionnaires differ in their outcomes, and what insights\nthese differences may provide. In this paper, we conduct a comprehensive\ncomparative analysis of the two types of questionnaires. Our analysis reveals\nthat established questionnaires (1) yield substantially different profiles of\nLLMs from ecologically valid ones, deviating from the psychological\ncharacteristics expressed in the context of user queries, (2) suffer from\ninsufficient items for stable measurement, (3) create misleading impressions\nthat LLMs possess stable constructs, and (4) yield exaggerated profiles for\npersona-prompted LLMs. Overall, our work cautions against the use of\nestablished psychological questionnaires for LLMs. Our code will be released\nupon publication.",
        "url": "http://arxiv.org/abs/2509.10078v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10078v1",
        "arxiv_id": "2509.10078v1",
        "authors": [
            "Dongmin Choi",
            "Woojung Song",
            "Jongwook Han",
            "Eun-Ju Lee",
            "Yohan Jo"
        ],
        "submitted": "2025-09-12 09:14:42",
        "source": "arxiv",
        "comment": "17 pages, 4 figures",
        "score": 4,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. It focuses on the application of established psychometric questionnaires to Large Language Models, which is outside your primary areas of interest."
    },
    {
        "title": "MatSKRAFT: A framework for large-scale materials knowledge extraction from scientific tables",
        "abstract": "Scientific progress increasingly depends on synthesizing knowledge across\nvast literature, yet most experimental data remains trapped in semi-structured\nformats that resist systematic extraction and analysis. Here, we present\nMatSKRAFT, a computational framework that automatically extracts and integrates\nmaterials science knowledge from tabular data at unprecedented scale. Our\napproach transforms tables into graph-based representations processed by\nconstraint-driven GNNs that encode scientific principles directly into model\narchitecture. MatSKRAFT significantly outperforms state-of-the-art large\nlanguage models, achieving F1 scores of 88.68 for property extraction and 71.35\nfor composition extraction, while processing data $19$-$496\\times$ faster than\nthem (compared to the slowest and the fastest models, respectively) with modest\nhardware requirements. Applied to nearly 69,000 tables from more than 47,000\nresearch publications, we construct a comprehensive database containing over\n535,000 entries, including 104,000 compositions that expand coverage beyond\nmajor existing databases, pending manual validation. This systematic approach\nreveals previously overlooked materials with distinct property combinations and\nenables data-driven discovery of composition-property relationships forming the\ncornerstone of materials and scientific discovery.",
        "url": "http://arxiv.org/abs/2509.10448v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10448v1",
        "arxiv_id": "2509.10448v1",
        "authors": [
            "Kausik Hira",
            "Mohd Zaki",
            "Mausam",
            "N. M. Anoop Krishnan"
        ],
        "submitted": "2025-09-12 17:55:11",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves data extraction and analysis, the focus is on materials science and scientific knowledge extraction, which is not a central match to your research themes."
    },
    {
        "title": "RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment",
        "abstract": "To optimize the reasoning and problem-solving capabilities of Large Language\nModels (LLMs), we propose a novel cloud-edge collaborative architecture that\nenables a structured, multi-agent prompting framework. This framework comprises\nthree specialized components: GuideLLM, a lightweight model deployed at the\nedge to provide methodological guidance; SolverLLM, a more powerful model\nhosted in the cloud responsible for generating code solutions; and JudgeLLM, an\nautomated evaluator for assessing solution correctness and quality. To evaluate\nand demonstrate the effectiveness of this architecture in realistic settings,\nwe introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate\nand enhance the performance of Large Language Models (LLMs) across multi-domain\ncoding tasks. Motivated by the limitations of existing benchmarks,\nRefactorCoderQA systematically covers various technical domains, including\nSoftware Engineering, Data Science, Machine Learning, and Natural Language\nProcessing, using authentic coding challenges from Stack Overflow. Extensive\nexperiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves\nstate-of-the-art performance, significantly outperforming leading open-source\nand commercial baselines with an overall accuracy of 76.84%. Human evaluations\nfurther validate the interpretability, accuracy, and practical relevance of the\ngenerated solutions. In addition, we evaluate system-level metrics, such as\nthroughput and latency, to gain deeper insights into the performance\ncharacteristics and trade-offs of the proposed architecture.",
        "url": "http://arxiv.org/abs/2509.10436v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10436v1",
        "arxiv_id": "2509.10436v1",
        "authors": [
            "Shadikur Rahman",
            "Aroosa Hameed",
            "Gautam Srivastava",
            "Syed Muhammad Danish"
        ],
        "submitted": "2025-09-12 17:44:22",
        "source": "arxiv",
        "comment": "12 pages, 5 figures, submitted to IEEE Transactions on Services\n  Computing",
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a novel architecture for optimizing Large Language Models (LLMs) in cloud-edge deployment, which is somewhat related to information retrieval and NLP. However, the focus on coding question solutions and multi-domain coding tasks is not directly aligned with the user's core research themes in query understanding, ranking models, and user behavior modeling. The paper's relevance to recommender systems is also not a central match."
    },
    {
        "title": "RecoWorld: Building Simulated Environments for Agentic Recommender Systems",
        "abstract": "We present RecoWorld, a blueprint for building simulated environments\ntailored to agentic recommender systems. Such environments give agents a proper\ntraining space where they can learn from errors without impacting real users.\nRecoWorld distinguishes itself with a dual-view architecture: a simulated user\nand an agentic recommender engage in multi-turn interactions aimed at\nmaximizing user retention. The user simulator reviews recommended items,\nupdates its mindset, and when sensing potential user disengagement, generates\nreflective instructions. The agentic recommender adapts its recommendations by\nincorporating these user instructions and reasoning traces, creating a dynamic\nfeedback loop that actively engages users. This process leverages the\nexceptional reasoning capabilities of modern LLMs. We explore diverse content\nrepresentations within the simulator, including text-based, multimodal, and\nsemantic ID modeling, and discuss how multi-turn RL enables the recommender to\nrefine its strategies through iterative interactions. RecoWorld also supports\nmulti-agent simulations, allowing creators to simulate the responses of\ntargeted user populations. It marks an important first step toward recommender\nsystems where users and agents collaboratively shape personalized information\nstreams. We envision new interaction paradigms where \"user instructs,\nrecommender responds,\" jointly optimizing user retention and engagement.",
        "url": "http://arxiv.org/abs/2509.10397v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10397v1",
        "arxiv_id": "2509.10397v1",
        "authors": [
            "Fei Liu",
            "Xinyu Lin",
            "Hanchao Yu",
            "Mingyuan Wu",
            "Jianyu Wang",
            "Qiang Zhang",
            "Zhuokai Zhao",
            "Yinglong Xia",
            "Yao Zhang",
            "Weiwei Li",
            "Mingze Gao",
            "Qifan Wang",
            "Lizhu Zhang",
            "Benyu Zhang",
            "Xiangjun Fan"
        ],
        "submitted": "2025-09-12 16:44:34",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on recommender systems, which is a related topic to your research interests in Information Retrieval and Search technologies. However, it primarily deals with agentic recommender systems and simulated environments, which is not a central match to your core research themes. The use of modern LLMs and multi-turn RL is somewhat relevant to your interests in ranking models and user behavior modeling."
    },
    {
        "title": "Population-Aligned Persona Generation for LLM-based Social Simulation",
        "abstract": "Recent advances in large language models (LLMs) have enabled human-like\nsocial simulations at unprecedented scale and fidelity, offering new\nopportunities for computational social science. A key challenge, however, is\nthe construction of persona sets that authentically represent the diversity and\ndistribution of real-world populations. Most existing LLM-based social\nsimulation studies focus primarily on designing agentic frameworks and\nsimulation environments, often overlooking the complexities of persona\ngeneration and the potential biases introduced by unrepresentative persona\nsets. In this paper, we propose a systematic framework for synthesizing\nhigh-quality, population-aligned persona sets for LLM-driven social simulation.\nOur approach begins by leveraging LLMs to generate narrative personas from\nlong-term social media data, followed by rigorous quality assessment to filter\nout low-fidelity profiles. We then apply importance sampling to achieve global\nalignment with reference psychometric distributions, such as the Big Five\npersonality traits. To address the needs of specific simulation contexts, we\nfurther introduce a task-specific module that adapts the globally aligned\npersona set to targeted subpopulations. Extensive experiments demonstrate that\nour method significantly reduces population-level bias and enables accurate,\nflexible social simulation for a wide range of research and policy\napplications.",
        "url": "http://arxiv.org/abs/2509.10127v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10127v1",
        "arxiv_id": "2509.10127v1",
        "authors": [
            "Zhengyu Hu",
            "Zheyuan Xiao",
            "Max Xiong",
            "Yuxuan Lei",
            "Tianfu Wang",
            "Jianxun Lian",
            "Kaize Ding",
            "Ziang Xiao",
            "Nicholas Jing Yuan",
            "Xing Xie"
        ],
        "submitted": "2025-09-12 10:43:47",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on persona generation for social simulation using large language models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context is more aligned with social science and simulation, rather than search or retrieval."
    },
    {
        "title": "Large Language Models Meet Legal Artificial Intelligence: A Survey",
        "abstract": "Large Language Models (LLMs) have significantly advanced the development of\nLegal Artificial Intelligence (Legal AI) in recent years, enhancing the\nefficiency and accuracy of legal tasks. To advance research and applications of\nLLM-based approaches in legal domain, this paper provides a comprehensive\nreview of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and\nalso gather 15 benchmarks and 29 datasets to evaluate different legal\ncapabilities. Additionally, we analyse the challenges and discuss future\ndirections for LLM-based approaches in the legal domain. We hope this paper\nprovides a systematic introduction for beginners and encourages future research\nin this field. Resources are available at\nhttps://github.com/ZhitianHou/LLMs4LegalAI.",
        "url": "http://arxiv.org/abs/2509.09969v1",
        "pdf_url": "http://arxiv.org/pdf/2509.09969v1",
        "arxiv_id": "2509.09969v1",
        "authors": [
            "Zhitian Hou",
            "Zihan Ye",
            "Nanli Zeng",
            "Tianyong Hao",
            "Kun Zeng"
        ],
        "submitted": "2025-09-12 05:08:11",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves Large Language Models, which are a subset of NLP, the focus is on Legal Artificial Intelligence, which is not a primary area of interest for the user."
    },
    {
        "title": "Pragmatic Frames Evoked by Gestures: A FrameNet Brasil Approach to Multimodality in Turn Organization",
        "abstract": "This paper proposes a framework for modeling multimodal conversational turn\norganization via the proposition of correlations between language and\ninteractive gestures, based on analysis as to how pragmatic frames are\nconceptualized and evoked by communicators. As a means to provide evidence for\nthe analysis, we developed an annotation methodology to enrich a multimodal\ndataset (annotated for semantic frames) with pragmatic frames modeling\nconversational turn organization. Although conversational turn organization has\nbeen studied by researchers from diverse fields, the specific strategies,\nespecially gestures used by communicators, had not yet been encoded in a\ndataset that can be used for machine learning. To fill this gap, we enriched\nthe Frame2 dataset with annotations of gestures used for turn organization. The\nFrame2 dataset features 10 episodes from the Brazilian TV series Pedro Pelo\nMundo annotated for semantic frames evoked in both video and text. This dataset\nallowed us to closely observe how communicators use interactive gestures\noutside a laboratory, in settings, to our knowledge, not previously recorded in\nrelated literature. Our results have confirmed that communicators involved in\nface-to-face conversation make use of gestures as a tool for passing, taking\nand keeping conversational turns, and also revealed variations of some gestures\nthat had not been documented before. We propose that the use of these gestures\narises from the conceptualization of pragmatic frames, involving mental spaces,\nblending and conceptual metaphors. In addition, our data demonstrate that the\nannotation of pragmatic frames contributes to a deeper understanding of human\ncognition and language.",
        "url": "http://arxiv.org/abs/2509.09804v1",
        "pdf_url": "http://arxiv.org/pdf/2509.09804v1",
        "arxiv_id": "2509.09804v1",
        "authors": [
            "Helen de Andrade Abreu",
            "Tiago Timponi Torrent",
            "Ely Edison da Silva Matos"
        ],
        "submitted": "2025-09-11 19:14:57",
        "source": "arxiv",
        "comment": "Paper submitted to Language Sciences Journal",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multimodal conversational turn organization and gesture analysis, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning",
        "abstract": "The adaptation of large language models (LLMs) to specialized reasoning tasks\nis fundamentally constrained by computational resources. Parameter-Efficient\nFine-Tuning (PEFT) methods have emerged as a powerful solution, yet the\nlandscape of these techniques is diverse, with distinct methods operating in\neither the model's weight space or its representation space. This paper\ninvestigates the hypothesis that a synergistic combination of these paradigms\ncan unlock superior performance and efficiency. We introduce HEFT (Hierarchical\nEfficient Fine-Tuning), a novel hierarchical adaptation strategy that composes\ntwo distinct PEFT methods in a coarse-to-fine manner: first, a broad,\nfoundational adaptation in the weight space using Low-Rank Adaptation (LoRA),\nfollowed by a precise, surgical refinement of internal activations using\nRepresentation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a\nLlama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential\nreasoning. Our results reveal a profound synergistic effect. A model fine-tuned\nfor only three epochs with our HEFT strategy achieves an accuracy of 85.17\\%,\nexceeding the performance of models trained for 20 epochs with either LoRA-only\n(85.05\\%) or ReFT-only (83.36\\%) methodologies. This work demonstrates that the\nthoughtful composition of PEFT methods is a potent algorithmic innovation,\noffering a more efficient and effective path toward advancing the reasoning\ncapabilities of language models. By achieving superior results with a fraction\nof the computational budget, our findings present a principled approach to\novercoming the obstacles inherent in adapting large-scale models for complex\ncognitive tasks.",
        "url": "http://arxiv.org/abs/2509.09801v1",
        "pdf_url": "http://arxiv.org/pdf/2509.09801v1",
        "arxiv_id": "2509.09801v1",
        "authors": [
            "Brennen Hill"
        ],
        "submitted": "2025-09-11 19:06:46",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rank' (score: +1)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving the efficiency and accuracy of language model reasoning through a novel hierarchical adaptation strategy. While it involves fine-tuning a large language model, the topic is not directly related to information retrieval, search technologies, or user behavior modeling, which are the core areas of your research interests."
    },
    {
        "title": "Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems",
        "abstract": "Failure attribution in multi-agent systems -- pinpointing the exact step\nwhere a decisive error occurs -- is a critical yet unsolved challenge. Current\nmethods treat this as a pattern recognition task over long conversation logs,\nleading to critically low step-level accuracy (below 17\\%), which renders them\nimpractical for debugging complex systems. Their core weakness is a fundamental\ninability to perform robust counterfactual reasoning: to determine if\ncorrecting a single action would have actually averted the task failure. To\nbridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)\nScaffolding, a novel agent framework that transforms failure attribution from\npattern recognition into a structured causal inference task. A2P explicitly\nguides a large language model through a formal three-step reasoning process\nwithin a single inference pass: (1) Abduction, to infer the hidden root causes\nbehind an agent's actions; (2) Action, to define a minimal corrective\nintervention; and (3) Prediction, to simulate the subsequent trajectory and\nverify if the intervention resolves the failure. This structured approach\nleverages the holistic context of the entire conversation while imposing a\nrigorous causal logic on the model's analysis. Our extensive experiments on the\nWho\\&When benchmark demonstrate its efficacy. On the Algorithm-Generated\ndataset, A2P achieves 47.46\\% step-level accuracy, a 2.85$\\times$ improvement\nover the 16.67\\% of the baseline. On the more complex Hand-Crafted dataset, it\nachieves 29.31\\% step accuracy, a 2.43$\\times$ improvement over the baseline's\n12.07\\%. By reframing the problem through a causal lens, A2P Scaffolding\nprovides a robust, verifiable, and significantly more accurate solution for\nautomated failure attribution.",
        "url": "http://arxiv.org/abs/2509.10401v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10401v1",
        "arxiv_id": "2509.10401v1",
        "authors": [
            "Alva West",
            "Yixuan Weng",
            "Minjun Zhu",
            "Zhen Lin",
            "Yue Zhang"
        ],
        "submitted": "2025-09-12 16:51:15",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on causal inference and failure attribution in multi-agent systems, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "Model-agnostic post-hoc explainability for recommender systems",
        "abstract": "Recommender systems often benefit from complex feature embeddings and deep\nlearning algorithms, which deliver sophisticated recommendations that enhance\nuser experience, engagement, and revenue. However, these methods frequently\nreduce the interpretability and transparency of the system. In this research,\nwe develop a systematic application, adaptation, and evaluation of deletion\ndiagnostics in the recommender setting. The method compares the performance of\na model to that of a similar model trained without a specific user or item,\nallowing us to quantify how that observation influences the recommender, either\npositively or negatively. To demonstrate its model-agnostic nature, the\nproposal is applied to both Neural Collaborative Filtering (NCF), a widely used\ndeep learning-based recommender, and Singular Value Decomposition (SVD), a\nclassical collaborative filtering technique. Experiments on the MovieLens and\nAmazon Reviews datasets provide insights into model behavior and highlight the\ngenerality of the approach across different recommendation paradigms.",
        "url": "http://arxiv.org/abs/2509.10245v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10245v1",
        "arxiv_id": "2509.10245v1",
        "authors": [
            "Irina Arévalo",
            "Jose L Salmeron"
        ],
        "submitted": "2025-09-12 13:43:16",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "While this paper focuses on recommender systems, which is a related area to information retrieval, it does not directly address query understanding, ranking models, or user behavior modeling. The paper's emphasis on explainability and interpretability is also not a primary focus of your research interests. However, the use of deep learning-based recommender systems and collaborative filtering techniques may be of some interest to you."
    },
    {
        "title": "A Research Vision for Web Search on Emerging Topics",
        "abstract": "We regularly encounter information on novel, emerging topics for which the\nbody of knowledge is still evolving, which can be linked, for instance, to\ncurrent events. A primary way to learn more about such topics is through web\nsearch. However, information on emerging topics is sparse and evolves\ndynamically as knowledge grows, making it uncertain and variable in quality and\ntrustworthiness and prone to deliberate or accidental manipulation,\nmisinformation, and bias. In this paper, we outline a research vision towards\nsearch systems and interfaces that support effective knowledge acquisition,\nawareness of the dynamic nature of topics, and responsible opinion formation\namong people searching the web for information on emerging topics. To realize\nthis vision, we propose three overarching research questions, aimed at\nunderstanding the status quo, determining requirements of systems aligned with\nour vision, and building these systems. For each of the three questions, we\nhighlight relevant literature, including pointers on how they could be\naddressed. Lastly, we discuss the challenges that will potentially arise in\npursuing the proposed vision.",
        "url": "http://arxiv.org/abs/2509.10212v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10212v1",
        "arxiv_id": "2509.10212v1",
        "authors": [
            "Alisa Rieger",
            "Stefan Dietze",
            "Ran Yu"
        ],
        "submitted": "2025-09-12 13:00:06",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'web search' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper aligns with your interests in Information Retrieval, particularly in the context of web search and emerging topics. The focus on knowledge acquisition, dynamic topic awareness, and responsible opinion formation resonates with your expertise in query understanding and ranking models. While it doesn't delve into specific NLP or recommender systems, the paper's emphasis on real-time relevance optimization and system building makes it relevant to your broader research interests."
    },
    {
        "title": "Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing Generative AI with Synthetic Patient Records",
        "abstract": "The development of medical chatbots in Arabic is significantly constrained by\nthe scarcity of large-scale, high-quality annotated datasets. While prior\nefforts compiled a dataset of 20,000 Arabic patient-doctor interactions from\nsocial media to fine-tune large language models (LLMs), model scalability and\ngeneralization remained limited. In this study, we propose a scalable synthetic\ndata augmentation strategy to expand the training corpus to 100,000 records.\nUsing advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated\n80,000 contextually relevant and medically coherent synthetic question-answer\npairs grounded in the structure of the original dataset. These synthetic\nsamples were semantically filtered, manually validated, and integrated into the\ntraining pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,\nand evaluated their performance using BERTScore metrics and expert-driven\nqualitative assessments. To further analyze the effectiveness of synthetic\nsources, we conducted an ablation study comparing ChatGPT-4o and\nGemini-generated data independently. The results showed that ChatGPT-4o data\nconsistently led to higher F1-scores and fewer hallucinations across all\nmodels. Overall, our findings demonstrate the viability of synthetic\naugmentation as a practical solution for enhancing domain-specific language\nmodels in-low resource medical NLP, paving the way for more inclusive,\nscalable, and accurate Arabic healthcare chatbot systems.",
        "url": "http://arxiv.org/abs/2509.10108v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10108v1",
        "arxiv_id": "2509.10108v1",
        "authors": [
            "Abdulrahman Allam",
            "Seif Ahmed",
            "Ali Hamdi",
            "Khaled Shaban"
        ],
        "submitted": "2025-09-12 09:58:11",
        "source": "arxiv",
        "comment": "Accepted in AICCSA 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Arabic medical chatbots and generative AI, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve NLP, the specific domain and application are quite different from your areas of focus."
    },
    {
        "title": "!MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for Readability Assessment",
        "abstract": "We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained\nArabic readability assessment, achieving first place in six of six tracks. Our\napproach is a confidence-weighted ensemble of four complementary transformer\nmodels (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with\ndistinct loss functions to capture diverse readability signals. To tackle\nsevere class imbalance and data scarcity, we applied weighted training,\nadvanced preprocessing, SAMER corpus relabeling with our strongest model, and\nsynthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level\nsamples. A targeted post-processing step corrected prediction distribution\nskew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system\nreached 87.5 percent QWK at the sentence level and 87.4 percent at the document\nlevel, demonstrating the power of model and loss diversity, confidence-informed\nfusion, and intelligent augmentation for robust Arabic readability prediction.",
        "url": "http://arxiv.org/abs/2509.10040v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10040v1",
        "arxiv_id": "2509.10040v1",
        "authors": [
            "Mohamed Basem",
            "Mohamed Younes",
            "Seif Ahmed",
            "Abdelrahman Moustafa"
        ],
        "submitted": "2025-09-12 08:08:45",
        "source": "arxiv",
        "comment": "10 Pages , 8 figures , ArabicNLP 2025 , Co-located with EMNLP 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. Although it involves transformer models and fine-tuning, the focus is on readability assessment in Arabic, which is not a primary area of interest for the user."
    },
    {
        "title": "Linguistic trajectories of bipolar disorder on social media",
        "abstract": "Language provides valuable markers of affective disorders such as bipolar\ndisorder (BD), yet clinical assessments remain limited in scale. In response,\nanalyses of social media (SM) language have gained prominence due to their high\ntemporal resolution and longitudinal scope. Here, we introduce a method to\ndetermine the timing of users' diagnoses and apply it to study language\ntrajectories from 3 years before to 21 years after BD diagnosis - contrasted\nwith uses reporting unipolar depression (UD) and non-affected users (HC). We\nshow that BD diagnosis is accompanied by pervasive linguistic alterations\nreflecting mood disturbance, psychiatric comorbidity, substance abuse,\nhospitalization, medical comorbidities, unusual thought content, and\ndisorganized thought. We further observe recurring mood-related language\nchanges across two decades after the diagnosis, with a pronounced 12-month\nperiodicity suggestive of seasonal mood episodes. Finally, trend-level evidence\nsuggests an increased periodicity in users estimated to be female. In sum, our\nfindings provide evidence for language alterations in the acute and chronic\nphase of BD. This validates and extends recent efforts leveraging SM for\nscalable monitoring of mental health.",
        "url": "http://arxiv.org/abs/2509.10035v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10035v1",
        "arxiv_id": "2509.10035v1",
        "authors": [
            "Laurin Plank",
            "Armin Zlomuzica"
        ],
        "submitted": "2025-09-12 08:02:38",
        "source": "arxiv",
        "comment": "Pre-print",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on analyzing linguistic patterns in social media to diagnose and monitor mental health conditions, which is outside your areas of expertise."
    },
    {
        "title": "Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs",
        "abstract": "In this paper, we provide an extensive analysis of multi-label intent\nclassification using Large Language Models (LLMs) that are open-source,\npublicly available, and can be run in consumer hardware. We use the MultiWOZ\n2.1 dataset, a benchmark in the dialogue system domain, to investigate the\nefficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,\nMistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot\nsetup, giving 20 examples in the prompt with some instructions. Our approach\nfocuses on the differences in performance of these models across several\nperformance metrics by methodically assessing these models on multi-label\nintent classification tasks. Additionally, we compare the performance of the\ninstruction-based fine-tuning approach with supervised learning using the\nsmaller transformer model BertForSequenceClassification as a baseline. To\nevaluate the performance of the models, we use evaluation metrics like\naccuracy, precision, and recall as well as micro, macro, and weighted F1 score.\nWe also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1\noutperforms two other generative models on 11 intent classes out of 14 in terms\nof F-Score, with a weighted average of 0.50. It also has relatively lower\nHumming Loss and higher Jaccard Similarity, making it the winning model in the\nfew-shot setting. We find BERT based supervised classifier having superior\nperformance compared to the best performing few-shot generative LLM. The study\nprovides a framework for small open-source LLMs in detecting complex\nmulti-intent dialogues, enhancing the Natural Language Understanding aspect of\ntask-oriented chatbots.",
        "url": "http://arxiv.org/abs/2509.10010v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10010v1",
        "arxiv_id": "2509.10010v1",
        "authors": [
            "Adnan Ahmad",
            "Philine Kowol",
            "Stefan Hillmann",
            "Sebastian Möller"
        ],
        "submitted": "2025-09-12 07:10:55",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on dialogue understanding and multi-intent recognition using Large Language Models, which is somewhat related to your interests in Natural Language Processing (NLP) and related topics. However, it does not directly align with your primary focus on Information Retrieval (IR), query understanding, and ranking models."
    },
    {
        "title": "Unsupervised Hallucination Detection by Inspecting Reasoning Processes",
        "abstract": "Unsupervised hallucination detection aims to identify hallucinated content\ngenerated by large language models (LLMs) without relying on labeled data.\nWhile unsupervised methods have gained popularity by eliminating\nlabor-intensive human annotations, they frequently rely on proxy signals\nunrelated to factual correctness. This misalignment biases detection probes\ntoward superficial or non-truth-related aspects, limiting generalizability\nacross datasets and scenarios. To overcome these limitations, we propose IRIS,\nan unsupervised hallucination detection framework, leveraging internal\nrepresentations intrinsic to factual correctness. IRIS prompts the LLM to\ncarefully verify the truthfulness of a given statement, and obtain its\ncontextualized embedding as informative features for training. Meanwhile, the\nuncertainty of each response is considered a soft pseudolabel for truthfulness.\nExperimental results demonstrate that IRIS consistently outperforms existing\nunsupervised methods. Our approach is fully unsupervised, computationally low\ncost, and works well even with few training data, making it suitable for\nreal-time detection.",
        "url": "http://arxiv.org/abs/2509.10004v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10004v1",
        "arxiv_id": "2509.10004v1",
        "authors": [
            "Ponhvoan Srey",
            "Xiaobao Wu",
            "Anh Tuan Luu"
        ],
        "submitted": "2025-09-12 06:58:17",
        "source": "arxiv",
        "comment": "To appear in EMNLP 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on unsupervised hallucination detection in large language models, which is somewhat related to information retrieval and NLP. However, the primary focus on factual correctness and truthfulness verification does not directly align with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is limited to the intersection of NLP and IR, but it does not address the user's core research themes."
    },
    {
        "title": "DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL",
        "abstract": "Augmenting large language models (LLMs) with browsing tools substantially\nimproves their potential as deep search agents to solve complex, real-world\ntasks. Yet, open LLMs still perform poorly in such settings due to limited\nlong-horizon reasoning capacity with browsing tools and the lack of\nsufficiently difficult supervised data. To address these challenges, we present\nDeepDive to advance deep search agents. First, we propose a strategy to\nautomatically synthesize complex, difficult, and hard-to-find questions from\nopen knowledge graphs. Second, we apply end-to-end multi-turn reinforcement\nlearning (RL) to enhance LLMs' long-horizon reasoning with deep search.\nExperiments show that DeepDive-32B achieves a new open-source competitive\nresult on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and\nSearch-o1. We demonstrate that multi-turn RL training improves deep search\nability and significantly contributes to the performance improvements across\nmultiple benchmarks. We observe that DeepDive enables test-time scaling of tool\ncalls and parallel sampling. All datasets, models, and code are publicly\navailable at https://github.com/THUDM/DeepDive.",
        "url": "http://arxiv.org/abs/2509.10446v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10446v1",
        "arxiv_id": "2509.10446v1",
        "authors": [
            "Rui Lu",
            "Zhenyu Hou",
            "Zihan Wang",
            "Hanchen Zhang",
            "Xiao Liu",
            "Yujiang Li",
            "Shi Feng",
            "Jie Tang",
            "Yuxiao Dong"
        ],
        "submitted": "2025-09-12 17:52:35",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of deep semantic understanding and real-time relevance optimization. The use of knowledge graphs and multi-turn reinforcement learning to enhance large language models' long-horizon reasoning capacity aligns with your focus on query understanding and ranking models. However, the e-commerce domain is not explicitly mentioned, which is the only reason it doesn't score higher."
    },
    {
        "title": "Benchmark of stylistic variation in LLM-generated texts",
        "abstract": "This study investigates the register variation in texts written by humans and\ncomparable texts produced by large language models (LLMs). Biber's\nmultidimensional analysis (MDA) is applied to a sample of human-written texts\nand AI-created texts generated to be their counterparts to find the dimensions\nof variation in which LLMs differ most significantly and most systematically\nfrom humans. As textual material, a new LLM-generated corpus AI-Brown is used,\nwhich is comparable to BE-21 (a Brown family corpus representing contemporary\nBritish English). Since all languages except English are underrepresented in\nthe training data of frontier LLMs, similar analysis is replicated on Czech\nusing AI-Koditex corpus and Czech multidimensional model. Examined were 16\nfrontier models in various settings and prompts, with emphasis placed on the\ndifference between base models and instruction-tuned models. Based on this, a\nbenchmark is created through which models can be compared with each other and\nranked in interpretable dimensions.",
        "url": "http://arxiv.org/abs/2509.10179v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10179v1",
        "arxiv_id": "2509.10179v1",
        "authors": [
            "Jiří Milička",
            "Anna Marklová",
            "Václav Cvrček"
        ],
        "submitted": "2025-09-12 12:12:20",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the stylistic variation in LLM-generated texts, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing, particularly in areas requiring deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Towards Reliable and Interpretable Document Question Answering via VLMs",
        "abstract": "Vision-Language Models (VLMs) have shown strong capabilities in document\nunderstanding, particularly in identifying and extracting textual information\nfrom complex documents. Despite this, accurately localizing answers within\ndocuments remains a major challenge, limiting both interpretability and\nreal-world applicability. To address this, we introduce\n\\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that\ndecouples answer generation from spatial localization. This design makes it\napplicable to existing VLMs, including proprietary systems where fine-tuning is\nnot feasible. Through systematic evaluation, we provide quantitative insights\ninto the gap between textual accuracy and spatial grounding, showing that\ncorrect answers often lack reliable localization. Our standardized framework\nhighlights these shortcomings and establishes a benchmark for future research\ntoward more interpretable and robust document information extraction VLMs.",
        "url": "http://arxiv.org/abs/2509.10129v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10129v1",
        "arxiv_id": "2509.10129v1",
        "authors": [
            "Alessio Chen",
            "Simone Giovannini",
            "Andrea Gemelli",
            "Fabio Coppini",
            "Simone Marinai"
        ],
        "submitted": "2025-09-12 10:44:24",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper explores the application of Vision-Language Models (VLMs) in document question answering, which is somewhat related to information retrieval and query understanding. However, the focus on spatial localization and bounding-box prediction is not directly aligned with my core research themes in ranking models and user behavior modeling."
    },
    {
        "title": "Prominence-aware automatic speech recognition for conversational speech",
        "abstract": "This paper investigates prominence-aware automatic speech recognition (ASR)\nby combining prominence detection and speech recognition for conversational\nAustrian German. First, prominence detectors were developed by fine-tuning\nwav2vec2 models to classify word-level prominence. The detector was then used\nto automatically annotate prosodic prominence in a large corpus. Based on those\nannotations, we trained novel prominence-aware ASR systems that simultaneously\ntranscribe words and their prominence levels. The integration of prominence\ninformation did not change performance compared to our baseline ASR system,\nwhile reaching a prominence detection accuracy of 85.53% for utterances where\nthe recognized word sequence was correct. This paper shows that\ntransformer-based models can effectively encode prosodic information and\nrepresents a novel contribution to prosody-enhanced ASR, with potential\napplications for linguistic research and prosody-informed dialogue systems.",
        "url": "http://arxiv.org/abs/2509.10116v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10116v1",
        "arxiv_id": "2509.10116v1",
        "authors": [
            "Julian Linke",
            "Barbara Schuppler"
        ],
        "submitted": "2025-09-12 10:18:38",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on automatic speech recognition and prosody-enhanced ASR, which is outside the user's core research themes in Information Retrieval and Search technologies. While it involves NLP, the topic is not directly related to query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "VARCO-VISION-2.0 Technical Report",
        "abstract": "We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model\n(VLM) for Korean and English with improved capabilities compared to the\nprevious model VARCO-VISION-14B. The model supports multi-image understanding\nfor complex inputs such as documents, charts, and tables, and delivers\nlayoutaware OCR by predicting both textual content and its spatial location.\nTrained with a four-stage curriculum with memory-efficient techniques, the\nmodel achieves enhanced multimodal alignment, while preserving core language\nabilities and improving safety via preference optimization. Extensive benchmark\nevaluations demonstrate strong spatial grounding and competitive results for\nboth languages, with the 14B model achieving 8th place on the OpenCompass VLM\nleaderboard among models of comparable scale. Alongside the 14B-scale model, we\nrelease a 1.7B version optimized for on-device deployment. We believe these\nmodels advance the development of bilingual VLMs and their practical\napplications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a\nfull-scale 14B model and a lightweight 1.7B model.",
        "url": "http://arxiv.org/abs/2509.10105v1",
        "pdf_url": "http://arxiv.org/pdf/2509.10105v1",
        "arxiv_id": "2509.10105v1",
        "authors": [
            "Young-rok Cha",
            "Jeongho Ju",
            "SunYoung Park",
            "Jong-Hyeon Lee",
            "Younghyun Yu",
            "Youngjune Kim"
        ],
        "submitted": "2025-09-12 09:55:56",
        "source": "arxiv",
        "comment": "19 pages, 1 figure, 14 tables. Technical report for VARCO-VISION-2.0,\n  a Korean-English bilingual VLM in 14B and 1.7B variants. Key features:\n  multi-image understanding, OCR with text localization, improved Korean\n  capabilities",
        "score": 1,
        "keyword_reasons": [
            "Found 'korea' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on vision-language models, which is a related but distinct area from information retrieval and search technologies. While it involves multimodal alignment and understanding, it does not directly address query understanding, ranking models, or user behavior modeling, making it less relevant to your core research interests."
    },
    {
        "title": "CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China",
        "abstract": "Minority languages in China, such as Tibetan, Uyghur, and Traditional\nMongolian, face significant challenges due to their unique writing systems,\nwhich differ from international standards. This discrepancy has led to a severe\nlack of relevant corpora, particularly for supervised tasks like headline\ngeneration. To address this gap, we introduce a novel dataset, Chinese Minority\nHeadline Generation (CMHG), which includes 100,000 entries for Tibetan, and\n50,000 entries each for Uyghur and Mongolian, specifically curated for headline\ngeneration tasks. Additionally, we propose a high-quality test set annotated by\nnative speakers, designed to serve as a benchmark for future research in this\ndomain. We hope this dataset will become a valuable resource for advancing\nheadline generation in Chinese minority languages and contribute to the\ndevelopment of related benchmarks.",
        "url": "http://arxiv.org/abs/2509.09990v1",
        "pdf_url": "http://arxiv.org/pdf/2509.09990v1",
        "arxiv_id": "2509.09990v1",
        "authors": [
            "Guixian Xu",
            "Zeli Su",
            "Ziyin Zhang",
            "Jianing Liu",
            "XU Han",
            "Ting Zhang",
            "Yushuang Dong"
        ],
        "submitted": "2025-09-12 06:18:44",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on headline generation for minority languages in China, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves NLP, the specific task and domain are quite different from the user's interests."
    },
    {
        "title": "Emulating Public Opinion: A Proof-of-Concept of AI-Generated Synthetic Survey Responses for the Chilean Case",
        "abstract": "Large Language Models (LLMs) offer promising avenues for methodological and\napplied innovations in survey research by using synthetic respondents to\nemulate human answers and behaviour, potentially mitigating measurement and\nrepresentation errors. However, the extent to which LLMs recover aggregate item\ndistributions remains uncertain and downstream applications risk reproducing\nsocial stereotypes and biases inherited from training data. We evaluate the\nreliability of LLM-generated synthetic survey responses against ground-truth\nhuman responses from a Chilean public opinion probabilistic survey.\nSpecifically, we benchmark 128 prompt-model-question triplets, generating\n189,696 synthetic profiles, and pool performance metrics (i.e., accuracy,\nprecision, recall, and F1-score) in a meta-analysis across 128\nquestion-subsample pairs to test for biases along key sociodemographic\ndimensions. The evaluation spans OpenAI's GPT family and o-series reasoning\nmodels, as well as Llama and Qwen checkpoints. Three results stand out. First,\nsynthetic responses achieve excellent performance on trust items (F1-score and\naccuracy > 0.90). Second, GPT-4o, GPT-4o-mini and Llama 4 Maverick perform\ncomparably on this task. Third, synthetic-human alignment is highest among\nrespondents aged 45-59. Overall, LLM-based synthetic samples approximate\nresponses from a probabilistic sample, though with substantial item-level\nheterogeneity. Capturing the full nuance of public opinion remains challenging\nand requires careful calibration and additional distributional tests to ensure\nalgorithmic fidelity and reduce errors.",
        "url": "http://arxiv.org/abs/2509.09871v1",
        "pdf_url": "http://arxiv.org/pdf/2509.09871v1",
        "arxiv_id": "2509.09871v1",
        "authors": [
            "Bastián González-Bustamante",
            "Nando Verelst",
            "Carla Cisternas"
        ],
        "submitted": "2025-09-11 21:43:59",
        "source": "arxiv",
        "comment": "Working paper: 18 pages, 4 tables, 2 figures",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing, as it focuses on emulating public opinion using AI-generated synthetic survey responses. While it involves Large Language Models, the context and application are distinct from your areas of focus."
    }
]