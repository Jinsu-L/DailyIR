# Daily Papers Report - 2025-06-22

오늘의 Top 10개 관련 논문입니다.

## 1. SciSage: A Multi-Agent Framework for High-Quality Scientific Survey Generation

- **Score**: 9
- **Authors**: Xiaofeng Shi, Qian Kou, Yuduo Li, Ning Tang, Jinxin Xie, Longbin Yu, Songjing Wang, Hua Zhou
- **URL**: <http://arxiv.org/abs/2506.12689v1>
- **Submitted**: 2025-06-15 02:23:47
- **Keyword Reasons**: Found 'search' (score: +3); Found 'retrieval' (score: +3); Found 'query' (score: +3)

### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Automated Scientific Survey Generation
- **Aim**: To develop a novel multi-agent framework, SciSage, for generating high-quality scientific surveys in computer science
- **Rationale**: To improve the efficiency and quality of scientific survey writing, leveraging large language models and multi-agent collaboration
- **Ground**: The SciSage framework consists of three interconnected components: Query Understanding and Rewrite, Retrieval and Content Generation, and Iterative Hierarchical Reflection
- **Experiment**: Evaluation of SciSage using SurveyScope benchmark and a comprehensive evaluation framework, involving automatic and human evaluation
- **Takeaway**: SciSage demonstrates significant improvements in structural coherence and citation accuracy over existing methods, offering a promising foundation for research-assistive writing tools

### Abstract
> The rapid growth of scientific literature demands robust tools for automated survey-generation. However, current large language model (LLM)-based methods often lack in-depth analysis, structural coherence, and reliable citations. To address these limitations, we introduce SciSage, a multi-agent framework employing a reflect-when-you-write paradigm. SciSage features a hierarchical Reflector agent that critically evaluates drafts at outline, section, and document levels, collaborating with specialized agents for query interpretation, content retrieval, and refinement. We also release SurveyScope, a rigorously curated benchmark of 46 high-impact papers (2020-2025) across 11 computer science domains, with strict recency and citation-based quality controls. Evaluations demonstrate that SciSage outperforms state-of-the-art baselines (LLM x MapReduce-V2, AutoSurvey), achieving +1.73 points in document coherence and +32% in citation F1 scores. Human evaluations reveal mixed outcomes (3 wins vs. 7 losses against human-written surveys), but highlight SciSage's strengths in topical breadth and retrieval efficiency. Overall, SciSage offers a promising foundation for research-assistive writing tools.

---

## 2. FlexRAG: A Flexible and Comprehensive Framework for Retrieval-Augmented Generation

- **Score**: 9
- **Authors**: Zhuocheng Zhang, Yang Feng, Min Zhang
- **URL**: <http://arxiv.org/abs/2506.12494v1>
- **Submitted**: 2025-06-14 13:16:31
- **Comment**: Accepted by ACL 2025 Demo
- **Keyword Reasons**: Found 'search' (score: +3); Found 'retrieval' (score: +3); Found 'rag' (score: +2); Found 'nlp' (score: +1)

### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: FlexRAG: A Comprehensive Framework for Retrieval-Augmented Generation (RAG) Systems
- **Aim**: To design a flexible and comprehensive framework for developing, deploying, and sharing RAG systems, addressing limitations of existing frameworks
- **Rationale**: Existing RAG frameworks have limitations such as difficulties in algorithm reproduction and sharing, lack of new techniques, and high system overhead
- **Ground**: FlexRAG provides comprehensive lifecycle support, efficient asynchronous processing, and persistent caching capabilities, supporting text-based, multimodal, and network-based RAG systems
- **Experiment**: Comparative analysis with existing RAG frameworks (FlashRAG, LangChain, LlamaIndex, and UltraRAG) demonstrates FlexRAG's superior performance in system overhead, algorithm reproducibility, and knowledge sharing
- **Takeaway**: FlexRAG is a unified and flexible framework for developing, evaluating, and deploying RAG systems, offering efficient system resource management and standardized RAG evaluation process

### Abstract
> Retrieval-Augmented Generation (RAG) plays a pivotal role in modern large language model applications, with numerous existing frameworks offering a wide range of functionalities to facilitate the development of RAG systems. However, we have identified several persistent challenges in these frameworks, including difficulties in algorithm reproduction and sharing, lack of new techniques, and high system overhead. To address these limitations, we introduce \textbf{FlexRAG}, an open-source framework specifically designed for research and prototyping. FlexRAG supports text-based, multimodal, and network-based RAG, providing comprehensive lifecycle support alongside efficient asynchronous processing and persistent caching capabilities. By offering a robust and flexible solution, FlexRAG enables researchers to rapidly develop, deploy, and share advanced RAG systems. Our toolkit and resources are available at \href{https://github.com/ictnlp/FlexRAG}{https://github.com/ictnlp/FlexRAG}.

---

## 3. LTRR: Learning To Rank Retrievers for LLMs

- **Score**: 8
- **Authors**: To Eun Kim, Fernando Diaz
- **URL**: <http://arxiv.org/abs/2506.13743v1>
- **Submitted**: 2025-06-16 17:53:18
- **Comment**: SIGIR 2025 LiveRAG Spotlight
- **Reason**: The paper's title and abstract show a strong connection to Learning to Rank (LTR) and Retrieval-Augmented Generation (RAG) systems, which align with your research interests in IR and Search technologies. The use of query routing and ranking models is also relevant to your interests in query processing and ranking models. Additionally, the paper's focus on LLMs and NLP-related applications is of interest to you. The only reason for not scoring it a 10 is that the paper's specific focus on RAG systems and LLMs might not be directly applicable to your e-commerce domain expertise.

### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Learning To Rank Retrievers (LTRR) for query routing in Large Language Models (LLMs)
- **Aim**: To develop a novel query routing approach that dynamically selects from a pool of retrievers based on the query to improve adaptability and reduce computational costs
- **Rationale**: No single retriever performs optimally across all query types, and query routing can improve adaptability and reduce computational costs
- **Ground**: LTRR framework learns to rank retrievers based on their expected utility gain to downstream LLM performance, framing routing as a learning-to-rank (LTR) problem
- **Experiment**: Evaluation of LTRR algorithms in a retrieval-augmented generation (RAG) setting, comparing them to standard single-retriever-based RAG systems
- **Takeaway**: LTRR algorithms, particularly those trained using pairwise XGBoost, outperform standard systems in both in-distribution and some out-of-distribution evaluations, highlighting the effectiveness of pairwise training and the potential of query routing in adaptive retrieval architectures

### Abstract
> Retrieval-Augmented Generation (RAG) systems typically rely on a single fixed retriever, despite growing evidence that no single retriever performs optimally across all query types. In this paper, we explore a query routing approach that dynamically selects from a pool of retrievers based on the query, using both train-free heuristics and learned routing models. We frame routing as a learning-to-rank (LTR) problem and introduce LTRR, a framework that learns to rank retrievers by their expected utility gain to downstream LLM performance. Our experiments, conducted on synthetic QA data with controlled query type variations, show that routing-based RAG systems can outperform the best single-retriever-based systems. Performance gains are especially pronounced in models trained with the Answer Correctness (AC) metric and with pairwise learning approaches, especially with XGBoost. We also observe improvements in generalization to out-of-distribution queries. As part of the SIGIR 2025 LiveRAG challenge, our submitted system demonstrated the practical viability of our approach, achieving competitive performance in both answer correctness and faithfulness. These findings highlight the importance of both training methodology and metric selection in query routing for RAG systems.

---

## 4. OneRec Technical Report

- **Score**: 8
- **Authors**: Guorui Zhou, Jiaxin Deng, Jinghao Zhang, Kuo Cai, Lejian Ren, Qiang Luo, Qianqian Wang, Qigen Hu, Rui Huang, Shiyao Wang, Weifeng Ding, Wuchao Li, Xinchen Luo, Xingmei Wang, Zexuan Cheng, Zixing Zhang, Bin Zhang, Boxuan Wang, Chaoyi Ma, Chengru Song, Chenhui Wang, Di Wang, Dongxue Meng, Fan Yang, Fangyu Zhang, Feng Jiang, Fuxing Zhang, Gang Wang, Guowang Zhang, Han Li, Hengrui Hu, Hezheng Lin, Hongtao Cheng, Hongyang Cao, Huanjie Wang, Jiaming Huang, Jiapeng Chen, Jiaqiang Liu, Jinghui Jia, Kun Gai, Lantao Hu, Liang Zeng, Liao Yu, Qiang Wang, Qidong Zhou, Shengzhe Wang, Shihui He, Shuang Yang, Shujie Yang, Sui Huang, Tao Wu, Tiantian He, Tingting Gao, Wei Yuan, Xiao Liang, Xiaoxiao Xu, Xugang Liu, Yan Wang, Yi Wang, Yiwu Liu, Yue Song, Yufei Zhang, Yunfan Wu, Yunfeng Zhao, Zhanyu Liu
- **URL**: <http://arxiv.org/abs/2506.13695v1>
- **Submitted**: 2025-06-16 16:58:55
- **Comment**: Authors are listed alphabetically by their first name
- **Keyword Reasons**: Found 'queries' (score: +3); Found 'rag' (score: +2); Found 'recommend' (score: +1); Found 'recommendation' (score: +1); Found 'recommender system' (score: +1)

### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: OneRec: A Novel End-to-End Generative Approach to Recommendation Systems
- **Aim**: To propose a novel end-to-end generative approach to recommendation systems that integrates retrieval and ranking processes into a single-stage encoder-decoder framework
- **Rationale**: To address the limitations of traditional recommender systems, including inefficient resource allocation, low utilization of resources dedicated to computation, and the objective collision problem
- **Ground**: The authors identify infrastructure optimizations that achieve 23.7% and 28.8% Model FLOPs Utilization (MFU) on flagship GPUs during training and inference, respectively, reducing operating expense (OPEX) to 10.6% of traditional complex recommendation pipelines
- **Experiment**: The proposed approach has been deployed in Kuaishou/Kuaishou Lite APP, handling 25% of total queries per second (QPS), and enhancing overall App Stay Time by 0.54% and 1.24%, respectively
- **Takeaway**: OneRec outperforms traditional recommendation systems, achieving significant gains in online metrics, including a 95% legality rate, +0.13% in APP Stay Time, and +0.30% in Watch Time

### Abstract
> Recommender systems have been widely used in various large-scale user-oriented platforms for many years. However, compared to the rapid developments in the AI community, recommendation systems have not achieved a breakthrough in recent years. For instance, they still rely on a multi-stage cascaded architecture rather than an end-to-end approach, leading to computational fragmentation and optimization inconsistencies, and hindering the effective application of key breakthrough technologies from the AI community in recommendation scenarios.   To address these issues, we propose OneRec, which reshapes the recommendation system through an end-to-end generative approach and achieves promising results. Firstly, we have enhanced the computational FLOPs of the current recommendation model by 10 $\times$ and have identified the scaling laws for recommendations within certain boundaries. Secondly, reinforcement learning techniques, previously difficult to apply for optimizing recommendations, show significant potential in this framework. Lastly, through infrastructure optimizations, we have achieved 23.7% and 28.8% Model FLOPs Utilization (MFU) on flagship GPUs during training and inference, respectively, aligning closely with the LLM community. This architecture significantly reduces communication and storage overhead, resulting in operating expense that is only 10.6% of traditional recommendation pipelines. Deployed in Kuaishou/Kuaishou Lite APP, it handles 25% of total queries per second, enhancing overall App Stay Time by 0.54% and 1.24%, respectively. Additionally, we have observed significant increases in metrics such as 7-day Lifetime, which is a crucial indicator of recommendation experience. We also provide practical lessons and insights derived from developing, optimizing, and maintaining a production-scale recommendation system with significant real-world impact.

---

## 5. Assessing the Performance Gap Between Lexical and Semantic Models for Information Retrieval With Formulaic Legal Language

- **Score**: 7
- **Authors**: Larissa Mori, Carlos Sousa de Oliveira, Yuehwern Yih, Mario Ventresca
- **URL**: <http://arxiv.org/abs/2506.12895v1>
- **Submitted**: 2025-06-15 15:53:38
- **Reason**: The paper's focus on information retrieval, specifically legal passage retrieval, and its comparison of lexical and semantic models, including BM25 and dense retrieval models, aligns with your research interests in Information Retrieval and Search technologies. The paper's exploration of the performance gap between these models and its analysis of the effectiveness of different approaches in different scenarios is relevant to your interests in query processing and ranking models like Learning to Rank. However, the paper's specific focus on legal language and the Court of Justice of the European Union may not be directly applicable to your work in the e-commerce domain.

### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Performance of lexical and semantic models for information retrieval in formulaic legal language
- **Aim**: To compare the performance of lexical and semantic models for legal passage/paragraph retrieval in the context of the Court of Justice of the European Union (CJEU)
- **Rationale**: The task of legal passage/paragraph retrieval is particularly relevant in the CJEU context, where references to cited legal cases point to specific paragraphs in other decisions, rather than citing the entire case
- **Ground**: The authors use a dataset published in 2023, which consists of paragraph-to-paragraph citations from CJEU cases decided between 1978 and 2021
- **Experiment**: The authors compare the performance of lexical models (BM25 and TF-IDF) and dense models (SBERT, SimCSE, Nomic, Ada-v2, and Emb-3-large) using standard evaluation metrics such as Recall@k, nDCG@10, Mean Average Precision (MAP), and Mean Reciprocal Rank (MRR)
- **Takeaway**: The study highlights the importance of determining when statistical models are more effective than dense models in managing repetitive patterns of legal language, and suggests developing a two-stage re-ranking pipeline to potentially lead to higher accuracy and robustness

### Abstract
> Legal passage retrieval is an important task that assists legal practitioners in the time-intensive process of finding relevant precedents to support legal arguments. This study investigates the task of retrieving legal passages or paragraphs from decisions of the Court of Justice of the European Union (CJEU), whose language is highly structured and formulaic, leading to repetitive patterns. Understanding when lexical or semantic models are more effective at handling the repetitive nature of legal language is key to developing retrieval systems that are more accurate, efficient, and transparent for specific legal domains. To this end, we explore when this routinized legal language is better suited for retrieval using methods that rely on lexical and statistical features, such as BM25, or dense retrieval models trained to capture semantic and contextual information. A qualitative and quantitative analysis with three complementary metrics shows that both lexical and dense models perform well in scenarios with more repetitive usage of language, whereas BM25 performs better than the dense models in more nuanced scenarios where repetition and verbatim~quotes are less prevalent and in longer queries. Our experiments also show that BM25 is a strong baseline, surpassing off-the-shelf dense models in 4 out of 7 performance metrics. However, fine-tuning a dense model on domain-specific data led to improved performance, surpassing BM25 in most metrics, and we analyze the effect of the amount of data used in fine-tuning on the model's performance and temporal robustness. The code, dataset and appendix related to this work are available on: https://github.com/larimo/lexsem-legal-ir.

---

## 6. Beyond One-Size-Fits-All: A Study of Neural and Behavioural Variability Across Different Recommendation Categories

- **Score**: 7
- **Authors**: Georgios Koutroumpas, Sebastian Idesis, Mireia Masias Bruns, Carlos Segura, Joemon M. Jose, Sergi Abadal, Ioannis Arapakis
- **URL**: <http://arxiv.org/abs/2506.13409v1>
- **Submitted**: 2025-06-16 12:23:17
- **Comment**: 11 pages, 7 figures, 5 tables
- **Reason**: The paper explores recommender systems, which is a related area of interest. The study focuses on neural and behavioral variability across different recommendation categories, which is a novel aspect. Although it's not directly related to Information Retrieval or Search technologies, the paper's findings on user preferences and decision-making processes could be relevant to query processing and ranking models. The e-commerce domain is also relevant to the author's experience. However, the paper's scope is narrower than expected, and the connection to Learning to Rank (LTR) is not immediately apparent.

### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Impact of product recommendation categories on user engagement and experience
- **Aim**: To investigate neural signatures in brain activity that differentiate between recommendation categories and identify neurophysiological markers of engagement
- **Rationale**: Shifting focus from algorithmic-centric approaches to understanding user cognitive processes
- **Ground**: Controlled study using a comprehensive e-commerce dataset, collecting EEG and behavioral data from 21 participants
- **Experiment**: Within-subjects design, EEG data preprocessing using MNE-Python library, and three complementary approaches: within-subjects classification, between-subjects analysis, and analysis of established neurophysiological markers of engagement
- **Takeaway**: Incorporating intermediate categories into recommendation systems could improve user experience, and personalized strategies integrating richer behavioral and neural signals could improve recommendation quality and alleviate cold-start issues

### Abstract
> Traditionally, Recommender Systems (RS) have primarily measured performance based on the accuracy and relevance of their recommendations. However, this algorithmic-centric approach overlooks how different types of recommendations impact user engagement and shape the overall quality of experience. In this paper, we shift the focus to the user and address for the first time the challenge of decoding the neural and behavioural variability across distinct recommendation categories, considering more than just relevance. Specifically, we conducted a controlled study using a comprehensive e-commerce dataset containing various recommendation types, and collected Electroencephalography and behavioural data. We analysed both neural and behavioural responses to recommendations that were categorised as Exact, Substitute, Complement, or Irrelevant products within search query results. Our findings offer novel insights into user preferences and decision-making processes, revealing meaningful relationships between behavioural and neural patterns for each category, but also indicate inter-subject variability.

---

## 7. Hierarchical Group-wise Ranking Framework for Recommendation Models

- **Score**: 7
- **Authors**: YaChen Yan, Liubo Li, Ravi Choudhary
- **URL**: <http://arxiv.org/abs/2506.12756v1>
- **Submitted**: 2025-06-15 07:47:26
- **Reason**: The paper's focus on ranking models, specifically Learning to Rank (LTR), and its application to recommender systems aligns with your research interests. The use of hierarchical group-wise ranking framework and residual vector quantization is an innovative approach in the field of IR and NLP. However, the paper's specific focus on recommender systems and e-commerce domain may not be directly applicable to your broader interests in IR and NLP.

### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Hierarchical Group-wise Ranking Framework for Recommendation Models
- **Aim**: Improve item ranking quality by addressing limitations of in-batch negative sampling
- **Rationale**: Existing ranking losses rely on in-batch negative sampling or uniformly sampled negative pairs, leading to overemphasizing easy negatives and underutilizing harder negatives
- **Ground**: Integrates hierarchical ranking objective with standard calibration losses in a multi-task learning framework
- **Experiment**: Evaluates the proposed framework on two large-scale public datasets from short video recommendation and e-commerce domains
- **Takeaway**: The proposed Hierarchical Group-wise Ranking Framework provides an efficient and scalable alternative for industrial recommendation systems, improving ranking performance without requiring complex real-time context collection or retrieval infrastructure

### Abstract
> In modern recommender systems, CTR/CVR models are increasingly trained with ranking objectives to improve item ranking quality. While this shift aligns training more closely with serving goals, most existing methods rely on in-batch negative sampling, which predominantly surfaces easy negatives. This limits the model's ability to capture fine-grained user preferences and weakens overall ranking performance. To address this, we propose a Hierarchical Group-wise Ranking Framework with two key components. First, we apply residual vector quantization to user embeddings to generate hierarchical user codes that partition users into hierarchical, trie-structured clusters. Second, we apply listwise ranking losses to user-item pairs at each level of the hierarchy, where shallow levels group loosely similar users and deeper levels group highly similar users, reinforcing learning-to-rank signals through progressively harder negatives. Since users with similar preferences and content exposure tend to yield more informative negatives, applying ranking losses within these hierarchical user groups serves as an effective approximation of hard negative mining. Our approach improves ranking performance without requiring complex real-time context collection or retrieval infrastructure. Extensive experiments demonstrate that the proposed framework consistently enhances both model calibration and ranking accuracy, offering a scalable and practical solution for industrial recommender systems.

---

## 8. Decompositional Reasoning for Graph Retrieval with Large Language Models

- **Score**: 7
- **Authors**: Valentin Six, Evan Dufraisse, Gaël de Chalendar
- **URL**: <http://arxiv.org/abs/2506.13380v1>
- **Submitted**: 2025-06-16 11:44:28
- **Reason**: The paper's focus on integrating Large Language Models with Knowledge Graphs and query decomposition shows relevance to Information Retrieval and Search technologies, particularly in the context of complex question answering. The use of weighted similarity functions and structured reasoning pipelines also touches on related areas like natural language processing and recommender systems. While the paper does not explicitly mention Learning to Rank, the query decomposition approach shares similarities with ranking models. However, the paper's primary focus on multi-hop QA tasks and knowledge graph retrieval limits its direct relevance to the user's research interests.

### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Integrating Textual Knowledge Graphs into Large Language Models for Complex Question Answering
- **Aim**: To develop a novel approach that integrates textual knowledge graphs into the Large Language Model (LLM) reasoning process via query decomposition to improve complex question answering
- **Rationale**: The need for explicit mechanisms for integrating or reasoning over structured information and the importance of LLMs to verify facts or reason explicitly over external knowledge
- **Ground**: The authors' approach involves decomposing complex questions into sub-questions, retrieving relevant textual subgraphs, and composing a question-specific knowledge graph to guide answer generation
- **Experiment**: The authors evaluate their method on two question-answering benchmarks, CWQ and WebQSP, and demonstrate consistent improvements in accuracy without increasing the number of parameters or LLM calls
- **Takeaway**: The authors' approach achieves a 3× to 5× reduction in LLM calls compared to other baselines, and demonstrates the importance of integrating textual knowledge graphs into LLMs for complex question answering

### Abstract
> Large Language Models (LLMs) excel at many NLP tasks, but struggle with multi-hop reasoning and factual consistency, limiting their effectiveness on knowledge-intensive tasks like complex question answering (QA). Linking Knowledge Graphs (KG) and LLMs has shown promising results, but LLMs generally lack the ability to reason efficiently over graph-structured information. To tackle this problem, we propose a novel retrieval approach that integrates textual knowledge graphs into the LLM reasoning process via query decomposition. Our method decomposes complex questions into sub-questions, retrieves relevant textual subgraphs, and composes a question-specific knowledge graph to guide answer generation. For that, we use a weighted similarity function that focuses on both the complex question and the generated subquestions to extract a relevant subgraph, which allows efficient and precise retrieval for complex questions and improves the performance of LLMs on multi-hop QA tasks. This structured reasoning pipeline enhances factual grounding and interpretability while leveraging the generative strengths of LLMs. We evaluate our method on standard multi-hop QA benchmarks and show that it achieves comparable or superior performance to competitive existing methods, using smaller models and fewer LLM calls.

---

## 9. INTERPOS: Interaction Rhythm Guided Positional Morphing for Mobile App Recommender Systems

- **Score**: 7
- **Authors**: M. H. Maqbool, Moghis Fereidouni, Umar Farooq, A. B. Siddique, Hassan Foroosh
- **URL**: <http://arxiv.org/abs/2506.12661v1>
- **Submitted**: 2025-06-14 23:40:49
- **Comment**: 10 pages, 8 tables, 3 figures
- **Keyword Reasons**: Found 'search' (score: +3); Found 'recommend' (score: +1); Found 'recommendation' (score: +1); Found 'recommender system' (score: +1); Found 'natural language processing' (score: +1)

### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Autoregressive Mobile App Recommender Systems
- **Aim**: To propose a novel approach, INTERPOS, that incorporates user interaction rhythm into the recommendation process
- **Rationale**: Traditional sequential recommender systems neglect the time elapsed between consecutive interactions, referred to as 'user rhythm', which is particularly challenging in the mobile app domain
- **Ground**: Recommender systems research, including balancing Markov Chain and Recurrent Neural Network designs, using cloze objectives for masked items prediction, and fusing similarity-based methods with Markov chains for personalized sequential recommendations
- **Experiment**: Evaluating INTERPOS on seven mobile app recommendation datasets, reporting significant performance improvements across various metrics, including NDCG@K and HIT@K
- **Takeaway**: Incorporating interaction rhythm guidance and morphed positioning into autoregressive next-item prediction models can facilitate better learning of user behavioral patterns, leading to tailored predictions

### Abstract
> The mobile app market has expanded exponentially, offering millions of apps with diverse functionalities, yet research in mobile app recommendation remains limited. Traditional sequential recommender systems utilize the order of items in users' historical interactions to predict the next item for the users. Position embeddings, well-established in transformer-based architectures for natural language processing tasks, effectively distinguish token positions in sequences. In sequential recommendation systems, position embeddings can capture the order of items in a user's historical interaction sequence. Nevertheless, this ordering does not consider the time elapsed between two interactions of the same user (e.g., 1 day, 1 week, 1 month), referred to as "user rhythm". In mobile app recommendation datasets, the time between consecutive user interactions is notably longer compared to other domains like movies, posing significant challenges for sequential recommender systems. To address this phenomenon in the mobile app domain, we introduce INTERPOS, an Interaction Rhythm Guided Positional Morphing strategy for autoregressive mobile app recommender systems. INTERPOS incorporates rhythm-guided position embeddings, providing a more comprehensive representation that considers both the sequential order of interactions and the temporal gaps between them. This approach enables a deep understanding of users' rhythms at a fine-grained level, capturing the intricacies of their interaction patterns over time. We propose three strategies to incorporate the morphed positional embeddings in two transformer-based sequential recommendation system architectures. Our extensive evaluations show that INTERPOS outperforms state-of-the-art models using 7 mobile app recommendation datasets on NDCG@K and HIT@K metrics. The source code of INTERPOS is available at https://github.com/dlgrad/INTERPOS.

---

## 10. Tree-Based Text Retrieval via Hierarchical Clustering in RAGFrameworks: Application on Taiwanese Regulations

- **Score**: 6
- **Authors**: Chia-Heng Yu, Yen-Lung Tsai
- **URL**: <http://arxiv.org/abs/2506.13607v1>
- **Submitted**: 2025-06-16 15:34:29
- **Comment**: 19 pages, 5 figures, Code available at
  https://github.com/arthur422tp/hierachical
- **Reason**: The paper discusses a novel approach to text retrieval in the context of Retrieval-Augmented Generation (RAG) systems, which is relevant to Information Retrieval (IR) and Search technologies. The use of hierarchical clustering for adaptive selection of semantically relevant content is an interesting application of clustering techniques in IR. However, the paper does not explicitly mention Learning to Rank (LTR) or query processing and ranking models, which are key areas of interest for the user. The paper's focus on legal text retrieval and its application to a specific domain (Taiwanese regulations) may also limit its broader relevance to the user's interests.

### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Tree-Based Text Retrieval via Hierarchical Clustering in RAG Frameworks
- **Aim**: To propose a hierarchical clustering-based retrieval method to address the challenge of selecting an appropriate k-value in Retrieval-Augmented Generation (RAG) systems
- **Rationale**: Traditional RAG systems employ brute-force inner product search to retrieve the top-k most similar documents, but selecting an appropriate k-value is crucial, as a small k may fail to retrieve sufficient information, while a large k can introduce excessive and irrelevant content
- **Ground**: The proposed method uses hierarchical clustering to eliminate the need to predefine k, maintaining the accuracy and relevance of system responses while adaptively selecting semantically relevant content
- **Experiment**: The authors demonstrate the effectiveness of their method through an experiment on a Taiwanese legal dataset with expert-graded queries, achieving superior performance in expert evaluations and maintaining high precision
- **Takeaway**: The proposed method is a practical solution for real-world applications under limited resources, as it is simple to implement and easily integrates with existing RAG pipelines

### Abstract
> Traditional Retrieval-Augmented Generation (RAG) systems employ brute-force inner product search to retrieve the top-k most similar documents, then combined with the user query and passed to a language model. This allows the model to access external knowledge and reduce hallucinations. However, selecting an appropriate k value remains a significant challenge in practical applications: a small k may fail to retrieve sufficient information, while a large k can introduce excessive and irrelevant content. To address this, we propose a hierarchical clustering-based retrieval method that eliminates the need to predefine k. Our approach maintains the accuracy and relevance of system responses while adaptively selecting semantically relevant content. In the experiment stage, we applied our method to a Taiwanese legal dataset with expert-graded queries. The results show that our approach achieves superior performance in expert evaluations and maintains high precision while eliminating the need to predefine k, demonstrating improved accuracy and interpretability in legal text retrieval tasks. Our framework is simple to implement and easily integrates with existing RAG pipelines, making it a practical solution for real-world applications under limited resources.

---

