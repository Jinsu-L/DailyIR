# Daily Papers Report - 2025-09-10

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Query Expansion in the Age of Pre-trained and Large Language Models: A Comprehensive Survey

- **LLM Score**: 9
- **Keyword Score**: 21
- **Authors**: Minghan Li, Xinxuan Lv, Junjie Zou, Tongna Chen, Chao Zhang, Suchao An, Ercong Nie, Guodong Zhou
- **URL**: <http://arxiv.org/abs/2509.07794v1>
- **Submitted**: 2025-09-09 14:31:11
- **Comment**: 38 pages,3 figures
- **Topic Keywords**: information retrieval, query, queries, ranking, rag, retrieval, commerce, e-commerce, web search, rank, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly query understanding, ranking models, and user behavior modeling. The focus on query expansion, pre-trained language models, and large language models aligns well with your expertise in Search technologies and NLP.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Query Expansion (QE) in Information Retrieval
- **Aim**: To survey the field of QE, focusing on the impact of pre-trained language models (PLMs) and large language models (LLMs).
- **Rationale**: QE is crucial for improving information retrieval accuracy and relevance.
- **Ground**: The survey presents a four-dimensional framework for understanding QE and categorizes QE models into five types.
- **Experiment**: The paper compares traditional and PLM/LLM-based QE methods across seven key aspects and maps QE applications across diverse domains.
- **Takeaway**: Robust QE techniques are needed to address challenges like topic drift, hallucination, and domain adaptation through grounding, alignment, and knowledge graph constraints.

#### Abstract
> Modern information retrieval (IR) must bridge short, ambiguous queries and
ever more diverse, rapidly evolving corpora. Query Expansion (QE) remains a key
mechanism for mitigating vocabulary mismatch, but the design space has shifted
markedly with pre-trained language models (PLMs) and large language models
(LLMs). This survey synthesizes the field from three angles: (i) a
four-dimensional framework of query expansion - from the point of injection
(explicit vs. implicit QE), through grounding and interaction (knowledge bases,
model-internal capabilities, multi-turn retrieval) and learning alignment, to
knowledge graph-based argumentation; (ii) a model-centric taxonomy spanning
encoder-only, encoder-decoder, decoder-only, instruction-tuned, and
domain/multilingual variants, highlighting their characteristic affordances for
QE (contextual disambiguation, controllable generation, zero-/few-shot
reasoning); and (iii) practice-oriented guidance on where and how neural QE
helps in first-stage retrieval, multi-query fusion, re-ranking, and
retrieval-augmented generation (RAG). We compare traditional query expansion
with PLM/LLM-based methods across seven key aspects, and we map applications
across web search, biomedicine, e-commerce, open-domain QA/RAG, conversational
and code search, and cross-lingual settings. The review distills design
grounding and interaction, alignment/distillation (SFT/PEFT/DPO), and KG
constraints - as robust remedies to topic drift and hallucination. We conclude
with an agenda on quality control, cost-aware invocation, domain/temporal
adaptation, evaluation beyond end-task metrics, and fairness/privacy.
Collectively, these insights provide a principled blueprint for selecting and
combining QE techniques under real-world constraints.

---

### 2. Benchmarking Information Retrieval Models on Complex Retrieval Tasks

- **LLM Score**: 8
- **Keyword Score**: 14
- **Authors**: Julian Killingback, Hamed Zamani
- **URL**: <http://arxiv.org/abs/2509.07253v1>
- **Submitted**: 2025-09-08 22:11:10
- **Topic Keywords**: information retrieval, query, queries, rag, retrieval, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in complex retrieval tasks and the evaluation of retrieval models. The paper's focus on benchmarking retrieval models and exploring the impact of LLM-based query expansion and rewriting aligns with your interests in query understanding and ranking models.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Retrieval Models for Complex Queries
- **Aim**: To evaluate the performance of retrieval models on complex, multi-faceted queries and investigate the impact of LLM-based query expansion and rewriting techniques.
- **Rationale**: Current retrieval models struggle with complex queries, and there is a lack of comprehensive benchmark datasets for evaluating their performance in realistic settings.
- **Ground**: A new benchmark comprising diverse and realistic complex retrieval tasks is introduced.
- **Experiment**: State-of-the-art retrieval models are evaluated on the new benchmark, with and without LLM-based query expansion and rewriting techniques.
- **Takeaway**: Even advanced retrieval models struggle with complex queries, achieving low performance scores. While LLM augmentation can benefit weaker models, it negatively impacts the strongest model when using rewriting techniques.

#### Abstract
> Large language models (LLMs) are incredible and versatile tools for
text-based tasks that have enabled countless, previously unimaginable,
applications. Retrieval models, in contrast, have not yet seen such capable
general-purpose models emerge. To achieve this goal, retrieval models must be
able to perform complex retrieval tasks, where queries contain multiple parts,
constraints, or requirements in natural language. These tasks represent a
natural progression from the simple, single-aspect queries that are used in the
vast majority of existing, commonly used evaluation sets. Complex queries
naturally arise as people expect search systems to handle more specific and
often ambitious information requests, as is demonstrated by how people use
LLM-based information systems. Despite the growing desire for retrieval models
to expand their capabilities in complex retrieval tasks, there exist limited
resources to assess the ability of retrieval models on a comprehensive set of
diverse complex tasks. The few resources that do exist feature a limited scope
and often lack realistic settings making it hard to know the true capabilities
of retrieval models on complex real-world retrieval tasks. To address this
shortcoming and spur innovation in next-generation retrieval models, we
construct a diverse and realistic set of complex retrieval tasks and benchmark
a representative set of state-of-the-art retrieval models. Additionally, we
explore the impact of LLM-based query expansion and rewriting on retrieval
quality. Our results show that even the best models struggle to produce
high-quality retrieval results with the highest average nDCG@10 of only 0.346
and R@100 of only 0.587 across all tasks. Although LLM augmentation can help
weaker models, the strongest model has decreased performance across all metrics
with all rewriting techniques.

---

### 3. Multi-view-guided Passage Reranking with Large Language Models

- **LLM Score**: 8
- **Keyword Score**: 13
- **Authors**: Jeongwoo Na, Jun Kwon, Eunseong Choi, Jongwuk Lee
- **URL**: <http://arxiv.org/abs/2509.07485v1>
- **Submitted**: 2025-09-09 08:05:16
- **Topic Keywords**: query, ranking, rerank, relevance, rank
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The use of large language models for passage reranking aligns with your focus on deep semantic understanding and real-time relevance optimization. The paper's emphasis on efficiency and sensitivity to external biases also resonates with your interests in user behavior modeling and click models.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Passage Reranking for Information Retrieval
- **Aim**: To develop a more efficient and robust LLM-based passage reranking model than existing generative methods.
- **Rationale**: Existing generative reranking methods are computationally expensive due to autoregressive decoding and susceptible to biases like position and selection bias.
- **Ground**: Multi-view encoding and anchor-guided decoding approach.
- **Experiment**: MVP model is trained using the FiD architecture, ListNet loss function, and orthogonal regularization. Performance is evaluated on benchmark datasets and compared to baselines.
- **Takeaway**: MVP achieves a 100√ó reduction in inference latency while maintaining comparable performance. It demonstrates strong resistance to position and selection biases and outperforms other T5-based reranking models.

#### Abstract
> Recent advances in large language models (LLMs) have shown impressive
performance in passage reranking tasks. Despite their success, LLM-based
methods still face challenges in efficiency and sensitivity to external biases.
(1) Existing models rely mostly on autoregressive generation and sliding window
strategies to rank passages, which incur heavy computational overhead as the
number of passages increases. (2) External biases, such as position or
selection bias, hinder the model's ability to accurately represent passages and
increase input-order sensitivity. To address these limitations, we introduce a
novel passage reranking model, called Multi-View-guided Passage Reranking
(MVP). MVP is a non-generative LLM-based reranking method that encodes
query-passage information into diverse view embeddings without being influenced
by external biases. For each view, it combines query-aware passage embeddings
to produce a distinct anchor vector, which is then used to directly compute
relevance scores in a single decoding step. In addition, it employs an
orthogonal loss to make the views more distinctive. Extensive experiments
demonstrate that MVP, with just 220M parameters, matches the performance of
much larger 7B-scale fine-tuned models while achieving a 100x reduction in
inference latency. Notably, the 3B-parameter variant of MVP achieves
state-of-the-art performance on both in-domain and out-of-domain benchmarks.
The source code is available at: https://github.com/bulbna/MVP

---

### 4. Beyond Sequential Reranking: Reranker-Guided Search Improves Reasoning Intensive Retrieval

- **LLM Score**: 8
- **Keyword Score**: 10
- **Authors**: Haike Xu, Tong Chen
- **URL**: <http://arxiv.org/abs/2509.07163v1>
- **Submitted**: 2025-09-08 19:24:09
- **Topic Keywords**: ranking, rerank, retrieval, rank, search
- **Reason**: This paper is highly relevant to Information Retrieval, particularly in the context of ranking models and real-time relevance optimization. The introduction of Reranker-Guided-Search addresses limitations in traditional retrieve-and-rerank pipelines, which aligns with the user's interest in query understanding and ranking models. The experimental results and analysis also demonstrate the potential for improving retrieval accuracy, making this paper a useful contribution to the field.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Document Retrieval
- **Aim**: Improve document retrieval accuracy, especially when reranking resources are limited.
- **Rationale**: Traditional retrieve-and-rerank pipelines are inefficient as they rerank all retrieved documents, wasting resources on low-ranked ones.
- **Ground**: Proximity graphs constructed using Approximate Nearest Neighbor Search (ANNS), specifically DiskANN algorithm.
- **Experiment**: RGS is evaluated on multiple benchmarks (BRIGHT, M-BEIR, FollowIR) using Reranker@k evaluation setup to assess efficiency within a fixed budget (k=100, 300, or 500).
- **Takeaway**: RGS outperforms existing methods by strategically reranking documents within promising neighborhoods, achieving higher accuracy with limited reranking resources.

#### Abstract
> The widely used retrieve-and-rerank pipeline faces two critical limitations:
they are constrained by the initial retrieval quality of the top-k documents,
and the growing computational demands of LLM-based rerankers restrict the
number of documents that can be effectively processed. We introduce
Reranker-Guided-Search (RGS), a novel approach that bypasses these limitations
by directly retrieving documents according to reranker preferences rather than
following the traditional sequential reranking method. Our method uses a greedy
search on proximity graphs generated by approximate nearest neighbor
algorithms, strategically prioritizing promising documents for reranking based
on document similarity. Experimental results demonstrate substantial
performance improvements across multiple benchmarks: 3.5 points on BRIGHT, 2.9
on FollowIR, and 5.1 on M-BEIR, all within a constrained reranker budget of 100
documents. Our analysis suggests that, given a fixed pair of embedding and
reranker models, strategically selecting documents to rerank can significantly
improve retrieval accuracy under limited reranker budget.

---

### 5. A Survey of Long-Document Retrieval in the PLM and LLM Era

- **LLM Score**: 8
- **Keyword Score**: 9
- **Authors**: Minghan Li, Miyang Luo, Tianrui Lv, Yishuai Zhang, Siqi Zhao, Ercong Nie, Guodong Zhou
- **URL**: <http://arxiv.org/abs/2509.07759v1>
- **Submitted**: 2025-09-09 13:57:53
- **Comment**: 33 pages, 6 figures
- **Topic Keywords**: information retrieval, ranking, retrieval, rank
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of long-document retrieval, which requires deep semantic understanding and real-time relevance optimization. The focus on pre-trained and large language models aligns with your interests in ranking models and query understanding. However, the paper's specific focus on long-document retrieval might not be a central match with your broader interests in user behavior modeling and click models.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Long-Document Retrieval (LDR)
- **Aim**: To provide a comprehensive overview of LDR techniques and guide future research directions, especially concerning foundation models.
- **Rationale**: LDR presents unique challenges due to the complexity of long documents, requiring specialized methods.
- **Ground**: The survey examines the evolution of LDR techniques across three eras: Classical, Pre-trained Language Models (PLMs), and Large Language Models (LLMs).
- **Experiment**: N/A
- **Takeaway**: The survey highlights domain-specific applications, evaluation resources, and open challenges in LDR, including efficiency, multimodal integration, and model faithfulness.

#### Abstract
> The proliferation of long-form documents presents a fundamental challenge to
information retrieval (IR), as their length, dispersed evidence, and complex
structures demand specialized methods beyond standard passage-level techniques.
This survey provides the first comprehensive treatment of long-document
retrieval (LDR), consolidating methods, challenges, and applications across
three major eras. We systematize the evolution from classical lexical and early
neural models to modern pre-trained (PLM) and large language models (LLMs),
covering key paradigms like passage aggregation, hierarchical encoding,
efficient attention, and the latest LLM-driven re-ranking and retrieval
techniques. Beyond the models, we review domain-specific applications,
specialized evaluation resources, and outline critical open challenges such as
efficiency trade-offs, multimodal alignment, and faithfulness. This survey aims
to provide both a consolidated reference and a forward-looking agenda for
advancing long-document retrieval in the era of foundation models.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. NOWJ@COLIEE 2025: A Multi-stage Framework Integrating Embedding Models and Large Language Models for Legal Retrieval and Entailment

- **LLM Score**: 8
- **Keyword Score**: 9
- **Authors**: Hoang-Trung Nguyen, Tan-Minh Nguyen, Xuan-Bach Le, Tuan-Kiet Le, Khanh-Huyen Nguyen, Ha-Thanh Nguyen, Thi-Hai-Yen Vuong, Le-Minh Nguyen
- **URL**: <http://arxiv.org/abs/2509.08025v1>
- **Submitted**: 2025-09-09 12:05:52
- **Topic Keywords**: ranking, relevance, retrieval, rank
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of legal retrieval and entailment. The use of hybrid models integrating traditional IR techniques with Large Language Models is also of interest. However, the focus on the legal domain is somewhat specific and may not be directly applicable to your e-commerce background.

#### Abstract
> This paper presents the methodologies and results of the NOWJ team's
participation across all five tasks at the COLIEE 2025 competition, emphasizing
advancements in the Legal Case Entailment task (Task 2). Our comprehensive
approach systematically integrates pre-ranking models (BM25, BERT, monoT5),
embedding-based semantic representations (BGE-m3, LLM2Vec), and advanced Large
Language Models (Qwen-2, QwQ-32B, DeepSeek-V3) for summarization, relevance
scoring, and contextual re-ranking. Specifically, in Task 2, our two-stage
retrieval system combined lexical-semantic filtering with contextualized LLM
analysis, achieving first place with an F1 score of 0.3195. Additionally, in
other tasks--including Legal Case Retrieval, Statute Law Retrieval, Legal
Textual Entailment, and Legal Judgment Prediction--we demonstrated robust
performance through carefully engineered ensembles and effective prompt-based
reasoning strategies. Our findings highlight the potential of hybrid models
integrating traditional IR techniques with contemporary generative models,
providing a valuable reference for future advancements in legal information
processing.

### 7. ELEC: Efficient Large Language Model-Empowered Click-Through Rate Prediction

- **LLM Score**: 8
- **Keyword Score**: 8
- **Authors**: Rui Dong, Wentao Ouyang, Xiangzheng Liu
- **URL**: <http://arxiv.org/abs/2509.07594v1>
- **Submitted**: 2025-09-09 11:06:37
- **Comment**: SIGIR 2025
- **Topic Keywords**: rag, click, ctr, click-through rate
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in click models and ranking models. The focus on leveraging Large Language Models for click-through rate prediction aligns with your interests in query understanding and real-time relevance optimization.

#### Abstract
> Click-through rate (CTR) prediction plays an important role in online
advertising systems. On the one hand, traditional CTR prediction models capture
the collaborative signals in tabular data via feature interaction modeling, but
they lose semantics in text. On the other hand, Large Language Models (LLMs)
excel in understanding the context and meaning behind text, but they face
challenges in capturing collaborative signals and they have long inference
latency. In this paper, we aim to leverage the benefits of both types of models
and pursue collaboration, semantics and efficiency. We present ELEC, which is
an Efficient LLM-Empowered CTR prediction framework. We first adapt an LLM for
the CTR prediction task. In order to leverage the ability of the LLM but
simultaneously keep efficiency, we utilize the pseudo-siamese network which
contains a gain network and a vanilla network. We inject the high-level
representation vector generated by the LLM into a collaborative CTR model to
form the gain network such that it can take advantage of both tabular modeling
and textual modeling. However, its reliance on the LLM limits its efficiency.
We then distill the knowledge from the gain network to the vanilla network on
both the score level and the representation level, such that the vanilla
network takes only tabular data as input, but can still generate comparable
performance as the gain network. Our approach is model-agnostic. It allows for
the integration with various existing LLMs and collaborative CTR models.
Experiments on real-world datasets demonstrate the effectiveness and efficiency
of ELEC for CTR prediction.

### 8. SciGPT: A Large Language Model for Scientific Literature Understanding and Knowledge Discovery

- **LLM Score**: 8
- **Keyword Score**: 1
- **Authors**: Fengyu She, Nan Wang, Hongfei Wu, Ziyi Wan, Jingmian Wang, Chang Wang
- **URL**: <http://arxiv.org/abs/2509.08032v1>
- **Submitted**: 2025-09-09 16:09:19
- **Topic Keywords**: search
- **Reason**: This paper presents a large language model, SciGPT, specifically designed for scientific literature understanding and knowledge discovery. While not directly focused on information retrieval or search technologies, it aligns with your interests in NLP and deep semantic understanding. The model's innovations and experimental results demonstrate its potential to facilitate AI-augmented scientific discovery.

#### Abstract
> Scientific literature is growing exponentially, creating a critical
bottleneck for researchers to efficiently synthesize knowledge. While
general-purpose Large Language Models (LLMs) show potential in text processing,
they often fail to capture scientific domain-specific nuances (e.g., technical
jargon, methodological rigor) and struggle with complex scientific tasks,
limiting their utility for interdisciplinary research. To address these gaps,
this paper presents SciGPT, a domain-adapted foundation model for scientific
literature understanding and ScienceBench, an open source benchmark tailored to
evaluate scientific LLMs.
  Built on the Qwen3 architecture, SciGPT incorporates three key innovations:
(1) low-cost domain distillation via a two-stage pipeline to balance
performance and efficiency; (2) a Sparse Mixture-of-Experts (SMoE) attention
mechanism that cuts memory consumption by 55\% for 32,000-token long-document
reasoning; and (3) knowledge-aware adaptation integrating domain ontologies to
bridge interdisciplinary knowledge gaps.
  Experimental results on ScienceBench show that SciGPT outperforms GPT-4o in
core scientific tasks including sequence labeling, generation, and inference.
It also exhibits strong robustness in unseen scientific tasks, validating its
potential to facilitate AI-augmented scientific discovery.

### 9. Towards End-to-End Model-Agnostic Explanations for RAG Systems

- **LLM Score**: 7
- **Keyword Score**: 6
- **Authors**: Viju Sudhi, Sinchana Ramakanth Bhat, Max Rudat, Roman Teucher, Nicolas Flores-Herr
- **URL**: <http://arxiv.org/abs/2509.07620v1>
- **Submitted**: 2025-09-09 11:47:40
- **Comment**: Accepted to Workshop on Explainability in Information Retrieval
  (WExIR), SIGIR 2025 - July 17, 2025
- **Topic Keywords**: rag, retrieval augmented generation, retrieval
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, specifically in the context of Retrieval Augmented Generation (RAG) systems. While it doesn't directly focus on query understanding, ranking models, or user behavior modeling, it does address explainability in RAG systems, which is a relevant aspect of IR. However, the paper's primary focus on model-agnostic explanations and post-hoc techniques means it's not a central match for your interests.

#### Abstract
> Retrieval Augmented Generation (RAG) systems, despite their growing
popularity for enhancing model response reliability, often struggle with
trustworthiness and explainability. In this work, we present a novel, holistic,
model-agnostic, post-hoc explanation framework leveraging perturbation-based
techniques to explain the retrieval and generation processes in a RAG system.
We propose different strategies to evaluate these explanations and discuss the
sufficiency of model-agnostic explanations in RAG systems. With this work, we
further aim to catalyze a collaborative effort to build reliable and
explainable RAG systems.

### 10. Toward Purpose-oriented Topic Model Evaluation enabled by Large Language Models

- **LLM Score**: 7
- **Keyword Score**: 3
- **Authors**: Zhiyin Tan, Jennifer D'Souza
- **URL**: <http://arxiv.org/abs/2509.07142v1>
- **Submitted**: 2025-09-08 18:46:08
- **Comment**: Accepted for publication in International Journal on Digital
  Libraries (IJDL)
- **Topic Keywords**: relevance
- **Reason**: This paper is somewhat related to the user's interests in Information Retrieval, particularly in the area of topic modeling and evaluation. The use of Large Language Models for topic model evaluation aligns with the user's focus on deep semantic understanding and real-time relevance optimization. However, the paper's primary focus on topic modeling in digital library systems and scholarly content retrieval is not directly related to the user's e-commerce background or recommender systems interests.

#### Abstract
> This study presents a framework for automated evaluation of dynamically
evolving topic models using Large Language Models (LLMs). Topic modeling is
essential for organizing and retrieving scholarly content in digital library
systems, helping users navigate complex and evolving knowledge domains.
However, widely used automated metrics, such as coherence and diversity, often
capture only narrow statistical patterns and fail to explain semantic failures
in practice. We introduce a purpose-oriented evaluation framework that employs
nine LLM-based metrics spanning four key dimensions of topic quality: lexical
validity, intra-topic semantic soundness, inter-topic structural soundness, and
document-topic alignment soundness. The framework is validated through
adversarial and sampling-based protocols, and is applied across datasets
spanning news articles, scholarly publications, and social media posts, as well
as multiple topic modeling methods and open-source LLMs. Our analysis shows
that LLM-based metrics provide interpretable, robust, and task-relevant
assessments, uncovering critical weaknesses in topic models such as redundancy
and semantic drift, which are often missed by traditional metrics. These
results support the development of scalable, fine-grained evaluation tools for
maintaining topic relevance in dynamic datasets. All code and data supporting
this work are accessible at
https://github.com/zhiyintan/topic-model-LLMjudgment.

### 11. KLIPA: A Knowledge Graph and LLM-Driven QA Framework for IP Analysis

- **LLM Score**: 6
- **Keyword Score**: 8
- **Authors**: Guanzhi Deng, Yi Xie, Yu-Keung Ng, Mingyang Liu, Peijun Zheng, Jie Liu, Dapeng Wu, Yinqiao Li, Linqi Song
- **URL**: <http://arxiv.org/abs/2509.07860v1>
- **Submitted**: 2025-09-09 15:40:23
- **Topic Keywords**: queries, rag, retrieval, search
- **Reason**: The paper KLIPA explores a novel framework for patent analysis, leveraging knowledge graphs and large language models. While it touches on information retrieval and retrieval-augmented generation, its primary focus is on intellectual property analysis and knowledge extraction, which aligns somewhat with your interests in information retrieval and NLP. However, the specific domain and application are not directly related to your core research themes.

#### Abstract
> Effectively managing intellectual property is a significant challenge.
Traditional methods for patent analysis depend on labor-intensive manual
searches and rigid keyword matching. These approaches are often inefficient and
struggle to reveal the complex relationships hidden within large patent
datasets, hindering strategic decision-making. To overcome these limitations,
we introduce KLIPA, a novel framework that leverages a knowledge graph and a
large language model (LLM) to significantly advance patent analysis. Our
approach integrates three key components: a structured knowledge graph to map
explicit relationships between patents, a retrieval-augmented generation(RAG)
system to uncover contextual connections, and an intelligent agent that
dynamically determines the optimal strategy for resolving user queries. We
validated KLIPA on a comprehensive, real-world patent database, where it
demonstrated substantial improvements in knowledge extraction, discovery of
novel connections, and overall operational efficiency. This combination of
technologies enhances retrieval accuracy, reduces reliance on domain experts,
and provides a scalable, automated solution for any organization managing
intellectual property, including technology corporations and legal firms,
allowing them to better navigate the complexities of strategic innovation and
competitive intelligence.

### 12. Avoiding Over-Personalization with Rule-Guided Knowledge Graph Adaptation for LLM Recommendations

- **LLM Score**: 6
- **Keyword Score**: 5
- **Authors**: Fernando Spadea, Oshani Seneviratne
- **URL**: <http://arxiv.org/abs/2509.07133v1>
- **Submitted**: 2025-09-08 18:33:36
- **Comment**: 5 pages, 2 figures, ISWC
- **Topic Keywords**: relevance, recommend, personalization
- **Reason**: The paper explores recommender systems, specifically addressing over-personalization using Knowledge Graphs, which is somewhat related to the user's interests in Information Retrieval and Search technologies. However, the focus on recommender systems and LLM-based recommendations is not the primary area of interest for the user, who has a stronger focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> We present a lightweight neuro-symbolic framework to mitigate
over-personalization in LLM-based recommender systems by adapting user-side
Knowledge Graphs (KGs) at inference time. Instead of retraining models or
relying on opaque heuristics, our method restructures a user's Personalized
Knowledge Graph (PKG) to suppress feature co-occurrence patterns that reinforce
Personalized Information Environments (PIEs), i.e., algorithmically induced
filter bubbles that constrain content diversity. These adapted PKGs are used to
construct structured prompts that steer the language model toward more diverse,
Out-PIE recommendations while preserving topical relevance. We introduce a
family of symbolic adaptation strategies, including soft reweighting, hard
inversion, and targeted removal of biased triples, and a client-side learning
algorithm that optimizes their application per user. Experiments on a recipe
recommendation benchmark show that personalized PKG adaptations significantly
increase content novelty while maintaining recommendation quality,
outperforming global adaptation and naive prompt-based methods.

### 13. ALLabel: Three-stage Active Learning for LLM-based Entity Recognition using Demonstration Retrieval

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Zihan Chen, Lei Shi, Weize Wu, Qiji Zhou, Yue Zhang
- **URL**: <http://arxiv.org/abs/2509.07512v1>
- **Submitted**: 2025-09-09 08:47:13
- **Topic Keywords**: ctr, retrieval, search
- **Reason**: The paper focuses on entity recognition using Large Language Models (LLMs), which is a related topic to NLP. However, it doesn't directly align with the user's primary focus on Information Retrieval, especially query understanding, ranking models, and user behavior modeling. The paper's emphasis on entity recognition and active learning strategies is somewhat relevant but not a central match to the user's research interests.

#### Abstract
> Many contemporary data-driven research efforts in the natural sciences, such
as chemistry and materials science, require large-scale, high-performance
entity recognition from scientific datasets. Large language models (LLMs) have
increasingly been adopted to solve the entity recognition task, with the same
trend being observed on all-spectrum NLP tasks. The prevailing entity
recognition LLMs rely on fine-tuned technology, yet the fine-tuning process
often incurs significant cost. To achieve a best performance-cost trade-off, we
propose ALLabel, a three-stage framework designed to select the most
informative and representative samples in preparing the demonstrations for LLM
modeling. The annotated examples are used to construct a ground-truth retrieval
corpus for LLM in-context learning. By sequentially employing three distinct
active learning strategies, ALLabel consistently outperforms all baselines
under the same annotation budget across three specialized domain datasets.
Experimental results also demonstrate that selectively annotating only 5\%-10\%
of the dataset with ALLabel can achieve performance comparable to the method
annotating the entire dataset. Further analyses and ablation studies verify the
effectiveness and generalizability of our proposal.

### 14. LongEmotion: Measuring Emotional Intelligence of Large Language Models in Long-Context Interaction

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Weichu Liu, Jing Xiong, Yuxuan Hu, Zixuan Li, Minghuan Tan, Ningning Mao, Chenyang Zhao, Zhongwei Wan, Chaofan Tao, Wendong Xu, Hui Shen, Chengming Li, Lingpeng Kong, Ngai Wong
- **URL**: <http://arxiv.org/abs/2509.07403v1>
- **Submitted**: 2025-09-09 05:32:45
- **Comment**: Technical Report
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on Emotional Intelligence in Large Language Models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on long-context interaction and emotional understanding is not directly aligned with the user's core research themes.

#### Abstract
> Large language models (LLMs) make significant progress in Emotional
Intelligence (EI) and long-context understanding. However, existing benchmarks
tend to overlook certain aspects of EI in long-context scenarios, especially
under realistic, practical settings where interactions are lengthy, diverse,
and often noisy. To move towards such realistic settings, we present
LongEmotion, a benchmark specifically designed for long-context EI tasks. It
covers a diverse set of tasks, including Emotion Classification, Emotion
Detection, Emotion QA, Emotion Conversation, Emotion Summary, and Emotion
Expression. On average, the input length for these tasks reaches 8,777 tokens,
with long-form generation required for Emotion Expression. To enhance
performance under realistic constraints, we incorporate Retrieval-Augmented
Generation (RAG) and Collaborative Emotional Modeling (CoEM), and compare them
with standard prompt-based methods. Unlike conventional approaches, our RAG
method leverages both the conversation context and the large language model
itself as retrieval sources, avoiding reliance on external knowledge bases. The
CoEM method further improves performance by decomposing the task into five
stages, integrating both retrieval augmentation and limited knowledge
injection. Experimental results show that both RAG and CoEM consistently
enhance EI-related performance across most long-context tasks, advancing LLMs
toward more practical and real-world EI applications. Furthermore, we conducted
a comparative case study experiment on the GPT series to demonstrate the
differences among various models in terms of EI. Code is available on GitHub at
https://github.com/LongEmotion/LongEmotion, and the project page can be found
at https://longemotion.github.io/.

### 15. Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Xin Lai, Junyi Li, Wei Li, Tao Liu, Tianjian Li, Hengshuang Zhao
- **URL**: <http://arxiv.org/abs/2509.07969v1>
- **Submitted**: 2025-09-09 17:54:21
- **Comment**: Code, datasets, models are available at
  https://github.com/Mini-o3/Mini-o3. Project Page: https://mini-o3.github.io/
- **Topic Keywords**: rag, search
- **Reason**: This paper is somewhat related to information retrieval and search technologies, but its focus on visual search and multimodal models is not directly aligned with the user's core research themes. While it involves deep semantic understanding and real-time relevance optimization, the context is specific to visual search, which is not a primary area of interest for the user.

#### Abstract
> Recent advances in large multimodal models have leveraged image-based tools
with reinforcement learning to tackle visual problems. However, existing
open-source approaches often exhibit monotonous reasoning patterns and allow
only a limited number of interaction turns, making them inadequate for
difficult tasks that require trial-and-error exploration. In this work, we
address this limitation by scaling up tool-based interactions and introduce
Mini-o3, a system that executes deep, multi-turn reasoning -- spanning tens of
steps -- and achieves state-of-the-art performance on challenging visual search
tasks. Our recipe for reproducing OpenAI o3-style behaviors comprises three key
components. First, we construct the Visual Probe Dataset, a collection of
thousands of challenging visual search problems designed for exploratory
reasoning. Second, we develop an iterative data collection pipeline to obtain
cold-start trajectories that exhibit diverse reasoning patterns, including
depth-first search, trial-and-error, and goal maintenance. Third, we propose an
over-turn masking strategy that prevents penalization of over-turn responses
(those that hit the maximum number of turns) during reinforcement learning,
thereby balancing training-time efficiency with test-time scalability. Despite
training with an upper bound of only six interaction turns, our model generates
trajectories that naturally scale to tens of turns at inference time, with
accuracy improving as the number of turns increases. Extensive experiments
demonstrate that Mini-o3 produces rich reasoning patterns and deep thinking
paths, effectively solving challenging visual search problems.

### 16. SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and Relation Extraction in NLP

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Decheng Duan, Yingyi Zhang, Jitong Peng, Chengzhi Zhang
- **URL**: <http://arxiv.org/abs/2509.07801v2>
- **Submitted**: 2025-09-09 14:41:40
- **Comment**: EMNLP 2025 Main
- **Topic Keywords**: rag, search
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and data mining, but it focuses on a specific task of entity and relation extraction in scientific literature, which is not directly aligned with your primary focus on information retrieval and query understanding.

#### Abstract
> Structured information extraction from scientific literature is crucial for
capturing core concepts and emerging trends in specialized fields. While
existing datasets aid model development, most focus on specific publication
sections due to domain complexity and the high cost of annotating scientific
texts. To address this limitation, we introduce SciNLP - a specialized
benchmark for full-text entity and relation extraction in the Natural Language
Processing (NLP) domain. The dataset comprises 60 manually annotated full-text
NLP publications, covering 7,072 entities and 1,826 relations. Compared to
existing research, SciNLP is the first dataset providing full-text annotations
of entities and their relationships in the NLP domain. To validate the
effectiveness of SciNLP, we conducted comparative experiments with similar
datasets and evaluated the performance of state-of-the-art supervised models on
this dataset. Results reveal varying extraction capabilities of existing models
across academic texts of different lengths. Cross-comparisons with existing
datasets show that SciNLP achieves significant performance improvements on
certain baseline models. Using models trained on SciNLP, we implemented
automatic construction of a fine-grained knowledge graph for the NLP domain.
Our KG has an average node degree of 3.2 per entity, indicating rich semantic
topological information that enhances downstream applications. The dataset is
publicly available at https://github.com/AKADDC/SciNLP.

### 17. FLeW: Facet-Level and Adaptive Weighted Representation Learning of Scientific Documents

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Zheng Dou, Deqing Wang, Fuzhen Zhuang, Jian Ren, Yanlin Hu
- **URL**: <http://arxiv.org/abs/2509.07531v1>
- **Submitted**: 2025-09-09 09:08:44
- **Comment**: Accepted by DASFAA2025
- **Topic Keywords**: rag, search
- **Reason**: The paper discusses a novel method for scientific document representation learning, which is somewhat related to information retrieval and NLP. However, it focuses on representation learning and does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. While it may have some indirect applications in IR, it is not a central match for the user's research themes.

#### Abstract
> Scientific document representation learning provides powerful embeddings for
various tasks, while current methods face challenges across three approaches.
1) Contrastive training with citation-structural signals underutilizes citation
information and still generates single-vector representations. 2) Fine-grained
representation learning, which generates multiple vectors at the sentence or
aspect level, requires costly integration and lacks domain generalization. 3)
Task-aware learning depends on manually predefined task categorization,
overlooking nuanced task distinctions and requiring extra training data for
task-specific modules. To address these problems, we propose a new method that
unifies the three approaches for better representations, namely FLeW.
Specifically, we introduce a novel triplet sampling method that leverages
citation intent and frequency to enhance citation-structural signals for
training. Citation intents (background, method, result), aligned with the
general structure of scientific writing, facilitate a domain-generalized facet
partition for fine-grained representation learning. Then, we adopt a simple
weight search to adaptively integrate three facet-level embeddings into a
task-specific document embedding without task-aware fine-tuning. Experiments
show the applicability and robustness of FLeW across multiple scientific tasks
and fields, compared to prior models.

### 18. SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Lukas Haas, Gal Yona, Giovanni D'Antonio, Sasha Goldshtein, Dipanjan Das
- **URL**: <http://arxiv.org/abs/2509.07968v1>
- **Submitted**: 2025-09-09 17:53:58
- **Topic Keywords**: search, www
- **Reason**: This paper introduces a benchmark for evaluating Large Language Model factuality, which is somewhat related to information retrieval and search technologies, particularly in the context of query understanding and ranking models. However, the focus on factuality and hallucinations in LLMs is not directly aligned with the user's primary research interests in IR and search technologies. The connection to NLP is relevant, but the paper's scope is more narrow than the user's broader interests.

#### Abstract
> We introduce SimpleQA Verified, a 1,000-prompt benchmark for evaluating Large
Language Model (LLM) short-form factuality based on OpenAI's SimpleQA. It
addresses critical limitations in OpenAI's benchmark, including noisy and
incorrect labels, topical biases, and question redundancy. SimpleQA Verified
was created through a rigorous multi-stage filtering process involving
de-duplication, topic balancing, and source reconciliation to produce a more
reliable and challenging evaluation set, alongside improvements in the
autorater prompt. On this new benchmark, Gemini 2.5 Pro achieves a
state-of-the-art F1-score of 55.6, outperforming other frontier models,
including GPT-5. This work provides the research community with a
higher-fidelity tool to track genuine progress in parametric model factuality
and to mitigate hallucinations. The benchmark dataset, evaluation code, and
leaderboard are available at:
https://www.kaggle.com/benchmarks/deepmind/simpleqa-verified.

### 19. GENUINE: Graph Enhanced Multi-level Uncertainty Estimation for Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Tuo Wang, Adithya Kulkarni, Tyler Cody, Peter A. Beling, Yujun Yan, Dawei Zhou
- **URL**: <http://arxiv.org/abs/2509.07925v1>
- **Submitted**: 2025-09-09 17:07:44
- **Comment**: Accepted by EMNLP 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on uncertainty estimation for Large Language Models, which is related to my interests in NLP. However, it doesn't directly address query understanding, ranking models, or user behavior modeling, which are core areas of my research. While it explores a novel approach to uncertainty modeling, its relevance to my primary research themes is limited.

#### Abstract
> Uncertainty estimation is essential for enhancing the reliability of Large
Language Models (LLMs), particularly in high-stakes applications. Existing
methods often overlook semantic dependencies, relying on token-level
probability measures that fail to capture structural relationships within the
generated text. We propose GENUINE: Graph ENhanced mUlti-level uncertaINty
Estimation for Large Language Models, a structure-aware framework that
leverages dependency parse trees and hierarchical graph pooling to refine
uncertainty quantification. By incorporating supervised learning, GENUINE
effectively models semantic and structural relationships, improving confidence
assessments. Extensive experiments across NLP tasks show that GENUINE achieves
up to 29% higher AUROC than semantic entropy-based approaches and reduces
calibration errors by over 15%, demonstrating the effectiveness of graph-based
uncertainty modeling. The code is available at
https://github.com/ODYSSEYWT/GUQ.

### 20. M-BRe: Discovering Training Samples for Relation Extraction from Unlabeled Texts with Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Zexuan Li, Hongliang Dai, Piji Li
- **URL**: <http://arxiv.org/abs/2509.07730v2>
- **Submitted**: 2025-09-09 13:32:29
- **Comment**: Accepted by EMNLP2025 Main Conference
- **Topic Keywords**: rag
- **Reason**: The paper focuses on Relation Extraction, a task related to Information Retrieval, but its primary goal is to improve the efficiency of training data extraction for RE models. While it leverages large language models, which are relevant to NLP, the specific application and challenges addressed are not directly aligned with the user's core research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> For Relation Extraction (RE), the manual annotation of training data may be
prohibitively expensive, since the sentences that contain the target relations
in texts can be very scarce and difficult to find. It is therefore beneficial
to develop an efficient method that can automatically extract training
instances from unlabeled texts for training RE models. Recently, large language
models (LLMs) have been adopted in various natural language processing tasks,
with RE also benefiting from their advances. However, when leveraging LLMs for
RE with predefined relation categories, two key challenges arise. First, in a
multi-class classification setting, LLMs often struggle to comprehensively
capture the semantics of every relation, leading to suboptimal results. Second,
although employing binary classification for each relation individually can
mitigate this issue, it introduces significant computational overhead,
resulting in impractical time complexity for real-world applications.
Therefore, this paper proposes a framework called M-BRe to extract training
instances from unlabeled texts for RE. It utilizes three modules to combine the
advantages of both of the above classification approaches: Relation Grouping,
Relation Extraction, and Label Decision. Extensive experiments confirm its
superior capability in discovering high-quality training samples from unlabeled
texts for RE.

### 21. MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Yao Liang, Dongcheng Zhao, Feifei Zhao, Guobin Shen, Yuwei Wang, Dongqi Liang, Yi Zeng
- **URL**: <http://arxiv.org/abs/2509.08022v1>
- **Submitted**: 2025-09-09 09:25:08
- **Topic Keywords**: rank, search
- **Reason**: The paper MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, particularly in the context of large language models and their alignment with human values. However, the focus on value alignment and cultural diversity is not directly aligned with the user's primary research themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> The alignment of large language models (LLMs) with human values is critical
for their safe and effective deployment across diverse user populations.
However, existing benchmarks often neglect cultural and demographic diversity,
leading to limited understanding of how value alignment generalizes globally.
In this work, we introduce MVPBench, a novel benchmark that systematically
evaluates LLMs' alignment with multi-dimensional human value preferences across
75 countries. MVPBench contains 24,020 high-quality instances annotated with
fine-grained value labels, personalized questions, and rich demographic
metadata, making it the most comprehensive resource of its kind to date. Using
MVPBench, we conduct an in-depth analysis of several state-of-the-art LLMs,
revealing substantial disparities in alignment performance across geographic
and demographic lines. We further demonstrate that lightweight fine-tuning
methods, such as Low-Rank Adaptation (LoRA) and Direct Preference Optimization
(DPO), can significantly enhance value alignment in both in-domain and
out-of-domain settings. Our findings underscore the necessity for
population-aware alignment evaluation and provide actionable insights for
building culturally adaptive and value-sensitive LLMs. MVPBench serves as a
practical foundation for future research on global alignment, personalized
value modeling, and equitable AI development.

### 22. Datasets for Navigating Sensitive Topics in Recommendation Systems

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Amelia Kovacs, Jerry Chee, Kimia Kazemian, Sarah Dean
- **URL**: <http://arxiv.org/abs/2509.07269v1>
- **Submitted**: 2025-09-08 22:58:17
- **Comment**: Companion Proceedings of the ACM on Web Conference 2025, 2025
- **Topic Keywords**: recommend, search
- **Reason**: This paper is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, but it focuses on recommender systems and sensitive topic navigation, which is not the user's primary focus. The paper's emphasis on dataset creation and sensitivity labels is also somewhat tangential to the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Personalized AI systems, from recommendation systems to chatbots, are a
prevalent method for distributing content to users based on their learned
preferences. However, there is growing concern about the adverse effects of
these systems, including their potential tendency to expose users to sensitive
or harmful material, negatively impacting overall well-being. To address this
concern quantitatively, it is necessary to create datasets with relevant
sensitivity labels for content, enabling researchers to evaluate personalized
systems beyond mere engagement metrics. To this end, we introduce two novel
datasets that include a taxonomy of sensitivity labels alongside user-content
ratings: one that integrates MovieLens rating data with content warnings from
the Does the Dog Die? community ratings website, and another that combines
fan-fiction interaction data and user-generated warnings from Archive of Our
Own.

### 23. Avoiding Knowledge Edit Skipping in Multi-hop Question Answering with Guided Decomposition

- **LLM Score**: 3
- **Keyword Score**: 4
- **Authors**: Yi Liu, Xiangrong Zhu, Xiangyu Liu, Wei Wei, Wei Hu
- **URL**: <http://arxiv.org/abs/2509.07555v1>
- **Submitted**: 2025-09-09 09:49:23
- **Comment**: Accepted in EMNLP Findings 2025
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on knowledge editing in large language models, which is somewhat related to information retrieval and query understanding. However, the specific context of multi-hop question answering and knowledge editing in language models is not directly aligned with the user's core research themes.

#### Abstract
> In a rapidly evolving world where information updates swiftly, knowledge in
large language models (LLMs) becomes outdated quickly. Retraining LLMs is not a
cost-effective option, making knowledge editing (KE) without modifying
parameters particularly necessary. We find that although existing
retrieval-augmented generation (RAG)-based KE methods excel at editing simple
knowledge, they struggle with KE in multi-hop question answering due to the
issue of "edit skipping", which refers to skipping the relevant edited fact in
inference. In addition to the diversity of natural language expressions of
knowledge, edit skipping also arises from the mismatch between the granularity
of LLMs in problem-solving and the facts in the edited memory. To address this
issue, we propose a novel Iterative Retrieval-Augmented Knowledge Editing
method with guided decomposition (IRAKE) through the guidance from single
edited facts and entire edited cases. Experimental results demonstrate that
IRAKE mitigates the failure of editing caused by edit skipping and outperforms
state-of-the-art methods for KE in multi-hop question answering.

### 24. From Detection to Mitigation: Addressing Gender Bias in Chinese Texts via Efficient Tuning and Voting-Based Rebalancing

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Chengyan Wu, Yiqiang Cai, Yufei Cheng, Yun Xue
- **URL**: <http://arxiv.org/abs/2509.07889v1>
- **Submitted**: 2025-09-09 16:12:11
- **Comment**: NLPCC 2025
- **Topic Keywords**: ranking, rag, rank
- **Reason**: This paper focuses on addressing gender bias in Chinese texts, which is a task related to Natural Language Processing (NLP), but it does not align with the user's primary research interests in Information Retrieval (IR), query understanding, ranking models, and user behavior modeling. Although the paper involves fine-tuning large language models, it is not directly applicable to the user's areas of expertise.

#### Abstract
> This paper presents our team's solution to Shared Task 7 of NLPCC-2025, which
focuses on sentence-level gender bias detection and mitigation in Chinese. The
task aims to promote fairness and controllability in natural language
generation by automatically detecting, classifying, and mitigating gender bias.
To address this challenge, we adopt a fine-tuning approach based on large
language models (LLMs), efficiently adapt to the bias detection task via
Low-Rank Adaptation (LoRA). In terms of data processing, we construct a more
balanced training set to alleviate class imbalance and introduce heterogeneous
samples from multiple sources to enhance model generalization. For the
detection and classification sub-tasks, we employ a majority voting strategy
that integrates outputs from multiple expert models to boost performance.
Additionally, to improve bias generation detection and mitigation, we design a
multi-temperature sampling mechanism to capture potential variations in bias
expression styles. Experimental results demonstrate the effectiveness of our
approach in bias detection, classification, and mitigation. Our method
ultimately achieves an average score of 47.90%, ranking fourth in the shared
task.

### 25. VeriOS: Query-Driven Proactive Human-Agent-GUI Interaction for Trustworthy OS Agents

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Zheng Wu, Heyuan Huang, Xingyu Lou, Xiangmou Qu, Pengzhou Cheng, Zongru Wu, Weiwen Liu, Weinan Zhang, Jun Wang, Zhaoxiang Wang, Zhuosheng Zhang
- **URL**: <http://arxiv.org/abs/2509.07553v1>
- **Submitted**: 2025-09-09 09:46:01
- **Topic Keywords**: query, rag
- **Reason**: This paper focuses on operating system agents and their interaction with humans, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves query-driven interaction, the context is more about human-agent interaction rather than query understanding or ranking models.

#### Abstract
> With the rapid progress of multimodal large language models, operating system
(OS) agents become increasingly capable of automating tasks through on-device
graphical user interfaces (GUIs). However, most existing OS agents are designed
for idealized settings, whereas real-world environments often present
untrustworthy conditions. To mitigate risks of over-execution in such
scenarios, we propose a query-driven human-agent-GUI interaction framework that
enables OS agents to decide when to query humans for more reliable task
completion. Built upon this framework, we introduce VeriOS-Agent, a trustworthy
OS agent trained with a two-stage learning paradigm that falicitate the
decoupling and utilization of meta-knowledge. Concretely, VeriOS-Agent
autonomously executes actions in normal conditions while proactively querying
humans in untrustworthy scenarios. Experiments show that VeriOS-Agent improves
the average step-wise success rate by 20.64\% in untrustworthy scenarios over
the state-of-the-art, without compromising normal performance. Analysis
highlights VeriOS-Agent's rationality, generalizability, and scalability. The
codes, datasets and models are available at
https://github.com/Wuzheng02/VeriOS.

### 26. HALT-RAG: A Task-Adaptable Framework for Hallucination Detection with Calibrated NLI Ensembles and Abstention

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Saumya Goswami, Siddharth Kurra
- **URL**: <http://arxiv.org/abs/2509.07475v1>
- **Submitted**: 2025-09-09 07:58:46
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper focuses on detecting hallucinations in generative language models, which is a topic related to NLP, but it does not directly align with your core research interests in Information Retrieval, Search technologies, and query understanding.

#### Abstract
> Detecting content that contradicts or is unsupported by a given source text
is a critical challenge for the safe deployment of generative language models.
We introduce HALT-RAG, a post-hoc verification system designed to identify
hallucinations in the outputs of Retrieval-Augmented Generation (RAG)
pipelines. Our flexible and task-adaptable framework uses a universal feature
set derived from an ensemble of two frozen, off-the-shelf Natural Language
Inference (NLI) models and lightweight lexical signals. These features are used
to train a simple, calibrated, and task-adapted meta-classifier. Using a
rigorous 5-fold out-of-fold (OOF) training protocol to prevent data leakage and
produce unbiased estimates, we evaluate our system on the HaluEval benchmark.
By pairing our universal feature set with a lightweight, task-adapted
classifier and a precision-constrained decision policy, HALT-RAG achieves
strong OOF F1-scores of 0.7756, 0.9786, and 0.7391 on the summarization, QA,
and dialogue tasks, respectively. The system's well-calibrated probabilities
enable a practical abstention mechanism, providing a reliable tool for
balancing model performance with safety requirements.

### 27. AIxcellent Vibes at GermEval 2025 Shared Task on Candy Speech Detection: Improving Model Performance by Span-Level Training

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Christian Rene Thelen, Patrick Gustav Blaneck, Tobias Bornheim, Niklas Grieger, Stephan Bialonski
- **URL**: <http://arxiv.org/abs/2509.07459v1>
- **Submitted**: 2025-09-09 07:29:14
- **Comment**: 6 pages, 1 figure, 2 tables
- **Topic Keywords**: ranking, rank
- **Reason**: This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves NLP and model performance, its focus on candy speech detection in social media is not aligned with the user's interests in query understanding, ranking models, or real-time relevance optimization.

#### Abstract
> Positive, supportive online communication in social media (candy speech) has
the potential to foster civility, yet automated detection of such language
remains underexplored, limiting systematic analysis of its impact. We
investigate how candy speech can be reliably detected in a 46k-comment German
YouTube corpus by monolingual and multilingual language models, including
GBERT, Qwen3 Embedding, and XLM-RoBERTa. We find that a multilingual
XLM-RoBERTa-Large model trained to detect candy speech at the span level
outperforms other approaches, ranking first in both binary positive F1: 0.8906)
and categorized span-based detection (strict F1: 0.6307) subtasks at the
GermEval 2025 Shared Task on Candy Speech Detection. We speculate that
span-based training, multilingual capabilities, and emoji-aware tokenizers
improved detection performance. Our results demonstrate the effectiveness of
multilingual models in identifying positive, supportive language.

### 28. Causal Attention with Lookahead Keys

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Zhuoqing Song, Peng Sun, Huizhuo Yuan, Quanquan Gu
- **URL**: <http://arxiv.org/abs/2509.07301v1>
- **Submitted**: 2025-09-09 00:15:23
- **Topic Keywords**: query
- **Reason**: This paper focuses on attention mechanisms in language modeling, which is related to Natural Language Processing, but does not directly address Information Retrieval, query understanding, ranking models, or user behavior modeling, which are core areas of interest.

#### Abstract
> In standard causal attention, each token's query, key, and value (QKV) are
static and encode only preceding context. We introduce CAuSal aTtention with
Lookahead kEys (CASTLE), an attention mechanism that continually updates each
token's keys as the context unfolds. We term these updated keys lookahead keys
because they belong to earlier positions yet integrate information from tokens
that appear later relative to those positions, while strictly preserving the
autoregressive property. Although the mechanism appears sequential, we derive a
mathematical equivalence that avoids explicitly materializing lookahead keys at
each position and enables efficient parallel training. On language modeling
benchmarks, CASTLE consistently outperforms standard causal attention across
model scales, reducing validation perplexity and improving performance on a
range of downstream tasks.

### 29. Neurocognitive Modeling for Text Generation: Deep Learning Architecture for EEG Data

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Khushiyant
- **URL**: <http://arxiv.org/abs/2509.07202v1>
- **Submitted**: 2025-09-08 20:32:41
- **Comment**: 15 pages, 10 figures, 5 tables
- **Topic Keywords**: ctr, search
- **Reason**: This paper focuses on text generation using EEG data and deep learning architectures, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves deep learning and language models, the context and application are distinct from the user's areas of focus.

#### Abstract
> Text generating capabilities have undergone a substantial transformation with
the introduction of large language models (LLMs). Electroencephalography
(EEG)-based text production is still difficult, though, because it requires a
lot of data and processing power. This paper introduces a new method that
combines the use of the Gemma 2B LLM with a classifier-LLM architecture to
incorporate a Recurrent Neural Network (RNN) encoder. Our approach drastically
lowers the amount of data and compute power needed while achieving performance
close to that of cutting-edge methods. Notably, compared to current
methodologies, our methodology delivers an overall performance improvement of
10%. The suggested architecture demonstrates the possibility of effective
transfer learning for EEG-based text production, remaining strong and
functional even in the face of data limits. This work highlights the potential
of integrating LLMs with EEG decoding to improve assistive technologies and
improve independence and communication for those with severe motor limitations.
Our method pushes the limits of present capabilities and opens new paths for
research and application in brain-computer interfaces by efficiently using the
strengths of pre-trained language models. This makes EEG-based text production
more accessible and efficient.

### 30. Towards EnergyGPT: A Large Language Model Specialized for the Energy Sector

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Amal Chebbi, Babajide Kolade
- **URL**: <http://arxiv.org/abs/2509.07177v1>
- **Submitted**: 2025-09-08 19:48:52
- **Topic Keywords**: relevance
- **Reason**: This paper focuses on developing a domain-specialized language model for the energy sector, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves language understanding and generation tasks, the context is highly specialized and does not align with the user's interests in e-commerce, query understanding, ranking models, or user behavior modeling.

#### Abstract
> Large Language Models have demonstrated impressive capabilities across
various domains. However, their general-purpose nature often limits their
effectiveness in specialized fields such as energy, where deep technical
expertise and precise domain knowledge are essential. In this paper, we
introduce EnergyGPT, a domain-specialized language model tailored for the
energy sector, developed by fine-tuning LLaMA 3.1-8B model using Supervised
Fine-Tuning on a high-quality, curated corpus of energy-related texts. We
present a complete development pipeline, including data collection and
curation, model fine-tuning, benchmark design and LLM-judge choice, evaluation
and deployment. Through this work, we demonstrate that our training strategy
enables improvements in domain relevance and performance without the need for
large-scale infrastructure. By evaluating the performance of the model using
domain-specific question-answering benchmarks, our results demonstrate that
EnergyGPT outperforms the base model in most of the energy-related language
understanding and generation tasks.

### 31. That's So FETCH: Fashioning Ensemble Techniques for LLM Classification in Civil Legal Intake and Referral

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Quinten Steenhuis
- **URL**: <http://arxiv.org/abs/2509.07170v2>
- **Submitted**: 2025-09-08 19:34:57
- **Comment**: Submission to JURIX 2025
- **Topic Keywords**: queries
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves LLM classification, the context is specific to legal issue classification and referral, which is not a central match to your areas of focus.

#### Abstract
> Each year millions of people seek help for their legal problems by calling a
legal aid program hotline, walking into a legal aid office, or using a lawyer
referral service. The first step to match them to the right help is to identify
the legal problem the applicant is experiencing. Misdirection has consequences.
Applicants may miss a deadline, experience physical abuse, lose housing or lose
custody of children while waiting to connect to the right legal help. We
introduce and evaluate the FETCH classifier for legal issue classification and
describe two methods for improving accuracy: a hybrid LLM/ML ensemble
classification method, and the automatic generation of follow-up questions to
enrich the initial problem narrative. We employ a novel data set of 419
real-world queries to a nonprofit lawyer referral service. Ultimately, we show
classification accuracy (hits@2) of 97.37\% using a mix of inexpensive models,
exceeding the performance of the current state-of-the-art GPT-5 model. Our
approach shows promise in significantly reducing the cost of guiding users of
the legal system to the right resource for their problem while achieving high
accuracy.

### 32. Neuro-Symbolic Frameworks: Conceptual Characterization and Empirical Comparative Analysis

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Sania Sinha, Tanawan Premsri, Danial Kamali, Parisa Kordjamshidi
- **URL**: <http://arxiv.org/abs/2509.07122v1>
- **Submitted**: 2025-09-08 18:17:33
- **Topic Keywords**: rag, search
- **Reason**: This paper is primarily focused on neurosymbolic frameworks, which is a topic in Natural Language Processing (NLP). While it touches on the intersection of symbolic and neural representations, it does not directly relate to information retrieval, search technologies, or query understanding, which are the core areas of your research interests.

#### Abstract
> Neurosymbolic (NeSy) frameworks combine neural representations and learning
with symbolic representations and reasoning. Combining the reasoning
capacities, explainability, and interpretability of symbolic processing with
the flexibility and power of neural computing allows us to solve complex
problems with more reliability while being data-efficient. However, this
recently growing topic poses a challenge to developers with its learning curve,
lack of user-friendly tools, libraries, and unifying frameworks. In this paper,
we characterize the technical facets of existing NeSy frameworks, such as the
symbolic representation language, integration with neural models, and the
underlying algorithms. A majority of the NeSy research focuses on algorithms
instead of providing generic frameworks for declarative problem specification
to leverage problem solving. To highlight the key aspects of Neurosymbolic
modeling, we showcase three generic NeSy frameworks - \textit{DeepProbLog},
\textit{Scallop}, and \textit{DomiKnowS}. We identify the challenges within
each facet that lay the foundation for identifying the expressivity of each
framework in solving a variety of problems. Building on this foundation, we aim
to spark transformative action and encourage the community to rethink this
problem in novel ways.

### 33. Instruction Agent: Enhancing Agent with Expert Demonstration

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yinheng Li, Hailey Hultquist, Justin Wagle, Kazuhito Koishida
- **URL**: <http://arxiv.org/abs/2509.07098v1>
- **Submitted**: 2025-09-08 18:00:12
- **Topic Keywords**: rag, rank
- **Reason**: This paper focuses on Graphical User Interface (GUI) agents and their ability to complete complex tasks with expert demonstrations. While it touches on automation and task completion, it does not align with the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Graphical user interface (GUI) agents have advanced rapidly but still
struggle with complex tasks involving novel UI elements, long-horizon actions,
and personalized trajectories. In this work, we introduce Instruction Agent, a
GUI agent that leverages expert demonstrations to solve such tasks, enabling
completion of otherwise difficult workflows. Given a single demonstration, the
agent extracts step-by-step instructions and executes them by strictly
following the trajectory intended by the user, which avoids making mistakes
during execution. The agent leverages the verifier and backtracker modules
further to improve robustness. Both modules are critical to understand the
current outcome from each action and handle unexpected interruptions(such as
pop-up windows) during execution. Our experiments show that Instruction Agent
achieves a 60% success rate on a set of tasks in OSWorld that all top-ranked
agents failed to complete. The Instruction Agent offers a practical and
extensible framework, bridging the gap between current GUI agents and reliable
real-world GUI task automation.

### 34. Parallel-R1: Towards Parallel Thinking via Reinforcement Learning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Tong Zheng, Hongming Zhang, Wenhao Yu, Xiaoyang Wang, Xinyu Yang, Runpeng Dai, Rui Liu, Huiwen Bao, Chengsong Huang, Heng Huang, Dong Yu
- **URL**: <http://arxiv.org/abs/2509.07980v1>
- **Submitted**: 2025-09-09 17:59:35
- **Comment**: Project website: https://zhengkid.github.io/Parallel_R1.github.io/
- **Topic Keywords**: rag
- **Reason**: This paper focuses on enhancing the reasoning capabilities of large language models through reinforcement learning, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves deep semantic understanding, the context is different from the user's primary research interests.

#### Abstract
> Parallel thinking has emerged as a novel approach for enhancing the reasoning
capabilities of large language models (LLMs) by exploring multiple reasoning
paths concurrently. However, activating such capabilities through training
remains challenging, as existing methods predominantly rely on supervised
fine-tuning (SFT) over synthetic data, which encourages teacher-forced
imitation rather than exploration and generalization. Different from them, we
propose \textbf{Parallel-R1}, the first reinforcement learning (RL) framework
that enables parallel thinking behaviors for complex real-world reasoning
tasks. Our framework employs a progressive curriculum that explicitly addresses
the cold-start problem in training parallel thinking with RL. We first use SFT
on prompt-generated trajectories from easier tasks to instill the parallel
thinking ability, then transition to RL to explore and generalize this skill on
harder problems. Experiments on various math benchmarks, including MATH, AMC23,
and AIME, show that Parallel-R1 successfully instills parallel thinking,
leading to 8.4% accuracy improvements over the sequential thinking model
trained directly on challenging tasks with RL. Further analysis reveals a clear
shift in the model's thinking behavior: at an early stage, it uses parallel
thinking as an exploration strategy, while in a later stage, it uses the same
capability for multi-perspective verification. Most significantly, we validate
parallel thinking as a \textbf{mid-training exploration scaffold}, where this
temporary exploratory phase unlocks a higher performance ceiling after RL,
yielding a 42.9% improvement over the baseline on AIME25. Our model, data, and
code will be open-source at https://github.com/zhengkid/Parallel-R1.

### 35. GLEAM: Learning to Match and Explain in Cross-View Geo-Localization

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xudong Lu, Zhi Zheng, Yi Wan, Yongxiang Yao, Annan Wang, Renrui Zhang, Panwang Xia, Qiong Wu, Qingyun Li, Weifeng Lin, Xiangyu Zhao, Xue Yang, Hongsheng Li
- **URL**: <http://arxiv.org/abs/2509.07450v1>
- **Submitted**: 2025-09-09 07:14:31
- **Comment**: 18 pages
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Cross-View Geo-Localization, which is not directly related to Information Retrieval or Search technologies. While it involves multimodal large language models, the primary application is geo-localization, and the paper's emphasis on explainability and interpretability does not align with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Cross-View Geo-Localization (CVGL) focuses on identifying correspondences
between images captured from distinct perspectives of the same geographical
location. However, existing CVGL approaches are typically restricted to a
single view or modality, and their direct visual matching strategy lacks
interpretability: they merely predict whether two images correspond, without
explaining the rationale behind the match. In this paper, we present GLEAM-C, a
foundational CVGL model that unifies multiple views and modalities-including
UAV imagery, street maps, panoramic views, and ground photographs-by aligning
them exclusively with satellite imagery. Our framework enhances training
efficiency through optimized implementation while achieving accuracy comparable
to prior modality-specific CVGL models through a two-phase training strategy.
Moreover, to address the lack of interpretability in traditional CVGL methods,
we leverage the reasoning capabilities of multimodal large language models
(MLLMs) to propose a new task, GLEAM-X, which combines cross-view
correspondence prediction with explainable reasoning. To support this task, we
construct a bilingual benchmark using GPT-4o and Doubao-1.5-Thinking-Vision-Pro
to generate training and testing data. The test set is further refined through
detailed human revision, enabling systematic evaluation of explainable
cross-view reasoning and advancing transparency and scalability in
geo-localization. Together, GLEAM-C and GLEAM-X form a comprehensive CVGL
pipeline that integrates multi-modal, multi-view alignment with interpretable
correspondence analysis, unifying accurate cross-view matching with explainable
reasoning and advancing Geo-Localization by enabling models to better Explain
And Match. Code and datasets used in this work will be made publicly accessible
at https://github.com/Lucky-Lance/GLEAM.

### 36. Language Self-Play For Data-Free Training

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jakub Grudzien Kuba, Mengting Gu, Qi Ma, Yuandong Tian, Vijai Mohan
- **URL**: <http://arxiv.org/abs/2509.07414v1>
- **Submitted**: 2025-09-09 05:51:34
- **Topic Keywords**: rag
- **Reason**: This paper focuses on language models and data-free training, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context is more on model training and improvement rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> Large language models (LLMs) have advanced rapidly in recent years, driven by
scale, abundant high-quality training data, and reinforcement learning. Yet
this progress faces a fundamental bottleneck: the need for ever more data from
which models can continue to learn. In this work, we propose a reinforcement
learning approach that removes this dependency by enabling models to improve
without additional data. Our method leverages a game-theoretic framework of
self-play, where a model's capabilities are cast as performance in a
competitive game and stronger policies emerge by having the model play against
itself - a process we call Language Self-Play (LSP). Experiments with
Llama-3.2-3B-Instruct on instruction-following benchmarks show that pretrained
models can not only enhance their performance on challenging tasks through
self-play alone, but can also do so more effectively than data-driven
baselines.

### 37. The Role of Exploration Modules in Small Language Models for Knowledge Graph Question Answering

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yi-Jie Cheng, Oscar Chew, Yun-Nung Chen
- **URL**: <http://arxiv.org/abs/2509.07399v1>
- **Submitted**: 2025-09-09 05:26:29
- **Comment**: Extended from ACL 2025 SRW
- **Topic Keywords**: rag
- **Reason**: This paper focuses on knowledge graph question answering and the integration of knowledge graphs with language models, which is not directly related to the user's core research themes in Information Retrieval and Search technologies. While it touches on the idea of improving model performance, it does not address query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's interests.

#### Abstract
> Integrating knowledge graphs (KGs) into the reasoning processes of large
language models (LLMs) has emerged as a promising approach to mitigate
hallucination. However, existing work in this area often relies on proprietary
or extremely large models, limiting accessibility and scalability. In this
study, we investigate the capabilities of existing integration methods for
small language models (SLMs) in KG-based question answering and observe that
their performance is often constrained by their limited ability to traverse and
reason over knowledge graphs. To address this limitation, we propose leveraging
simple and efficient exploration modules to handle knowledge graph traversal in
place of the language model itself. Experiment results demonstrate that these
lightweight modules effectively improve the performance of small language
models on knowledge graph question answering tasks. Source code:
https://github.com/yijie-cheng/SLM-ToG/.

### 38. Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sankalp Tattwadarshi Swain, Anshika Krishnatray, Dhruv Kumar, Jagat Sesh Challa
- **URL**: <http://arxiv.org/abs/2509.07389v1>
- **Submitted**: 2025-09-09 05:09:27
- **Comment**: Under review
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves large language models, the focus is on linguistic acquisition and language learning, which is not a central theme in your research.

#### Abstract
> Existing evaluation studies on linguistic competence of large language models
(LLM agents) have focused primarily on vocabulary learning, morphological rule
induction, syntactic generalization, pragmatic inference, and cross-linguistic
transfer. However, none assess whether LLM agents can acquire a language
through pattern recognition and interactive feedback, a central feature of
human language acquisition. We propose a novel experimental framework in which
an LLM agent is evaluated on its ability to acquire and use a newly constructed
language (Tinkatongue) in conversation with a bot that understands only
Tinkatongue. Our findings show that LLM agents fail to establish a conversation
within 100 responses, yet they adopt distinct strategies that mirror human
approaches to language learning. The results suggest a new direction for
evaluation benchmarks and open pathways to model designs that learn more
effectively from interactive feedback.

### 39. Rule-Based Moral Principles for Explaining Uncertainty in Natural Language Generation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zahra Atf, Peter R Lewis
- **URL**: <http://arxiv.org/abs/2509.07190v1>
- **Submitted**: 2025-09-08 20:14:03
- **Comment**: This paper was accepted for presentation at the 35th IEEE
  International Conference on Collaborative Advances in Software and Computing.
  Conference website:https://conf.researchr.org/home/cascon-2025
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Natural Language Generation and uncertainty explanation, which, while related to NLP, is not directly aligned with your core research interests in Information Retrieval, Search technologies, and query understanding.

#### Abstract
> Large language models (LLMs) are increasingly used in high-stakes settings,
where explaining uncertainty is both technical and ethical. Probabilistic
methods are often opaque and misaligned with expectations of transparency. We
propose a framework based on rule-based moral principles for handling
uncertainty in LLM-generated text. Using insights from moral psychology and
virtue ethics, we define rules such as precaution, deference, and
responsibility to guide responses under epistemic or aleatoric uncertainty.
These rules are encoded in a lightweight Prolog engine, where uncertainty
levels (low, medium, high) trigger aligned system actions with plain-language
rationales. Scenario-based simulations benchmark rule coverage, fairness, and
trust calibration. Use cases in clinical and legal domains illustrate how moral
reasoning can improve trust and interpretability. Our approach offers a
transparent, lightweight alternative to probabilistic models for socially
responsible natural language generation.

### 40. DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zonghai Yao, Michael Sun, Won Seok Jang, Sunjae Kwon, Soie Kwon, Hong Yu
- **URL**: <http://arxiv.org/abs/2509.07188v2>
- **Submitted**: 2025-09-08 20:07:30
- **Comment**: Equal contribution for the first two authors. To appear in the
  proceedings of the Main Conference on Empirical Methods in Natural Language
  Processing (EMNLP) 2025
- **Topic Keywords**: rag
- **Reason**: This paper appears to be primarily focused on evaluating large language models in the context of educational doctor-patient communication at discharge. While it touches on aspects of language understanding and generation, it does not directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Discharge communication is a critical yet underexplored component of patient
care, where the goal shifts from diagnosis to education. While recent large
language model (LLM) benchmarks emphasize in-visit diagnostic reasoning, they
fail to evaluate models' ability to support patients after the visit. We
introduce DischargeSim, a novel benchmark that evaluates LLMs on their ability
to act as personalized discharge educators. DischargeSim simulates post-visit,
multi-turn conversations between LLM-driven DoctorAgents and PatientAgents with
diverse psychosocial profiles (e.g., health literacy, education, emotion).
Interactions are structured across six clinically grounded discharge topics and
assessed along three axes: (1) dialogue quality via automatic and LLM-as-judge
evaluation, (2) personalized document generation including free-text summaries
and structured AHRQ checklists, and (3) patient comprehension through a
downstream multiple-choice exam. Experiments across 18 LLMs reveal significant
gaps in discharge education capability, with performance varying widely across
patient profiles. Notably, model size does not always yield better education
outcomes, highlighting trade-offs in strategy use and content prioritization.
DischargeSim offers a first step toward benchmarking LLMs in post-visit
clinical education and promoting equitable, personalized patient support.

### 41. Are Humans as Brittle as Large Language Models?

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jiahui Li, Sean Papay, Roman Klinger
- **URL**: <http://arxiv.org/abs/2509.07869v1>
- **Submitted**: 2025-09-09 15:56:51
- **Topic Keywords**: search
- **Reason**: This paper explores the brittleness of large language models and human annotators in response to prompt modifications, which is a topic in NLP. However, it does not directly relate to information retrieval, query understanding, ranking models, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> The output of large language models (LLM) is unstable, due to both
non-determinism of the decoding process as well as to prompt brittleness. While
the intrinsic non-determinism of LLM generation may mimic existing uncertainty
in human annotations through distributional shifts in outputs, it is largely
assumed, yet unexplored, that the prompt brittleness effect is unique to LLMs.
This raises the question: do human annotators show similar sensitivity to
instruction changes? If so, should prompt brittleness in LLMs be considered
problematic? One may alternatively hypothesize that prompt brittleness
correctly reflects human annotation variances. To fill this research gap, we
systematically compare the effects of prompt modifications on LLMs and
identical instruction modifications for human annotators, focusing on the
question of whether humans are similarly sensitive to prompt perturbations. To
study this, we prompt both humans and LLMs for a set of text classification
tasks conditioned on prompt variations. Our findings indicate that both humans
and LLMs exhibit increased brittleness in response to specific types of prompt
modifications, particularly those involving the substitution of alternative
label sets or label formats. However, the distribution of human judgments is
less affected by typographical errors and reversed label order than that of
LLMs.

### 42. Small Open Models Achieve Near Parity with Large Models in Low Resource Literary Translation at a Fraction of the Cost

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Mihai Nadas, Laura Diosan, Andreea Tomescu, Andrei Piscoran
- **URL**: <http://arxiv.org/abs/2509.07829v1>
- **Submitted**: 2025-09-09 15:07:14
- **Comment**: 25 pages, 8 figures, includes datasets and models released on Hugging
  Face
- **Topic Keywords**: search
- **Reason**: This paper focuses on machine translation, specifically in low resource languages, and does not directly relate to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing, particularly in areas requiring deep semantic understanding and real-time relevance optimization.

#### Abstract
> Literary translation has recently gained attention as a distinct and complex
task in machine translation research. However, the translation by small open
models remains an open problem. We contribute to this ongoing research by
introducing TINYFABULIST TRANSLATION FRAMEWORK (TF2), a unified framework for
dataset creation, fine tuning, and evaluation in English-Romanian literary
translations, centred on the creation and open release of both a compact, fine
tuned language model (TF2-12B) and large scale synthetic parallel datasets
(DS-TF2-EN-RO-3M and DS-TF2-EN-RO-15K). Building on DS-TF1-EN-3M (TF1), the
largest collection of synthetic English fables to date, we address the need for
rich, high quality literary datasets in low resource languages such as
Romanian. Our pipeline first generates 15k high quality Romanian references
from the TF1 pool using a high performing LLM. We then apply a two stage fine
tuning process to a 12B parameter open weight model: (i) instruction tuning to
capture genre specific narrative style, and (ii) adapter compression for
efficient deployment. Evaluation combines corpus level BLEU and a five
dimension LLM based rubric (accuracy, fluency, coherence, style, cultural
adaptation) to provide a nuanced assessment of translation quality. Results
show that our fine tuned model achieves fluency and adequacy competitive with
top performing large proprietary models, while being open, accessible, and
significantly more cost effective. Alongside the fine tuned model and both
datasets, we publicly release all scripts and evaluation prompts. TF2 thus
provides an end-to-end, reproducible pipeline for research on cost efficient
translation, cross lingual narrative generation, and the broad adoption of open
models for culturally significant literary content in low resource settings.

### 43. Understanding Stigmatizing Language Lexicons: A Comparative Analysis in Clinical Contexts

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yiliang Zhou, Di Hu, Tianchu Lyu, Jasmine Dhillon, Alexandra L. Beck, Gelareh Sadigh, Kai Zheng
- **URL**: <http://arxiv.org/abs/2509.07462v1>
- **Submitted**: 2025-09-09 07:41:20
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing, as it focuses on stigmatizing language lexicons in clinical contexts, which does not align with your areas of expertise.

#### Abstract
> Stigmatizing language results in healthcare inequities, yet there is no
universally accepted or standardized lexicon defining which words, terms, or
phrases constitute stigmatizing language in healthcare. We conducted a
systematic search of the literature to identify existing stigmatizing language
lexicons and then analyzed them comparatively to examine: 1) similarities and
discrepancies between these lexicons, and 2) the distribution of positive,
negative, or neutral terms based on an established sentiment dataset. Our
search identified four lexicons. The analysis results revealed moderate
semantic similarity among them, and that most stigmatizing terms are related to
judgmental expressions by clinicians to describe perceived negative behaviors.
Sentiment analysis showed a predominant proportion of negatively classified
terms, though variations exist across lexicons. Our findings underscore the
need for a standardized lexicon and highlight challenges in defining
stigmatizing language in clinical texts.

### 44. MEGG: Replay via Maximally Extreme GGscore in Incremental Learning for Neural Recommendation Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yunxiao Shi, Shuo Yang, Haimin Zhang, Li Wang, Yongze Wang, Qiang Wu, Min Xu
- **URL**: <http://arxiv.org/abs/2509.07319v1>
- **Submitted**: 2025-09-09 01:35:51
- **Comment**: Accepted by Data Mining and Knowledge Discovery (DMKD) in Sep 2025
- **Topic Keywords**: recommend
- **Reason**: This paper focuses on recommender systems and incremental learning, which is somewhat related to your interests in Information Retrieval and Search technologies. However, it does not align with your core research themes, particularly query understanding, ranking models, and user behavior modeling.

#### Abstract
> Neural Collaborative Filtering models are widely used in recommender systems
but are typically trained under static settings, assuming fixed data
distributions. This limits their applicability in dynamic environments where
user preferences evolve. Incremental learning offers a promising solution, yet
conventional methods from computer vision or NLP face challenges in
recommendation tasks due to data sparsity and distinct task paradigms. Existing
approaches for neural recommenders remain limited and often lack
generalizability. To address this, we propose MEGG, Replay Samples with
Maximally Extreme GGscore, an experience replay based incremental learning
framework. MEGG introduces GGscore, a novel metric that quantifies sample
influence, enabling the selective replay of highly influential samples to
mitigate catastrophic forgetting. Being model-agnostic, MEGG integrates
seamlessly across architectures and frameworks. Experiments on three neural
models and four benchmark datasets show superior performance over
state-of-the-art baselines, with strong scalability, efficiency, and
robustness. Implementation will be released publicly upon acceptance.

### 45. LLM Analysis of 150+ years of German Parliamentary Debates on Migration Reveals Shift from Post-War Solidarity to Anti-Solidarity in the Last Decade

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Aida Kostikova, Ole P√ºtz, Steffen Eger, Olga Sabelfeld, Benjamin Paassen
- **URL**: <http://arxiv.org/abs/2509.07274v1>
- **Submitted**: 2025-09-08 23:16:03
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing, as it focuses on political text analysis and social science interpretation of large language models in the context of migration debates in Germany.

#### Abstract
> Migration has been a core topic in German political debate, from millions of
expellees post World War II over labor migration to refugee movements in the
recent past. Studying political speech regarding such wide-ranging phenomena in
depth traditionally required extensive manual annotations, limiting the scope
of analysis to small subsets of the data. Large language models (LLMs) have the
potential to partially automate even complex annotation tasks. We provide an
extensive evaluation of a multiple LLMs in annotating (anti-)solidarity
subtypes in German parliamentary debates compared to a large set of thousands
of human reference annotations (gathered over a year). We evaluate the
influence of model size, prompting differences, fine-tuning, historical versus
contemporary data; and we investigate systematic errors. Beyond methodological
evaluation, we also interpret the resulting annotations from a social science
lense, gaining deeper insight into (anti-)solidarity trends towards migrants in
the German post-World War II period and recent past. Our data reveals a high
degree of migrant-directed solidarity in the postwar period, as well as a
strong trend towards anti-solidarity in the German parliament since 2015,
motivating further research. These findings highlight the promise of LLMs for
political text analysis and the importance of migration debates in Germany,
where demographic decline and labor shortages coexist with rising polarization.

### 46. Astra: A Multi-Agent System for GPU Kernel Performance Optimization

- **LLM Score**: 0
- **Keyword Score**: 3
- **Authors**: Anjiang Wei, Tianran Sun, Yogesh Seenichamy, Hang Song, Anne Ouyang, Azalia Mirhoseini, Ke Wang, Alex Aiken
- **URL**: <http://arxiv.org/abs/2509.07506v1>
- **Submitted**: 2025-09-09 08:39:50
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on GPU kernel optimization using multi-agent systems and large language models, which is unrelated to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> GPU kernel optimization has long been a central challenge at the intersection
of high-performance computing and machine learning. Efficient kernels are
crucial for accelerating large language model (LLM) training and serving, yet
attaining high performance typically requires extensive manual tuning.
Compiler-based systems reduce some of this burden, but still demand substantial
manual design and engineering effort. Recently, researchers have explored using
LLMs for GPU kernel generation, though prior work has largely focused on
translating high-level PyTorch modules into CUDA code. In this work, we
introduce Astra, the first LLM-based multi-agent system for GPU kernel
optimization. Unlike previous approaches, Astra starts from existing CUDA
implementations extracted from SGLang, a widely deployed framework for serving
LLMs, rather than treating PyTorch modules as the specification. Within Astra,
specialized LLM agents collaborate through iterative code generation, testing,
profiling, and planning to produce kernels that are both correct and
high-performance. On kernels from SGLang, Astra achieves an average speedup of
1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study
further demonstrates that LLMs can autonomously apply loop transformations,
optimize memory access patterns, exploit CUDA intrinsics, and leverage fast
math operations to yield substantial performance gains. Our work highlights
multi-agent LLM systems as a promising new paradigm for GPU kernel
optimization.

---

