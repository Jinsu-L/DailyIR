# Daily Papers Report - 2025-12-24

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Multi-hop Reasoning via Early Knowledge Alignment

- **LLM Score**: 7
- **Keyword Score**: 7
- **Authors**: Yuxin Wang, Shicheng Fang, Bo Wang, Qi Luo, Xuanjing Huang, Yining Zheng, Xipeng Qiu
- **URL**: <http://arxiv.org/abs/2512.20144v1>
- **Submitted**: 2025-12-23 08:14:44
- **Comment**: 16 pages
- **Topic Keywords**: queries, rag, retrieval
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of query understanding and ranking models. The focus on retrieval-augmented generation and multi-hop reasoning is relevant, but the emphasis on Large Language Models and reinforcement learning is not a central match to your primary focus on IR and search technologies.

#### Abstract
> Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for Large Language Models (LLMs) to address knowledge-intensive queries requiring domain-specific or up-to-date information. To handle complex multi-hop questions that are challenging for single-step retrieval, iterative RAG approaches incorporating reinforcement learning have been proposed. However, existing iterative RAG systems typically plan to decompose questions without leveraging information about the available retrieval corpus, leading to inefficient retrieval and reasoning chains that cascade into suboptimal performance. In this paper, we introduce Early Knowledge Alignment (EKA), a simple but effective module that aligns LLMs with retrieval set before planning in iterative RAG systems with contextually relevant retrieved knowledge. Extensive experiments on six standard RAG datasets demonstrate that by establishing a stronger reasoning foundation, EKA significantly improves retrieval precision, reduces cascading errors, and enhances both performance and efficiency. Our analysis from an entropy perspective demonstrate that incorporating early knowledge reduces unnecessary exploration during the reasoning process, enabling the model to focus more effectively on relevant information subsets. Moreover, EKA proves effective as a versatile, training-free inference strategy that scales seamlessly to large models. Generalization tests across diverse datasets and retrieval corpora confirm the robustness of our approach. Overall, EKA advances the state-of-the-art in iterative RAG systems while illuminating the critical interplay between structured reasoning and efficient exploration in reinforcement learning-augmented frameworks. The code is released at \href{https://github.com/yxzwang/EarlyKnowledgeAlignment}{Github}.

---

### 2. Sentiment-Aware Extractive and Abstractive Summarization for Unstructured Text Mining

- **LLM Score**: 6
- **Keyword Score**: 9
- **Authors**: Junyi Liu, Stanley Kok
- **URL**: <http://arxiv.org/abs/2512.20404v1>
- **Submitted**: 2025-12-23 14:48:42
- **Comment**: WITS 2025 (Workshop on Information Technologies and Systems 2025)
- **Topic Keywords**: ranking, relevance, rag, rank
- **Reason**: The paper explores text summarization, a related area to Information Retrieval, with a focus on sentiment modeling, which is somewhat relevant to user behavior modeling and query understanding. However, the primary focus on summarization and text mining, rather than search technologies or ranking models, limits its alignment with the user's core research themes.

#### Abstract
> With the rapid growth of unstructured data from social media, reviews, and forums, text mining has become essential in Information Systems (IS) for extracting actionable insights. Summarization can condense fragmented, emotion-rich posts, but existing methods-optimized for structured news-struggle with noisy, informal content. Emotional cues are critical for IS tasks such as brand monitoring and market analysis, yet few studies integrate sentiment modeling into summarization of short user-generated texts. We propose a sentiment-aware framework extending extractive (TextRank) and abstractive (UniLM) approaches by embedding sentiment signals into ranking and generation processes. This dual design improves the capture of emotional nuances and thematic relevance, producing concise, sentiment-enriched summaries that enhance timely interventions and strategic decision-making in dynamic online environments.

---

### 3. Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark

- **LLM Score**: 6
- **Keyword Score**: 9
- **Authors**: Hao Guo, Xugong Qin, Jun Jie Ou Yang, Peng Zhang, Gangyan Zeng, Yubo Li, Hailun Lin
- **URL**: <http://arxiv.org/abs/2512.20174v1>
- **Submitted**: 2025-12-23 09:14:16
- **Comment**: CVPR 2025
- **Topic Keywords**: query, queries, retrieval, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the area of query understanding and deep semantic understanding. However, it focuses on document image retrieval and natural language-based queries, which is a specific application area rather than a central theme of your research. The use of contrastive vision-language models and OCR-free visual document understanding models is also relevant, but not a primary focus of your work.

#### Abstract
> Document image retrieval (DIR) aims to retrieve document images from a gallery according to a given query. Existing DIR methods are primarily based on image queries that retrieve documents within the same coarse semantic category, e.g., newspapers or receipts. However, these methods struggle to effectively retrieve document images in real-world scenarios where textual queries with fine-grained semantics are usually provided. To bridge this gap, we introduce a new Natural Language-based Document Image Retrieval (NL-DIR) benchmark with corresponding evaluation metrics. In this work, natural language descriptions serve as semantically rich queries for the DIR task. The NL-DIR dataset contains 41K authentic document images, each paired with five high-quality, fine-grained semantic queries generated and evaluated through large language models in conjunction with manual verification. We perform zero-shot and fine-tuning evaluations of existing mainstream contrastive vision-language models and OCR-free visual document understanding (VDU) models. A two-stage retrieval method is further investigated for performance improvement while achieving both time and space efficiency. We hope the proposed NL-DIR benchmark can bring new opportunities and facilitate research for the VDU community. Datasets and codes will be publicly available at huggingface.co/datasets/nianbing/NL-DIR.

---

### 4. Making Large Language Models Efficient Dense Retrievers

- **LLM Score**: 6
- **Keyword Score**: 8
- **Authors**: Yibin Lei, Shwai He, Ang Li, Andrew Yates
- **URL**: <http://arxiv.org/abs/2512.20612v1>
- **Submitted**: 2025-12-23 18:58:25
- **Topic Keywords**: retriever, dense retrieval, retrieval
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, specifically in the context of dense retrieval and large language models. However, the focus on efficiency and compression of models, while relevant to the broader field of IR, does not directly align with your core research themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> Recent work has shown that directly fine-tuning large language models (LLMs) for dense retrieval yields strong performance, but their substantial parameter counts make them computationally inefficient. While prior studies have revealed significant layer redundancy in LLMs for generative tasks, it remains unclear whether similar redundancy exists when these models are adapted for retrieval tasks, which require encoding entire sequences into fixed representations rather than generating tokens iteratively. To this end, we conduct a comprehensive analysis of layer redundancy in LLM-based dense retrievers. We find that, in contrast to generative settings, MLP layers are substantially more prunable, while attention layers remain critical for semantic aggregation. Building on this insight, we propose EffiR, a framework for developing efficient retrievers that performs large-scale MLP compression through a coarse-to-fine strategy (coarse-grained depth reduction followed by fine-grained width reduction), combined with retrieval-specific fine-tuning. Across diverse BEIR datasets and LLM backbones, EffiR achieves substantial reductions in model size and inference cost while preserving the performance of full-size models.

---

### 5. Retrieval-augmented Prompt Learning for Pre-trained Foundation Models

- **LLM Score**: 6
- **Keyword Score**: 5
- **Authors**: Xiang Chen, Yixin Ou, Quan Feng, Lei Li, Piji Li, Haibo Ye, Sheng-Jun Huang, Shuofei Qiao, Shumin Deng, Huajun Chen, Ningyu Zhang
- **URL**: <http://arxiv.org/abs/2512.20145v1>
- **Submitted**: 2025-12-23 08:15:34
- **Comment**: IEEE/ACM Transactions on Audio, Speech and Language Processing
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper discusses a novel approach to prompt learning for pre-trained foundation models, leveraging a retrieval mechanism to enhance contextual information. While it touches on aspects of query understanding and real-time relevance optimization, its primary focus is on improving few-shot performance and generalization, which is somewhat related to information retrieval but not a central match for your research interests.

#### Abstract
> The pre-trained foundation models (PFMs) have become essential for facilitating large-scale multimodal learning. Researchers have effectively employed the ``pre-train, prompt, and predict'' paradigm through prompt learning to induce improved few-shot performance. However, prompt learning approaches for PFMs still follow a parametric learning paradigm. As such, the stability of generalization in memorization and rote learning can be compromised. More specifically, conventional prompt learning might face difficulties in fully utilizing atypical instances and avoiding overfitting to shallow patterns with limited data during the process of fully-supervised training. To overcome these constraints, we present our approach, named RetroPrompt, which aims to achieve a balance between memorization and generalization by decoupling knowledge from mere memorization. Unlike traditional prompting methods, RetroPrompt leverages a publicly accessible knowledge base generated from the training data and incorporates a retrieval mechanism throughout the input, training, and inference stages. This enables the model to actively retrieve relevant contextual information from the corpus, thereby enhancing the available cues. We conduct comprehensive experiments on a variety of datasets across natural language processing and computer vision tasks to demonstrate the superior performance of our proposed approach, RetroPrompt, in both zero-shot and few-shot scenarios. Through detailed analysis of memorization patterns, we observe that RetroPrompt effectively reduces the reliance on rote memorization, leading to enhanced generalization.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Laser: Governing Long-Horizon Agentic Search via Structured Protocol and Context Register

- **LLM Score**: 6
- **Keyword Score**: 4
- **Authors**: Shuting Wang, Qiaolin Xia, Hao Wang, Yu Lu, Bobsimons, Zhicheng Dou
- **URL**: <http://arxiv.org/abs/2512.20458v1>
- **Submitted**: 2025-12-23 15:53:33
- **Topic Keywords**: queries, search
- **Reason**: The paper explores agentic search systems, which is a related topic to information retrieval, particularly in the context of query understanding and ranking models. However, the focus on Large Language Models and Large Reasoning Models, as well as the specific application to multi-hop queries, is somewhat niche and not directly aligned with the user's core research themes.

#### Abstract
> Recent advances in Large Language Models (LLMs) and Large Reasoning Models (LRMs) have enabled agentic search systems that interleave multi-step reasoning with external tool use. However, existing frameworks largely rely on unstructured natural-language reasoning and accumulate raw intermediate traces in the context, which often leads to unstable reasoning trajectories, context overflow, and degraded performance on complex multi-hop queries. In this study, we introduce Laser, a general framework for stabilizing and scaling agentic search. Laser defines a symbolic action protocol that organizes agent behaviors into three spaces: planning, task-solving, and retrospection. Each action is specified with explicit semantics and a deterministic execution format, enabling structured and logical reasoning processes and reliable action parsing. This design makes intermediate decisions interpretable and traceable, enhancing explicit retrospection and fine-grained control over reasoning trajectories. In coordination with parsable actions, Laser further maintains a compact context register that stores only essential states of the reasoning process, allowing the agent to reason over long horizons without uncontrolled context expansion. Experiments on Qwen2.5/3-series models across challenging multi-hop QA datasets show that Laser consistently outperforms existing agentic search baselines under both prompting-only and fine-tuning settings, demonstrating that Laser provides a principled and effective foundation for robust, scalable agentic search.

### 7. Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems

- **LLM Score**: 6
- **Keyword Score**: 1
- **Authors**: Heet Bodara, Md Masum Mushfiq, Isma Farah Siddiqui
- **URL**: <http://arxiv.org/abs/2512.19950v1>
- **Submitted**: 2025-12-23 00:41:48
- **Topic Keywords**: search
- **Reason**: This paper explores tone bias in Large Language Models (LLMs) used in conversational systems, which is related to query understanding and user behavior modeling in Information Retrieval. However, it focuses more on NLP and UX aspects, rather than search technologies or ranking models, making it somewhat relevant but not a central match for your research interests.

#### Abstract
> Large Language Models are increasingly used in conversational systems such as digital personal assistants, shaping how people interact with technology through language. While their responses often sound fluent and natural, they can also carry subtle tone biases such as sounding overly polite, cheerful, or cautious even when neutrality is expected. These tendencies can influence how users perceive trust, empathy, and fairness in dialogue. In this study, we explore tone bias as a hidden behavioral trait of large language models. The novelty of this research lies in the integration of controllable large language model based dialogue synthesis with tone classification models, enabling robust and ethical emotion recognition in personal assistant interactions. We created two synthetic dialogue datasets, one generated from neutral prompts and another explicitly guided to produce positive or negative tones. Surprisingly, even the neutral set showed consistent tonal skew, suggesting that bias may stem from the model's underlying conversational style. Using weak supervision through a pretrained DistilBERT model, we labeled tones and trained several classifiers to detect these patterns. Ensemble models achieved macro F1 scores up to 0.92, showing that tone bias is systematic, measurable, and relevant to designing fair and trustworthy conversational AI.

### 8. M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation

- **LLM Score**: 4
- **Keyword Score**: 13
- **Authors**: Hyeongcheol Park, Jiyoung Seo, Jaewon Mun, Hogun Park, Wonmin Byeon, Sung June Kim, Hyeonsoo Im, JeungSub Lee, Sangpil Kim
- **URL**: <http://arxiv.org/abs/2512.20136v2>
- **Submitted**: 2025-12-23 07:54:03
- **Topic Keywords**: query, queries, relevance, rag, retrieval
- **Reason**: The paper discusses multimodal knowledge graph-enhanced retrieval-augmented generation, which is somewhat related to information retrieval and query understanding. However, the focus on multimodal knowledge graphs and audio-visual domains is not directly aligned with the user's core research themes in e-commerce and deep semantic understanding. The connection to natural language processing and data mining is more relevant, but the paper's scope is not a central match for the user's interests.

#### Abstract
> Retrieval-Augmented Generation (RAG) has recently been extended to multimodal settings, connecting multimodal large language models (MLLMs) with vast corpora of external knowledge such as multimodal knowledge graphs (MMKGs). Despite their recent success, multimodal RAG in the audio-visual domain remains challenging due to 1) limited modality coverage and multi-hop connectivity of existing MMKGs, and 2) retrieval based solely on similarity in a shared multimodal embedding space, which fails to filter out off-topic or redundant knowledge. To address these limitations, we propose M$^3$KG-RAG, a Multi-hop Multimodal Knowledge Graph-enhanced RAG that retrieves query-aligned audio-visual knowledge from MMKGs, improving reasoning depth and answer faithfulness in MLLMs. Specifically, we devise a lightweight multi-agent pipeline to construct multi-hop MMKG (M$^3$KG), which contains context-enriched triplets of multimodal entities, enabling modality-wise retrieval based on input queries. Furthermore, we introduce GRASP (Grounded Retrieval And Selective Pruning), which ensures precise entity grounding to the query, evaluates answer-supporting relevance, and prunes redundant context to retain only knowledge essential for response generation. Extensive experiments across diverse multimodal benchmarks demonstrate that M$^3$KG-RAG significantly enhances MLLMs' multimodal reasoning and grounding over existing approaches.

### 9. IGDMRec: Behavior Conditioned Item Graph Diffusion for Multimodal Recommendation

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Ziyuan Guo, Jie Guo, Zhenghao Chen, Bin Song, Fei Richard Yu
- **URL**: <http://arxiv.org/abs/2512.19983v1>
- **Submitted**: 2025-12-23 02:13:01
- **Comment**: 12 pages, 6 figures. This paper has been accepted for publication in IEEE Transactions on Multimedia. The final published version will be available via IEEE Xplore
- **Topic Keywords**: rag, user behavior, recommend
- **Reason**: The paper focuses on multimodal recommendation systems, which is somewhat related to information retrieval, but it primarily deals with recommender systems and does not directly address query understanding, ranking models, or user behavior modeling. The use of diffusion models and graph-based methods is an interesting aspect, but it does not align with the user's core research themes.

#### Abstract
> Multimodal recommender systems (MRSs) are critical for various online platforms, offering users more accurate personalized recommendations by incorporating multimodal information of items. Structure-based MRSs have achieved state-of-the-art performance by constructing semantic item graphs, which explicitly model relationships between items based on modality feature similarity. However, such semantic item graphs are often noisy due to 1) inherent noise in multimodal information and 2) misalignment between item semantics and user-item co-occurrence relationships, which introduces false links and leads to suboptimal recommendations. To address this challenge, we propose Item Graph Diffusion for Multimodal Recommendation (IGDMRec), a novel method that leverages a diffusion model with classifier-free guidance to denoise the semantic item graph by integrating user behavioral information. Specifically, IGDMRec introduces a Behavior-conditioned Graph Diffusion (BGD) module, incorporating interaction data as conditioning information to guide the denoising of the semantic item graph. Additionally, a Conditional Denoising Network (CD-Net) is designed to implement the denoising process with manageable complexity. Finally, we propose a contrastive representation augmentation scheme that leverages both the denoised item graph and the original item graph to enhance item representations. \LL{Extensive experiments on four real-world datasets demonstrate the superiority of IGDMRec over competitive baselines, with robustness analysis validating its denoising capability and ablation studies verifying the effectiveness of its key components.

### 10. FaithLens: Detecting and Explaining Faithfulness Hallucination

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Shuzheng Si, Qingyi Wang, Haozhe Zhao, Yuzhuo Bai, Guanqiao Chen, Kangyang Luo, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun
- **URL**: <http://arxiv.org/abs/2512.20182v1>
- **Submitted**: 2025-12-23 09:20:32
- **Topic Keywords**: retrieval
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it deals with detecting faithfulness hallucination in large language models. However, the focus is more on NLP and model evaluation rather than query understanding, ranking models, or user behavior modeling, which are your core research themes.

#### Abstract
> Recognizing whether outputs from large language models (LLMs) contain faithfulness hallucination is crucial for real-world applications, e.g., retrieval-augmented generation and summarization. In this paper, we introduce FaithLens, a cost-efficient and effective faithfulness hallucination detection model that can jointly provide binary predictions and corresponding explanations to improve trustworthiness. To achieve this, we first synthesize training data with explanations via advanced LLMs and apply a well-defined data filtering strategy to ensure label correctness, explanation quality, and data diversity. Subsequently, we fine-tune the model on these well-curated training data as a cold start and further optimize it with rule-based reinforcement learning, using rewards for both prediction correctness and explanation quality. Results on 12 diverse tasks show that the 8B-parameter FaithLens outperforms advanced models such as GPT-4.1 and o3. Also, FaithLens can produce high-quality explanations, delivering a distinctive balance of trustworthiness, efficiency, and effectiveness.

### 11. Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Marko ƒåechoviƒç, Nat√°lia Komorn√≠kov√°, Dominik Mach√°ƒçek, Ond≈ôej Bojar
- **URL**: <http://arxiv.org/abs/2512.20204v1>
- **Submitted**: 2025-12-23 09:56:23
- **Comment**: 12 pages, 2 figures, 6 tables, published as a conference paper in Text, Speech, and Dialogue 28th International Conference, TSD 2025, Erlangen, Germany, August 25-28, 2025, Proceedings, Part II. This version published here on arXiv.org is before review comments and seedings of the TSD conference staff
- **Topic Keywords**: search
- **Reason**: This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and data mining, but it does not directly align with their primary focus on Information Retrieval, especially in areas requiring deep semantic understanding and real-time relevance optimization. The paper's focus on cross-lingual dialogues and misunderstanding detection is not a central match for the user's research themes.

#### Abstract
> Speech processing and translation technology have the potential to facilitate meetings of individuals who do not share any common language. To evaluate automatic systems for such a task, a versatile and realistic evaluation corpus is needed. Therefore, we create and present a corpus of cross-lingual dialogues between individuals without a common language who were facilitated by automatic simultaneous speech translation. The corpus consists of 5 hours of speech recordings with ASR and gold transcripts in 12 original languages and automatic and corrected translations into English. For the purposes of research into cross-lingual summarization, our corpus also includes written summaries (minutes) of the meetings.
  Moreover, we propose automatic detection of misunderstandings. For an overview of this task and its complexity, we attempt to quantify misunderstandings in cross-lingual meetings. We annotate misunderstandings manually and also test the ability of current large language models to detect them automatically. The results show that the Gemini model is able to identify text spans with misunderstandings with recall of 77% and precision of 47%.

### 12. Collaborative Group-Aware Hashing for Fast Recommender Systems

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Yan Zhang, Li Deng, Lixin Duan, Ivor W. Tsang, Guowu Yang
- **URL**: <http://arxiv.org/abs/2512.20172v1>
- **Submitted**: 2025-12-23 09:07:28
- **Topic Keywords**: recommend
- **Reason**: The paper focuses on recommender systems and hashing techniques, which are somewhat related to your interests in Information Retrieval and Search technologies. However, the emphasis on collaborative filtering and content-aware recommendations, while relevant to your background in e-commerce, does not directly align with your primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> The fast online recommendation is critical for applications with large-scale databases; meanwhile, it is challenging to provide accurate recommendations in sparse scenarios. Hash technique has shown its superiority for speeding up the online recommendation by bit operations on Hamming distance computations. However, existing hashing-based recommendations suffer from low accuracy, especially with sparse settings, due to the limited representation capability of each bit and neglected inherent relations among users and items. To this end, this paper lodges a Collaborative Group-Aware Hashing (CGAH) method for both collaborative filtering (namely CGAH-CF) and content-aware recommendations (namely CGAH) by integrating the inherent group information to alleviate the sparse issue. Firstly, we extract inherent group affinities of users and items by classifying their latent vectors into different groups. Then, the preference is formulated as the inner product of the group affinity and the similarity of hash codes. By learning hash codes with the inherent group information, CGAH obtains more effective hash codes than other discrete methods with sparse interactive data. Extensive experiments on three public datasets show the superior performance of our proposed CGAH and CGAH-CF over the state-of-the-art discrete collaborative filtering methods and discrete content-aware recommendations under different sparse settings.

### 13. Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents

- **LLM Score**: 3
- **Keyword Score**: 6
- **Authors**: Yiming Du, Baojun Wang, Yifan Xiang, Zhaowei Wang, Wenyu Huang, Boyang Xue, Bin Liang, Xingshan Zeng, Fei Mi, Haoli Bai, Lifeng Shang, Jeff Z. Pan, Yuxin Jiang, Kam-Fai Wong
- **URL**: <http://arxiv.org/abs/2512.20092v1>
- **Submitted**: 2025-12-23 06:37:29
- **Topic Keywords**: query, relevance
- **Reason**: This paper focuses on temporal reasoning in conversational agents, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the primary focus on conversational agents and dialogue histories makes it less directly relevant to the user's core research themes in IR and Search technologies.

#### Abstract
> Temporal reasoning over long, multi-session dialogues is a critical capability for conversational agents. However, existing works and our pilot study have shown that as dialogue histories grow in length and accumulate noise, current long-context models struggle to accurately identify temporally pertinent information, significantly impairing reasoning performance. To address this, we introduce Memory-T1, a framework that learns a time-aware memory selection policy using reinforcement learning (RL). It employs a coarse-to-fine strategy, first pruning the dialogue history into a candidate set using temporal and relevance filters, followed by an RL agent that selects the precise evidence sessions. The RL training is guided by a multi-level reward function optimizing (i) answer accuracy, (ii) evidence grounding, and (iii) temporal consistency. In particular, the temporal consistency reward provides a dense signal by evaluating alignment with the query time scope at both the session-level (chronological proximity) and the utterance-level (chronological fidelity), enabling the agent to resolve subtle chronological ambiguities. On the Time-Dialog benchmark, Memory-T1 boosts a 7B model to an overall score of 67.0\%, establishing a new state-of-the-art performance for open-source models and outperforming a 14B baseline by 10.2\%. Ablation studies show temporal consistency and evidence grounding rewards jointly contribute to a 15.0\% performance gain. Moreover, Memory-T1 maintains robustness up to 128k tokens, where baseline models collapse, proving effectiveness against noise in extensive dialogue histories. The code and datasets are publicly available at https://github.com/Elvin-Yiming-Du/Memory-T1/

### 14. HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Shashi Kant Gupta, Arijeet Pramanik, Jerrin John Thomas, Regina Schwind, Lauren Wiener, Avi Raju, Jeremy Kornbluth, Yanshan Wang, Zhaohui Su, Hrituraj Singh
- **URL**: <http://arxiv.org/abs/2512.19864v1>
- **Submitted**: 2025-12-22 20:38:30
- **Comment**: 39 Pages, Supplementary Included
- **Topic Keywords**: rag, ctr, retrieval, search
- **Reason**: This paper is not relevant to your research interests as it focuses on extracting structured data from unstructured clinical notes in the oncology domain, using large language models for reasoning. While it involves natural language processing and data extraction, it does not address information retrieval, search technologies, or query understanding, which are your primary research areas.

#### Abstract
> Unstructured notes within the electronic health record (EHR) contain rich clinical information vital for cancer treatment decision making and research, yet reliably extracting structured oncology data remains challenging due to extensive variability, specialized terminology, and inconsistent document formats. Manual abstraction, although accurate, is prohibitively costly and unscalable. Existing automated approaches typically address narrow scenarios - either using synthetic datasets, restricting focus to document-level extraction, or isolating specific clinical variables (e.g., staging, biomarkers, histology) - and do not adequately handle patient-level synthesis across the large number of clinical documents containing contradictory information. In this study, we propose an agentic framework that systematically decomposes complex oncology data extraction into modular, adaptive tasks. Specifically, we use large language models (LLMs) as reasoning agents, equipped with context-sensitive retrieval and iterative synthesis capabilities, to exhaustively and comprehensively extract structured clinical variables from real-world oncology notes. Evaluated on a large-scale dataset of over 400,000 unstructured clinical notes and scanned PDF reports spanning 2,250 cancer patients, our method achieves an average F1-score of 0.93, with 100 out of 103 oncology-specific clinical variables exceeding 0.85, and critical variables (e.g., biomarkers and medications) surpassing 0.95. Moreover, integration of the agentic system into a data curation workflow resulted in 0.94 direct manual approval rate, significantly reducing annotation costs. To our knowledge, this constitutes the first exhaustive, end-to-end application of LLM-based agents for structured oncology data extraction at scale

### 15. Fun-Audio-Chat Technical Report

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Qian Chen, Luyao Cheng, Chong Deng, Xiangang Li, Jiaqing Liu, Chao-Hong Tan, Wen Wang, Junhao Xu, Jieping Ye, Qinglin Zhang, Qiquan Zhang, Jingren Zhou
- **URL**: <http://arxiv.org/abs/2512.20156v1>
- **Submitted**: 2025-12-23 08:35:27
- **Comment**: 21 pages, https://github.com/FunAudioLLM/Fun-Audio-Chat
- **Topic Keywords**: ranking, rag, rank
- **Reason**: This paper focuses on Large Audio Language Models for voice interactions, which is not directly related to Information Retrieval or Search technologies. While it involves Natural Language Processing, the primary focus is on speech-text models and audio understanding, which doesn't align with the user's core research themes.

#### Abstract
> Recent advancements in joint speech-text models show great potential for seamless voice interactions. However, existing models face critical challenges: temporal resolution mismatch between speech tokens (25Hz) and text tokens (~3Hz) dilutes semantic information, incurs high computational costs, and causes catastrophic forgetting of text LLM knowledge. We introduce Fun-Audio-Chat, a Large Audio Language Model addressing these limitations via two innovations from our previous work DrVoice. First, Dual-Resolution Speech Representations (DRSR): the Shared LLM processes audio at efficient 5Hz (via token grouping), while the Speech Refined Head generates high-quality tokens at 25Hz, balancing efficiency (~50% GPU reduction) and quality. Second, Core-Cocktail Training, a two-stage fine-tuning with intermediate merging that mitigates catastrophic forgetting. We then apply Multi-Task DPO Training to enhance robustness, audio understanding, instruction-following and voice empathy. This multi-stage post-training enables Fun-Audio-Chat to retain text LLM knowledge while gaining powerful audio understanding, reasoning, and generation. Unlike recent LALMs requiring large-scale audio-text pre-training, Fun-Audio-Chat leverages pre-trained models and extensive post-training. Fun-Audio-Chat 8B and MoE 30B-A3B achieve competitive performance on Speech-to-Text and Speech-to-Speech tasks, ranking top among similar-scale models on Spoken QA benchmarks. They also achieve competitive to superior performance on Audio Understanding, Speech Function Calling, Instruction-Following and Voice Empathy. We develop Fun-Audio-Chat-Duplex, a full-duplex variant with strong performance on Spoken QA and full-duplex interactions. We open-source Fun-Audio-Chat-8B with training and inference code, and provide an interactive demo.

### 16. Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Tarik Houichime, Abdelghani Souhar, Younes El Amrani
- **URL**: <http://arxiv.org/abs/2512.20245v1>
- **Submitted**: 2025-12-23 10:55:32
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper appears to be primarily focused on a novel architecture for Large Language Models, exploring the concept of infinite context memory through a biomimetic approach. While it touches on the idea of memory and storage, it does not seem to be directly related to Information Retrieval, Search technologies, or query understanding, which are core areas of your research interests.

#### Abstract
> The memory of contemporary Large Language Models is bound by a physical paradox: as they learn, they fill up. The linear accumulation (O(N)) of Key-Value states treats context as a warehouse of static artifacts, eventually forcing a destructive choice between amnesia and latency. We challenge this discrete orthodoxy, proposing that long-term memory is not the storage of items, but the persistence of a trajectory. We introduce Phonetic Trajectory Memory (PTM), a neuro-symbolic architecture that encodes language not as a sequence of tensors, but as a continuous path on an ergodic manifold governed by irrational rotation matrices. By decoupling the navigation (an invariant O(1) geometric signal) from the reconstruction (a probabilistic generative act), PTM achieves a compression magnitude of greater than 3,000x relative to dense caches. We demonstrate that retrieval becomes a process of resonance: the phonetic trace stabilizes the model against hallucination via "Signal Consensus" mechanism, securing up to approximately 92% factual accuracy. While this aggressive abstraction alters generative texture, it unlocks immediate access latency (approximately 34ms) independent of depth. Our results suggest that infinite context does not require infinite silicon; it requires treating memory not as data to be stored, but as a reconstructive process acting on a conserved, undying physical signal.

### 17. Counterfactual LLM-based Framework for Measuring Rhetorical Style

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Jingyi Qiu, Hong Chen, Zongyi Li
- **URL**: <http://arxiv.org/abs/2512.19908v1>
- **Submitted**: 2025-12-22 22:22:46
- **Topic Keywords**: pairwise, iclr
- **Reason**: This paper explores the use of LLMs to measure rhetorical style in machine learning papers, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it touches on the use of LLMs, the focus is on evaluating scientific writing rather than improving search or retrieval processes.

#### Abstract
> The rise of AI has fueled growing concerns about ``hype'' in machine learning papers, yet a reliable way to quantify rhetorical style independently of substantive content has remained elusive. Because bold language can stem from either strong empirical results or mere rhetorical style, it is often difficult to distinguish between the two. To disentangle rhetorical style from substantive content, we introduce a counterfactual, LLM-based framework: multiple LLM rhetorical personas generate counterfactual writings from the same substantive content, an LLM judge compares them through pairwise evaluations, and the outcomes are aggregated using a Bradley--Terry model. Applying this method to 8,485 ICLR submissions sampled from 2017 to 2025, we generate more than 250,000 counterfactual writings and provide a large-scale quantification of rhetorical style in ML papers. We find that visionary framing significantly predicts downstream attention, including citations and media attention, even after controlling for peer-review evaluations. We also observe a sharp rise in rhetorical strength after 2023, and provide empirical evidence showing that this increase is largely driven by the adoption of LLM-based writing assistance. The reliability of our framework is validated by its robustness to the choice of personas and the high correlation between LLM judgments and human annotations. Our work demonstrates that LLMs can serve as instruments to measure and improve scientific evaluation.

### 18. PHOTON: Hierarchical Autoregressive Modeling for Lightspeed and Memory-Efficient Language Generation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yuma Ichikawa, Naoya Takagi, Takumi Nakagawa, Yuzi Kanazawa, Akira Sakai
- **URL**: <http://arxiv.org/abs/2512.20687v1>
- **Submitted**: 2025-12-22 19:26:59
- **Comment**: 12 pages, 5 figures
- **Topic Keywords**: query
- **Reason**: This paper focuses on hierarchical autoregressive modeling for language generation, which is not directly related to information retrieval or search technologies. Although it involves deep semantic understanding, the context is language generation rather than relevance optimization or ranking models.

#### Abstract
> Transformers operate as horizontal token-by-token scanners; at each generation step, the model attends to an ever-growing sequence of token-level states. This access pattern increases prefill latency and makes long-context decoding increasingly memory-bound, as KV-cache reads and writes dominate inference throughput rather than arithmetic computation. We propose Parallel Hierarchical Operation for Top-down Networks (PHOTON), a hierarchical autoregressive model that replaces flat scanning with vertical, multi-resolution context access. PHOTON maintains a hierarchy of latent streams: a bottom-up encoder progressively compresses tokens into low-rate contextual states, while lightweight top-down decoders reconstruct fine-grained token representations. Experimental results show that PHOTON is superior to competitive Transformer-based language models regarding the throughput-quality trade-off, offering significant advantages in long-context and multi-query tasks. This reduces decode-time KV-cache traffic, yielding up to $10^{3}\times$ higher throughput per unit memory.

### 19. Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Humza Nusrat, Luke Francisco, Bing Luo, Hassan Bagher-Ebadian, Joshua Kim, Karen Chin-Snyder, Salim Siddiqui, Mira Shah, Eric Mellon, Mohammad Ghassemi, Anthony Doemer, Benjamin Movsas, Kundan Thind
- **URL**: <http://arxiv.org/abs/2512.20586v1>
- **Submitted**: 2025-12-23 18:32:17
- **Topic Keywords**: rag
- **Reason**: The paper appears to be focused on stereotactic radiosurgery planning using a large language model agent, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves a human-in-the-loop reasoning model, the context is medical planning rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the reasoning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.

### 20. Step-DeepResearch Technical Report

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Chen Hu, Haikuo Du, Heng Wang, Lin Lin, Mingrui Chen, Peng Liu, Ruihang Miao, Tianchi Yue, Wang You, Wei Ji, Wei Yuan, Wenjin Deng, Xiaojian Yuan, Xiaoyun Zhang, Xiangyu Liu, Xikai Liu, Yanming Xu, Yicheng Cao, Yifei Zhang, Yongyao Wang, Yubo Shu, Yurong Zhang, Yuxiang Zhang, Zheng Gong, Zhichao Chang, Binyan Li, Dan Ma, Furong Jia, Hongyuan Wang, Jiayu Liu, Jing Bai, Junlan Liu, Manjiao Liu, Na Wang, Qiuping Wu, Qinxin Du, Shiwei Li, Wen Sun, Yifeng Gong, Yonglin Chen, Yuling Zhao, Yuxuan Lin, Ziqi Ren, Zixuan Wang, Aihu Zhang, Brian Li, Buyun Ma, Kang An, Li Xie, Mingliang Li, Pan Li, Shidong Yang, Xi Chen, Xiaojia Liu, Yuchu Luo, Yuan Song, YuanHao Ding, Yuanwei Liang, Zexi Li, Zhaoning Zhang, Zixin Zhang, Binxing Jiao, Daxin Jiang, Jiansheng Chen, Jing Li, Xiangyu Zhang, Yibo Zhu
- **URL**: <http://arxiv.org/abs/2512.20491v2>
- **Submitted**: 2025-12-23 16:32:27
- **Topic Keywords**: search
- **Reason**: This paper appears to be related to natural language processing and deep learning, but its focus on autonomous agents, intent recognition, and planning does not align with the user's primary research interests in information retrieval, query understanding, and ranking models. The paper's emphasis on real-world applications and evaluation metrics also seems to be more aligned with recommender systems or data mining, rather than the user's core focus on deep semantic understanding and real-time relevance optimization.

#### Abstract
> As LLMs shift toward autonomous agents, Deep Research has emerged as a pivotal metric. However, existing academic benchmarks like BrowseComp often fail to meet real-world demands for open-ended research, which requires robust skills in intent recognition, long-horizon decision-making, and cross-source verification. To address this, we introduce Step-DeepResearch, a cost-effective, end-to-end agent. We propose a Data Synthesis Strategy Based on Atomic Capabilities to reinforce planning and report writing, combined with a progressive training path from agentic mid-training to SFT and RL. Enhanced by a Checklist-style Judger, this approach significantly improves robustness. Furthermore, to bridge the evaluation gap in the Chinese domain, we establish ADR-Bench for realistic deep research scenarios. Experimental results show that Step-DeepResearch (32B) scores 61.4% on Scale AI Research Rubrics. On ADR-Bench, it significantly outperforms comparable models and rivals SOTA closed-source models like OpenAI and Gemini DeepResearch. These findings prove that refined training enables medium-sized models to achieve expert-level capabilities at industry-leading cost-efficiency.

### 21. Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Nilesh Jain, Seyi Adeyinka, Leor Roseman, Aza Allsop
- **URL**: <http://arxiv.org/abs/2512.20352v1>
- **Submitted**: 2025-12-23 13:32:43
- **Comment**: 11 pages, 1 figure, 3 tables
- **Topic Keywords**: search
- **Reason**: This paper focuses on qualitative research validation using LLMs, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context and application are distinct from the user's areas of focus.

#### Abstract
> Qualitative research faces a critical reliability challenge: traditional inter-rater agreement methods require multiple human coders, are time-intensive, and often yield moderate consistency. We present a multi-perspective validation framework for LLM-based thematic analysis that combines ensemble validation with dual reliability metrics: Cohen's Kappa ($Œ∫$) for inter-rater agreement and cosine similarity for semantic consistency. Our framework enables configurable analysis parameters (1-6 seeds, temperature 0.0-2.0), supports custom prompt structures with variable substitution, and provides consensus theme extraction across any JSON format. As proof-of-concept, we evaluate three leading LLMs (Gemini 2.5 Pro, GPT-4o, Claude 3.5 Sonnet) on a psychedelic art therapy interview transcript, conducting six independent runs per model. Results demonstrate Gemini achieves highest reliability ($Œ∫= 0.907$, cosine=95.3%), followed by GPT-4o ($Œ∫= 0.853$, cosine=92.6%) and Claude ($Œ∫= 0.842$, cosine=92.1%). All three models achieve a high agreement ($Œ∫> 0.80$), validating the multi-run ensemble approach. The framework successfully extracts consensus themes across runs, with Gemini identifying 6 consensus themes (50-83% consistency), GPT-4o identifying 5 themes, and Claude 4 themes. Our open-source implementation provides researchers with transparent reliability metrics, flexible configuration, and structure-agnostic consensus extraction, establishing methodological foundations for reliable AI-assisted qualitative research.

### 22. SpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Maxime Poli, Mahi Luthra, Youssef Benchekroun, Yosuke Higuchi, Martin Gleize, Jiayi Shen, Robin Algayres, Yu-An Chung, Mido Assran, Juan Pino, Emmanuel Dupoux
- **URL**: <http://arxiv.org/abs/2512.20308v1>
- **Submitted**: 2025-12-23 12:22:25
- **Comment**: 30 pages, 16 figures
- **Topic Keywords**: search
- **Reason**: This paper focuses on spoken language models and speech representation learning, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve language modeling, it's specifically focused on spoken language and doesn't address query understanding, ranking models, or user behavior modeling.

#### Abstract
> The parallel advances in language modeling and speech representation learning have raised the prospect of learning language directly from speech without textual intermediates. This requires extracting semantic representations directly from speech. Our contributions are threefold. First, we introduce SpidR, a self-supervised speech representation model that efficiently learns representations with highly accessible phonetic information, which makes it particularly suited for textless spoken language modeling. It is trained on raw waveforms using a masked prediction objective combined with self-distillation and online clustering. The intermediate layers of the student model learn to predict assignments derived from the teacher's intermediate layers. This learning objective stabilizes the online clustering procedure compared to previous approaches, resulting in higher quality codebooks. SpidR outperforms wav2vec 2.0, HuBERT, WavLM, and DinoSR on downstream language modeling benchmarks (sWUGGY, sBLIMP, tSC). Second, we systematically evaluate across models and layers the correlation between speech unit quality (ABX, PNMI) and language modeling performance, validating these metrics as reliable proxies. Finally, SpidR significantly reduces pretraining time compared to HuBERT, requiring only one day of pretraining on 16 GPUs, instead of a week. This speedup is enabled by the pretraining method and an efficient codebase, which allows faster iteration and easier experimentation. We open-source the training code and model checkpoints at https://github.com/facebookresearch/spidr.

### 23. AprielGuard

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jaykumar Kasundra, Anjaneya Praharaj, Sourabh Surana, Lakshmi Sirisha Chodisetty, Sourav Sharma, Abhigya Verma, Abhishek Bhardwaj, Debasish Kanhar, Aakash Bhagat, Khalil Slimi, Seganrasan Subramanian, Sathwik Tejaswi Madhusudhan, Ranga Prasad Chenna, Srinivas Sunkara
- **URL**: <http://arxiv.org/abs/2512.20293v1>
- **Submitted**: 2025-12-23 12:01:32
- **Topic Keywords**: search
- **Reason**: This paper focuses on safeguarding large language models, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it touches on NLP, it's more focused on model safety and robustness rather than deep semantic understanding or real-time relevance optimization.

#### Abstract
> Safeguarding large language models (LLMs) against unsafe or adversarial behavior is critical as they are increasingly deployed in conversational and agentic settings. Existing moderation tools often treat safety risks (e.g. toxicity, bias) and adversarial threats (e.g. prompt injections, jailbreaks) as separate problems, limiting their robustness and generalizability. We introduce AprielGuard, an 8B parameter safeguard model that unify these dimensions within a single taxonomy and learning framework. AprielGuard is trained on a diverse mix of open and synthetic data covering standalone prompts, multi-turn conversations, and agentic workflows, augmented with structured reasoning traces to improve interpretability. Across multiple public and proprietary benchmarks, AprielGuard achieves strong performance in detecting harmful content and adversarial manipulations, outperforming existing opensource guardrails such as Llama-Guard and Granite Guardian, particularly in multi-step and reasoning intensive scenarios. By releasing the model, we aim to advance transparent and reproducible research on reliable safeguards for LLMs.

### 24. AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Honglin Mu, Jinghao Liu, Kaiyang Wan, Rui Xing, Xiuying Chen, Timothy Baldwin, Wanxiang Che
- **URL**: <http://arxiv.org/abs/2512.20164v1>
- **Submitted**: 2025-12-23 08:42:09
- **Topic Keywords**: search
- **Reason**: This paper focuses on AI security, specifically adversarial vulnerabilities in Large Language Models (LLMs), which is outside your primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on a related topic, the context and application are not aligned with your core research themes.

#### Abstract
> Large Language Models (LLMs) excel at text comprehension and generation, making them ideal for automated tasks like code review and content moderation. However, our research identifies a vulnerability: LLMs can be manipulated by "adversarial instructions" hidden in input data, such as resumes or code, causing them to deviate from their intended task. Notably, while defenses may exist for mature domains such as code review, they are often absent in other common applications such as resume screening and peer review. This paper introduces a benchmark to assess this vulnerability in resume screening, revealing attack success rates exceeding 80% for certain attack types. We evaluate two defense mechanisms: prompt-based defenses achieve 10.1% attack reduction with 12.5% false rejection increase, while our proposed FIDS (Foreign Instruction Detection through Separation) using LoRA adaptation achieves 15.4% attack reduction with 10.4% false rejection increase. The combined approach provides 26.3% attack reduction, demonstrating that training-time defenses outperform inference-time mitigations in both security and utility preservation.

### 25. Coherence in the brain unfolds across separable temporal regimes

- **LLM Score**: 0
- **Keyword Score**: 3
- **Authors**: Davide Stauba, Finn Rabe, Akhil Misra, Yves Pauli, Roya H√ºppi, Ni Yang, Nils Lang, Lars Michels, Victoria Edkins, Sascha Fr√ºhholz, Iris Sommer, Wolfram Hinzen, Philipp Homan
- **URL**: <http://arxiv.org/abs/2512.20481v2>
- **Submitted**: 2025-12-23 16:16:42
- **Topic Keywords**: ltr
- **Reason**: This paper appears to be unrelated to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The study focuses on neural mechanisms of language comprehension in the brain, which is a topic in cognitive neuroscience, not directly relevant to your areas of expertise.

#### Abstract
> Coherence in language requires the brain to satisfy two competing temporal demands: gradual accumulation of meaning across extended context and rapid reconfiguration of representations at event boundaries. Despite their centrality to language and thought, how these processes are implemented in the human brain during naturalistic listening remains unclear. Here, we tested whether these two processes can be captured by annotation-free drift and shift signals and whether their neural expression dissociates across large-scale cortical systems. These signals were derived from a large language model (LLM) and formalized contextual drift and event shifts directly from the narrative input. To enable high-precision voxelwise encoding models with stable parameter estimates, we densely sampled one healthy adult across more than 7 hours of listening to thirteen crime stories while collecting ultra high-field (7T) BOLD data. We then modeled the feature-informed hemodynamic response using a regularized encoding framework validated on independent stories. Drift predictions were prevalent in default-mode network hubs, whereas shift predictions were evident bilaterally in the primary auditory cortex and language association cortex. Furthermore, activity in default-mode and parietal networks was best explained by a signal capturing how meaning accumulates and gradually fades over the course of the narrative. Together, these findings show that coherence during language comprehension is implemented through dissociable neural regimes of slow contextual integration and rapid event-driven reconfiguration, offering a mechanistic entry point for understanding disturbances of language coherence in psychiatric disorders.

---

