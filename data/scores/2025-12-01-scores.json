[
    {
        "title": "CourseTimeQA: A Lecture-Video Benchmark and a Latency-Constrained Cross-Modal Fusion Method for Timestamped QA",
        "abstract": "We study timestamped question answering over educational lecture videos under a single-GPU latency/memory budget. Given a natural-language query, the system retrieves relevant timestamped segments and synthesizes a grounded answer. We present CourseTimeQA (52.3 h, 902 queries across six courses) and a lightweight, latency-constrained cross-modal retriever (CrossFusion-RAG) that combines frozen encoders, a learned 512->768 vision projection, shallow query-agnostic cross-attention over ASR and frames with a temporal-consistency regularizer, and a small cross-attentive reranker. On CourseTimeQA, CrossFusion-RAG improves nDCG@10 by 0.10 and MRR by 0.08 over a strong BLIP-2 retriever while achieving approximately 1.55 s median end-to-end latency on a single A100. Closest comparators (zero-shot CLIP multi-frame pooling; CLIP + cross-encoder reranker + MMR; learned late-fusion gating; text-only hybrid with cross-encoder reranking and its MMR variant; caption-augmented text retrieval; non-learned temporal smoothing) are evaluated under matched hardware and indexing. We report robustness across ASR noise (WER quartiles), diagnostics for temporal localization, and full training/tuning details to support reproducible comparison.",
        "url": "http://arxiv.org/abs/2512.00360v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00360v1",
        "arxiv_id": "2512.00360v1",
        "authors": [
            "Vsevolod Kovalev",
            "Parteek Kumar"
        ],
        "submitted": "2025-11-29 07:06:51",
        "source": "arxiv",
        "comment": "5 figures, 8 tables",
        "score": 20,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be primarily focused on a specific application of cross-modal fusion in educational lecture videos, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve query understanding and ranking models, the context and methodology are quite distinct from the user's areas of interest."
    },
    {
        "title": "SHRAG: AFrameworkfor Combining Human-Inspired Search with RAG",
        "abstract": "Retrieval-Augmented Generation (RAG) is gaining recognition as one of the key technological axes for next generation information retrieval, owing to its ability to mitigate the hallucination phenomenon in Large Language\n  Models (LLMs)and effectively incorporate up-to-date information. However, specialized expertise is necessary to\n  construct ahigh-quality retrieval system independently; moreover, RAGdemonstratesrelativelyslowerprocessing\n  speeds compared to conventional pure retrieval systems because it involves both retrieval and generation stages.\n  Accordingly, this study proposes SHRAG, a novel framework designed to facilitate the seamless integration of\n  Information Retrieval and RAG while simultaneously securing precise retrieval performance. SHRAG utilizes a\n  Large Language Model as a Query Strategist to automatically transform unstructured natural language queries\n  into logically structured search queries, subsequently performing Boolean retrieval to emulate the search process\n  of an expert human searcher. Furthermore, it incorporates multilingual query expansion and a multilingual\n  embedding model, enabling it to perform efficient cross-lingual question answering within the multilingual\n  dataset environment of the ScienceON Challenge. Experimental results demonstrate that the proposed method,\n  combining logical retrieval capabilities and generative reasoning, can significantly enhance the accuracy and\n  reliability of RAG systems. Furthermore, SHRAG movesbeyondconventionaldocument-centric retrieval methods,\n  presenting the potential for a new search paradigm capable of providing direct and reliable responses to queries.",
        "url": "http://arxiv.org/abs/2512.00772v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00772v1",
        "arxiv_id": "2512.00772v1",
        "authors": [
            "Hyunseok Ryu",
            "Wonjune Shin",
            "Hyun Park"
        ],
        "submitted": "2025-11-30 08:06:47",
        "source": "arxiv",
        "comment": "10 pages, 4 figures, 1 table, 1 algorithm, 3 prompts",
        "score": 14,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 9,
        "llm_reason": "This paper is extremely relevant to your research interests in Information Retrieval, particularly in the areas of query understanding, ranking models, and user behavior modeling. The proposed framework, SHRAG, integrates Retrieval-Augmented Generation (RAG) with Information Retrieval, addressing challenges such as hallucination and slower processing speeds. The paper's focus on logical retrieval capabilities and generative reasoning aligns with your interests in deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Evolving Paradigms in Task-Based Search and Learning: A Comparative Analysis of Traditional Search Engine with LLM-Enhanced Conversational Search System",
        "abstract": "Large Language Models (LLMs) are rapidly reshaping information retrieval by enabling interactive, generative, and inference-driven search. While traditional keyword-based search remains central to web and academic information access, it often struggles to support multi-step reasoning and exploratory learning tasks. LLM-powered search interfaces, such as ChatGPT and Claude, introduce new capabilities that may influence how users formulate queries, navigate information, and construct knowledge. However, empirical understanding of these effects is still limited. This study compares search behavior and learning outcomes in two environments: a standard search engine and an LLM-powered search system. We investigate (1) how search strategies, query formulation, and evaluation behaviors differ across systems, and (2) how LLM use affects comprehension, knowledge integration, and critical thinking during search-based learning tasks. Findings offer insight into how generative AI shapes information-seeking processes and contribute to ongoing discussions in information retrieval, human-AI interaction, and technology-supported learning.",
        "url": "http://arxiv.org/abs/2512.00313v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00313v1",
        "arxiv_id": "2512.00313v1",
        "authors": [
            "Zhitong Guan",
            "Yi Wang"
        ],
        "submitted": "2025-11-29 04:14:14",
        "source": "arxiv",
        "comment": null,
        "score": 12,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 9,
        "llm_reason": "This paper aligns closely with your research interests in Information Retrieval, particularly in the context of query understanding and user behavior modeling. The study's focus on the impact of Large Language Models on search behavior and learning outcomes is highly relevant to your work in query understanding and ranking models. The paper's exploration of human-AI interaction also touches on your interests in Natural Language Processing and related topics."
    },
    {
        "title": "Optimizing Generative Ranking Relevance via Reinforcement Learning in Xiaohongshu Search",
        "abstract": "Ranking relevance is a fundamental task in search engines, aiming to identify the items most relevant to a given user query. Traditional relevance models typically produce scalar scores or directly predict relevance labels, limiting both interpretability and the modeling of complex relevance signals. Inspired by recent advances in Chain-of-Thought (CoT) reasoning for complex tasks, we investigate whether explicit reasoning can enhance both interpretability and performance in relevance modeling. However, existing reasoning-based Generative Relevance Models (GRMs) primarily rely on supervised fine-tuning on large amounts of human-annotated or synthetic CoT data, which often leads to limited generalization. Moreover, domain-agnostic, free-form reasoning tends to be overly generic and insufficiently grounded, limiting its potential to handle the diverse and ambiguous cases prevalent in open-domain search. In this work, we formulate relevance modeling in Xiaohongshu search as a reasoning task and introduce a Reinforcement Learning (RL)-based training framework to enhance the grounded reasoning capabilities of GRMs. Specifically, we incorporate practical business-specific relevance criteria into the multi-step reasoning prompt design and propose Stepwise Advantage Masking (SAM), a lightweight process-supervision strategy which facilitates effective learning of these criteria through improved credit assignment. To enable industrial deployment, we further distill the large-scale RL-tuned model to a lightweight version suitable for real-world search systems. Extensive experiments on industrial datasets, along with online A/B tests, demonstrate the effectiveness of our approach.",
        "url": "http://arxiv.org/abs/2512.00968v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00968v1",
        "arxiv_id": "2512.00968v1",
        "authors": [
            "Ziyang Zeng",
            "Heming Jing",
            "Jindong Chen",
            "Xiangli Li",
            "Hongyu Liu",
            "Yixuan He",
            "Zhengyu Li",
            "Yige Sun",
            "Zheyong Xie",
            "Yuqing Yang",
            "Shaosheng Cao",
            "Jun Fan",
            "Yi Wu",
            "Yao Hu"
        ],
        "submitted": "2025-11-30 16:31:16",
        "source": "arxiv",
        "comment": "Accepted by KDD 2026 ADS Track",
        "score": 11,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, specifically in ranking models and relevance optimization. The use of reinforcement learning to enhance the grounded reasoning capabilities of Generative Relevance Models aligns with your focus on deep semantic understanding and real-time relevance optimization. However, the specific domain of Xiaohongshu search is not directly related to your e-commerce background."
    },
    {
        "title": "The Information Theory of Similarity",
        "abstract": "We establish a precise mathematical equivalence between witness-based similarity systems (REWA) and Shannon's information theory. We prove that witness overlap is mutual information, that REWA bit complexity bounds arise from channel capacity limitations, and that ranking-preserving encodings obey rate-distortion constraints. This unification reveals that fifty years of similarity search research -- from Bloom filters to locality-sensitive hashing to neural retrieval -- implicitly developed information theory for relational data. We derive fundamental lower bounds showing that REWA's $O(Δ^{-2} \\log N)$ complexity is optimal: no encoding scheme can preserve similarity rankings with fewer bits. The framework establishes that semantic similarity has physical units (bits of mutual information), search is communication (query transmission over a noisy channel), and retrieval systems face fundamental capacity limits analogous to Shannon's channel coding theorem.",
        "url": "http://arxiv.org/abs/2512.00378v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00378v1",
        "arxiv_id": "2512.00378v1",
        "authors": [
            "Nikit Phadke"
        ],
        "submitted": "2025-11-29 08:12:45",
        "source": "arxiv",
        "comment": null,
        "score": 10,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper establishes a mathematical equivalence between similarity systems and Shannon's information theory, which is somewhat related to the user's interests in Information Retrieval, particularly in query understanding and ranking models. However, the focus on similarity search and information theory is not directly aligned with the user's primary focus on deep semantic understanding and real-time relevance optimization. The paper's relevance is somewhat related but not a central match."
    },
    {
        "title": "Advancing Academic Chatbots: Evaluation of Non Traditional Outputs",
        "abstract": "Most evaluations of large language models focus on standard tasks such as factual question answering or short summarization. This research expands that scope in two directions: first, by comparing two retrieval strategies, Graph RAG, structured knowledge-graph based, and Advanced RAG, hybrid keyword-semantic search, for QA; and second, by evaluating whether LLMs can generate high quality non-traditional academic outputs, specifically slide decks and podcast scripts. We implemented a prototype combining Meta's LLaMA 3 70B open weight and OpenAI's GPT 4o mini API based. QA performance was evaluated using both human ratings across eleven quality dimensions and large language model judges for scalable cross validation. GPT 4o mini with Advanced RAG produced the most accurate responses. Graph RAG offered limited improvements and led to more hallucinations, partly due to its structural complexity and manual setup. Slide and podcast generation was tested with document grounded retrieval. GPT 4o mini again performed best, though LLaMA 3 showed promise in narrative coherence. Human reviewers were crucial for detecting layout and stylistic flaws, highlighting the need for combined human LLM evaluation in assessing emerging academic outputs.",
        "url": "http://arxiv.org/abs/2512.00991v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00991v1",
        "arxiv_id": "2512.00991v1",
        "authors": [
            "Nicole Favero",
            "Francesca Salute",
            "Daniel Hardt"
        ],
        "submitted": "2025-11-30 17:25:23",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'semantic search' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Information Retrieval (IR), specifically in the context of large language models and retrieval strategies. However, the focus on academic chatbots and non-traditional outputs is not directly aligned with your primary research themes of query understanding, ranking models, and user behavior modeling. The paper's relevance is limited to the NLP aspect of your research interests."
    },
    {
        "title": "ART: Adaptive Response Tuning Framework -- A Multi-Agent Tournament-Based Approach to LLM Response Optimization",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation. However, single-model responses often exhibit inconsistencies, hallucinations, and varying quality across different query domains. This paper presents ART (Adaptive Response Tuning), a novel framework that employs tournament-style ELO ranking and multi-agent reasoning to systematically optimize LLM outputs. By enabling multiple LLM agents to compete, critique, and collaborate through structured tournament workflows, ART produces consensus responses that outperform individual model outputs. Our framework introduces configurable tournament parameters, dynamic agent selection, and multiple consensus fusion strategies. Experimental evaluations demonstrate significant improvements in response accuracy, coherence, and reliability compared to baseline single-model approaches. The ART framework provides a scalable, production-ready solution for applications requiring high-quality, vetted LLM responses, achieving an 8.4% improvement in overall quality metrics and R22 values exceeding 0.96 in ELO rating convergence.",
        "url": "http://arxiv.org/abs/2512.00617v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00617v1",
        "arxiv_id": "2512.00617v1",
        "authors": [
            "Omer Jauhar Khan"
        ],
        "submitted": "2025-11-29 20:16:11",
        "source": "arxiv",
        "comment": "8 pages, 5 figures, 5 tables. Conference-style paper",
        "score": 7,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The paper's focus on optimizing Large Language Model (LLM) responses through a multi-agent tournament-based approach aligns with your interests in deep semantic understanding and real-time relevance optimization. The application of the framework in a production-ready solution also resonates with your e-commerce background."
    },
    {
        "title": "Comparative Analysis of 47 Context-Based Question Answer Models Across 8 Diverse Datasets",
        "abstract": "Context-based question answering (CBQA) models provide more accurate and relevant answers by considering the contextual information. They effectively extract specific information given a context, making them functional in various applications involving user support, information retrieval, and educational platforms. In this manuscript, we benchmarked the performance of 47 CBQA models from Hugging Face on eight different datasets. This study aims to identify the best-performing model across diverse datasets without additional fine-tuning. It is valuable for practical applications where the need to retrain models for specific datasets is minimized, streamlining the implementation of these models in various contexts. The best-performing models were trained on the SQuAD v2 or SQuAD v1 datasets. The best-performing model was ahotrod/electra_large_discriminator_squad2_512, which yielded 43\\% accuracy across all datasets. We observed that the computation time of all models depends on the context length and the model size. The model's performance usually decreases with an increase in the answer length. Moreover, the model's performance depends on the context complexity. We also used the Genetic algorithm to improve the overall accuracy by integrating responses from other models. ahotrod/electra_large_discriminator_squad2_512 generated the best results for bioasq10b-factoid (65.92\\%), biomedical\\_cpgQA (96.45\\%), QuAC (11.13\\%), and Question Answer Dataset (41.6\\%). Bert-large-uncased-whole-word-masking-finetuned-squad achieved an accuracy of 82\\% on the IELTS dataset.",
        "url": "http://arxiv.org/abs/2512.00323v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00323v1",
        "arxiv_id": "2512.00323v1",
        "authors": [
            "Muhammad Muneeb",
            "David B. Ascher",
            "Ahsan Baidar Bakht"
        ],
        "submitted": "2025-11-29 05:31:45",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'ctr' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "LLM scoring failed."
    },
    {
        "title": "Mitigating the Threshold Priming Effect in Large Language Model-Based Relevance Judgments via Personality Infusing",
        "abstract": "Recent research has explored LLMs as scalable tools for relevance labeling, but studies indicate they are susceptible to priming effects, where prior relevance judgments influence later ones. Although psychological theories link personality traits to such biases, it is unclear whether simulated personalities in LLMs exhibit similar effects. We investigate how Big Five personality profiles in LLMs influence priming in relevance labeling, using multiple LLMs on TREC 2021 and 2022 Deep Learning Track datasets. Our results show that certain profiles, such as High Openness and Low Neuroticism, consistently reduce priming susceptibility. Additionally, the most effective personality in mitigating priming may vary across models and task types. Based on these findings, we propose personality prompting as a method to mitigate threshold priming, connecting psychological evidence with LLM-based evaluation practices.",
        "url": "http://arxiv.org/abs/2512.00390v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00390v1",
        "arxiv_id": "2512.00390v1",
        "authors": [
            "Nuo Chen",
            "Hanpei Fang",
            "Jiqun Liu",
            "Wilson Wei",
            "Tetsuya Sakai",
            "Xiao-Ming Wu"
        ],
        "submitted": "2025-11-29 08:37:51",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'search' (score: +1)",
            "Found 'trec' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to information retrieval, but its focus on large language models and personality traits is more aligned with natural language processing. While it touches on relevance judgments, it's not directly related to query understanding, ranking models, or user behavior modeling, which are core areas of interest."
    },
    {
        "title": "Breaking It Down: Domain-Aware Semantic Segmentation for Retrieval Augmented Generation",
        "abstract": "Document chunking is a crucial component of Retrieval-Augmented Generation (RAG), as it directly affects the retrieval of relevant and precise context. Conventional fixed-length and recursive splitters often produce arbitrary, incoherent segments that fail to preserve semantic structure. Although semantic chunking has gained traction, its influence on generation quality remains underexplored. This paper introduces two efficient semantic chunking methods, Projected Similarity Chunking (PSC) and Metric Fusion Chunking (MFC), trained on PubMed data using three different embedding models. We further present an evaluation framework that measures the effect of chunking on both retrieval and generation by augmenting PubMedQA with full-text PubMed Central articles. Our results show substantial retrieval improvements (24x with PSC) in MRR and higher Hits@k on PubMedQA. We provide a comprehensive analysis, including statistical significance and response-time comparisons with common chunking libraries. Despite being trained on a single domain, PSC and MFC also generalize well, achieving strong out-of-domain generation performance across multiple datasets. Overall, our findings confirm that our semantic chunkers, especially PSC, consistently deliver superior performance.",
        "url": "http://arxiv.org/abs/2512.00367v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00367v1",
        "arxiv_id": "2512.00367v1",
        "authors": [
            "Aparajitha Allamraju",
            "Maitreya Prafulla Chitale",
            "Hiranmai Sri Adibhatla",
            "Rahul Mishra",
            "Manish Shrivastava"
        ],
        "submitted": "2025-11-29 07:30:37",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval augmented generation' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to the field of Information Retrieval, specifically in the area of Retrieval-Augmented Generation, which aligns with your interests in query understanding and ranking models. The paper introduces novel semantic chunking methods that improve retrieval performance, a key aspect of IR. While it does not directly focus on e-commerce, the techniques presented can be applied to various domains, making it a useful contribution to the field."
    },
    {
        "title": "Evidence-Guided Schema Normalization for Temporal Tabular Reasoning",
        "abstract": "Temporal reasoning over evolving semi-structured tables poses a challenge to current QA systems. We propose a SQL-based approach that involves (1) generating a 3NF schema from Wikipedia infoboxes, (2) generating SQL queries, and (3) query execution. Our central finding challenges model scaling assumptions: the quality of schema design has a greater impact on QA precision than model capacity. We establish three evidence-based principles: normalization that preserves context, semantic naming that reduces ambiguity, and consistent temporal anchoring. Our best configuration (Gemini 2.5 Flash schema + Gemini-2.0-Flash queries) achieves 80.39 EM, a 16.8\\% improvement over the baseline (68.89 EM).",
        "url": "http://arxiv.org/abs/2512.00329v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00329v1",
        "arxiv_id": "2512.00329v1",
        "authors": [
            "Ashish Thanga",
            "Vibhu Dixit",
            "Abhilash Shankarampeta",
            "Vivek Gupta"
        ],
        "submitted": "2025-11-29 05:40:08",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on temporal tabular reasoning and schema normalization, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves query execution and SQL-based approach, it does not explicitly address query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Dr.Mi-Bench: A Modular-integrated Benchmark for Scientific Deep Research Agent",
        "abstract": "The explosive growth in academic literature necessitates automated deep research (DR) agents, yet their evaluation remains a significant challenge. First, existing benchmarks often focus narrowly on retrieval while neglecting high-level planning and reasoning. Second, existing benchmarks favor general domains over the scientific domains that are the core application for DR agents. To address these gaps, we introduce Dr.Mi-Bench, a Modular-integrated benchmark for scientific DR agents. Grounded in academic literature, our benchmark uses a human-annotated dataset of 200 instances across 10 scientific domains, including both research and review papers. Besides, we also propose a Modular-integrated Evaluation Paradigm for DR Agents (Dr.Mi-Eval), a novel modular-integrated evaluation paradigm, which leverages the rich structure of academic papers to assess the core competencies of planning, retrieval, and reasoning through two complementary modes: an end-to-end evaluation for DR agents and an isolated evaluation for foundational LLMs as potential backbones. Experimental results reveal a fragmented performance landscape: agents exhibit specialized strengths but share critical weaknesses, most notably in performing the multi-source retrieval required for review-style tasks and performing consistently across diverse scientific fields. Moreover, improving high-level planning capability is the crucial factor for unlocking the reasoning potential of foundational LLMs as backbones. By exposing these actionable failure modes, Dr.Mi-Bench provides a diagnostic tool to guide the development of more reliable academic research assistants.",
        "url": "http://arxiv.org/abs/2512.00986v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00986v1",
        "arxiv_id": "2512.00986v1",
        "authors": [
            "Zhihan Guo",
            "Feiyang Xu",
            "Yifan Li",
            "Muzhi Li",
            "Shuai Zou",
            "Jiele Wu",
            "Han Shi",
            "Haoli Bai",
            "Ho-fung Leung",
            "Irwin King"
        ],
        "submitted": "2025-11-30 17:16:47",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a benchmark for scientific deep research agents, which is somewhat related to information retrieval and search technologies. However, the focus is on high-level planning and reasoning, and the evaluation paradigm is more aligned with natural language processing and data mining. While the paper touches on retrieval, it is not the primary focus, and the relevance to the user's core research themes is limited."
    },
    {
        "title": "DLRREC: Denoising Latent Representations via Multi-Modal Knowledge Fusion in Deep Recommender Systems",
        "abstract": "Modern recommender systems struggle to effectively utilize the rich, yet high-dimensional and noisy, multi-modal features generated by Large Language Models (LLMs). Treating these features as static inputs decouples them from the core recommendation task. We address this limitation with a novel framework built on a key insight: deeply fusing multi-modal and collaborative knowledge for representation denoising. Our unified architecture introduces two primary technical innovations. First, we integrate dimensionality reduction directly into the recommendation model, enabling end-to-end co-training that makes the reduction process aware of the final ranking objective. Second, we introduce a contrastive learning objective that explicitly incorporates the collaborative filtering signal into the latent space. This synergistic process refines raw LLM embeddings, filtering noise while amplifying task-relevant signals. Extensive experiments confirm our method's superior discriminative power, proving that this integrated fusion and denoising strategy is critical for achieving state-of-the-art performance. Our work provides a foundational paradigm for effectively harnessing LLMs in recommender systems.",
        "url": "http://arxiv.org/abs/2512.00596v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00596v1",
        "arxiv_id": "2512.00596v1",
        "authors": [
            "Jiahao Tian",
            "Zhenkai Wang"
        ],
        "submitted": "2025-11-29 18:57:42",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on recommender systems, which is related to your interests in Information Retrieval and Search technologies. However, the primary focus is on deep learning and recommender systems, which is somewhat tangential to your core research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Statistical NLP for Optimization of Clinical Trial Success Prediction in Pharmaceutical R&D",
        "abstract": "This work presents the development and evaluation of an NLP-enabled probabilistic classifier designed to estimate the probability of technical and regulatory success (pTRS) for clinical trials in the field of neuroscience. While pharmaceutical R&D is plagued by high attrition rates and enormous costs, particularly within neuroscience, where success rates are below 10%, timely identification of promising programs can streamline resource allocation and reduce financial risk. Leveraging data from the ClinicalTrials.gov database and success labels from the recently developed Clinical Trial Outcome dataset, the classifier extracts text-based clinical trial features using statistical NLP techniques. These features were integrated into several non-LLM frameworks (logistic regression, gradient boosting, and random forest) to generate calibrated probability scores. Model performance was assessed on a retrospective dataset of 101,145 completed clinical trials spanning 1976-2024, achieving an overall ROC-AUC of 0.64. An LLM-based predictive model was then built using BioBERT, a domain-specific language representation encoder. The BioBERT-based model achieved an overall ROC-AUC of 0.74 and a Brier Score of 0.185, indicating its predictions had, on average, 40% less squared error than would be observed using industry benchmarks. The BioBERT-based model also made trial outcome predictions that were superior to benchmark values 70% of the time overall. By integrating NLP-driven insights into drug development decision-making, this work aims to enhance strategic planning and optimize investment allocation in neuroscience programs.",
        "url": "http://arxiv.org/abs/2512.00586v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00586v1",
        "arxiv_id": "2512.00586v1",
        "authors": [
            "Michael R. Doane"
        ],
        "submitted": "2025-11-29 18:40:42",
        "source": "arxiv",
        "comment": "Doctor of Engineering Praxis Dissertation, The George Washington University. 122 pages. Present affiliation: Iambic Therapeutics",
        "score": 5,
        "keyword_reasons": [
            "Found 'ltr' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "LLM scoring failed."
    },
    {
        "title": "CACARA: Cross-Modal Alignment Leveraging a Text-Centric Approach for Cost-Effective Multimodal and Multilingual Learning",
        "abstract": "As deep learning models evolve, new applications and challenges are rapidly emerging. Tasks that once relied on a single modality, such as text, images, or audio, are now enriched by seamless interactions between multimodal data. These connections bridge information gaps: an image can visually materialize a text, while audio can add context to an image. Researchers have developed numerous multimodal models, but most rely on resource-intensive training across multiple modalities. Similarly, extending these models to new languages often follows the same resource-heavy training strategy. In this work, we propose a multimodal and multilingual architecture, CACARA, trained through emergent alignment learning, enabling the seamless integration of new modalities into an existing bimodal/multimodal model without requiring full retraining. This work breaks new ground by demonstrating that this emergent alignment paradigm can unlock multilingual capabilities from monolingual training. By fine-tuning the newly incorporated modality only on data aligned with the English language, our model develops support for over 100 languages without explicit multilingual pretraining or tuning of the text encoder. Such emergent multimodal and multilingual properties are gained efficiently, preserving previously learned knowledge at a training cost comparable to that of a monolingual model. Our strategy achieves up to a 14.24 percentage points improvement in R@1 audio-to-text retrieval, outperforming state-of-the-art multimodal models -- all without the heavy computational cost of retraining across every modality and language.",
        "url": "http://arxiv.org/abs/2512.00496v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00496v1",
        "arxiv_id": "2512.00496v1",
        "authors": [
            "Diego A. B. Moreira",
            "Alef I. Ferreira",
            "Jhessica Silva",
            "Gabriel O. dos Santos",
            "Gustavo Bonil",
            "João Gondim",
            "Marina dos Santos",
            "Helena Maia",
            "Simone Hashiguti",
            "Nádia da Silva",
            "Carolina Scarton",
            "Helio Pedrini",
            "Sandra Avila"
        ],
        "submitted": "2025-11-29 14:04:27",
        "source": "arxiv",
        "comment": "25 pages, 12 tables, 5 figures",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a multimodal and multilingual architecture, CACARA, which leverages emergent alignment learning to integrate new modalities into an existing model. While it touches on the concept of multimodal interactions, it does not directly address query understanding, ranking models, or user behavior modeling in information retrieval, which are core areas of your research interests."
    },
    {
        "title": "Evaluating Legal Reasoning Traces with Legal Issue Tree Rubrics",
        "abstract": "Evaluating the quality of LLM-generated reasoning traces in expert domains (e.g., law) is essential for ensuring credibility and explainability, yet remains challenging due to the inherent complexity of such reasoning tasks. We introduce LEGIT (LEGal Issue Trees), a novel large-scale (24K instances) expert-level legal reasoning dataset with an emphasis on reasoning trace evaluation. We convert court judgments into hierarchical trees of opposing parties' arguments and the court's conclusions, which serve as rubrics for evaluating the issue coverage and correctness of the reasoning traces. We verify the reliability of these rubrics via human expert annotations and comparison with coarse, less informative rubrics. Using the LEGIT dataset, we show that (1) LLMs' legal reasoning ability is seriously affected by both legal issue coverage and correctness, and that (2) retrieval-augmented generation (RAG) and RL with rubrics bring complementary benefits for legal reasoning abilities, where RAG improves overall reasoning capability, whereas RL improves correctness albeit with reduced coverage.",
        "url": "http://arxiv.org/abs/2512.01020v1",
        "pdf_url": "https://arxiv.org/pdf/2512.01020v1",
        "arxiv_id": "2512.01020v1",
        "authors": [
            "Jinu Lee",
            "Kyoung-Woon On",
            "Simeng Han",
            "Arman Cohan",
            "Julia Hockenmaier"
        ],
        "submitted": "2025-11-30 18:32:43",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on evaluating legal reasoning traces in the law domain, which is not a primary area of interest for you. While it involves some aspects of information retrieval, such as retrieval-augmented generation, the context and application are quite different from your usual research themes."
    },
    {
        "title": "Wikontic: Constructing Wikidata-Aligned, Ontology-Aware Knowledge Graphs with Large Language Models",
        "abstract": "Knowledge graphs (KGs) provide structured, verifiable grounding for large language models (LLMs), but current LLM-based systems commonly use KGs as auxiliary structures for text retrieval, leaving their intrinsic quality underexplored. In this work, we propose Wikontic, a multi-stage pipeline that constructs KGs from open-domain text by extracting candidate triplets with qualifiers, enforcing Wikidata-based type and relation constraints, and normalizing entities to reduce duplication. The resulting KGs are compact, ontology-consistent, and well-connected; on MuSiQue, the correct answer entity appears in 96% of generated triplets. On HotpotQA, our triplets-only setup achieves 76.0 F1, and on MuSiQue 59.8 F1, matching or surpassing several retrieval-augmented generation baselines that still require textual context. In addition, Wikontic attains state-of-the-art information-retention performance on the MINE-1 benchmark (86%), outperforming prior KG construction methods. Wikontic is also efficient at build time: KG construction uses less than 1,000 output tokens, about 3$\\times$ fewer than AriGraph and $<$1/20 of GraphRAG. The proposed pipeline enhances the quality of the generated KG and offers a scalable solution for leveraging structured knowledge in LLMs.",
        "url": "http://arxiv.org/abs/2512.00590v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00590v1",
        "arxiv_id": "2512.00590v1",
        "authors": [
            "Alla Chepurova",
            "Aydar Bulatov",
            "Yuri Kuratov",
            "Mikhail Burtsev"
        ],
        "submitted": "2025-11-29 18:44:25",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of leveraging structured knowledge in large language models. However, it focuses more on knowledge graph construction and quality assessment, rather than query understanding, ranking models, or user behavior modeling. While it touches on the intersection of IR and NLP, it doesn't directly align with your core research themes."
    },
    {
        "title": "Associative Syntax and Maximal Repetitions reveal context-dependent complexity in fruit bat communication",
        "abstract": "This study presents an unsupervised method to infer discreteness, syntax and temporal structures of fruit-bats vocalizations, as a case study of graded vocal systems, and evaluates the complexity of communication patterns in relation with behavioral context. The method improved the baseline for unsupervised labeling of vocal units (i.e. syllables) through manifold learning, by investigating how dimen- sionality reduction on mel-spectrograms affects labeling, and comparing it with unsupervised labels based on acoustic similarity. We then encoded vocalizations as syllabic sequences to analyze the type of syntax, and extracted the Maximal Repetitions (MRs) to evaluate syntactical structures. We found evidence for: i) associative syntax, rather than combinatorial (context classification is unaffected by permutation of sequences, F 1 > 0.9); ii) context-dependent use of syllables (Wilcoxon rank-sum tests, p-value < 0.05); iii) heavy-tail distribution of MRs (truncated power-law, exponent α < 2), indicative of mechanism encoding com- binatorial complexity. Analysis of MRs and syllabic transition networks revealed that mother-pupil interactions were characterized by repetitions, while commu- nication in conflict-contexts exhibited higher complexity (longer MRs and more interconnected vocal sequences) than non-agonistic contexts. We propose that communicative complexity is higher in scenarios of disagreement, reflecting lower compressibility of information.",
        "url": "http://arxiv.org/abs/2512.01033v1",
        "pdf_url": "https://arxiv.org/pdf/2512.01033v1",
        "arxiv_id": "2512.01033v1",
        "authors": [
            "Luigi Assom"
        ],
        "submitted": "2025-11-30 19:01:59",
        "source": "arxiv",
        "comment": "Accepted for a lightning talk at the NeurIPS 2025 Workshop: \"AI for Non-Human Animal Communication\"",
        "score": 3,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing, as it focuses on the analysis of fruit bat communication patterns using unsupervised methods and manifold learning."
    },
    {
        "title": "Towards Active Synthetic Data Generation for Finetuning Language Models",
        "abstract": "A common and effective means for improving language model capabilities involves finetuning a ``student'' language model's parameters on generations from a more proficient ``teacher'' model. Termed ``synthetic data'', these generations are often produced before any student finetuning, but some work has considered generating new synthetic samples as training progresses. This paper studies and advocates for the latter case, where data are generated in an iterative, closed-loop fashion that is guided by the current state of the student model. For a fixed budget of generated samples, or a budget in terms of compute spent querying a teacher, we show that this curation of finetuning data affords improved student performance over static generation. Further, while there have been several LLM-specific methods proposed that operate in this regime, we find that simple, inexpensive selection criteria from the active learning literature tend to be most performant. We validate these claims across four mathematical and logical reasoning datasets using four different small language models.",
        "url": "http://arxiv.org/abs/2512.00884v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00884v1",
        "arxiv_id": "2512.00884v1",
        "authors": [
            "Samuel Kessler",
            "Menglin Xia",
            "Daniel Madrigal Diaz",
            "Dongge Han",
            "Helia Heshemi",
            "Saravan Rajmohan",
            "Victor Ruehle",
            "Jordan T. Ash"
        ],
        "submitted": "2025-11-30 13:13:00",
        "source": "arxiv",
        "comment": "14 figures, 36 pages",
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on language model finetuning and synthetic data generation, which is outside your primary areas of interest in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions language models, it does not relate to query understanding, ranking models, or user behavior modeling, which are key aspects of your research."
    },
    {
        "title": "WaterSearch: A Quality-Aware Search-based Watermarking Framework for Large Language Models",
        "abstract": "Watermarking acts as a critical safeguard in text generated by Large Language Models (LLMs). By embedding identifiable signals into model outputs, watermarking enables reliable attribution and enhances the security of machine-generated content. Existing approaches typically embed signals by manipulating token generation probabilities. Despite their effectiveness, these methods inherently face a trade-off between detectability and text quality: the signal strength and randomness required for robust watermarking tend to degrade the performance of downstream tasks.\n  In this paper, we design a novel embedding scheme that controls seed pools to facilitate diverse parallel generation of watermarked text. Based on that scheme, we propose WaterSearch, a sentence-level, search-based watermarking framework adaptable to a wide range of existing methods. WaterSearch enhances text quality by jointly optimizing two key aspects: 1) distribution fidelity and 2) watermark signal characteristics. Furthermore, WaterSearch is complemented by a sentence-level detection method with strong attack robustness. We evaluate our method on three popular LLMs across ten diverse tasks. Extensive experiments demonstrate that our method achieves an average performance improvement of 51.01\\% over state-of-the-art baselines at a watermark detectability strength of 95\\%. In challenging scenarios such as short text generation and low-entropy output generation, our method yields performance gains of 47.78\\% and 36.47\\%, respectively. Moreover, under different attack senarios including insertion, synonym substitution and paraphrase attasks, WaterSearch maintains high detectability, further validating its robust anti-attack capabilities. Our code is available at \\href{https://github.com/Yukang-Lin/WaterSearch}{https://github.com/Yukang-Lin/WaterSearch}.",
        "url": "http://arxiv.org/abs/2512.00837v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00837v1",
        "arxiv_id": "2512.00837v1",
        "authors": [
            "Yukang Lin",
            "Jiahao Shao",
            "Shuoran Jiang",
            "Wentao Zhu",
            "Bingjie Lu",
            "Xiangping Wu",
            "Joanna Siebert",
            "Qingcai Chen"
        ],
        "submitted": "2025-11-30 11:11:21",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on watermarking techniques for Large Language Models, which is a specific application in NLP. While it involves search-based methods, the context is not directly related to information retrieval, query understanding, or ranking models, which are core areas of interest for the user."
    },
    {
        "title": "Probing the \"Psyche'' of Large Reasoning Models: Understanding Through a Human Lens",
        "abstract": "Large reasoning models (LRMs) have garnered significant attention from researchers owing to their exceptional capability in addressing complex tasks. Motivated by the observed human-like behaviors in their reasoning processes, this paper introduces a comprehensive taxonomy to characterize atomic reasoning steps and probe the ``psyche'' of LRM intelligence. Specifically, it comprises five groups and seventeen categories derived from human mental processes, thereby grounding the understanding of LRMs in an interdisciplinary perspective. The taxonomy is then applied for an in-depth understanding of current LRMs, resulting in a distinct labeled dataset that comprises 277,534 atomic reasoning steps. Using this resource, we analyze contemporary LRMs and distill several actionable takeaways for improving training and post-training of reasoning models. Notably, our analysis reveals that prevailing post-answer ``double-checks'' (self-monitoring evaluations) are largely superficial and rarely yield substantive revisions. Thus, incentivizing comprehensive multi-step reflection, rather than simple self-monitoring, may offer a more effective path forward. To complement the taxonomy, an automatic annotation framework, named CAPO, is proposed to leverage large language models (LLMs) for generating the taxonomy-based annotations. Experimental results demonstrate that CAPO achieves higher consistency with human experts compared to baselines, facilitating a scalable and comprehensive analysis of LRMs from a human cognitive perspective. Together, the taxonomy, CAPO, and the derived insights provide a principled, scalable path toward understanding and advancing LRM reasoning.",
        "url": "http://arxiv.org/abs/2512.00729v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00729v1",
        "arxiv_id": "2512.00729v1",
        "authors": [
            "Yuxiang Chen",
            "Zuohan Wu",
            "Ziwei Wang",
            "Xiangning Yu",
            "Xujia Li",
            "Linyi Yang",
            "Mengyue Yang",
            "Jun Wang",
            "Lei Chen"
        ],
        "submitted": "2025-11-30 04:49:44",
        "source": "arxiv",
        "comment": "13 pages",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on understanding the reasoning processes of large language models from a human cognitive perspective, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing, the context is more aligned with NLP applications rather than IR or search technologies."
    },
    {
        "title": "ProEx: A Unified Framework Leveraging Large Language Model with Profile Extrapolation for Recommendation",
        "abstract": "The powerful text understanding and generation capabilities of large language models (LLMs) have brought new vitality to general recommendation with implicit feedback. One possible strategy involves generating a unique user (or item) profile from historical interaction data, which is then mapped to a semantic representation in the language space. However, a single-instance profile may be insufficient to comprehensively capture the complex intentions behind a user's interacted items. Moreover, due to the inherent instability of LLMs, a biased or misinterpreted profile could even undermine the original recommendation performance. Consequently, an intuitive solution is to generate multiple profiles for each user (or item), each reflecting a distinct aspect of their characteristics. In light of this, we propose a unified recommendation framework with multi-faceted profile extrapolation (ProEx) in this paper. By leveraging chain-of-thought reasoning, we construct multiple distinct profiles for each user and item. These new profiles are subsequently mapped into semantic vectors, extrapolating from the position of the original profile to explore a broader region of the language space. Subsequently, we introduce the concept of environments, where each environment represents a possible linear combination of all profiles. The differences across environments are minimized to reveal the inherent invariance of user preferences. We apply ProEx to three discriminative methods and three generative methods, and conduct extensive experiments on three datasets. The experimental results demonstrate that ProEx significantly enhances the performance of these base recommendation models.",
        "url": "http://arxiv.org/abs/2512.00679v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00679v1",
        "arxiv_id": "2512.00679v1",
        "authors": [
            "Yi Zhang",
            "Yiwen Zhang",
            "Yu Wang",
            "Tong Chen",
            "Hongzhi Yin"
        ],
        "submitted": "2025-11-30 00:24:24",
        "source": "arxiv",
        "comment": "Accepted by KDD 2026 (First Cycle)",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on recommendation systems, leveraging large language models and profile extrapolation, which is somewhat related to information retrieval and search technologies. However, the primary focus on recommendation systems and user profiling is not a central match to your core research themes in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Prism: A Minimal Compositional Metalanguage for Specifying Agent Behavior",
        "abstract": "Prism is a small, compositional metalanguage for specifying the behaviour of tool-using software agents. Rather than introducing ad hoc control constructs, Prism is built around a fixed core context, Core1, which provides a minimal background grammar of categories numbers, strings, user prompts, tools together with abstract combinators for booleans, predicates, pairs, and lists. Agent policies are written as ordinary expressions using a single abstraction operator so that conditionals appear as selections between alternatives instead of imperative if-else blocks. Domains extend the core by defining their own context-mini-grammars that introduce new categories, predicates, and external tools while reusing the same compositional machinery. We illustrate this with worked examples from thermostat control, home security, e-commerce recommendation, and medical monitoring, showing how natural language decision rules can be mapped to inspectable, executable policies. From a linguistic perspective, Prism enforces a clear separation between a reusable grammar-like core and domain specific lexicons and treats tools as bridges between internal policy representations and the external world. From an engineering perspective, it offers a compact interface language for agent control, making the space of possible actions explicit and amenable to analysis, verification, and safety constraints.",
        "url": "http://arxiv.org/abs/2512.00611v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00611v1",
        "arxiv_id": "2512.00611v1",
        "authors": [
            "Franck Binard",
            "Vanja Kljajevic"
        ],
        "submitted": "2025-11-29 19:52:21",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on e-commerce recommendation, the focus is on specifying agent behavior using a compositional metalanguage, which is not a central theme in your research."
    },
    {
        "title": "Catch Me If You Can: How Smaller Reasoning Models Pretend to Reason with Mathematical Fidelity",
        "abstract": "Current evaluation of mathematical reasoning in language models relies primarily on answer accuracy, potentially masking fundamental failures in logical computation. We introduce a diagnostic framework that distinguishes genuine mathematical reasoning from superficial pattern matching through four complementary axes: forward-backward consistency, transitivity coverage, counterfactual sensitivity, and perturbation robustness. Through a case study applying this framework to Qwen3-0.6B on the MenatQA dataset, we reveal a striking disconnect between surface performance and reasoning fidelity. While the model achieves reasonable answer accuracy (70%+), it demonstrates poor backward consistency (15%), limited transitivity coverage (32.2%), and brittle sensitivity to perturbations. Our diagnostics expose reasoning failures invisible to traditional accuracy metrics, suggesting that this small model relies heavily on pattern matching rather than genuine logical computation. While our empirical findings are based on a single 600M-parameter model, the diagnostic framework itself is model-agnostic and generalizable. We release our evaluation protocols to enable the research community to assess reasoning fidelity across different model scales and architectures, moving beyond surface-level accuracy toward verifiable mathematical reasoning.",
        "url": "http://arxiv.org/abs/2512.00552v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00552v1",
        "arxiv_id": "2512.00552v1",
        "authors": [
            "Subramanyam Sahoo",
            "Vinija Jain",
            "Saanidhya Vats",
            "Siddharth Mohapatra",
            "Rui Min",
            "Aman Chadha",
            "Divya Chaudhary"
        ],
        "submitted": "2025-11-29 16:47:01",
        "source": "arxiv",
        "comment": "8 pages, 5 figures. A preprint. Initial Work",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and deep semantic understanding, but it focuses on mathematical reasoning in language models rather than information retrieval or search technologies. The diagnostic framework introduced in the paper could potentially be applied to other areas of NLP, but its direct relevance to the user's core research themes is limited."
    },
    {
        "title": "CryptoBench: A Dynamic Benchmark for Expert-Level Evaluation of LLM Agents in Cryptocurrency",
        "abstract": "This paper introduces CryptoBench, the first expert-curated, dynamic benchmark designed to rigorously evaluate the real-world capabilities of Large Language Model (LLM) agents in the uniquely demanding and fast-paced cryptocurrency domain. Unlike general-purpose agent benchmarks for search and prediction, professional crypto analysis presents specific challenges: \\emph{extreme time-sensitivity}, \\emph{a highly adversarial information environment}, and the critical need to synthesize data from \\emph{diverse, specialized sources}, such as on-chain intelligence platforms and real-time Decentralized Finance (DeFi) dashboards. CryptoBench thus serves as a much more challenging and valuable scenario for LLM agent assessment. To address these challenges, we constructed a live, dynamic benchmark featuring 50 questions per month, expertly designed by crypto-native professionals to mirror actual analyst workflows. These tasks are rigorously categorized within a four-quadrant system: Simple Retrieval, Complex Retrieval, Simple Prediction, and Complex Prediction. This granular categorization enables a precise assessment of an LLM agent's foundational data-gathering capabilities alongside its advanced analytical and forecasting skills.\n  Our evaluation of ten LLMs, both directly and within an agentic framework, reveals a performance hierarchy and uncovers a failure mode. We observe a \\textit{retrieval-prediction imbalance}, where many leading models, despite being proficient at data retrieval, demonstrate a pronounced weakness in tasks requiring predictive analysis. This highlights a problematic tendency for agents to appear factually grounded while lacking the deeper analytical capabilities to synthesize information.",
        "url": "http://arxiv.org/abs/2512.00417v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00417v1",
        "arxiv_id": "2512.00417v1",
        "authors": [
            "Jiacheng Guo",
            "Suozhi Huang",
            "Zixin Yao",
            "Yifan Zhang",
            "Yifu Lu",
            "Jiashuo Liu",
            "Zihao Li",
            "Yanyan Deng",
            "Qixin Xiao",
            "Jia Tian",
            "Kanghong Zhan",
            "Tianyi Li",
            "Xiaochen Liu",
            "Jason Ge",
            "Chaoyang He",
            "Kaixuan Huang",
            "Lin Yang",
            "Wenhao Huang",
            "Mengdi Wang"
        ],
        "submitted": "2025-11-29 09:52:34",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to information retrieval, but its focus on Large Language Model (LLM) agents in the cryptocurrency domain and expert-level evaluation is not directly aligned with your core research themes in query understanding, ranking models, and user behavior modeling. While it touches on data retrieval, the primary emphasis is on predictive analysis and agent assessment, which is not a central match for your research interests."
    },
    {
        "title": "Towards Corpus-Grounded Agentic LLMs for Multilingual Grammatical Analysis",
        "abstract": "Empirical grammar research has become increasingly data-driven, but the systematic analysis of annotated corpora still requires substantial methodological and technical effort. We explore how agentic large language models (LLMs) can streamline this process by reasoning over annotated corpora and producing interpretable, data-grounded answers to linguistic questions. We introduce an agentic framework for corpus-grounded grammatical analysis that integrates concepts such as natural-language task interpretation, code generation, and data-driven reasoning. As a proof of concept, we apply it to Universal Dependencies (UD) corpora, testing it on multilingual grammatical tasks inspired by the World Atlas of Language Structures (WALS). The evaluation spans 13 word-order features and over 170 languages, assessing system performance across three complementary dimensions - dominant-order accuracy, order-coverage completeness, and distributional fidelity - which reflect how well the system generalizes, identifies, and quantifies word-order variations. The results demonstrate the feasibility of combining LLM reasoning with structured linguistic data, offering a first step toward interpretable, scalable automation of corpus-based grammatical inquiry.",
        "url": "http://arxiv.org/abs/2512.00214v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00214v1",
        "arxiv_id": "2512.00214v1",
        "authors": [
            "Matej Klemen",
            "Tjaša Arčon",
            "Luka Terčon",
            "Marko Robnik-Šikonja",
            "Kaja Dobrovoljc"
        ],
        "submitted": "2025-11-28 21:27:58",
        "source": "arxiv",
        "comment": "Pre-print, submission under review",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multilingual grammatical analysis using large language models, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific application and methodology are quite different from the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "When Safety Blocks Sense: Measuring Semantic Confusion in LLM Refusals",
        "abstract": "Safety-aligned language models often refuse prompts that are actually harmless. Current evaluations mostly report global rates such as false rejection or compliance. These scores treat each prompt alone and miss local inconsistency, where a model accepts one phrasing of an intent but rejects a close paraphrase. This gap limits diagnosis and tuning. We introduce \"semantic confusion,\" a failure mode that captures such local inconsistency, and a framework to measure it. We build ParaGuard, a 10k-prompt corpus of controlled paraphrase clusters that hold intent fixed while varying surface form. We then propose three model-agnostic metrics at the token level: Confusion Index, Confusion Rate, and Confusion Depth. These metrics compare each refusal to its nearest accepted neighbors and use token embeddings, next-token probabilities, and perplexity signals. Experiments across diverse model families and deployment guards show that global false-rejection rate hides critical structure. Our metrics reveal globally unstable boundaries in some settings, localized pockets of inconsistency in others, and cases where stricter refusal does not increase inconsistency. We also show how confusion-aware auditing separates how often a system refuses from how sensibly it refuses. This gives developers a practical signal to reduce false refusals while preserving safety.",
        "url": "http://arxiv.org/abs/2512.01037v1",
        "pdf_url": "https://arxiv.org/pdf/2512.01037v1",
        "arxiv_id": "2512.01037v1",
        "authors": [
            "Riad Ahmed Anonto",
            "Md Labid Al Nahiyan",
            "Md Tanvir Hassan",
            "Ch. Md. Rakin Haider"
        ],
        "submitted": "2025-11-30 19:11:45",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Information Retrieval (IR), particularly in the context of language models and their evaluation. However, the focus on safety-aligned language models and semantic confusion in LLM refusals is not directly aligned with your primary interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Table as a Modality for Large Language Models",
        "abstract": "To migrate the remarkable successes of Large Language Models (LLMs), the community has made numerous efforts to generalize them to the table reasoning tasks for the widely deployed tabular data. Despite that, in this work, by showing a probing experiment on our proposed StructQA benchmark, we postulate that even the most advanced LLMs (such as GPTs) may still fall short of coping with tabular data. More specifically, the current scheme often simply relies on serializing the tabular data, together with the meta information, then inputting them through the LLMs. We argue that the loss of structural information is the root of this shortcoming. In this work, we further propose TAMO, which bears an ideology to treat the tables as an independent modality integrated with the text tokens. The resulting model in TAMO is a multimodal framework consisting of a hypergraph neural network as the global table encoder seamlessly integrated with the mainstream LLM. Empirical results on various benchmarking datasets, including HiTab, WikiTQ, WikiSQL, FeTaQA, and StructQA, have demonstrated significant improvements on generalization with an average relative gain of 42.65%.",
        "url": "http://arxiv.org/abs/2512.00947v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00947v1",
        "arxiv_id": "2512.00947v1",
        "authors": [
            "Liyao Li",
            "Chao Ye",
            "Wentao Ye",
            "Yifei Sun",
            "Zhe Jiang",
            "Haobo Wang",
            "Jiaming Tian",
            "Yiming Zhang",
            "Ningtao Wang",
            "Xing Fu",
            "Gang Chen",
            "Junbo Zhao"
        ],
        "submitted": "2025-11-30 15:59:56",
        "source": "arxiv",
        "comment": "Accepted to NeurIPS 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Large Language Models and their application to table reasoning tasks, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves multimodal frameworks and neural networks, the primary goal is to improve generalization on table reasoning tasks, which is not a central match for the user's interests."
    },
    {
        "title": "Mitigating Hallucinations in Zero-Shot Scientific Summarisation: A Pilot Study",
        "abstract": "Large language models (LLMs) produce context inconsistency hallucinations, which are LLM generated outputs that are misaligned with the user prompt. This research project investigates whether prompt engineering (PE) methods can mitigate context inconsistency hallucinations in zero-shot LLM summarisation of scientific texts, where zero-shot indicates that the LLM relies purely on its pre-training data. Across eight yeast biotechnology research paper abstracts, six instruction-tuned LLMs were prompted with seven methods: a base- line prompt, two levels of increasing instruction complexity (PE-1 and PE-2), two levels of context repetition (CR-K1 and CR-K2), and two levels of random addition (RA-K1 and RA-K2). Context repetition involved the identification and repetition of K key sentences from the abstract, whereas random addition involved the repetition of K randomly selected sentences from the abstract, where K is 1 or 2. A total of 336 LLM-generated summaries were evaluated using six metrics: ROUGE-1, ROUGE-2, ROUGE-L, BERTScore, METEOR, and cosine similarity, which were used to compute the lexical and semantic alignment be- tween the summaries and the abstracts. Four hypotheses on the effects of prompt methods on summary alignment with the reference text were tested. Statistical analysis on 3744 collected datapoints was performed using bias-corrected and accelerated (BCa) bootstrap confidence intervals and Wilcoxon signed-rank tests with Bonferroni-Holm correction. The results demonstrated that CR and RA significantly improve the lexical alignment of LLM-generated summaries with the abstracts. These findings indicate that prompt engineering has the potential to impact hallucinations in zero-shot scientific summarisation tasks.",
        "url": "http://arxiv.org/abs/2512.00931v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00931v1",
        "arxiv_id": "2512.00931v1",
        "authors": [
            "Imane Jaaouine",
            "Ross D. King"
        ],
        "submitted": "2025-11-30 15:19:41",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and information retrieval, specifically in the context of zero-shot scientific summarization. However, it focuses more on mitigating hallucinations in summarization rather than query understanding, ranking models, or user behavior modeling, which are your core areas of interest."
    },
    {
        "title": "One Swallow Does Not Make a Summer: Understanding Semantic Structures in Embedding Spaces",
        "abstract": "Embedding spaces are fundamental to modern AI, translating raw data into high-dimensional vectors that encode rich semantic relationships. Yet, their internal structures remain opaque, with existing approaches often sacrificing semantic coherence for structural regularity or incurring high computational overhead to improve interpretability. To address these challenges, we introduce the Semantic Field Subspace (SFS), a geometry-preserving, context-aware representation that captures local semantic neighborhoods within the embedding space. We also propose SAFARI (SemAntic Field subspAce deteRmInation), an unsupervised, modality-agnostic algorithm that uncovers hierarchical semantic structures using a novel metric called Semantic Shift, which quantifies how semantics evolve as SFSes evolve. To ensure scalability, we develop an efficient approximation of Semantic Shift that replaces costly SVD computations, achieving a 15~30x speedup with average errors below 0.01. Extensive evaluations across six real-world text and image datasets show that SFSes outperform standard classifiers not only in classification but also in nuanced tasks such as political bias detection, while SAFARI consistently reveals interpretable and generalizable semantic hierarchies. This work presents a unified framework for structuring, analyzing, and scaling semantic understanding in embedding spaces.",
        "url": "http://arxiv.org/abs/2512.00852v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00852v1",
        "arxiv_id": "2512.00852v1",
        "authors": [
            "Yandong Sun",
            "Qiang Huang",
            "Ziwei Xu",
            "Yiqun Sun",
            "Yixuan Tang",
            "Anthony K. H. Tung"
        ],
        "submitted": "2025-11-30 11:48:00",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in areas requiring deep semantic understanding. The authors introduce a novel representation (Semantic Field Subspace) and algorithm (SAFARI) to uncover hierarchical semantic structures in embedding spaces, which is closely related to your focus on query understanding and ranking models. While not directly related to search technologies or user behavior modeling, the work has the potential to improve the semantic understanding and relevance optimization in IR systems."
    },
    {
        "title": "Accelerating Bangla NLP Tasks with Automatic Mixed Precision: Resource-Efficient Training Preserving Model Efficacy",
        "abstract": "Training models for Natural Language Processing (NLP) requires substantial computational resources and time, posing significant challenges, especially for NLP development in Bangla, where access to high-end hardware is often limited. In this work, we explore automatic mixed precision (AMP) training as a means to improve computational efficiency without sacrificing model performance. By leveraging a dynamic mix of 16-bit and 32-bit floating-point computations, AMP lowers GPU memory requirements and speeds up training without degrading model performance. We evaluate AMP across four standard Bangla NLP tasks, namely sentiment analysis, named entity recognition, error classification, and question answering, using four transformer-based models: BanglaBERT, BanglishBERT, XLM-R, and mBERT. Our results demonstrate that AMP accelerates training by 44.5% and reduces memory consumption by 17.6%, while maintaining F-1 score within 99.7% of the full-precision baselines. This empirical study highlights AMP's potential to democratize access to state-of-the-art NLP capabilities in hardware-constrained settings by lowering computational barriers.",
        "url": "http://arxiv.org/abs/2512.00829v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00829v1",
        "arxiv_id": "2512.00829v1",
        "authors": [
            "Md Mehrab Hossain Opi",
            "Sumaiya Khan",
            "Moshammad Farzana Rahman"
        ],
        "submitted": "2025-11-30 10:34:08",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is primarily focused on accelerating NLP tasks using automatic mixed precision training, which is not directly related to the user's core research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. While it does involve NLP, it's more focused on computational efficiency and hardware constraints, rather than deep semantic understanding or real-time relevance optimization."
    },
    {
        "title": "Upcycled and Merged MoE Reward Model for Mitigating Reward Hacking",
        "abstract": "Reward models play a critical role in Reinforcement Learning from Human Feedback (RLHF) by assessing the consistency between generated outputs and human preferences. However, conventional reward models are prone to reward hacking or over-optimization, where the policy exploits shortcut patterns to obtain high reward scores that do not reflect true human preference. Although Mixture-of-Experts (MoE)-based reward models can enhance discriminative capability, they typically introduce substantial computational overhead. To address these challenges, we propose an upcycle and merge MoE reward modeling approach. We first upcycle a dense reward model into a MoE architecture, where a shared expert captures general knowledge, while normal experts specialize in instruction-specific patterns. We then apply routing-weight normalization and merge experts back into a dense model through a learnable weight-averaging mechanism, preserving performance gains while significantly reducing inference cost. Experimental results demonstrate that our method effectively mitigates reward hacking across various model scales. Our work highlights the potential of upcycle and merge MoE structures for improving both robustness and efficiency of RLHF reward models.",
        "url": "http://arxiv.org/abs/2512.00724v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00724v1",
        "arxiv_id": "2512.00724v1",
        "authors": [
            "Lingling Fu"
        ],
        "submitted": "2025-11-30 04:36:37",
        "source": "arxiv",
        "comment": "9 pages,5 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Reinforcement Learning from Human Feedback (RLHF) and reward models, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on the concept of 'reward hacking', it is more relevant to the broader field of Artificial Intelligence and Machine Learning, rather than the user's specific areas of focus."
    },
    {
        "title": "Sycophancy Claims about Language Models: The Missing Human-in-the-Loop",
        "abstract": "Sycophantic response patterns in Large Language Models (LLMs) have been increasingly claimed in the literature. We review methodological challenges in measuring LLM sycophancy and identify five core operationalizations. Despite sycophancy being inherently human-centric, current research does not evaluate human perception. Our analysis highlights the difficulties in distinguishing sycophantic responses from related concepts in AI alignment and offers actionable recommendations for future research.",
        "url": "http://arxiv.org/abs/2512.00656v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00656v1",
        "arxiv_id": "2512.00656v1",
        "authors": [
            "Jan Batzner",
            "Volker Stocker",
            "Stefan Schmid",
            "Gjergji Kasneci"
        ],
        "submitted": "2025-11-29 22:40:53",
        "source": "arxiv",
        "comment": "NeurIPS 2025 Workshop on LLM Evaluation and ICLR 2025 Workshop on Bi-Directional Human-AI Alignment",
        "score": 2,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be primarily focused on the evaluation of Large Language Models (LLMs) through the lens of human perception, which is not directly related to your core research themes in Information Retrieval and Search technologies. While it touches on AI alignment, it does not seem to address query understanding, ranking models, or user behavior modeling, making it only loosely relevant to your interests."
    },
    {
        "title": "Whose Personae? Synthetic Persona Experiments in LLM Research and Pathways to Transparency",
        "abstract": "Synthetic personae experiments have become a prominent method in Large Language Model alignment research, yet the representativeness and ecological validity of these personae vary considerably between studies. Through a review of 63 peer-reviewed studies published between 2023 and 2025 in leading NLP and AI venues, we reveal a critical gap: task and population of interest are often underspecified in persona-based experiments, despite personalization being fundamentally dependent on these criteria. Our analysis shows substantial differences in user representation, with most studies focusing on limited sociodemographic attributes and only 35% discussing the representativeness of their LLM personae. Based on our findings, we introduce a persona transparency checklist that emphasizes representative sampling, explicit grounding in empirical data, and enhanced ecological validity. Our work provides both a comprehensive assessment of current practices and practical guidelines to improve the rigor and ecological validity of persona-based evaluations in language model alignment research.",
        "url": "http://arxiv.org/abs/2512.00461v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00461v1",
        "arxiv_id": "2512.00461v1",
        "authors": [
            "Jan Batzner",
            "Volker Stocker",
            "Bingjun Tang",
            "Anusha Natarajan",
            "Qinhao Chen",
            "Stefan Schmid",
            "Gjergji Kasneci"
        ],
        "submitted": "2025-11-29 12:27:34",
        "source": "arxiv",
        "comment": "Published at AAAI/ACM AIES 2025. Presented at NeurIPS 2025 Workshop Evaluating the Evolving LLM Lifecycle: Benchmarks, Emergent Abilities, and Scaling",
        "score": 2,
        "keyword_reasons": [
            "Found 'personalization' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling. While it touches on NLP, its focus is on Large Language Model alignment research and persona-based experiments, which is a niche area in NLP that doesn't align with your primary research themes."
    },
    {
        "title": "IndicParam: Benchmark to evaluate LLMs on low-resource Indic Languages",
        "abstract": "While large language models excel on high-resource multilingual tasks, low- and extremely low-resource Indic languages remain severely under-evaluated. We present IndicParam, a human-curated benchmark of over 13,000 multiple-choice questions covering 11 such languages (Nepali, Gujarati, Marathi, Odia as low-resource; Dogri, Maithili, Rajasthani, Sanskrit, Bodo, Santali, Konkani as extremely low-resource) plus Sanskrit-English code-mixed set. We evaluated 19 LLMs, both proprietary and open-weights, which reveals that even the top-performing GPT-5 reaches only 45.0% average accuracy, followed by DeepSeek-3.2 (43.1) and Claude-4.5 (42.7). We additionally label each question as knowledge-oriented or purely linguistic to discriminate factual recall from grammatical proficiency. Further, we assess the ability of LLMs to handle diverse question formats-such as list-based matching, assertion-reason pairs, and sequence ordering-alongside conventional multiple-choice questions. IndicParam provides insights into limitations of cross-lingual transfer and establishes a challenging benchmark for Indic languages. The dataset is available at https://huggingface.co/datasets/bharatgenai/IndicParam. Scripts to run benchmark are present at https://github.com/ayushbits/IndicParam.",
        "url": "http://arxiv.org/abs/2512.00333v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00333v1",
        "arxiv_id": "2512.00333v1",
        "authors": [
            "Ayush Maheshwari",
            "Kaushal Sharma",
            "Vivek Patel",
            "Aditya Maheshwari"
        ],
        "submitted": "2025-11-29 05:49:50",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your interests in Natural Language Processing (NLP) and deep semantic understanding, but it focuses on low-resource Indic languages and large language models, which is not a central match to your primary focus on Information Retrieval, especially in e-commerce and real-time relevance optimization."
    },
    {
        "title": "Progressive Code Integration for Abstractive Bug Report Summarization",
        "abstract": "Bug reports are often unstructured and verbose, making it challenging for developers to efficiently comprehend software issues. Existing summarization approaches typically rely on surface-level textual cues, resulting in incomplete or redundant summaries, and they frequently ignore associated code snippets, which are essential for accurate defect diagnosis. To address these limitations, we propose a progressive code-integration framework for LLM-based abstractive bug report summarization. Our approach incrementally incorporates long code snippets alongside textual content, overcoming standard LLM context window constraints and producing semantically rich summaries. Evaluated on four benchmark datasets using eight LLMs, our pipeline outperforms extractive baselines by 7.5%-58.2% and achieves performance comparable to state-of-the-art abstractive methods, highlighting the benefits of jointly leveraging textual and code information for enhanced bug comprehension.",
        "url": "http://arxiv.org/abs/2512.00325v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00325v1",
        "arxiv_id": "2512.00325v1",
        "authors": [
            "Shaira Sadia Karim",
            "Abrar Mahmud Rahim",
            "Lamia Alam",
            "Ishmam Tashdeed",
            "Lutfun Nahar Lota",
            "Md. Abu Raihan M. Kamal",
            "Md. Azam Hossain"
        ],
        "submitted": "2025-11-29 05:35:36",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper primarily focuses on abstractive bug report summarization, which is not directly related to your core research themes in Information Retrieval and Search technologies. While it involves Natural Language Processing, the context is specific to software bug reports and code integration, which is not a central match to your interests."
    },
    {
        "title": "OmniFusion: Simultaneous Multilingual Multimodal Translations via Modular Fusion",
        "abstract": "There has been significant progress in open-source text-only translation large language models (LLMs) with better language coverage and quality. However, these models can be only used in cascaded pipelines for speech translation (ST), performing automatic speech recognition first followed by translation. This introduces additional latency, which is particularly critical in simultaneous ST (SimulST), and prevents the model from exploiting multimodal context, such as images, which can aid disambiguation. Pretrained multimodal foundation models (MMFMs) already possess strong perception and reasoning capabilities across multiple modalities, but generally lack the multilingual coverage and specialized translation performance of dedicated translation LLMs. To build an effective multimodal translation system, we propose an end-to-end approach that fuses MMFMs with translation LLMs. We introduce a novel fusion strategy that connects hidden states from multiple layers of a pretrained MMFM to a translation LLM, enabling joint end-to-end training. The resulting model, OmniFusion, built on Omni 2.5-7B as the MMFM and SeedX PPO-7B as the translation LLM, can perform speech-to-text, speech-and-image-to-text, and text-and-image-to-text translation. Experiments demonstrate that OmniFusion effectively leverages both audio and visual inputs, achieves a 1-second latency reduction in SimulST compared to cascaded pipelines and also improves the overall translation quality\\footnote{Code is available at https://github.com/saikoneru/OmniFusion}.",
        "url": "http://arxiv.org/abs/2512.00234v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00234v1",
        "arxiv_id": "2512.00234v1",
        "authors": [
            "Sai Koneru",
            "Matthias Huck",
            "Jan Niehues"
        ],
        "submitted": "2025-11-28 22:39:12",
        "source": "arxiv",
        "comment": "Preprint for ACL 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multimodal translation systems, which is a topic related to Natural Language Processing (NLP), but it does not directly align with your core research interests in Information Retrieval (IR), query understanding, ranking models, or user behavior modeling. While it involves deep semantic understanding, the context is specific to translation systems, which is not a primary focus of your research."
    },
    {
        "title": "Minimal-Edit Instruction Tuning for Low-Resource Indic GEC",
        "abstract": "Grammatical error correction for Indic languages faces limited supervision, diverse scripts, and rich morphology. We propose an augmentation-free setup that uses instruction-tuned large language models and conservative decoding. A 12B GEMMA 3 model is instruction-tuned in bnb 4-bit precision with parameter-efficient fine-tuning (PEFT) and Alpaca-style formatting. Decoding follows a deterministic, constraint-aware procedure with a lightweight normaliser that encourages minimal, meaning-preserving edits. We operationalise inference, subsequent to instruction fine-tuning (IFT), via a fixed, language-specific prompt directly synthesised from a deterministic error classifier's taxonomy, label distributions, and precedence ordering computed on the training corpus.\n  Under the official untuned GLEU evaluation, the system scores 92.41 on Malayalam, sixth overall, and 81.44 on Hindi, third overall. These results indicate that classifier-informed prompt design, adapter-based instruction tuning, and deterministic decoding provide a reproducible and a computationally efficient alternative to augmentation-centred pipelines for Indic GEC. The approach also motivates future work on stronger morphosyntactic constraints and human-centred evaluation of conservative edits.",
        "url": "http://arxiv.org/abs/2512.00219v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00219v1",
        "arxiv_id": "2512.00219v1",
        "authors": [
            "Akhil Rajeev P"
        ],
        "submitted": "2025-11-28 21:38:27",
        "source": "arxiv",
        "comment": "Submitted to AACL-IJCNLP Bhasha Workshop Shared Task1 :GEC",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Grammatical Error Correction for Indic languages, which is not directly related to your primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language models and NLP, the specific application and methodology are not aligned with your core themes."
    },
    {
        "title": "Tree Matching Networks for Natural Language Inference: Parameter-Efficient Semantic Understanding via Dependency Parse Trees",
        "abstract": "In creating sentence embeddings for Natural Language Inference (NLI) tasks, using transformer-based models like BERT leads to high accuracy, but require hundreds of millions of parameters. These models take in sentences as a sequence of tokens, and learn to encode the meaning of the sequence into embeddings such that those embeddings can be used reliably for NLI tasks. Essentially, every word is considered against every other word in the sequence, and the transformer model is able to determine the relationships between them, entirely from scratch. However, a model that accepts explicit linguistic structures like dependency parse trees may be able to leverage prior encoded information about these relationships, without having to learn them from scratch, thus improving learning efficiency. To investigate this, we adapt Graph Matching Networks (GMN) to operate on dependency parse trees, creating Tree Matching Networks (TMN). We compare TMN to a BERT based model on the SNLI entailment task and on the SemEval similarity task. TMN is able to achieve significantly better results with a significantly reduced memory footprint and much less training time than the BERT based model on the SNLI task, while both models struggled to preform well on the SemEval. Explicit structural representations significantly outperform sequence-based models at comparable scales, but current aggregation methods limit scalability. We propose multi-headed attention aggregation to address this limitation.",
        "url": "http://arxiv.org/abs/2512.00204v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00204v1",
        "arxiv_id": "2512.00204v1",
        "authors": [
            "Jason Lunder"
        ],
        "submitted": "2025-11-28 21:06:11",
        "source": "arxiv",
        "comment": "16 pages, preprint",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on Natural Language Inference and develops a new model, Tree Matching Networks, to improve learning efficiency. While it touches on semantic understanding, which is related to your interests in Information Retrieval, it is primarily concerned with NLP and does not directly address query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Testing the Machine Consciousness Hypothesis",
        "abstract": "The Machine Consciousness Hypothesis states that consciousness is a substrate-free functional property of computational systems capable of second-order perception. I propose a research program to investigate this idea in silico by studying how collective self-models (coherent, self-referential representations) emerge from distributed learning systems embedded within universal self-organizing environments. The theory outlined here starts from the supposition that consciousness is an emergent property of collective intelligence systems undergoing synchronization of prediction through communication. It is not an epiphenomenon of individual modeling but a property of the language that a system evolves to internally describe itself. For a model of base reality, I begin with a minimal but general computational world: a cellular automaton, which exhibits both computational irreducibility and local reducibility. On top of this computational substrate, I introduce a network of local, predictive, representational (neural) models capable of communication and adaptation. I use this layered model to study how collective intelligence gives rise to self-representation as a direct consequence of inter-agent alignment. I suggest that consciousness does not emerge from modeling per se, but from communication. It arises from the noisy, lossy exchange of predictive messages between groups of local observers describing persistent patterns in the underlying computational substrate (base reality). It is through this representational dialogue that a shared model arises, aligning many partial views of the world. The broader goal is to develop empirically testable theories of machine consciousness, by studying how internal self-models may form in distributed systems without centralized control.",
        "url": "http://arxiv.org/abs/2512.01081v1",
        "pdf_url": "https://arxiv.org/pdf/2512.01081v1",
        "arxiv_id": "2512.01081v1",
        "authors": [
            "Stephen Fitz"
        ],
        "submitted": "2025-11-30 21:05:48",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper appears to be unrelated to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topic of machine consciousness and its emergence in distributed systems does not align with your focus on query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Fine-tuning of lightweight large language models for sentiment classification on heterogeneous financial textual data",
        "abstract": "Large language models (LLMs) play an increasingly important role in finan- cial markets analysis by capturing signals from complex and heterogeneous textual data sources, such as tweets, news articles, reports, and microblogs. However, their performance is dependent on large computational resources and proprietary datasets, which are costly, restricted, and therefore inacces- sible to many researchers and practitioners. To reflect realistic situations we investigate the ability of lightweight open-source LLMs - smaller and publicly available models designed to operate with limited computational resources - to generalize sentiment understanding from financial datasets of varying sizes, sources, formats, and languages. We compare the benchmark finance natural language processing (NLP) model, FinBERT, and three open-source lightweight LLMs, DeepSeek-LLM 7B, Llama3 8B Instruct, and Qwen3 8B on five publicly available datasets: FinancialPhraseBank, Financial Question Answering, Gold News Sentiment, Twitter Sentiment and Chinese Finance Sentiment. We find that LLMs, specially Qwen3 8B and Llama3 8B, perform best in most scenarios, even from using only 5% of the available training data. These results hold in zero-shot and few-shot learning scenarios. Our findings indicate that lightweight, open-source large language models (LLMs) consti- tute a cost-effective option, as they can achieve competitive performance on heterogeneous textual data even when trained on only a limited subset of the extensive annotated corpora that are typically deemed necessary.",
        "url": "http://arxiv.org/abs/2512.00946v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00946v1",
        "arxiv_id": "2512.00946v1",
        "authors": [
            "Alvaro Paredes Amorin",
            "Andre Python",
            "Christoph Weisser"
        ],
        "submitted": "2025-11-30 15:58:22",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and large language models, but it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The focus on sentiment classification and financial textual data is also somewhat tangential to the user's primary research themes."
    },
    {
        "title": "Less is More: Resource-Efficient Low-Rank Adaptation",
        "abstract": "Low-Rank Adaptation (LoRA) is a widely adopted parameter-efficient fine-tuning (PEFT) method for Large Language Models (LLMs), but it still incurs notable overhead and suffers from parameter interference in complex datasets. While re- cent works decouple LoRA update matrices to exploit matrix-wise asymmetry, training costs remain high. We revisit LoRA from the perspective of inter-matrix and intra-layer parameter redundancy and propose Resource-Efficient Low-Rank Adaptation, EffiLoRA, a lightweight and generalizable approach for language, multimodal, and diffusion models. EffiLoRA employs a unified A matrix across all transformer layers and introduces a runtime selective B matrices up- date to dynamically trade-off the system resource budget and model performance. EffiLoRA consistently outperforms LoRA across diverse modalities, including commonsense reasoning, visual instruction tuning, and image generation, demon- strating improved efficiency and robustness.",
        "url": "http://arxiv.org/abs/2512.00878v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00878v1",
        "arxiv_id": "2512.00878v1",
        "authors": [
            "Chunlin Tian",
            "Xuyang Wei",
            "Huanrong Liu",
            "Zhijiang Guo",
            "Li Li"
        ],
        "submitted": "2025-11-30 12:52:04",
        "source": "arxiv",
        "comment": "18 pages, 7 figures",
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving the efficiency of a parameter-efficient fine-tuning method for Large Language Models, which is not directly related to information retrieval, query understanding, or ranking models. While it involves NLP, the context is not aligned with the user's core research themes."
    },
    {
        "title": "Text Mining Analysis of Symptom Patterns in Medical Chatbot Conversations",
        "abstract": "The fast growth of digital health systems has led to a need to better comprehend how they interpret and represent patient-reported symptoms. Chatbots have been used in healthcare to provide clinical support and enhance the user experience, making it possible to provide meaningful clinical patterns from text-based data through chatbots. The proposed research utilises several different natural language processing methods to study the occurrences of symptom descriptions in medicine as well as analyse the patterns that emerge through these conversations within medical bots. Through the use of the Medical Conversations to Disease Dataset which contains 960 multi-turn dialogues divided into 24 Clinical Conditions, a standardised representation of conversations between patient and bot is created for further analysis by computational means. The multi-method approach uses a variety of tools, including Latent Dirichlet Allocation (LDA) to identify latent symptom themes, K-Means to group symptom descriptions by similarity, Transformer-based Named Entity Recognition (NER) to extract medical concepts, and the Apriori algorithm to discover frequent symptom pairs. Findings from the analysis indicate a coherent structure of clinically relevant topics, moderate levels of clustering cohesiveness and several high confidence rates on the relationships between symptoms like fever headache and rash itchiness. The results support the notion that conversational medical data can be a valuable diagnostic signal for early symptom interpretation, assist in strengthening decision support and improve how users interact with tele-health technology. By demonstrating a method for converting unstructured free-flowing dialogue into actionable knowledge regarding symptoms this work provides an extensible framework to further enhance future performance, dependability and clinical utility of selecting medical chatbots.",
        "url": "http://arxiv.org/abs/2512.00768v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00768v1",
        "arxiv_id": "2512.00768v1",
        "authors": [
            "Hamed Razavi"
        ],
        "submitted": "2025-11-30 07:40:02",
        "source": "arxiv",
        "comment": "9 pages, 4 tables",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Information Retrieval (IR), particularly in the context of text mining and chatbot conversations. However, it does not directly align with your focus on query understanding, ranking models, or user behavior modeling in the e-commerce domain."
    },
    {
        "title": "FastPOS: Language-Agnostic Scalable POS Tagging Framework Low-Resource Use Case",
        "abstract": "This study proposes a language-agnostic transformer-based POS tagging framework designed for low-resource languages, using Bangla and Hindi as case studies. With only three lines of framework-specific code, the model was adapted from Bangla to Hindi, demonstrating effective portability with minimal modification. The framework achieves 96.85 percent and 97 percent token-level accuracy across POS categories in Bangla and Hindi while sustaining strong F1 scores despite dataset imbalance and linguistic overlap. A performance discrepancy in a specific POS category underscores ongoing challenges in dataset curation. The strong results stem from the underlying transformer architecture, which can be replaced with limited code adjustments. Its modular and open-source design enables rapid cross-lingual adaptation while reducing model design and tuning overhead, allowing researchers to focus on linguistic preprocessing and dataset refinement, which are essential for advancing NLP in underrepresented languages.",
        "url": "http://arxiv.org/abs/2512.00745v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00745v1",
        "arxiv_id": "2512.00745v1",
        "authors": [
            "Md Abdullah Al Kafi",
            "Sumit Kumar Banshal"
        ],
        "submitted": "2025-11-30 05:48:12",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is primarily focused on POS tagging, a task in Natural Language Processing (NLP), but it does not directly relate to the user's core research themes in Information Retrieval (IR), query understanding, ranking models, or user behavior modeling. While it touches on cross-lingual adaptation, which is a related topic, the paper's focus on low-resource languages and POS tagging makes it only loosely relevant to the user's interests."
    },
    {
        "title": "PEOAT: Personalization-Guided Evolutionary Question Assembly for One-Shot Adaptive Testing",
        "abstract": "With the rapid advancement of intelligent education, Computerized Adaptive Testing (CAT) has attracted increasing attention by integrating educational psychology with deep learning technologies. Unlike traditional paper-and-pencil testing, CAT aims to efficiently and accurately assess examinee abilities by adaptively selecting the most suitable items during the assessment process. However, its real-time and sequential nature presents limitations in practical scenarios, particularly in large-scale assessments where interaction costs are high, or in sensitive domains such as psychological evaluations where minimizing noise and interference is essential. These challenges constrain the applicability of conventional CAT methods in time-sensitive or resourceconstrained environments. To this end, we first introduce a novel task called one-shot adaptive testing (OAT), which aims to select a fixed set of optimal items for each test-taker in a one-time selection. Meanwhile, we propose PEOAT, a Personalization-guided Evolutionary question assembly framework for One-shot Adaptive Testing from the perspective of combinatorial optimization. Specifically, we began by designing a personalization-aware initialization strategy that integrates differences between examinee ability and exercise difficulty, using multi-strategy sampling to construct a diverse and informative initial population. Building on this, we proposed a cognitive-enhanced evolutionary framework incorporating schema-preserving crossover and cognitively guided mutation to enable efficient exploration through informative signals. To maintain diversity without compromising fitness, we further introduced a diversity-aware environmental selection mechanism. The effectiveness of PEOAT is validated through extensive experiments on two datasets, complemented by case studies that uncovered valuable insights.",
        "url": "http://arxiv.org/abs/2512.00439v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00439v1",
        "arxiv_id": "2512.00439v1",
        "authors": [
            "Xiaoshan Yu",
            "Ziwei Huang",
            "Shangshang Yang",
            "Ziwen Wang",
            "Haiping Ma",
            "Xingyi Zhang"
        ],
        "submitted": "2025-11-29 10:38:25",
        "source": "arxiv",
        "comment": "AAAI-2026, 9 pages",
        "score": 1,
        "keyword_reasons": [
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on Computerized Adaptive Testing (CAT) and one-shot adaptive testing, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some optimization techniques, the context and application are quite different from your areas of focus."
    },
    {
        "title": "A Taxonomy of Errors in English as she is spoke: Toward an AI-Based Method of Error Analysis for EFL Writing Instruction",
        "abstract": "This study describes the development of an AI-assisted error analysis system designed to identify, categorize, and correct writing errors in English. Utilizing Large Language Models (LLMs) like Claude 3.5 Sonnet and DeepSeek R1, the system employs a detailed taxonomy grounded in linguistic theories from Corder (1967), Richards (1971), and James (1998). Errors are classified at both word and sentence levels, covering spelling, grammar, and punctuation. Implemented through Python-coded API calls, the system provides granular feedback beyond traditional rubric-based assessments. Initial testing on isolated errors refined the taxonomy, addressing challenges like overlapping categories. Final testing used \"English as she is spoke\" by Jose da Fonseca (1855), a text rich with authentic linguistic errors, to evaluate the system's capacity for handling complex, multi-layered analysis. The AI successfully identified diverse error types but showed limitations in contextual understanding and occasionally generated new error categories when encountering uncoded errors. This research demonstrates AI's potential to transform EFL instruction by automating detailed error analysis and feedback. While promising, further development is needed to improve contextual accuracy and expand the taxonomy to stylistic and discourse-level errors.",
        "url": "http://arxiv.org/abs/2512.00392v1",
        "pdf_url": "https://arxiv.org/pdf/2512.00392v1",
        "arxiv_id": "2512.00392v1",
        "authors": [
            "Damian Heywood",
            "Joseph Andrew Carrier",
            "Kyu-Hong Hwang"
        ],
        "submitted": "2025-11-29 08:45:00",
        "source": "arxiv",
        "comment": "Metadata at \"Replication Data for: A Taxonomy of Errors in English as she is spoke: An AI-Based System for Error Analysis for EFL Writing Instruction\", https://doi.org/10.7910/DVN/N5O7C4, Harvard Dataverse, V1",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on error analysis in English language learning, utilizing AI and NLP techniques, but does not address information retrieval, search technologies, or related topics."
    }
]