# Daily Papers Report - 2025-07-10

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Shifting from Ranking to Set Selection for Retrieval Augmented Generation

- **LLM Score**: 7
- **Keyword Score**: 23
- **Authors**: Dahyun Lee, Yongrae Jo, Haeju Park, Moontae Lee
- **URL**: <http://arxiv.org/abs/2507.06838v2>
- **Submitted**: 2025-07-09 13:35:36
- **Comment**: Accepted to ACL 2025 main (Oral Presentation)
- **Topic Keywords**: query, queries, ranking, rerank, relevance, rag, retrieval augmented generation, retrieval, rank, search
- **Reason**: The paper explores Retrieval-Augmented Generation, which is related to Information Retrieval and Search technologies. The focus on set selection and passage retrieval is somewhat relevant to query understanding and ranking models, but the emphasis on Chain-of-Thought reasoning and multi-hop question answering is not directly aligned with the user's interests in e-commerce or real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Retrieval-Augmented Generation (RAG) with Set-wise Passage Selection
- **Aim**: To propose a novel approach to RAG called SETR, which selects a comprehensive set of passages that collectively satisfy the information requirements of a query
- **Rationale**: Relevance-based reranking alone is insufficient for retrieval modules in RAG systems, and a set-wise retrieval approach is needed to jointly optimize relevance, completeness, and conciseness of the retrieved set
- **Ground**: SETR uses Chain-of-Thought (CoT) reasoning to identify the information requirements of a query and select an optimal subset from the retrieved passages
- **Experiment**: SETR is evaluated on four complex multi-hop QA datasets, outperforming proprietary LLM-based rerankers and open-source baselines in terms of answer correctness, precision, and recall
- **Takeaway**: SETR achieves higher F1 and Accuracy scores while using fewer passages on average, and its set-wise passage selection approach and CoT reasoning contribute to the performance boost

#### Abstract
> Retrieval in Retrieval-Augmented Generation(RAG) must ensure that retrieved
passages are not only individually relevant but also collectively form a
comprehensive set. Existing approaches primarily rerank top-k passages based on
their individual relevance, often failing to meet the information needs of
complex queries in multi-hop question answering. In this work, we propose a
set-wise passage selection approach and introduce SETR, which explicitly
identifies the information requirements of a query through Chain-of-Thought
reasoning and selects an optimal set of passages that collectively satisfy
those requirements. Experiments on multi-hop RAG benchmarks show that SETR
outperforms both proprietary LLM-based rerankers and open-source baselines in
terms of answer correctness and retrieval quality, providing an effective and
efficient alternative to traditional rerankers in RAG systems. The code is
available at https://github.com/LGAI-Research/SetR

---

### 2. Temporal Information Retrieval via Time-Specifier Model Merging

- **LLM Score**: 7
- **Keyword Score**: 14
- **Authors**: SeungYoon Han, Taeho Hwang, Sukmin Cho, Soyeong Jeong, Hoyun Song, Huije Lee, Jong C. Park
- **URL**: <http://arxiv.org/abs/2507.06782v1>
- **Submitted**: 2025-07-09 12:16:11
- **Topic Keywords**: information retrieval, retriever, dense retrieval, queries, retrieval
- **Reason**: The paper focuses on Temporal Information Retrieval (TIR), which is a specific subfield within Information Retrieval (IR). While it doesn't directly address query understanding, ranking models, or user behavior modeling, it does explore a novel method for handling temporal constraints in IR, which is related to the user's interests in IR and query understanding. The paper's emphasis on preserving accuracy on non-temporal queries also shows some relevance to the user's broader interests in IR.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Temporal Information Retrieval (TIR) and Time-Specifier Model Merging (TSM)
- **Aim**: To enhance temporal retrieval while preserving accuracy on non-temporal queries
- **Rationale**: Existing dense retrieval methods underperform on temporal queries and fine-tuning often results in catastrophic forgetting
- **Ground**: TSM trains specialized retrievers for individual time specifiers and merges them into a unified model, enabling precise handling of temporal constraints
- **Experiment**: Evaluation on four question-answering datasets shows TSM outperforms baselines on temporal datasets and maintains competitive performance on non-temporal datasets
- **Takeaway**: TSM effectively balances temporal and non-temporal information, mitigating attention bias, but has limitations and requires future work to improve coverage and robustness

#### Abstract
> The rapid expansion of digital information and knowledge across structured
and unstructured sources has heightened the importance of Information Retrieval
(IR). While dense retrieval methods have substantially improved semantic
matching for general queries, they consistently underperform on queries with
explicit temporal constraints--often those containing numerical expressions and
time specifiers such as ``in 2015.'' Existing approaches to Temporal
Information Retrieval (TIR) improve temporal reasoning but often suffer from
catastrophic forgetting, leading to reduced performance on non-temporal
queries. To address this, we propose Time-Specifier Model Merging (TSM), a
novel method that enhances temporal retrieval while preserving accuracy on
non-temporal queries. TSM trains specialized retrievers for individual time
specifiers and merges them in to a unified model, enabling precise handling of
temporal constraints without compromising non-temporal retrieval. Extensive
experiments on both temporal and non-temporal datasets demonstrate that TSM
significantly improves performance on temporally constrained queries while
maintaining strong results on non-temporal queries, consistently outperforming
other baseline methods. Our code is available at
https://github.com/seungyoonee/TSM .

---

### 3. A Semantic Parsing Framework for End-to-End Time Normalization

- **LLM Score**: 7
- **Keyword Score**: 7
- **Authors**: Xin Su, Sungduk Yu, Phillip Howard, Steven Bethard
- **URL**: <http://arxiv.org/abs/2507.06450v1>
- **Submitted**: 2025-07-08 23:30:11
- **Topic Keywords**: information retrieval, rag, retrieval
- **Reason**: The paper is relevant to information retrieval and search technologies, specifically in the area of query understanding, as it deals with natural language temporal expressions and their conversion into machine-readable representations. The use of large language models and code generation tasks is also related to ranking models and user behavior modeling. However, the focus on time normalization and its applications in question answering and clinical decision-making is not directly aligned with the user's primary research interests in e-commerce and real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Time Normalization using SCATE Framework
- **Aim**: To develop a novel approach to time normalization using the SCATE framework, enabling accurate and interpretable conversion of natural language temporal expressions into machine-readable representations
- **Rationale**: The SCATE framework provides a comprehensive and flexible way to handle complex temporal expressions, addressing the challenge of data scarcity and enabling practical time normalization
- **Ground**: The authors implement PySCATE, a fully executable SCATE Python library, and develop an automatic data augmentation pipeline using large language models to synthesize large-scale annotated data
- **Experiment**: The approach is evaluated using the TempEval-2013 dataset, training various large language models and a local model on a single NVIDIA 80GB A100 GPU, achieving an average accuracy and F1 score of 0.62
- **Takeaway**: The SCATE framework and PySCATE library enable accurate and interpretable time normalization, and the use of large language models and data augmentation can improve performance, highlighting the importance of precise annotation and identification of temporal expression spans

#### Abstract
> Time normalization is the task of converting natural language temporal
expressions into machine-readable representations. It underpins many downstream
applications in information retrieval, question answering, and clinical
decision-making. Traditional systems based on the ISO-TimeML schema limit
expressivity and struggle with complex constructs such as compositional,
event-relative, and multi-span time expressions. In this work, we introduce a
novel formulation of time normalization as a code generation task grounded in
the SCATE framework, which defines temporal semantics through symbolic and
compositional operators. We implement a fully executable SCATE Python library
and demonstrate that large language models (LLMs) can generate executable SCATE
code. Leveraging this capability, we develop an automatic data augmentation
pipeline using LLMs to synthesize large-scale annotated data with code-level
validation. Our experiments show that small, locally deployable models trained
on this augmented data can achieve strong performance, outperforming even their
LLM parents and enabling practical, accurate, and interpretable time
normalization.

---

### 4. Investigating the Robustness of Retrieval-Augmented Generation at the Query Level

- **LLM Score**: 6
- **Keyword Score**: 11
- **Authors**: Sezen Per√ßin, Xin Su, Qutub Sha Syed, Phillip Howard, Aleksei Kuvshinov, Leo Schwinn, Kay-Ulrich Scholl
- **URL**: <http://arxiv.org/abs/2507.06956v1>
- **Submitted**: 2025-07-09 15:39:17
- **Comment**: Accepted to Generation, Evaluation & Metrics (GEM) Workshop at ACL
  2025
- **Topic Keywords**: retriever, query, rag, retrieval, recommend
- **Reason**: The paper investigates the robustness of Retrieval-Augmented Generation (RAG) at the query level, which is related to query understanding and ranking models in Information Retrieval. However, the focus is on the robustness of RAG rather than query understanding or ranking models themselves, making it somewhat relevant to the user's interests.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Robustness of Retrieval-Augmented Generation (RAG) Systems in NLP and Information Retrieval
- **Aim**: To investigate the robustness of RAG systems to query perturbations and provide actionable recommendations for practitioners
- **Rationale**: RAG systems are sensitive to query perturbations, and understanding their robustness is crucial for reliable performance in real-world applications
- **Ground**: The study is grounded in the analysis of 12 question-answering pipelines using four retrievers and three Large Language Models (LLMs), with experiments on three datasets from the BEIR benchmark
- **Experiment**: The authors conducted experiments to evaluate the query-level robustness of RAG pipelines, analyzing the performance of different retrievers and LLMs under various query perturbations
- **Takeaway**: The study provides a comprehensive analysis of the robustness of RAG systems, highlighting the need for further research and providing practical recommendations for improving robustness, such as using the proposed evaluation framework and integrating findings into joint training regimes

#### Abstract
> Large language models (LLMs) are very costly and inefficient to update with
new information. To address this limitation, retrieval-augmented generation
(RAG) has been proposed as a solution that dynamically incorporates external
knowledge during inference, improving factual consistency and reducing
hallucinations. Despite its promise, RAG systems face practical challenges-most
notably, a strong dependence on the quality of the input query for accurate
retrieval. In this paper, we investigate the sensitivity of different
components in the RAG pipeline to various types of query perturbations. Our
analysis reveals that the performance of commonly used retrievers can degrade
significantly even under minor query variations. We study each module in
isolation as well as their combined effect in an end-to-end question answering
setting, using both general-domain and domain-specific datasets. Additionally,
we propose an evaluation framework to systematically assess the query-level
robustness of RAG pipelines and offer actionable recommendations for
practitioners based on the results of more than 1092 experiments we performed.

---

### 5. DS@GT at CheckThat! 2025: Exploring Retrieval and Reranking Pipelines for Scientific Claim Source Retrieval on Social Media Discourse

- **LLM Score**: 6
- **Keyword Score**: 9
- **Authors**: Jeanette Schofield, Shuyu Tian, Hoang Thanh Thanh Truong, Maximilian Heil
- **URL**: <http://arxiv.org/abs/2507.06563v1>
- **Submitted**: 2025-07-09 05:32:02
- **Topic Keywords**: ranking, rerank, retrieval, rank
- **Reason**: The paper explores retrieval and reranking pipelines for scientific claim source retrieval on social media discourse, which is related to information retrieval and search technologies. While it doesn't specifically focus on query understanding, ranking models, or user behavior modeling, it does involve ranking and retrieval techniques. However, the topic is not directly aligned with the user's primary focus on deep semantic understanding and real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Scientific Claim Source Retrieval
- **Aim**: Retrieve relevant scientific papers based on implicit references in tweets
- **Rationale**: Language differences between social media and scientific articles make the task challenging
- **Ground**: CLEF 2025 CheckThat! Lab Task 4b, using CiteWorth and SCiteTweets datasets
- **Experiment**: Explored six data augmentation techniques, seven retrieval and reranking pipelines, and fine-tuned a bi-encoder
- **Takeaway**: Achieved an MRR@5 of 0.58 on the evaluation set, suggesting that more data may not necessarily lead to better performance

#### Abstract
> Social media users often make scientific claims without citing where these
claims come from, generating a need to verify these claims. This paper details
work done by the DS@GT team for CLEF 2025 CheckThat! Lab Task 4b Scientific
Claim Source Retrieval which seeks to find relevant scientific papers based on
implicit references in tweets. Our team explored 6 different data augmentation
techniques, 7 different retrieval and reranking pipelines, and finetuned a
bi-encoder. Achieving an MRR@5 of 0.58, our team ranked 16th out of 30 teams
for the CLEF 2025 CheckThat! Lab Task 4b, and improvement of 0.15 over the BM25
baseline of 0.43. Our code is available on Github at
https://github.com/dsgt-arc/checkthat-2025-swd/tree/main/subtask-4b.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations

- **LLM Score**: 6
- **Keyword Score**: 8
- **Authors**: Fengran Mo, Yifan Gao, Chuan Meng, Xin Liu, Zhuofeng Wu, Kelong Mao, Zhengyang Wang, Pei Chen, Zheng Li, Xian Li, Bing Yin, Meng Jiang
- **URL**: <http://arxiv.org/abs/2507.07030v1>
- **Submitted**: 2025-07-09 17:02:40
- **Comment**: Accepted by ACL 2025 (main)
- **Topic Keywords**: dense retrieval, rag, retrieval, search
- **Reason**: The paper explores the unification of retrieval and response generation for large language models in conversations, which is related to information retrieval and search technologies. However, the focus on conversational search and language models is not directly aligned with the user's primary interest in query understanding, ranking models, and user behavior modeling. The paper's relevance is somewhat related but not a central match.

#### Abstract
> The rapid advancement of conversational search systems revolutionizes how
information is accessed by enabling the multi-turn interaction between the user
and the system. Existing conversational search systems are usually built with
two different models. This separation restricts the system from leveraging the
intrinsic knowledge of the models simultaneously, which cannot ensure the
effectiveness of retrieval benefiting the generation. The existing studies for
developing unified models cannot fully address the aspects of understanding
conversational context, managing retrieval independently, and generating
responses. In this paper, we explore how to unify dense retrieval and response
generation for large language models in conversation. We conduct joint
fine-tuning with different objectives and design two mechanisms to reduce the
inconsistency risks while mitigating data discrepancy. The evaluations on five
conversational search datasets demonstrate that our unified model can mutually
improve both tasks and outperform the existing baselines.

### 7. MS-DPPs: Multi-Source Determinantal Point Processes for Contextual Diversity Refinement of Composite Attributes in Text to Image Retrieval

- **LLM Score**: 6
- **Keyword Score**: 2
- **Authors**: Naoya Sogi, Takashi Shibata, Makoto Terao, Masanori Suganuma, Takayuki Okatani
- **URL**: <http://arxiv.org/abs/2507.06654v1>
- **Submitted**: 2025-07-09 08:38:46
- **Comment**: IJCAI 2025. Code: https://github.com/NEC-N-SOGI/msdpp
- **Topic Keywords**: retrieval
- **Reason**: The paper focuses on Text-to-Image Retrieval and Result Diversification, which is related to Information Retrieval and Search technologies. The use of Determinantal Point Processes and manifold representation is also relevant to query understanding and ranking models. However, the paper's primary focus on diversification of image appearances and attributes is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Result diversification (RD) is a crucial technique in Text-to-Image Retrieval
for enhancing the efficiency of a practical application. Conventional methods
focus solely on increasing the diversity metric of image appearances. However,
the diversity metric and its desired value vary depending on the application,
which limits the applications of RD. This paper proposes a novel task called
CDR-CA (Contextual Diversity Refinement of Composite Attributes). CDR-CA aims
to refine the diversities of multiple attributes, according to the
application's context. To address this task, we propose Multi-Source DPPs, a
simple yet strong baseline that extends the Determinantal Point Process (DPP)
to multi-sources. We model MS-DPP as a single DPP model with a unified
similarity matrix based on a manifold representation. We also introduce Tangent
Normalization to reflect contexts. Extensive experiments demonstrate the
effectiveness of the proposed method. Our code is publicly available at
https://github.com/NEC-N-SOGI/msdpp.

### 8. Can Interpretation Predict Behavior on Unseen Data?

- **LLM Score**: 6
- **Keyword Score**: 1
- **Authors**: Victoria R. Li, Jenny Kaufmann, Martin Wattenberg, David Alvarez-Melis, Naomi Saphra
- **URL**: <http://arxiv.org/abs/2507.06445v1>
- **Submitted**: 2025-07-08 23:07:33
- **Topic Keywords**: search
- **Reason**: The paper explores the relationship between attention patterns and out-of-distribution generalization in Transformer models, which is somewhat related to my interests in query understanding and ranking models. However, the focus on interpretability and OOD generalization is not directly aligned with my primary focus on information retrieval and real-time relevance optimization.

#### Abstract
> Interpretability research often aims to predict how a model will respond to
targeted interventions on specific mechanisms. However, it rarely predicts how
a model will respond to unseen input data. This paper explores the promises and
challenges of interpretability as a tool for predicting out-of-distribution
(OOD) model behavior. Specifically, we investigate the correspondence between
attention patterns and OOD generalization in hundreds of Transformer models
independently trained on a synthetic classification task. These models exhibit
several distinct systematic generalization rules OOD, forming a diverse
population for correlational analysis. In this setting, we find that simple
observational tools from interpretability can predict OOD performance. In
particular, when in-distribution attention exhibits hierarchical patterns, the
model is likely to generalize hierarchically on OOD data -- even when the
rule's implementation does not rely on these hierarchical patterns, according
to ablation tests. Our findings offer a proof-of-concept to motivate further
interpretability work on predicting unseen model behavior.

### 9. SPEAR: Subset-sampled Performance Evaluation via Automated Ground Truth Generation for RAG

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Zou Yuheng, Wang Yiran, Tian Yuzhu, Zhu Min, Huang Yanhua
- **URL**: <http://arxiv.org/abs/2507.06554v1>
- **Submitted**: 2025-07-09 05:13:09
- **Topic Keywords**: retriever, queries, rag, retrieval
- **Reason**: The paper focuses on Retrieval-Augmented Generation (RAG) and proposes a method for evaluating retrievers in RAG systems. While it touches on topics related to information retrieval, such as retrieval models and metrics, the primary focus is on the evaluation of RAG systems rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest for you.

#### Abstract
> Retrieval-Augmented Generation (RAG) is a core approach for enhancing Large
Language Models (LLMs), where the effectiveness of the retriever largely
determines the overall response quality of RAG systems. Retrievers encompass a
multitude of hyperparameters that significantly impact performance outcomes and
demonstrate sensitivity to specific applications. Nevertheless, hyperparameter
optimization entails prohibitively high computational expenses. Existing
evaluation methods suffer from either prohibitive costs or disconnection from
domain-specific scenarios. This paper proposes SEARA (Subset sampling
Evaluation for Automatic Retriever Assessment), which addresses evaluation data
challenges through subset sampling techniques and achieves robust automated
retriever evaluation by minimal retrieval facts extraction and comprehensive
retrieval metrics. Based on real user queries, this method enables fully
automated retriever evaluation at low cost, thereby obtaining optimal retriever
for specific business scenarios. We validate our method across classic RAG
applications in rednote, including knowledge-based Q&A system and
retrieval-based travel assistant, successfully obtaining scenario-specific
optimal retrievers.

### 10. USD: A User-Intent-Driven Sampling and Dual-Debiasing Framework for Large-Scale Homepage Recommendations

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Jiaqi Zheng, Cheng Guo, Yi Cao, Chaoqun Hou, Tong Liu, Bo Zheng
- **URL**: <http://arxiv.org/abs/2507.06503v2>
- **Submitted**: 2025-07-09 03:02:23
- **Topic Keywords**: click, ctr, click-through rate, recommend
- **Reason**: The paper focuses on recommender systems, specifically large-scale homepage recommendations, which is somewhat related to the user's interests in Information Retrieval and Search technologies. However, the paper's emphasis on user intent-aware sampling and debiasing is not directly aligned with the user's primary focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large-scale homepage recommendations face critical challenges from
pseudo-negative samples caused by exposure bias, where non-clicks may indicate
inattention rather than disinterest. Existing work lacks thorough analysis of
invalid exposures and typically addresses isolated aspects (e.g., sampling
strategies), overlooking the critical impact of pseudo-positive samples - such
as homepage clicks merely to visit marketing portals. We propose a unified
framework for large-scale homepage recommendation sampling and debiasing. Our
framework consists of two key components: (1) a user intent-aware negative
sampling module to filter invalid exposure samples, and (2) an intent-driven
dual-debiasing module that jointly corrects exposure bias and click bias.
Extensive online experiments on Taobao demonstrate the efficacy of our
framework, achieving significant improvements in user click-through rates
(UCTR) by 35.4% and 14.5% in two variants of the marketing block on the Taobao
homepage, Baiyibutie and Taobaomiaosha.

### 11. Checklist Engineering Empowers Multilingual LLM Judges

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Mohammad Ghiasvand Mohammadkhani, Hamid Beigy
- **URL**: <http://arxiv.org/abs/2507.06774v1>
- **Submitted**: 2025-07-09 12:03:06
- **Topic Keywords**: pointwise, pairwise
- **Reason**: The paper explores the use of Large Language Models (LLMs) for text evaluation in multilingual contexts, which is related to my interests in NLP and search technologies. However, the focus on multilingual evaluation and the use of proprietary models (GPT-4o) limits the relevance to my primary research themes in information retrieval and query understanding.

#### Abstract
> Automated text evaluation has long been a central issue in Natural Language
Processing (NLP). Recently, the field has shifted toward using Large Language
Models (LLMs) as evaluators-a trend known as the LLM-as-a-Judge paradigm. While
promising and easily adaptable across tasks, this approach has seen limited
exploration in multilingual contexts. Existing multilingual studies often rely
on proprietary models or require extensive training data for fine-tuning,
raising concerns about cost, time, and efficiency. In this paper, we propose
Checklist Engineering based LLM-as-a-Judge (CE-Judge), a training-free
framework that uses checklist intuition for multilingual evaluation with an
open-source model. Experiments across multiple languages and three benchmark
datasets, under both pointwise and pairwise settings, show that our method
generally surpasses the baselines and performs on par with the GPT-4o model.

### 12. Reward Models Can Improve Themselves: Reward-Guided Adversarial Failure Mode Discovery for Robust Reward Modeling

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Pankayaraj Pathmanathan, Furong Huang
- **URL**: <http://arxiv.org/abs/2507.06419v1>
- **Submitted**: 2025-07-08 21:56:33
- **Topic Keywords**: ranking, rag, rank
- **Reason**: The paper is somewhat related to information retrieval, as it discusses reward modeling for large language models, which is used in tasks such as ranking. However, the focus is on robustness and failure mode discovery, which is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Reward modeling (RM), which captures human preferences to align large
language models (LLMs), is increasingly employed in tasks such as model
finetuning, response filtering, and ranking. However, due to the inherent
complexity of human preferences and the limited coverage of available datasets,
reward models often fail under distributional shifts or adversarial
perturbations. Existing approaches for identifying such failure modes typically
rely on prior knowledge about preference distributions or failure attributes,
limiting their practicality in real-world settings where such information is
unavailable. In this work, we propose a tractable, preference-distribution
agnostic method for discovering reward model failure modes via reward guided
controlled decoding. Building on this, we introduce REFORM, a self-improving
reward modeling framework that enhances robustness by using the reward model
itself to guide the generation of falsely scored responses. These adversarial
examples are then used to augment the training data and patch the reward
model's misaligned behavior. We evaluate REFORM on two widely used preference
datasets Anthropic Helpful Harmless (HH) and PKU Beavertails and demonstrate
that it significantly improves robustness without sacrificing reward quality.
Notably, REFORM preserves performance both in direct evaluation and in
downstream policy training, and further improves alignment quality by removing
spurious correlations.

### 13. GR-LLMs: Recent Advances in Generative Recommendation Based on Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Zhen Yang, Haitao Lin, Jiawei xue, Ziji Zhang
- **URL**: <http://arxiv.org/abs/2507.06507v1>
- **Submitted**: 2025-07-09 03:13:08
- **Comment**: 8 pages, 3 figures
- **Topic Keywords**: rag, recommend, search
- **Reason**: The paper focuses on Generative Recommendations and Large Language Models, which is related to your interest in Information Retrieval and Search technologies. However, the paper's primary focus on recommender systems and its lack of direct connection to query understanding, ranking models, and user behavior modeling make it only loosely relevant to your research interests.

#### Abstract
> In the past year, Generative Recommendations (GRs) have undergone substantial
advancements, especially in leveraging the powerful sequence modeling and
reasoning capabilities of Large Language Models (LLMs) to enhance overall
recommendation performance. LLM-based GRs are forming a new paradigm that is
distinctly different from discriminative recommendations, showing strong
potential to replace traditional recommendation systems heavily dependent on
complex hand-crafted features. In this paper, we provide a comprehensive survey
aimed at facilitating further research of LLM-based GRs. Initially, we outline
the general preliminaries and application cases of LLM-based GRs. Subsequently,
we introduce the main considerations when LLM-based GRs are applied in real
industrial scenarios. Finally, we explore promising directions for LLM-based
GRs. We hope that this survey contributes to the ongoing advancement of the GR
domain.

### 14. PERK: Long-Context Reasoning as Parameter-Efficient Test-Time Learning

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Zeming Chen, Angelika Romanou, Gail Weiss, Antoine Bosselut
- **URL**: <http://arxiv.org/abs/2507.06415v1>
- **Submitted**: 2025-07-08 21:38:45
- **Comment**: 10 pages, 7 figures
- **Topic Keywords**: rag, rank, search
- **Reason**: The paper proposes a method for long-context reasoning, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on the topic of learning to encode context, it does not specifically address ranking models or user behavior modeling. The paper's focus on natural language processing and data mining is relevant, but the connection to information retrieval is tenuous.

#### Abstract
> Long-context reasoning requires accurately identifying relevant information
in extensive, noisy input contexts. Previous research shows that using
test-time learning to encode context directly into model parameters can
effectively enable reasoning over noisy information. However, meta-learning
methods for enabling test-time learning are prohibitively memory-intensive,
preventing their application to long context settings. In this work, we propose
PERK (Parameter Efficient Reasoning over Knowledge), a scalable approach for
learning to encode long input contexts using gradient updates to a lightweight
model adapter at test time. Specifically, PERK employs two nested optimization
loops in a meta-training phase. The inner loop rapidly encodes contexts into a
low-rank adapter (LoRA) that serves as a parameter-efficient memory module for
the base model. Concurrently, the outer loop learns to use the updated adapter
to accurately recall and reason over relevant information from the encoded long
context. Our evaluations on several long-context reasoning tasks show that PERK
significantly outperforms the standard prompt-based long-context baseline,
achieving average absolute performance gains of up to 90% for smaller models
(GPT-2) and up to 27% for our largest evaluated model, Qwen-2.5-0.5B. In
general, PERK is more robust to reasoning complexity, length extrapolation, and
the locations of relevant information in contexts. Finally, we show that while
PERK is memory-intensive during training, it scales more efficiently at
inference time than prompt-based long-context inference.

### 15. A Systematic Analysis of Hybrid Linear Attention

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Dustin Wang, Rui-Jie Zhu, Steven Abreu, Yong Shan, Taylor Kergan, Yuqi Pan, Yuhong Chou, Zheng Li, Ge Zhang, Wenhao Huang, Jason Eshraghian
- **URL**: <http://arxiv.org/abs/2507.06457v1>
- **Submitted**: 2025-07-08 23:54:11
- **Topic Keywords**: recommend, search
- **Reason**: The paper focuses on linear attention mechanisms and hybrid architectures, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the paper's primary focus is on language modeling and recall tasks, which is not directly aligned with the user's research interests in user behavior modeling and real-time relevance optimization.

#### Abstract
> Transformers face quadratic complexity and memory issues with long sequences,
prompting the adoption of linear attention mechanisms using fixed-size hidden
states. However, linear models often suffer from limited recall performance,
leading to hybrid architectures that combine linear and full attention layers.
Despite extensive hybrid architecture research, the choice of linear attention
component has not been deeply explored. We systematically evaluate various
linear attention models across generations - vector recurrences to advanced
gating mechanisms - both standalone and hybridized. To enable this
comprehensive analysis, we trained and open-sourced 72 models: 36 at 340M
parameters (20B tokens) and 36 at 1.3B parameters (100B tokens), covering six
linear attention variants across five hybridization ratios. Benchmarking on
standard language modeling and recall tasks reveals that superior standalone
linear models do not necessarily excel in hybrids. While language modeling
remains stable across linear-to-full attention ratios, recall significantly
improves with increased full attention layers, particularly below a 3:1 ratio.
Our study highlights selective gating, hierarchical recurrence, and controlled
forgetting as critical for effective hybrid models. We recommend architectures
such as HGRN-2 or GatedDeltaNet with a linear-to-full ratio between 3:1 and 6:1
to achieve Transformer-level recall efficiently. Our models are open-sourced at
https://huggingface.co/collections/m-a-p/hybrid-linear-attention-research-686c488a63d609d2f20e2b1e.

### 16. Perception-Aware Policy Optimization for Multimodal Reasoning

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Zhenhailong Wang, Xuehang Guo, Sofia Stoica, Haiyang Xu, Hongru Wang, Hyeonjeong Ha, Xiusi Chen, Yangyi Chen, Ming Yan, Fei Huang, Heng Ji
- **URL**: <http://arxiv.org/abs/2507.06448v1>
- **Submitted**: 2025-07-08 23:22:34
- **Topic Keywords**: rag
- **Reason**: The paper proposes a reinforcement learning approach to multimodal reasoning, which is not directly related to information retrieval or search technologies. While it involves learning objectives and optimization techniques, the focus is on visual perception and multimodal reasoning, which is not a core area of interest for the user.

#### Abstract
> Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be a
highly effective strategy for endowing Large Language Models (LLMs) with robust
multi-step reasoning abilities. However, its design and optimizations remain
tailored to purely textual domains, resulting in suboptimal performance when
applied to multimodal reasoning tasks. In particular, we observe that a major
source of error in current multimodal reasoning lies in the perception of
visual inputs. To address this bottleneck, we propose Perception-Aware Policy
Optimization (PAPO), a simple yet effective extension of GRPO that encourages
the model to learn to perceive while learning to reason, entirely from internal
supervision signals. Notably, PAPO does not rely on additional data curation,
external reward models, or proprietary models. Specifically, we introduce the
Implicit Perception Loss in the form of a KL divergence term to the GRPO
objective, which, despite its simplicity, yields significant overall
improvements (4.4%) on diverse multimodal benchmarks. The improvements are more
pronounced, approaching 8.0%, on tasks with high vision dependency. We also
observe a substantial reduction (30.5%) in perception errors, indicating
improved perceptual capabilities with PAPO. We conduct comprehensive analysis
of PAPO and identify a unique loss hacking issue, which we rigorously analyze
and mitigate through a Double Entropy Loss. Overall, our work introduces a
deeper integration of perception-aware supervision into RLVR learning
objectives and lays the groundwork for a new RL framework that encourages
visually grounded reasoning. Project page: https://mikewangwzhl.github.io/PAPO.

### 17. CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs

- **LLM Score**: 2
- **Keyword Score**: 10
- **Authors**: Garapati Keerthana, Manik Gupta
- **URL**: <http://arxiv.org/abs/2507.06715v1>
- **Submitted**: 2025-07-09 10:13:38
- **Comment**: 12 pages, 4 figures
- **Topic Keywords**: queries, relevance, rag, retrieval
- **Reason**: The paper focuses on clinical text generation using LLMs, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on clinical note types and structured text generation is also not aligned with the user's background in e-commerce and interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> Large language models (LLMs), including zero-shot and few-shot paradigms,
have shown promising capabilities in clinical text generation. However,
real-world applications face two key challenges: (1) patient data is highly
unstructured, heterogeneous, and scattered across multiple note types and (2)
clinical notes are often long and semantically dense, making naive prompting
infeasible due to context length constraints and the risk of omitting
clinically relevant information.
  We introduce CLI-RAG (Clinically Informed Retrieval-Augmented Generation), a
domain-specific framework for structured and clinically grounded text
generation using LLMs. It incorporates a novel hierarchical chunking strategy
that respects clinical document structure and introduces a task-specific
dual-stage retrieval mechanism. The global stage identifies relevant note types
using evidence-based queries, while the local stage extracts high-value content
within those notes creating relevance at both document and section levels.
  We apply the system to generate structured progress notes for individual
hospital visits using 15 clinical note types from the MIMIC-III dataset.
Experiments show that it preserves temporal and semantic alignment across
visits, achieving an average alignment score of 87.7%, surpassing the 80.7%
baseline from real clinician-authored notes. The generated outputs also
demonstrate high consistency across LLMs, reinforcing deterministic behavior
essential for reproducibility, reliability, and clinical trust.

### 18. VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Ziang Ye, Yang Zhang, Wentao Shi, Xiaoyu You, Fuli Feng, Tat-Seng Chua
- **URL**: <http://arxiv.org/abs/2507.06899v1>
- **Submitted**: 2025-07-09 14:36:00
- **Topic Keywords**: ltr, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on visual grounding manipulation and backdoor attacks on GUI agents, which is outside the scope of your research areas.

#### Abstract
> Graphical User Interface (GUI) agents powered by Large Vision-Language Models
(LVLMs) have emerged as a revolutionary approach to automating human-machine
interactions, capable of autonomously operating personal devices (e.g., mobile
phones) or applications within the device to perform complex real-world tasks
in a human-like manner. However, their close integration with personal devices
raises significant security concerns, with many threats, including backdoor
attacks, remaining largely unexplored. This work reveals that the visual
grounding of GUI agent-mapping textual plans to GUI elements-can introduce
vulnerabilities, enabling new types of backdoor attacks. With backdoor attack
targeting visual grounding, the agent's behavior can be compromised even when
given correct task-solving plans. To validate this vulnerability, we propose
VisualTrap, a method that can hijack the grounding by misleading the agent to
locate textual plans to trigger locations instead of the intended targets.
VisualTrap uses the common method of injecting poisoned data for attacks, and
does so during the pre-training of visual grounding to ensure practical
feasibility of attacking. Empirical results show that VisualTrap can
effectively hijack visual grounding with as little as 5% poisoned data and
highly stealthy visual triggers (invisible to the human eye); and the attack
can be generalized to downstream tasks, even after clean fine-tuning. Moreover,
the injected trigger can remain effective across different GUI environments,
e.g., being trained on mobile/web and generalizing to desktop environments.
These findings underscore the urgent need for further research on backdoor
attack risks in GUI agents.

### 19. Temporal Analysis of Climate Policy Discourse: Insights from Dynamic Embedded Topic Modeling

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Rafiu Adekoya Badekale, Adewale Akinfaderin
- **URL**: <http://arxiv.org/abs/2507.06435v1>
- **Submitted**: 2025-07-08 22:30:01
- **Comment**: 10 pages, 7 figures. Code and data available at
  https://github.com/AdeTheBade/TACPD.git
- **Topic Keywords**: relevance, search
- **Reason**: The paper's focus on temporal analysis of climate policy discourse using dynamic embedded topic modeling is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's methodology and application are also outside the user's e-commerce domain expertise.

#### Abstract
> Understanding how policy language evolves over time is critical for assessing
global responses to complex challenges such as climate change. Temporal
analysis helps stakeholders, including policymakers and researchers, to
evaluate past priorities, identify emerging themes, design governance
strategies, and develop mitigation measures. Traditional approaches, such as
manual thematic coding, are time-consuming and limited in capturing the
complex, interconnected nature of global policy discourse. With the increasing
relevance of unsupervised machine learning, these limitations can be addressed,
particularly under high-volume, complex, and high-dimensional data conditions.
In this work, we explore a novel approach that applies the dynamic embedded
topic model (DETM) to analyze the evolution of global climate policy discourse.
A probabilistic model designed to capture the temporal dynamics of topics over
time. We collected a corpus of United Nations Framework Convention on Climate
Change (UNFCCC) policy decisions from 1995 to 2023, excluding 2020 due to the
postponement of COP26 as a result of the COVID-19 pandemic. The model reveals
shifts from early emphases on greenhouse gases and international conventions to
recent focuses on implementation, technical collaboration, capacity building,
finance, and global agreements. Section 3 presents the modeling pipeline,
including preprocessing, model training, and visualization of temporal word
distributions. Our results show that DETM is a scalable and effective tool for
analyzing the evolution of global policy discourse. Section 4 discusses the
implications of these findings and we concluded with future directions and
refinements to extend this approach to other policy domains.

### 20. Boosting Parameter Efficiency in LLM-Based Recommendation through Sophisticated Pruning

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Shanle Zheng, Keqin Bao, Jizhi Zhang, Yang Zhang, Fuli Feng, Xiangnan He
- **URL**: <http://arxiv.org/abs/2507.07064v1>
- **Submitted**: 2025-07-09 17:26:10
- **Topic Keywords**: rag, recommend
- **Reason**: The paper focuses on recommender systems and parameter pruning, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions LLMs, it does not explore query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user.

#### Abstract
> LLM-based recommender systems have made significant progress; however, the
deployment cost associated with the large parameter volume of LLMs still
hinders their real-world applications. This work explores parameter pruning to
improve parameter efficiency while maintaining recommendation quality, thereby
enabling easier deployment. Unlike existing approaches that focus primarily on
inter-layer redundancy, we uncover intra-layer redundancy within components
such as self-attention and MLP modules. Building on this analysis, we propose a
more fine-grained pruning approach that integrates both intra-layer and
layer-wise pruning. Specifically, we introduce a three-stage pruning strategy
that progressively prunes parameters at different levels and parts of the
model, moving from intra-layer to layer-wise pruning, or from width to depth.
Each stage also includes a performance restoration step using distillation
techniques, helping to strike a balance between performance and parameter
efficiency. Empirical results demonstrate the effectiveness of our approach:
across three datasets, our models achieve an average of 88% of the original
model's performance while pruning more than 95% of the non-embedding
parameters. This underscores the potential of our method to significantly
reduce resource requirements without greatly compromising recommendation
quality. Our code will be available at: https://github.com/zheng-sl/PruneRec

### 21. FlexOlmo: Open Language Models for Flexible Data Use

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Weijia Shi, Akshita Bhagia, Kevin Farhat, Niklas Muennighoff, Pete Walsh, Jacob Morrison, Dustin Schwenk, Shayne Longpre, Jake Poznanski, Allyson Ettinger, Daogao Liu, Margaret Li, Dirk Groeneveld, Mike Lewis, Wen-tau Yih, Luca Soldaini, Kyle Lo, Noah A. Smith, Luke Zettlemoyer, Pang Wei Koh, Hannaneh Hajishirzi, Ali Farhadi, Sewon Min
- **URL**: <http://arxiv.org/abs/2507.07024v1>
- **Submitted**: 2025-07-09 16:54:21
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on language models and their applications, but does not seem to be directly related to information retrieval, search technologies, or query understanding. The topics of data mining and NLP are somewhat relevant, but the paper's focus on data sharing and data ownership is not aligned with the user's interests.

#### Abstract
> We introduce FlexOlmo, a new class of language models (LMs) that supports (1)
distributed training without data sharing, where different model parameters are
independently trained on closed datasets, and (2) data-flexible inference,
where these parameters along with their associated data can be flexibly
included or excluded from model inferences with no further training. FlexOlmo
employs a mixture-of-experts (MoE) architecture where each expert is trained
independently on closed datasets and later integrated through a new
domain-informed routing without any joint training. FlexOlmo is trained on
FlexMix, a corpus we curate comprising publicly available datasets alongside
seven domain-specific sets, representing realistic approximations of closed
sets. We evaluate models with up to 37 billion parameters (20 billion active)
on 31 diverse downstream tasks. We show that a general expert trained on public
data can be effectively combined with independently trained experts from other
data owners, leading to an average 41% relative improvement while allowing
users to opt out of certain data based on data licensing or permission
requirements. Our approach also outperforms prior model merging methods by
10.1% on average and surpasses the standard MoE trained without data
restrictions using the same training FLOPs. Altogether, this research presents
a solution for both data owners and researchers in regulated industries with
sensitive or protected data. FlexOlmo enables benefiting from closed data while
respecting data owners' preferences by keeping their data local and supporting
fine-grained control of data access during inference.

### 22. SCoRE: Streamlined Corpus-based Relation Extraction using Multi-Label Contrastive Learning and Bayesian kNN

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Luca Mariotti, Veronica Guidetti, Federica Mandreoli
- **URL**: <http://arxiv.org/abs/2507.06895v1>
- **Submitted**: 2025-07-09 14:33:07
- **Topic Keywords**: rag, recommend
- **Reason**: This paper focuses on relation extraction, a topic outside of the user's primary research interests in Information Retrieval and Search technologies. While it mentions large language models and benchmark datasets, the paper's scope and methodology are not directly related to query understanding, ranking models, or user behavior modeling.

#### Abstract
> The growing demand for efficient knowledge graph (KG) enrichment leveraging
external corpora has intensified interest in relation extraction (RE),
particularly under low-supervision settings. To address the need for adaptable
and noise-resilient RE solutions that integrate seamlessly with pre-trained
large language models (PLMs), we introduce SCoRE, a modular and cost-effective
sentence-level RE system. SCoRE enables easy PLM switching, requires no
finetuning, and adapts smoothly to diverse corpora and KGs. By combining
supervised contrastive learning with a Bayesian k-Nearest Neighbors (kNN)
classifier for multi-label classification, it delivers robust performance
despite the noisy annotations of distantly supervised corpora. To improve RE
evaluation, we propose two novel metrics: Correlation Structure Distance (CSD),
measuring the alignment between learned relational patterns and KG structures,
and Precision at R (P@R), assessing utility as a recommender system. We also
release Wiki20d, a benchmark dataset replicating real-world RE conditions where
only KG-derived annotations are available. Experiments on five benchmarks show
that SCoRE matches or surpasses state-of-the-art methods while significantly
reducing energy consumption. Further analyses reveal that increasing model
complexity, as seen in prior work, degrades performance, highlighting the
advantages of SCoRE's minimal design. Combining efficiency, modularity, and
scalability, SCoRE stands as an optimal choice for real-world RE applications.

### 23. CDC: Causal Domain Clustering for Multi-Domain Recommendation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Huishi Luo, Yiqing Wu, Yiwen Chen, Fuzhen Zhuang, Deqing Wang
- **URL**: <http://arxiv.org/abs/2507.06877v1>
- **Submitted**: 2025-07-09 14:15:47
- **Comment**: Accepted at SIGIR 2025
- **Topic Keywords**: rag, recommend
- **Reason**: This paper focuses on multi-domain recommendation, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it mentions clustering and affinity matrices, the context is different from the user's areas of focus, and the paper does not explore query understanding, ranking models, or user behavior modeling.

#### Abstract
> Multi-domain recommendation leverages domain-general knowledge to improve
recommendations across several domains. However, as platforms expand to dozens
or hundreds of scenarios, training all domains in a unified model leads to
performance degradation due to significant inter-domain differences. Existing
domain grouping methods, based on business logic or data similarities, often
fail to capture the true transfer relationships required for optimal grouping.
To effectively cluster domains, we propose Causal Domain Clustering (CDC). CDC
models domain transfer patterns within a large number of domains using two
distinct effects: the Isolated Domain Affinity Matrix for modeling
non-interactive domain transfers, and the Hybrid Domain Affinity Matrix for
considering dynamic domain synergy or interference under joint training. To
integrate these two transfer effects, we introduce causal discovery to
calculate a cohesion-based coefficient that adaptively balances their
contributions. A Co-Optimized Dynamic Clustering algorithm iteratively
optimizes target domain clustering and source domain selection for training.
CDC significantly enhances performance across over 50 domains on public
datasets and in industrial settings, achieving a 4.9% increase in online eCPM.
Code is available at
https://github.com/Chrissie-Law/Causal-Domain-Clustering-for-Multi-Domain-Recommendation

### 24. InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Huisheng Wang, Zhuoshi Pan, Hangjing Zhang, Mingxiao Liu, Hanqing Gao, H. Vicky Zhao
- **URL**: <http://arxiv.org/abs/2507.06528v1>
- **Submitted**: 2025-07-09 04:07:22
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on aligning large language models with investor decision-making processes under herd behavior, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on natural language processing, the context is specific to behavioral finance and does not align with the user's primary research interests.

#### Abstract
> Aligning Large Language Models (LLMs) with investor decision-making processes
under herd behavior is a critical challenge in behavioral finance, which
grapples with a fundamental limitation: the scarcity of real-user data needed
for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM
outputs and human behavioral patterns, its reliance on massive authentic data
imposes substantial collection costs and privacy risks. We propose InvestAlign,
a novel framework that constructs high-quality SFT datasets by leveraging
theoretical solutions to similar and simple optimal investment problems rather
than complex scenarios. Our theoretical analysis demonstrates that training
LLMs with InvestAlign-generated data achieves faster parameter convergence than
using real-user data, suggesting superior learning efficiency. Furthermore, we
develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which
demonstrates significantly closer alignment to real-user data than pre-SFT
models in both simple and complex investment problems. This highlights our
proposed InvestAlign as a promising approach with the potential to address
complex optimal investment problems and align LLMs with investor
decision-making processes under herd behavior. Our code is publicly available
at https://github.com/thu-social-network-research-group/InvestAlign.

### 25. SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Zicong Tang, Shi Luohe, Zuchao Li, Baoyuan Qi, Guoming Liu, Lefei Zhang, Ping Wang
- **URL**: <http://arxiv.org/abs/2507.06517v1>
- **Submitted**: 2025-07-09 03:33:44
- **Comment**: Accepted by ACL 2025 main
- **Topic Keywords**: query
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on KV cache reduction methods for Large Language Models, which is outside your primary focus area.

#### Abstract
> Large Language Models (LLMs) have achieved impressive accomplishments in
recent years. However, the increasing memory consumption of KV cache has
possessed a significant challenge to the inference system. Eviction methods
have revealed the inherent redundancy within the KV cache, demonstrating its
potential for reduction, particularly in deeper layers. However, KV cache
reduction for shallower layers has been found to be insufficient. Based on our
observation that, the KV cache exhibits a high degree of similarity. Based on
this observation, we proposed a novel KV cache reduction method, SpindleKV,
which balances both shallow and deep layers. For deep layers, we employ an
attention weight based eviction method, while for shallow layers, we apply a
codebook based replacement approach which is learnt by similarity and merging
policy. Moreover, SpindleKV addressed the Grouped-Query Attention (GQA) dilemma
faced by other attention based eviction methods. Experiments on two common
benchmarks with three different LLMs shown that SpindleKV obtained better KV
cache reduction effect compared to baseline methods, while preserving similar
or even better model performance.

### 26. Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Russell Taylor, Benjamin Herbert, Michael Sana
- **URL**: <http://arxiv.org/abs/2507.06506v1>
- **Submitted**: 2025-07-09 03:09:14
- **Comment**: CLEF 2025 Working Notes, 9-12 September 2025, Madrid, Spain
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on translating puns from English to French using large language models and specialized techniques, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on linguistic creativity and humor, it does not address query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user.

#### Abstract
> Translating wordplay across languages presents unique challenges that have
long confounded both professional human translators and machine translation
systems. This research proposes a novel approach for translating puns from
English to French by combining state-of-the-art large language models with
specialized techniques for wordplay generation.
  Our methodology employs a three-stage approach. First, we establish a
baseline using multiple frontier large language models with feedback based on a
new contrastive learning dataset. Second, we implement a guided
chain-of-thought pipeline with combined phonetic-semantic embeddings. Third, we
implement a multi-agent generator-discriminator framework for evaluating and
regenerating puns with feedback.
  Moving beyond the limitations of literal translation, our methodology's
primary objective is to capture the linguistic creativity and humor of the
source text wordplay, rather than simply duplicating its vocabulary. Our best
runs earned first and second place in the CLEF JOKER 2025 Task 2 competition
where they were evaluated manually by expert native French speakers.
  This research addresses a gap between translation studies and computational
linguistics by implementing linguistically-informed techniques for wordplay
translation, advancing our understanding of how language models can be
leveraged to handle the complex interplay between semantic ambiguity, phonetic
similarity, and the implicit cultural and linguistic awareness needed for
successful humor.

### 27. Growing Transformers: Modular Composition and Layer-wise Expansion on a Frozen Substrate

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: A. Bochkov
- **URL**: <http://arxiv.org/abs/2507.07129v1>
- **Submitted**: 2025-07-08 20:01:15
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on scaling large language models using a constructive approach, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on topics like model development and optimization, the primary focus is on the scaling of language models, which is outside the user's core research themes.

#### Abstract
> The prevailing paradigm for scaling large language models (LLMs) involves
monolithic, end-to-end training, a resource-intensive process that lacks
flexibility. This paper explores an alternative, constructive approach to model
development, built upon the foundation of non-trainable, deterministic input
embeddings. In prior [1], we established that high-level semantic reasoning can
emerge in Transformers using frozen embeddings derived from the visual
structure of Unicode glyphs. Here, we demonstrate that this fixed
representational substrate acts as a universal "docking port," enabling two
powerful and efficient scaling paradigms: seamless modular composition and
progressive layer-wise growth.
  First, we show that specialist models trained on disparate datasets (e.g.,
Russian and Chinese text) can be merged into a single, more capable
Mixture-of-Experts (MoE) model, post-training, with zero architectural
modification. This is achieved by simply averaging their output logits. The
resulting MoE model exhibits immediate performance improvements on reasoning
benchmarks like MMLU, surpassing its constituent experts without catastrophic
forgetting. Second, we introduce a layer-wise constructive training
methodology, where a deep Transformer is "grown" by progressively stacking and
training one layer at a time. This method demonstrates stable convergence and a
clear correlation between model depth and the emergence of complex reasoning
abilities, such as those required for SQuAD.
  Our findings suggest a paradigm shift from monolithic optimization towards a
more biological or constructive model of AI development, where complexity is
built incrementally and modules can be composed freely. This opens new avenues
for resource-efficient scaling, continual learning, and a more democratized
ecosystem for building powerful AI systems. We release all code and models to
facilitate further research.

### 28. Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Li Du, Hanyu Zhao, Yiming Ju, Tengfei Pan
- **URL**: <http://arxiv.org/abs/2507.06968v1>
- **Submitted**: 2025-07-09 15:59:02
- **Topic Keywords**: rag
- **Reason**: The paper focuses on instruction tuning and dataset construction for large-scale pretrained models, which is not directly related to Information Retrieval, Search technologies, or query understanding. Although it mentions model performance and generalizability, the context is specific to instruction following and task completion, which is not aligned with the user's research interests.

#### Abstract
> Instruction tuning has become a foundation for unlocking the capabilities of
large-scale pretrained models and improving their performance on complex tasks.
Thus, the construction of high-quality instruction datasets is crucial for
enhancing model performance and generalizability. Although current instruction
datasets have reached tens of millions of samples, models finetuned on them may
still struggle with complex instruction following and tasks in rare domains.
This is primarily due to limited expansion in both ``coverage'' (coverage of
task types and knowledge areas) and ``depth'' (instruction complexity) of the
instruction set. To address this issue, we propose a systematic instruction
data construction framework, which integrates a hierarchical labeling system,
an informative seed selection algorithm, an evolutionary data synthesis
process, and a model deficiency diagnosis with targeted data generation. These
components form an iterative closed-loop to continuously enhance the coverage
and depth of instruction data. Based on this framework, we construct
InfinityInstruct-Subject, a high-quality dataset containing ~1.5 million
instructions. Experiments on multiple foundation models and benchmark tasks
demonstrate its effectiveness in improving instruction-following capabilities.
Further analyses suggest that InfinityInstruct-Subject shows enlarged coverage
and depth compared to comparable synthesized instruction datasets. Our work
lays a theoretical and practical foundation for the efficient, continuous
evolution of instruction datasets, moving from data quantity expansion to
qualitative improvement.

### 29. Rethinking Verification for LLM Code Generation: From Generation to Testing

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zihan Ma, Taolin Zhang, Maosong Cao, Junnan Liu, Wenwei Zhang, Minnan Luo, Songyang Zhang, Kai Chen
- **URL**: <http://arxiv.org/abs/2507.06920v2>
- **Submitted**: 2025-07-09 14:58:47
- **Topic Keywords**: rag
- **Reason**: The paper focuses on code generation and verification, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions reinforcement learning, it is not applied to search or IR, and the paper's primary concern is code evaluation, not search or retrieval.

#### Abstract
> Large language models (LLMs) have recently achieved notable success in
code-generation benchmarks such as HumanEval and LiveCodeBench. However, a
detailed examination reveals that these evaluation suites often comprise only a
limited number of homogeneous test cases, resulting in subtle faults going
undetected. This not only artificially inflates measured performance but also
compromises accurate reward estimation in reinforcement learning frameworks
utilizing verifiable rewards (RLVR). To address these critical shortcomings, we
systematically investigate the test-case generation (TCG) task by proposing
multi-dimensional metrics designed to rigorously quantify test-suite
thoroughness. Furthermore, we introduce a human-LLM collaborative method
(SAGA), leveraging human programming expertise with LLM reasoning capability,
aimed at significantly enhancing both the coverage and the quality of generated
test cases. In addition, we develop a TCGBench to facilitate the study of the
TCG task. Experiments show that SAGA achieves a detection rate of 90.62% and a
verifier accuracy of 32.58% on TCGBench. The Verifier Accuracy (Verifier Acc)
of the code generation evaluation benchmark synthesized by SAGA is 10.78%
higher than that of LiveCodeBench-v6. These results demonstrate the
effectiveness of our proposed method. We hope this work contributes to building
a scalable foundation for reliable LLM code evaluation, further advancing RLVR
in code generation, and paving the way for automated adversarial test synthesis
and adaptive benchmark integration.

### 30. Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jing Liang, Hongyao Tang, Yi Ma, Jinyi Liu, Yan Zheng, Shuyue Hu, Lei Bai, Jianye Hao
- **URL**: <http://arxiv.org/abs/2507.06892v2>
- **Submitted**: 2025-07-09 14:29:45
- **Comment**: Preliminary version, v2, added more details and corrected some minor
  mistakes. Project page: https://anitaleungxx.github.io/ReMix
- **Topic Keywords**: rag
- **Reason**: The paper focuses on Reinforcement Learning and Large Language Models, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions policy gradient and proximal policy gradient, the context is different from the user's background in e-commerce and query understanding.

#### Abstract
> Reinforcement Learning (RL) has demonstrated its potential to improve the
reasoning ability of Large Language Models (LLMs). One major limitation of most
existing Reinforcement Finetuning (RFT) methods is that they are on-policy RL
in nature, i.e., data generated during the past learning process is not fully
utilized. This inevitably comes at a significant cost of compute and time,
posing a stringent bottleneck on continuing economic and efficient scaling. To
this end, we launch the renaissance of off-policy RL and propose Reincarnating
Mix-policy Proximal Policy Gradient (ReMix), a general approach to enable
on-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix
consists of three major components: (1) Mix-policy proximal policy gradient
with an increased Update-To-Data (UTD) ratio for efficient training; (2)
KL-Convex policy constraint to balance the trade-off between stability and
flexibility; (3) Policy reincarnation to achieve a seamless transition from
efficient early-stage learning to steady asymptotic improvement. In our
experiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base
models. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with
0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B
model) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math
reasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and
MATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level
performance with an over 30x to 450x reduction in training cost in terms of
rollout data volume. In addition, we reveal insightful findings via
multifaceted analysis, including the implicit preference for shorter responses
due to the Whipping Effect of off-policy discrepancy, the collapse mode of
self-reflection behavior under the presence of severe off-policyness, etc.

### 31. Adaptive Termination for Multi-round Parallel Reasoning: An Universal Semantic Entropy-Guided Framework

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zenan Xu, Zexuan Qiu, Guanhua Huang, Kun Li, Siheng Li, Chenchen Zhang, Kejiao Li, Qi Yi, Yuhao Jiang, Bo Zhou, Fengzong Lian, Zhanhui Kang
- **URL**: <http://arxiv.org/abs/2507.06829v1>
- **Submitted**: 2025-07-09 13:28:35
- **Comment**: 13 pages, 5 fiures
- **Topic Keywords**: rag
- **Reason**: The paper focuses on large language models, inference-time scaling, and parallel reasoning, which is not directly related to the user's interests in Information Retrieval, Search technologies, and query understanding. The concepts of semantic entropy and collaborative inference are not relevant to the user's research themes.

#### Abstract
> Recent advances in large language models (LLMs) have accelerated progress
toward artificial general intelligence, with inference-time scaling emerging as
a key technique. Contemporary approaches leverage either sequential reasoning
(iteratively extending chains of thought) or parallel reasoning (generating
multiple solutions simultaneously) to scale inference. However, both paradigms
face fundamental limitations: sequential scaling typically relies on arbitrary
token budgets for termination, leading to inefficiency or premature cutoff;
while parallel scaling often lacks coordination among parallel branches and
requires intrusive fine-tuning to perform effectively. In light of these
challenges, we aim to design a flexible test-time collaborative inference
framework that exploits the complementary strengths of both sequential and
parallel reasoning paradigms. Towards this goal, the core challenge lies in
developing an efficient and accurate intrinsic quality metric to assess model
responses during collaborative inference, enabling dynamic control and early
termination of the reasoning trace. To address this challenge, we introduce
semantic entropy (SE), which quantifies the semantic diversity of parallel
model responses and serves as a robust indicator of reasoning quality due to
its strong negative correlation with accuracy...

### 32. On the Effect of Uncertainty on Layer-wise Inference Dynamics

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sunwoo Kim, Haneul Yoo, Alice Oh
- **URL**: <http://arxiv.org/abs/2507.06722v1>
- **Submitted**: 2025-07-09 10:30:09
- **Comment**: Accepted to Actionable Interpretability Workshop - ICML 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on understanding the internal workings of large language models, specifically how they process uncertainty, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on interpretability methods, the connection to user behavior modeling, ranking models, or real-time relevance optimization is tenuous.

#### Abstract
> Understanding how large language models (LLMs) internally represent and
process their predictions is central to detecting uncertainty and preventing
hallucinations. While several studies have shown that models encode uncertainty
in their hidden states, it is underexplored how this affects the way they
process such hidden states. In this work, we demonstrate that the dynamics of
output token probabilities across layers for certain and uncertain outputs are
largely aligned, revealing that uncertainty does not seem to affect inference
dynamics. Specifically, we use the Tuned Lens, a variant of the Logit Lens, to
analyze the layer-wise probability trajectories of final prediction tokens
across 11 datasets and 5 models. Using incorrect predictions as those with
higher epistemic uncertainty, our results show aligned trajectories for certain
and uncertain predictions that both observe abrupt increases in confidence at
similar layers. We balance this finding by showing evidence that more competent
models may learn to process uncertainty differently. Our findings challenge the
feasibility of leveraging simplistic methods for detecting uncertainty at
inference. More broadly, our work demonstrates how interpretability methods may
be used to investigate the way uncertainty affects inference.

### 33. Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: James Stewart-Evans, Emma Wilson, Tessa Langley, Andrew Prayle, Angela Hands, Karen Exley, Jo Leonardi-Bee
- **URL**: <http://arxiv.org/abs/2507.06623v1>
- **Submitted**: 2025-07-09 07:50:55
- **Comment**: 44 pages, 4 figures
- **Topic Keywords**: recommend, search
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on data extraction using large language models and scoping review protocols, which is outside the scope of the user's research interests.

#### Abstract
> The data extraction stages of reviews are resource-intensive, and researchers
may seek to expediate data extraction using online (large language models) LLMs
and review protocols. Claude 3.5 Sonnet was used to trial two approaches that
used a review protocol to prompt data extraction from 10 evidence sources
included in a case study scoping review. A protocol-based approach was also
used to review extracted data. Limited performance evaluation was undertaken
which found high accuracy for the two extraction approaches (83.3% and 100%)
when extracting simple, well-defined citation details; accuracy was lower (9.6%
and 15.8%) when extracting more complex, subjective data items. Considering all
data items, both approaches had precision >90% but low recall (<25%) and F1
scores (<40%). The context of a complex scoping review, open response types and
methodological approach likely impacted performance due to missed and
misattributed data. LLM feedback considered the baseline extraction accurate
and suggested minor amendments: four of 15 (26.7%) to citation details and 8 of
38 (21.1%) to key findings data items were considered to potentially add value.
However, when repeating the process with a dataset featuring deliberate errors,
only 2 of 39 (5%) errors were detected. Review-protocol-based methods used for
expediency require more robust performance evaluation across a range of LLMs
and review contexts with comparison to conventional prompt engineering
approaches. We recommend researchers evaluate and report LLM performance if
using them similarly to conduct data extraction or review extracted data. LLM
feedback contributed to protocol adaptation and may assist future review
protocol drafting.

### 34. Impacts of Mainstream-Driven Algorithms on Recommendations for Children Across Domains: A Reproducibility Study

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Robin Ungruh, Alejandro Bellog√≠n, Dominik Kowald, Maria Soledad Pera
- **URL**: <http://arxiv.org/abs/2507.06596v1>
- **Submitted**: 2025-07-09 07:15:12
- **Comment**: Preprint of accepted RecSys 2025 contribution
- **Topic Keywords**: recommend, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The focus is on recommender systems, specifically for children, which is a niche area. The paper does not address deep semantic understanding, real-time relevance optimization, or e-commerce, which are key aspects of your research interests.

#### Abstract
> Children are often exposed to items curated by recommendation algorithms.
Yet, research seldom considers children as a user group, and when it does, it
is anchored on datasets where children are underrepresented, risking
overlooking their interests, favoring those of the majority, i.e., mainstream
users. Recently, Ungruh et al. demonstrated that children's consumption
patterns and preferences differ from those of mainstream users, resulting in
inconsistent recommendation algorithm performance and behavior for this user
group. These findings, however, are based on two datasets with a limited child
user sample. We reproduce and replicate this study on a wider range of datasets
in the movie, music, and book domains, uncovering interaction patterns and
aspects of child-recommender interactions consistent across domains, as well as
those specific to some user samples in the data. We also extend insights from
the original study with popularity bias metrics, given the interpretation of
results from the original study. With this reproduction and extension, we
uncover consumption patterns and differences between age groups stemming from
intrinsic differences between children and others, and those unique to specific
datasets or domains.

### 35. Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Srihari K B, Pushpak Bhattacharyya
- **URL**: <http://arxiv.org/abs/2507.06571v1>
- **Submitted**: 2025-07-09 05:59:06
- **Topic Keywords**: retrieval
- **Reason**: The paper focuses on a specific domain (food) and uses multimodal knowledge graphs, generative AI, and multimodal generation, which is not directly related to the user's interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper's emphasis on question answering and multimodal generation is also not aligned with the user's focus on real-time relevance optimization and deep semantic understanding.

#### Abstract
> We propose a unified food-domain QA framework that combines a large-scale
multimodal knowledge graph (MMKG) with generative AI. Our MMKG links 13,000
recipes, 3,000 ingredients, 140,000 relations, and 14,000 images. We generate
40,000 QA pairs using 40 templates and LLaVA/DeepSeek augmentation. Joint
fine-tuning of Meta LLaMA 3.1-8B and Stable Diffusion 3.5-Large improves
BERTScore by 16.2\%, reduces FID by 37.8\%, and boosts CLIP alignment by
31.1\%. Diagnostic analyses-CLIP-based mismatch detection (35.2\% to 7.3\%) and
LLaVA-driven hallucination checks-ensure factual and visual fidelity. A hybrid
retrieval-generation strategy achieves 94.1\% accurate image reuse and 85\%
adequacy in synthesis. Our results demonstrate that structured knowledge and
multimodal generation together enhance reliability and diversity in food QA.

### 36. Video-RTS: Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ziyang Wang, Jaehong Yoon, Shoubin Yu, Md Mohaiminul Islam, Gedas Bertasius, Mohit Bansal
- **URL**: <http://arxiv.org/abs/2507.06485v1>
- **Submitted**: 2025-07-09 02:06:13
- **Comment**: The first two authors contributed equally. Project page:
  https://sites.google.com/cs.unc.edu/videorts2025/
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to Information Retrieval (IR) or Search technologies, and does not address query understanding, ranking models, or user behavior modeling. The focus is on reinforcement learning and video reasoning, which is outside the user's primary research interests.

#### Abstract
> Despite advances in reinforcement learning (RL)-based video reasoning with
large language models (LLMs), data collection and finetuning remain significant
challenges. These methods often rely on large-scale supervised fine-tuning
(SFT) with extensive video data and long Chain-of-Thought (CoT) annotations,
making them costly and hard to scale. To address this, we present Video-RTS, a
new approach to improve video reasoning capability with drastically improved
data efficiency by combining data-efficient RL with a video-adaptive test-time
scaling (TTS) strategy. Based on observations about the data scaling of RL
samples, we skip the resource-intensive SFT step and employ efficient pure-RL
training with output-based rewards, requiring no additional annotations or
extensive fine-tuning. Furthermore, to utilize computational resources more
efficiently, we introduce a sparse-to-dense video TTS strategy that improves
inference by iteratively adding frames based on output consistency. We validate
our approach on multiple video reasoning benchmarks, showing that Video-RTS
surpasses existing video reasoning models by an average of 2.4% in accuracy
using only 3.6% training samples. For example, Video-RTS achieves a 4.2%
improvement on Video-Holmes, a recent and challenging video reasoning
benchmark, and a 2.6% improvement on MMVU. Notably, our pure RL training and
adaptive video TTS offer complementary strengths, enabling Video-RTS's strong
reasoning performance.

### 37. Learning Deliberately, Acting Intuitively: Unlocking Test-Time Reasoning in Multimodal LLMs

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yahan Yu, Yuyang Dong, Masafumi Oyamada
- **URL**: <http://arxiv.org/abs/2507.06999v1>
- **Submitted**: 2025-07-09 16:25:44
- **Comment**: Work in progress
- **Topic Keywords**: search
- **Reason**: This paper focuses on multimodal large language models, proposing a framework to improve reasoning ability without additional annotations or complex rewards. While it explores reasoning and training techniques, it does not directly relate to information retrieval, search technologies, or query understanding, which are the primary areas of interest.

#### Abstract
> Reasoning is a key capability for large language models (LLMs), particularly
when applied to complex tasks such as mathematical problem solving. However,
multimodal reasoning research still requires further exploration of modality
alignment and training costs. Many of these approaches rely on additional data
annotation and relevant rule-based rewards to enhance the understanding and
reasoning ability, which significantly increases training costs and limits
scalability. To address these challenges, we propose the
Deliberate-to-Intuitive reasoning framework (D2I) that improves the
understanding and reasoning ability of multimodal LLMs (MLLMs) without extra
annotations and complex rewards. Specifically, our method sets deliberate
reasoning strategies to enhance modality alignment only through the rule-based
format reward during training. While evaluating, the reasoning style shifts to
intuitive, which removes deliberate reasoning strategies during training and
implicitly reflects the model's acquired abilities in the response. D2I
outperforms baselines across both in-domain and out-of-domain benchmarks. Our
findings highlight the role of format reward in fostering transferable
reasoning skills in MLLMs, and inspire directions for decoupling training-time
reasoning depth from test-time response flexibility.

### 38. FRaN-X: FRaming and Narratives-eXplorer

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Artur Muratov, Hana Fatima Shaikh, Vanshikaa Jani, Tarek Mahmoud, Zhuohan Xie, Daniil Orel, Aaryamonvikram Singh, Yuxia Wang, Aadi Joshi, Hasan Iqbal, Ming Shan Hee, Dhruv Sahnan, Nikolaos Nikolaidis, Purifica√ß√£o Silvano, Dimitar Dimitrov, Roman Yangarber, Ricardo Campos, Al√≠pio Jorge, Nuno Guimar√£es, Elisa Sartori, Nicolas Stefanovitch, Giovanni Da San Martino, Jakub Piskorski, Preslav Nakov
- **URL**: <http://arxiv.org/abs/2507.06974v1>
- **Submitted**: 2025-07-09 16:04:51
- **Comment**: 19 pages, 13 figures, submitted to EMNLP 2025 - Demo Track
- **Topic Keywords**: search
- **Reason**: The paper focuses on a specific domain (media analysis) and uses techniques like sequence labeling and fine-grained role classification, which are not directly related to information retrieval, search technologies, or query understanding. While it involves text analysis, the scope is narrow and does not align with the user's broader interests in IR, NLP, and data mining.

#### Abstract
> We present FRaN-X, a Framing and Narratives Explorer that automatically
detects entity mentions and classifies their narrative roles directly from raw
text. FRaN-X comprises a two-stage system that combines sequence labeling with
fine-grained role classification to reveal how entities are portrayed as
protagonists, antagonists, or innocents, using a unique taxonomy of 22
fine-grained roles nested under these three main categories. The system
supports five languages (Bulgarian, English, Hindi, Russian, and Portuguese)
and two domains (the Russia-Ukraine Conflict and Climate Change). It provides
an interactive web interface for media analysts to explore and compare framing
across different sources, tackling the challenge of automatically detecting and
labeling how entities are framed. Our system allows end users to focus on a
single article as well as analyze up to four articles simultaneously. We
provide aggregate level analysis including an intuitive graph visualization
that highlights the narrative a group of articles are pushing. Our system
includes a search feature for users to look up entities of interest, along with
a timeline view that allows analysts to track an entity's role transitions
across different contexts within the article. The FRaN-X system and the trained
models are licensed under an MIT License. FRaN-X is publicly accessible at
https://fran-x.streamlit.app/ and a video demonstration is available at
https://youtu.be/VZVi-1B6yYk.

### 39. MultiJustice: A Chinese Dataset for Multi-Party, Multi-Charge Legal Prediction

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Xiao Wang, Jiahuan Pei, Diancheng Shui, Zhiguang Han, Xin Sun, Dawei Zhu, Xiaoyu Shen
- **URL**: <http://arxiv.org/abs/2507.06909v1>
- **Submitted**: 2025-07-09 14:47:00
- **Comment**: Accepted by NLPCC 2025
- **Topic Keywords**: search
- **Reason**: The paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on legal judgment prediction, large language models, and legal datasets, which are outside the user's areas of interest.

#### Abstract
> Legal judgment prediction offers a compelling method to aid legal
practitioners and researchers. However, the research question remains
relatively under-explored: Should multiple defendants and charges be treated
separately in LJP? To address this, we introduce a new dataset namely
multi-person multi-charge prediction (MPMCP), and seek the answer by evaluating
the performance of several prevailing legal large language models (LLMs) on
four practical legal judgment scenarios: (S1) single defendant with a single
charge, (S2) single defendant with multiple charges, (S3) multiple defendants
with a single charge, and (S4) multiple defendants with multiple charges. We
evaluate the dataset across two LJP tasks, i.e., charge prediction and penalty
term prediction. We have conducted extensive experiments and found that the
scenario involving multiple defendants and multiple charges (S4) poses the
greatest challenges, followed by S2, S3, and S1. The impact varies
significantly depending on the model. For example, in S4 compared to S1,
InternLM2 achieves approximately 4.5% lower F1-score and 2.8% higher LogD,
while Lawformer demonstrates around 19.7% lower F1-score and 19.0% higher LogD.
Our dataset and code are available at
https://github.com/lololo-xiao/MultiJustice-MPMCP.

### 40. Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Milena Pustet, Elisabeth Steffen, Helena Mihaljeviƒá, Grischa Stanjek, Yannis Illies
- **URL**: <http://arxiv.org/abs/2507.06734v1>
- **Submitted**: 2025-07-09 10:46:58
- **Topic Keywords**: search
- **Reason**: The paper's focus on AI-assisted content monitoring and collaboration with civil society organizations is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions AI tools, the context is specific to content moderation and not relevant to query understanding, ranking models, or user behavior modeling.

#### Abstract
> The role of civil society organizations (CSOs) in monitoring harmful online
content is increasingly crucial, especially as platform providers reduce their
investment in content moderation. AI tools can assist in detecting and
monitoring harmful content at scale. However, few open-source tools offer
seamless integration of AI models and social media monitoring infrastructures.
Given their thematic expertise and contextual understanding of harmful content,
CSOs should be active partners in co-developing technological tools, providing
feedback, helping to improve models, and ensuring alignment with stakeholder
needs and values, rather than as passive 'consumers'. However, collaborations
between the open source community, academia, and civil society remain rare, and
research on harmful content seldom translates into practical tools usable by
civil society actors. This work in progress explores how CSOs can be
meaningfully involved in an AI-assisted open-source monitoring tool of
anti-democratic movements on Telegram, which we are currently developing in
collaboration with CSO stakeholders.

---

