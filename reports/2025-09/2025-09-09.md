# Daily Papers Report - 2025-09-09

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Reasoning-enhanced Query Understanding through Decomposition and Interpretation

- **LLM Score**: 9
- **Keyword Score**: 18
- **Authors**: Yunfei Zhong, Jun Yang, Yixing Fan, Jiafeng Guo, Lixin Su, Maarten de Rijke, Ruqing Zhang, Dawei Yin, Xueqi Cheng
- **URL**: <http://arxiv.org/abs/2509.06544v1>
- **Submitted**: 2025-09-08 10:58:42
- **Topic Keywords**: dense retrieval, query, queries, ranking, rag, retrieval, rank, search
- **Reason**: This paper aligns closely with your interests in Information Retrieval, particularly query understanding and ranking models. The proposed approach, ReDI, leverages large language models to decompose and interpret complex queries, which is a key aspect of your research focus. The paper's emphasis on real-world complex queries and its evaluation on established benchmarks further supports its relevance.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Information Retrieval
- **Aim**: Improve information retrieval for complex user queries by leveraging reasoning capabilities of LLMs.
- **Rationale**: Traditional methods struggle with complex queries; LLMs can enhance comprehension and reasoning.
- **Ground**: ReDI framework with a three-stage pipeline: decomposition, interpretation, and fusion.
- **Experiment**: Evaluated on Coin dataset and BRIGHT/BEIR benchmarks using metrics like nDCG@10 and Recall@1.
- **Takeaway**: ReDI outperforms baselines, highlighting the effectiveness of reasoning-enhanced decomposition and two-stage fine-tuning. Distilled student models demonstrate potential for lightweight, efficient solutions.

#### Abstract
> Accurate inference of user intent is crucial for enhancing document retrieval
in modern search engines. While large language models (LLMs) have made
significant strides in this area, their effectiveness has predominantly been
assessed with short, keyword-based queries. As AI-driven search evolves,
long-form queries with intricate intents are becoming more prevalent, yet they
remain underexplored in the context of LLM-based query understanding (QU). To
bridge this gap, we introduce ReDI: a Reasoning-enhanced approach for query
understanding through Decomposition and Interpretation. ReDI leverages the
reasoning and comprehension capabilities of LLMs in a three-stage pipeline: (i)
it breaks down complex queries into targeted sub-queries to accurately capture
user intent; (ii) it enriches each sub-query with detailed semantic
interpretations to improve the query-document matching; and (iii) it
independently retrieves documents for each sub-query and employs a fusion
strategy to aggregate the results for the final ranking. We compiled a
large-scale dataset of real-world complex queries from a major search engine
and distilled the query understanding capabilities of teacher models into
smaller models for practical application. Experiments on BRIGHT and BEIR
demonstrate that ReDI consistently surpasses strong baselines in both sparse
and dense retrieval paradigms, affirming its effectiveness.

---

### 2. Language Bias in Information Retrieval: The Nature of the Beast and Mitigation Methods

- **LLM Score**: 9
- **Keyword Score**: 12
- **Authors**: Jinrui Yang, Fan Jiang, Timothy Baldwin
- **URL**: <http://arxiv.org/abs/2509.06195v1>
- **Submitted**: 2025-09-07 20:10:49
- **Comment**: Accepted at EMNLP MRL 2024
- **Topic Keywords**: information retrieval, queries, ranking, retrieval, rank
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of multilingual information retrieval, language fairness, and mitigation methods. The use of neural rankers and novel loss functions also aligns with your focus on deep semantic understanding and real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Language Bias in Multilingual Information Retrieval (MLIR)
- **Aim**: To ensure semantically equivalent queries in different languages yield equivalent ranking lists and mitigate language biases in MLIR systems.
- **Rationale**: Existing MLIR systems exhibit language biases, leading to unfair retrieval results for users querying in different languages.
- **Ground**: The study utilizes the MultiEuP-v2 dataset, a benchmark comprising 24 European languages with parallel query sets derived from human-annotated document tags.
- **Experiment**: The authors propose LaKDA, a new loss function designed to mitigate language biases in neural MLIR approaches. Experiments conducted using mBERT and XLM-R pretrained multilingual models demonstrate that LaKDA effectively improves language fairness (MRC@5) while maintaining or even enhancing retrieval performance (MRR@100).
- **Takeaway**: The research highlights the importance of parallel data for language fairness and emphasizes the need for query-level fairness to ensure equal access to relevant information regardless of the user's language.

#### Abstract
> Language fairness in multilingual information retrieval (MLIR) systems is
crucial for ensuring equitable access to information across diverse languages.
This paper sheds light on the issue, based on the assumption that queries in
different languages, but with identical semantics, should yield equivalent
ranking lists when retrieving on the same multilingual documents. We evaluate
the degree of fairness using both traditional retrieval methods, and a DPR
neural ranker based on mBERT and XLM-R. Additionally, we introduce `LaKDA', a
novel loss designed to mitigate language biases in neural MLIR approaches. Our
analysis exposes intrinsic language biases in current MLIR technologies, with
notable disparities across the retrieval methods, and the effectiveness of
LaKDA in enhancing language fairness.

---

### 3. Rethinking LLM Parametric Knowledge as Post-retrieval Confidence for Dynamic Retrieval and Reranking

- **LLM Score**: 8
- **Keyword Score**: 14
- **Authors**: Haoxiang Jin, Ronghan Li, Zixiang Lu, Qiguang Miao
- **URL**: <http://arxiv.org/abs/2509.06472v2>
- **Submitted**: 2025-09-08 09:37:20
- **Topic Keywords**: queries, ranking, rerank, rag, retrieval, rank
- **Reason**: This paper explores the application of Large Language Models (LLMs) in retrieval and reranking, which aligns with your interests in Information Retrieval and Search technologies. The focus on post-retrieval confidence and knowledge filtering also relates to your interest in query understanding and ranking models. However, the specific domain of LLMs and their limitations may not be a central match for your primary research focus.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Retrieval-Augmented Generation (RAG) Systems
- **Aim**: Enhance the accuracy and efficiency of RAG systems by addressing the lack of knowledge boundary awareness in Large Language Models (LLMs).
- **Rationale**: LLMs often struggle to differentiate between questions they can confidently answer with internal knowledge and those requiring external context retrieval.
- **Ground**: Confidence-Based Dynamic Retrieval (CBDR) approach leverages LLM confidence to dynamically adjust the retrieval process.
- **Experiment**: Experiments conducted using various Reranker models and fine-tuning on different downstream LLMs.
- **Takeaway**: CBDR achieves significant improvements in accuracy, efficiency, and cost-effectiveness compared to traditional RAG systems.

#### Abstract
> Large Language Models (LLMs) often generate inaccurate responses
(hallucinations) when faced with questions beyond their knowledge scope.
Retrieval-Augmented Generation (RAG) addresses this by leveraging external
knowledge, but a critical challenge remains: determining whether retrieved
contexts effectively enhance the model`s ability to answer specific queries.
This challenge underscores the importance of knowledge boundary awareness,
which current methods-relying on discrete labels or limited signals-fail to
address adequately, as they overlook the rich information in LLMs` continuous
internal hidden states. To tackle this, we propose a novel post-retrieval
knowledge filtering approach. First, we construct a confidence detection model
based on LLMs` internal hidden states to quantify how retrieved contexts
enhance the model`s confidence. Using this model, we build a preference dataset
(NQ_Rerank) to fine-tune a reranker, enabling it to prioritize contexts
preferred by the downstream LLM during reranking. Additionally, we introduce
Confidence-Based Dynamic Retrieval (CBDR), which adaptively triggers retrieval
based on the LLM`s initial confidence in the original question, reducing
knowledge conflicts and improving efficiency. Experimental results demonstrate
significant improvements in accuracy for context screening and end-to-end RAG
performance, along with a notable reduction in retrieval costs while
maintaining competitive accuracy.

---

### 4. UniSearch: Rethinking Search System with a Unified Generative Architecture

- **LLM Score**: 8
- **Keyword Score**: 11
- **Authors**: Jiahui Chen, Xiaoze Jiang, Zhibo Wang, Quanzhi Zhu, Junyao Zhao, Feng Hu, Kang Pan, Ao Xie, Maohua Pei, Zhiheng Qin, Hongjing Zhang, Zhixin Zhai, Xiaobo Guo, Runbin Zhou, Kefeng Wang, Mingyang Geng, Cheng Chen, Jingshan Lv, Yupeng Huang, Xiao Liang, Han Li
- **URL**: <http://arxiv.org/abs/2509.06887v1>
- **Submitted**: 2025-09-08 17:08:26
- **Topic Keywords**: query, ranking, rag, recommend, rank, search
- **Reason**: This paper proposes a unified generative search framework, UniSearch, which integrates a search generator and a video encoder to improve representation quality and generation accuracy. The framework's end-to-end architecture and joint optimization of components align with your interests in information retrieval and deep semantic understanding. However, the specific focus on video search and the Kuaishou Search platform may limit its direct relevance to your broader research interests in e-commerce and general search technologies.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Information Retrieval and Search
- **Aim**: To develop a novel unified generative search framework, UniSearch, that effectively handles long-tail queries in industrial search settings.
- **Rationale**: Traditional cascaded search architectures struggle with long-tail queries, which are less frequent and semantically complex.
- **Ground**: UniSearch leverages a BART-based Search Generator and a BERT-based Video Encoder trained on large-scale Kuaishou search datasets.
- **Experiment**: UniSearch was evaluated through offline experiments and online A/B testing in Kuaishou's live streaming and short-video search platforms.
- **Takeaway**: UniSearch significantly outperforms traditional architectures, achieving notable improvements in key metrics like play counts, click-through rates, and user engagement, particularly for long-tail queries and new users.

#### Abstract
> Modern search systems play a crucial role in facilitating information
acquisition. Traditional search engines typically rely on a cascaded
architecture, where results are retrieved through recall, pre-ranking, and
ranking stages. The complexity of designing and maintaining multiple modules
makes it difficult to achieve holistic performance gains. Recent advances in
generative recommendation have motivated the exploration of unified generative
search as an alternative. However, existing approaches are not genuinely
end-to-end: they typically train an item encoder to tokenize candidates first
and then optimize a generator separately, leading to objective inconsistency
and limited generalization. To address these limitations, we propose UniSearch,
a unified generative search framework for Kuaishou Search. UniSearch replaces
the cascaded pipeline with an end-to-end architecture that integrates a Search
Generator and a Video Encoder. The Generator produces semantic identifiers of
relevant items given a user query, while the Video Encoder learns latent item
embeddings and provides their tokenized representations. A unified training
framework jointly optimizes both components, enabling mutual enhancement and
improving representation quality and generation accuracy. Furthermore, we
introduce Search Preference Optimization (SPO), which leverages a reward model
and real user feedback to better align generation with user preferences.
Extensive experiments on industrial-scale datasets, together with online A/B
testing in both short-video and live search scenarios, demonstrate the strong
effectiveness and deployment potential of UniSearch. Notably, its deployment in
live search yields the largest single-experiment improvement in recent years of
our product's history, highlighting its practical value for real-world
applications.

---

### 5. Domain-Aware RAG: MoL-Enhanced RL for Efficient Training and Scalable Retrieval

- **LLM Score**: 8
- **Keyword Score**: 11
- **Authors**: Hao Lin, Peitong Xie, Jingxue Chen, Jie Lin, Qingkun Tang, Qianchun Lu
- **URL**: <http://arxiv.org/abs/2509.06650v1>
- **Submitted**: 2025-09-08 13:04:07
- **Topic Keywords**: query, ranking, rag, retrieval, rank
- **Reason**: This paper proposes a novel method for optimizing retrieval in Retrieval-Augmented Generation (RAG) systems, leveraging domain-aware reinforcement learning and multi-query late fusion. While not exclusively focused on e-commerce, the method's emphasis on domain-specific knowledge and scalable retrieval aligns with your interests in Information Retrieval and Search technologies. The paper's focus on optimizing retrieval performance and bridging knowledge gaps in RAG systems also resonates with your research themes.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Retrieval Augmented Generation (RAG)
- **Aim**: To enhance retrieval performance in RAG systems
- **Rationale**: Existing query augmentation techniques have limitations.
- **Ground**: MoLER addresses these limitations by leveraging continual learning, multi-query expansion, and reinforcement learning.
- **Experiment**: Experiments conducted on NFCORPUS and SCIFACT datasets demonstrate MoLER's superior performance compared to baseline methods.
- **Takeaway**: MoLER achieves state-of-the-art results in terms of Recall@1k, nDCG@10, Recall@10, and nDCG@10, showcasing its effectiveness and efficiency.

#### Abstract
> Retrieval-Augmented Generation (RAG) systems rely heavily on the retrieval
stage, particularly the coarse-ranking process. Existing coarse-ranking
optimization approaches often struggle to balance domain-specific knowledge
learning with query enhencement, resulting in suboptimal retrieval performance.
To address this challenge, we propose MoLER, a domain-aware RAG method that
uses MoL-Enhanced Reinforcement Learning to optimize retrieval. MoLER has a
two-stage pipeline: a continual pre-training (CPT) phase using a Mixture of
Losses (MoL) to balance domain-specific knowledge with general language
capabilities, and a reinforcement learning (RL) phase leveraging Group Relative
Policy Optimization (GRPO) to optimize query and passage generation for
maximizing document recall. A key innovation is our Multi-query Single-passage
Late Fusion (MSLF) strategy, which reduces computational overhead during RL
training while maintaining scalable inference via Multi-query Multi-passage
Late Fusion (MMLF). Extensive experiments on benchmark datasets show that MoLER
achieves state-of-the-art performance, significantly outperforming baseline
methods. MoLER bridges the knowledge gap in RAG systems, enabling robust and
scalable retrieval in specialized domains.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents

- **LLM Score**: 8
- **Keyword Score**: 6
- **Authors**: Junteng Liu, Yunji Li, Chi Zhang, Jingyang Li, Aili Chen, Ke Ji, Weiyu Cheng, Zijia Wu, Chengyu Du, Qidi Xu, Jiayuan Song, Zhengmao Zhu, Wenhu Chen, Pengyu Zhao, Junxian He
- **URL**: <http://arxiv.org/abs/2509.06501v1>
- **Submitted**: 2025-09-08 10:07:03
- **Topic Keywords**: query, rag, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly query understanding and ranking models, as it presents a novel approach to training long-horizon web agents using model-based exploration and iterative query evolution. The paper's focus on web browsing capabilities and information-seeking abilities aligns with your interests in search technologies and user behavior modeling. However, the paper's primary focus on Large Language Models and web agents is somewhat outside your core e-commerce domain expertise.

#### Abstract
> The paradigm of Large Language Models (LLMs) has increasingly shifted toward
agentic applications, where web browsing capabilities are fundamental for
retrieving information from diverse online sources. However, existing
open-source web agents either demonstrate limited information-seeking abilities
on complex tasks or lack transparent implementations. In this work, we identify
that the key challenge lies in the scarcity of challenging data for information
seeking. To address this limitation, we introduce WebExplorer: a systematic
data generation approach using model-based exploration and iterative,
long-to-short query evolution. This method creates challenging query-answer
pairs that require multi-step reasoning and complex web navigation. By
leveraging our curated high-quality dataset, we successfully develop advanced
web agent WebExplorer-8B through supervised fine-tuning followed by
reinforcement learning. Our model supports 128K context length and up to 100
tool calling turns, enabling long-horizon problem solving. Across diverse
information-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art
performance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able
to effectively search over an average of 16 turns after RL training, achieving
higher accuracy than WebSailor-72B on BrowseComp-en/zh and attaining the best
performance among models up to 100B parameters on WebWalkerQA and FRAMES.
Beyond these information-seeking tasks, our model also achieves strong
generalization on the HLE benchmark even though it is only trained on
knowledge-intensive QA data. These results highlight our approach as a
practical path toward long-horizon web agents.

### 7. Modeling shopper interest broadness with entropy-driven dialogue policy in the context of arbitrarily large product catalogs

- **LLM Score**: 7
- **Keyword Score**: 15
- **Authors**: Firas Jarboui, Issa Memari
- **URL**: <http://arxiv.org/abs/2509.06185v1>
- **Submitted**: 2025-09-07 19:30:09
- **Topic Keywords**: retriever, query, queries, retrieval, recommend, commerce, e-commerce, rank
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of conversational recommender systems and query understanding. However, it focuses more on the recommender system aspect and less on deep semantic understanding and real-time relevance optimization, which are your primary areas of interest.

#### Abstract
> Conversational recommender systems promise rich interactions for e-commerce,
but balancing exploration (clarifying user needs) and exploitation (making
recommendations) remains challenging, especially when deploying large language
models (LLMs) with vast product catalogs. We address this challenge by modeling
the breadth of user interest via the entropy of retrieval score distributions.
Our method uses a neural retriever to fetch relevant items for a user query and
computes the entropy of the re-ranked scores to dynamically route the dialogue
policy: low-entropy (specific) queries trigger direct recommendations, whereas
high-entropy (ambiguous) queries prompt exploratory questions. This simple yet
effective strategy allows an LLM-driven agent to remain aware of an arbitrarily
large catalog in real-time without bloating its context window.

### 8. AudioBoost: Increasing Audiobook Retrievability in Spotify Search with Synthetic Query Generation

- **LLM Score**: 7
- **Keyword Score**: 13
- **Authors**: Enrico Palumbo, Gustavo Penha, Alva Liu, Marcus Eltscheminov, Jefferson Carvalho dos Santos, Alice Wang, Hugues Bouchard, Humberto Jes√∫s Corona Pampin, Michelle Tran Luu
- **URL**: <http://arxiv.org/abs/2509.06452v1>
- **Submitted**: 2025-09-08 08:57:03
- **Comment**: EARL Workshop @ RecSys25
- **Topic Keywords**: query, queries, rag, click, retrieval, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in query understanding and ranking models. The use of synthetic query generation and Large Language Models (LLMs) is relevant to your interests in NLP and deep semantic understanding. However, the focus on audiobook retrievability in Spotify Search is somewhat niche and not directly aligned with your core research themes.

#### Abstract
> Spotify has recently introduced audiobooks as part of its catalog,
complementing its music and podcast offering. Search is often the first entry
point for users to access new items, and an important goal for Spotify is to
support users in the exploration of the audiobook catalog. More specifically,
we would like to enable users without a specific item in mind to broadly search
by topic, genre, story tropes, decade, and discover audiobooks, authors and
publishers they may like. To do this, we need to 1) inspire users to type more
exploratory queries for audiobooks and 2) augment our retrieval systems to
better deal with exploratory audiobook queries. This is challenging in a
cold-start scenario, where we have a retrievabiliy bias due to the little
amount of user interactions with audiobooks compared to previously available
items such as music and podcast content. To address this, we propose
AudioBoost, a system to boost audiobook retrievability in Spotify's Search via
synthetic query generation. AudioBoost leverages Large Language Models (LLMs)
to generate synthetic queries conditioned on audiobook metadata. The synthetic
queries are indexed both in the Query AutoComplete (QAC) and in the Search
Retrieval engine to improve query formulation and retrieval at the same time.
We show through offline evaluation that synthetic queries increase
retrievability and are of high quality. Moreover, results from an online A/B
test show that AudioBoost leads to a +0.7% in audiobook impressions, +1.22% in
audiobook clicks, and +1.82% in audiobook exploratory query completions.

### 9. On the Same Wavelength? Evaluating Pragmatic Reasoning in Language Models across Broad Concepts

- **LLM Score**: 6
- **Keyword Score**: 2
- **Authors**: Linlu Qiu, Cedegao E. Zhang, Joshua B. Tenenbaum, Yoon Kim, Roger P. Levy
- **URL**: <http://arxiv.org/abs/2509.06952v1>
- **Submitted**: 2025-09-08 17:59:32
- **Comment**: EMNLP 2025 (Main)
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and query understanding, as it evaluates language models' pragmatic reasoning abilities. However, the focus on language comprehension and production, rather than information retrieval or search technologies, limits its relevance to your core research themes.

#### Abstract
> Language use is shaped by pragmatics -- i.e., reasoning about communicative
goals and norms in context. As language models (LMs) are increasingly used as
conversational agents, it becomes ever more important to understand their
pragmatic reasoning abilities. We propose an evaluation framework derived from
Wavelength, a popular communication game where a speaker and a listener
communicate about a broad range of concepts in a granular manner. We study a
range of LMs on both language comprehension and language production using
direct and Chain-of-Thought (CoT) prompting, and further explore a Rational
Speech Act (RSA) approach to incorporating Bayesian pragmatic reasoning into LM
inference. We find that state-of-the-art LMs, but not smaller ones, achieve
strong performance on language comprehension, obtaining similar-to-human
accuracy and exhibiting high correlations with human judgments even without CoT
prompting or RSA. On language production, CoT can outperform direct prompting,
and using RSA provides significant improvements over both approaches. Our study
helps identify the strengths and limitations in LMs' pragmatic reasoning
abilities and demonstrates the potential for improving them with RSA, opening
up future avenues for understanding conceptual representation, language
understanding, and social reasoning in LMs and humans.

### 10. Beamforming-LLM: What, Where and When Did I Miss?

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Vishal Choudhari
- **URL**: <http://arxiv.org/abs/2509.06221v1>
- **Submitted**: 2025-09-07 21:52:26
- **Topic Keywords**: query, queries, rag, retrieval
- **Reason**: The paper combines spatial audio capture with retrieval-augmented generation, which shows some relevance to information retrieval and natural language processing. However, the focus on auditory memory systems and assistive technology is not directly aligned with the user's core research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> We present Beamforming-LLM, a system that enables users to semantically
recall conversations they may have missed in multi-speaker environments. The
system combines spatial audio capture using a microphone array with
retrieval-augmented generation (RAG) to support natural language queries such
as, "What did I miss when I was following the conversation on dogs?"
Directional audio streams are separated using beamforming, transcribed with
Whisper, and embedded into a vector database using sentence encoders. Upon
receiving a user query, semantically relevant segments are retrieved,
temporally aligned with non-attended segments, and summarized using a
lightweight large language model (GPT-4o-mini). The result is a user-friendly
interface that provides contrastive summaries, spatial context, and timestamped
audio playback. This work lays the foundation for intelligent auditory memory
systems and has broad applications in assistive technology, meeting
summarization, and context-aware personal spatial computing.

### 11. The Majority is not always right: RL training for solution aggregation

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Wenting Zhao, Pranjal Aggarwal, Swarnadeep Saha, Asli Celikyilmaz, Jason Weston, Ilia Kulikov
- **URL**: <http://arxiv.org/abs/2509.06870v1>
- **Submitted**: 2025-09-08 16:39:38
- **Topic Keywords**: ranking, rank
- **Reason**: The paper discusses a method for aggregating solutions to improve large language models, which is somewhat related to information retrieval and ranking models. However, the focus is on reinforcement learning and solution aggregation, which is not directly aligned with the user's core research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Scaling up test-time compute, by generating multiple independent solutions
and selecting or aggregating among them, has become a central paradigm for
improving large language models (LLMs) on challenging reasoning tasks. While
most prior work relies on simple majority voting or reward model ranking to
aggregate solutions, these approaches may only yield limited benefits. In this
work, we propose to learn aggregation as an explicit reasoning skill: given a
set of candidate solutions, we train an aggregator model to review, reconcile,
and synthesize a final, correct answer using reinforcement learning from
verifiable rewards. A key ingredient is careful balancing of easy and hard
training examples, allowing the model to learn both to recover
minority-but-correct answers as well as easy majority-correct answers.
Empirically, we find our method, AggLM, outperforms both strong rule-based and
reward-model baselines, across multiple benchmarks. Furthermore, it generalizes
effectively to solutions from differing models, including stronger ones than
contained in the training data, all while requiring substantially fewer tokens
than majority voting with larger numbers of solutions.

### 12. Guided Decoding and Its Critical Role in Retrieval-Augmented Generation

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: √ñzg√ºr Uƒüur, Musa Yƒ±lmaz, Esra ≈ûavirdi, √ñzay Ezerceli, Mahmut El Huseyni, Selva Ta≈ü, Reyhan Bayraktar
- **URL**: <http://arxiv.org/abs/2509.06631v1>
- **Submitted**: 2025-09-08 12:51:40
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper explores Retrieval-Augmented Generation (RAG) systems, which is a related topic to Information Retrieval. However, the focus on Large Language Models (LLMs) and structured output generation is more aligned with NLP and generation tasks rather than traditional IR and search technologies. While the paper's findings may have some implications for IR, it does not directly address the user's core research themes.

#### Abstract
> The integration of Large Language Models (LLMs) into various applications has
driven the need for structured and reliable responses. A key challenge in
Retrieval-Augmented Generation (RAG) systems is ensuring that outputs align
with expected formats while minimizing hallucinations. This study examines the
role of guided decoding in RAG systems, comparing three methods, Outlines,
XGrammar, and LM Format Enforcer, across different multi-turn prompting setups
(0-turn, 1-turn, and 2-turn). By evaluating success rates, hallucination rates,
and output quality, we provide insights into their performance and
applicability. Our findings reveal how multi-turn interactions influence guided
decoding, uncovering unexpected performance variations that can inform method
selection for specific use cases. This work advances the understanding of
structured output generation in RAG systems, offering both theoretical insights
and practical guidance for LLM deployment.

### 13. mmBERT: A Modern Multilingual Encoder with Annealed Language Learning

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Marc Marone, Orion Weller, William Fleshman, Eugene Yang, Dawn Lawrie, Benjamin Van Durme
- **URL**: <http://arxiv.org/abs/2509.06888v1>
- **Submitted**: 2025-09-08 17:08:42
- **Topic Keywords**: retrieval, search
- **Reason**: This paper introduces a multilingual encoder model (mmBERT) that shows significant performance gains on classification and retrieval tasks. While it is related to Information Retrieval and NLP, its focus on multilingual models and classification tasks is somewhat tangential to the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Encoder-only languages models are frequently used for a variety of standard
machine learning tasks, including classification and retrieval. However, there
has been a lack of recent research for encoder models, especially with respect
to multilingual models. We introduce mmBERT, an encoder-only language model
pretrained on 3T tokens of multilingual text in over 1800 languages. To build
mmBERT we introduce several novel elements, including an inverse mask ratio
schedule and an inverse temperature sampling ratio. We add over 1700
low-resource languages to the data mix only during the decay phase, showing
that it boosts performance dramatically and maximizes the gains from the
relatively small amount of training data. Despite only including these
low-resource languages in the short decay phase we achieve similar
classification performance to models like OpenAI's o3 and Google's Gemini 2.5
Pro. Overall, we show that mmBERT significantly outperforms the previous
generation of models on classification and retrieval tasks -- on both high and
low-resource languages.

### 14. Outcome-based Exploration for LLM Reasoning

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Yuda Song, Julia Kempe, Remi Munos
- **URL**: <http://arxiv.org/abs/2509.06941v1>
- **Submitted**: 2025-09-08 17:52:56
- **Comment**: 26 pages, 11 figures
- **Topic Keywords**: rag
- **Reason**: This paper explores the application of reinforcement learning to improve the reasoning abilities of large language models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on language models and reasoning tasks is not directly aligned with the user's primary research interests in IR and search technologies. The paper's emphasis on diversity and scalability is also somewhat relevant, but not a central match for the user's research themes.

#### Abstract
> Reinforcement learning (RL) has emerged as a powerful method for improving
the reasoning abilities of large language models (LLMs). Outcome-based RL,
which rewards policies solely for the correctness of the final answer, yields
substantial accuracy gains but also induces a systematic loss in generation
diversity. This collapse undermines real-world performance, where diversity is
critical for test-time scaling. We analyze this phenomenon by viewing RL
post-training as a sampling process and show that, strikingly, RL can reduce
effective diversity even on the training set relative to the base model. Our
study highlights two central findings: (i) a transfer of diversity degradation,
where reduced diversity on solved problems propagates to unsolved ones, and
(ii) the tractability of the outcome space, since reasoning tasks admit only a
limited set of distinct answers. Motivated by these insights, we propose
outcome-based exploration, which assigns exploration bonuses according to final
outcomes. We introduce two complementary algorithms: historical exploration,
which encourages rarely observed answers via UCB-style bonuses, and batch
exploration, which penalizes within-batch repetition to promote test-time
diversity. Experiments on standard competition math with Llama and Qwen models
demonstrate that both methods improve accuracy while mitigating diversity
collapse. On the theoretical side, we formalize the benefit of outcome-based
exploration through a new model of outcome-based bandits. Together, these
contributions chart a practical path toward RL methods that enhance reasoning
without sacrificing the diversity essential for scalable deployment.

### 15. LAMDAS: LLM as an Implicit Classifier for Domain-specific Data Selection

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Jian Wu, Hang Yu, Bingchang Liu, Wenjie Yang, Peng Di, Jianguo Li, Yue Zhang
- **URL**: <http://arxiv.org/abs/2509.06524v1>
- **Submitted**: 2025-09-08 10:30:58
- **Topic Keywords**: rag
- **Reason**: This paper introduces a novel approach to domain-specific data selection using pre-trained large language models (LLMs) as implicit classifiers. While it touches on the topic of data selection, which is related to information retrieval, it does not directly address query understanding, ranking models, or user behavior modeling. The focus on LLMs and their applications in NLP is somewhat relevant to your research interests.

#### Abstract
> Adapting large language models (LLMs) to specific domains often faces a
critical bottleneck: the scarcity of high-quality, human-curated data. While
large volumes of unchecked data are readily available, indiscriminately using
them for fine-tuning risks introducing noise and degrading performance.
Strategic data selection is thus crucial, requiring a method that is both
accurate and efficient. Existing approaches, categorized as similarity-based
and direct optimization methods, struggle to simultaneously achieve these
goals. In this paper, we introduce LAMDAS (LLM As an iMplicit classifier for
domain-specific DAta Selection), a novel approach that leverages the
pre-trained LLM itself as an implicit classifier, thereby bypassing explicit
feature engineering and computationally intensive optimization process. LAMDAS
reframes data selection as a one-class classification problem, identifying
candidate data that "belongs" to the target domain defined by a small reference
dataset. Extensive experimental results demonstrate that LAMDAS not only
exceeds the performance of full-data training using a fraction of the data but
also outperforms nine state-of-the-art (SOTA) baselines under various
scenarios. Furthermore, LAMDAS achieves the most compelling balance between
performance gains and computational efficiency compared to all evaluated
baselines.

### 16. Modelling Intertextuality with N-gram Embeddings

- **LLM Score**: 3
- **Keyword Score**: 5
- **Authors**: Yi Xing
- **URL**: <http://arxiv.org/abs/2509.06637v2>
- **Submitted**: 2025-09-08 12:54:38
- **Topic Keywords**: pairwise, rag
- **Reason**: The paper explores NLP techniques for analyzing intertextuality in literary texts, which is somewhat related to the user's interests in NLP. However, it does not directly align with the user's focus on information retrieval, search technologies, or query understanding, and is more specialized in the domain of literary studies.

#### Abstract
> Intertextuality is a central tenet in literary studies. It refers to the
intricate links between literary texts that are created by various types of
references. This paper proposes a new quantitative model of intertextuality to
enable scalable analysis and network-based insights: perform pairwise
comparisons of the embeddings of n-grams from two texts and average their
results as the overall intertextuality. Validation on four texts with known
degrees of intertextuality, alongside a scalability test on 267 diverse texts,
demonstrates the method's effectiveness and efficiency. Network analysis
further reveals centrality and community structures, affirming the approach's
success in capturing and quantifying intertextual relationships.

### 17. Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Jiacheng Miao, Joe R. Davis, Jonathan K. Pritchard, James Zou
- **URL**: <http://arxiv.org/abs/2509.06917v1>
- **Submitted**: 2025-09-08 17:28:42
- **Topic Keywords**: queries, rag, search
- **Reason**: This paper focuses on converting research papers into AI agents, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves natural language processing, the context is more about knowledge dissemination and AI co-scientists, rather than search or ranking models.

#### Abstract
> We introduce Paper2Agent, an automated framework that converts research
papers into AI agents. Paper2Agent transforms research output from passive
artifacts into active systems that can accelerate downstream use, adoption, and
discovery. Conventional research papers require readers to invest substantial
effort to understand and adapt a paper's code, data, and methods to their own
work, creating barriers to dissemination and reuse. Paper2Agent addresses this
challenge by automatically converting a paper into an AI agent that acts as a
knowledgeable research assistant. It systematically analyzes the paper and the
associated codebase using multiple agents to construct a Model Context Protocol
(MCP) server, then iteratively generates and runs tests to refine and robustify
the resulting MCP. These paper MCPs can then be flexibly connected to a chat
agent (e.g. Claude Code) to carry out complex scientific queries through
natural language while invoking tools and workflows from the original paper. We
demonstrate Paper2Agent's effectiveness in creating reliable and capable paper
agents through in-depth case studies. Paper2Agent created an agent that
leverages AlphaGenome to interpret genomic variants and agents based on ScanPy
and TISSUE to carry out single-cell and spatial transcriptomics analyses. We
validate that these paper agents can reproduce the original paper's results and
can correctly carry out novel user queries. By turning static papers into
dynamic, interactive AI agents, Paper2Agent introduces a new paradigm for
knowledge dissemination and a foundation for the collaborative ecosystem of AI
co-scientists.

### 18. Compare: A Framework for Scientific Comparisons

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Moritz Staudinger, Wojciech Kusa, Matteo Cancellieri, David Pride, Petr Knoth, Allan Hanbury
- **URL**: <http://arxiv.org/abs/2509.06412v1>
- **Submitted**: 2025-09-08 08:05:26
- **Comment**: Accepted at CIKM 2025
- **Topic Keywords**: rag, retrieval, search
- **Reason**: This paper focuses on a scientific comparison framework, which, while related to information retrieval, does not directly align with your core research themes of query understanding, ranking models, and user behavior modeling. Although it mentions retrieval, it's in the context of scientific contributions and citation analysis, which is a different domain from your e-commerce and NLP interests.

#### Abstract
> Navigating the vast and rapidly increasing sea of academic publications to
identify institutional synergies, benchmark research contributions and pinpoint
key research contributions has become an increasingly daunting task, especially
with the current exponential increase in new publications. Existing tools
provide useful overviews or single-document insights, but none supports
structured, qualitative comparisons across institutions or publications.
  To address this, we demonstrate Compare, a novel framework that tackles this
challenge by enabling sophisticated long-context comparisons of scientific
contributions. Compare empowers users to explore and analyze research overlaps
and differences at both the institutional and publication granularity, all
driven by user-defined questions and automatic retrieval over online resources.
For this we leverage on Retrieval-Augmented Generation over evolving data
sources to foster long context knowledge synthesis. Unlike traditional
scientometric tools, Compare goes beyond quantitative indicators by providing
qualitative, citation-supported comparisons.

### 19. A Comparative Benchmark of Large Language Models for Labelling Wind Turbine Maintenance Logs

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Max Malyi, Jonathan Shek, Alasdair McDonald, Andre Biscaya
- **URL**: <http://arxiv.org/abs/2509.06813v1>
- **Submitted**: 2025-09-08 15:48:17
- **Comment**: Associated GitHub repository:
  https://github.com/mvmalyi/wind-farm-maintenance-logs-labelling-with-llms
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves Large Language Models, the focus is on a specific industrial application (wind turbine maintenance logs) and does not address query understanding, ranking models, or user behavior modeling.

#### Abstract
> Effective Operation and Maintenance (O&M) is critical to reducing the
Levelised Cost of Energy (LCOE) from wind power, yet the unstructured,
free-text nature of turbine maintenance logs presents a significant barrier to
automated analysis. Our paper addresses this by presenting a novel and
reproducible framework for benchmarking Large Language Models (LLMs) on the
task of classifying these complex industrial records. To promote transparency
and encourage further research, this framework has been made publicly available
as an open-source tool. We systematically evaluate a diverse suite of
state-of-the-art proprietary and open-source LLMs, providing a foundational
assessment of their trade-offs in reliability, operational efficiency, and
model calibration. Our results quantify a clear performance hierarchy,
identifying top models that exhibit high alignment with a benchmark standard
and trustworthy, well-calibrated confidence scores. We also demonstrate that
classification performance is highly dependent on the task's semantic
ambiguity, with all models showing higher consensus on objective component
identification than on interpretive maintenance actions. Given that no model
achieves perfect accuracy and that calibration varies dramatically, we conclude
that the most effective and responsible near-term application is a
Human-in-the-Loop system, where LLMs act as a powerful assistant to accelerate
and standardise data labelling for human experts, thereby enhancing O&M data
quality and downstream reliability analysis.

### 20. Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Valentin Quesnel, Damien Sileo
- **URL**: <http://arxiv.org/abs/2509.06809v1>
- **Submitted**: 2025-09-08 15:43:29
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on Large Language Models (LLMs) and mathematical reasoning, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context is specific to mathematical reasoning and theorem proving, making it somewhat tangential to your main areas of focus.

#### Abstract
> The scarcity of high-quality, logically sound data is a critical bottleneck
for advancing the mathematical reasoning of Large Language Models (LLMs). Our
work confronts this challenge by turning decades of automated theorem proving
research into a scalable data engine. Rather than relying on error-prone LLMs
or complex proof-assistant syntax like Lean and Isabelle, our framework
leverages E-prover's saturation capabilities on the vast TPTP axiom library to
derive a massive, guaranteed-valid corpus of theorems. Our pipeline is
principled and simple: saturate axioms, filter for "interesting" theorems, and
generate tasks. With no LLMs in the loop, we eliminate factual errors by
construction. This purely symbolic data is then transformed into three
difficulty-controlled challenges: entailment verification, premise selection,
and proof reconstruction. Our zero-shot experiments on frontier models reveal a
clear weakness: performance collapses on tasks requiring deep, structural
reasoning. Our framework provides both the diagnostic tool to measure this gap
and a scalable source of symbolic training data to address it. We make the code
and data publicly available.
  https://github.com/sileod/reasoning_core
https://hf.co/datasets/reasoning-core/rc1

### 21. MachineLearningLM: Continued Pretraining Language Models on Millions of Synthetic Tabular Prediction Tasks Scales In-Context ML

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Haoyu Dong, Pengkun Zhang, Mingzhe Lu, Yanzhen Shen, Guolin Ke
- **URL**: <http://arxiv.org/abs/2509.06806v1>
- **Submitted**: 2025-09-08 15:38:31
- **Topic Keywords**: rag, rank
- **Reason**: This paper focuses on continued pretraining of language models for in-context machine learning tasks, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves natural language processing, the context is more aligned with NLP applications rather than IR or search technologies.

#### Abstract
> Large language models (LLMs) possess broad world knowledge and strong
general-purpose reasoning ability, yet they struggle to learn from many
in-context examples on standard machine learning (ML) tasks, that is, to
leverage many-shot demonstrations purely via in-context learning (ICL) without
gradient descent. We introduce MachineLearningLM, a portable
continued-pretraining framework that equips a general-purpose LLM with robust
in-context ML capability while preserving its general knowledge and reasoning
for broader chat workflows.
  Our pretraining procedure synthesizes ML tasks from millions of structural
causal models (SCMs), spanning shot counts up to 1,024. We begin with a
random-forest teacher, distilling tree-based decision strategies into the LLM
to strengthen robustness in numerical modeling. All tasks are serialized with a
token-efficient prompt, enabling 3x to 6x more examples per context window and
delivering up to 50x amortized throughput via batch inference.
  Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8),
MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an
average of about 15% on out-of-distribution tabular classification across
finance, physics, biology, and healthcare domains. It exhibits a striking
many-shot scaling law: accuracy increases monotonically as in-context
demonstrations grow from 8 to 1,024. Without any task-specific training, it
attains random-forest-level accuracy across hundreds of shots. General chat
capabilities, including knowledge and reasoning, are preserved: it achieves
75.4% on MMLU.

### 22. Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from LLMs via Claim Verification

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Aivin V. Solatorio
- **URL**: <http://arxiv.org/abs/2509.06902v1>
- **Submitted**: 2025-09-08 17:20:16
- **Topic Keywords**: retrieval
- **Reason**: This paper focuses on a protocol for trustworthy numeric answers from Large Language Models (LLMs), which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. While it involves NLP, the topic is more aligned with model verification and trustworthiness rather than deep semantic understanding or real-time relevance optimization.

#### Abstract
> Large Language Models (LLMs) as stochastic systems may generate numbers that
deviate from available data, a failure known as \emph{numeric hallucination}.
Existing safeguards -- retrieval-augmented generation, citations, and
uncertainty estimation -- improve transparency but cannot guarantee fidelity:
fabricated or misquoted values may still be displayed as if correct. We propose
\textbf{Proof-Carrying Numbers (PCN)}, a presentation-layer protocol that
enforces numeric fidelity through mechanical verification. Under PCN, numeric
spans are emitted as \emph{claim-bound tokens} tied to structured claims, and a
verifier checks each token under a declared policy (e.g., exact equality,
rounding, aliases, or tolerance with qualifiers). Crucially, PCN places
verification in the \emph{renderer}, not the model: only claim-checked numbers
are marked as verified, and all others default to unverified. This separation
prevents spoofing and guarantees fail-closed behavior. We formalize PCN and
prove soundness, completeness under honest tokens, fail-closed behavior, and
monotonicity under policy refinement. PCN is lightweight and model-agnostic,
integrates seamlessly into existing applications, and can be extended with
cryptographic commitments. By enforcing verification as a mandatory step before
display, PCN establishes a simple contract for numerically sensitive settings:
\emph{trust is earned only by proof}, while the absence of a mark communicates
uncertainty.

### 23. Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: James Xu Zhao, Bryan Hooi, See-Kiong Ng
- **URL**: <http://arxiv.org/abs/2509.06861v1>
- **Submitted**: 2025-09-08 16:28:25
- **Comment**: 20 pages, 4 figures, 6 tables
- **Topic Keywords**: rag
- **Reason**: This paper appears to be unrelated to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on reasoning models and knowledge-intensive tasks seems to be more aligned with Artificial Intelligence or Machine Learning, rather than your areas of expertise.

#### Abstract
> Test-time scaling increases inference-time computation by allowing models to
generate long reasoning chains, and has shown strong performance across many
domains. However, in this work, we show that this approach is not yet effective
for knowledge-intensive tasks, where high factual accuracy and low
hallucination rates are essential. We conduct a comprehensive evaluation of
test-time scaling using 12 reasoning models on two knowledge-intensive
benchmarks. Our results reveal that increasing test-time computation does not
consistently improve accuracy and, in many cases, it even leads to more
hallucinations. We then analyze how extended reasoning affects hallucination
behavior. We find that reduced hallucinations often result from the model
choosing to abstain after thinking more, rather than from improved factual
recall. Conversely, for some models, longer reasoning encourages attempts on
previously unanswered questions, many of which result in hallucinations. Case
studies show that extended reasoning can induce confirmation bias, leading to
overconfident hallucinations. Despite these limitations, we observe that
compared to non-thinking, enabling thinking remains beneficial. Code and data
are available at https://github.com/XuZhao0/tts-knowledge

### 24. HAVE: Head-Adaptive Gating and ValuE Calibration for Hallucination Mitigation in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xin Tong, Zhi Lin, Jingya Wang, Bo Jin
- **URL**: <http://arxiv.org/abs/2509.06596v1>
- **Submitted**: 2025-09-08 12:06:09
- **Topic Keywords**: retrieval
- **Reason**: This paper focuses on Large Language Models and hallucination mitigation, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some NLP aspects, the primary focus is on model improvement rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> Large Language Models (LLMs) often produce hallucinations in
retrieval-augmented or long-context generation, even when relevant evidence is
present. This stems from two issues: head importance is treated as
input-agnostic, and raw attention weights poorly reflect each token's true
contribution. We present HAVE (Head-Adaptive Gating and ValuE Calibration), a
parameter-free decoding framework that directly addresses both challenges. HAVE
introduces head-adaptive gating, which performs instance-level soft reweighing
of attention heads, and value calibration, which augments attention with the
magnitude of value vectors to approximate write-back contribution. Together,
these modules construct token-level evidence aligned with model updates and
fuse it with the LM distribution through a lightweight uncertainty-scaled
policy. HAVE requires no finetuning and operates in a single forward pass,
making it efficient and broadly applicable. Experiments across multiple QA
benchmarks and LLM families demonstrate that HAVE consistently reduces
hallucinations and outperforms strong baselines, including DAGCD, with modest
overhead. The framework is transparent, reproducible, and readily integrates
with off-the-shelf LLMs, advancing trustworthy generation in real-world
settings.

### 25. Tackling Device Data Distribution Real-time Shift via Prototype-based Parameter Editing

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zheqi Lv, Wenqiao Zhang, Kairui Fu, Qi Tian, Shengyu Zhang, Jiajie Su, Jingyuan Chen, Kun Kuang, Fei Wu
- **URL**: <http://arxiv.org/abs/2509.06552v1>
- **Submitted**: 2025-09-08 11:06:50
- **Comment**: Published on MM'25: Proceedings of the 33rd ACM International
  Conference on Multimedia
- **Topic Keywords**: recommend, search
- **Reason**: This paper focuses on addressing real-time data distribution shifts in on-device models, which is not directly related to the user's core research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. While it involves some NLP and data mining aspects, the primary focus is on model adaptation and fine-tuning, which is not a central match for the user's research themes.

#### Abstract
> The on-device real-time data distribution shift on devices challenges the
generalization of lightweight on-device models. This critical issue is often
overlooked in current research, which predominantly relies on data-intensive
and computationally expensive fine-tuning approaches. To tackle this, we
introduce Persona, a novel personalized method using a prototype-based,
backpropagation-free parameter editing framework to enhance model
generalization without post-deployment retraining. Persona employs a neural
adapter in the cloud to generate a parameter editing matrix based on real-time
device data. This matrix adeptly adapts on-device models to the prevailing data
distributions, efficiently clustering them into prototype models. The
prototypes are dynamically refined via the parameter editing matrix,
facilitating efficient evolution. Furthermore, the integration of cross-layer
knowledge transfer ensures consistent and context-aware multi-layer parameter
changes and prototype assignment. Extensive experiments on vision task and
recommendation task on multiple datasets confirm Persona's effectiveness and
generality.

### 26. Index-Preserving Lightweight Token Pruning for Efficient Document Understanding in Vision-Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jaemin Son, Sujin Choi, Inyong Yun
- **URL**: <http://arxiv.org/abs/2509.06415v1>
- **Submitted**: 2025-09-08 08:12:26
- **Comment**: Submitted to ICASSP 2026
- **Topic Keywords**: rag
- **Reason**: This paper focuses on vision-language models for document understanding, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve document understanding, it's more focused on computer vision and image processing, rather than semantic understanding or ranking models.

#### Abstract
> Recent progress in vision-language models (VLMs) has led to impressive
results in document understanding tasks, but their high computational demands
remain a challenge. To mitigate the compute burdens, we propose a lightweight
token pruning framework that filters out non-informative background regions
from document images prior to VLM processing. A binary patch-level classifier
removes non-text areas, and a max-pooling refinement step recovers fragmented
text regions to enhance spatial coherence. Experiments on real-world document
datasets demonstrate that our approach substantially lowers computational
costs, while maintaining comparable accuracy.

### 27. PL-CA: A Parametric Legal Case Augmentation Framework

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ao Chang, Yubo Chen, Jun Zhao
- **URL**: <http://arxiv.org/abs/2509.06356v1>
- **Submitted**: 2025-09-08 06:08:06
- **Topic Keywords**: rag
- **Reason**: This paper focuses on a legal case augmentation framework, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve some aspects of model knowledge and augmentation, the context is highly specialized in the judicial domain and does not align with the user's broader interests.

#### Abstract
> Conventional RAG is considered one of the most effective methods for
addressing model knowledge insufficiency and hallucination, particularly in the
judicial domain that requires high levels of knowledge rigor, logical
consistency, and content integrity. However, the conventional RAG method only
injects retrieved documents directly into the model's context, which severely
constrains models due to their limited context windows and introduces
additional computational overhead through excessively long contexts, thereby
disrupting models' attention and degrading performance on downstream tasks.
Moreover, many existing benchmarks lack expert annotation and focus solely on
individual downstream tasks while real-world legal scenarios consist of
multiple mixed legal tasks, indicating conventional benchmarks' inadequacy for
reflecting models' true capabilities. To address these limitations, we propose
PL-CA, which introduces a parametric RAG (P-RAG) framework to perform data
augmentation on corpus knowledge and encode this legal knowledge into
parametric vectors, and then integrates this parametric knowledge into the
LLM's feed-forward networks (FFN) via LoRA, thereby alleviating models' context
pressure. Additionally, we also construct a multi-task legal dataset comprising
more than 2000 training and test instances, which are all expert-annotated and
manually verified. We conduct our experiments on our dataset, and the
experimental results demonstrate that our method reduces the overhead
associated with excessively long contexts while maintaining competitive
performance on downstream tasks compared to conventional RAG. Our code and
dataset are provided in the appendix.

### 28. MSLEF: Multi-Segment LLM Ensemble Finetuning in Recruitment

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Omar Walid, Mohamed T. Younes, Khaled Shaban, Mai Hassan, Ali Hamdi
- **URL**: <http://arxiv.org/abs/2509.06200v1>
- **Submitted**: 2025-09-07 20:27:58
- **Comment**: Accepted in AICCSA 2025
- **Topic Keywords**: rag
- **Reason**: This paper focuses on recruitment automation and resume parsing, which is not a central match to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves fine-tuning Large Language Models, the application domain and specific use case are not aligned with your primary focus on e-commerce and real-time relevance optimization.

#### Abstract
> This paper presents MSLEF, a multi-segment ensemble framework that employs
LLM fine-tuning to enhance resume parsing in recruitment automation. It
integrates fine-tuned Large Language Models (LLMs) using weighted voting, with
each model specializing in a specific resume segment to boost accuracy.
Building on MLAR , MSLEF introduces a segment-aware architecture that leverages
field-specific weighting tailored to each resume part, effectively overcoming
the limitations of single-model systems by adapting to diverse formats and
structures. The framework incorporates Gemini-2.5-Flash LLM as a high-level
aggregator for complex sections and utilizes Gemma 9B, LLaMA 3.1 8B, and Phi-4
14B. MSLEF achieves significant improvements in Exact Match (EM), F1 score,
BLEU, ROUGE, and Recruitment Similarity (RS) metrics, outperforming the best
single model by up to +7% in RS. Its segment-aware design enhances
generalization across varied resume layouts, making it highly adaptable to
real-world hiring scenarios while ensuring precise and reliable candidate
representation.

### 29. Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yinjie Wang, Ling Yang, Bowen Li, Ye Tian, Ke Shen, Mengdi Wang
- **URL**: <http://arxiv.org/abs/2509.06949v1>
- **Submitted**: 2025-09-08 17:58:06
- **Comment**: Code and Models: https://github.com/Gen-Verse/dLLM-RL
- **Topic Keywords**: search
- **Reason**: This paper focuses on reinforcement learning for diffusion large language models, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves deep learning and NLP, the application and context are quite different from the user's core research themes.

#### Abstract
> We propose TraceRL, a trajectory-aware reinforcement learning framework for
diffusion language models (DLMs) that incorporates preferred inference
trajectory into post-training, and is applicable across different
architectures. Equipped with a diffusion-based value model that enhances
training stability, we demonstrate improved reasoning performance on complex
math and coding tasks. Besides, it can also be applied to adapt block-specific
models to larger blocks, which improves sampling flexibility. Employing
TraceRL, we derive a series of state-of-the-art diffusion language models,
namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still
consistently outperforms them across complex math reasoning tasks.
TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over
Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical
reasoning benchmarks. Through curriculum learning, we also derive the first
long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1%
relative accuracy gain. To facilitate reproducible research and practical
applications, we release a comprehensive open-source framework for building,
training, and deploying diffusion LLMs across diverse architectures. The
framework integrates accelerated KV-cache techniques and inference engines for
both inference and reinforcement learning, and includes implementations of
various supervised fine-tuning and RL methods for mathematics, coding, and
general tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL

### 30. An Ethically Grounded LLM-Based Approach to Insider Threat Synthesis and Detection

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Haywood Gelman, John D. Hastings, David Kenley
- **URL**: <http://arxiv.org/abs/2509.06920v1>
- **Submitted**: 2025-09-08 17:32:17
- **Comment**: 6 pages, 5 figures, 5 tables
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests as it focuses on insider threat detection using large language models, which is outside your primary areas of interest in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Insider threats are a growing organizational problem due to the complexity of
identifying their technical and behavioral elements. A large research body is
dedicated to the study of insider threats from technological, psychological,
and educational perspectives. However, research in this domain has been
generally dependent on datasets that are static and limited access which
restricts the development of adaptive detection models. This study introduces a
novel, ethically grounded approach that uses the large language model (LLM)
Claude Sonnet 3.7 to dynamically synthesize syslog messages, some of which
contain indicators of insider threat scenarios. The messages reflect real-world
data distributions by being highly imbalanced (1% insider threats). The syslogs
were analyzed for insider threats by both Claude Sonnet 3.7 and GPT-4o, with
their performance evaluated through statistical metrics including precision,
recall, MCC, and ROC AUC. Sonnet 3.7 consistently outperformed GPT-4o across
nearly all metrics, particularly in reducing false alarms and improving
detection accuracy. The results show strong promise for the use of LLMs in
synthetic dataset generation and insider threat detection.

### 31. Anchoring Refusal Direction: Mitigating Safety Risks in Tuning via Projection Constraint

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yanrui Du, Fenglei Fan, Sendong Zhao, Jiawei Cao, Qika Lin, Kai He, Ting Liu, Bing Qin, Mengling Feng
- **URL**: <http://arxiv.org/abs/2509.06795v1>
- **Submitted**: 2025-09-08 15:24:33
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on safety risks in Large Language Models and proposes a method to mitigate these risks, which is outside your primary research areas.

#### Abstract
> Instruction Fine-Tuning (IFT) has been widely adopted as an effective
post-training strategy to enhance various abilities of Large Language Models
(LLMs). However, prior studies have shown that IFT can significantly compromise
LLMs' safety, particularly their ability to refuse malicious instructions,
raising significant concerns. Recent research into the internal mechanisms of
LLMs has identified the refusal direction (r-direction) in the hidden states,
which plays a pivotal role in governing refusal behavior. Building on this
insight, our study reveals that the r-direction tends to drift during training,
which we identify as one of the causes of the associated safety risks. To
mitigate such drift, our proposed ProCon method introduces a
projection-constrained loss term that regularizes the projection magnitude of
each training sample's hidden state onto the r-direction. Our initial analysis
shows that applying an appropriate constraint can effectively mitigate the
refusal direction drift and associated safety risks, but remains limited by
overall performance barriers. To overcome this barrier, informed by our
observation of early-stage sharp drift and a data-driven perspective, we
introduce a warm-up strategy that emphasizes early-stage strong constraints and
broaden the data distribution to strengthen constraint signals, leading to an
enhanced ProCon method. Experimental results under various datasets, scenarios,
and LLMs demonstrate that our method can significantly mitigate safety risks
posed by IFT while preserving task performance gains. Even compared with strong
baselines, our method consistently delivers superior overall performance.
Crucially, our analysis indicates that ProCon can contribute to stabilizing the
r-direction during training, while such an interpretability-driven exploration
of LLMs' internal mechanisms lays a solid foundation for future safety
research.

### 32. Reinforcement Learning Foundations for Deep Research Systems: A Survey

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Wenjun Li, Zhi Chen, Jingru Lin, Hannan Cao, Wei Han, Sheng Liang, Zhi Zhang, Kuicai Dong, Dexun Li, Chen Zhang, Yong Liu
- **URL**: <http://arxiv.org/abs/2509.06733v1>
- **Submitted**: 2025-09-08 14:27:23
- **Comment**: 38 pages, first version
- **Topic Keywords**: search
- **Reason**: This paper focuses on reinforcement learning foundations for deep research systems, which is somewhat related to information retrieval, but primarily deals with a different area of research. While it touches on search and tool use, the main emphasis is on training agentic AI for complex tasks, which is not directly aligned with the user's core research themes.

#### Abstract
> Deep research systems, agentic AI that solve complex, multi-step tasks by
coordinating reasoning, search across the open web and user files, and tool
use, are moving toward hierarchical deployments with a Planner, Coordinator,
and Executors. In practice, training entire stacks end-to-end remains
impractical, so most work trains a single planner connected to core tools such
as search, browsing, and code. While SFT imparts protocol fidelity, it suffers
from imitation and exposure biases and underuses environment feedback.
Preference alignment methods such as DPO are schema and proxy-dependent,
off-policy, and weak for long-horizon credit assignment and multi-objective
trade-offs. A further limitation of SFT and DPO is their reliance on human
defined decision points and subskills through schema design and labeled
comparisons. Reinforcement learning aligns with closed-loop, tool-interaction
research by optimizing trajectory-level policies, enabling exploration,
recovery behaviors, and principled credit assignment, and it reduces dependence
on such human priors and rater biases.
  This survey is, to our knowledge, the first dedicated to the RL foundations
of deep research systems. It systematizes work after DeepSeek-R1 along three
axes: (i) data synthesis and curation; (ii) RL methods for agentic research
covering stability, sample efficiency, long context handling, reward and credit
design, multi-objective optimization, and multimodal integration; and (iii)
agentic RL training systems and frameworks. We also cover agent architecture
and coordination, as well as evaluation and benchmarks, including recent QA,
VQA, long-form synthesis, and domain-grounded, tool-interaction tasks. We
distill recurring patterns, surface infrastructure bottlenecks, and offer
practical guidance for training robust, transparent deep research agents with
RL.

### 33. IntrEx: A Dataset for Modeling Engagement in Educational Conversations

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Xingwei Tan, Mahathi Parvatham, Chiara Gambi, Gabriele Pergola
- **URL**: <http://arxiv.org/abs/2509.06652v1>
- **Submitted**: 2025-09-08 13:07:35
- **Comment**: EMNLP 2025 Findings camera-ready, 9+7 pages
- **Topic Keywords**: search
- **Reason**: This paper focuses on educational conversations and engagement, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves large language models and NLP, the context and application are quite different from your areas of focus.

#### Abstract
> Engagement and motivation are crucial for second-language acquisition, yet
maintaining learner interest in educational conversations remains a challenge.
While prior research has explored what makes educational texts interesting,
still little is known about the linguistic features that drive engagement in
conversations. To address this gap, we introduce IntrEx, the first large
dataset annotated for interestingness and expected interestingness in
teacher-student interactions. Built upon the Teacher-Student Chatroom Corpus
(TSCC), IntrEx extends prior work by incorporating sequence-level annotations,
allowing for the study of engagement beyond isolated turns to capture how
interest evolves over extended dialogues. We employ a rigorous annotation
process with over 100 second-language learners, using a comparison-based rating
approach inspired by reinforcement learning from human feedback (RLHF) to
improve agreement. We investigate whether large language models (LLMs) can
predict human interestingness judgments. We find that LLMs (7B/8B parameters)
fine-tuned on interestingness ratings outperform larger proprietary models like
GPT-4o, demonstrating the potential for specialised datasets to model
engagement in educational settings. Finally, we analyze how linguistic and
cognitive factors, such as concreteness, comprehensibility (readability), and
uptake, influence engagement in educational dialogues.

### 34. SFR-DeepResearch: Towards Effective Reinforcement Learning for Autonomously Reasoning Single Agents

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Xuan-Phi Nguyen, Shrey Pandit, Revanth Gangi Reddy, Austin Xu, Silvio Savarese, Caiming Xiong, Shafiq Joty
- **URL**: <http://arxiv.org/abs/2509.06283v2>
- **Submitted**: 2025-09-08 02:07:09
- **Comment**: Technical Report
- **Topic Keywords**: search
- **Reason**: This paper is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves large language models and reinforcement learning, the focus is on agentic AI research and single-agent models, which is not a central match for the user's interests.

#### Abstract
> Equipping large language models (LLMs) with complex, interleaved reasoning
and tool-use capabilities has become a key focus in agentic AI research,
especially with recent advances in reasoning-oriented (``thinking'') models.
Such capabilities are key to unlocking a number of important applications. One
such application is Deep Research (DR), which requires extensive search and
reasoning over many sources. Our work in this paper focuses on the development
of native Autonomous Single-Agent models for DR featuring minimal web crawling
and Python tool integration. Unlike multi-agent systems, where agents take up
pre-defined roles and are told what to do at each step in a static workflow, an
autonomous single-agent determines its next action dynamically based on
context, without manual directive. While prior work has proposed training
recipes for base or instruction-tuned LLMs, we focus on continual reinforcement
learning (RL) of reasoning-optimized models to further enhance agentic skills
while preserving reasoning ability. Towards this end, we propose a simple RL
recipe with entirely synthetic data, which we apply to various open-source
LLMs. Our best variant SFR-DR-20B achieves up to 28.7% on Humanity's Last Exam
benchmark. In addition, we conduct key analysis experiments to provide more
insights into our methodologies.

### 35. No Encore: Unlearning as Opt-Out in Music Generation

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jinju Kim, Taehan Kim, Abdul Waheed, Rita Singh
- **URL**: <http://arxiv.org/abs/2509.06277v1>
- **Submitted**: 2025-09-08 01:56:51
- **Comment**: Work in progress. 7 pages
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests as it focuses on music generation, machine unlearning, and its application in creative industries, which does not align with your core areas of Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> AI music generation is rapidly emerging in the creative industries, enabling
intuitive music generation from textual descriptions. However, these systems
pose risks in exploitation of copyrighted creations, raising ethical and legal
concerns. In this paper, we present preliminary results on the first
application of machine unlearning techniques from an ongoing research to
prevent inadvertent usage of creative content. Particularly, we explore
existing methods in machine unlearning to a pre-trained Text-to-Music (TTM)
baseline and analyze their efficacy in unlearning pre-trained datasets without
harming model performance. Through our experiments, we provide insights into
the challenges of applying unlearning in music generation, offering a
foundational analysis for future works on the application of unlearning for
music generative models.

### 36. Benchmarking Gender and Political Bias in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jinrui Yang, Xudong Han, Timothy Baldwin
- **URL**: <http://arxiv.org/abs/2509.06164v1>
- **Submitted**: 2025-09-07 18:23:30
- **Comment**: The 8th International Conference on Natural Language and Speech
  Processing (Oral)
- **Topic Keywords**: search
- **Reason**: The paper focuses on evaluating bias in large language models, which is a topic within NLP. However, it does not relate to the user's primary research interests in Information Retrieval, query understanding, ranking models, or user behavior modeling, and is more focused on fairness and accountability in NLP rather than deep semantic understanding or real-time relevance optimization.

#### Abstract
> We introduce EuroParlVote, a novel benchmark for evaluating large language
models (LLMs) in politically sensitive contexts. It links European Parliament
debate speeches to roll-call vote outcomes and includes rich demographic
metadata for each Member of the European Parliament (MEP), such as gender, age,
country, and political group. Using EuroParlVote, we evaluate state-of-the-art
LLMs on two tasks -- gender classification and vote prediction -- revealing
consistent patterns of bias. We find that LLMs frequently misclassify female
MEPs as male and demonstrate reduced accuracy when simulating votes for female
speakers. Politically, LLMs tend to favor centrist groups while underperforming
on both far-left and far-right ones. Proprietary models like GPT-4o outperform
open-weight alternatives in terms of both robustness and fairness. We release
the EuroParlVote dataset, code, and demo to support future research on fairness
and accountability in NLP within political contexts.

---

