[
    {
        "title": "For Those Who May Find Themselves on the Red Team",
        "abstract": "This position paper argues that literary scholars must engage with large language model (LLM) interpretability research. While doing so will involve ideological struggle, if not out-right complicity, the necessity of this engagement is clear: the abiding instrumentality of current approaches to interpretability cannot be the only standard by which we measure interpretation with LLMs. One site at which this struggle could take place, I suggest, is the red team.",
        "url": "http://arxiv.org/abs/2511.18499v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18499v1",
        "arxiv_id": "2511.18499v1",
        "authors": [
            "Tyler Shoemaker"
        ],
        "submitted": "2025-11-23 15:31:03",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "MindEval: Benchmarking Language Models on Multi-turn Mental Health Support",
        "abstract": "Demand for mental health support through AI chatbots is surging, though current systems present several limitations, like sycophancy or overvalidation, and reinforcement of maladaptive beliefs. A core obstacle to the creation of better systems is the scarcity of benchmarks that capture the complexity of real therapeutic interactions. Most existing benchmarks either only test clinical knowledge through multiple-choice questions or assess single responses in isolation. To bridge this gap, we present MindEval, a framework designed in collaboration with Ph.D-level Licensed Clinical Psychologists for automatically evaluating language models in realistic, multi-turn mental health therapy conversations. Through patient simulation and automatic evaluation with LLMs, our framework balances resistance to gaming with reproducibility via its fully automated, model-agnostic design. We begin by quantitatively validating the realism of our simulated patients against human-generated text and by demonstrating strong correlations between automatic and human expert judgments. Then, we evaluate 12 state-of-the-art LLMs and show that all models struggle, scoring below 4 out of 6, on average, with particular weaknesses in problematic AI-specific patterns of communication. Notably, reasoning capabilities and model scale do not guarantee better performance, and systems deteriorate with longer interactions or when supporting patients with severe symptoms. We release all code, prompts, and human evaluation data.",
        "url": "http://arxiv.org/abs/2511.18491v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18491v1",
        "arxiv_id": "2511.18491v1",
        "authors": [
            "José Pombal",
            "Maya D'Eon",
            "Nuno M. Guerreiro",
            "Pedro Henrique Martins",
            "António Farinhas",
            "Ricardo Rei"
        ],
        "submitted": "2025-11-23 15:19:29",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "InstructAudio: Unified speech and music generation with natural language instruction",
        "abstract": "Text-to-speech (TTS) and text-to-music (TTM) models face significant limitations in instruction-based control. TTS systems usually depend on reference audio for timbre, offer only limited text-level attribute control, and rarely support dialogue generation. TTM systems are constrained by input conditioning requirements that depend on expert knowledge annotations. The high heterogeneity of these input control conditions makes them difficult to joint modeling with speech synthesis. Despite sharing common acoustic modeling characteristics, these two tasks have long been developed independently, leaving open the challenge of achieving unified modeling through natural language instructions. We introduce InstructAudio, a unified framework that enables instruction-based (natural language descriptions) control of acoustic attributes including timbre (gender, age), paralinguistic (emotion, style, accent), and musical (genre, instrument, rhythm, atmosphere). It supports expressive speech, music, and dialogue generation in English and Chinese. The model employs joint and single diffusion transformer layers with a standardized instruction-phoneme input format, trained on 50K hours of speech and 20K hours of music data, enabling multi-task learning and cross-modal alignment. Fig. 1 visualizes performance comparisons with mainstream TTS and TTM models, demonstrating that InstructAudio achieves optimal results on most metrics. To our best knowledge, InstructAudio represents the first instruction-controlled framework unifying speech and music generation. Audio samples are available at: https://qiangchunyu.github.io/InstructAudio/",
        "url": "http://arxiv.org/abs/2511.18487v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18487v1",
        "arxiv_id": "2511.18487v1",
        "authors": [
            "Chunyu Qiang",
            "Kang Yin",
            "Xiaopeng Wang",
            "Yuzhe Liang",
            "Jiahui Zhao",
            "Ruibo Fu",
            "Tianrui Wang",
            "Cheng Gong",
            "Chen Zhang",
            "Longbiao Wang",
            "Jianwu Dang"
        ],
        "submitted": "2025-11-23 15:15:21",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Shadows in the Code: Exploring the Risks and Defenses of LLM-based Multi-Agent Software Development Systems",
        "abstract": "The rapid advancement of Large Language Model (LLM)-driven multi-agent systems has significantly streamlined software developing tasks, enabling users with little technical expertise to develop executable applications. While these systems democratize software creation through natural language requirements, they introduce significant security risks that remain largely unexplored. We identify two risky scenarios: Malicious User with Benign Agents (MU-BA) and Benign User with Malicious Agents (BU-MA). We introduce the Implicit Malicious Behavior Injection Attack (IMBIA), demonstrating how multi-agent systems can be manipulated to generate software with concealed malicious capabilities beneath seemingly benign applications, and propose Adv-IMBIA as a defense mechanism. Evaluations across ChatDev, MetaGPT, and AgentVerse frameworks reveal varying vulnerability patterns, with IMBIA achieving attack success rates of 93%, 45%, and 71% in MU-BA scenarios, and 71%, 84%, and 45% in BU-MA scenarios. Our defense mechanism reduced attack success rates significantly, particularly in the MU-BA scenario. Further analysis reveals that compromised agents in the coding and testing phases pose significantly greater security risks, while also identifying critical agents that require protection against malicious user exploitation. Our findings highlight the urgent need for robust security measures in multi-agent software development systems and provide practical guidelines for implementing targeted, resource-efficient defensive strategies.",
        "url": "http://arxiv.org/abs/2511.18467v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18467v1",
        "arxiv_id": "2511.18467v1",
        "authors": [
            "Xiaoqing Wang",
            "Keman Huang",
            "Bin Liang",
            "Hongyu Li",
            "Xiaoyong Du"
        ],
        "submitted": "2025-11-23 14:26:35",
        "source": "arxiv",
        "comment": "Accepted by AAAI 2026 Alignment Track"
    },
    {
        "title": "General Agentic Memory Via Deep Research",
        "abstract": "Memory is critical for AI agents, yet the widely-adopted static memory, aiming to create readily available memory in advance, is inevitably subject to severe information loss. To address this limitation, we propose a novel framework called \\textbf{general agentic memory (GAM)}. GAM follows the principle of \"\\textbf{just-in time (JIT) compilation}\" where it focuses on creating optimized contexts for its client at runtime while keeping only simple but useful memory during the offline stage. To this end, GAM employs a duo-design with the following components. 1) \\textbf{Memorizer}, which highlights key historical information using a lightweight memory, while maintaining complete historical information within a universal page-store. 2) \\textbf{Researcher}, which retrieves and integrates useful information from the page-store for its online request guided by the pre-constructed memory. This design allows GAM to effectively leverage the agentic capabilities and test-time scalability of frontier large language models (LLMs), while also facilitating end-to-end performance optimization through reinforcement learning. In our experimental study, we demonstrate that GAM achieves substantial improvement on various memory-grounded task completion scenarios against existing memory systems.",
        "url": "http://arxiv.org/abs/2511.18423v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18423v1",
        "arxiv_id": "2511.18423v1",
        "authors": [
            "B. Y. Yan",
            "Chaofan Li",
            "Hongjin Qian",
            "Shuqi Lu",
            "Zheng Liu"
        ],
        "submitted": "2025-11-23 12:29:33",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Multi-Agent Collaborative Filtering: Orchestrating Users and Items for Agentic Recommendations",
        "abstract": "Agentic recommendations cast recommenders as large language model (LLM) agents that can plan, reason, use tools, and interact with users of varying preferences in web applications. However, most existing agentic recommender systems focus on generic single-agent plan-execute workflows or multi-agent task decomposition pipelines. Without recommendation-oriented design, they often underuse the collaborative signals in the user-item interaction history, leading to unsatisfying recommendation results. To address this, we propose the Multi-Agent Collaborative Filtering (MACF) framework for agentic recommendations, drawing an analogy between traditional collaborative filtering algorithms and LLM-based multi-agent collaboration. Specifically, given a target user and query, we instantiate similar users and relevant items as LLM agents with unique profiles. Each agent is able to call retrieval tools, suggest candidate items, and interact with other agents. Different from the static preference aggregation in traditional collaborative filtering, MACF employs a central orchestrator agent to adaptively manage the collaboration between user and item agents via dynamic agent recruitment and personalized collaboration instruction. Experimental results on datasets from three different domains show the advantages of our MACF framework compared to strong agentic recommendation baselines.",
        "url": "http://arxiv.org/abs/2511.18413v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18413v1",
        "arxiv_id": "2511.18413v1",
        "authors": [
            "Yu Xia",
            "Sungchul Kim",
            "Tong Yu",
            "Ryan A. Rossi",
            "Julian McAuely"
        ],
        "submitted": "2025-11-23 11:57:10",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "SmolKalam: Ensemble Quality-Filtered Translation at Scale for High Quality Arabic Post-Training Data",
        "abstract": "Although the community has tackled the acquisition of high-quality Arabic pretraining data, we still lack large-scale, multi-turn Arabic datasets that include reasoning and tool calling. Naive translation can work at the pretraining scale, but post-training demands much higher quality, which requires a stricter approach to dataset curation. In this work, we introduce SmolKalam, a translation of Smoltalk2 that uses a multi-model ensemble translation pipeline, applies quality filtering, and examines effective translation techniques for traditional decoder-only models through ablations.",
        "url": "http://arxiv.org/abs/2511.18411v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18411v1",
        "arxiv_id": "2511.18411v1",
        "authors": [
            "Sultan Alrashed",
            "Chadi Helwe",
            "Francesco Orabona"
        ],
        "submitted": "2025-11-23 11:53:30",
        "source": "arxiv",
        "comment": "Work in progress"
    },
    {
        "title": "Findings of the BlackboxNLP 2025 Shared Task: Localizing Circuits and Causal Variables in Language Models",
        "abstract": "Mechanistic interpretability (MI) seeks to uncover how language models (LMs) implement specific behaviors, yet measuring progress in MI remains challenging. The recently released Mechanistic Interpretability Benchmark (MIB; Mueller et al., 2025) provides a standardized framework for evaluating circuit and causal variable localization. Building on this foundation, the BlackboxNLP 2025 Shared Task extends MIB into a community-wide reproducible comparison of MI techniques. The shared task features two tracks: circuit localization, which assesses methods that identify causally influential components and interactions driving model behavior, and causal variable localization, which evaluates approaches that map activations into interpretable features. With three teams spanning eight different methods, participants achieved notable gains in circuit localization using ensemble and regularization strategies for circuit discovery. With one team spanning two methods, participants achieved significant gains in causal variable localization using low-dimensional and non-linear projections to featurize activation vectors. The MIB leaderboard remains open; we encourage continued work in this standard evaluation framework to measure progress in MI research going forward.",
        "url": "http://arxiv.org/abs/2511.18409v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18409v1",
        "arxiv_id": "2511.18409v1",
        "authors": [
            "Dana Arad",
            "Yonatan Belinkov",
            "Hanjie Chen",
            "Najoung Kim",
            "Hosein Mohebbi",
            "Aaron Mueller",
            "Gabriele Sarti",
            "Martin Tutek"
        ],
        "submitted": "2025-11-23 11:33:59",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "A Multimodal Conversational Agent for Tabular Data Analysis",
        "abstract": "Large language models (LLMs) can reshape information processing by handling data analysis, visualization, and interpretation in an interactive, context-aware dialogue with users, including voice interaction, while maintaining high performance. In this article, we present Talk2Data, a multimodal LLM-driven conversational agent for intuitive data exploration. The system lets users query datasets with voice or text instructions and receive answers as plots, tables, statistics, or spoken explanations. Built on LLMs, the suggested design combines OpenAI Whisper automatic speech recognition (ASR) system, Qwen-coder code generation LLM/model, custom sandboxed execution tools, and Coqui library for text-to-speech (TTS) within an agentic orchestration loop. Unlike text-only analysis tools, it adapts responses across modalities and supports multi-turn dialogues grounded in dataset context. In an evaluation of 48 tasks on three datasets, our prototype achieved 95.8% accuracy with model-only generation time under 1.7 seconds (excluding ASR and execution time). A comparison across five LLM sizes (1.5B-32B) revealed accuracy-latency-cost trade-offs, with a 7B model providing the best balance for interactive use. By routing between conversation with user and code execution, constrained to a transparent sandbox, with simultaneously grounding prompts in schema-level context, the Talk2Data agent reliably retrieves actionable insights from tables while making computations verifiable. In the article, except for the Talk2Data agent itself, we discuss implications for human-data interaction, trust in LLM-driven analytics, and future extensions toward large-scale multimodal assistants.",
        "url": "http://arxiv.org/abs/2511.18405v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18405v1",
        "arxiv_id": "2511.18405v1",
        "authors": [
            "Mohammad Nour Al Awad",
            "Sergey Ivanov",
            "Olga Tikhonova",
            "Ivan Khodnenko"
        ],
        "submitted": "2025-11-23 11:21:04",
        "source": "arxiv",
        "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses"
    },
    {
        "title": "Towards Robust and Fair Next Visit Diagnosis Prediction under Noisy Clinical Notes with Large Language Models",
        "abstract": "A decade of rapid advances in artificial intelligence (AI) has opened new opportunities for clinical decision support systems (CDSS), with large language models (LLMs) demonstrating strong reasoning abilities on timely medical tasks. However, clinical texts are often degraded by human errors or failures in automated pipelines, raising concerns about the reliability and fairness of AI-assisted decision-making. Yet the impact of such degradations remains under-investigated, particularly regarding how noise-induced shifts can heighten predictive uncertainty and unevenly affect demographic subgroups. We present a systematic study of state-of-the-art LLMs under diverse text corruption scenarios, focusing on robustness and equity in next-visit diagnosis prediction. To address the challenge posed by the large diagnostic label space, we introduce a clinically grounded label-reduction scheme and a hierarchical chain-of-thought (CoT) strategy that emulates clinicians' reasoning. Our approach improves robustness and reduces subgroup instability under degraded inputs, advancing the reliable use of LLMs in CDSS. We release code at https://github.com/heejkoo9/NECHOv3.",
        "url": "http://arxiv.org/abs/2511.18393v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18393v1",
        "arxiv_id": "2511.18393v1",
        "authors": [
            "Heejoon Koo"
        ],
        "submitted": "2025-11-23 10:40:36",
        "source": "arxiv",
        "comment": "Accepted by the Association for the Advancement of Artificial Intelligence (AAAI) 2026 1st Workshop on Safe, Ethical, Certified, Uncertainty-aware, Robust, and Explainable AI for Health (SECURE-AI4H)"
    },
    {
        "title": "Tu crois que c'est vrai ? Diversite des regimes d'enonciation face aux fake news et mecanismes d'autoregulation conversationnelle",
        "abstract": "This thesis addresses two paradoxes: (1) why empirical studies find that fake news represent only a small share of the information consulted and shared on social media despite the absence of editorial control or journalistic norms, and (2) how political polarization has intensified even though users do not appear especially receptive to fake news. To investigate these issues, two complementary studies were carried out on Twitter and Facebook, combining quantitative analyses of digital traces with online observation and interviews. This mixed-methods design avoids reducing users to single reactions to identified fake items and instead examines the variety of practices across different interactional situations, online and offline, while recording socio-demographic traits. The first study mapped users who shared at least one item labeled fake by fact-checkers in the French Twittersphere. The second used a corpus of items flagged by Facebook users to study reactions to statements whose epistemic status is uncertain. Three main findings emerge. First, sharing fake news is concentrated among a limited group of users who are not less educated or cognitively disadvantaged but are more politicized and critical of institutions; owing to their high activity and prolific sharing, they can help set the agenda for their political camp. Second, exposed users can deploy varying forms of critical distance depending on their social position and the interactional norms of the situations they inhabit: either discursive caution (prudence énonciative) or interventions ('points d'arrêt') that express disagreement or corrections. Third, these forms of critical distance seldom yield genuine deliberative debates or agonistic pluralism; rather, they often produce dialogues of the deaf among a small, particularly active minority.",
        "url": "http://arxiv.org/abs/2511.18369v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18369v1",
        "arxiv_id": "2511.18369v1",
        "authors": [
            "Manon Berriche"
        ],
        "submitted": "2025-11-23 09:28:16",
        "source": "arxiv",
        "comment": "in French language"
    },
    {
        "title": "Toward an AI-Native Internet: Rethinking the Web Architecture for Semantic Retrieval",
        "abstract": "The rise of Generative AI Search is fundamentally transforming how users and intelligent systems interact with the Internet. LLMs increasingly act as intermediaries between humans and web information. Yet the web remains optimized for human browsing rather than AI-driven semantic retrieval, resulting in wasted network bandwidth, lower information quality, and unnecessary complexity for developers. We introduce the concept of an AI-Native Internet, a web architecture in which servers expose semantically relevant information chunks rather than full documents, supported by a Web-native semantic resolver that allows AI applications to discover relevant information sources before retrieving fine-grained chunks. Through motivational experiments, we quantify the inefficiencies of current HTML-based retrieval, and outline architectural directions and open challenges for evolving today's document-centric web into an AI-oriented substrate that better supports semantic access to web content.",
        "url": "http://arxiv.org/abs/2511.18354v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18354v1",
        "arxiv_id": "2511.18354v1",
        "authors": [
            "Muhammad Bilal",
            "Zafar Qazi",
            "Marco Canini"
        ],
        "submitted": "2025-11-23 09:01:22",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Time Matters: Enhancing Sequential Recommendations with Time-Guided Graph Neural ODEs",
        "abstract": "Sequential recommendation (SR) is widely deployed in e-commerce platforms, streaming services, etc., revealing significant potential to enhance user experience. However, existing methods often overlook two critical factors: irregular user interests between interactions and highly uneven item distributions over time. The former factor implies that actual user preferences are not always continuous, and long-term historical interactions may not be relevant to current purchasing behavior. Therefore, relying only on these historical interactions for recommendations may result in a lack of user interest at the target time. The latter factor, characterized by peaks and valleys in interaction frequency, may result from seasonal trends, special events, or promotions. These externally driven distributions may not align with individual user interests, leading to inaccurate recommendations. To address these deficiencies, we propose TGODE to both enhance and capture the long-term historical interactions. Specifically, we first construct a user time graph and item evolution graph, which utilize user personalized preferences and global item distribution information, respectively. To tackle the temporal sparsity caused by irregular user interactions, we design a time-guided diffusion generator to automatically obtain an augmented time-aware user graph. Additionally, we devise a user interest truncation factor to efficiently identify sparse time intervals and achieve balanced preference inference. After that, the augmented user graph and item graph are fed into a generalized graph neural ordinary differential equation (ODE) to align with the evolution of user preferences and item distributions. This allows two patterns of information evolution to be matched over time. Experimental results demonstrate that TGODE outperforms baseline methods across five datasets, with improvements ranging from 10% to 46%.",
        "url": "http://arxiv.org/abs/2511.18347v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18347v1",
        "arxiv_id": "2511.18347v1",
        "authors": [
            "Haoyan Fu",
            "Zhida Qin",
            "Shixiao Yang",
            "Haoyao Zhang",
            "Bin Lu",
            "Shuang Li",
            "Tianyu Huang",
            "John C. S. Lui"
        ],
        "submitted": "2025-11-23 08:46:27",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "UFO: Unfair-to-Fair Evolving Mitigates Unfairness in LLM-based Recommender Systems via Self-Play Fine-tuning",
        "abstract": "Large language model-based Recommender Systems (LRSs) have demonstrated superior recommendation performance by integrating pre-training with Supervised Fine-Tuning (SFT). However, this approach introduces item-side unfairness. Existing studies primarily attribute this issue to the absence of fairness constraints during SFT and attempt to mitigate unfairness via re-weighting and re-ranking methods. In this paper, we find that unfairness arises not only from SFT but also from pre-training, where inherent biases are further amplified during SFT. This finding underscores the failure of current methods to address the root causes of unfairness. Moreover, current methods struggle to preserve satisfactory recommendation performance. To tackle these issues, we propose an Unfair-to-Fair evOlving (UFO) framework using a self-play mechanism, formulating unfairness mitigation as a two-player game. UFO alternates between two player roles: the \\textit{judger}, which identifies unfairness from both pre-training and SFT, and the \\textit{corrector}, which adjusts the LRS to address identified unfairness while preserving recommendation performance. Iterative optimization between these roles enables UFO to completely resolve unfairness. Extensive experiments demonstrate that UFO effectively mitigates unfairness while improving recommendation performance.",
        "url": "http://arxiv.org/abs/2511.18342v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18342v1",
        "arxiv_id": "2511.18342v1",
        "authors": [
            "Jiaming Zhang",
            "Yuyuan Li",
            "Xiaohua Feng",
            "Zhifei Ren",
            "Li Zhang",
            "Chaochao Chen"
        ],
        "submitted": "2025-11-23 08:34:30",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "OmniStruct: Universal Text-to-Structure Generation across Diverse Schemas",
        "abstract": "The ability of Large Language Models (LLMs) to generate structured outputs that follow arbitrary schemas is crucial to a wide range of downstream tasks that require diverse structured representations of results such as information extraction, table generation, and function calling. While modern LLMs excel in generating unstructured responses in natural language, whether this advancement translates to a strong performance on text-to-structure tasks remains unclear. To bridge this gap, we first introduce OmniStruct, a comprehensive benchmark for assessing LLMs' capabilities on diverse text-to-structure tasks such as information extraction, table generation, and function calling. We build OmniStruct by identifying existing datasets across a wide range of tasks that are suitable for a structured answer format, and adapting them under a unified text-to-structure problem setting. To facilitate the development of efficient text-to-structure models, we collect high-quality training data via synthetic task generation. Without using any supervised data for OmniStruct tasks, our experiments demonstrate the possibility of fine-tuning much smaller models on synthetic data into universal structured generation models that can rival the performance of GPT-4o.",
        "url": "http://arxiv.org/abs/2511.18335v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18335v1",
        "arxiv_id": "2511.18335v1",
        "authors": [
            "James Y. Huang",
            "Wenxuan Zhou",
            "Nan Xu",
            "Fei Wang",
            "Qin Liu",
            "Sheng Zhang",
            "Hoifung Poon",
            "Muhao Chen"
        ],
        "submitted": "2025-11-23 08:18:12",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Gradient Masters at BLP-2025 Task 1: Advancing Low-Resource NLP for Bengali using Ensemble-Based Adversarial Training for Hate Speech Detection",
        "abstract": "This paper introduces the approach of \"Gradient Masters\" for BLP-2025 Task 1: \"Bangla Multitask Hate Speech Identification Shared Task\". We present an ensemble-based fine-tuning strategy for addressing subtasks 1A (hate-type classification) and 1B (target group classification) in YouTube comments. We propose a hybrid approach on a Bangla Language Model, which outperformed the baseline models and secured the 6th position in subtask 1A with a micro F1 score of 73.23% and the third position in subtask 1B with 73.28%. We conducted extensive experiments that evaluated the robustness of the model throughout the development and evaluation phases, including comparisons with other Language Model variants, to measure generalization in low-resource Bangla hate speech scenarios and data set coverage. In addition, we provide a detailed analysis of our findings, exploring misclassification patterns in the detection of hate speech.",
        "url": "http://arxiv.org/abs/2511.18324v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18324v1",
        "arxiv_id": "2511.18324v1",
        "authors": [
            "Syed Mohaiminul Hoque",
            "Naimur Rahman",
            "Md Sakhawat Hossain"
        ],
        "submitted": "2025-11-23 07:29:09",
        "source": "arxiv",
        "comment": "6 pages, 2 figures, 4 tables. Accepted at the Second International Workshop on Bangla Language Processing (BLP-2025) co-located with AACL-IJCNLP 2025. Ranked 6th (Subtask 1A, 73.23% micro F1) and 3rd (Subtask 1B, 73.28% micro F1) on the official leaderboard"
    },
    {
        "title": "Path-Constrained Retrieval: A Structural Approach to Reliable LLM Agent Reasoning Through Graph-Scoped Semantic Search",
        "abstract": "Large Language Model agents often retrieve context from knowledge bases that lack structural consistency with the agent's current reasoning state, leading to incoherent reasoning chains. We introduce Path-Constrained Retrieval (PCR), a retrieval method that combines structural graph constraints with semantic search to ensure retrieved information maintains logical relationships within a knowledge graph. PCR restricts the search space to nodes reachable from an anchor node, preventing retrieval of structurally disconnected information that may lead to inconsistent reasoning. We evaluate PCR on PathRAG-6, a benchmark spanning six domains with 180 nodes and 360 edges. Our results show that PCR achieves full structural consistency compared to 24-32 percent in baseline methods, while maintaining strong relevance scores. On the technology domain, PCR obtains full relevance at rank 10 with full structural consistency, significantly outperforming vector search and hybrid retrieval. PCR reduces the average graph distance of retrieved context by 78 percent compared to baselines, demonstrating retrieval of more structurally consistent information. These findings suggest that path-constrained retrieval is an effective approach for improving the reliability and coherence of LLM agent reasoning systems.",
        "url": "http://arxiv.org/abs/2511.18313v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18313v1",
        "arxiv_id": "2511.18313v1",
        "authors": [
            "Joseph Oladokun"
        ],
        "submitted": "2025-11-23 06:50:01",
        "source": "arxiv",
        "comment": "10 pages"
    },
    {
        "title": "Table Comprehension in Building Codes using Vision Language Models and Domain-Specific Fine-Tuning",
        "abstract": "Building codes contain critical information for ensuring safety, regulatory compliance, and informed decision-making in construction and engineering. Automated question answering systems over such codes enable quick and accurate access to specific regulatory clauses, improving efficiency and reducing errors. Retrieval-Augmented Generation (RAG) systems are essential for this task as they combine the precision of information retrieval with the generative capabilities of language models. However, tabular data are challenging to extract as they often involve complex layouts, merged cells, multi-row headers, and embedded semantic relationships that are not easily captured by traditional natural language processing techniques and Vision Language Models (VLMs). This paper explores and compares two methods for extracting information from tabular data in building codes using several pre-trained VLMs. First, a direct input method is used, where the image of the page is input directly into the VLMs, which are then tasked with answering questions based on the image. Second, an indirect input method is introduced, which involves converting an image of a page containing tables into the LaTeX code and then answering inquires based on the LaTeX-based input. The experiments find that the direct input method generally resulted in higher accuracy than the indirect input method. To further improve the performance, we fine-tuned each VLM using Low Rank Adaptation (LoRA) on a domain-specific tabular dataset. The fine-tuned models exhibited substantial improvements, with Qwen2.5-VL-3B-Instruct achieving relative accuracy gains exceeding 100%. Our results highlight the potential of parameter-efficient fine-tuning methods to adapt powerful VLMs for understanding complex structured data in specialized fields, such as building code interpretation and regulatory compliance.",
        "url": "http://arxiv.org/abs/2511.18306v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18306v1",
        "arxiv_id": "2511.18306v1",
        "authors": [
            "Mohammad Aqib",
            "Mohd Hamza",
            "Ying Hei Chui",
            "Qipei Mei"
        ],
        "submitted": "2025-11-23 06:34:51",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "\"AGI\" team at SHROOM-CAP: Data-Centric Approach to Multilingual Hallucination Detection using XLM-RoBERTa",
        "abstract": "The detection of hallucinations in multilingual scientific text generated by Large Language Models (LLMs) presents significant challenges for reliable AI systems. This paper describes our submission to the SHROOM-CAP 2025 shared task on scientific hallucination detection across 9 languages. Unlike most approaches that focus primarily on model architecture, we adopted a data-centric strategy that addressed the critical issue of training data scarcity and imbalance. We unify and balance five existing datasets to create a comprehensive training corpus of 124,821 samples (50% correct, 50% hallucinated), representing a 172x increase over the original SHROOM training data. Our approach fine-tuned XLM-RoBERTa-Large with 560 million parameters on this enhanced dataset, achieves competitive performance across all languages, including \\textbf{2nd place in Gujarati} (zero-shot language) with Factuality F1 of 0.5107, and rankings between 4th-6th place across the remaining 8 languages. Our results demonstrate that systematic data curation can significantly outperform architectural innovations alone, particularly for low-resource languages in zero-shot settings.",
        "url": "http://arxiv.org/abs/2511.18301v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18301v1",
        "arxiv_id": "2511.18301v1",
        "authors": [
            "Harsh Rathva",
            "Pruthwik Mishra",
            "Shrikant Malviya"
        ],
        "submitted": "2025-11-23 05:48:27",
        "source": "arxiv",
        "comment": "Accepted to the 1st Workshop on Confabulation, Hallucinations & Overgeneration in Multilingual and Practical Settings (CHOMPS) at AACL-IJCNLP 2025"
    },
    {
        "title": "Large Language Model Enhanced Graph Invariant Contrastive Learning for Out-of-Distribution Recommendation",
        "abstract": "Out-of-distribution (OOD) generalization has emerged as a significant challenge in graph recommender systems. Traditional graph neural network algorithms often fail because they learn spurious environmental correlations instead of stable causal relationships, leading to substantial performance degradation under distribution shifts. While recent advancements in Large Language Models (LLMs) offer a promising avenue due to their vast world knowledge and reasoning capabilities, effectively integrating this knowledge with the fine-grained topology of specific graphs to solve the OOD problem remains a significant challenge. To address these issues, we propose {$\\textbf{Inv}$ariant $\\textbf{G}$raph $\\textbf{C}$ontrastive Learning with $\\textbf{LLM}$s for Out-of-Distribution Recommendation (InvGCLLM)}, an innovative causal learning framework that synergistically integrates the strengths of data-driven models and knowledge-driven LLMs. Our framework first employs a data-driven invariant learning model to generate causal confidence scores for each user-item interaction. These scores then guide an LLM to perform targeted graph refinement, leveraging its world knowledge to prune spurious connections and augment missing causal links. Finally, the structurally purified graphs provide robust supervision for a causality-guided contrastive learning objective, enabling the model to learn representations that are resilient to spurious correlations. Experiments conducted on four public datasets demonstrate that InvGCLLM achieves significant improvements in out-of-distribution recommendation, consistently outperforming state-of-the-art baselines.",
        "url": "http://arxiv.org/abs/2511.18282v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18282v1",
        "arxiv_id": "2511.18282v1",
        "authors": [
            "Jiahao Liang",
            "Haoran Yang",
            "Xiangyu Zhao",
            "Zhiwen Yu",
            "Mianjie Li",
            "Chuan Shi",
            "Kaixiang Yang"
        ],
        "submitted": "2025-11-23 04:24:58",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Democratic Recommendation with User and Item Representatives Produced by Graph Condensation",
        "abstract": "The challenges associated with large-scale user-item interaction graphs have attracted increasing attention in graph-based recommendation systems, primarily due to computational inefficiencies and inadequate information propagation. Existing methods provide partial solutions but suffer from notable limitations: model-centric approaches, such as sampling and aggregation, often struggle with generalization, while data-centric techniques, including graph sparsification and coarsening, lead to information loss and ineffective handling of bipartite graph structures. Recent advances in graph condensation offer a promising direction by reducing graph size while preserving essential information, presenting a novel approach to mitigating these challenges. Inspired by the principles of democracy, we propose \\textbf{DemoRec}, a framework that leverages graph condensation to generate user and item representatives for recommendation tasks. By constructing a compact interaction graph and clustering nodes with shared characteristics from the original graph, DemoRec significantly reduces graph size and computational complexity. Furthermore, it mitigates the over-reliance on high-order information, a critical challenge in large-scale bipartite graphs. Extensive experiments conducted on four public datasets demonstrate the effectiveness of DemoRec, showcasing substantial improvements in recommendation performance, computational efficiency, and robustness compared to SOTA methods.",
        "url": "http://arxiv.org/abs/2511.18279v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18279v1",
        "arxiv_id": "2511.18279v1",
        "authors": [
            "Jiahao Liang",
            "Haoran Yang",
            "Xiangyu Zhao",
            "Zhiwen Yu",
            "Guandong Xu",
            "Wanyu Wang",
            "Kaixiang Yang"
        ],
        "submitted": "2025-11-23 04:09:28",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "LLM Reasoning for Cold-Start Item Recommendation",
        "abstract": "Large Language Models (LLMs) have shown significant potential for improving recommendation systems through their inherent reasoning capabilities and extensive knowledge base. Yet, existing studies predominantly address warm-start scenarios with abundant user-item interaction data, leaving the more challenging cold-start scenarios, where sparse interactions hinder traditional collaborative filtering methods, underexplored. To address this limitation, we propose novel reasoning strategies designed for cold-start item recommendations within the Netflix domain. Our method utilizes the advanced reasoning capabilities of LLMs to effectively infer user preferences, particularly for newly introduced or rarely interacted items. We systematically evaluate supervised fine-tuning, reinforcement learning-based fine-tuning, and hybrid approaches that combine both methods to optimize recommendation performance. Extensive experiments on real-world data demonstrate significant improvements in both methodological efficacy and practical performance in cold-start recommendation contexts. Remarkably, our reasoning-based fine-tuned models outperform Netflix's production ranking model by up to 8% in certain cases.",
        "url": "http://arxiv.org/abs/2511.18261v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18261v1",
        "arxiv_id": "2511.18261v1",
        "authors": [
            "Shijun Li",
            "Yu Wang",
            "Jin Wang",
            "Ying Li",
            "Joydeep Ghosh",
            "Anne Cocos"
        ],
        "submitted": "2025-11-23 03:22:53",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "From Archives to Decisions: Multi-Agent Pharmaceutical Co-Scientist for Traceable Drug Discovery and Reverse Translation",
        "abstract": "Pharmaceutical research and development has accumulated vast, heterogeneous archives of data. Much of this knowledge stems from discontinued programs, and reusing these archives is invaluable for reverse translation. However, in practice, such reuse is often infeasible. In this work, we introduce DiscoVerse, a multi-agent co-scientist designed to support pharmaceutical research and development. The system implements semantic retrieval, cross-document linking, and auditable synthesis on a large historical corpus from Roche. To validate our approach at real-world scale, we selected a subset of 180 molecules from the Roche research repositories, covering over 0.87 billion BPE tokens and more than four decades of research. Given that automated evaluation metrics are poorly aligned with scientific utility, we evaluate the performance of DiscoVerse using blinded expert evaluation of source-linked outputs. To our knowledge, this is the first agentic framework systematically assessed on real pharmaceutical data for reverse translation, enabled by authorized access to confidential, end-to-end drug-development archives. Our contributions include role-specialized agent designs aligned with scientist workflows; human-in-the-loop support for reverse translation; expert evaluation; and a large-scale demonstration showing promising answer accuracy and decision-making insights. In brief, across seven benchmark queries covering 180 molecules, DiscoVerse achieved near-perfect recall ($\\geq 0.99$) with moderate precision ($0.71-0.91$), while qualitative assessments of discontinuation rationale and organ-specific toxicity showed faithful, source-linked synthesis across preclinical and clinical evidence.",
        "url": "http://arxiv.org/abs/2511.18259v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18259v1",
        "arxiv_id": "2511.18259v1",
        "authors": [
            "Xiaochen Zheng",
            "Alvaro Serra",
            "Ilya Schneider Chernov",
            "Maddalena Marchesi",
            "Eunice Musvasva",
            "Tatyana Y. Doktorova"
        ],
        "submitted": "2025-11-23 03:17:26",
        "source": "arxiv",
        "comment": "22 pages, 4 figures, 3 tables"
    },
    {
        "title": "ProHD: Projection-Based Hausdorff Distance Approximation",
        "abstract": "The Hausdorff distance (HD) is a robust measure of set dissimilarity, but computing it exactly on large, high-dimensional datasets is prohibitively expensive. We propose \\textbf{ProHD}, a projection-guided approximation algorithm that dramatically accelerates HD computation while maintaining high accuracy. ProHD identifies a small subset of candidate \"extreme\" points by projecting the data onto a few informative directions (such as the centroid axis and top principal components) and computing the HD on this subset. This approach guarantees an underestimate of the true HD with a bounded additive error and typically achieves results within a few percent of the exact value. In extensive experiments on image, physics, and synthetic datasets (up to two million points in $D=256$), ProHD runs 10--100$\\times$ faster than exact algorithms while attaining 5--20$\\times$ lower error than random sampling-based approximations. Our method enables practical HD calculations in scenarios like large vector databases and streaming data, where quick and reliable set distance estimation is needed.",
        "url": "http://arxiv.org/abs/2511.18207v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18207v1",
        "arxiv_id": "2511.18207v1",
        "authors": [
            "Jiuzhou Fu",
            "Luanzheng Guo",
            "Nathan R. Tallent",
            "Dongfang Zhao"
        ],
        "submitted": "2025-11-22 22:44:46",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Agent-as-a-Graph: Knowledge Graph-Based Tool and Agent Retrieval for LLM Multi-Agent Systems",
        "abstract": "Recent advances in Large Language Model Multi-Agent Systems enable scalable orchestration and retrieval of specialized, parallelized subagents, each equipped with hundreds or thousands of Model Context Protocol (MCP) servers and tools. However, existing agent, MCP, and retrieval methods typically match queries against a single agent description, obscuring fine-grained tool capabilities of each agent, resulting in suboptimal agent selection. We introduce Agent-as-a-Graph retrieval, a knowledge graph retrieval augmented generation approach that represents both tools and their parent agents as nodes and edges in a knowledge graph. During retrieval, i) relevant agents and tool nodes are first retrieved through vector search, ii) we apply a type-specific weighted reciprocal rank fusion (wRRF) for reranking tools and agents, and iii) parent agents are traversed in the knowledge graph for the final set of agents. We evaluate Agent-as-a-Graph on the LiveMCPBenchmark, achieving 14.9% and 14.6% improvements in Recall@5 and nDCG@5 over prior state-of-the-art retrievers, and 2.4% improvements in wRRF optimizations.",
        "url": "http://arxiv.org/abs/2511.18194v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18194v1",
        "arxiv_id": "2511.18194v1",
        "authors": [
            "Faheem Nizar",
            "Elias Lumer",
            "Anmol Gulati",
            "Pradeep Honaganahalli Basavaraju",
            "Vamse Kumar Subbiah"
        ],
        "submitted": "2025-11-22 21:24:16",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Rethinking Retrieval: From Traditional Retrieval Augmented Generation to Agentic and Non-Vector Reasoning Systems in the Financial Domain for Large Language Models",
        "abstract": "Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models to answer financial questions using external knowledge bases of U.S. SEC filings, earnings reports, and regulatory documents. However, existing work lacks systematic comparison of vector-based and non-vector RAG architectures for financial documents, and the empirical impact of advanced RAG techniques on retrieval accuracy, answer quality, latency, and cost remain unclear. We present the first systematic evaluation comparing vector-based agentic RAG using hybrid search and metadata filtering against hierarchical node-based systems that traverse document structure without embeddings. We evaluate two enhancement techniques applied to the vector-based architecture, i) cross-encoder reranking for retrieval precision, and ii) small-to-big chunk retrieval for context completeness. Across 1,200 SEC 10-K, 10-Q, and 8-K filings on a 150-question benchmark, we measure retrieval metrics (MRR, Recall@5), answer quality through LLM-as-a-judge pairwise comparisons, latency, and preprocessing costs. Vector-based agentic RAG achieves a 68% win rate over hierarchical node-based systems with comparable latency (5.2 compared to 5.98 seconds). Cross-encoder reranking achieves a 59% absolute improvement at optimal parameters (10, 5) for MRR@5. Small-to-big retrieval achieves a 65% win rate over baseline chunking with only 0.2 seconds additional latency. Our findings reveal that applying advanced RAG techniques to financial Q&A systems improves retrieval accuracy, answer quality, and has cost-performance tradeoffs to be considered in production.",
        "url": "http://arxiv.org/abs/2511.18177v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18177v1",
        "arxiv_id": "2511.18177v1",
        "authors": [
            "Elias Lumer",
            "Matt Melich",
            "Olivia Zino",
            "Elena Kim",
            "Sara Dieter",
            "Pradeep Honaganahalli Basavaraju",
            "Vamse Kumar Subbiah",
            "James A. Burke",
            "Roberto Hernandez"
        ],
        "submitted": "2025-11-22 20:06:25",
        "source": "arxiv",
        "comment": "8 pages, 2 figures"
    },
    {
        "title": "Vector Arithmetic in Concept and Token Subspaces",
        "abstract": "In order to predict the next token, LLMs must represent semantic and surface-level information about the current word. Previous work identified two types of attention heads that disentangle this information: (i) Concept induction heads, which copy word meanings, and (ii) Token induction heads, which copy literal token representations (Feucht et al., 2025). We show that these heads can be used to identify subspaces of model activations that exhibit coherent semantic structure in Llama-2-7b. Specifically, when we transform hidden states using the attention weights of concept heads, we are able to more accurately perform parallelogram arithmetic (Mikolov et al., 2013) on the resulting hidden states, e.g., showing that \"Athens\" - \"Greece\" + \"China\" = \"Beijing\". This transformation allows for much higher nearest-neighbor accuracy (80%) than direct use of raw hidden states (47%). Analogously, we show that token heads allow for transformations that reveal surface-level word information in hidden states, allowing for operations like \"coding\" - \"code\" + \"dance\" = \"dancing\".",
        "url": "http://arxiv.org/abs/2511.18162v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18162v1",
        "arxiv_id": "2511.18162v1",
        "authors": [
            "Sheridan Feucht",
            "Byron Wallace",
            "David Bau"
        ],
        "submitted": "2025-11-22 19:21:13",
        "source": "arxiv",
        "comment": "9 pages, 6 figures. NeurIPS 2025 Mechanistic Interpretability Workshop"
    },
    {
        "title": "GeeSanBhava: Sentiment Tagged Sinhala Music Video Comment Data Set",
        "abstract": "This study introduce GeeSanBhava, a high-quality data set of Sinhala song comments extracted from YouTube manually tagged using Russells Valence-Arousal model by three independent human annotators. The human annotators achieve a substantial inter-annotator agreement (Fleiss kappa = 84.96%). The analysis revealed distinct emotional profiles for different songs, highlighting the importance of comment based emotion mapping. The study also addressed the challenges of comparing comment-based and song-based emotions, mitigating biases inherent in user-generated content. A number of Machine learning and deep learning models were pre-trained on a related large data set of Sinhala News comments in order to report the zero-shot result of our Sinhala YouTube comment data set. An optimized Multi-Layer Perceptron model, after extensive hyperparameter tuning, achieved a ROC-AUC score of 0.887. The model is a three-layer MLP with a configuration of 256, 128, and 64 neurons. This research contributes a valuable annotated dataset and provides insights for future work in Sinhala Natural Language Processing and music emotion recognition.",
        "url": "http://arxiv.org/abs/2511.18146v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18146v1",
        "arxiv_id": "2511.18146v1",
        "authors": [
            "Yomal De Mel",
            "Nisansa de Silva"
        ],
        "submitted": "2025-11-22 18:15:06",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Bias Is a Subspace, Not a Coordinate: A Geometric Rethinking of Post-hoc Debiasing in Vision-Language Models",
        "abstract": "Vision-Language Models (VLMs) have become indispensable for multimodal reasoning, yet their representations often encode and amplify demographic biases, resulting in biased associations and misaligned predictions in downstream tasks. Such behavior undermines fairness and distorts the intended alignment between vision and language. Recent post-hoc approaches attempt to mitigate bias by replacing the most attribute-correlated embedding coordinates with neutral values. However, our systematic analysis reveals three critical failures of this coordinate-wise approach: feature entanglement, poor cross-dataset generalization, and incomplete bias removal. We find that bias is not localized to a few coordinates but is instead distributed across a few linear subspaces. To address these limitations, we propose $\\textbf{S}$ubspace $\\textbf{P}$rojection $\\textbf{D}$ebiasing ($\\textbf{SPD}$), a geometrically principled framework that identifies and removes the entire subspace of linearly decodable bias while reinserting a neutral mean component to preserve semantic fidelity. Extensive experiments across zero-shot classification, text-to-image retrieval, and image generation validate the effectiveness of SPD: our method achieves more robust debiasing with an average improvement of $18.5\\%$ across four fairness metrics, while maintaining minimal loss in task performance compared to the best debiasing baseline.",
        "url": "http://arxiv.org/abs/2511.18123v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18123v1",
        "arxiv_id": "2511.18123v1",
        "authors": [
            "Dachuan Zhao",
            "Weiyue Li",
            "Zhenda Shen",
            "Yushu Qiu",
            "Bowen Xu",
            "Haoyu Chen",
            "Yongchao Chen"
        ],
        "submitted": "2025-11-22 17:04:30",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Comparing Labeled Markov Chains: A Cantor-Kantorovich Approach",
        "abstract": "Labeled Markov Chains (or LMCs for short) are useful mathematical objects to model complex probabilistic languages. A central challenge is to compare two LMCs, for example to assess the accuracy of an abstraction or to quantify the effect of model perturbations. In this work, we study the recently introduced Cantor-Kantorovich (or CK) distance. In particular we show that the latter can be framed as a discounted sum of finite-horizon Total Variation distances, making it an instance of discounted linear distance, but arising from the natural Cantor topology. Building on the latter observation, we analyze the properties of the CK distance along three dimensions: computational complexity, continuity properties and approximation. More precisely, we show that the exact computation of the CK distance is #P-hard. We also provide an upper bound on the CK distance as a function of the approximation relation between the two LMCs, and show that a bounded CK distance implies a bounded error between probabilities of finite-horizon traces. Finally, we provide a computable approximation scheme, and show that the latter is also #P-hard. Altogether, our results provide a rigorous theoretical foundation for the CK distance and clarify its relationship with existing distances.",
        "url": "http://arxiv.org/abs/2511.18103v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18103v1",
        "arxiv_id": "2511.18103v1",
        "authors": [
            "Adrien Banse",
            "Alessandro Abate",
            "Raphaël M. Jungers"
        ],
        "submitted": "2025-11-22 16:02:56",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "IE-Critic-R1: Advancing the Explanatory Measurement of Text-Driven Image Editing for Human Perception Alignment",
        "abstract": "Recent advances in text-driven image editing have been significant, yet the task of accurately evaluating these edited images continues to pose a considerable challenge. Different from the assessment of text-driven image generation, text-driven image editing is characterized by simultaneously conditioning on both text and a source image. The edited images often retain an intrinsic connection to the original image, which dynamically change with the semantics of the text. However, previous methods tend to solely focus on text-image alignment or have not well aligned with human perception. In this work, we introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to enhance the assessment of text-driven edited images. IE-Bench includes a database contains diverse source images, various editing prompts and the corresponding edited results from different editing methods, and nearly 4,000 samples with corresponding Mean Opinion Scores (MOS) provided by 15 human subjects. Furthermore, we introduce IE-Critic-R1, which, benefiting from Reinforcement Learning from Verifiable Rewards (RLVR), provides more comprehensive and explainable quality assessment for text-driven image editing that aligns with human perception. Extensive experiments demonstrate IE-Critic-R1's superior subjective-alignments on the text-driven image editing task compared with previous metrics. Related data and codes are available to the public.",
        "url": "http://arxiv.org/abs/2511.18055v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18055v1",
        "arxiv_id": "2511.18055v1",
        "authors": [
            "Bowen Qu",
            "Shangkun Sun",
            "Xiaoyu Liang",
            "Wei Gao"
        ],
        "submitted": "2025-11-22 13:16:58",
        "source": "arxiv",
        "comment": "18 pages, 10 figures, 8 tables"
    },
    {
        "title": "Blu-WERP (Web Extraction and Refinement Pipeline): A Scalable Pipeline for Preprocessing Large Language Model Datasets",
        "abstract": "High-quality training data is fundamental to large language model (LLM) performance, yet existing preprocessing pipelines often struggle to effectively remove noise and unstructured content from web-scale corpora. This paper presents Blu-WERP, a novel data preprocessing pipeline designed to optimize the quality of Common Crawl WARC files for LLM training. We demonstrate that Blu-WERP significantly outperforms established baselines including DCLM across multiple model scales and evaluation benchmarks. Our pipeline processes CC WARC dumps, implementing advanced filtering and quality assessment mechanisms. We conducted comprehensive evaluations using models with 150M, 400M, 530M, 750M, and 1B parameters, testing against nine standard benchmarks categorized as World Knowledge & Reasoning, Language Understanding, and Commonsense Reasoning. Results show Blu-WERP consistently achieved superior performance across all model scales. At the 1B parameter scale, Relatively Blu-WERP demonstrates a 4.0% and 9.5% aggregate improvement over DCLM and Fineweb respectively, while achieving quality-per-token efficiency gain. Categorical analysis reveals 2.4% improvement in World Knowledge & Reasoning, 6.2% improvement in Language Understanding, and 4.2% improvement in Commonsense Reasoning. These results establish Blu-WERP as a state-of-the-art preprocessing pipeline that substantially improves LLM training data quality and downstream model performance with reduced computational cost. Our findings contribute to the growing body of research on data-centric AI, demonstrating that preprocessing pipeline design significantly impacts LLM capabilities. The Blu-WERP pipeline represents a practical advancement in data quality optimization, offering researchers and practitioners an effective solution for improving LLM training efficiency and model performance.",
        "url": "http://arxiv.org/abs/2511.18054v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18054v1",
        "arxiv_id": "2511.18054v1",
        "authors": [
            "Gowtham",
            "Sai Rupesh",
            "Sanjay Kumar",
            "Saravanan",
            "Venkata Chaithanya"
        ],
        "submitted": "2025-11-22 13:14:07",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Fidelity-Aware Recommendation Explanations via Stochastic Path Integration",
        "abstract": "Explanation fidelity, which measures how accurately an explanation reflects a model's true reasoning, remains critically underexplored in recommender systems. We introduce SPINRec (Stochastic Path Integration for Neural Recommender Explanations), a model-agnostic approach that adapts path-integration techniques to the sparse and implicit nature of recommendation data. To overcome the limitations of prior methods, SPINRec employs stochastic baseline sampling: instead of integrating from a fixed or unrealistic baseline, it samples multiple plausible user profiles from the empirical data distribution and selects the most faithful attribution path. This design captures the influence of both observed and unobserved interactions, yielding more stable and personalized explanations. We conduct the most comprehensive fidelity evaluation to date across three models (MF, VAE, NCF), three datasets (ML1M, Yahoo! Music, Pinterest), and a suite of counterfactual metrics, including AUC-based perturbation curves and fixed-length diagnostics. SPINRec consistently outperforms all baselines, establishing a new benchmark for faithful explainability in recommendation. Code and evaluation tools are publicly available at https://github.com/DeltaLabTLV/SPINRec.",
        "url": "http://arxiv.org/abs/2511.18047v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18047v1",
        "arxiv_id": "2511.18047v1",
        "authors": [
            "Oren Barkan",
            "Yahlly Schein",
            "Yehonatan Elisha",
            "Veronika Bogina",
            "Mikhail Baklanov",
            "Noam Koenigstein"
        ],
        "submitted": "2025-11-22 12:59:04",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Paper2SysArch: Structure-Constrained System Architecture Generation from Scientific Papers",
        "abstract": "The manual creation of system architecture diagrams for scientific papers is a time-consuming and subjective process, while existing generative models lack the necessary structural control and semantic understanding for this task. A primary obstacle hindering research and development in this domain has been the profound lack of a standardized benchmark to quantitatively evaluate the automated generation of diagrams from text. To address this critical gap, we introduce a novel and comprehensive benchmark, the first of its kind, designed to catalyze progress in automated scientific visualization. It consists of 3,000 research papers paired with their corresponding high-quality ground-truth diagrams and is accompanied by a three-tiered evaluation metric assessing semantic accuracy, layout coherence, and visual quality. Furthermore, to establish a strong baseline on this new benchmark, we propose Paper2SysArch, an end-to-end system that leverages multi-agent collaboration to convert papers into structured, editable diagrams. To validate its performance on complex cases, the system was evaluated on a manually curated and more challenging subset of these papers, where it achieves a composite score of 69.0. This work's principal contribution is the establishment of a large-scale, foundational benchmark to enable reproducible research and fair comparison. Meanwhile, our proposed system serves as a viable proof-of-concept, demonstrating a promising path forward for this complex task.",
        "url": "http://arxiv.org/abs/2511.18036v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18036v1",
        "arxiv_id": "2511.18036v1",
        "authors": [
            "Ziyi Guo",
            "Zhou Liu",
            "Wentao Zhang"
        ],
        "submitted": "2025-11-22 12:24:30",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Extracting Interaction-Aware Monosemantic Concepts in Recommender Systems",
        "abstract": "We present a method for extracting \\emph{monosemantic} neurons, defined as latent dimensions that align with coherent and interpretable concepts, from user and item embeddings in recommender systems. Our approach employs a Sparse Autoencoder (SAE) to reveal semantic structure within pretrained representations. In contrast to work on language models, monosemanticity in recommendation must preserve the interactions between separate user and item embeddings. To achieve this, we introduce a \\emph{prediction aware} training objective that backpropagates through a frozen recommender and aligns the learned latent structure with the model's user-item affinity predictions. The resulting neurons capture properties such as genre, popularity, and temporal trends, and support post hoc control operations including targeted filtering and content promotion without modifying the base model. Our method generalizes across different recommendation models and datasets, providing a practical tool for interpretable and controllable personalization. Code and evaluation resources are available at https://github.com/DeltaLabTLV/Monosemanticity4Rec.",
        "url": "http://arxiv.org/abs/2511.18024v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18024v1",
        "arxiv_id": "2511.18024v1",
        "authors": [
            "Dor Arviv",
            "Yehonatan Elisha",
            "Oren Barkan",
            "Noam Koenigstein"
        ],
        "submitted": "2025-11-22 11:27:32",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Save, Revisit, Retain: A Scalable Framework for Enhancing User Retention in Large-Scale Recommender Systems",
        "abstract": "User retention is a critical objective for online platforms like Pinterest, as it strengthens user loyalty and drives growth through repeated engagement. A key indicator of retention is revisitation, i.e., when users return to view previously saved content, a behavior often sparked by personalized recommendations and user satisfaction. However, modeling and optimizing revisitation poses significant challenges. One core difficulty is accurate attribution: it is often unclear which specific user actions or content exposures trigger a revisit, since many confounding factors (e.g., content quality, user interface, notifications, or even changing user intent) can influence return behavior. Additionally, the scale and timing of revisitations introduce further complexity; users may revisit content days or even weeks after their initial interaction, requiring the system to maintain and associate extensive historical records across millions of users and sessions. These complexities render existing methods insufficient for robustly capturing and optimizing long-term revisitation. To address these gaps, we introduce a novel, lightweight, and interpretable framework for modeling revisitation behavior and optimizing long-term user retention in Pinterest's search-based recommendation context. By defining a surrogate attribution process that links saves to subsequent revisitations, we reduce noise in the causal relationship between user actions and return visits. Our scalable event aggregation pipeline enables large-scale analysis of user revisitation patterns and enhances the ranking system's ability to surface items with high retention value. Deployed on Pinterest's Related Pins surface to serve 500+ million users, the framework led to a significant lift of 0.1% in active users without additional computational costs.",
        "url": "http://arxiv.org/abs/2511.18013v1",
        "pdf_url": "https://arxiv.org/pdf/2511.18013v1",
        "arxiv_id": "2511.18013v1",
        "authors": [
            "Weijie Jiang",
            "Armando Ordorica",
            "Jaewon Yang",
            "Olafur Gudmundsson",
            "Yucheng Tu",
            "Huizhong Duan"
        ],
        "submitted": "2025-11-22 10:27:20",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "HyM-UNet: Synergizing Local Texture and Global Context via Hybrid CNN-Mamba Architecture for Medical Image Segmentation",
        "abstract": "Accurate organ and lesion segmentation is a critical prerequisite for computer-aided diagnosis. Convolutional Neural Networks (CNNs), constrained by their local receptive fields, often struggle to capture complex global anatomical structures. To tackle this challenge, this paper proposes a novel hybrid architecture, HyM-UNet, designed to synergize the local feature extraction capabilities of CNNs with the efficient global modeling capabilities of Mamba. Specifically, we design a Hierarchical Encoder that utilizes convolutional modules in the shallow stages to preserve high-frequency texture details, while introducing Visual Mamba modules in the deep stages to capture long-range semantic dependencies with linear complexity. To bridge the semantic gap between the encoder and the decoder, we propose a Mamba-Guided Fusion Skip Connection (MGF-Skip). This module leverages deep semantic features as gating signals to dynamically suppress background noise within shallow features, thereby enhancing the perception of ambiguous boundaries. We conduct extensive experiments on public benchmark dataset ISIC 2018. The results demonstrate that HyM-UNet significantly outperforms existing state-of-the-art methods in terms of Dice coefficient and IoU, while maintaining lower parameter counts and inference latency. This validates the effectiveness and robustness of the proposed method in handling medical segmentation tasks characterized by complex shapes and scale variations.",
        "url": "http://arxiv.org/abs/2511.17988v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17988v1",
        "arxiv_id": "2511.17988v1",
        "authors": [
            "Haodong Chen",
            "Xianfei Han",
            "Qwen"
        ],
        "submitted": "2025-11-22 09:02:06",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "MTikGuard System: A Transformer-Based Multimodal System for Child-Safe Content Moderation on TikTok",
        "abstract": "With the rapid rise of short-form videos, TikTok has become one of the most influential platforms among children and teenagers, but also a source of harmful content that can affect their perception and behavior. Such content, often subtle or deceptive, challenges traditional moderation methods due to the massive volume and real-time nature of uploads. This paper presents MTikGuard, a real-time multimodal harmful content detection system for TikTok, with three key contributions: (1) an extended TikHarm dataset expanded to 4,723 labeled videos by adding diverse real-world samples, (2) a multimodal classification framework integrating visual, audio, and textual features to achieve state-of-the-art performance with 89.37% accuracy and 89.45% F1-score, and (3) a scalable streaming architecture built on Apache Kafka and Apache Spark for real-time deployment. The results demonstrate the effectiveness of combining dataset expansion, advanced multimodal fusion, and robust deployment for practical large-scale social media content moderation. The dataset is available at https://github.com/ntdat-8324/MTikGuard-System.git.",
        "url": "http://arxiv.org/abs/2511.17955v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17955v1",
        "arxiv_id": "2511.17955v1",
        "authors": [
            "Dat Thanh Nguyen",
            "Nguyen Hung Lam",
            "Anh Hoang-Thi Nguyen",
            "Trong-Hop Do"
        ],
        "submitted": "2025-11-22 07:41:16",
        "source": "arxiv",
        "comment": "Accepted at PACLIC39"
    },
    {
        "title": "Leveraging Evidence-Guided LLMs to Enhance Trustworthy Depression Diagnosis",
        "abstract": "Large language models (LLMs) show promise in automating clinical diagnosis, yet their non-transparent decision-making and limited alignment with diagnostic standards hinder trust and clinical adoption. We address this challenge by proposing a two-stage diagnostic framework that enhances transparency, trustworthiness, and reliability. First, we introduce Evidence-Guided Diagnostic Reasoning (EGDR), which guides LLMs to generate structured diagnostic hypotheses by interleaving evidence extraction with logical reasoning grounded in DSM-5 criteria. Second, we propose a Diagnosis Confidence Scoring (DCS) module that evaluates the factual accuracy and logical consistency of generated diagnoses through two interpretable metrics: the Knowledge Attribution Score (KAS) and the Logic Consistency Score (LCS). Evaluated on the D4 dataset with pseudo-labels, EGDR outperforms direct in-context prompting and Chain-of-Thought (CoT) across five LLMs. For instance, on OpenBioLLM, EGDR improves accuracy from 0.31 (Direct) to 0.76 and increases DCS from 0.50 to 0.67. On MedLlama, DCS rises from 0.58 (CoT) to 0.77. Overall, EGDR yields up to +45% accuracy and +36% DCS gains over baseline methods, offering a clinically grounded, interpretable foundation for trustworthy AI-assisted diagnosis.",
        "url": "http://arxiv.org/abs/2511.17947v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17947v1",
        "arxiv_id": "2511.17947v1",
        "authors": [
            "Yining Yuan",
            "J. Ben Tamo",
            "Micky C. Nnamdi",
            "Yifei Wang",
            "May D. Wang"
        ],
        "submitted": "2025-11-22 07:08:23",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Measuring the Impact of Lexical Training Data Coverage on Hallucination Detection in Large Language Models",
        "abstract": "Hallucination in large language models (LLMs) is a fundamental challenge, particularly in open-domain question answering. Prior work attempts to detect hallucination with model-internal signals such as token-level entropy or generation consistency, while the connection between pretraining data exposure and hallucination is underexplored. Existing studies show that LLMs underperform on long-tail knowledge, i.e., the accuracy of the generated answer drops for the ground-truth entities that are rare in pretraining. However, examining whether data coverage itself can serve as a detection signal is overlooked. We propose a complementary question: Does lexical training-data coverage of the question and/or generated answer provide additional signal for hallucination detection? To investigate this, we construct scalable suffix arrays over RedPajama's 1.3-trillion-token pretraining corpus to retrieve $n$-gram statistics for both prompts and model generations. We evaluate their effectiveness for hallucination detection across three QA benchmarks. Our observations show that while occurrence-based features are weak predictors when used alone, they yield modest gains when combined with log-probabilities, particularly on datasets with higher intrinsic model uncertainty. These findings suggest that lexical coverage features provide a complementary signal for hallucination detection. All code and suffix-array infrastructure are provided at https://github.com/WWWonderer/ostd.",
        "url": "http://arxiv.org/abs/2511.17946v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17946v1",
        "arxiv_id": "2511.17946v1",
        "authors": [
            "Shuo Zhang",
            "Fabrizio Gotti",
            "Fengran Mo",
            "Jian-Yun Nie"
        ],
        "submitted": "2025-11-22 06:59:55",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "SPINE: Token-Selective Test-Time Reinforcement Learning with Entropy-Band Regularization",
        "abstract": "Large language models (LLMs) and multimodal LLMs (MLLMs) excel at chain-of-thought reasoning but face distribution shift at test-time and a lack of verifiable supervision. Recent test-time reinforcement learning (TTRL) methods derive label-free pseudo-rewards from self-consistency voting over sampled trajectories, yet they often collapse: the majority-vote reward prevails, responses shorten, and Pass@1 declines. We trace this to uniform sequence updates in which most tokens are low-entropy followers, while a small high-entropy subset determines the reasoning branches. Thus we propose SPINE, a token-selective test-time reinforcement learning framework that (i) updates only forking tokens, the high-entropy branch points identified from forward-pass statistics, and (ii) applies an entropy-band regularizer at those tokens to sustain exploration when entropy is too low and to suppress noisy supervision when it is too high. SPINE plugs into GRPO-style objectives, optionally with a KL anchor, and requires no labels or reward models. Across ten benchmarks spanning multimodal VQA, general and expert QA, mathematical reasoning, and medical QA, SPINE consistently improves Pass@1 over TTRL while avoiding response-length collapse and yielding more stable training dynamics on both LLM and MLLM backbones. These results indicate that aligning updates with chain-of-thought branch points is a simple and label-free mechanism for stable and effective test-time adaptation in reasoning models. Code is available at https://github.com/JianghaoWu/SPINE.",
        "url": "http://arxiv.org/abs/2511.17938v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17938v1",
        "arxiv_id": "2511.17938v1",
        "authors": [
            "Jianghao Wu",
            "Yasmeen George",
            "Jin Ye",
            "Yicheng Wu",
            "Daniel F. Schmidt",
            "Jianfei Cai"
        ],
        "submitted": "2025-11-22 06:32:34",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Towards Efficient LLM-aware Heterogeneous Graph Learning",
        "abstract": "Heterogeneous graphs are widely present in real-world complex networks, where the diversity of node and relation types leads to complex and rich semantics. Efforts for modeling complex relation semantics in heterogeneous graphs are restricted by the limitations of predefined semantic dependencies and the scarcity of supervised signals. The advanced pre-training and fine-tuning paradigm leverages graph structure to provide rich self-supervised signals, but introduces semantic gaps between tasks. Large Language Models (LLMs) offer significant potential to address the semantic issues of relations and tasks in heterogeneous graphs through their strong reasoning capabilities in textual modality, but their incorporation into heterogeneous graphs is largely limited by computational complexity. Therefore, in this paper, we propose an Efficient LLM-Aware (ELLA) framework for heterogeneous graphs, addressing the above issues. To capture complex relation semantics, we propose an LLM-aware Relation Tokenizer that leverages LLM to encode multi-hop, multi-type relations. To reduce computational complexity, we further employ a Hop-level Relation Graph Transformer, which help reduces the complexity of LLM-aware relation reasoning from exponential to linear. To bridge semantic gaps between pre-training and fine-tuning tasks, we introduce the fine-grained task-aware textual Chain-of-Thought (CoT) prompts. Extensive experiments on four heterogeneous graphs show that our proposed ELLA outperforms state-of-the-art methods in the performance and efficiency. In particular, ELLA scales up to 13b-parameter LLMs and achieves up to a 4x speedup compared with existing LLM-based methods. Our code is publicly available at https://github.com/l-wd/ELLA.",
        "url": "http://arxiv.org/abs/2511.17923v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17923v1",
        "arxiv_id": "2511.17923v1",
        "authors": [
            "Wenda Li",
            "Tongya Zheng",
            "Shunyu Liu",
            "Yu Wang",
            "Kaixuan Chen",
            "Hanyang Yuan",
            "Bingde Hu",
            "Zujie Ren",
            "Mingli Song",
            "Gang Chen"
        ],
        "submitted": "2025-11-22 05:38:03",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Token-Controlled Re-ranking for Sequential Recommendation via LLMs",
        "abstract": "The widespread adoption of Large Language Models (LLMs) as re-rankers is shifting recommender systems towards a user-centric paradigm. However, a significant gap remains: current re-rankers often lack mechanisms for fine-grained user control. They struggle to balance inherent user preferences with multiple attribute-based constraints, often resorting to simplistic hard filtering that can excessively narrow the recommendation pool and yield suboptimal results. This limitation leaves users as passive recipients rather than active collaborators in the recommendation process. To bridge this gap, we propose COREC, a novel token-augmented re-ranking framework that incorporates specific user requirements in co-creating the recommendation outcome. COREC empowers users to steer re-ranking results with precise and flexible control via explicit, attribute-based signals. The framework learns to balance these commands against latent preferences, yielding rankings that adhere to user instructions without sacrificing personalization. Experiments show that COREC: (1) exceeds state-of-the-art baselines on standard recommendation effectiveness and (2) demonstrates superior adherence to specific attribute requirements, proving that COREC enables fine-grained and predictable manipulation of the rankings.",
        "url": "http://arxiv.org/abs/2511.17913v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17913v1",
        "arxiv_id": "2511.17913v1",
        "authors": [
            "Wenxi Dai",
            "Wujiang Xu",
            "Pinhuan Wang",
            "Dimitris N. Metaxas"
        ],
        "submitted": "2025-11-22 04:31:19",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "L2V-CoT: Cross-Modal Transfer of Chain-of-Thought Reasoning via Latent Intervention",
        "abstract": "Recently, Chain-of-Thought (CoT) reasoning has significantly enhanced the capabilities of large language models (LLMs), but Vision-Language Models (VLMs) still struggle with multi-step reasoning tasks due to limited multimodal reasoning data. To bridge this gap, researchers have explored methods to transfer CoT reasoning from LLMs to VLMs. However, existing approaches either need high training costs or require architectural alignment. In this paper, we use Linear Artificial Tomography (LAT) to empirically show that LLMs and VLMs share similar low-frequency latent representations of CoT reasoning despite architectural differences. Based on this insight, we propose L2V-CoT, a novel training-free latent intervention approach that transfers CoT reasoning from LLMs to VLMs. L2V-CoT extracts and resamples low-frequency CoT representations from LLMs in the frequency domain, enabling dimension matching and latent injection into VLMs during inference to enhance reasoning capabilities. Extensive experiments demonstrate that our approach consistently outperforms training-free baselines and even surpasses supervised methods.",
        "url": "http://arxiv.org/abs/2511.17910v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17910v1",
        "arxiv_id": "2511.17910v1",
        "authors": [
            "Yuliang Zhan",
            "Xinyu Tang",
            "Han Wan",
            "Jian Li",
            "Ji-Rong Wen",
            "Hao Sun"
        ],
        "submitted": "2025-11-22 04:25:25",
        "source": "arxiv",
        "comment": "AAAI 2026 oral"
    },
    {
        "title": "Principled Context Engineering for RAG: Statistical Guarantees via Conformal Prediction",
        "abstract": "Retrieval-Augmented Generation (RAG) enhances factual grounding in large language models (LLMs) by incorporating retrieved evidence, but LLM accuracy declines when long or noisy contexts exceed the model's effective attention span. Existing pre-generation filters rely on heuristics or uncalibrated LLM confidence scores, offering no statistical control over retained evidence. We evaluate and demonstrate context engineering through conformal prediction, a coverage-controlled filtering framework that removes irrelevant content while preserving recall of supporting evidence. Using both embedding- and LLM-based scoring functions, we test this approach on the NeuCLIR and RAGTIME collections. Conformal filtering consistently meets its target coverage, ensuring that a specified fraction of relevant snippets are retained, and reduces retained context by 2-3x relative to unfiltered retrieval. On NeuCLIR, downstream factual accuracy measured by ARGUE F1 improves under strict filtering and remains stable at moderate coverage, indicating that most discarded material is redundant or irrelevant. These results demonstrate that conformal prediction enables reliable, coverage-controlled context reduction in RAG, offering a model-agnostic and principled approach to context engineering.",
        "url": "http://arxiv.org/abs/2511.17908v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17908v1",
        "arxiv_id": "2511.17908v1",
        "authors": [
            "Debashish Chakraborty",
            "Eugene Yang",
            "Daniel Khashabi",
            "Dawn Lawrie",
            "Kevin Duh"
        ],
        "submitted": "2025-11-22 04:17:06",
        "source": "arxiv",
        "comment": "Preprint"
    },
    {
        "title": "When Better Teachers Don't Make Better Students: Revisiting Knowledge Distillation for CLIP Models in VQA",
        "abstract": "Vision-language models (VLMs) have achieved remarkable success across multimodal tasks, yet their substantial computational demands hinder efficient deployment. Knowledge distillation (KD) has emerged as a powerful approach for building lightweight but competitive models, with strong evidence from both language and vision domains. However, its application to VLMs, particularly CLIP-style models, remains limited, often constrained to small-scale teachers and narrow evaluation tasks such as classification or retrieval. In this work, we present the first systematic study of distillation across a range of CLIP-style teacher models, ranging from standard baselines to large-scale state-of-the-art models. Contrary to trends observed in NLP and vision, we find that stronger teachers do not consistently yield better students; in fact, existing distillation frameworks often fail to scale, leading to degraded performance in downstream multimodal tasks such as visual question answering. Our findings challenge prevailing assumptions in KD and point toward new directions for designing parameter-efficient multimodal models.",
        "url": "http://arxiv.org/abs/2511.17886v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17886v1",
        "arxiv_id": "2511.17886v1",
        "authors": [
            "Pume Tuchinda",
            "Parinthapat Pengpun",
            "Romrawin Chumpu",
            "Sarana Nutanong",
            "Peerat Limkonchotiwat"
        ],
        "submitted": "2025-11-22 02:30:18",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "A superpersuasive autonomous policy debating system",
        "abstract": "The capacity for highly complex, evidence-based, and strategically adaptive persuasion remains a formidable great challenge for artificial intelligence. Previous work, like IBM Project Debater, focused on generating persuasive speeches in simplified and shortened debate formats intended for relatively lay audiences. We introduce DeepDebater, a novel autonomous system capable of participating in and winning a full, unmodified, two-team competitive policy debate. Our system employs a hierarchical architecture of specialized multi-agent workflows, where teams of LLM-powered agents collaborate and critique one another to perform discrete argumentative tasks. Each workflow utilizes iterative retrieval, synthesis, and self-correction using a massive corpus of policy debate evidence (OpenDebateEvidence) and produces complete speech transcripts, cross-examinations, and rebuttals. We introduce a live, interactive end-to-end presentation pipeline that renders debates with AI speech and animation: transcripts are surface-realized and synthesized to audio with OpenAI TTS, and then displayed as talking-head portrait videos with EchoMimic V1. Beyond fully autonomous matches (AI vs AI), DeepDebater supports hybrid human-AI operation: human debaters can intervene at any stage, and humans can optionally serve as opponents against AI in any speech, allowing AI-human and AI-AI rounds. In preliminary evaluations against human-authored cases, DeepDebater produces qualitatively superior argumentative components and consistently wins simulated rounds as adjudicated by an independent autonomous judge. Expert human debate coaches also prefer the arguments, evidence, and cases constructed by DeepDebater. We open source all code, generated speech transcripts, audio and talking head video here: https://github.com/Hellisotherpeople/DeepDebater/tree/main",
        "url": "http://arxiv.org/abs/2511.17854v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17854v1",
        "arxiv_id": "2511.17854v1",
        "authors": [
            "Allen Roush",
            "Devin Gonier",
            "John Hines",
            "Judah Goldfeder",
            "Philippe Martin Wyder",
            "Sanjay Basu",
            "Ravid Shwartz Ziv"
        ],
        "submitted": "2025-11-22 00:45:01",
        "source": "arxiv",
        "comment": "Accepted to CLIP workshop at AAAI 2026"
    },
    {
        "title": "Deterministic Inference across Tensor Parallel Sizes That Eliminates Training-Inference Mismatch",
        "abstract": "Deterministic inference is increasingly critical for large language model (LLM) applications such as LLM-as-a-judge evaluation, multi-agent systems, and Reinforcement Learning (RL). However, existing LLM serving frameworks exhibit non-deterministic behavior: identical inputs can yield different outputs when system configurations (e.g., tensor parallel (TP) size, batch size) vary, even under greedy decoding. This arises from the non-associativity of floating-point arithmetic and inconsistent reduction orders across GPUs. While prior work has addressed batch-size-related nondeterminism through batch-invariant kernels, determinism across different TP sizes remains an open problem, particularly in RL settings, where the training engine typically uses Fully Sharded Data Parallel (i.e., TP = 1) while the rollout engine relies on multi-GPU TP to maximize the inference throughput, creating a natural mismatch between the two. This precision mismatch problem may lead to suboptimal performance or even collapse for RL training. We identify and analyze the root causes of TP-induced inconsistency and propose Tree-Based Invariant Kernels (TBIK), a set of TP-invariant matrix multiplication and reduction primitives that guarantee bit-wise identical results regardless of TP size. Our key insight is to align intra- and inter-GPU reduction orders through a unified hierarchical binary tree structure. We implement these kernels in Triton and integrate them into vLLM and FSDP. Experiments confirm zero probability divergence and bit-wise reproducibility for deterministic inference across different TP sizes. Also, we achieve bit-wise identical results between vLLM and FSDP in RL training pipelines with different parallel strategy. Code is available at https://github.com/nanomaoli/llm_reproducibility.",
        "url": "http://arxiv.org/abs/2511.17826v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17826v1",
        "arxiv_id": "2511.17826v1",
        "authors": [
            "Ziyang Zhang",
            "Xinheng Ding",
            "Jiayi Yuan",
            "Rixin Liu",
            "Huizi Mao",
            "Jiarong Xing",
            "Zirui Liu"
        ],
        "submitted": "2025-11-21 22:40:00",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Point of Order: Action-Aware LLM Persona Modeling for Realistic Civic Simulation",
        "abstract": "Large language models offer opportunities to simulate multi-party deliberation, but realistic modeling remains limited by a lack of speaker-attributed data. Transcripts produced via automatic speech recognition (ASR) assign anonymous speaker labels (e.g., Speaker_1), preventing models from capturing consistent human behavior. This work introduces a reproducible pipeline to transform public Zoom recordings into speaker-attributed transcripts with metadata like persona profiles and pragmatic action tags (e.g., [propose_motion]). We release three local government deliberation datasets: Appellate Court hearings, School Board meetings, and Municipal Council sessions. Fine-tuning LLMs to model specific participants using this \"action-aware\" data produces a 67% reduction in perplexity and nearly doubles classifier-based performance metrics for speaker fidelity and realism. Turing-style human evaluations show our simulations are often indistinguishable from real deliberations, providing a practical and scalable method for complex realistic civic simulations.",
        "url": "http://arxiv.org/abs/2511.17813v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17813v1",
        "arxiv_id": "2511.17813v1",
        "authors": [
            "Scott Merrill",
            "Shashank Srivastava"
        ],
        "submitted": "2025-11-21 22:07:33",
        "source": "arxiv",
        "comment": "8 pages (29 pages including appendix), 18 figures. Code and datasets are available at https://github.com/smerrillunc/action-aware-llms. Submitted to ACL 2026"
    },
    {
        "title": "PoETa v2: Toward More Robust Evaluation of Large Language Models in Portuguese",
        "abstract": "Large Language Models (LLMs) exhibit significant variations in performance across linguistic and cultural contexts, underscoring the need for systematic evaluation in diverse languages. In this work, we present the most extensive evaluation of LLMs for the Portuguese language to date. Leveraging our newly introduced PoETa v2 benchmark -- a comprehensive suite of over 40 tasks in Portuguese -- we assess more than 20 models covering a broad spectrum of training scales and computational resources. Our study reveals how computational investment and language-specific adaptation impact performance in Portuguese, while also analyzing performance gaps in comparison to equivalent tasks in English. Through this benchmark and analysis, PoETa v2 lays the groundwork for future research on Portuguese language modeling and evaluation. The benchmark is available at https://github.com/PoETaV2/PoETaV2.",
        "url": "http://arxiv.org/abs/2511.17808v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17808v1",
        "arxiv_id": "2511.17808v1",
        "authors": [
            "Thales Sales Almeida",
            "Rodrigo Nogueira",
            "Hélio Pedrini"
        ],
        "submitted": "2025-11-21 22:01:51",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Computational frame analysis revisited: On LLMs for studying news coverage",
        "abstract": "Computational approaches have previously shown various promises and pitfalls when it comes to the reliable identification of media frames. Generative LLMs like GPT and Claude are increasingly being used as content analytical tools, but how effective are they for frame analysis? We address this question by systematically evaluating them against their computational predecessors: bag-of-words models and encoder-only transformers; and traditional manual coding procedures. Our analysis rests on a novel gold standard dataset that we inductively and iteratively developed through the study, investigating six months of news coverage of the US Mpox epidemic of 2022. While we discover some potential applications for generative LLMs, we demonstrate that they were consistently outperformed by manual coders, and in some instances, by smaller language models. Some form of human validation was always necessary to determine appropriate model choice. Additionally, by examining how the suitability of various approaches depended on the nature of different tasks that were part of our frame analytical workflow, we provide insights as to how researchers may leverage the complementarity of these approaches to use them in tandem. We conclude by endorsing a methodologically pluralistic approach and put forth a roadmap for computational frame analysis for researchers going forward.",
        "url": "http://arxiv.org/abs/2511.17746v1",
        "pdf_url": "https://arxiv.org/pdf/2511.17746v1",
        "arxiv_id": "2511.17746v1",
        "authors": [
            "Sharaj Kunjar",
            "Alyssa Hasegawa Smith",
            "Tyler R Mckenzie",
            "Rushali Mohbe",
            "Samuel V Scarpino",
            "Brooke Foucault Welles"
        ],
        "submitted": "2025-11-21 19:52:46",
        "source": "arxiv",
        "comment": null
    }
]