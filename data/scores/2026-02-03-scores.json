[
    {
        "title": "RANKVIDEO: Reasoning Reranking for Text-to-Video Retrieval",
        "abstract": "Reranking is a critical component of modern retrieval systems, which typically pair an efficient first-stage retriever with a more expressive model to refine results. While large reasoning models have driven rapid progress in text-centric reranking, reasoning-based reranking for video retrieval remains underexplored. To address this gap, we introduce RANKVIDEO, a reasoning-based reranker for video retrieval that explicitly reasons over query-video pairs using video content to assess relevance. RANKVIDEO is trained using a two-stage curriculum consisting of perception-grounded supervised fine-tuning followed by reranking training that combines pointwise, pairwise, and teacher confidence distillation objectives, and is supported by a data synthesis pipeline for constructing reasoning-intensive query-video pairs. Experiments on the large-scale MultiVENT 2.0 benchmark demonstrate that RANKVIDEO consistently improves retrieval performance within a two-stage framework, yielding an average improvement of 31% on nDCG@10 and outperforming text-only and vision-language reranking alternatives, while more efficient.",
        "url": "http://arxiv.org/abs/2602.02444v2",
        "pdf_url": "https://arxiv.org/pdf/2602.02444v2",
        "arxiv_id": "2602.02444v2",
        "authors": [
            "Tyler Skow",
            "Alexander Martin",
            "Benjamin Van Durme",
            "Rama Chellappa",
            "Reno Kriz"
        ],
        "submitted": "2026-02-02 18:40:37",
        "source": "arxiv",
        "comment": null,
        "score": 26,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'pointwise' (score: +3)",
            "Found 'pairwise' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper on RANKVIDEO, a reasoning-based reranker for video retrieval, is highly relevant to your interests in Information Retrieval, particularly in the context of query understanding and ranking models. Although it focuses on video retrieval, the use of reasoning and reranking techniques aligns with your expertise in Learning to Rank and click models. The paper's emphasis on real-time relevance optimization also resonates with your interests."
    },
    {
        "title": "Misconception Diagnosis From Student-Tutor Dialogue: Generate, Retrieve, Rerank",
        "abstract": "Timely and accurate identification of student misconceptions is key to improving learning outcomes and pre-empting the compounding of student errors. However, this task is highly dependent on the effort and intuition of the teacher. In this work, we present a novel approach for detecting misconceptions from student-tutor dialogues using large language models (LLMs). First, we use a fine-tuned LLM to generate plausible misconceptions, and then retrieve the most promising candidates among these using embedding similarity with the input dialogue. These candidates are then assessed and re-ranked by another fine-tuned LLM to improve misconception relevance. Empirically, we evaluate our system on real dialogues from an educational tutoring platform. We consider multiple base LLM models including LLaMA, Qwen and Claude on zero-shot and fine-tuned settings. We find that our approach improves predictive performance over baseline models and that fine-tuning improves both generated misconception quality and can outperform larger closed-source models. Finally, we conduct ablation studies to both validate the importance of our generation and reranking steps on misconception generation quality.",
        "url": "http://arxiv.org/abs/2602.02414v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02414v1",
        "arxiv_id": "2602.02414v1",
        "authors": [
            "Joshua Mitton",
            "Prarthana Bhattacharyya",
            "Digory Smith",
            "Thomas Christie",
            "Ralph Abboud",
            "Simon Woodhead"
        ],
        "submitted": "2026-02-02 18:14:35",
        "source": "arxiv",
        "comment": "21 pages, 8 figures, 8 tables. Joshua Mitton and Prarthana Bhattacharyya contributed equally to this paper",
        "score": 10,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on misconception diagnosis from student-tutor dialogue, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves large language models and retrieval, the context and application are significantly different from the user's interests."
    },
    {
        "title": "Graph-Augmented Reasoning with Large Language Models for Tobacco Pest and Disease Management",
        "abstract": "This paper proposes a graph-augmented reasoning framework for tobacco pest and disease management that integrates structured domain knowledge into large language models. Building on GraphRAG, we construct a domain-specific knowledge graph and retrieve query-relevant subgraphs to provide relational evidence during answer generation. The framework adopts ChatGLM as the Transformer backbone with LoRA-based parameter-efficient fine-tuning, and employs a graph neural network to learn node representations that capture symptom-disease-treatment dependencies. By explicitly modeling diseases, symptoms, pesticides, and control measures as linked entities, the system supports evidence-aware retrieval beyond surface-level text similarity. Retrieved graph evidence is incorporated into the LLM input to guide generation toward domain-consistent recommendations and to mitigate hallucinated or inappropriate treatments. Experimental results show consistent improvements over text-only baselines, with the largest gains observed on multi-hop and comparative reasoning questions that require chaining multiple relations.",
        "url": "http://arxiv.org/abs/2602.02635v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02635v1",
        "arxiv_id": "2602.02635v1",
        "authors": [
            "Siyu Li",
            "Chenwei Song",
            "Qi Zhou",
            "Wan Zhou",
            "Xinyi Liu"
        ],
        "submitted": "2026-02-02 18:29:52",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your core research themes in Information Retrieval and Search technologies, as it focuses on a specific domain (tobacco pest and disease management) and employs a graph-augmented reasoning framework with large language models, which is not directly related to your interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "ROG: Retrieval-Augmented LLM Reasoning for Complex First-Order Queries over Knowledge Graphs",
        "abstract": "Answering first-order logic (FOL) queries over incomplete knowledge graphs (KGs) is difficult, especially for complex query structures that compose projection, intersection, union, and negation. We propose ROG, a retrieval-augmented framework that combines query-aware neighborhood retrieval with large language model (LLM) chain-of-thought reasoning. ROG decomposes a multi-operator query into a sequence of single-operator sub-queries and grounds each step in compact, query-relevant neighborhood evidence. Intermediate answer sets are cached and reused across steps, improving consistency on deep reasoning chains. This design reduces compounding errors and yields more robust inference on complex and negation-heavy queries. Overall, ROG provides a practical alternative to embedding-based logical reasoning by replacing learned operators with retrieval-grounded, step-wise inference. Experiments on standard KG reasoning benchmarks show consistent gains over strong embedding-based baselines, with the largest improvements on high-complexity and negation-heavy query types.",
        "url": "http://arxiv.org/abs/2602.02382v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02382v1",
        "arxiv_id": "2602.02382v1",
        "authors": [
            "Ziyan Zhang",
            "Chao Wang",
            "Zhuo Chen",
            "Chiyi Li",
            "Kai Song"
        ],
        "submitted": "2026-02-02 17:45:43",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The use of retrieval-augmented framework and large language model chain-of-thought reasoning aligns with your focus on deep semantic understanding and real-time relevance optimization. However, the specific application to knowledge graphs and first-order logic queries is somewhat outside your primary e-commerce domain interest."
    },
    {
        "title": "Beyond RAG for Agent Memory: Retrieval by Decoupling and Aggregation",
        "abstract": "Agent memory systems often adopt the standard Retrieval-Augmented Generation (RAG) pipeline, yet its underlying assumptions differ in this setting. RAG targets large, heterogeneous corpora where retrieved passages are diverse, whereas agent memory is a bounded, coherent dialogue stream with highly correlated spans that are often duplicates. Under this shift, fixed top-$k$ similarity retrieval tends to return redundant context, and post-hoc pruning can delete temporally linked prerequisites needed for correct reasoning. We argue retrieval should move beyond similarity matching and instead operate over latent components, following decoupling to aggregation: disentangle memories into semantic components, organise them into a hierarchy, and use this structure to drive retrieval. We propose xMemory, which builds a hierarchy of intact units and maintains a searchable yet faithful high-level node organisation via a sparsity--semantics objective that guides memory split and merge. At inference, xMemory retrieves top-down, selecting a compact, diverse set of themes and semantics for multi-fact queries, and expanding to episodes and raw messages only when it reduces the reader's uncertainty. Experiments on LoCoMo and PerLTQA across the three latest LLMs show consistent gains in answer quality and token efficiency.",
        "url": "http://arxiv.org/abs/2602.02007v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02007v1",
        "arxiv_id": "2602.02007v1",
        "authors": [
            "Zhanghao Hu",
            "Qinglin Zhu",
            "Hanqi Yan",
            "Yulan He",
            "Lin Gui"
        ],
        "submitted": "2026-02-02 12:04:58",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses a novel approach to agent memory systems, proposing a method called xMemory that decouples and aggregates memories into semantic components. While it touches on retrieval and ranking, the focus is more on the organizational structure of memories rather than query understanding or ranking models. The paper's relevance to information retrieval and search technologies is somewhat related, but not a central match."
    },
    {
        "title": "Cross-Lingual Stability of LLM Judges Under Controlled Generation: Evidence from Finno-Ugric Languages",
        "abstract": "Cross-lingual evaluation of large language models (LLMs) typically conflates two sources of variance: genuine model performance differences and measurement instability. We investigate evaluation reliability by holding generation conditions constant while varying target language. Using synthetic customer-support dialogues generated with identical parameters across Estonian, Finnish, and Hungarian, we test whether automatic metrics and LLM-as-a-judge scoring produce stable model rankings across these morphologically rich, related Finno-Ugric languages. With a small set of Estonian native speaker annotations as a reference point, we find systematic ranking instabilities: surface-level metrics (lexical diversity, surface and semantic similarity) maintain cross-language stability, but pragmatic judgments (coherence, instruction-following) exhibit rank inversions and near-zero correlations. Because generation is controlled, these inconsistencies reflect how judge scoring behaves differently across languages rather than true model differences.\n  This controlled design provides a diagnostic probe: evaluation methods that fail to maintain stability under identical generation conditions signal transfer failure before deployment. Our findings suggest that zero-shot judge transfer is unreliable for discourse-level assessment in morphologically rich languages, motivating language-specific calibration against targeted human baselines. We release our controlled generation protocol, synthetic data, and evaluation framework to enable replication across language families at https://github.com/isaac-chung/cross-lingual-stability-judges.",
        "url": "http://arxiv.org/abs/2602.02287v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02287v1",
        "arxiv_id": "2602.02287v1",
        "authors": [
            "Isaac Chung",
            "Linda Freienthal"
        ],
        "submitted": "2026-02-02 16:27:32",
        "source": "arxiv",
        "comment": "First Workshop on Multilingual Multicultural Evaluation, co-located with EACL 2026",
        "score": 6,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on cross-lingual evaluation of large language models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on aspects of language understanding, the context is more aligned with NLP and machine learning, rather than your specific areas of focus."
    },
    {
        "title": "Am I More Pointwise or Pairwise? Revealing Position Bias in Rubric-Based LLM-as-a-Judge",
        "abstract": "Large language models (LLMs) are now widely used to evaluate the quality of text, a field commonly referred to as LLM-as-a-judge. While prior works mainly focus on point-wise and pair-wise evaluation paradigms. Rubric-based evaluation, where LLMs select a score from multiple rubrics, has received less analysis. In this work, we show that rubric-based evaluation implicitly resembles a multi-choice setting and therefore has position bias: LLMs prefer score options appearing at specific positions in the rubric list. Through controlled experiments across multiple models and datasets, we demonstrate consistent position bias. To mitigate this bias, we propose a balanced permutation strategy that evenly distributes each score option across positions. We show that aggregating scores across balanced permutations not only reveals latent position bias, but also improves correlation between the LLM-as-a-Judge and human. Our results suggest that rubric-based LLM-as-a-Judge is not inherently point-wise and that simple permutation-based calibration can substantially improve its reliability.",
        "url": "http://arxiv.org/abs/2602.02219v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02219v1",
        "arxiv_id": "2602.02219v1",
        "authors": [
            "Yuzheng Xu",
            "Tosho Hirasawa",
            "Tadashi Kozuno",
            "Yoshitaka Ushiku"
        ],
        "submitted": "2026-02-02 15:24:37",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'pointwise' (score: +3)",
            "Found 'pairwise' (score: +3)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper explores position bias in rubric-based evaluation of large language models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on LLM-as-a-judge and rubric-based evaluation is not a central match to the user's core research themes. The paper's findings on position bias and calibration may be of interest to researchers in related areas, but it does not directly address the user's primary interests in IR and NLP."
    },
    {
        "title": "Reward-free Alignment for Conflicting Objectives",
        "abstract": "Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.",
        "url": "http://arxiv.org/abs/2602.02495v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02495v1",
        "arxiv_id": "2602.02495v1",
        "authors": [
            "Peter Chen",
            "Xiaopeng Li",
            "Xi Chen",
            "Tianyi Lin"
        ],
        "submitted": "2026-02-02 18:59:52",
        "source": "arxiv",
        "comment": "27 pages",
        "score": 5,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 3,
        "llm_reason": "This paper is loosely relevant to your research interests in Information Retrieval and Natural Language Processing, as it deals with large language models and alignment with human preferences. However, the focus on multi-objective alignment and conflict resolution in the context of LLMs does not directly align with your primary interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Rethinking Generative Recommender Tokenizer: Recsys-Native Encoding and Semantic Quantization Beyond LLMs",
        "abstract": "Semantic ID (SID)-based recommendation is a promising paradigm for scaling sequential recommender systems, but existing methods largely follow a semantic-centric pipeline: item embeddings are learned from foundation models and discretized using generic quantization schemes. This design is misaligned with generative recommendation objectives: semantic embeddings are weakly coupled with collaborative prediction, and generic quantization is inefficient at reducing sequential uncertainty for autoregressive modeling. To address these, we propose ReSID, a recommendation-native, principled SID framework that rethinks representation learning and quantization from the perspective of information preservation and sequential predictability, without relying on LLMs. ReSID consists of two components: (i) Field-Aware Masked Auto-Encoding (FAMAE), which learns predictive-sufficient item representations from structured features, and (ii) Globally Aligned Orthogonal Quantization (GAOQ), which produces compact and predictable SID sequences by jointly reducing semantic ambiguity and prefix-conditional uncertainty. Theoretical analysis and extensive experiments across ten datasets show the effectiveness of ReSID. ReSID consistently outperforms strong sequential and SID-based generative baselines by an average of over 10%, while reducing tokenization cost by up to 122x. Code is available at https://github.com/FuCongResearchSquad/ReSID.",
        "url": "http://arxiv.org/abs/2602.02338v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02338v1",
        "arxiv_id": "2602.02338v1",
        "authors": [
            "Yu Liang",
            "Zhongjin Zhang",
            "Yuxuan Zhu",
            "Kerui Zhang",
            "Zhiluohan Guo",
            "Wenhang Zhou",
            "Zonqi Yang",
            "Kangle Wu",
            "Yabo Ni",
            "Anxiang Zeng",
            "Cong Fu",
            "Jianxin Wang",
            "Jiazhi Xia"
        ],
        "submitted": "2026-02-02 17:00:04",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)",
            "Found 'recsys' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores recommender systems and proposes a new framework called ReSID, which focuses on semantic ID-based recommendations. While it touches on aspects of information retrieval, such as representation learning and quantization, its primary focus is on recommender systems rather than information retrieval or query understanding. The paper's relevance to the user's interests is somewhat related but not a central match."
    },
    {
        "title": "dziribot: rag based intelligent conversational agent for algerian arabic dialect",
        "abstract": "The rapid digitalization of customer service has intensified the demand for conversational agents capable of providing accurate and natural interactions. In the Algerian context, this is complicated by the linguistic complexity of Darja, a dialect characterized by non-standardized orthography, extensive code-switching with French, and the simultaneous use of Arabic and Latin (Arabizi) scripts. This paper introduces DziriBOT, a hybrid intelligent conversational agent specifically engineered to overcome these challenges. We propose a multi-layered architecture that integrates specialized Natural Language Understanding (NLU) with Retrieval-Augmented Generation (RAG), allowing for both structured service flows and dynamic, knowledge-intensive responses grounded in curated enterprise documentation. To address the low-resource nature of Darja, we systematically evaluate three distinct approaches: a sparse-feature Rasa pipeline, classical machine learning baselines, and transformer-based fine-tuning. Our experimental results demonstrate that the fine-tuned DziriBERT model achieves state-of-the-art performance. These results significantly outperform traditional baselines, particularly in handling orthographic noise and rare intents. Ultimately, DziriBOT provides a robust, scalable solution that bridges the gap between formal language models and the linguistic realities of Algerian users, offering a blueprint for dialect-aware automation in the regional market.",
        "url": "http://arxiv.org/abs/2602.02270v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02270v1",
        "arxiv_id": "2602.02270v1",
        "authors": [
            "El Batoul Bechiri",
            "Dihia Lanasri"
        ],
        "submitted": "2026-02-02 16:11:32",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and conversational agents, but it focuses on a specific dialect and application in the Algerian market. While it involves Retrieval-Augmented Generation (RAG), which is a relevant technique, the paper's primary focus is on dialect-aware automation rather than information retrieval or query understanding."
    },
    {
        "title": "Towards AI Evaluation in Domain-Specific RAG Systems: The AgriHubi Case Study",
        "abstract": "Large language models show promise for knowledge-intensive domains, yet their use in agriculture is constrained by weak grounding, English-centric training data, and limited real-world evaluation. These issues are amplified for low-resource languages, where high-quality domain documentation exists but remains difficult to access through general-purpose models. This paper presents AgriHubi, a domain-adapted retrieval-augmented generation (RAG) system for Finnish-language agricultural decision support. AgriHubi integrates Finnish agricultural documents with open PORO family models and combines explicit source grounding with user feedback to support iterative refinement. Developed over eight iterations and evaluated through two user studies, the system shows clear gains in answer completeness, linguistic accuracy, and perceived reliability. The results also reveal practical trade-offs between response quality and latency when deploying larger models. This study provides empirical guidance for designing and evaluating domain-specific RAG systems in low-resource language settings.",
        "url": "http://arxiv.org/abs/2602.02208v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02208v1",
        "arxiv_id": "2602.02208v1",
        "authors": [
            "Md. Toufique Hasan",
            "Ayman Asad Khan",
            "Mika Saari",
            "Vaishnavi Bankhele",
            "Pekka Abrahamsson"
        ],
        "submitted": "2026-02-02 15:15:24",
        "source": "arxiv",
        "comment": "6 pages, 2 figures, submitted to MIPRO 2026",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses the development of a domain-specific retrieval-augmented generation (RAG) system for Finnish-language agricultural decision support, which shows some relevance to information retrieval and NLP. However, the focus on domain-specific RAG systems and low-resource languages does not directly align with the user's primary interests in query understanding, ranking models, and user behavior modeling. The paper's emphasis on real-world evaluation and practical trade-offs is somewhat related to the user's interests in real-time relevance optimization."
    },
    {
        "title": "Deep learning enables urban change profiling through alignment of historical maps",
        "abstract": "Prior to modern Earth observation technologies, historical maps provide a unique record of long-term urban transformation and offer a lens on the evolving identity of cities. However, extracting consistent and fine-grained change information from historical map series remains challenging due to spatial misalignment, cartographic variation, and degrading document quality, limiting most analyses to small-scale or qualitative approaches. We propose a fully automated, deep learning-based framework for fine-grained urban change analysis from large collections of historical maps, built on a modular design that integrates dense map alignment, multi-temporal object detection, and change profiling. This framework shifts the analysis of historical maps from ad hoc visual comparison toward systematic, quantitative characterization of urban change. Experiments demonstrate the robust performance of the proposed alignment and object detection methods. Applied to Paris between 1868 and 1937, the framework reveals the spatial and temporal heterogeneity in urban transformation, highlighting its relevance for research in the social sciences and humanities. The modular design of our framework further supports adaptation to diverse cartographic contexts and downstream applications.",
        "url": "http://arxiv.org/abs/2602.02154v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02154v1",
        "arxiv_id": "2602.02154v1",
        "authors": [
            "Sidi Wu",
            "Yizi Chen",
            "Maurizio Gribaudi",
            "Konrad Schindler",
            "Cl√©ment Mallet",
            "Julien Perret",
            "Lorenz Hurni"
        ],
        "submitted": "2026-02-02 14:31:33",
        "source": "arxiv",
        "comment": "40 pages",
        "score": 4,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. It focuses on deep learning for urban change analysis from historical maps, which is outside your core areas of interest."
    },
    {
        "title": "WildGraphBench: Benchmarking GraphRAG with Wild-Source Corpora",
        "abstract": "Graph-based Retrieval-Augmented Generation (GraphRAG) organizes external knowledge as a hierarchical graph, enabling efficient retrieval and aggregation of scattered evidence across multiple documents. However, many existing benchmarks for GraphRAG rely on short, curated passages as external knowledge, failing to adequately evaluate systems in realistic settings involving long contexts and large-scale heterogeneous documents. To bridge this gap, we introduce WildGraphBench, a benchmark designed to assess GraphRAG performance in the wild. We leverage Wikipedia's unique structure, where cohesive narratives are grounded in long and heterogeneous external reference documents, to construct a benchmark reflecting real-word scenarios. Specifically, we sample articles across 12 top-level topics, using their external references as the retrieval corpus and citation-linked statements as ground truth, resulting in 1,100 questions spanning three levels of complexity: single-fact QA, multi-fact QA, and section-level summarization. Experiments across multiple baselines reveal that current GraphRAG pipelines help on multi-fact aggregation when evidence comes from a moderate number of sources, but this aggregation paradigm may overemphasize high-level statements at the expense of fine-grained details, leading to weaker performance on summarization tasks. Project page:https://github.com/BstWPY/WildGraphBench.",
        "url": "http://arxiv.org/abs/2602.02053v2",
        "pdf_url": "https://arxiv.org/pdf/2602.02053v2",
        "arxiv_id": "2602.02053v2",
        "authors": [
            "Pengyu Wang",
            "Benfeng Xu",
            "Licheng Zhang",
            "Shaohan Wang",
            "Mingxuan Du",
            "Chiwei Zhu",
            "Zhendong Mao"
        ],
        "submitted": "2026-02-02 12:55:29",
        "source": "arxiv",
        "comment": "https://github.com/BstWPY/WildGraphBench",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper introduces a benchmark for GraphRAG, a graph-based retrieval-augmented generation model. While it touches on information retrieval and knowledge aggregation, its primary focus is on evaluating GraphRAG's performance in realistic settings, which is somewhat related to the user's interests in query understanding and ranking models. However, the paper's emphasis on graph-based retrieval and aggregation is not a central match for the user's research themes."
    },
    {
        "title": "Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models",
        "abstract": "The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely completes assigned tasks. Data Science provides a natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, a large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models.",
        "url": "http://arxiv.org/abs/2602.02039v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02039v1",
        "arxiv_id": "2602.02039v1",
        "authors": [
            "Wei Liu",
            "Peijie Yu",
            "Michele Orini",
            "Yali Du",
            "Yulan He"
        ],
        "submitted": "2026-02-02 12:36:57",
        "source": "arxiv",
        "comment": "14 pages, 7 tables, 8 figures",
        "score": 4,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the evaluation of Large Language Models in a data science context, which is somewhat related to Information Retrieval, but it does not directly address query understanding, ranking models, or user behavior modeling. The paper's emphasis on autonomy and agentic intelligence in LLMs is not a central theme in the user's research interests."
    },
    {
        "title": "From Directions to Regions: Decomposing Activations in Language Models via Local Geometry",
        "abstract": "Activation decomposition methods in language models are tightly coupled to geometric assumptions on how concepts are realized in activation space. Existing approaches search for individual global directions, implicitly assuming linear separability, which overlooks concepts with nonlinear or multi-dimensional structure. In this work, we leverage Mixture of Factor Analyzers (MFA) as a scalable, unsupervised alternative that models the activation space as a collection of Gaussian regions with their local covariance structure. MFA decomposes activations into two compositional geometric objects: the region's centroid in activation space, and the local variation from the centroid. We train large-scale MFAs for Llama-3.1-8B and Gemma-2-2B, and show they capture complex, nonlinear structures in activation space. Moreover, evaluations on localization and steering benchmarks show that MFA outperforms unsupervised baselines, is competitive with supervised localization methods, and often achieves stronger steering performance than sparse autoencoders. Together, our findings position local geometry, expressed through subspaces, as a promising unit of analysis for scalable concept discovery and model control, accounting for complex structures that isolated directions fail to capture.",
        "url": "http://arxiv.org/abs/2602.02464v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02464v1",
        "arxiv_id": "2602.02464v1",
        "authors": [
            "Or Shafran",
            "Shaked Ronen",
            "Omri Fahn",
            "Shauli Ravfogel",
            "Atticus Geiger",
            "Mor Geva"
        ],
        "submitted": "2026-02-02 18:49:05",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval or Search technologies, but rather focuses on activation decomposition in language models using local geometry. While it involves NLP, it doesn't address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's focus on concept discovery and model control is somewhat tangential to the user's research themes."
    },
    {
        "title": "Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction",
        "abstract": "As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarification, and thus do not measure multi-turn disambiguation under grounded execution risk. We introduce \\textbf{Drift-Bench}, the first diagnostic benchmark that evaluates agentic pragmatics under input faults through multi-turn clarification across state-oriented and service-oriented execution environments. Grounded in classical theories of communication, \\textbf{Drift-Bench} provides a unified taxonomy of cooperative breakdowns and employs a persona-driven user simulator with the \\textbf{Rise} evaluation protocol. Experiments show substantial performance drops under these faults, with clarification effectiveness varying across user personas and fault types. \\MethodName bridges clarification research and agent safety evaluation, enabling systematic diagnosis of failures that can lead to unsafe executions.",
        "url": "http://arxiv.org/abs/2602.02455v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02455v1",
        "arxiv_id": "2602.02455v1",
        "authors": [
            "Han Bao",
            "Zheyuan Zhang",
            "Pengcheng Jing",
            "Zhengqing Yuan",
            "Kaiwen Shi",
            "Yanfang Ye"
        ],
        "submitted": "2026-02-02 18:46:16",
        "source": "arxiv",
        "comment": "65 pages, 40 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Large Language Models (LLMs) and their cooperative breakdowns under input faults, which is not directly related to Information Retrieval or Search technologies. While it involves multi-turn interaction, it's more aligned with NLP and agent safety evaluation, but lacks direct relevance to the user's core research themes."
    },
    {
        "title": "Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models",
        "abstract": "Multimodal Large Language Models (MLLMs) have advanced VQA and now support Vision-DeepResearch systems that use search engines for complex visual-textual fact-finding. However, evaluating these visual and textual search abilities is still difficult, and existing benchmarks have two major limitations. First, existing benchmarks are not visual search-centric: answers that should require visual search are often leaked through cross-textual cues in the text questions or can be inferred from the prior world knowledge in current MLLMs. Second, overly idealized evaluation scenario: On the image-search side, the required information can often be obtained via near-exact matching against the full image, while the text-search side is overly direct and insufficiently challenging. To address these issues, we construct the Vision-DeepResearch benchmark (VDR-Bench) comprising 2,000 VQA instances. All questions are created via a careful, multi-stage curation pipeline and rigorous expert review, designed to assess the behavior of Vision-DeepResearch systems under realistic real-world conditions. Moreover, to address the insufficient visual retrieval capabilities of current MLLMs, we propose a simple multi-round cropped-search workflow. This strategy is shown to effectively improve model performance in realistic visual retrieval scenarios. Overall, our results provide practical guidance for the design of future multimodal deep-research systems. The code will be released in https://github.com/Osilly/Vision-DeepResearch.",
        "url": "http://arxiv.org/abs/2602.02185v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02185v1",
        "arxiv_id": "2602.02185v1",
        "authors": [
            "Yu Zeng",
            "Wenxuan Huang",
            "Zhen Fang",
            "Shuang Chen",
            "Yufan Shen",
            "Yishuo Cai",
            "Xiaoman Wang",
            "Zhenfei Yin",
            "Lin Chen",
            "Zehui Chen",
            "Shiting Huang",
            "Yiming Zhao",
            "Yao Hu",
            "Philip Torr",
            "Wanli Ouyang",
            "Shaosheng Cao"
        ],
        "submitted": "2026-02-02 14:53:11",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of multimodal search and visual-textual fact-finding. The proposed benchmark and evaluation framework are relevant to your work on query understanding and ranking models, but the focus on multimodal large language models and visual search is not a central match to your core research themes."
    },
    {
        "title": "Understanding the Reversal Curse Mitigation in Masked Diffusion Models through Attention and Training Dynamics",
        "abstract": "Autoregressive language models (ARMs) suffer from the reversal curse: after learning that \"$A$ is $B$\", they often fail on the reverse query \"$B$ is $A$\". Masked diffusion-based language models (MDMs) exhibit this failure in a much weaker form, but the underlying reason has remained unclear. A common explanation attributes this mitigation to the any-order training objective. However, observing \"[MASK] is $B$\" during training does not necessarily teach the model to handle the reverse prompt \"$B$ is [MASK]\". We show that the mitigation arises from architectural structure and its interaction with training. In a one-layer Transformer encoder, weight sharing couples the two directions by making forward and reverse attention scores positively correlated. In the same setting, we further show that the corresponding gradients are aligned, so minimizing the forward loss also reduces the reverse loss. Experiments on both controlled toy tasks and large-scale diffusion language models support these mechanisms, explaining why MDMs partially overcome a failure mode that persists in strong ARMs.",
        "url": "http://arxiv.org/abs/2602.02133v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02133v1",
        "arxiv_id": "2602.02133v1",
        "authors": [
            "Sangwoo Shin",
            "BumJun Kim",
            "Kyelim Lee",
            "Moongyu Jeon",
            "Albert No"
        ],
        "submitted": "2026-02-02 14:17:08",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on masked diffusion models and their mitigation of the reversal curse in language models, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language models, the specific topic and analysis are more aligned with NLP and deep learning, rather than the user's primary focus on query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System",
        "abstract": "We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL",
        "url": "http://arxiv.org/abs/2602.02488v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02488v1",
        "arxiv_id": "2602.02488v1",
        "authors": [
            "Yinjie Wang",
            "Tianbao Xie",
            "Ke Shen",
            "Mengdi Wang",
            "Ling Yang"
        ],
        "submitted": "2026-02-02 18:59:04",
        "source": "arxiv",
        "comment": "Code: https://github.com/Gen-Verse/Open-AgentRL",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on reinforcement learning (RL) and its application to large language models (LLMs) and agentic scenarios. While it touches on optimization and learning signals, it does not directly relate to information retrieval, query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's emphasis on RL and LLMs makes it somewhat tangential to the user's primary research themes."
    },
    {
        "title": "Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability",
        "abstract": "Large language models (LLMs) have demonstrated strong reasoning capabilities through step-by-step chain-of-thought (CoT) reasoning. Nevertheless, at the limits of model capability, CoT often proves insufficient, and its strictly sequential nature constrains test-time scalability. A potential alternative is divide-and-conquer (DAC) reasoning, which decomposes a complex problem into subproblems to facilitate more effective exploration of the solution. Although promising, our analysis reveals a fundamental misalignment between general-purpose post-training and DAC-style inference, which limits the model's capacity to fully leverage this potential. To bridge this gap and fully unlock LLMs' reasoning capabilities on the most challenging tasks, we propose an end-to-end reinforcement learning (RL) framework to enhance their DAC-style reasoning capacity. At each step, the policy decomposes a problem into a group of subproblems, solves them sequentially, and addresses the original one conditioned on the subproblem solutions, with both decomposition and solution integrated into RL training. Under comparable training, our DAC-style framework endows the model with a higher performance ceiling and stronger test-time scalability, surpassing CoT by 8.6% in Pass@1 and 6.3% in Pass@32 on competition-level benchmarks.",
        "url": "http://arxiv.org/abs/2602.02477v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02477v1",
        "arxiv_id": "2602.02477v1",
        "authors": [
            "Xiao Liang",
            "Zhong-Zhi Li",
            "Zhenghao Lin",
            "Eric Hancheng Jiang",
            "Hengyuan Zhang",
            "Yelong Shen",
            "Kai-Wei Chang",
            "Ying Nian Wu",
            "Yeyun Gong",
            "Weizhu Chen"
        ],
        "submitted": "2026-02-02 18:54:54",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and deep semantic understanding, but it does not directly address information retrieval or search technologies. The focus on large language models and reasoning capabilities is tangentially relevant to the user's background in e-commerce and query understanding, but the connection is not strong enough to warrant a higher score."
    },
    {
        "title": "Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts",
        "abstract": "Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of site-specific procedural knowledge, and unstable long-term task tracking and memory, particularly when operating over complex Document Object Model structures. To address these limitations, we introduce Avenir-Web, a web agent that achieves a new open-source state of the art on the Online-Mind2Web benchmark in real-world deployment. Avenir-Web leverages a Mixture of Grounding Experts, Experience-Imitation Planning for incorporating procedural priors, and a task-tracking checklist combined with adaptive memory to enable robust and seamless interaction across diverse user interface paradigms. We evaluate Avenir-Web on Online-Mind2Web, a rigorous benchmark of live and user-centered web tasks. Our results demonstrate that Avenir-Web significantly surpasses prior open-source agents and attains performance parity with top-tier proprietary models, thereby establishing a new open-source state of the art for reliable web agents on live websites.",
        "url": "http://arxiv.org/abs/2602.02468v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02468v1",
        "arxiv_id": "2602.02468v1",
        "authors": [
            "Aiden Yiliu Li",
            "Xinyue Hao",
            "Shilong Liu",
            "Mengdi Wang"
        ],
        "submitted": "2026-02-02 18:50:07",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on developing a web agent that can interact with complex web interfaces, which is not directly related to information retrieval, query understanding, or ranking models. While it involves multimodal large language models, the primary goal is to create a reliable web agent, which is more aligned with recommender systems or human-computer interaction. The paper's emphasis on procedural knowledge and task tracking also diverges from the user behavior modeling and click models that are central to the user's research interests."
    },
    {
        "title": "Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models",
        "abstract": "Large Language Models (LLMs) often struggle with deductive judgment in syllogistic reasoning, systematically conflating semantic plausibility with formal validity a phenomenon known as content effect. This bias persists even when models generate step-wise explanations, indicating that intermediate rationales may inherit the same semantic shortcuts that affect answers. Recent approaches propose mitigating this issue by increasing inference-time structural constraints, either by encouraging abstract intermediate representations or by intervening directly in the model's internal computations; however, reliably suppressing semantic interference remains an open challenge. To make formal deduction less sensitive to semantic content, we introduce a framework for abstraction-guided reasoning that explicitly separates structural inference from lexical semantics. We construct paired content-laden and abstract syllogisms and use the model's activations on abstract inputs to define an abstract reasoning space. We then learn lightweight Abstractors that, from content-conditioned residual-stream states, predict representations aligned with this space and integrate these predictions via multi-layer interventions during the forward pass. Using cross-lingual transfer as a test bed, we show that abstraction-aligned steering reduces content-driven errors and improves validity-sensitive performance. Our results position activation-level abstraction as a scalable mechanism for enhancing the robustness of formal reasoning in LLMs against semantic interference.",
        "url": "http://arxiv.org/abs/2602.02462v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02462v1",
        "arxiv_id": "2602.02462v1",
        "authors": [
            "Gabriele Maraia",
            "Marco Valentino",
            "Fabio Massimo Zanzotto",
            "Leonardo Ranaldi"
        ],
        "submitted": "2026-02-02 18:48:44",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving the robustness of Large Language Models (LLMs) in formal reasoning tasks, specifically addressing the issue of semantic interference. While it touches on the topic of deep semantic understanding, it is primarily concerned with the robustness of LLMs rather than information retrieval or search technologies. The paper's relevance to the user's core research themes is limited."
    },
    {
        "title": "Proof-RM: A Scalable and Generalizable Reward Model for Math Proof",
        "abstract": "While Large Language Models (LLMs) have demonstrated strong math reasoning abilities through Reinforcement Learning with *Verifiable Rewards* (RLVR), many advanced mathematical problems are proof-based, with no guaranteed way to determine the authenticity of a proof by simple answer matching. To enable automatic verification, a Reward Model (RM) capable of reliably evaluating full proof processes is required. In this work, we design a *scalable* data-construction pipeline that, with minimal human effort, leverages LLMs to generate a large quantity of high-quality \"**question-proof-check**\" triplet data. By systematically varying problem sources, generation methods, and model configurations, we create diverse problem-proof pairs spanning multiple difficulty levels, linguistic styles, and error types, subsequently filtered through hierarchical human review for label alignment. Utilizing these data, we train a proof-checking RM, incorporating additional process reward and token weight balance to stabilize the RL process. Our experiments validate the model's scalability and strong performance from multiple perspectives, including reward accuracy, generalization ability and test-time guidance, providing important practical recipes and tools for strengthening LLM mathematical capabilities.",
        "url": "http://arxiv.org/abs/2602.02377v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02377v1",
        "arxiv_id": "2602.02377v1",
        "authors": [
            "Haotong Yang",
            "Zitong Wang",
            "Shijia Kang",
            "Siqi Yang",
            "Wenkai Yu",
            "Xu Niu",
            "Yike Sun",
            "Yi Hu",
            "Zhouchen Lin",
            "Muhan Zhang"
        ],
        "submitted": "2026-02-02 17:42:53",
        "source": "arxiv",
        "comment": "Under review",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be primarily focused on developing a reward model for math proof verification, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves Large Language Models, the application is specific to math proof verification and does not align with the user's interests in query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Language Steering for Multilingual In-Context Learning",
        "abstract": "While multilingual large language models have gained widespread adoption, their performance on non-English languages remains substantially inferior to English. This disparity is particularly evident in in-context learning scenarios, where providing demonstrations in English but testing on non-English inputs leads to significant performance degradation. In this paper, we hypothesize that LLMs develop a universal semantic space for understanding languages, where different languages are encoded as distinct directions within this space. Based on this hypothesis, we propose language vectors -- a training-free language steering approach that leverages activation differences between source and target languages to guide model behavior. We steer the model generations by adding the vector to the intermediate model activations during inference. This is done to make the model's internal representations shift towards the target language space without any parameter updates. We evaluate our method across three datasets and test on a total of 19 languages on three different models. Our results show consistent improvements on multilingual in-context learning over baselines across all tasks and languages tested. Beyond performance gains, hierarchical clustering of steering vectors reveals meaningful linguistic structure aligned with language families. These vectors also successfully transfer across tasks, demonstrating that these representations are task-agnostic.",
        "url": "http://arxiv.org/abs/2602.02326v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02326v1",
        "arxiv_id": "2602.02326v1",
        "authors": [
            "Neeraja Kirtane",
            "Kuan-Hao Huang"
        ],
        "submitted": "2026-02-02 16:52:09",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores multilingual large language models, which is somewhat related to information retrieval and search technologies. However, the focus is on language understanding and model steering, which is more aligned with natural language processing and deep learning. While the paper touches on the idea of semantic understanding, it does not directly address query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Advancing General-Purpose Reasoning Models with Modular Gradient Surgery",
        "abstract": "Reinforcement learning (RL) has played a central role in recent advances in large reasoning models (LRMs), yielding strong gains in verifiable and open-ended reasoning. However, training a single general-purpose LRM across diverse domains remains challenging due to pronounced domain heterogeneity. Through a systematic study of two widely used strategies, Sequential RL and Mixed RL, we find that both incur substantial cross-domain interference at the behavioral and gradient levels, resulting in limited overall gains. To address these challenges, we introduce **M**odular **G**radient **S**urgery (**MGS**), which resolves gradient conflicts at the module level within the transformer. When applied to Llama and Qwen models, MGS achieves average improvements of 4.3 (16.6\\%) and 4.5 (11.1\\%) points, respectively, over standard multi-task RL across three representative domains (math, general chat, and instruction following). Further analysis demonstrates that MGS remains effective under prolonged training. Overall, our study clarifies the sources of interference in multi-domain RL and presents an effective solution for training general-purpose LRMs.",
        "url": "http://arxiv.org/abs/2602.02301v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02301v1",
        "arxiv_id": "2602.02301v1",
        "authors": [
            "Min Cai",
            "Yu Liang",
            "Longzheng Wang",
            "Yan Wang",
            "Yueyang Zhang",
            "Long Xia",
            "Zhiyuan Sun",
            "Xi Ye",
            "Daiting Shi"
        ],
        "submitted": "2026-02-02 16:34:39",
        "source": "arxiv",
        "comment": "Preprint; Code: https://github.com/StringNLPLAB/MGS; Website: https://modular-gradient-surgery.github.io",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is primarily focused on advancing general-purpose reasoning models, which is a topic related to NLP, but it does not directly address query understanding, ranking models, or user behavior modeling in the context of Information Retrieval, making it only loosely relevant to your research interests."
    },
    {
        "title": "RACA: Representation-Aware Coverage Criteria for LLM Safety Testing",
        "abstract": "Recent advancements in LLMs have led to significant breakthroughs in various AI applications. However, their sophisticated capabilities also introduce severe safety concerns, particularly the generation of harmful content through jailbreak attacks. Current safety testing for LLMs often relies on static datasets and lacks systematic criteria to evaluate the quality and adequacy of these tests. While coverage criteria have been effective for smaller neural networks, they are not directly applicable to LLMs due to scalability issues and differing objectives. To address these challenges, this paper introduces RACA, a novel set of coverage criteria specifically designed for LLM safety testing. RACA leverages representation engineering to focus on safety-critical concepts within LLMs, thereby reducing dimensionality and filtering out irrelevant information. The framework operates in three stages: first, it identifies safety-critical representations using a small, expert-curated calibration set of jailbreak prompts. Second, it calculates conceptual activation scores for a given test suite based on these representations. Finally, it computes coverage results using six sub-criteria that assess both individual and compositional safety concepts. We conduct comprehensive experiments to validate RACA's effectiveness, applicability, and generalization, where the results demonstrate that RACA successfully identifies high-quality jailbreak prompts and is superior to traditional neuron-level criteria. We also showcase its practical application in real-world scenarios, such as test set prioritization and attack prompt sampling. Furthermore, our findings confirm RACA's generalization to various scenarios and its robustness across various configurations. Overall, RACA provides a new framework for evaluating the safety of LLMs, contributing a valuable technique to the field of testing for AI.",
        "url": "http://arxiv.org/abs/2602.02280v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02280v1",
        "arxiv_id": "2602.02280v1",
        "authors": [
            "Zeming Wei",
            "Zhixin Zhang",
            "Chengcan Wu",
            "Yihao Zhang",
            "Xiaokun Luan",
            "Meng Sun"
        ],
        "submitted": "2026-02-02 16:20:51",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it touches on AI applications, its focus is on safety testing for Large Language Models, which is not a central theme in your research."
    },
    {
        "title": "Learning While Staying Curious: Entropy-Preserving Supervised Fine-Tuning via Adaptive Self-Distillation for Large Reasoning Models",
        "abstract": "The standard post-training recipe for large reasoning models, supervised fine-tuning followed by reinforcement learning (SFT-then-RL), may limit the benefits of the RL stage: while SFT imitates expert demonstrations, it often causes overconfidence and reduces generation diversity, leaving RL with a narrowed solution space to explore. Adding entropy regularization during SFT is not a cure-all; it tends to flatten token distributions toward uniformity, increasing entropy without improving meaningful exploration capability. In this paper, we propose CurioSFT, an entropy-preserving SFT method designed to enhance exploration capabilities through intrinsic curiosity. It consists of (a) Self-Exploratory Distillation, which distills the model toward a self-generated, temperature-scaled teacher to encourage exploration within its capability; and (b) Entropy-Guided Temperature Selection, which adaptively adjusts distillation strength to mitigate knowledge forgetting by amplifying exploration at reasoning tokens while stabilizing factual tokens. Extensive experiments on mathematical reasoning tasks demonstrate that, in SFT stage, CurioSFT outperforms the vanilla SFT by 2.5 points on in-distribution tasks and 2.9 points on out-of-distribution tasks. We also verify that exploration capabilities preserved during SFT successfully translate into concrete gains in RL stage, yielding an average improvement of 5.0 points.",
        "url": "http://arxiv.org/abs/2602.02244v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02244v1",
        "arxiv_id": "2602.02244v1",
        "authors": [
            "Hao Wang",
            "Hao Gu",
            "Hongming Piao",
            "Kaixiong Gong",
            "Yuxiao Ye",
            "Xiangyu Yue",
            "Sirui Han",
            "Yike Guo",
            "Dapeng Wu"
        ],
        "submitted": "2026-02-02 15:53:55",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving the performance of large reasoning models through a novel fine-tuning method called CurioSFT. While it touches on aspects of model behavior and exploration, it does not directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "Using Correspondence Patterns to Identify Irregular Words in Cognate sets Through Leave-One-Out Validation",
        "abstract": "Regular sound correspondences constitute the principal evidence in historical language comparison. Despite the heuristic focus on regularity, it is often more an intuitive judgement than a quantified evaluation, and irregularity is more common than expected from the Neogrammarian model. Given the recent progress of computational methods in historical linguistics and the increased availability of standardized lexical data, we are now able to improve our workflows and provide such a quantitative evaluation. Here, we present the balanced average recurrence of correspondence patterns as a new measure of regularity. We also present a new computational method that uses this measure to identify cognate sets that lack regularity with respect to their correspondence patterns. We validate the method through two experiments, using simulated and real data. In the experiments, we employ leave-one-out validation to measure the regularity of cognate sets in which one word form has been replaced by an irregular one, checking how well our method identifies the forms causing the irregularity. Our method achieves an overall accuracy of 85\\% with the datasets based on real data. We also show the benefits of working with subsamples of large datasets and how increasing irregularity in the data influences our results. Reflecting on the broader potential of our new regularity measure and the irregular cognate identification method based on it, we conclude that they could play an important role in improving the quality of existing and future datasets in computer-assisted language comparison.",
        "url": "http://arxiv.org/abs/2602.02221v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02221v1",
        "arxiv_id": "2602.02221v1",
        "authors": [
            "Frederic Blum",
            "Johann-Mattis List"
        ],
        "submitted": "2026-02-02 15:26:41",
        "source": "arxiv",
        "comment": "Accepted for the L'Change workshop @ EACL 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. It focuses on historical language comparison, computational methods in historical linguistics, and lexical data, which are outside your primary areas of interest."
    },
    {
        "title": "Evaluating Metalinguistic Knowledge in Large Language Models across the World's Languages",
        "abstract": "Large language models (LLMs) are routinely evaluated on language use tasks, yet their knowledge of linguistic structure remains poorly understood. Existing linguistic benchmarks typically focus on narrow phenomena, emphasize high-resource languages, and rarely evaluate metalinguistic knowledge-explicit reasoning about language structure rather than language use. Using accuracy and macro F1, together with majority-class and chance baselines, we analyse overall performance and examine variation by linguistic domains and language-related factors. Our results show that metalinguistic knowledge in current LLMs is limited: GPT-4o performs best but achieves only moderate accuracy (0.367), while open-source models lag behind. All models perform above chance but fail to outperform the majority-class baseline, suggesting they capture cross-linguistic patterns but lack fine-grained grammatical distinctions. Performance varies across linguistic domains, with lexical features showing the highest accuracy and phonological features among the lowest, partially reflecting differences in online visibility. At the language level, accuracy shows a strong association with digital language status: languages with higher digital presence and resource availability are evaluated more accurately, while low-resource languages show substantially lower performance. Analyses of predictive factors confirm that resource-related indicators (Wikipedia size, corpus availability) are more informative predictors of accuracy than geographical, genealogical, or sociolinguistic factors. Together, these results suggest that LLMs' metalinguistic knowledge is fragmented and shaped by data availability rather than generalizable grammatical competence across the world's languages. We release our benchmark as an open-source dataset to support systematic evaluation and encourage greater global linguistic diversity in future LLMs.",
        "url": "http://arxiv.org/abs/2602.02182v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02182v1",
        "arxiv_id": "2602.02182v1",
        "authors": [
            "Tja≈°a Arƒçon",
            "Matej Klemen",
            "Marko Robnik-≈†ikonja",
            "Kaja Dobrovoljc"
        ],
        "submitted": "2026-02-02 14:49:56",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing, as it focuses on evaluating metalinguistic knowledge in Large Language Models across languages, which is more relevant to linguistic structure and language understanding rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "AR-MAP: Are Autoregressive Large Language Models Implicit Teachers for Diffusion Large Language Models?",
        "abstract": "Diffusion Large Language Models (DLLMs) have emerged as a powerful alternative to autoregressive models, enabling parallel token generation across multiple positions. However, preference alignment of DLLMs remains challenging due to high variance introduced by Evidence Lower Bound (ELBO)-based likelihood estimation. In this work, we propose AR-MAP, a novel transfer learning framework that leverages preference-aligned autoregressive LLMs (AR-LLMs) as implicit teachers for DLLM alignment. We reveal that DLLMs can effectively absorb alignment knowledge from AR-LLMs through simple weight scaling, exploiting the shared architectural structure between these divergent generation paradigms. Crucially, our approach circumvents the high variance and computational overhead of direct DLLM alignment and comprehensive experiments across diverse preference alignment tasks demonstrate that AR-MAP achieves competitive or superior performance compared to existing DLLM-specific alignment methods, achieving 69.08\\% average score across all tasks and models. Our Code is available at https://github.com/AMAP-ML/AR-MAP.",
        "url": "http://arxiv.org/abs/2602.02178v2",
        "pdf_url": "https://arxiv.org/pdf/2602.02178v2",
        "arxiv_id": "2602.02178v2",
        "authors": [
            "Liang Lin",
            "Feng Xiong",
            "Zengbin Wang",
            "Kun Wang",
            "Junhao Dong",
            "Xuecai Hu",
            "Yong Wang",
            "Xiangxiang Chu"
        ],
        "submitted": "2026-02-02 14:48:40",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's research interests in Information Retrieval, Search technologies, or Natural Language Processing. The focus on Large Language Models and their alignment is not a central match to the user's core themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing",
        "abstract": "Diffusion Large Language Models (dLLMs) deliver strong long-context processing capability in a non-autoregressive decoding paradigm. However, the considerable computational cost of bidirectional full attention limits the inference efficiency. Although sparse attention is promising, existing methods remain ineffective. This stems from the need to estimate attention importance for tokens yet to be decoded, while the unmasked token positions are unknown during diffusion. In this paper, we present Focus-dLLM, a novel training-free attention sparsification framework tailored for accurate and efficient long-context dLLM inference. Based on the finding that token confidence strongly correlates across adjacent steps, we first design a past confidence-guided indicator to predict unmasked regions. Built upon this, we propose a sink-aware pruning strategy to accurately estimate and remove redundant attention computation, while preserving highly influential attention sinks. To further reduce overhead, this strategy reuses identified sink locations across layers, leveraging the observed cross-layer consistency. Experimental results show that our method offers more than $29\\times$ lossless speedup under $32K$ context length. The code is publicly available at: https://github.com/Longxmas/Focus-dLLM",
        "url": "http://arxiv.org/abs/2602.02159v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02159v1",
        "arxiv_id": "2602.02159v1",
        "authors": [
            "Lingkun Long",
            "Yushi Huang",
            "Shihao Bai",
            "Ruihao Gong",
            "Jun Zhang",
            "Ao Zhou",
            "Jianlei Yang"
        ],
        "submitted": "2026-02-02 14:36:10",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper focuses on accelerating inference efficiency of Diffusion Large Language Models (dLLMs) using a novel attention sparsification framework. Although it involves NLP and deep learning, it does not appear to be directly related to Information Retrieval, Search technologies, or user behavior modeling, which are the primary areas of interest."
    },
    {
        "title": "Out of the Memory Barrier: A Highly Memory Efficient Training System for LLMs with Million-Token Contexts",
        "abstract": "Training Large Language Models (LLMs) on long contexts is severely constrained by prohibitive GPU memory overhead, not training time. The primary culprits are the activations, whose memory footprints scale linearly with sequence length. We introduce OOMB, a highly memory-efficient training system that directly confronts this barrier. Our approach employs a chunk-recurrent training framework with on-the-fly activation recomputation, which maintains a constant activation memory footprint (O(1)) and shifts the primary bottleneck to the growing KV cache. To manage the KV cache, OOMB integrates a suite of synergistic optimizations: a paged memory manager for both the KV cache and its gradients to eliminate fragmentation, asynchronous CPU offloading to hide data transfer latency, and page-level sparse attention to reduce both computational complexity and communication overhead. The synergy of these techniques yields exceptional efficiency. Our empirical results show that for every additional 10K tokens of context, the end-to-end training memory overhead increases by a mere 10MB for Qwen2.5-7B. This allows training Qwen2.5-7B with a 4M-token context on a single H200 GPU, a feat that would otherwise require a large cluster using context parallelism. This work represents a substantial advance in resource efficiency for long-context LLM training. The source code is available at https://github.com/wenhaoli-xmu/OOMB.",
        "url": "http://arxiv.org/abs/2602.02108v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02108v1",
        "arxiv_id": "2602.02108v1",
        "authors": [
            "Wenhao Li",
            "Daohai Yu",
            "Gen Luo",
            "Yuxin Zhang",
            "Fei Chao",
            "Rongrong Ji",
            "Yifan Wu",
            "Jiaxin Liu",
            "Ziyang Gong",
            "Zimu Liao"
        ],
        "submitted": "2026-02-02 13:52:40",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on memory efficiency for training Large Language Models, which is a specific problem in Natural Language Processing. While it touches on deep semantic understanding, it's not directly related to information retrieval, search technologies, or query understanding, which are core areas of your research interests."
    },
    {
        "title": "Dicta-LM 3.0: Advancing The Frontier of Hebrew Sovereign LLMs",
        "abstract": "Open-weight LLMs have been released by frontier labs; however, sovereign Large Language Models (for languages other than English) remain low in supply yet high in demand. Training large language models (LLMs) for low-resource languages such as Hebrew poses unique challenges. In this paper, we introduce Dicta-LM 3.0: an open-weight collection of LLMs trained on substantially-sized corpora of Hebrew and English texts. The model is released in three sizes: 24B - adapted from the Mistral-Small-3.1 base model, 12B - adapted from the NVIDIA Nemotron Nano V2 model, and 1.7B - adapted from the Qwen3-1.7B base model. We are releasing multiple variants of each model, each with a native context length of 65k tokens; base model and chat model with tool-calling support. To rigorously evaluate our models, we introduce a new benchmark suite for evaluation of Hebrew chat-LLMs, covering a diverse set of tasks including Translation, Summarization, Winograd, Israeli Trivia, and Diacritization (nikud). Our work not only addresses the intricacies of training LLMs in low-resource languages but also proposes a framework that can be leveraged for adapting other LLMs to various non-English languages, contributing to the broader field of multilingual NLP.",
        "url": "http://arxiv.org/abs/2602.02104v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02104v1",
        "arxiv_id": "2602.02104v1",
        "authors": [
            "Shaltiel Shmidman",
            "Avi Shmidman",
            "Amir DN Cohen",
            "Moshe Koppel"
        ],
        "submitted": "2026-02-02 13:47:54",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on developing Large Language Models for low-resource languages, specifically Hebrew, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing, particularly in areas requiring deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "No Global Plan in Chain-of-Thought: Uncover the Latent Planning Horizon of LLMs",
        "abstract": "This work stems from prior complementary observations on the dynamics of Chain-of-Thought (CoT): Large Language Models (LLMs) is shown latent planning of subsequent reasoning prior to CoT emergence, thereby diminishing the significance of explicit CoT; whereas CoT remains critical for tasks requiring multi-step reasoning. To deepen the understanding between LLM's internal states and its verbalized reasoning trajectories, we investigate the latent planning strength of LLMs, through our probing method, Tele-Lens, applying to hidden states across diverse task domains. Our empirical results indicate that LLMs exhibit a myopic horizon, primarily conducting incremental transitions without precise global planning. Leveraging this characteristic, we propose a hypothesis on enhancing uncertainty estimation of CoT, which we validate that a small subset of CoT positions can effectively represent the uncertainty of the entire path. We further underscore the significance of exploiting CoT dynamics, and demonstrate that automatic recognition of CoT bypass can be achieved without performance degradation. Our code, data and models are released at https://github.com/lxucs/tele-lens.",
        "url": "http://arxiv.org/abs/2602.02103v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02103v1",
        "arxiv_id": "2602.02103v1",
        "authors": [
            "Liyan Xu",
            "Mo Yu",
            "Fandong Meng",
            "Jie Zhou"
        ],
        "submitted": "2026-02-02 13:46:56",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be related to Large Language Models (LLMs) and their internal reasoning processes, but it does not directly address information retrieval, search technologies, or user behavior modeling. While it touches on the concept of 'Chain-of-Thought' which could be relevant to query understanding, the focus is more on the internal workings of LLMs rather than its application to IR or search."
    },
    {
        "title": "Think Dense, Not Long: Dynamic Decoupled Conditional Advantage for Efficient Reasoning",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) can elicit strong multi-step reasoning, yet it often encourages overly verbose traces. Moreover, naive length penalties in group-relative optimization can severely hurt accuracy. We attribute this failure to two structural issues: (i) Dilution of Length Baseline, where incorrect responses (with zero length reward) depress the group baseline and over-penalize correct solutions; and (ii) Difficulty-Penalty Mismatch, where a static penalty cannot adapt to problem difficulty, suppressing necessary reasoning on hard instances while leaving redundancy on easy ones. We propose Dynamic Decoupled Conditional Advantage (DDCA) to decouple efficiency optimization from correctness. DDCA computes length advantages conditionally within the correct-response cluster to eliminate baseline dilution, and dynamically scales the penalty strength using the group pass rate as a proxy for difficulty. Experiments on GSM8K, MATH500, AMC23, and AIME25 show that DDCA consistently improves the efficiency--accuracy trade-off relative to adaptive baselines, reducing generated tokens by approximately 60% on simpler tasks (e.g., GSM8K) versus over 20% on harder benchmarks (e.g., AIME25), thereby maintaining or improving accuracy. Code is available at https://github.com/alphadl/DDCA.",
        "url": "http://arxiv.org/abs/2602.02099v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02099v1",
        "arxiv_id": "2602.02099v1",
        "authors": [
            "Keqin Peng",
            "Yuanxin Ouyang",
            "Xuebo Liu",
            "Zhiliang Tian",
            "Ruijian Han",
            "Yancheng Yuan",
            "Liang Ding"
        ],
        "submitted": "2026-02-02 13:43:52",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on efficient reasoning and optimization in reinforcement learning, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on optimization and efficiency, the context is different and the techniques proposed are not applicable to your areas of expertise."
    },
    {
        "title": "Closing the Loop: Universal Repository Representation with RPG-Encoder",
        "abstract": "Current repository agents encounter a reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within a unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder, a framework that generalizes the Repository Planning Graph (RPG) from a static generative blueprint into a unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as a unified interface for structure-aware navigation. In evaluations, RPG-Encoder establishes state-of-the-art localization performance on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% in localization accuracy on SWE-bench Live Lite. These results highlight our superior fine-grained precision in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPG's high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation.",
        "url": "http://arxiv.org/abs/2602.02084v2",
        "pdf_url": "https://arxiv.org/pdf/2602.02084v2",
        "arxiv_id": "2602.02084v2",
        "authors": [
            "Jane Luo",
            "Chengyu Yin",
            "Xin Zhang",
            "Qingtao Li",
            "Steven Liu",
            "Yiming Huang",
            "Jie Wu",
            "Hao Liu",
            "Yangyu Huang",
            "Yu Kang",
            "Fangkai Yang",
            "Ying Xin",
            "Scarlett Li"
        ],
        "submitted": "2026-02-02 13:30:00",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on repository comprehension and generation, proposing a framework called RPG-Encoder to unify repository representations. While it involves semantic understanding and code analysis, the primary focus is on repository planning and generation, which is somewhat related to information retrieval but not directly aligned with your core research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Adaptive Quality-Diversity Trade-offs for Large-Scale Batch Recommendation",
        "abstract": "A core research question in recommender systems is to propose batches of highly relevant and diverse items, that is, items personalized to the user's preferences, but which also might get the user out of their comfort zone. This diversity might induce properties of serendipidity and novelty which might increase user engagement or revenue. However, many real-life problems arise in that case: e.g., avoiding to recommend distinct but too similar items to reduce the churn risk, and computational cost for large item libraries, up to millions of items. First, we consider the case when the user feedback model is perfectly observed and known in advance, and introduce an efficient algorithm called B-DivRec combining determinantal point processes and a fuzzy denuding procedure to adjust the degree of item diversity. This helps enforcing a quality-diversity trade-off throughout the user history. Second, we propose an approach to adaptively tailor the quality-diversity trade-off to the user, so that diversity in recommendations can be enhanced if it leads to positive feedback, and vice-versa. Finally, we illustrate the performance and versatility of B-DivRec in the two settings on synthetic and real-life data sets on movie recommendation and drug repurposing.",
        "url": "http://arxiv.org/abs/2602.02024v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02024v1",
        "arxiv_id": "2602.02024v1",
        "authors": [
            "Cl√©mence R√©da",
            "Tomas Rigaux",
            "Hiba Bederina",
            "Koh Takeuchi",
            "Hisashi Kashima",
            "Jill-J√™nn Vie"
        ],
        "submitted": "2026-02-02 12:20:07",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is primarily focused on recommender systems, which is a related topic, but it does not align with the user's core research themes in Information Retrieval and Search technologies, particularly query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Rethinking Genomic Modeling Through Optical Character Recognition",
        "abstract": "Recent genomic foundation models largely adopt large language model architectures that treat DNA as a one-dimensional token sequence. However, exhaustive sequential reading is structurally misaligned with sparse and discontinuous genomic semantics, leading to wasted computation on low-information background and preventing understanding-driven compression for long contexts. Here, we present OpticalDNA, a vision-based framework that reframes genomic modeling as Optical Character Recognition (OCR)-style document understanding. OpticalDNA renders DNA into structured visual layouts and trains an OCR-capable vision--language model with a \\emph{visual DNA encoder} and a \\emph{document decoder}, where the encoder produces compact, reconstructible visual tokens for high-fidelity compression. Building on this representation, OpticalDNA defines prompt-conditioned objectives over core genomic primitives-reading, region grounding, subsequence retrieval, and masked span completion-thereby learning layout-aware DNA representations that retain fine-grained genomic information under a reduced effective token budget. Across diverse genomic benchmarks, OpticalDNA consistently outperforms recent baselines; on sequences up to 450k bases, it achieves the best overall performance with nearly $20\\times$ fewer effective tokens, and surpasses models with up to $985\\times$ more activated parameters while tuning only 256k \\emph{trainable} parameters.",
        "url": "http://arxiv.org/abs/2602.02014v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02014v1",
        "arxiv_id": "2602.02014v1",
        "authors": [
            "Hongxin Xiang",
            "Pengsen Ma",
            "Yunkang Cao",
            "Di Yu",
            "Haowen Chen",
            "Xinyu Yang",
            "Xiangxiang Zeng"
        ],
        "submitted": "2026-02-02 12:12:00",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on genomic modeling and Optical Character Recognition (OCR) for DNA sequences, which is outside the scope of Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "NEAT: Neuron-Based Early Exit for Large Reasoning Models",
        "abstract": "Large Reasoning Models (LRMs) often suffer from \\emph{overthinking}, a phenomenon in which redundant reasoning steps are generated after a correct solution has already been reached. Existing early reasoning exit methods primarily rely on output-level heuristics or trained probing models to skip redundant reasoning steps, thereby mitigating overthinking. However, these approaches typically require additional rollout computation or externally labeled datasets. In this paper, we propose \\textbf{NEAT}, a \\textbf{N}euron-based \\textbf{E}arly re\\textbf{A}soning exi\\textbf{T} framework that monitors neuron-level activation dynamics to enable training-free early exits, without introducing additional test-time computation. NEAT identifies exit-associated neurons and tracks their activation patterns during reasoning to dynamically trigger early exit or suppress reflection, thereby reducing unnecessary reasoning while preserving solution quality. Experiments on four reasoning benchmarks across six models with different scales and architectures show that, for each model, NEAT achieves an average token reduction of 22\\% to 28\\% when averaged over the four benchmarks, while maintaining accuracy.",
        "url": "http://arxiv.org/abs/2602.02010v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02010v1",
        "arxiv_id": "2602.02010v1",
        "authors": [
            "Kang Liu",
            "Yongkang Liu",
            "Xiaocui Yang",
            "Peidong Wang",
            "Wen Zhang",
            "Shi Feng",
            "Yifei Zhang",
            "Daling Wang"
        ],
        "submitted": "2026-02-02 12:09:59",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on optimizing the performance of Large Reasoning Models by reducing unnecessary reasoning steps, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. Although it involves neural networks and optimization techniques, the context is more aligned with NLP and deep learning, rather than IR or search. The paper's emphasis on real-time relevance optimization is not a primary concern in this work."
    },
    {
        "title": "Mixture-of-Experts with Intermediate CTC Supervision for Accented Speech Recognition",
        "abstract": "Accented speech remains a persistent challenge for automatic speech recognition (ASR), as most models are trained on data dominated by a few high-resource English varieties, leading to substantial performance degradation for other accents. Accent-agnostic approaches improve robustness yet struggle with heavily accented or unseen varieties, while accent-specific methods rely on limited and often noisy labels. We introduce Moe-Ctc, a Mixture-of-Experts architecture with intermediate CTC supervision that jointly promotes expert specialization and generalization. During training, accent-aware routing encourages experts to capture accent-specific patterns, which gradually transitions to label-free routing for inference. Each expert is equipped with its own CTC head to align routing with transcription quality, and a routing-augmented loss further stabilizes optimization. Experiments on the Mcv-Accent benchmark demonstrate consistent gains across both seen and unseen accents in low- and high-resource conditions, achieving up to 29.3% relative WER reduction over strong FastConformer baselines.",
        "url": "http://arxiv.org/abs/2602.01967v1",
        "pdf_url": "https://arxiv.org/pdf/2602.01967v1",
        "arxiv_id": "2602.01967v1",
        "authors": [
            "Wonjun Lee",
            "Hyounghun Kim",
            "Gary Geunbae Lee"
        ],
        "submitted": "2026-02-02 11:16:34",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper focuses on speech recognition for accented speech, which is outside your primary research interests in Information Retrieval and Search technologies, and related topics like NLP, data mining, and recommender systems."
    },
    {
        "title": "RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents",
        "abstract": "LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.",
        "url": "http://arxiv.org/abs/2602.02486v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02486v1",
        "arxiv_id": "2602.02486v1",
        "authors": [
            "Jialiang Zhu",
            "Gongrui Zhang",
            "Xiaolong Ma",
            "Lin Xu",
            "Miaosen Zhang",
            "Ruiqi Yang",
            "Song Wang",
            "Kai Qiu",
            "Zhirong Wu",
            "Qi Dai",
            "Ruichun Ma",
            "Bei Liu",
            "Yifan Yang",
            "Chong Luo",
            "Zhengyuan Yang",
            "Linjie Li",
            "Lijuan Wang",
            "Weizhu Chen",
            "Xin Geng",
            "Baining Guo"
        ],
        "submitted": "2026-02-02 18:58:07",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper proposes a new framework for deep search agents, Re-TRAC, which enables cross-trajectory exploration and globally informed planning. While it is related to search technologies and deep semantic understanding, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's focus on agentic frameworks and trajectory compression is somewhat relevant to information retrieval, but it is not a central match."
    },
    {
        "title": "WideSeek: Advancing Wide Research via Multi-Agent Scaling",
        "abstract": "Search intelligence is evolving from Deep Research to Wide Research, a paradigm essential for retrieving and synthesizing comprehensive information under complex constraints in parallel. However, progress in this field is impeded by the lack of dedicated benchmarks and optimization methodologies for search breadth. To address these challenges, we take a deep dive into Wide Research from two perspectives: Data Pipeline and Agent Optimization. First, we produce WideSeekBench, a General Broad Information Seeking (GBIS) benchmark constructed via a rigorous multi-phase data pipeline to ensure diversity across the target information volume, logical constraints, and domains. Second, we introduce WideSeek, a dynamic hierarchical multi-agent architecture that can autonomously fork parallel sub-agents based on task requirements. Furthermore, we design a unified training framework that linearizes multi-agent trajectories and optimizes the system using end-to-end RL. Experimental results demonstrate the effectiveness of WideSeek and multi-agent RL, highlighting that scaling the number of agents is a promising direction for advancing the Wide Research paradigm.",
        "url": "http://arxiv.org/abs/2602.02636v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02636v1",
        "arxiv_id": "2602.02636v1",
        "authors": [
            "Ziyang Huang",
            "Haolin Ren",
            "Xiaowei Yuan",
            "Jiawei Wang",
            "Zhongtao Jiang",
            "Kun Xu",
            "Shizhu He",
            "Jun Zhao",
            "Kang Liu"
        ],
        "submitted": "2026-02-02 18:32:48",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper WideSeek: Advancing Wide Research via Multi-Agent Scaling is somewhat related to the user's interests in Information Retrieval, particularly in the context of search breadth and optimization. However, it does not directly focus on query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user. The paper's emphasis on multi-agent scaling and reinforcement learning is an interesting aspect, but it does not align with the user's primary focus on deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Trust by Design: Skill Profiles for Transparent, Cost-Aware LLM Routing",
        "abstract": "How should Large Language Model (LLM) practitioners select the right model for a task without wasting money? We introduce BELLA (Budget-Efficient LLM Selection via Automated skill-profiling), a framework that recommends optimal LLM selection for tasks through interpretable skill-based model selection. Standard benchmarks report aggregate metrics that obscure which specific capabilities a task requires and whether a cheaper model could suffice. BELLA addresses this gap through three stages: (1) decomposing LLM outputs and extract the granular skills required by using critic-based profiling, (2) clustering skills into structured capability matrices, and (3) multi-objective optimization to select the right models to maximize performance while respecting budget constraints. BELLA provides natural-language rationale for recommendations, providing transparency that current black-box routing systems lack. We describe the framework architecture, situate it within the landscape of LLM routing and evaluation, and discuss its application to financial reasoning as a representative domain exhibiting diverse skill requirements and cost-variation across models. Our framework enables practitioners to make principled and cost-performance trade-offs for deploying LLMs.",
        "url": "http://arxiv.org/abs/2602.02386v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02386v1",
        "arxiv_id": "2602.02386v1",
        "authors": [
            "Mika Okamoto",
            "Ansel Kaplan Erol",
            "Glenn Matlin"
        ],
        "submitted": "2026-02-02 17:49:30",
        "source": "arxiv",
        "comment": "Appeared at MLSys YPS 2025",
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores Large Language Model (LLM) routing and selection, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on LLMs and skill-based model selection is not directly aligned with the user's primary research interests in IR and search technologies. The paper's emphasis on transparency and cost-awareness is also relevant to the e-commerce domain, but not a central match for the user's interests."
    },
    {
        "title": "Kimi K2.5: Visual Agentic Intelligence",
        "abstract": "We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to $4.5\\times$ over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence.",
        "url": "http://arxiv.org/abs/2602.02276v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02276v1",
        "arxiv_id": "2602.02276v1",
        "authors": [
            "Kimi Team",
            "Tongtong Bai",
            "Yifan Bai",
            "Yiping Bao",
            "S. H. Cai",
            "Yuan Cao",
            "Y. Charles",
            "H. S. Che",
            "Cheng Chen",
            "Guanduo Chen",
            "Huarong Chen",
            "Jia Chen",
            "Jiahao Chen",
            "Jianlong Chen",
            "Jun Chen",
            "Kefan Chen",
            "Liang Chen",
            "Ruijue Chen",
            "Xinhao Chen",
            "Yanru Chen",
            "Yanxu Chen",
            "Yicun Chen",
            "Yimin Chen",
            "Yingjiang Chen",
            "Yuankun Chen",
            "Yujie Chen",
            "Yutian Chen",
            "Zhirong Chen",
            "Ziwei Chen",
            "Dazhi Cheng",
            "Minghan Chu",
            "Jialei Cui",
            "Jiaqi Deng",
            "Muxi Diao",
            "Hao Ding",
            "Mengfan Dong",
            "Mengnan Dong",
            "Yuxin Dong",
            "Yuhao Dong",
            "Angang Du",
            "Chenzhuang Du",
            "Dikang Du",
            "Lingxiao Du",
            "Yulun Du",
            "Yu Fan",
            "Shengjun Fang",
            "Qiulin Feng",
            "Yichen Feng",
            "Garimugai Fu",
            "Kelin Fu",
            "Hongcheng Gao",
            "Tong Gao",
            "Yuyao Ge",
            "Shangyi Geng",
            "Chengyang Gong",
            "Xiaochen Gong",
            "Zhuoma Gongque",
            "Qizheng Gu",
            "Xinran Gu",
            "Yicheng Gu",
            "Longyu Guan",
            "Yuanying Guo",
            "Xiaoru Hao",
            "Weiran He",
            "Wenyang He",
            "Yunjia He",
            "Chao Hong",
            "Hao Hu",
            "Jiaxi Hu",
            "Yangyang Hu",
            "Zhenxing Hu",
            "Ke Huang",
            "Ruiyuan Huang",
            "Weixiao Huang",
            "Zhiqi Huang",
            "Tao Jiang",
            "Zhejun Jiang",
            "Xinyi Jin",
            "Yu Jing",
            "Guokun Lai",
            "Aidi Li",
            "C. Li",
            "Cheng Li",
            "Fang Li",
            "Guanghe Li",
            "Guanyu Li",
            "Haitao Li",
            "Haoyang Li",
            "Jia Li",
            "Jingwei Li",
            "Junxiong Li",
            "Lincan Li",
            "Mo Li",
            "Weihong Li",
            "Wentao Li",
            "Xinhang Li",
            "Xinhao Li",
            "Yang Li",
            "Yanhao Li",
            "Yiwei Li",
            "Yuxiao Li",
            "Zhaowei Li",
            "Zheming Li",
            "Weilong Liao",
            "Jiawei Lin",
            "Xiaohan Lin",
            "Zhishan Lin",
            "Zichao Lin",
            "Cheng Liu",
            "Chenyu Liu",
            "Hongzhang Liu",
            "Liang Liu",
            "Shaowei Liu",
            "Shudong Liu",
            "Shuran Liu",
            "Tianwei Liu",
            "Tianyu Liu",
            "Weizhou Liu",
            "Xiangyan Liu",
            "Yangyang Liu",
            "Yanming Liu",
            "Yibo Liu",
            "Yuanxin Liu",
            "Yue Liu",
            "Zhengying Liu",
            "Zhongnuo Liu",
            "Enzhe Lu",
            "Haoyu Lu",
            "Zhiyuan Lu",
            "Junyu Luo",
            "Tongxu Luo",
            "Yashuo Luo",
            "Long Ma",
            "Yingwei Ma",
            "Shaoguang Mao",
            "Yuan Mei",
            "Xin Men",
            "Fanqing Meng",
            "Zhiyong Meng",
            "Yibo Miao",
            "Minqing Ni",
            "Kun Ouyang",
            "Siyuan Pan",
            "Bo Pang",
            "Yuchao Qian",
            "Ruoyu Qin",
            "Zeyu Qin",
            "Jiezhong Qiu",
            "Bowen Qu",
            "Zeyu Shang",
            "Youbo Shao",
            "Tianxiao Shen",
            "Zhennan Shen",
            "Juanfeng Shi",
            "Lidong Shi",
            "Shengyuan Shi",
            "Feifan Song",
            "Pengwei Song",
            "Tianhui Song",
            "Xiaoxi Song",
            "Hongjin Su",
            "Jianlin Su",
            "Zhaochen Su",
            "Lin Sui",
            "Jinsong Sun",
            "Junyao Sun",
            "Tongyu Sun",
            "Flood Sung",
            "Yunpeng Tai",
            "Chuning Tang",
            "Heyi Tang",
            "Xiaojuan Tang",
            "Zhengyang Tang",
            "Jiawen Tao",
            "Shiyuan Teng",
            "Chaoran Tian",
            "Pengfei Tian",
            "Ao Wang",
            "Bowen Wang",
            "Chensi Wang",
            "Chuang Wang",
            "Congcong Wang",
            "Dingkun Wang",
            "Dinglu Wang",
            "Dongliang Wang",
            "Feng Wang",
            "Hailong Wang",
            "Haiming Wang",
            "Hengzhi Wang",
            "Huaqing Wang",
            "Hui Wang",
            "Jiahao Wang",
            "Jinhong Wang",
            "Jiuzheng Wang",
            "Kaixin Wang",
            "Linian Wang",
            "Qibin Wang",
            "Shengjie Wang",
            "Shuyi Wang",
            "Si Wang",
            "Wei Wang",
            "Xiaochen Wang",
            "Xinyuan Wang",
            "Yao Wang",
            "Yejie Wang",
            "Yipu Wang",
            "Yiqin Wang",
            "Yucheng Wang",
            "Yuzhi Wang",
            "Zhaoji Wang",
            "Zhaowei Wang",
            "Zhengtao Wang",
            "Zhexu Wang",
            "Zihan Wang",
            "Zizhe Wang",
            "Chu Wei",
            "Ming Wei",
            "Chuan Wen",
            "Zichen Wen",
            "Chengjie Wu",
            "Haoning Wu",
            "Junyan Wu",
            "Rucong Wu",
            "Wenhao Wu",
            "Yuefeng Wu",
            "Yuhao Wu",
            "Yuxin Wu",
            "Zijian Wu",
            "Chenjun Xiao",
            "Jin Xie",
            "Xiaotong Xie",
            "Yuchong Xie",
            "Yifei Xin",
            "Bowei Xing",
            "Boyu Xu",
            "Jianfan Xu",
            "Jing Xu",
            "Jinjing Xu",
            "L. H. Xu",
            "Lin Xu",
            "Suting Xu",
            "Weixin Xu",
            "Xinbo Xu",
            "Xinran Xu",
            "Yangchuan Xu",
            "Yichang Xu",
            "Yuemeng Xu",
            "Zelai Xu",
            "Ziyao Xu",
            "Junjie Yan",
            "Yuzi Yan",
            "Guangyao Yang",
            "Hao Yang",
            "Junwei Yang",
            "Kai Yang",
            "Ningyuan Yang",
            "Ruihan Yang",
            "Xiaofei Yang",
            "Xinlong Yang",
            "Ying Yang",
            "Yi Yang",
            "Yi Yang",
            "Zhen Yang",
            "Zhilin Yang",
            "Zonghan Yang",
            "Haotian Yao",
            "Dan Ye",
            "Wenjie Ye",
            "Zhuorui Ye",
            "Bohong Yin",
            "Chengzhen Yu",
            "Longhui Yu",
            "Tao Yu",
            "Tianxiang Yu",
            "Enming Yuan",
            "Mengjie Yuan",
            "Xiaokun Yuan",
            "Yang Yue",
            "Weihao Zeng",
            "Dunyuan Zha",
            "Haobing Zhan",
            "Dehao Zhang",
            "Hao Zhang",
            "Jin Zhang",
            "Puqi Zhang",
            "Qiao Zhang",
            "Rui Zhang",
            "Xiaobin Zhang",
            "Y. Zhang",
            "Yadong Zhang",
            "Yangkun Zhang",
            "Yichi Zhang",
            "Yizhi Zhang",
            "Yongting Zhang",
            "Yu Zhang",
            "Yushun Zhang",
            "Yutao Zhang",
            "Yutong Zhang",
            "Zheng Zhang",
            "Chenguang Zhao",
            "Feifan Zhao",
            "Jinxiang Zhao",
            "Shuai Zhao",
            "Xiangyu Zhao",
            "Yikai Zhao",
            "Zijia Zhao",
            "Huabin Zheng",
            "Ruihan Zheng",
            "Shaojie Zheng",
            "Tengyang Zheng",
            "Junfeng Zhong",
            "Longguang Zhong",
            "Weiming Zhong",
            "M. Zhou",
            "Runjie Zhou",
            "Xinyu Zhou",
            "Zaida Zhou",
            "Jinguo Zhu",
            "Liya Zhu",
            "Xinhao Zhu",
            "Yuxuan Zhu",
            "Zhen Zhu",
            "Jingze Zhuang",
            "Weiyu Zhuang",
            "Ying Zou",
            "Xinxing Zu"
        ],
        "submitted": "2026-02-02 16:17:38",
        "source": "arxiv",
        "comment": "Kimi K2.5 tech report",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. The focus on multimodal agentic intelligence and agent swarm orchestration does not align with the user's interests in query understanding, ranking models, user behavior modeling, or deep semantic understanding in IR."
    },
    {
        "title": "OmniCode: A Benchmark for Evaluating Software Engineering Agents",
        "abstract": "LLM-powered coding agents are redefining how real-world software is developed. To drive the research towards better coding agents, we require challenging benchmarks that can rigorously evaluate the ability of such agents to perform various software engineering tasks. However, popular coding benchmarks such as HumanEval and SWE-Bench focus on narrowly scoped tasks such as competition programming and patch generation. In reality, software engineers have to handle a broader set of tasks for real-world software development. To address this gap, we propose OmniCode, a novel software engineering benchmark that contains a broader and more diverse set of task categories beyond code or patch generation. Overall, OmniCode contains 1794 tasks spanning three programming languages (Python, Java, and C++) and four key categories: bug fixing, test generation, code review fixing, and style fixing. In contrast to prior software engineering benchmarks, the tasks in OmniCode are (1) manually validated to eliminate ill-defined problems, and (2) synthetically crafted or recently curated to avoid data leakage issues, presenting a new framework for synthetically generating diverse software tasks from limited real-world data. We evaluate OmniCode with popular agent frameworks such as SWE-Agent and show that while they may perform well on bug fixing for Python, they fall short on tasks such as Test Generation and in languages such as C++ and Java. For instance, SWE-Agent achieves a maximum of 20.9% with DeepSeek-V3.1 on Java Test Generation tasks. OmniCode aims to serve as a robust benchmark and spur the development of agents that can perform well across different aspects of software development. Code and data are available at https://github.com/seal-research/OmniCode.",
        "url": "http://arxiv.org/abs/2602.02262v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02262v1",
        "arxiv_id": "2602.02262v1",
        "authors": [
            "Atharv Sonwane",
            "Eng-Shen Tu",
            "Wei-Chung Lu",
            "Claas Beger",
            "Carter Larsen",
            "Debjit Dhar",
            "Rachel Chen",
            "Ronit Pattanayak",
            "Tuan Anh Dang",
            "Guohao Chen",
            "Gloria Geng",
            "Kevin Ellis",
            "Saikat Dutta"
        ],
        "submitted": "2026-02-02 16:04:10",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus is on software engineering and benchmarking for coding agents, which is outside your primary areas of interest."
    },
    {
        "title": "Revisiting Adaptive Rounding with Vectorized Reparameterization for LLM Quantization",
        "abstract": "Adaptive Rounding has emerged as an alternative to round-to-nearest (RTN) for post-training quantization by enabling cross-element error cancellation. Yet, dense and element-wise rounding matrices are prohibitively expensive for billion-parameter large language models (LLMs). We revisit adaptive rounding from an efficiency perspective and propose VQRound, a parameter-efficient optimization framework that reparameterizes the rounding matrix into a compact codebook. Unlike low-rank alternatives, VQRound minimizes the element-wise worst-case error under $L_\\infty$ norm, which is critical for handling heavy-tailed weight distributions in LLMs. Beyond reparameterization, we identify rounding initialization as a decisive factor and develop a lightweight end-to-end finetuning pipeline that optimizes codebooks across all layers using only 128 samples. Extensive experiments on OPT, LLaMA, LLaMA2, and Qwen3 models demonstrate that VQRound achieves better convergence than traditional adaptive rounding at the same number of steps while using as little as 0.2% of the trainable parameters. Our results show that adaptive rounding can be made both scalable and fast-fitting. The code is available at https://github.com/zhoustan/VQRound.",
        "url": "http://arxiv.org/abs/2602.02151v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02151v1",
        "arxiv_id": "2602.02151v1",
        "authors": [
            "Yuli Zhou",
            "Qingxuan Chen",
            "Luca Benini",
            "Guolei Sun",
            "Yawei Li"
        ],
        "submitted": "2026-02-02 14:27:12",
        "source": "arxiv",
        "comment": "17 pages, 6 figures, 14 tables",
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on quantization techniques for large language models, which is a topic outside of information retrieval, search technologies, and natural language processing."
    },
    {
        "title": "EvoMU: Evolutionary Machine Unlearning",
        "abstract": "Machine unlearning aims to unlearn specified training data (e.g. sensitive or copyrighted material). A prominent approach is to fine-tune an existing model with an unlearning loss that retains overall utility. The space of suitable unlearning loss functions is vast, making the search for an optimal loss function daunting. Additionally, there might not even exist a universally optimal loss function: differences in the structure and overlap of the forget and retain data can cause a loss to work well in one setting but over-unlearn or under-unlearn in another. Our approach EvoMU tackles these two challenges simultaneously. An evolutionary search procedure automatically finds task-specific losses in the vast space of possible unlearning loss functions. This allows us to find dataset-specific losses that match or outperform existing losses from the literature, without the need for a human-in-the-loop. This work is therefore an instance of automatic scientific discovery, a.k.a. an AI co-scientist. In contrast to previous AI co-scientist works, we do so on a budget: We achieve SotA results using a small 4B parameter model (Qwen3-4B-Thinking), showing the potential of AI co-scientists with limited computational resources. Our experimental evaluation shows that we surpass previous loss-based unlearning formulations on TOFU-5%, TOFU-10%, MUSE and WMDP by synthesizing novel unlearning losses. Our code is available at https://github.com/Batorskq/EvoMU.",
        "url": "http://arxiv.org/abs/2602.02139v1",
        "pdf_url": "https://arxiv.org/pdf/2602.02139v1",
        "arxiv_id": "2602.02139v1",
        "authors": [
            "Pawel Batorski",
            "Paul Swoboda"
        ],
        "submitted": "2026-02-02 14:19:13",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. The topic of machine unlearning is not a central focus of the user's interests, and the paper's focus on evolutionary search and AI co-scientists is not a primary area of research for the user."
    }
]