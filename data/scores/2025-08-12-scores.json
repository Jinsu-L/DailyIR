[
    {
        "title": "DIVER: A Multi-Stage Approach for Reasoning-intensive Information Retrieval",
        "abstract": "Retrieval-augmented generation has achieved strong performance on\nknowledge-intensive tasks where query-document relevance can be identified\nthrough direct lexical or semantic matches. However, many real-world queries\ninvolve abstract reasoning, analogical thinking, or multi-step inference, which\nexisting retrievers often struggle to capture. To address this challenge, we\npresent \\textbf{DIVER}, a retrieval pipeline tailored for reasoning-intensive\ninformation retrieval. DIVER consists of four components: document processing\nto improve input quality, LLM-driven query expansion via iterative document\ninteraction, a reasoning-enhanced retriever fine-tuned on synthetic\nmulti-domain data with hard negatives, and a pointwise reranker that combines\nLLM-assigned helpfulness scores with retrieval scores. On the BRIGHT benchmark,\nDIVER achieves state-of-the-art nDCG@10 scores of 41.6 and 28.9 on original\nqueries, consistently outperforming competitive reasoning-aware models. These\nresults demonstrate the effectiveness of reasoning-aware retrieval strategies\nin complex real-world tasks. Our code and retrieval model will be released\nsoon.",
        "url": "http://arxiv.org/abs/2508.07995v2",
        "pdf_url": "http://arxiv.org/pdf/2508.07995v2",
        "arxiv_id": "2508.07995v2",
        "authors": [
            "Meixiu Long",
            "Duolin Sun",
            "Dan Yang",
            "Junjie Wang",
            "Yue Shen",
            "Jian Wang",
            "Peng Wei",
            "Jinjie Gu",
            "Jiahai Wang"
        ],
        "submitted": "2025-08-11 13:57:49",
        "source": "arxiv",
        "comment": null,
        "score": 24,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retriever' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'pointwise' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "The paper presents a retrieval pipeline, DIVER, designed for reasoning-intensive information retrieval, which aligns with your interest in query understanding and ranking models. The use of LLM-driven query expansion and reasoning-enhanced retriever also shows relevance to your focus on deep semantic understanding and real-time relevance optimization. However, the paper's primary focus is on retrieval-augmented generation, which is not a central match to your research themes."
    },
    {
        "title": "Improving Document Retrieval Coherence for Semantically Equivalent Queries",
        "abstract": "Dense Retrieval (DR) models have proven to be effective for Document\nRetrieval and Information Grounding tasks. Usually, these models are trained\nand optimized for improving the relevance of top-ranked documents for a given\nquery. Previous work has shown that popular DR models are sensitive to the\nquery and document lexicon: small variations of it may lead to a significant\ndifference in the set of retrieved documents. In this paper, we propose a\nvariation of the Multi-Negative Ranking loss for training DR that improves the\ncoherence of models in retrieving the same documents with respect to\nsemantically similar queries. The loss penalizes discrepancies between the\ntop-k ranked documents retrieved for diverse but semantic equivalent queries.\nWe conducted extensive experiments on various datasets, MS-MARCO, Natural\nQuestions, BEIR, and TREC DL 19/20. The results show that (i) models optimizes\nby our loss are subject to lower sensitivity, and, (ii) interestingly, higher\naccuracy.",
        "url": "http://arxiv.org/abs/2508.07975v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07975v1",
        "arxiv_id": "2508.07975v1",
        "authors": [
            "Stefano Campese",
            "Alessandro Moschitti",
            "Ivano Lauriola"
        ],
        "submitted": "2025-08-11 13:34:59",
        "source": "arxiv",
        "comment": null,
        "score": 20,
        "keyword_reasons": [
            "Found 'dense retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'trec' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "The paper focuses on improving document retrieval coherence for semantically equivalent queries, which aligns with your interest in query understanding and ranking models. The use of Multi-Negative Ranking loss and experiments on various datasets also demonstrate a strong connection to your research themes in Information Retrieval and Search technologies."
    },
    {
        "title": "Data-Efficient Biomedical In-Context Learning: A Diversity-Enhanced Submodular Perspective",
        "abstract": "Recent progress in large language models (LLMs) has leveraged their\nin-context learning (ICL) abilities to enable quick adaptation to unseen\nbiomedical NLP tasks. By incorporating only a few input-output examples into\nprompts, LLMs can rapidly perform these new tasks. While the impact of these\ndemonstrations on LLM performance has been extensively studied, most existing\napproaches prioritize representativeness over diversity when selecting examples\nfrom large corpora. To address this gap, we propose Dual-Div, a\ndiversity-enhanced data-efficient framework for demonstration selection in\nbiomedical ICL. Dual-Div employs a two-stage retrieval and ranking process:\nFirst, it identifies a limited set of candidate examples from a corpus by\noptimizing both representativeness and diversity (with optional annotation for\nunlabeled data). Second, it ranks these candidates against test queries to\nselect the most relevant and non-redundant demonstrations. Evaluated on three\nbiomedical NLP tasks (named entity recognition (NER), relation extraction (RE),\nand text classification (TC)) using LLaMA 3.1 and Qwen 2.5 for inference, along\nwith three retrievers (BGE-Large, BMRetriever, MedCPT), Dual-Div consistently\noutperforms baselines-achieving up to 5% higher macro-F1 scores-while\ndemonstrating robustness to prompt permutations and class imbalance. Our\nfindings establish that diversity in initial retrieval is more critical than\nranking-stage optimization, and limiting demonstrations to 3-5 examples\nmaximizes performance efficiency.",
        "url": "http://arxiv.org/abs/2508.08140v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08140v1",
        "arxiv_id": "2508.08140v1",
        "authors": [
            "Jun Wang",
            "Zaifu Zhan",
            "Qixin Zhang",
            "Mingquan Lin",
            "Meijia Song",
            "Rui Zhang"
        ],
        "submitted": "2025-08-11 16:13:21",
        "source": "arxiv",
        "comment": null,
        "score": 14,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on biomedical in-context learning using large language models, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions NLP tasks, the context is specific to biomedical applications, and the paper's emphasis on diversity-enhanced submodular perspective is not relevant to the user's core research themes."
    },
    {
        "title": "Careful Queries, Credible Results: Teaching RAG Models Advanced Web Search Tools with Reinforcement Learning",
        "abstract": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\nintegrating up-to-date external knowledge, yet real-world web environments\npresent unique challenges. These limitations manifest as two key challenges:\npervasive misinformation in the web environment, which introduces unreliable or\nmisleading content that can degrade retrieval accuracy, and the\nunderutilization of web tools, which, if effectively employed, could enhance\nquery precision and help mitigate this noise, ultimately improving the\nretrieval results in RAG systems. To address these issues, we propose\nWebFilter, a novel RAG framework that generates source-restricted queries and\nfilters out unreliable content. This approach combines a retrieval filtering\nmechanism with a behavior- and outcome-driven reward strategy, optimizing both\nquery formulation and retrieval outcomes. Extensive experiments demonstrate\nthat WebFilter improves answer quality and retrieval precision, outperforming\nexisting RAG methods on both in-domain and out-of-domain benchmarks.",
        "url": "http://arxiv.org/abs/2508.07956v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07956v1",
        "arxiv_id": "2508.07956v1",
        "authors": [
            "Yuqin Dai",
            "Shuo Yang",
            "Guoqing Wang",
            "Yong Deng",
            "Zhanwei Zhang",
            "Jun Yin",
            "Pengyu Zeng",
            "Zhenzhe Ying",
            "Changhua Meng",
            "Can Yi",
            "Yuchen Zhou",
            "Weiqiang Wang",
            "Shuai Lu"
        ],
        "submitted": "2025-08-11 13:08:37",
        "source": "arxiv",
        "comment": null,
        "score": 12,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'web search' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper explores Retrieval-Augmented Generation (RAG) models, which is related to query understanding and ranking models. The focus on web search tools and filtering out unreliable content is also relevant to information retrieval. However, the paper's primary focus is on RAG models rather than traditional IR techniques, which limits its alignment with the user's core research themes."
    },
    {
        "title": "HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches",
        "abstract": "Recently, large reasoning models have demonstrated strong mathematical and\ncoding abilities, and deep search leverages their reasoning capabilities in\nchallenging information retrieval tasks. Existing deep search works are\ngenerally limited to a single knowledge source, either local or the Web.\nHowever, enterprises often require private deep search systems that can\nleverage search tools over both local and the Web corpus. Simply training an\nagent equipped with multiple search tools using flat reinforcement learning\n(RL) is a straightforward idea, but it has problems such as low training data\nefficiency and poor mastery of complex tools. To address the above issue, we\npropose a hierarchical agentic deep search framework, HierSearch, trained with\nhierarchical RL. At the low level, a local deep search agent and a Web deep\nsearch agent are trained to retrieve evidence from their corresponding domains.\nAt the high level, a planner agent coordinates low-level agents and provides\nthe final answer. Moreover, to prevent direct answer copying and error\npropagation, we design a knowledge refiner that filters out hallucinations and\nirrelevant evidence returned by low-level agents. Experiments show that\nHierSearch achieves better performance compared to flat RL, and outperforms\nvarious deep search and multi-source retrieval-augmented generation baselines\nin six benchmarks across general, finance, and medical domains.",
        "url": "http://arxiv.org/abs/2508.08088v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08088v1",
        "arxiv_id": "2508.08088v1",
        "authors": [
            "Jiejun Tan",
            "Zhicheng Dou",
            "Yan Yu",
            "Jiehan Cheng",
            "Qiang Ju",
            "Jian Xie",
            "Ji-Rong Wen"
        ],
        "submitted": "2025-08-11 15:31:47",
        "source": "arxiv",
        "comment": "Code and datasets are available at\n  https://github.com/plageon/HierSearch",
        "score": 9,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'web search' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper proposes a hierarchical deep search framework that integrates local and Web searches, which is related to information retrieval and search technologies. However, the focus is more on the framework's architecture and training methods rather than query understanding, ranking models, or user behavior modeling, which are key areas of interest for you."
    },
    {
        "title": "MLego: Interactive and Scalable Topic Exploration Through Model Reuse",
        "abstract": "With massive texts on social media, users and analysts often rely on topic\nmodeling techniques to quickly extract key themes and gain insights.\nTraditional topic modeling techniques, such as Latent Dirichlet Allocation\n(LDA), provide valuable insights but are computationally expensive, making them\nimpractical for real-time data analysis. Although recent advances in\ndistributed training and fast sampling methods have improved efficiency,\nreal-time topic exploration remains a significant challenge. In this paper, we\npresent MLego, an interactive query framework designed to support real-time\ntopic modeling analysis by leveraging model materialization and reuse. Instead\nof retraining models from scratch, MLego efficiently merges materialized topic\nmodels to construct approximate results at interactive speeds. To further\nenhance efficiency, we introduce a hierarchical plan search strategy for single\nqueries and an optimized query reordering technique for batch queries. We\nintegrate MLego into a visual analytics prototype system, enabling users to\nexplore large-scale textual datasets through interactive queries. Extensive\nexperiments demonstrate that MLego significantly reduces computation costs\nwhile maintaining high-quality topic modeling results. MLego enhances existing\nvisual analytics approaches, which primarily focus on user-driven topic\nmodeling, by enabling real-time, query-driven exploration. This complements\ntraditional methods and bridges the gap between scalable topic modeling and\ninteractive data analysis.",
        "url": "http://arxiv.org/abs/2508.07654v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07654v1",
        "arxiv_id": "2508.07654v1",
        "authors": [
            "Fei Ye",
            "Jiapan Liu",
            "Yinan Jing",
            "Zhenying He",
            "Weirao Wang",
            "X. Sean Wang"
        ],
        "submitted": "2025-08-11 06:06:26",
        "source": "arxiv",
        "comment": "14 pages",
        "score": 9,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a novel approach to topic modeling, focusing on scalability and real-time analysis. While it touches on query-driven exploration, it does not directly address query understanding, ranking models, or user behavior modeling, which are core aspects of your research interests. The paper's relevance is somewhat limited to your interests in information retrieval and NLP, but it does not align with your primary focus on deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Encode Me If You Can: Learning Universal User Representations via Event Sequence Autoencoding",
        "abstract": "Building universal user representations that capture the essential aspects of\nuser behavior is a crucial task for modern machine learning systems. In\nreal-world applications, a user's historical interactions often serve as the\nfoundation for solving a wide range of predictive tasks, such as churn\nprediction, recommendations, or lifetime value estimation. Using a\ntask-independent user representation that is effective across all such tasks\ncan reduce the need for task-specific feature engineering and model retraining,\nleading to more scalable and efficient machine learning pipelines. The goal of\nthe RecSys Challenge 2025 by Synerise was to develop such Universal Behavioral\nProfiles from logs of past user behavior, which included various types of\nevents such as product purchases, page views, and search queries. We propose a\nmethod that transforms the entire user interaction history into a single\nchronological sequence and trains a GRU-based autoencoder to reconstruct this\nsequence from a fixed-size vector. If the model can accurately reconstruct the\nsequence, the latent vector is expected to capture the key behavioral patterns.\nIn addition to this core model, we explored several alternative methods for\ngenerating user embeddings and combined them by concatenating their output\nvectors into a unified representation. This ensemble strategy further improved\ngeneralization across diverse downstream tasks and helped our team,\nai_lab_recsys, achieve second place in the RecSys Challenge 2025.",
        "url": "http://arxiv.org/abs/2508.07748v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07748v1",
        "arxiv_id": "2508.07748v1",
        "authors": [
            "Anton Klenitskiy",
            "Artem Fatkulin",
            "Daria Denisova",
            "Anton Pembek",
            "Alexey Vasilev"
        ],
        "submitted": "2025-08-11 08:28:01",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'user behavior' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)",
            "Found 'recsys' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores user behavior modeling and representation learning, which is somewhat related to my interests in query understanding and user behavior modeling. However, the focus on event sequence autoencoding and universal user representations is not directly aligned with my primary focus on information retrieval and ranking models."
    },
    {
        "title": "GLiClass: Generalist Lightweight Model for Sequence Classification Tasks",
        "abstract": "Classification is one of the most widespread tasks in AI applications,\nserving often as the first step in filtering, sorting, and categorizing data.\nSince modern AI systems must handle large volumes of input data and early\npipeline stages can propagate errors downstream, achieving high efficiency and\naccuracy is critical. Moreover, classification requirements can change\ndynamically based on user needs, necessitating models with strong zero-shot\ncapabilities. While generative LLMs have become mainstream for zero-shot\nclassification due to their versatility, they suffer from inconsistent\ninstruction following and computational inefficiency. Cross-encoders, commonly\nused as rerankers in RAG pipelines, face a different bottleneck: they must\nprocess text-label pairs sequentially, significantly reducing efficiency with\nlarge label sets. Embedding-based approaches offer good efficiency but struggle\nwith complex scenarios involving logical and semantic constraints. We propose\nGLiClass, a novel method that adapts the GLiNER architecture for sequence\nclassification tasks. Our approach achieves strong accuracy and efficiency\ncomparable to embedding-based methods, while maintaining the flexibility needed\nfor zero-shot and few-shot learning scenarios. Additionally, we adapted\nproximal policy optimization (PPO) for multi-label text classification,\nenabling training classifiers in data-sparse conditions or from human feedback.",
        "url": "http://arxiv.org/abs/2508.07662v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07662v1",
        "arxiv_id": "2508.07662v1",
        "authors": [
            "Ihor Stepanov",
            "Mykhailo Shtopko",
            "Dmytro Vodianytskyi",
            "Oleksandr Lukashov",
            "Alexander Yavorskyi",
            "Mykyta Yaroshenko"
        ],
        "submitted": "2025-08-11 06:22:25",
        "source": "arxiv",
        "comment": "14 pages, 7 tables, 2 figures",
        "score": 6,
        "keyword_reasons": [
            "Found 'rerank' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on sequence classification tasks, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on efficiency and accuracy, the topics of ranking models, user behavior modeling, and deep semantic understanding are not addressed."
    },
    {
        "title": "UMRE: A Unified Monotonic Transformation for Ranking Ensemble in Recommender Systems",
        "abstract": "Industrial recommender systems commonly rely on ensemble sorting (ES) to\ncombine predictions from multiple behavioral objectives. Traditionally, this\nprocess depends on manually designed nonlinear transformations (e.g.,\npolynomial or exponential functions) and hand-tuned fusion weights to balance\ncompeting goals -- an approach that is labor-intensive and frequently\nsuboptimal in achieving Pareto efficiency. In this paper, we propose a novel\nUnified Monotonic Ranking Ensemble (UMRE) framework to address the limitations\nof traditional methods in ensemble sorting. UMRE replaces handcrafted\ntransformations with Unconstrained Monotonic Neural Networks (UMNN), which\nlearn expressive, strictly monotonic functions through the integration of\npositive neural integrals. Subsequently, a lightweight ranking model is\nemployed to fuse the prediction scores, assigning personalized weights to each\nprediction objective. To balance competing goals, we further introduce a Pareto\noptimality strategy that adaptively coordinates task weights during training.\nUMRE eliminates manual tuning, maintains ranking consistency, and achieves\nfine-grained personalization. Experimental results on two public recommendation\ndatasets (Kuairand and Tenrec) and online A/B tests demonstrate impressive\nperformance and generalization capabilities.",
        "url": "http://arxiv.org/abs/2508.07613v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07613v1",
        "arxiv_id": "2508.07613v1",
        "authors": [
            "Zhengrui Xu",
            "Zhe Yang",
            "Zhengxiao Guo",
            "Shukai Liu",
            "Luocheng Lin",
            "Xiaoyan Liu",
            "Yongqi Liu",
            "Han Li"
        ],
        "submitted": "2025-08-11 04:38:57",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'personalization' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on recommender systems, which is a related topic, but it does not directly address information retrieval, query understanding, or ranking models. The abstract mentions ensemble sorting and ranking, but the emphasis is on the novel framework and its application to recommender systems, rather than the underlying principles of ranking models."
    },
    {
        "title": "Exploring Procedural Data Generation for Automatic Acoustic Guitar Fingerpicking Transcription",
        "abstract": "Automatic transcription of acoustic guitar fingerpicking performances remains\na challenging task due to the scarcity of labeled training data and legal\nconstraints connected with musical recordings. This work investigates a\nprocedural data generation pipeline as an alternative to real audio recordings\nfor training transcription models. Our approach synthesizes training data\nthrough four stages: knowledge-based fingerpicking tablature composition, MIDI\nperformance rendering, physical modeling using an extended Karplus-Strong\nalgorithm, and audio augmentation including reverb and distortion. We train and\nevaluate a CRNN-based note-tracking model on both real and synthetic datasets,\ndemonstrating that procedural data can be used to achieve reasonable\nnote-tracking results. Finetuning with a small amount of real data further\nenhances transcription accuracy, improving over models trained exclusively on\nreal recordings. These results highlight the potential of procedurally\ngenerated audio for data-scarce music information retrieval tasks.",
        "url": "http://arxiv.org/abs/2508.07987v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07987v1",
        "arxiv_id": "2508.07987v1",
        "authors": [
            "Sebastian Murgul",
            "Michael Heizmann"
        ],
        "submitted": "2025-08-11 13:52:17",
        "source": "arxiv",
        "comment": "Accepted to the 6th Conference on AI Music Creativity (AIMC), 2025",
        "score": 5,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper explores procedural data generation for automatic acoustic guitar fingerpicking transcription, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it touches on music information retrieval, the focus is on audio processing and transcription, rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Joint Transcription of Acoustic Guitar Strumming Directions and Chords",
        "abstract": "Automatic transcription of guitar strumming is an underrepresented and\nchallenging task in Music Information Retrieval (MIR), particularly for\nextracting both strumming directions and chord progressions from audio signals.\nWhile existing methods show promise, their effectiveness is often hindered by\nlimited datasets. In this work, we extend a multimodal approach to guitar\nstrumming transcription by introducing a novel dataset and a deep\nlearning-based transcription model. We collect 90 min of real-world guitar\nrecordings using an ESP32 smartwatch motion sensor and a structured recording\nprotocol, complemented by a synthetic dataset of 4h of labeled strumming audio.\nA Convolutional Recurrent Neural Network (CRNN) model is trained to detect\nstrumming events, classify their direction, and identify the corresponding\nchords using only microphone audio. Our evaluation demonstrates significant\nimprovements over baseline onset detection algorithms, with a hybrid method\ncombining synthetic and real-world data achieving the highest accuracy for both\nstrumming action detection and chord classification. These results highlight\nthe potential of deep learning for robust guitar strumming transcription and\nopen new avenues for automatic rhythm guitar analysis.",
        "url": "http://arxiv.org/abs/2508.07973v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07973v1",
        "arxiv_id": "2508.07973v1",
        "authors": [
            "Sebastian Murgul",
            "Johannes Schimper",
            "Michael Heizmann"
        ],
        "submitted": "2025-08-11 13:34:49",
        "source": "arxiv",
        "comment": "Accepted to the 26th International Society for Music Information\n  Retrieval Conference (ISMIR), 2025",
        "score": 5,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, and Natural Language Processing. The topic of automatic transcription of guitar strumming directions and chords is not related to your areas of focus, and the paper does not discuss query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Exploring the Technical Knowledge Interaction of Global Digital Humanities: Three-decade Evidence from Bibliometric-based perspectives",
        "abstract": "Digital Humanities (DH) is an interdisciplinary field that integrates\ncomputational methods with humanities scholarship to investigate innovative\ntopics. Each academic discipline follows a unique developmental path shaped by\nthe topics researchers investigate and the methods they employ. With the help\nof bibliometric analysis, most of previous studies have examined DH across\nmultiple dimensions such as research hotspots, co-author networks, and\ninstitutional rankings. However, these studies have often been limited in their\nability to provide deep insights into the current state of technological\nadvancements and topic development in DH. As a result, their conclusions tend\nto remain superficial or lack interpretability in understanding how methods and\ntopics interrelate in the field. To address this gap, this study introduced a\nnew concept of Topic-Method Composition (TMC), which refers to a hybrid\nknowledge structure generated by the co-occurrence of specific research topics\nand the corresponding method. Especially by analyzing the interaction between\nTMCs, we can see more clearly the intersection and integration of digital\ntechnology and humanistic subjects in DH. Moreover, this study developed a\nTMC-based workflow combining bibliometric analysis, topic modeling, and network\nanalysis to analyze the development characteristics and patterns of research\ndisciplines. By applying this workflow to large-scale bibliometric data, it\nenables a detailed view of the knowledge structures, providing a tool adaptable\nto other fields.",
        "url": "http://arxiv.org/abs/2508.08347v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08347v1",
        "arxiv_id": "2508.08347v1",
        "authors": [
            "Jiayi Li",
            "Chengxi Yan",
            "Yurong Zeng",
            "Zhichao Fang",
            "Huiru Wang"
        ],
        "submitted": "2025-08-11 12:27:39",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper's focus on Digital Humanities, bibliometric analysis, and topic modeling is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's technical knowledge interaction and Topic-Method Composition concept do not align with the user's expertise in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Can You Trick the Grader? Adversarial Persuasion of LLM Judges",
        "abstract": "As large language models take on growing roles as automated evaluators in\npractical settings, a critical question arises: Can individuals persuade an LLM\njudge to assign unfairly high scores? This study is the first to reveal that\nstrategically embedded persuasive language can bias LLM judges when scoring\nmathematical reasoning tasks, where correctness should be independent of\nstylistic variation. Grounded in Aristotle's rhetorical principles, we\nformalize seven persuasion techniques (Majority, Consistency, Flattery,\nReciprocity, Pity, Authority, Identity) and embed them into otherwise identical\nresponses. Across six math benchmarks, we find that persuasive language leads\nLLM judges to assign inflated scores to incorrect solutions, by up to 8% on\naverage, with Consistency causing the most severe distortion. Notably,\nincreasing model size does not substantially mitigate this vulnerability.\nFurther analysis demonstrates that combining multiple persuasion techniques\namplifies the bias, and pairwise evaluation is likewise susceptible. Moreover,\nthe persuasive effect persists under counter prompting strategies, highlighting\na critical vulnerability in LLM-as-a-Judge pipelines and underscoring the need\nfor robust defenses against persuasion-based attacks.",
        "url": "http://arxiv.org/abs/2508.07805v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07805v1",
        "arxiv_id": "2508.07805v1",
        "authors": [
            "Yerin Hwang",
            "Dongryeol Lee",
            "Taegwan Kang",
            "Yongil Kim",
            "Kyomin Jung"
        ],
        "submitted": "2025-08-11 09:45:02",
        "source": "arxiv",
        "comment": "19 pages, 8 figures",
        "score": 5,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus on large language models and persuasion techniques is outside the scope of the user's research interests."
    },
    {
        "title": "Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment",
        "abstract": "Alignment methodologies have emerged as a critical pathway for enhancing\nlanguage model alignment capabilities. While SFT (supervised fine-tuning)\naccelerates convergence through direct token-level loss intervention, its\nefficacy is constrained by offline policy trajectory. In contrast,\nRL(reinforcement learning) facilitates exploratory policy optimization, but\nsuffers from low sample efficiency and stringent dependency on high-quality\nbase models. To address these dual challenges, we propose GRAO (Group Relative\nAlignment Optimization), a unified framework that synergizes the respective\nstrengths of SFT and RL through three key innovations: 1) A multi-sample\ngeneration strategy enabling comparative quality assessment via reward\nfeedback; 2) A novel Group Direct Alignment Loss formulation leveraging\nintra-group relative advantage weighting; 3) Reference-aware parameter updates\nguided by pairwise preference dynamics. Our theoretical analysis establishes\nGRAO's convergence guarantees and sample efficiency advantages over\nconventional approaches. Comprehensive evaluations across complex human\nalignment tasks demonstrate GRAO's superior performance, achieving\n57.70\\%,17.65\\% 7.95\\% and 5.18\\% relative improvements over SFT, DPO, PPO and\nGRPO baselines respectively. This work provides both a theoretically grounded\nalignment framework and empirical evidence for efficient capability evolution\nin language models.",
        "url": "http://arxiv.org/abs/2508.07750v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07750v1",
        "arxiv_id": "2508.07750v1",
        "authors": [
            "Haowen Wang",
            "Yun Yue",
            "Zhiling Ye",
            "Shuowen Zhang",
            "Lei Fan",
            "Jiaxin Liang",
            "Jiadi Jiang",
            "Cheng Wei",
            "Jingyuan Deng",
            "Xudong Han",
            "Ji Li",
            "Chunxiao Guo",
            "Peng Wei",
            "Jian Wang",
            "Jinjie Gu"
        ],
        "submitted": "2025-08-11 08:28:47",
        "source": "arxiv",
        "comment": "12 pages, 5 figures, 7 tables",
        "score": 5,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on language model alignment, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and query understanding. While the paper mentions reinforcement learning, which is a related topic, the context is different and the paper's contributions do not seem to have a direct impact on the user's research areas."
    },
    {
        "title": "Jinx: Unlimited LLMs for Probing Alignment Failures",
        "abstract": "Unlimited, or so-called helpful-only language models are trained without\nsafety alignment constraints and never refuse user queries. They are widely\nused by leading AI companies as internal tools for red teaming and alignment\nevaluation. For example, if a safety-aligned model produces harmful outputs\nsimilar to an unlimited model, this indicates alignment failures that require\nfurther attention. Despite their essential role in assessing alignment, such\nmodels are not available to the research community.\n  We introduce Jinx, a helpful-only variant of popular open-weight LLMs. Jinx\nresponds to all queries without refusals or safety filtering, while preserving\nthe base model's capabilities in reasoning and instruction following. It\nprovides researchers with an accessible tool for probing alignment failures,\nevaluating safety boundaries, and systematically studying failure modes in\nlanguage model safety.",
        "url": "http://arxiv.org/abs/2508.08243v2",
        "pdf_url": "http://arxiv.org/pdf/2508.08243v2",
        "arxiv_id": "2508.08243v2",
        "authors": [
            "Jiahao Zhao",
            "Liwei Dong"
        ],
        "submitted": "2025-08-11 17:56:06",
        "source": "arxiv",
        "comment": "https://huggingface.co/Jinx-org",
        "score": 4,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on language models, specifically introducing a new variant called Jinx, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on safety alignment and evaluation, the topic is not aligned with the user's primary research interests in IR and NLP."
    },
    {
        "title": "REX-RAG: Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation",
        "abstract": "Reinforcement learning (RL) is emerging as a powerful paradigm for enabling\nlarge language models (LLMs) to perform complex reasoning tasks. Recent\nadvances indicate that integrating RL with retrieval-augmented generation (RAG)\nallows LLMs to dynamically incorporate external knowledge, leading to more\ninformed and robust decision making. However, we identify a critical challenge\nduring policy-driven trajectory sampling: LLMs are frequently trapped in\nunproductive reasoning paths, which we refer to as \"dead ends\", committing to\noverconfident yet incorrect conclusions. This severely hampers exploration and\nundermines effective policy optimization. To address this challenge, we propose\nREX-RAG (Reasoning Exploration with Policy Correction in Retrieval-Augmented\nGeneration), a novel framework that explores alternative reasoning paths while\nmaintaining rigorous policy learning through principled distributional\ncorrections. Our approach introduces two key innovations: (1) Mixed Sampling\nStrategy, which combines a novel probe sampling method with exploratory prompts\nto escape dead ends; and (2) Policy Correction Mechanism, which employs\nimportance sampling to correct distribution shifts induced by mixed sampling,\nthereby mitigating gradient estimation bias. We evaluate it on seven\nquestion-answering benchmarks, and the experimental results show that REX-RAG\nachieves average performance gains of 5.1% on Qwen2.5-3B and 3.6% on Qwen2.5-7B\nover strong baselines, demonstrating competitive results across multiple\ndatasets. The code is publicly available at https://github.com/MiliLab/REX-RAG.",
        "url": "http://arxiv.org/abs/2508.08149v2",
        "pdf_url": "http://arxiv.org/pdf/2508.08149v2",
        "arxiv_id": "2508.08149v2",
        "authors": [
            "Wentao Jiang",
            "Xiang Feng",
            "Zengmao Wang",
            "Yong Luo",
            "Pingbo Xu",
            "Zhe Chen",
            "Bo Du",
            "Jing Zhang"
        ],
        "submitted": "2025-08-11 16:25:25",
        "source": "arxiv",
        "comment": "17 pages, 4 figures; updated references",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a framework for reasoning exploration in retrieval-augmented generation, which is a novel application of reinforcement learning in NLP. While it touches on some aspects of query understanding and ranking models, the focus is on reasoning and generation rather than search and retrieval. The paper's relevance to information retrieval is limited, and it does not directly address user behavior modeling or click models."
    },
    {
        "title": "WideSearch: Benchmarking Agentic Broad Info-Seeking",
        "abstract": "From professional research to everyday planning, many tasks are bottlenecked\nby wide-scale information seeking, which is more repetitive than cognitively\ncomplex. With the rapid development of Large Language Models (LLMs), automated\nsearch agents powered by LLMs offer a promising solution to liberate humans\nfrom this tedious work. However, the capability of these agents to perform such\n\"wide-context\" collection reliably and completely remains largely unevaluated\ndue to a lack of suitable benchmarks. To bridge this gap, we introduce\nWideSearch, a new benchmark engineered to evaluate agent reliability on these\nlarge-scale collection tasks. The benchmark features 200 manually curated\nquestions (100 in English, 100 in Chinese) from over 15 diverse domains,\ngrounded in real user queries. Each task requires agents to collect large-scale\natomic information, which could be verified one by one objectively, and arrange\nit into a well-organized output. A rigorous five-stage quality control pipeline\nensures the difficulty, completeness, and verifiability of the dataset. We\nbenchmark over 10 state-of-the-art agentic search systems, including\nsingle-agent, multi-agent frameworks, and end-to-end commercial systems. Most\nsystems achieve overall success rates near 0\\%, with the best performer\nreaching just 5\\%. However, given sufficient time, cross-validation by multiple\nhuman testers can achieve a near 100\\% success rate. These results demonstrate\nthat present search agents have critical deficiencies in large-scale\ninformation seeking, underscoring urgent areas for future research and\ndevelopment in agentic search. Our dataset, evaluation pipeline, and benchmark\nresults have been publicly released at https://widesearch-seed.github.io/",
        "url": "http://arxiv.org/abs/2508.07999v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07999v1",
        "arxiv_id": "2508.07999v1",
        "authors": [
            "Ryan Wong",
            "Jiawei Wang",
            "Junjie Zhao",
            "Li Chen",
            "Yan Gao",
            "Long Zhang",
            "Xuan Zhou",
            "Zuo Wang",
            "Kai Xiang",
            "Ge Zhang",
            "Wenhao Huang",
            "Yang Wang",
            "Ke Wang"
        ],
        "submitted": "2025-08-11 14:03:09",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper WideSearch: Benchmarking Agentic Broad Info-Seeking is somewhat related to your research interests in Information Retrieval and Search technologies, particularly in query understanding and ranking models. However, the focus on agentic search and large-scale information seeking is not directly aligned with your primary interests in user behavior modeling and real-time relevance optimization."
    },
    {
        "title": "Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL",
        "abstract": "Recent advancements in LLM-based agents have demonstrated remarkable\ncapabilities in handling complex, knowledge-intensive tasks by integrating\nexternal tools. Among diverse choices of tools, search tools play a pivotal\nrole in accessing vast external knowledge. However, open-source agents still\nfall short of achieving expert-level Search Intelligence, the ability to\nresolve ambiguous queries, generate precise searches, analyze results, and\nconduct thorough exploration. Existing approaches fall short in scalability,\nefficiency, and data quality. For example, small turn limits in existing online\nRL methods, e.g. <=10, restrict complex strategy learning. This paper\nintroduces ASearcher, an open-source project for large-scale RL training of\nsearch agents. Our key contributions include: (1) Scalable fully asynchronous\nRL training that enables long-horizon search while maintaining high training\nefficiency. (2) A prompt-based LLM agent that autonomously synthesizes\nhigh-quality and challenging QAs, creating a large-scale QA dataset. Through RL\ntraining, our prompt-based QwQ-32B agent achieves substantial improvements,\nwith 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our\nagent exhibits extreme long-horizon search, with tool calls exceeding 40 turns\nand output tokens exceeding 150k during training time. With a simple agent\ndesign and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on\nxBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We\nopen-source our models, training data, and codes in\nhttps://github.com/inclusionAI/ASearcher.",
        "url": "http://arxiv.org/abs/2508.07976v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07976v1",
        "arxiv_id": "2508.07976v1",
        "authors": [
            "Jiaxuan Gao",
            "Wei Fu",
            "Minyang Xie",
            "Shusheng Xu",
            "Chuyi He",
            "Zhiyu Mei",
            "Banghua Zhu",
            "Yi Wu"
        ],
        "submitted": "2025-08-11 13:36:57",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores large-scale asynchronous RL training for search agents, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on long-horizon search and QA dataset creation is not directly aligned with my primary research interests in real-time relevance optimization and user behavior modeling."
    },
    {
        "title": "Meta Off-Policy Estimation",
        "abstract": "Off-policy estimation (OPE) methods enable unbiased offline evaluation of\nrecommender systems, directly estimating the online reward some target policy\nwould have obtained, from offline data and with statistical guarantees. The\ntheoretical elegance of the framework combined with practical successes have\nled to a surge of interest, with many competing estimators now available to\npractitioners and researchers. Among these, Doubly Robust methods provide a\nprominent strategy to combine value- and policy-based estimators.\n  In this work, we take an alternative perspective to combine a set of OPE\nestimators and their associated confidence intervals into a single, more\naccurate estimate. Our approach leverages a correlated fixed-effects\nmeta-analysis framework, explicitly accounting for dependencies among\nestimators that arise due to shared data. This yields a best linear unbiased\nestimate (BLUE) of the target policy's value, along with an appropriately\nconservative confidence interval that reflects inter-estimator correlation. We\nvalidate our method on both simulated and real-world data, demonstrating\nimproved statistical efficiency over existing individual estimators.",
        "url": "http://arxiv.org/abs/2508.07914v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07914v1",
        "arxiv_id": "2508.07914v1",
        "authors": [
            "Olivier Jeunen"
        ],
        "submitted": "2025-08-11 12:31:13",
        "source": "arxiv",
        "comment": "To appear in the Nineteenth ACM Conference on Recommender Systems\n  (RecSys '25)",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on off-policy estimation for recommender systems, which is not directly related to the user's primary research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. While the paper touches on statistical estimation and confidence intervals, it does not address the user's specific areas of interest, such as deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Orthogonal Low Rank Embedding Stabilization",
        "abstract": "The instability of embedding spaces across model retraining cycles presents\nsignificant challenges to downstream applications using user or item embeddings\nderived from recommendation systems as input features. This paper introduces a\nnovel orthogonal low-rank transformation methodology designed to stabilize the\nuser/item embedding space, ensuring consistent embedding dimensions across\nretraining sessions. Our approach leverages a combination of efficient low-rank\nsingular value decomposition and orthogonal Procrustes transformation to map\nembeddings into a standardized space. This transformation is computationally\nefficient, lossless, and lightweight, preserving the dot product and inference\nquality while reducing operational burdens. Unlike existing methods that modify\ntraining objectives or embedding structures, our approach maintains the\nintegrity of the primary model application and can be seamlessly integrated\nwith other stabilization techniques.",
        "url": "http://arxiv.org/abs/2508.07574v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07574v1",
        "arxiv_id": "2508.07574v1",
        "authors": [
            "Kevin Zielnicki",
            "Ko-Jen Hsiao"
        ],
        "submitted": "2025-08-11 03:15:51",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on recommendation systems and embedding stabilization, which is not directly related to the user's primary research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. While the paper touches on embedding spaces, it does not address the user's specific areas of interest in deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models",
        "abstract": "Large Language Models (LLMs) have shown remarkable performance across a wide\nrange of natural language processing tasks. Quality Estimation (QE) for Machine\nTranslation (MT), which assesses the quality of a source-target pair without\nrelying on reference translations, remains a challenging cross-lingual task for\nLLMs. The challenges stem from the inherent limitations of existing LLM-based\nQE systems, which are pre-trained for causal language modelling rather than\nregression-specific tasks, further elevated by the presence of low-resource\nlanguages given pre-training data distribution. This paper introduces ALOPE, an\nadaptive layer-optimization framework designed to enhance LLM-based QE by\nrestructuring Transformer representations through layer-wise adaptation for\nimproved regression-based prediction. Our framework integrates low-rank\nadapters (LoRA) with regression task heads, leveraging selected pre-trained\nTransformer layers for improved cross-lingual alignment. In addition to the\nlayer-specific adaptation, ALOPE introduces two strategies-dynamic weighting,\nwhich adaptively combines representations from multiple layers, and multi-head\nregression, which aggregates regression losses from multiple heads for QE. Our\nframework shows improvements over various existing LLM-based QE approaches.\nEmpirical evidence suggests that intermediate Transformer layers in LLMs\nprovide contextual representations that are more aligned with the cross-lingual\nnature of the QE task. We make resultant models and framework code publicly\navailable for further research, also allowing existing LLM-based MT frameworks\nto be scaled with QE capabilities.",
        "url": "http://arxiv.org/abs/2508.07484v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07484v1",
        "arxiv_id": "2508.07484v1",
        "authors": [
            "Archchana Sindhujan",
            "Shenbin Qian",
            "Chan Chi Chun Matthew",
            "Constantin Orasan",
            "Diptesh Kanojia"
        ],
        "submitted": "2025-08-10 20:59:44",
        "source": "arxiv",
        "comment": "Accepted to COLM 2025 Conference",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Large Language Models (LLMs) for Quality Estimation (QE) in Machine Translation, which is not directly related to Information Retrieval or Search technologies. While it touches on Transformer representations and layer adaptation, the context is more relevant to NLP and MT, rather than IR or query understanding."
    },
    {
        "title": "Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning",
        "abstract": "Reinforcement learning for LLM reasoning has rapidly emerged as a prominent\nresearch area, marked by a significant surge in related studies on both\nalgorithmic innovations and practical applications. Despite this progress,\nseveral critical challenges remain, including the absence of standardized\nguidelines for employing RL techniques and a fragmented understanding of their\nunderlying mechanisms. Additionally, inconsistent experimental settings,\nvariations in training data, and differences in model initialization have led\nto conflicting conclusions, obscuring the key characteristics of these\ntechniques and creating confusion among practitioners when selecting\nappropriate techniques. This paper systematically reviews widely adopted RL\ntechniques through rigorous reproductions and isolated evaluations within a\nunified open-source framework. We analyze the internal mechanisms, applicable\nscenarios, and core principles of each technique through fine-grained\nexperiments, including datasets of varying difficulty, model sizes, and\narchitectures. Based on these insights, we present clear guidelines for\nselecting RL techniques tailored to specific setups, and provide a reliable\nroadmap for practitioners navigating the RL for the LLM domain. Finally, we\nreveal that a minimalist combination of two techniques can unlock the learning\ncapability of critic-free policies using vanilla PPO loss. The results\ndemonstrate that our simple combination consistently improves performance,\nsurpassing strategies like GRPO and DAPO.",
        "url": "http://arxiv.org/abs/2508.08221v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08221v1",
        "arxiv_id": "2508.08221v1",
        "authors": [
            "Zihe Liu",
            "Jiashun Liu",
            "Yancheng He",
            "Weixun Wang",
            "Jiaheng Liu",
            "Ling Pan",
            "Xinyu Hu",
            "Shaopan Xiong",
            "Ju Huang",
            "Jian Hu",
            "Shengyi Huang",
            "Siran Yang",
            "Jiamang Wang",
            "Wenbo Su",
            "Bo Zheng"
        ],
        "submitted": "2025-08-11 17:39:45",
        "source": "arxiv",
        "comment": "26 pages, 21 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The focus on Reinforcement Learning for Language Model Reasoning is outside the user's primary area of interest, and the techniques discussed are not applicable to the user's domain."
    },
    {
        "title": "Multi-modal Adaptive Mixture of Experts for Cold-start Recommendation",
        "abstract": "Recommendation systems have faced significant challenges in cold-start\nscenarios, where new items with a limited history of interaction need to be\neffectively recommended to users. Though multimodal data (e.g., images, text,\naudio, etc.) offer rich information to address this issue, existing approaches\noften employ simplistic integration methods such as concatenation, average\npooling, or fixed weighting schemes, which fail to capture the complex\nrelationships between modalities. Our study proposes a novel Mixture of Experts\n(MoE) framework for multimodal cold-start recommendation, named MAMEX, which\ndynamically leverages latent representation from different modalities. MAMEX\nutilizes modality-specific expert networks and introduces a learnable gating\nmechanism that adaptively weights the contribution of each modality based on\nits content characteristics. This approach enables MAMEX to emphasize the most\ninformative modalities for each item while maintaining robustness when certain\nmodalities are less relevant or missing. Extensive experiments on benchmark\ndatasets show that MAMEX outperforms state-of-the-art methods in cold-start\nscenarios, with superior accuracy and adaptability. For reproducibility, the\ncode has been made available on Github https://github.com/L2R-UET/MAMEX.",
        "url": "http://arxiv.org/abs/2508.08042v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08042v1",
        "arxiv_id": "2508.08042v1",
        "authors": [
            "Van-Khang Nguyen",
            "Duc-Hoang Pham",
            "Huy-Son Nguyen",
            "Cam-Van Thi Nguyen",
            "Hoang-Quynh Le",
            "Duc-Trong Le"
        ],
        "submitted": "2025-08-11 14:47:14",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on recommender systems, specifically cold-start recommendation, using multimodal data. While it employs a novel approach, it does not address query understanding, ranking models, or user behavior modeling, which are core aspects of Information Retrieval and Search technologies. The paper's relevance to the user's research interests is limited."
    },
    {
        "title": "LoSemB: Logic-Guided Semantic Bridging for Inductive Tool Retrieval",
        "abstract": "Tool learning has emerged as a promising paradigm for large language models\n(LLMs) to solve many real-world tasks. Nonetheless, with the tool repository\nrapidly expanding, it is impractical to contain all tools within the limited\ninput length of LLMs. To alleviate these issues, researchers have explored\nincorporating a tool retrieval module to select the most relevant tools or\nrepresent tools as unique tokens within LLM parameters. However, most\nstate-of-the-art methods are under transductive settings, assuming all tools\nhave been observed during training. Such a setting deviates from reality as the\nreal-world tool repository is evolving and incorporates new tools frequently.\nWhen dealing with these unseen tools, which refer to tools not encountered\nduring the training phase, these methods are limited by two key issues,\nincluding the large distribution shift and the vulnerability of\nsimilarity-based retrieval. To this end, inspired by human cognitive processes\nof mastering unseen tools through discovering and applying the logical\ninformation from prior experience, we introduce a novel Logic-Guided Semantic\nBridging framework for inductive tool retrieval, namely, LoSemB, which aims to\nmine and transfer latent logical information for inductive tool retrieval\nwithout costly retraining. Specifically, LoSemB contains a logic-based\nembedding alignment module to mitigate distribution shifts and implements a\nrelational augmented retrieval mechanism to reduce the vulnerability of\nsimilarity-based retrieval. Extensive experiments demonstrate that LoSemB\nachieves advanced performance in inductive settings while maintaining desirable\neffectiveness in the transductive setting.",
        "url": "http://arxiv.org/abs/2508.07690v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07690v1",
        "arxiv_id": "2508.07690v1",
        "authors": [
            "Luyao Zhuang",
            "Qinggang Zhang",
            "Huachi Zhou",
            "Juhua Liu",
            "Qing Li",
            "Xiao Huang"
        ],
        "submitted": "2025-08-11 07:07:18",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on tool retrieval, which is not directly related to information retrieval or search technologies. While it mentions language models and retrieval, the context is different from query understanding, ranking models, and user behavior modeling. The paper's emphasis on logic-guided semantic bridging and relational augmented retrieval is not directly applicable to the user's research interests."
    },
    {
        "title": "Conversational DNA: A New Visual Language for Understanding Dialogue Structure in Human and AI",
        "abstract": "What if the patterns hidden within dialogue reveal more about communication\nthan the words themselves? We introduce Conversational DNA, a novel visual\nlanguage that treats any dialogue -- whether between humans, between human and\nAI, or among groups -- as a living system with interpretable structure that can\nbe visualized, compared, and understood. Unlike traditional conversation\nanalysis that reduces rich interaction to statistical summaries, our approach\nreveals the temporal architecture of dialogue through biological metaphors.\nLinguistic complexity flows through strand thickness, emotional trajectories\ncascade through color gradients, conversational relevance forms through\nconnecting elements, and topic coherence maintains structural integrity through\nhelical patterns. Through exploratory analysis of therapeutic conversations and\nhistorically significant human-AI dialogues, we demonstrate how this\nvisualization approach reveals interaction patterns that traditional methods\nmiss. Our work contributes a new creative framework for understanding\ncommunication that bridges data visualization, human-computer interaction, and\nthe fundamental question of what makes dialogue meaningful in an age where\nhumans increasingly converse with artificial minds.",
        "url": "http://arxiv.org/abs/2508.07520v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07520v1",
        "arxiv_id": "2508.07520v1",
        "authors": [
            "Baihan Lin"
        ],
        "submitted": "2025-08-11 00:43:35",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper's focus on dialogue structure and visual language is not directly related to the user's interests in Information Retrieval, Search technologies, and query understanding. While it touches on human-computer interaction, it does not address ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest for the user."
    },
    {
        "title": "Word Clouds as Common Voices: LLM-Assisted Visualization of Participant-Weighted Themes in Qualitative Interviews",
        "abstract": "Word clouds are a common way to summarize qualitative interviews, yet\ntraditional frequency-based methods often fail in conversational contexts: they\nsurface filler words, ignore paraphrase, and fragment semantically related\nideas. This limits their usefulness in early-stage analysis, when researchers\nneed fast, interpretable overviews of what participant actually said. We\nintroduce ThemeClouds, an open-source visualization tool that uses large\nlanguage models (LLMs) to generate thematic, participant-weighted word clouds\nfrom dialogue transcripts. The system prompts an LLM to identify concept-level\nthemes across a corpus and then counts how many unique participants mention\neach topic, yielding a visualization grounded in breadth of mention rather than\nraw term frequency. Researchers can customize prompts and visualization\nparameters, providing transparency and control. Using interviews from a user\nstudy comparing five recording-device configurations (31 participants; 155\ntranscripts, Whisper ASR), our approach surfaces more actionable device\nconcerns than frequency clouds and topic-modeling baselines (e.g., LDA,\nBERTopic). We discuss design trade-offs for integrating LLM assistance into\nqualitative workflows, implications for interpretability and researcher agency,\nand opportunities for interactive analyses such as per-condition contrasts\n(``diff clouds'').",
        "url": "http://arxiv.org/abs/2508.07517v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07517v1",
        "arxiv_id": "2508.07517v1",
        "authors": [
            "Joseph T. Colonel",
            "Baihan Lin"
        ],
        "submitted": "2025-08-11 00:27:52",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on qualitative interviews and word clouds, which is not directly related to information retrieval, search technologies, or query understanding. While it uses language models, the application is in a different domain and does not address ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest."
    },
    {
        "title": "Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models",
        "abstract": "Large Language Models (LLMs) are prone to generating fluent but incorrect\ncontent, known as confabulation, which poses increasing risks in multi-turn or\nagentic applications where outputs may be reused as context. In this work, we\ninvestigate how in-context information influences model behavior and whether\nLLMs can identify their unreliable responses. We propose a reliability\nestimation that leverages token-level uncertainty to guide the aggregation of\ninternal model representations. Specifically, we compute aleatoric and\nepistemic uncertainty from output logits to identify salient tokens and\naggregate their hidden states into compact representations for response-level\nreliability prediction. Through controlled experiments on open QA benchmarks,\nwe find that correct in-context information improves both answer accuracy and\nmodel confidence, while misleading context often induces confidently incorrect\nresponses, revealing a misalignment between uncertainty and correctness. Our\nprobing-based method captures these shifts in model behavior and improves the\ndetection of unreliable outputs across multiple open-source LLMs. These results\nunderscore the limitations of direct uncertainty signals and highlight the\npotential of uncertainty-guided probing for reliability-aware generation.",
        "url": "http://arxiv.org/abs/2508.08139v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08139v1",
        "arxiv_id": "2508.08139v1",
        "authors": [
            "Tianyi Zhou",
            "Johanne Medina",
            "Sanjay Chawla"
        ],
        "submitted": "2025-08-11 16:12:36",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the reliability of Large Language Models (LLMs) and proposes a method to detect unreliable outputs. While it touches on uncertainty and confidence, which are related to query understanding and ranking models, the focus is on language models and reliability estimation, which is not directly aligned with my primary research interests in Information Retrieval and Search technologies."
    },
    {
        "title": "From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations",
        "abstract": "Event logs reflect the behavior of business processes that are mapped in\norganizational information systems. Predictive process monitoring (PPM)\ntransforms these data into value by creating process-related predictions that\nprovide the insights required for proactive interventions at process runtime.\nExisting PPM techniques require sufficient amounts of event data or other\nrelevant resources that might not be readily available, preventing some\norganizations from utilizing PPM. The transfer learning-based PPM technique\npresented in this paper allows organizations without suitable event data or\nother relevant resources to implement PPM for effective decision support. The\ntechnique is instantiated in two real-life use cases, based on which numerical\nexperiments are performed using event logs for IT service management processes\nin an intra- and inter-organizational setting. The results of the experiments\nsuggest that knowledge of one business process can be transferred to a similar\nbusiness process in the same or a different organization to enable effective\nPPM in the target context. With the proposed technique, organizations can\nbenefit from transfer learning in an intra- and inter-organizational setting,\nwhere resources like pre-trained models are transferred within and across\norganizational boundaries.",
        "url": "http://arxiv.org/abs/2508.08061v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08061v1",
        "arxiv_id": "2508.08061v1",
        "authors": [
            "Sven Weinzierl",
            "Sandra Zilker",
            "Annina Liessmann",
            "Martin Käppel",
            "Weixin Wang",
            "Martin Matzner"
        ],
        "submitted": "2025-08-11 15:03:50",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on predictive process monitoring in organizations, leveraging transfer learning, which is not directly related to information retrieval, search technologies, or natural language processing. While it touches on data analysis, it does not involve query understanding, ranking models, or user behavior modeling, making it irrelevant to the user's primary research interests."
    },
    {
        "title": "Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning",
        "abstract": "Recent advancements in large language models, multimodal large language\nmodels, and large audio language models (LALMs) have significantly improved\ntheir reasoning capabilities through reinforcement learning with rule-based\nrewards. However, the explicit reasoning process has yet to show significant\nbenefits for audio question answering, and effectively leveraging deep\nreasoning remains an open challenge, with LALMs still falling short of\nhuman-level auditory-language reasoning. To address these limitations, we\npropose Audio-Thinker, a reinforcement learning framework designed to enhance\nthe reasoning capabilities of LALMs, with a focus on improving adaptability,\nconsistency, and effectiveness. Our approach introduces an adaptive think\naccuracy reward, enabling the model to adjust its reasoning strategies based on\ntask complexity dynamically. Furthermore, we incorporate an external reward\nmodel to evaluate the overall consistency and quality of the reasoning process,\ncomplemented by think-based rewards that help the model distinguish between\nvalid and flawed reasoning paths during training. Experimental results\ndemonstrate that our Audio-Thinker model outperforms existing\nreasoning-oriented LALMs across various benchmark tasks, exhibiting superior\nreasoning and generalization capabilities.",
        "url": "http://arxiv.org/abs/2508.08039v2",
        "pdf_url": "http://arxiv.org/pdf/2508.08039v2",
        "arxiv_id": "2508.08039v2",
        "authors": [
            "Shu Wu",
            "Chenxing Li",
            "Wenfu Wang",
            "Hao Zhang",
            "Hualei Wang",
            "Meng Yu",
            "Dong Yu"
        ],
        "submitted": "2025-08-11 14:41:10",
        "source": "arxiv",
        "comment": "preprint",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on audio language models and reinforcement learning, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on reasoning and modeling, the context is specific to audio and language, making it less relevant to the user's primary research interests."
    },
    {
        "title": "Progressive Depth Up-scaling via Optimal Transport",
        "abstract": "Scaling Large Language Models (LLMs) yields performance gains but incurs\nsubstantial training costs. Depth up-scaling offers training efficiency by\nadding new layers to pre-trained models. However, most existing methods copy or\naverage weights from base layers, neglecting neuron permutation differences.\nThis limitation can potentially cause misalignment that harms performance.\nInspired by applying Optimal Transport (OT) for neuron alignment, we propose\nOptimal Transport Depth Up-Scaling (OpT-DeUS). OpT-DeUS aligns and fuses\nTransformer blocks in adjacent base layers via OT for new layer creation, to\nmitigate neuron permutation mismatch between layers. OpT-DeUS achieves better\noverall performance and offers improved training efficiency than existing\nmethods for continual pre-training and supervised fine-tuning across different\nmodel sizes. To further evaluate the impact of interpolation positions, our\nextensive analysis shows that inserting new layers closer to the top results in\nhigher training efficiency due to shorter back-propagation time while obtaining\nadditional performance gains.",
        "url": "http://arxiv.org/abs/2508.08011v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08011v1",
        "arxiv_id": "2508.08011v1",
        "authors": [
            "Mingzi Cao",
            "Xi Wang",
            "Nikolaos Aletras"
        ],
        "submitted": "2025-08-11 14:15:33",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on scaling large language models and proposing a new method for neuron alignment, which is not directly related to query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Early Explorations of Recommender Systems for Physical Activity and Well-being",
        "abstract": "As recommender systems increasingly guide physical actions, often through\nwearables and coaching tools, new challenges arise around how users interpret,\ntrust, and respond to this advice. This paper introduces a conceptual framework\nfor tangible recommendations that influence users' bodies, routines, and\nwell-being. We describe three design dimensions: trust and interpretation,\nintent alignment, and consequence awareness. These highlight key limitations in\napplying conventional recommender logic to embodied settings. Through examples\nand design reflections, we outline how future systems can support long-term\nwell-being, behavioral alignment, and socially responsible personalization.",
        "url": "http://arxiv.org/abs/2508.07980v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07980v1",
        "arxiv_id": "2508.07980v1",
        "authors": [
            "Alan Said"
        ],
        "submitted": "2025-08-11 13:38:58",
        "source": "arxiv",
        "comment": "Second International Workshop on Recommender Systems for\n  Sustainability and Social Good (RecSoGood) in conjunction with ACM RecSys\n  2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on recommender systems for physical activity and well-being, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although the paper touches on user behavior modeling, it is not specifically related to query understanding, ranking models, or click models."
    },
    {
        "title": "Tailored Emotional LLM-Supporter: Enhancing Cultural Sensitivity",
        "abstract": "Large language models (LLMs) show promise in offering emotional support and\ngenerating empathetic responses for individuals in distress, but their ability\nto deliver culturally sensitive support remains underexplored due to lack of\nresources. In this work, we introduce CultureCare, the first dataset designed\nfor this task, spanning four cultures and including 1729 distress messages,\n1523 cultural signals, and 1041 support strategies with fine-grained emotional\nand cultural annotations. Leveraging CultureCare, we (i) develop and test four\nadaptation strategies for guiding three state-of-the-art LLMs toward culturally\nsensitive responses; (ii) conduct comprehensive evaluations using LLM judges,\nin-culture human annotators, and clinical psychologists; (iii) show that\nadapted LLMs outperform anonymous online peer responses, and that simple\ncultural role-play is insufficient for cultural sensitivity; and (iv) explore\nthe application of LLMs in clinical training, where experts highlight their\npotential in fostering cultural competence in future therapists.",
        "url": "http://arxiv.org/abs/2508.07902v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07902v1",
        "arxiv_id": "2508.07902v1",
        "authors": [
            "Chen Cecilia Liu",
            "Hiba Arnaout",
            "Nils Kovačić",
            "Dana Atzil-Slonim",
            "Iryna Gurevych"
        ],
        "submitted": "2025-08-11 12:17:58",
        "source": "arxiv",
        "comment": "Under review; joint first authors",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on large language models and emotional support, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on cultural sensitivity, it does not address ranking models, user behavior modeling, or real-time relevance optimization, which are core areas of interest for your research."
    },
    {
        "title": "Maximizing GPU Efficiency via Optimal Adapter Caching: An Analytical Approach for Multi-Tenant LLM Serving",
        "abstract": "Serving LLM adapters has gained significant attention as an effective\napproach to adapt general-purpose language models to diverse, task-specific use\ncases. However, serving a wide range of adapters introduces several and\nsubstantial overheads, leading to performance degradation and challenges in\noptimal placement. To address these challenges, we present an analytical,\nAI-driven pipeline that accurately determines the optimal allocation of\nadapters in single-node setups. This allocation maximizes performance,\neffectively using GPU resources, while preventing request starvation.\nCrucially, the proposed allocation is given based on current workload patterns.\nThese insights in single-node setups can be leveraged in multi-replica\ndeployments for overall placement, load balancing and server configuration,\nultimately enhancing overall performance and improving resource efficiency. Our\napproach builds on an in-depth analysis of LLM adapter serving, accounting for\noverheads and performance variability, and includes the development of the\nfirst Digital Twin capable of replicating online LLM-adapter serving systems\nwith matching key performance metrics. The experimental results demonstrate\nthat the Digital Twin achieves a SMAPE difference of no more than 5.5% in\nthroughput compared to real results, and the proposed pipeline accurately\npredicts the optimal placement with minimal latency.",
        "url": "http://arxiv.org/abs/2508.08343v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08343v1",
        "arxiv_id": "2508.08343v1",
        "authors": [
            "Ferran Agullo",
            "Joan Oliveras",
            "Chen Wang",
            "Alberto Gutierrez-Torre",
            "Olivier Tardieu",
            "Alaa Youssef",
            "Jordi Torres",
            "Josep Ll. Berral"
        ],
        "submitted": "2025-08-11 10:47:35",
        "source": "arxiv",
        "comment": "Under review for a computer science conference",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on optimizing GPU efficiency for LLM serving, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions AI-driven pipeline, it's not clear how it relates to user behavior modeling or ranking models. The paper's topic is more aligned with computer architecture and system optimization."
    },
    {
        "title": "SASST: Leveraging Syntax-Aware Chunking and LLMs for Simultaneous Speech Translation",
        "abstract": "This work proposes a grammar-based chunking strategy that segments input\nstreams into semantically complete units by parsing dependency relations (e.g.,\nnoun phrase boundaries, verb-object structures) and punctuation features. The\nmethod ensures chunk coherence and minimizes semantic fragmentation. Building\non this mechanism, we present SASST (Syntax-Aware Simultaneous Speech\nTranslation), an end-to-end framework integrating frozen Whisper encoder and\ndecoder-only LLM. The unified architecture dynamically outputs translation\ntokens or <WAIT> symbols to jointly optimize translation timing and content,\nwith target-side reordering addressing word-order divergence. Experiments on\nCoVoST2 multilingual corpus En-{De, Zh, Ja} demonstrate significant translation\nquality improvements across languages and validate the effectiveness of\nsyntactic structures in LLM-driven SimulST systems.",
        "url": "http://arxiv.org/abs/2508.07781v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07781v1",
        "arxiv_id": "2508.07781v1",
        "authors": [
            "Zeyu Yang",
            "Lai Wei",
            "Roman Koshkin",
            "Xi Chen",
            "Satoshi Nakamura"
        ],
        "submitted": "2025-08-11 09:13:35",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on simultaneous speech translation, leveraging syntax-aware chunking and large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it does involve natural language processing, the specific application and techniques used are not aligned with the user's research interests."
    },
    {
        "title": "What am I missing here?: Evaluating Large Language Models for Masked Sentence Prediction",
        "abstract": "Transformer-based models primarily rely on Next Token Prediction (NTP), which\npredicts the next token in a sequence based on the preceding context. However,\nNTP's focus on single-token prediction often limits a model's ability to plan\nahead or maintain long-range coherence, raising questions about how well LLMs\ncan predict longer contexts, such as full sentences within structured\ndocuments. While NTP encourages local fluency, it provides no explicit\nincentive to ensure global coherence across sentence boundaries-an essential\nskill for reconstructive or discursive tasks. To investigate this, we evaluate\nthree commercial LLMs (GPT-4o, Claude 3.5 Sonnet, and Gemini 2.0 Flash) on\nMasked Sentence Prediction (MSP) - the task of infilling a randomly removed\nsentence - from three domains: ROCStories (narrative), Recipe1M (procedural),\nand Wikipedia (expository). We assess both fidelity (similarity to the original\nsentence) and cohesiveness (fit within the surrounding context). Our key\nfinding reveals that commercial LLMs, despite their superlative performance in\nother tasks, are poor at predicting masked sentences in low-structured domains,\nhighlighting a gap in current model capabilities.",
        "url": "http://arxiv.org/abs/2508.07702v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07702v1",
        "arxiv_id": "2508.07702v1",
        "authors": [
            "Charlie Wyatt",
            "Aditya Joshi",
            "Flora Salim"
        ],
        "submitted": "2025-08-11 07:25:50",
        "source": "arxiv",
        "comment": "Under Review",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper evaluates large language models for masked sentence prediction, which is a task related to natural language processing. While it touches on the idea of predicting longer contexts, it does not directly address query understanding, ranking models, or user behavior modeling, which are core interests in information retrieval and search technologies."
    },
    {
        "title": "ThinkTuning: Instilling Cognitive Reflections without Distillation",
        "abstract": "Recent advances in test-time scaling have led to the emergence of thinking\nLLMs that exhibit self-reflective behaviors and multi-step reasoning. While RL\ndrives this self-improvement paradigm, a recent study (Gandhi et al., 2025)\nshows that RL alone does not truly instill these new reasoning abilities - it\nmerely draws out behaviors already present in the base models. This raises a\nquestion: How can we train the models that don't exhibit such thinking behavior\nto develop it in the first place? To this end, we propose ThinkTuning, a\nGRPO-based interactive training approach where we augment the rollouts of a\nstudent model with the guidance from a teacher model. A simple idea from\nclassroom practice inspires our method: a teacher poses a problem, lets the\nstudent try an answer, then gives corrective feedback -- enough to point the\nmind in the right direction and then show the solution. Each piece of feedback\nreshapes the student's thoughts, leading them to arrive at the correct\nsolution. Similarly, we find that this type of implicit supervision through\nfeedback from a teacher model of the same size improves the reasoning\ncapabilities of the student model. In particular, on average, our method shows\na 3.85% improvement over zero-shot baselines across benchmarks, and on\nMATH-500, AIME and GPQA-Diamond it shows 2.08%, 2.23% and 3.99% improvements\nover the vanilla-GRPO baseline. Source code is available at\nhttps://github.com/3rdAT/ThinkTuning.",
        "url": "http://arxiv.org/abs/2508.07616v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07616v1",
        "arxiv_id": "2508.07616v1",
        "authors": [
            "Aswin RRV",
            "Jacob Dineen",
            "Divij Handa",
            "Md Nayem Uddin",
            "Mihir Parmar",
            "Chitta Baral",
            "Ben Zhou"
        ],
        "submitted": "2025-08-11 04:51:43",
        "source": "arxiv",
        "comment": "15 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on training AI models to develop self-reflective behaviors and multi-step reasoning, which is a topic in Natural Language Processing and Machine Learning, but not specifically relevant to the user's research interests."
    },
    {
        "title": "IBPS: Indian Bail Prediction System",
        "abstract": "Bail decisions are among the most frequently adjudicated matters in Indian\ncourts, yet they remain plagued by subjectivity, delays, and inconsistencies.\nWith over 75% of India's prison population comprising undertrial prisoners,\nmany from socioeconomically disadvantaged backgrounds, the lack of timely and\nfair bail adjudication exacerbates human rights concerns and contributes to\nsystemic judicial backlog. In this paper, we present the Indian Bail Prediction\nSystem (IBPS), an AI-powered framework designed to assist in bail\ndecision-making by predicting outcomes and generating legally sound rationales\nbased solely on factual case attributes and statutory provisions. We curate and\nrelease a large-scale dataset of 150,430 High Court bail judgments, enriched\nwith structured annotations such as age, health, criminal history, crime\ncategory, custody duration, statutes, and judicial reasoning. We fine-tune a\nlarge language model using parameter-efficient techniques and evaluate its\nperformance across multiple configurations, with and without statutory context,\nand with RAG. Our results demonstrate that models fine-tuned with statutory\nknowledge significantly outperform baselines, achieving strong accuracy and\nexplanation quality, and generalize well to a test set independently annotated\nby legal experts. IBPS offers a transparent, scalable, and reproducible\nsolution to support data-driven legal assistance, reduce bail delays, and\npromote procedural fairness in the Indian judicial system.",
        "url": "http://arxiv.org/abs/2508.07592v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07592v1",
        "arxiv_id": "2508.07592v1",
        "authors": [
            "Puspesh Kumar Srivastava",
            "Uddeshya Raj",
            "Praveen Patel",
            "/Shubham Kumar Nigam",
            "Noel Shallum",
            "Arnab Bhattacharya"
        ],
        "submitted": "2025-08-11 03:44:17",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on an AI-powered framework for bail decision-making in the Indian judicial system, which is unrelated to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on legal and judicial aspects, as well as its specific domain (Indian courts), makes it irrelevant to the user's broader interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "From Trial-and-Error to Improvement: A Systematic Analysis of LLM Exploration Mechanisms in RLVR",
        "abstract": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a\npowerful paradigm for enhancing the reasoning capabilities of large language\nmodels (LLMs). Unlike traditional RL approaches, RLVR leverages rule-based\nfeedback to guide LLMs in generating and refining complex reasoning chains -- a\nprocess critically dependent on effective exploration strategies. While prior\nwork has demonstrated RLVR's empirical success, the fundamental mechanisms\ngoverning LLMs' exploration behaviors remain underexplored. This technical\nreport presents a systematic investigation of exploration capacities in RLVR,\ncovering four main aspects: (1) exploration space shaping, where we develop\nquantitative metrics to characterize LLMs' capability boundaries; (2)\nentropy-performance exchange, analyzed across training stages, individual\ninstances, and token-level patterns; and (3) RL performance optimization,\nexamining methods to effectively translate exploration gains into measurable\nimprovements. By unifying previously identified insights with new empirical\nevidence, this work aims to provide a foundational framework for advancing RLVR\nsystems.",
        "url": "http://arxiv.org/abs/2508.07534v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07534v1",
        "arxiv_id": "2508.07534v1",
        "authors": [
            "Jia Deng",
            "Jie Chen",
            "Zhipeng Chen",
            "Daixuan Cheng",
            "Fei Bai",
            "Beichen Zhang",
            "Yinqian Min",
            "Yanzipeng Gao",
            "Wayne Xin Zhao",
            "Ji-Rong Wen"
        ],
        "submitted": "2025-08-11 01:26:16",
        "source": "arxiv",
        "comment": "27pages,25figures. arXiv admin note: text overlap with\n  arXiv:2508.02260",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores reinforcement learning with verifiable rewards (RLVR) for large language models (LLMs), focusing on exploration strategies. While it touches on some aspects of query understanding and ranking models, the primary focus is on LLMs' reasoning capabilities, which is not directly related to my core research interests in information retrieval and search technologies."
    },
    {
        "title": "Positional Biases Shift as Inputs Approach Context Window Limits",
        "abstract": "Large Language Models (LLMs) often struggle to use information across long\ninputs effectively. Prior work has identified positional biases, such as the\nLost in the Middle (LiM) effect, where models perform better when information\nappears at the beginning (primacy bias) or end (recency bias) of the input,\nrather than in the middle. However, long-context studies have not consistently\nreplicated these effects, raising questions about their intensity and the\nconditions under which they manifest. To address this, we conducted a\ncomprehensive analysis using relative rather than absolute input lengths,\ndefined with respect to each model's context window. Our findings reveal that\nthe LiM effect is strongest when inputs occupy up to 50% of a model's context\nwindow. Beyond that, the primacy bias weakens, while recency bias remains\nrelatively stable. This effectively eliminates the LiM effect; instead, we\nobserve a distance-based bias, where model performance is better when relevant\ninformation is closer to the end of the input. Furthermore, our results suggest\nthat successful retrieval is a prerequisite for reasoning in LLMs, and that the\nobserved positional biases in reasoning are largely inherited from retrieval.\nThese insights have implications for long-context tasks, the design of future\nLLM benchmarks, and evaluation methodologies for LLMs handling extended inputs.",
        "url": "http://arxiv.org/abs/2508.07479v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07479v1",
        "arxiv_id": "2508.07479v1",
        "authors": [
            "Blerta Veseli",
            "Julian Chibane",
            "Mariya Toneva",
            "Alexander Koller"
        ],
        "submitted": "2025-08-10 20:40:24",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores positional biases in Large Language Models, which is related to query understanding and ranking models in Information Retrieval. However, the focus on language models and their limitations in handling long inputs is not directly aligned with the user's interests in search technologies and user behavior modeling."
    },
    {
        "title": "Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health Dialogues via LLM-as-Judge",
        "abstract": "Evaluating the safety alignment of LLM responses in high-risk mental health\ndialogues is particularly difficult due to missing gold-standard answers and\nthe ethically sensitive nature of these interactions. To address this\nchallenge, we propose PsyCrisis-Bench, a reference-free evaluation benchmark\nbased on real-world Chinese mental health dialogues. It evaluates whether the\nmodel responses align with the safety principles defined by experts.\nSpecifically designed for settings without standard references, our method\nadopts a prompt-based LLM-as-Judge approach that conducts in-context evaluation\nusing expert-defined reasoning chains grounded in psychological intervention\nprinciples. We employ binary point-wise scoring across multiple safety\ndimensions to enhance the explainability and traceability of the evaluation.\nAdditionally, we present a manually curated, high-quality Chinese-language\ndataset covering self-harm, suicidal ideation, and existential distress,\nderived from real-world online discourse. Experiments on 3600 judgments show\nthat our method achieves the highest agreement with expert assessments and\nproduces more interpretable evaluation rationales compared to existing\napproaches. Our dataset and evaluation tool are publicly available to\nfacilitate further research.",
        "url": "http://arxiv.org/abs/2508.08236v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08236v1",
        "arxiv_id": "2508.08236v1",
        "authors": [
            "Yunna Cai",
            "Fan Wang",
            "Haowei Wang",
            "Kun Wang",
            "Kailai Yang",
            "Sophia Ananiadou",
            "Moyan Li",
            "Mingming Fan"
        ],
        "submitted": "2025-08-11 17:52:07",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on evaluating the safety alignment of LLM responses in mental health dialogues, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves LLMs and NLP, the topic is more specific to mental health and does not align with the user's primary focus on query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Capabilities of GPT-5 on Multimodal Medical Reasoning",
        "abstract": "Recent advances in large language models (LLMs) have enabled general-purpose\nsystems to perform increasingly complex domain-specific reasoning without\nextensive fine-tuning. In the medical domain, decision-making often requires\nintegrating heterogeneous information sources, including patient narratives,\nstructured data, and medical images. This study positions GPT-5 as a generalist\nmultimodal reasoner for medical decision support and systematically evaluates\nits zero-shot chain-of-thought reasoning performance on both text-based\nquestion answering and visual question answering tasks under a unified\nprotocol. We benchmark GPT-5, GPT-5-mini, GPT-5-nano, and GPT-4o-2024-11-20\nagainst standardized splits of MedQA, MedXpertQA (text and multimodal), MMLU\nmedical subsets, USMLE self-assessment exams, and VQA-RAD. Results show that\nGPT-5 consistently outperforms all baselines, achieving state-of-the-art\naccuracy across all QA benchmarks and delivering substantial gains in\nmultimodal reasoning. On MedXpertQA MM, GPT-5 improves reasoning and\nunderstanding scores by +29.62% and +36.18% over GPT-4o, respectively, and\nsurpasses pre-licensed human experts by +24.23% in reasoning and +29.40% in\nunderstanding. In contrast, GPT-4o remains below human expert performance in\nmost dimensions. A representative case study demonstrates GPT-5's ability to\nintegrate visual and textual cues into a coherent diagnostic reasoning chain,\nrecommending appropriate high-stakes interventions. Our results show that, on\nthese controlled multimodal reasoning benchmarks, GPT-5 moves from\nhuman-comparable to above human-expert performance. This improvement may\nsubstantially inform the design of future clinical decision-support systems.",
        "url": "http://arxiv.org/abs/2508.08224v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08224v1",
        "arxiv_id": "2508.08224v1",
        "authors": [
            "Shansong Wang",
            "Mingzhe Hu",
            "Qiang Li",
            "Mojtaba Safari",
            "Xiaofeng Yang"
        ],
        "submitted": "2025-08-11 17:43:45",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on the capabilities of GPT-5 in multimodal medical reasoning, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on medical decision support and clinical decision-support systems is also outside the user's primary focus."
    },
    {
        "title": "Czech Dataset for Complex Aspect-Based Sentiment Analysis Tasks",
        "abstract": "In this paper, we introduce a novel Czech dataset for aspect-based sentiment\nanalysis (ABSA), which consists of 3.1K manually annotated reviews from the\nrestaurant domain. The dataset is built upon the older Czech dataset, which\ncontained only separate labels for the basic ABSA tasks such as aspect term\nextraction or aspect polarity detection. Unlike its predecessor, our new\ndataset is specifically designed for more complex tasks, e.g.\ntarget-aspect-category detection. These advanced tasks require a unified\nannotation format, seamlessly linking sentiment elements (labels) together. Our\ndataset follows the format of the well-known SemEval-2016 datasets. This design\nchoice allows effortless application and evaluation in cross-lingual scenarios,\nultimately fostering cross-language comparisons with equivalent counterpart\ndatasets in other languages. The annotation process engaged two trained\nannotators, yielding an impressive inter-annotator agreement rate of\napproximately 90%. Additionally, we provide 24M reviews without annotations\nsuitable for unsupervised learning. We present robust monolingual baseline\nresults achieved with various Transformer-based models and insightful error\nanalysis to supplement our contributions. Our code and dataset are freely\navailable for non-commercial research purposes.",
        "url": "http://arxiv.org/abs/2508.08125v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08125v1",
        "arxiv_id": "2508.08125v1",
        "authors": [
            "Jakub Šmíd",
            "Pavel Přibáň",
            "Ondřej Pražák",
            "Pavel Král"
        ],
        "submitted": "2025-08-11 16:03:28",
        "source": "arxiv",
        "comment": "Published In Proceedings of the 2024 Joint International Conference\n  on Computational Linguistics, Language Resources and Evaluation (LREC-COLING\n  2024). Official version: https://aclanthology.org/2024.lrec-main.374/",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on aspect-based sentiment analysis, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves text analysis, the specific task and domain (restaurant reviews) are not relevant to the user's areas of interest."
    },
    {
        "title": "Investigating the Design Space of Visual Grounding in Multimodal Large Language Model",
        "abstract": "Fine-grained multimodal capability in Multimodal Large Language Models\n(MLLMs) has emerged as a critical research direction, particularly for tackling\nthe visual grounding (VG) problem. Despite the strong performance achieved by\nexisting approaches, they often employ disparate design choices when\nfine-tuning MLLMs for VG, lacking systematic verification to support these\ndesigns. To bridge this gap, this paper presents a comprehensive study of\nvarious design choices that impact the VG performance of MLLMs. We conduct our\nanalysis using LLaVA-1.5, which has been widely adopted in prior empirical\nstudies of MLLMs. While more recent models exist, we follow this convention to\nensure our findings remain broadly applicable and extendable to other\narchitectures. We cover two key aspects: (1) exploring different visual\ngrounding paradigms in MLLMs, identifying the most effective design, and\nproviding our insights; and (2) conducting ablation studies on the design of\ngrounding data to optimize MLLMs' fine-tuning for the VG task. Finally, our\nfindings contribute to a stronger MLLM for VG, achieving improvements of +5.6%\n/ +6.9% / +7.0% on RefCOCO/+/g over the LLaVA-1.5.",
        "url": "http://arxiv.org/abs/2508.08066v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08066v1",
        "arxiv_id": "2508.08066v1",
        "authors": [
            "Weitai Kang",
            "Weiming Zhuang",
            "Zhizhong Li",
            "Yan Yan",
            "Lingjuan Lyu"
        ],
        "submitted": "2025-08-11 15:10:52",
        "source": "arxiv",
        "comment": "8 pages for the main paper",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on visual grounding in multimodal large language models, which is not directly related to information retrieval, query understanding, or ranking models. While it explores design choices and ablation studies, the topic is more aligned with computer vision and multimodal processing, which are not core areas of interest for the user."
    },
    {
        "title": "9th Workshop on Sign Language Translation and Avatar Technologies (SLTAT 2025)",
        "abstract": "The Sign Language Translation and Avatar Technology (SLTAT) workshops\ncontinue a series of gatherings to share recent advances in improving deaf /\nhuman communication through non-invasive means. This 2025 edition, the 9th\nsince its first appearance in 2011, is hosted by the International Conference\non Intelligent Virtual Agents (IVA), giving the opportunity for contamination\nbetween two research communities, using digital humans as either virtual\ninterpreters or as interactive conversational agents. As presented in this\nsummary paper, SLTAT sees contributions beyond avatar technologies, with a\nconsistent number of submissions on sign language recognition, and other work\non data collection, data analysis, tools, ethics, usability, and affective\ncomputing.",
        "url": "http://arxiv.org/abs/2508.08050v1",
        "pdf_url": "http://arxiv.org/pdf/2508.08050v1",
        "arxiv_id": "2508.08050v1",
        "authors": [
            "Fabrizio Nunnari",
            "Cristina Luna Jiménez",
            "Rosalee Wolfe",
            "John C. McDonald",
            "Michael Filhol",
            "Eleni Efthimiou",
            "Evita Fotinea",
            "Thomas Hanke"
        ],
        "submitted": "2025-08-11 14:50:21",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not related to Information Retrieval, Search technologies, or Natural Language Processing, and does not address query understanding, ranking models, or user behavior modeling. The focus is on sign language translation and avatar technologies, which is outside the user's primary research interests."
    },
    {
        "title": "The Medical Metaphors Corpus (MCC)",
        "abstract": "Metaphor is a fundamental cognitive mechanism that shapes scientific\nunderstanding, enabling the communication of complex concepts while potentially\nconstraining paradigmatic thinking. Despite the prevalence of figurative\nlanguage in scientific discourse, existing metaphor detection resources\nprimarily focus on general-domain text, leaving a critical gap for\ndomain-specific applications. In this paper, we present the Medical Metaphors\nCorpus (MCC), a comprehensive dataset of 792 annotated scientific conceptual\nmetaphors spanning medical and biological domains. MCC aggregates metaphorical\nexpressions from diverse sources including peer-reviewed literature, news\nmedia, social media discourse, and crowdsourced contributions, providing both\nbinary and graded metaphoricity judgments validated through human annotation.\nEach instance includes source-target conceptual mappings and perceived\nmetaphoricity scores on a 0-7 scale, establishing the first annotated resource\nfor computational scientific metaphor research. Our evaluation demonstrates\nthat state-of-the-art language models achieve modest performance on scientific\nmetaphor detection, revealing substantial room for improvement in\ndomain-specific figurative language understanding. MCC enables multiple\nresearch applications including metaphor detection benchmarking, quality-aware\ngeneration systems, and patient-centered communication tools.",
        "url": "http://arxiv.org/abs/2508.07993v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07993v1",
        "arxiv_id": "2508.07993v1",
        "authors": [
            "Anna Sofia Lippolis",
            "Andrea Giovanni Nuzzolese",
            "Aldo Gangemi"
        ],
        "submitted": "2025-08-11 13:55:31",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on a specific domain (medicine and biology) and presents a dataset for metaphor detection, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on language models, it does not address ranking models or user behavior modeling, making it only loosely relevant to the user's research interests."
    },
    {
        "title": "Large Language Models for Subjective Language Understanding: A Survey",
        "abstract": "Subjective language understanding refers to a broad set of natural language\nprocessing tasks where the goal is to interpret or generate content that\nconveys personal feelings, opinions, or figurative meanings rather than\nobjective facts. With the advent of large language models (LLMs) such as\nChatGPT, LLaMA, and others, there has been a paradigm shift in how we approach\nthese inherently nuanced tasks. In this survey, we provide a comprehensive\nreview of recent advances in applying LLMs to subjective language tasks,\nincluding sentiment analysis, emotion recognition, sarcasm detection, humor\nunderstanding, stance detection, metaphor interpretation, intent detection, and\naesthetics assessment. We begin by clarifying the definition of subjective\nlanguage from linguistic and cognitive perspectives, and we outline the unique\nchallenges posed by subjective language (e.g. ambiguity, figurativeness,\ncontext dependence). We then survey the evolution of LLM architectures and\ntechniques that particularly benefit subjectivity tasks, highlighting why LLMs\nare well-suited to model subtle human-like judgments. For each of the eight\ntasks, we summarize task definitions, key datasets, state-of-the-art LLM-based\nmethods, and remaining challenges. We provide comparative insights, discussing\ncommonalities and differences among tasks and how multi-task LLM approaches\nmight yield unified models of subjectivity. Finally, we identify open issues\nsuch as data limitations, model bias, and ethical considerations, and suggest\nfuture research directions. We hope this survey will serve as a valuable\nresource for researchers and practitioners interested in the intersection of\naffective computing, figurative language processing, and large-scale language\nmodels.",
        "url": "http://arxiv.org/abs/2508.07959v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07959v1",
        "arxiv_id": "2508.07959v1",
        "authors": [
            "Changhao Song",
            "Yazhou Zhang",
            "Hui Gao",
            "Ben Yao",
            "Peng Zhang"
        ],
        "submitted": "2025-08-11 13:10:44",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on large language models for subjective language understanding, which is related to natural language processing and deep semantic understanding. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest in information retrieval and search technologies."
    },
    {
        "title": "Large Language Models for Czech Aspect-Based Sentiment Analysis",
        "abstract": "Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis\ntask that aims to identify sentiment toward specific aspects of an entity.\nWhile large language models (LLMs) have shown strong performance in various\nnatural language processing (NLP) tasks, their capabilities for Czech ABSA\nremain largely unexplored. In this work, we conduct a comprehensive evaluation\nof 19 LLMs of varying sizes and architectures on Czech ABSA, comparing their\nperformance in zero-shot, few-shot, and fine-tuning scenarios. Our results show\nthat small domain-specific models fine-tuned for ABSA outperform\ngeneral-purpose LLMs in zero-shot and few-shot settings, while fine-tuned LLMs\nachieve state-of-the-art results. We analyze how factors such as\nmultilingualism, model size, and recency influence performance and present an\nerror analysis highlighting key challenges, particularly in aspect term\nprediction. Our findings provide insights into the suitability of LLMs for\nCzech ABSA and offer guidance for future research in this area.",
        "url": "http://arxiv.org/abs/2508.07860v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07860v1",
        "arxiv_id": "2508.07860v1",
        "authors": [
            "Jakub Šmíd",
            "Pavel Přibáň",
            "Pavel Král"
        ],
        "submitted": "2025-08-11 11:24:57",
        "source": "arxiv",
        "comment": "Accepted for presentation at the 28th International Conference on\n  Text, Speech and Dialogue (TSD 2025)",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on aspect-based sentiment analysis, a topic in Natural Language Processing (NLP), but it does not directly relate to Information Retrieval (IR) or Search technologies, which are the user's primary research interests. The paper's emphasis on large language models and their performance on a specific task also does not align with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Recommendation Is a Dish Better Served Warm",
        "abstract": "In modern recommender systems, experimental settings typically include\nfiltering out cold users and items based on a minimum interaction threshold.\nHowever, these thresholds are often chosen arbitrarily and vary widely across\nstudies, leading to inconsistencies that can significantly affect the\ncomparability and reliability of evaluation results. In this paper, we\nsystematically explore the cold-start boundary by examining the criteria used\nto determine whether a user or an item should be considered cold. Our\nexperiments incrementally vary the number of interactions for different items\nduring training, and gradually update the length of user interaction histories\nduring inference. We investigate the thresholds across several widely used\ndatasets, commonly represented in recent papers from top-tier conferences, and\non multiple established recommender baselines. Our findings show that\ninconsistent selection of cold-start thresholds can either result in the\nunnecessary removal of valuable data or lead to the misclassification of cold\ninstances as warm, introducing more noise into the system.",
        "url": "http://arxiv.org/abs/2508.07856v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07856v1",
        "arxiv_id": "2508.07856v1",
        "authors": [
            "Danil Gusak",
            "Nikita Sukhorukov",
            "Evgeny Frolov"
        ],
        "submitted": "2025-08-11 11:14:49",
        "source": "arxiv",
        "comment": "Accepted for ACM RecSys 2025. Author's version. The final published\n  version will be available at the ACM Digital Library",
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores recommender systems, which is a related topic to information retrieval, but it focuses on the cold-start problem and threshold selection, which is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling. While the paper touches on the importance of data quality, it does not delve into the deep semantic understanding and real-time relevance optimization aspects that are central to the user's research themes."
    },
    {
        "title": "Evaluating Compositional Approaches for Focus and Sentiment Analysis",
        "abstract": "This paper summarizes the results of evaluating a compositional approach for\nFocus Analysis (FA) in Linguistics and Sentiment Analysis (SA) in Natural\nLanguage Processing (NLP). While quantitative evaluations of compositional and\nnon-compositional approaches in SA exist in NLP, similar quantitative\nevaluations are very rare in FA in Linguistics that deal with linguistic\nexpressions representing focus or emphasis such as \"it was John who left\". We\nfill this gap in research by arguing that compositional rules in SA also apply\nto FA because FA and SA are closely related meaning that SA is part of FA. Our\ncompositional approach in SA exploits basic syntactic rules such as rules of\nmodification, coordination, and negation represented in the formalism of\nUniversal Dependencies (UDs) in English and applied to words representing\nsentiments from sentiment dictionaries. Some of the advantages of our\ncompositional analysis method for SA in contrast to non-compositional analysis\nmethods are interpretability and explainability. We test the accuracy of our\ncompositional approach and compare it with a non-compositional approach VADER\nthat uses simple heuristic rules to deal with negation, coordination and\nmodification. In contrast to previous related work that evaluates\ncompositionality in SA on long reviews, this study uses more appropriate\ndatasets to evaluate compositionality. In addition, we generalize the results\nof compositional approaches in SA to compositional approaches in FA.",
        "url": "http://arxiv.org/abs/2508.07810v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07810v1",
        "arxiv_id": "2508.07810v1",
        "authors": [
            "Olga Kellert",
            "Muhammad Imran",
            "Nicholas Hill Matlis",
            "Mahmud Uz Zaman",
            "Carlos Gómez-Rodríguez"
        ],
        "submitted": "2025-08-11 09:52:41",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper evaluates compositional approaches for Focus and Sentiment Analysis, which is related to Natural Language Processing (NLP), but it does not directly address query understanding, ranking models, or user behavior modeling, which are core interests in Information Retrieval (IR). While the paper's focus on compositional analysis and its applications to sentiment analysis is somewhat relevant, it does not seem to have a direct impact on IR or search technologies."
    },
    {
        "title": "Towards Comprehensible Recommendation with Large Language Model Fine-tuning",
        "abstract": "Recommender systems have become increasingly ubiquitous in daily life. While\ntraditional recommendation approaches primarily rely on ID-based\nrepresentations or item-side content features, they often fall short in\ncapturing the underlying semantics aligned with user preferences (e.g.,\nrecommendation reasons for items), leading to a semantic-collaborative gap.\nRecently emerged LLM-based feature extraction approaches also face a key\nchallenge: how to ensure that LLMs possess recommendation-aligned reasoning\ncapabilities and can generate accurate, personalized reasons to mitigate the\nsemantic-collaborative gap. To address these issues, we propose a novel Content\nUnderstanding from a Collaborative Perspective framework (CURec), which\ngenerates collaborative-aligned content features for more comprehensive\nrecommendations. \\method first aligns the LLM with recommendation objectives\nthrough pretraining, equipping it with instruction-following and\nchain-of-thought reasoning capabilities. Next, we design a reward model\ninspired by traditional recommendation architectures to evaluate the quality of\nthe recommendation reasons generated by the LLM. Finally, using the reward\nsignals, CURec fine-tunes the LLM through RL and corrects the generated reasons\nto ensure their accuracy. The corrected reasons are then integrated into a\ndownstream recommender model to enhance comprehensibility and recommendation\nperformance. Extensive experiments on public benchmarks demonstrate the\nsuperiority of CURec over existing methods.",
        "url": "http://arxiv.org/abs/2508.07595v1",
        "pdf_url": "http://arxiv.org/pdf/2508.07595v1",
        "arxiv_id": "2508.07595v1",
        "authors": [
            "Yunze Luo",
            "Yinjie Jiang",
            "Gaode Chen",
            "Xinghua Zhang",
            "Jun Zhang",
            "Jian Liang",
            "Kaigui Bian"
        ],
        "submitted": "2025-08-11 03:55:31",
        "source": "arxiv",
        "comment": "11 pages, 6 figures",
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on recommender systems, which is a related topic to information retrieval, but it doesn't directly address query understanding, ranking models, or user behavior modeling. The use of large language models and fine-tuning for recommendation reasons is an interesting application, but it doesn't seem to be directly relevant to the user's core research themes."
    }
]