[
    {
        "title": "Question Decomposition for Retrieval-Augmented Generation",
        "abstract": "Grounding large language models (LLMs) in verifiable external sources is a\nwell-established strategy for generating reliable answers. Retrieval-augmented\ngeneration (RAG) is one such approach, particularly effective for tasks like\nquestion answering: it retrieves passages that are semantically related to the\nquestion and then conditions the model on this evidence. However, multi-hop\nquestions, such as \"Which company among NVIDIA, Apple, and Google made the\nbiggest profit in 2023?,\" challenge RAG because relevant facts are often\ndistributed across multiple documents rather than co-occurring in one source,\nmaking it difficult for standard RAG to retrieve sufficient information. To\naddress this, we propose a RAG pipeline that incorporates question\ndecomposition: (i) an LLM decomposes the original query into sub-questions,\n(ii) passages are retrieved for each sub-question, and (iii) the merged\ncandidate pool is reranked to improve the coverage and precision of the\nretrieved evidence. We show that question decomposition effectively assembles\ncomplementary documents, while reranking reduces noise and promotes the most\nrelevant passages before answer generation. Although reranking itself is\nstandard, we show that pairing an off-the-shelf cross-encoder reranker with\nLLM-driven question decomposition bridges the retrieval gap on multi-hop\nquestions and provides a practical, drop-in enhancement, without any extra\ntraining or specialized indexing. We evaluate our approach on the MultiHop-RAG\nand HotpotQA, showing gains in retrieval (MRR@10: +36.7%) and answer accuracy\n(F1: +11.6%) over standard RAG baselines.",
        "url": "http://arxiv.org/abs/2507.00355v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00355v1",
        "arxiv_id": "2507.00355v1",
        "authors": [
            "Paul J. L. Ammann",
            "Jonas Golde",
            "Alan Akbik"
        ],
        "submitted": "2025-07-01 01:01:54",
        "source": "arxiv",
        "comment": "Accepted to ACL SRW 2025. 9 Pages, 2 Figures, 4 Tables",
        "score": 14,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "The paper explores retrieval-augmented generation, which aligns with your interest in Information Retrieval and Search technologies. The focus on question decomposition and reranking models is also relevant to your research themes, particularly in the context of query understanding and ranking models. However, the paper's primary focus is on question answering and retrieval for specific tasks, which is somewhat narrower than your broader interests in NLP and data mining."
    },
    {
        "title": "MassTool: A Multi-Task Search-Based Tool Retrieval Framework for Large Language Models",
        "abstract": "Tool retrieval is a critical component in enabling large language models\n(LLMs) to interact effectively with external tools. It aims to precisely filter\nthe massive tools into a small set of candidates for the downstream\ntool-augmented LLMs. However, most existing approaches primarily focus on\noptimizing tool representations, often neglecting the importance of precise\nquery comprehension. To address this gap, we introduce MassTool, a multi-task\nsearch-based framework designed to enhance both query representation and tool\nretrieval accuracy. MassTool employs a two-tower architecture: a tool usage\ndetection tower that predicts the need for function calls, and a tool retrieval\ntower that leverages a query-centric graph convolution network (QC-GCN) for\neffective query-tool matching. It also incorporates search-based user intent\nmodeling (SUIM) to handle diverse and out-of-distribution queries, alongside an\nadaptive knowledge transfer (AdaKT) module for efficient multi-task learning.\nBy jointly optimizing tool usage detection loss, list-wise retrieval loss, and\ncontrastive regularization loss, MassTool establishes a robust dual-step\nsequential decision-making pipeline for precise query understanding. Extensive\nexperiments demonstrate its effectiveness in improving retrieval accuracy. Our\ncode is available at https://github.com/wxydada/MassTool.",
        "url": "http://arxiv.org/abs/2507.00487v2",
        "pdf_url": "http://arxiv.org/pdf/2507.00487v2",
        "arxiv_id": "2507.00487v2",
        "authors": [
            "Jianghao Lin",
            "Xinyuan Wang",
            "Xinyi Dai",
            "Menghui Zhu",
            "Bo Chen",
            "Ruiming Tang",
            "Yong Yu",
            "Weinan Zhang"
        ],
        "submitted": "2025-07-01 07:02:26",
        "source": "arxiv",
        "comment": null,
        "score": 11,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper focuses on tool retrieval for large language models, which is related to information retrieval and search technologies. The use of query-centric graph convolution network (QC-GCN) for query-tool matching and search-based user intent modeling (SUIM) for handling diverse queries are relevant to query understanding and ranking models. However, the paper's primary focus is on tool retrieval, which is not directly aligned with the user's core research themes."
    },
    {
        "title": "SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks",
        "abstract": "We present SciArena, an open and collaborative platform for evaluating\nfoundation models on scientific literature tasks. Unlike traditional benchmarks\nfor scientific literature understanding and synthesis, SciArena engages the\nresearch community directly, following the Chatbot Arena evaluation approach of\ncommunity voting on model comparisons. By leveraging collective intelligence,\nSciArena offers a community-driven evaluation of model performance on\nopen-ended scientific tasks that demand literature-grounded, long-form\nresponses. The platform currently supports 23 open-source and proprietary\nfoundation models and has collected over 13,000 votes from trusted researchers\nacross diverse scientific domains. We analyze the data collected so far and\nconfirm that the submitted questions are diverse, aligned with real-world\nliterature needs, and that participating researchers demonstrate strong\nself-consistency and inter-annotator agreement in their evaluations. We discuss\nthe results and insights based on the model ranking leaderboard. To further\npromote research in building model-based automated evaluation systems for\nliterature tasks, we release SciArena-Eval, a meta-evaluation benchmark based\non our collected preference data. The benchmark measures the accuracy of models\nin judging answer quality by comparing their pairwise assessments with human\nvotes. Our experiments highlight the benchmark's challenges and emphasize the\nneed for more reliable automated evaluation methods.",
        "url": "http://arxiv.org/abs/2507.01001v1",
        "pdf_url": "http://arxiv.org/pdf/2507.01001v1",
        "arxiv_id": "2507.01001v1",
        "authors": [
            "Yilun Zhao",
            "Kaiyan Zhang",
            "Tiansheng Hu",
            "Sihong Wu",
            "Ronan Le Bras",
            "Taira Anderson",
            "Jonathan Bragg",
            "Joseph Chee Chang",
            "Jesse Dodge",
            "Matt Latzke",
            "Yixin Liu",
            "Charles McGrady",
            "Xiangru Tang",
            "Zihang Wang",
            "Chen Zhao",
            "Hannaneh Hajishirzi",
            "Doug Downey",
            "Arman Cohan"
        ],
        "submitted": "2025-07-01 17:51:59",
        "source": "arxiv",
        "comment": null,
        "score": 10,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'pairwise' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on evaluating foundation models on scientific literature tasks, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on natural language processing and data mining, the scope is narrow and not aligned with the user's primary research interests."
    },
    {
        "title": "Read the Docs Before Rewriting: Equip Rewriter with Domain Knowledge via Continual Pre-training",
        "abstract": "A Retrieval-Augmented Generation (RAG)-based question-answering (QA) system\nenhances a large language model's knowledge by retrieving relevant documents\nbased on user queries. Discrepancies between user queries and document\nphrasings often necessitate query rewriting. However, in specialized domains,\nthe rewriter model may struggle due to limited domain-specific knowledge. To\nresolve this, we propose the R\\&R (Read the doc before Rewriting) rewriter,\nwhich involves continual pre-training on professional documents, akin to how\nstudents prepare for open-book exams by reviewing textbooks. Additionally, it\ncan be combined with supervised fine-tuning for improved results. Experiments\non multiple datasets demonstrate that R\\&R excels in professional QA across\nmultiple domains, effectively bridging the query-document gap, while\nmaintaining good performance in general scenarios, thus advancing the\napplication of RAG-based QA systems in specialized fields.",
        "url": "http://arxiv.org/abs/2507.00477v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00477v1",
        "arxiv_id": "2507.00477v1",
        "authors": [
            "Qi Wang",
            "Yixuan Cao",
            "Yifan Liu",
            "Jiangtao Zhao",
            "Ping Luo"
        ],
        "submitted": "2025-07-01 06:51:00",
        "source": "arxiv",
        "comment": null,
        "score": 10,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores Retrieval-Augmented Generation (RAG) for question-answering, which is related to Information Retrieval. The focus on query rewriting and domain-specific knowledge is also relevant to query understanding and ranking models. However, the paper's primary focus on question-answering and language models is not directly aligned with the user's interests in search technologies and user behavior modeling."
    },
    {
        "title": "WebANNS: Fast and Efficient Approximate Nearest Neighbor Search in Web Browsers",
        "abstract": "Approximate nearest neighbor search (ANNS) has become vital to modern AI\ninfrastructure, particularly in retrieval-augmented generation (RAG)\napplications. Numerous in-browser ANNS engines have emerged to seamlessly\nintegrate with popular LLM-based web applications, while addressing privacy\nprotection and challenges of heterogeneous device deployments. However, web\nbrowsers present unique challenges for ANNS, including computational\nlimitations, external storage access issues, and memory utilization\nconstraints, which state-of-the-art (SOTA) solutions fail to address\ncomprehensively. We propose WebANNS, a novel ANNS engine specifically designed\nfor web browsers. WebANNS leverages WebAssembly to overcome computational\nbottlenecks, designs a lazy loading strategy to optimize data retrieval from\nexternal storage, and applies a heuristic approach to reduce memory usage.\nExperiments show that WebANNS is fast and memory efficient, achieving up to\n$743.8\\times$ improvement in 99th percentile query latency over the SOTA\nengine, while reducing memory usage by up to 39\\%. Note that WebANNS decreases\nquery time from 10 seconds to the 10-millisecond range in browsers, making\nin-browser ANNS practical with user-acceptable latency.",
        "url": "http://arxiv.org/abs/2507.00521v2",
        "pdf_url": "http://arxiv.org/pdf/2507.00521v2",
        "arxiv_id": "2507.00521v2",
        "authors": [
            "Mugeng Liu",
            "Siqi Zhong",
            "Qi Yang",
            "Yudong Han",
            "Xuanzhe Liu",
            "Yun Ma"
        ],
        "submitted": "2025-07-01 07:37:18",
        "source": "arxiv",
        "comment": "SIGIR 2025",
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on approximate nearest neighbor search in web browsers, which is not directly related to information retrieval, query understanding, ranking models, or user behavior modeling. While it touches on retrieval-augmented generation, the primary focus is on the technical challenges of ANNS in web browsers, which is not a core area of interest for the user."
    },
    {
        "title": "Leveraging Large Language Models for Spontaneous Speech-Based Suicide Risk Detection",
        "abstract": "Early identification of suicide risk is crucial for preventing suicidal\nbehaviors. As a result, the identification and study of patterns and markers\nrelated to suicide risk have become a key focus of current research. In this\npaper, we present the results of our work in the 1st SpeechWellness Challenge\n(SW1), which aims to explore speech as a non-invasive and easily accessible\nmental health indicator for identifying adolescents at risk of suicide.Our\napproach leverages large language model (LLM) as the primary tool for feature\nextraction, alongside conventional acoustic and semantic features. The proposed\nmethod achieves an accuracy of 74\\% on the test set, ranking first in the SW1\nchallenge. These findings demonstrate the potential of LLM-based methods for\nanalyzing speech in the context of suicide risk assessment.",
        "url": "http://arxiv.org/abs/2507.00693v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00693v1",
        "arxiv_id": "2507.00693v1",
        "authors": [
            "Yifan Gao",
            "Jiao Fu",
            "Long Guo",
            "Hong Liu"
        ],
        "submitted": "2025-07-01 11:45:23",
        "source": "arxiv",
        "comment": "Accepted to Interspeech 2025",
        "score": 7,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus is on speech-based suicide risk detection using large language models, which is not related to query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "LineRetriever: Planning-Aware Observation Reduction for Web Agents",
        "abstract": "While large language models have demonstrated impressive capabilities in web\nnavigation tasks, the extensive context of web pages, often represented as DOM\nor Accessibility Tree (AxTree) structures, frequently exceeds model context\nlimits. Current approaches like bottom-up truncation or embedding-based\nretrieval lose critical information about page state and action history. This\nis particularly problematic for adaptive planning in web agents, where\nunderstanding the current state is essential for determining future actions. We\nhypothesize that embedding models lack sufficient capacity to capture\nplan-relevant information, especially when retrieving content that supports\nfuture action prediction. This raises a fundamental question: how can retrieval\nmethods be optimized for adaptive planning in web navigation tasks? In\nresponse, we introduce \\textit{LineRetriever}, a novel approach that leverages\na language model to identify and retrieve observation lines most relevant to\nfuture navigation steps. Unlike traditional retrieval methods that focus solely\non semantic similarity, \\textit{LineRetriever} explicitly considers the\nplanning horizon, prioritizing elements that contribute to action prediction.\nOur experiments demonstrate that \\textit{LineRetriever} can reduce the size of\nthe observation at each step for the web agent while maintaining consistent\nperformance within the context limitations.",
        "url": "http://arxiv.org/abs/2507.00210v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00210v1",
        "arxiv_id": "2507.00210v1",
        "authors": [
            "Imene Kerboua",
            "Sahar Omidi Shayegan",
            "Megh Thakkar",
            "Xing Han Lù",
            "Massimo Caccia",
            "Véronique Eglin",
            "Alexandre Aussem",
            "Jérémy Espinas",
            "Alexandre Lacoste"
        ],
        "submitted": "2025-06-30 19:24:45",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper introduces a novel approach for web agents to retrieve relevant information for adaptive planning, leveraging a language model to identify observation lines. While it touches on retrieval methods, it does not specifically focus on query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval. The paper's relevance is somewhat related, but not a central match."
    },
    {
        "title": "Digital Collections Explorer: An Open-Source, Multimodal Viewer for Searching Digital Collections",
        "abstract": "We present Digital Collections Explorer, a web-based, open-source exploratory\nsearch platform that leverages CLIP (Contrastive Language-Image Pre-training)\nfor enhanced visual discovery of digital collections. Our Digital Collections\nExplorer can be installed locally and configured to run on a visual collection\nof interest on disk in just a few steps. Building upon recent advances in\nmultimodal search techniques, our interface enables natural language queries\nand reverse image searches over digital collections with visual features. This\npaper describes the system's architecture, implementation, and application to\nvarious cultural heritage collections, demonstrating its potential for\ndemocratizing access to digital archives, especially those with impoverished\nmetadata. We present case studies with maps, photographs, and PDFs extracted\nfrom web archives in order to demonstrate the flexibility of the Digital\nCollections Explorer, as well as its ease of use. We demonstrate that the\nDigital Collections Explorer scales to hundreds of thousands of images on a\nMacBook Pro with an M4 chip. Lastly, we host a public demo of Digital\nCollections Explorer.",
        "url": "http://arxiv.org/abs/2507.00961v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00961v1",
        "arxiv_id": "2507.00961v1",
        "authors": [
            "Ying-Hsiang Huang",
            "Benjamin Charles Germain Lee"
        ],
        "submitted": "2025-07-01 17:10:34",
        "source": "arxiv",
        "comment": "14 pages, 8 figures, 2 tables",
        "score": 6,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a multimodal search platform for digital collections, leveraging CLIP for visual discovery. While it touches on search and retrieval aspects, its focus is more on the platform's architecture and implementation, rather than query understanding, ranking models, or user behavior modeling, which are key areas of interest in Information Retrieval. The paper's relevance to the user's research is somewhat limited."
    },
    {
        "title": "ONLY: One-Layer Intervention Sufficiently Mitigates Hallucinations in Large Vision-Language Models",
        "abstract": "Recent Large Vision-Language Models (LVLMs) have introduced a new paradigm\nfor understanding and reasoning about image input through textual responses.\nAlthough they have achieved remarkable performance across a range of\nmulti-modal tasks, they face the persistent challenge of hallucination, which\nintroduces practical weaknesses and raises concerns about their reliable\ndeployment in real-world applications. Existing work has explored contrastive\ndecoding approaches to mitigate this issue, where the output of the original\nLVLM is compared and contrasted with that of a perturbed version. However,\nthese methods require two or more queries that slow down LVLM response\ngeneration, making them less suitable for real-time applications. To overcome\nthis limitation, we propose ONLY, a training-free decoding approach that\nrequires only a single query and a one-layer intervention during decoding,\nenabling efficient real-time deployment. Specifically, we enhance textual\noutputs by selectively amplifying crucial textual information using a\ntext-to-visual entropy ratio for each token. Extensive experimental results\ndemonstrate that our proposed ONLY consistently outperforms state-of-the-art\nmethods across various benchmarks while requiring minimal implementation effort\nand computational cost. Code is available at https://github.com/zifuwan/ONLY.",
        "url": "http://arxiv.org/abs/2507.00898v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00898v1",
        "arxiv_id": "2507.00898v1",
        "authors": [
            "Zifu Wan",
            "Ce Zhang",
            "Silong Yong",
            "Martin Q. Ma",
            "Simon Stepputtis",
            "Louis-Philippe Morency",
            "Deva Ramanan",
            "Katia Sycara",
            "Yaqi Xie"
        ],
        "submitted": "2025-07-01 16:01:08",
        "source": "arxiv",
        "comment": "Accepted by ICCV 2025. Project page: https://zifuwan.github.io/ONLY/",
        "score": 6,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on Large Vision-Language Models and hallucination mitigation in the context of visual language understanding, which is outside the scope of Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on visual language models and entropy ratio for token amplification is not aligned with your interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "TeamCMU at Touché: Adversarial Co-Evolution for Advertisement Integration and Detection in Conversational Search",
        "abstract": "As conversational search engines increasingly adopt generation-based\nparadigms powered by Large Language Models (LLMs) and Retrieval-Augmented\nGeneration (RAG), the integration of advertisements into generated responses\npresents both commercial opportunities and challenges for user experience.\nUnlike traditional search, where advertisements are clearly delineated,\ngenerative systems blur the boundary between informational content and\npromotional material, raising concerns around transparency and trust. In this\nwork, we propose a modular pipeline for advertisement management in RAG-based\nconversational systems, consisting of an ad-rewriter for seamless ad\nintegration and a robust ad-classifier for detection. We leverage synthetic\ndata to train high-performing classifiers, which are then used to guide two\ncomplementary ad-integration strategies: supervised fine-tuning of the\nad-rewriter and a best-of-N sampling approach that selects the least detectable\nad-integrated response among multiple candidates. Our evaluation focuses on two\ncore questions: the effectiveness of ad classifiers in detecting diverse ad\nintegration strategies, and the training methods that best support coherent,\nminimally intrusive ad insertion. Experimental results show that our\nad-classifier, trained on synthetic advertisement data inspired by marketing\nstrategies and enhanced through curriculum learning, achieves robust detection\nperformance. Additionally, we demonstrate that classifier-guided optimization,\nthrough both fine-tuning and best-of-N sampling, significantly improves ad\nstealth, enabling more seamless integration. These findings contribute an\nadversarial co-evolution framework for developing more sophisticated ad-aware\ngenerative search systems and robust ad classifiers.",
        "url": "http://arxiv.org/abs/2507.00509v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00509v1",
        "arxiv_id": "2507.00509v1",
        "authors": [
            "To Eun Kim",
            "João Coelho",
            "Gbemileke Onilude",
            "Jai Singh"
        ],
        "submitted": "2025-07-01 07:24:29",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on advertisement integration and detection in conversational search, which is a specific application of search technologies. While it involves query understanding and ranking models, the primary focus is on advertisement management rather than information retrieval. The paper's relevance to the user's interests is somewhat limited, but it does touch on some related topics."
    },
    {
        "title": "Linearly Decoding Refused Knowledge in Aligned Language Models",
        "abstract": "Most commonly used language models (LMs) are instruction-tuned and aligned\nusing a combination of fine-tuning and reinforcement learning, causing them to\nrefuse users requests deemed harmful by the model. However, jailbreak prompts\ncan often bypass these refusal mechanisms and elicit harmful responses. In this\nwork, we study the extent to which information accessed via jailbreak prompts\nis decodable using linear probes trained on LM hidden states. We show that a\ngreat deal of initially refused information is linearly decodable. For example,\nacross models, the response of a jailbroken LM for the average IQ of a country\ncan be predicted by a linear probe with Pearson correlations exceeding $0.8$.\nSurprisingly, we find that probes trained on base models (which do not refuse)\nsometimes transfer to their instruction-tuned versions and are capable of\nrevealing information that jailbreaks decode generatively, suggesting that the\ninternal representations of many refused properties persist from base LMs\nthrough instruction-tuning. Importantly, we show that this information is not\nmerely \"leftover\" in instruction-tuned models, but is actively used by them: we\nfind that probe-predicted values correlate with LM generated pairwise\ncomparisons, indicating that the information decoded by our probes align with\nsuppressed generative behavior that may be expressed more subtly in other\ndownstream tasks. Overall, our results suggest that instruction-tuning does not\nwholly eliminate or even relocate harmful information in representation\nspace-they merely suppress its direct expression, leaving it both linearly\naccessible and indirectly influential in downstream behavior.",
        "url": "http://arxiv.org/abs/2507.00239v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00239v1",
        "arxiv_id": "2507.00239v1",
        "authors": [
            "Aryan Shrivastava",
            "Ari Holtzman"
        ],
        "submitted": "2025-06-30 20:13:49",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on language models and their internal representations, which is a topic in Natural Language Processing, but not specifically in the areas of interest."
    },
    {
        "title": "Verifiable Natural Language to Linear Temporal Logic Translation: A Benchmark Dataset and Evaluation Suite",
        "abstract": "Empirical evaluation of state-of-the-art natural-language (NL) to\ntemporal-logic (TL) translation systems reveals near-perfect performance on\nexisting benchmarks. However, current studies measure only the accuracy of the\ntranslation of NL logic into formal TL, ignoring a system's capacity to ground\natomic propositions into new scenarios or environments. This is a critical\nfeature, necessary for the verification of resulting formulas in a concrete\nstate space. Consequently, most NL-to-TL translation frameworks propose their\nown bespoke dataset in which the correct grounding is known a-priori, inflating\nperformance metrics and neglecting the need for extensible, domain-general\nsystems. In this paper, we introduce the Verifiable Linear Temporal Logic\nBenchmark ( VLTL-Bench), a unifying benchmark that measures verification and\nverifiability of automated NL-to-LTL translation. The dataset consists of three\nunique state spaces and thousands of diverse natural language specifications\nand corresponding formal specifications in temporal logic. Moreover, the\nbenchmark contains sample traces to validate the temporal logic expressions.\nWhile the benchmark directly supports end-to-end evaluation, we observe that\nmany frameworks decompose the process into i) lifting, ii) grounding, iii)\ntranslation, and iv) verification. The benchmark provides ground truths after\neach of these steps to enable researches to improve and evaluate different\nsubsteps of the overall problem. To encourage methodologically sound advances\nin verifiable NL-to-LTL translation approaches, we release VLTL-Bench here:\nhttps://www.kaggle.com/datasets/dubascudes/vltl bench.",
        "url": "http://arxiv.org/abs/2507.00877v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00877v1",
        "arxiv_id": "2507.00877v1",
        "authors": [
            "William H English",
            "Chase Walker",
            "Dominic Simon",
            "Sumit Kumar Jha",
            "Rickard Ewetz"
        ],
        "submitted": "2025-07-01 15:41:57",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)",
            "Found 'www' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling, which are the user's primary research interests. The paper focuses on natural language to temporal logic translation, which is a topic in Natural Language Processing, but it does not seem to be closely related to the user's background in e-commerce or real-time relevance optimization."
    },
    {
        "title": "Generative AI and the future of scientometrics: current topics and future questions",
        "abstract": "The aim of this paper is to review the use of GenAI in scientometrics, and to\nbegin a debate on the broader implications for the field. First, we provide an\nintroduction on GenAI's generative and probabilistic nature as rooted in\ndistributional linguistics. And we relate this to the debate on the extent to\nwhich GenAI might be able to mimic human 'reasoning'. Second, we leverage this\ndistinction for a critical engagement with recent experiments using GenAI in\nscientometrics, including topic labelling, the analysis of citation contexts,\npredictive applications, scholars' profiling, and research assessment. GenAI\nshows promise in tasks where language generation dominates, such as labelling,\nbut faces limitations in tasks that require stable semantics, pragmatic\nreasoning, or structured domain knowledge. However, these results might become\nquickly outdated. Our recommendation is, therefore, to always strive to\nsystematically compare the performance of different GenAI models for specific\ntasks. Third, we inquire whether, by generating large amounts of scientific\nlanguage, GenAI might have a fundamental impact on our field by affecting\ntextual characteristics used to measure science, such as authors, words, and\nreferences. We argue that careful empirical work and theoretical reflection\nwill be essential to remain capable of interpreting the evolving patterns of\nknowledge production.",
        "url": "http://arxiv.org/abs/2507.00783v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00783v1",
        "arxiv_id": "2507.00783v1",
        "authors": [
            "Benedetto Lepori",
            "Jens Peter Andersen",
            "Karsten Donnay"
        ],
        "submitted": "2025-07-01 14:22:16",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on Generative AI and its applications in scientometrics, which is a different field and does not align with the user's primary focus."
    },
    {
        "title": "LitBench: A Benchmark and Dataset for Reliable Evaluation of Creative Writing",
        "abstract": "Evaluating creative writing generated by large language models (LLMs) remains\nchallenging because open-ended narratives lack ground truths. Without\nperformant automated evaluation methods, off-the-shelf (OTS) language models\nare employed as zero-shot judges, yet their reliability is unclear in this\ncontext. In pursuit of robust evaluation for creative writing, we introduce\nLitBench, the first standardized benchmark and paired dataset for creative\nwriting verification, comprising a held-out test set of 2,480 debiased,\nhuman-labeled story comparisons drawn from Reddit and a 43,827-pair training\ncorpus of human preference labels. Using LitBench, we (i) benchmark zero-shot\nLLM judges, (ii) train Bradley Terry and generative reward models, and (iii)\nconduct an online human study to validate reward model rankings on newly\nLLM-generated stories. Our benchmark identifies Claude-3.7-Sonnet as the\nstrongest off-the-shelf judge, reaching 73% agreement with human preferences;\namong trained reward models, Bradley-Terry and Generative reward models both\nattain an accuracy of 78%, outperforming all off-the-shelf judges. An online\nhuman study further confirms that our trained reward models consistently align\nwith human preferences in novel LLM-generated stories. We release LitBench and\nreward models at\nhttps://huggingface.co/collections/SAA-Lab/litbench-68267b5da3aafe58f9e43461,\nproviding a vetted resource for reliable, automated evaluation and optimization\nof creative writing systems.",
        "url": "http://arxiv.org/abs/2507.00769v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00769v1",
        "arxiv_id": "2507.00769v1",
        "authors": [
            "Daniel Fein",
            "Sebastian Russo",
            "Violet Xiang",
            "Kabir Jolly",
            "Rafael Rafailov",
            "Nick Haber"
        ],
        "submitted": "2025-07-01 14:10:36",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on creative writing evaluation, large language models, and reward models, which are outside your primary areas of interest."
    },
    {
        "title": "Rethinking Group Recommender Systems in the Era of Generative AI: From One-Shot Recommendations to Agentic Group Decision Support",
        "abstract": "More than twenty-five years ago, first ideas were developed on how to design\na system that can provide recommendations to groups of users instead of\nindividual users. Since then, a rich variety of algorithmic proposals were\npublished, e.g., on how to acquire individual preferences, how to aggregate\nthem, and how to generate recommendations for groups of users. However, despite\nthe rich literature on the topic, barely any examples of real-world group\nrecommender systems can be found. This lets us question common assumptions in\nacademic research, in particular regarding communication processes in a group\nand how recommendation-supported decisions are made. In this essay, we argue\nthat these common assumptions and corresponding system designs often may not\nmatch the needs or expectations of users. We thus call for a reorientation in\nthis research area, leveraging the capabilities of modern Generative AI\nassistants like ChatGPT. Specifically, as one promising future direction, we\nenvision group recommender systems to be systems where human group members\ninteract in a chat and an AI-based group recommendation agent assists the\ndecision-making process in an agentic way. Ultimately, this shall lead to a\nmore natural group decision-making environment and finally to wider adoption of\ngroup recommendation systems in practice.",
        "url": "http://arxiv.org/abs/2507.00535v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00535v1",
        "arxiv_id": "2507.00535v1",
        "authors": [
            "Dietmar Jannach",
            "Amra Delić",
            "Francesco Ricci",
            "Markus Zanker"
        ],
        "submitted": "2025-07-01 07:56:37",
        "source": "arxiv",
        "comment": "Submitted for publication",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores group recommender systems, which is a related topic to information retrieval and search technologies. However, the focus on Generative AI and chat-based interaction is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's emphasis on group decision-making and chat-based interfaces is also not a central match for the user's research themes."
    },
    {
        "title": "Pitfalls of Evaluating Language Models with Open Benchmarks",
        "abstract": "Open Large Language Model (LLM) benchmarks, such as HELM and BIG-bench, offer\nstandardized, transparent protocols that facilitate the fair comparison,\nreproducibility, and iterative advancement of Language Models (LMs). However,\ntheir openness also introduces critical and underexplored pitfalls. This study\nexposes these weaknesses by systematically constructing ``cheating'' models --\nsmaller variants of BART, T5, and GPT-2 fine-tuned directly on public test sets\n-- which achieve top rankings on a prominent open, holistic benchmark (HELM)\ndespite poor generalization and limited practical utility. Our findings\nunderscore three key insights: \\ca high leaderboard performance on open\nbenchmarks may not always reflect real-world effectiveness; \\cb private or\ndynamic benchmarks must complement open evaluations to safeguard integrity; and\n\\cc a fundamental reevaluation of current benchmarking practices is essential\nto ensure robust and trustworthy LM assessments.",
        "url": "http://arxiv.org/abs/2507.00460v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00460v1",
        "arxiv_id": "2507.00460v1",
        "authors": [
            "Md. Najib Hasan",
            "Mohammad Fakhruddin Babar",
            "Souvika Sarkar",
            "Monowar Hasan",
            "Santu Karmaker"
        ],
        "submitted": "2025-07-01 06:17:48",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it touches on the topic of benchmarks, its focus is on language models and their evaluation, which is outside the scope of the user's primary research interests."
    },
    {
        "title": "Towards Style Alignment in Cross-Cultural Translation",
        "abstract": "Successful communication depends on the speaker's intended style (i.e., what\nthe speaker is trying to convey) aligning with the listener's interpreted style\n(i.e., what the listener perceives). However, cultural differences often lead\nto misalignment between the two; for example, politeness is often lost in\ntranslation. We characterize the ways that LLMs fail to translate style -\nbiasing translations towards neutrality and performing worse in non-Western\nlanguages. We mitigate these failures with RASTA (Retrieval-Augmented STylistic\nAlignment), a method that leverages learned stylistic concepts to encourage LLM\ntranslation to appropriately convey cultural communication norms and align\nstyle.",
        "url": "http://arxiv.org/abs/2507.00216v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00216v1",
        "arxiv_id": "2507.00216v1",
        "authors": [
            "Shreya Havaldar",
            "Adam Stein",
            "Eric Wong",
            "Lyle Ungar"
        ],
        "submitted": "2025-06-30 19:37:51",
        "source": "arxiv",
        "comment": "Accepted to ACL 2025",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on cross-cultural translation and style alignment, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on language models and translation, the context and goals of the paper are distinct from the user's areas of focus."
    },
    {
        "title": "Embedding-based Retrieval in Multimodal Content Moderation",
        "abstract": "Video understanding plays a fundamental role for content moderation on short\nvideo platforms, enabling the detection of inappropriate content. While\nclassification remains the dominant approach for content moderation, it often\nstruggles in scenarios requiring rapid and cost-efficient responses, such as\ntrend adaptation and urgent escalations. To address this issue, we introduce an\nEmbedding-Based Retrieval (EBR) method designed to complement traditional\nclassification approaches. We first leverage a Supervised Contrastive Learning\n(SCL) framework to train a suite of foundation embedding models, including both\nsingle-modal and multi-modal architectures. Our models demonstrate superior\nperformance over established contrastive learning methods such as CLIP and\nMoCo. Building on these embedding models, we design and implement the\nembedding-based retrieval system that integrates embedding generation and video\nretrieval to enable efficient and effective trend handling. Comprehensive\noffline experiments on 25 diverse emerging trends show that EBR improves\nROC-AUC from 0.85 to 0.99 and PR-AUC from 0.35 to 0.95. Further online\nexperiments reveal that EBR increases action rates by 10.32% and reduces\noperational costs by over 80%, while also enhancing interpretability and\nflexibility compared to classification-based solutions.",
        "url": "http://arxiv.org/abs/2507.01066v1",
        "pdf_url": "http://arxiv.org/pdf/2507.01066v1",
        "arxiv_id": "2507.01066v1",
        "authors": [
            "Hanzhong Liang",
            "Jinghao Shi",
            "Xiang Shen",
            "Zixuan Wang",
            "Vera Wen",
            "Ardalan Mehrani",
            "Zhiqian Chen",
            "Yifan Wu",
            "Zhixin Zhang"
        ],
        "submitted": "2025-06-30 19:11:25",
        "source": "arxiv",
        "comment": "Camera ready for SIGIR 2025",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on content moderation in short video platforms, using embedding-based retrieval to improve trend handling. While it involves multimodal content and retrieval, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core aspects of your research interests in Information Retrieval and Search technologies."
    },
    {
        "title": "Table Understanding and (Multimodal) LLMs: A Cross-Domain Case Study on Scientific vs. Non-Scientific Data",
        "abstract": "Tables are among the most widely used tools for representing structured data\nin research, business, medicine, and education. Although LLMs demonstrate\nstrong performance in downstream tasks, their efficiency in processing tabular\ndata remains underexplored. In this paper, we investigate the effectiveness of\nboth text-based and multimodal LLMs on table understanding tasks through a\ncross-domain and cross-modality evaluation. Specifically, we compare their\nperformance on tables from scientific vs. non-scientific contexts and examine\ntheir robustness on tables represented as images vs. text. Additionally, we\nconduct an interpretability analysis to measure context usage and input\nrelevance. We also introduce the TableEval benchmark, comprising 3017 tables\nfrom scholarly publications, Wikipedia, and financial reports, where each table\nis provided in five different formats: Image, Dictionary, HTML, XML, and LaTeX.\nOur findings indicate that while LLMs maintain robustness across table\nmodalities, they face significant challenges when processing scientific tables.",
        "url": "http://arxiv.org/abs/2507.00152v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00152v1",
        "arxiv_id": "2507.00152v1",
        "authors": [
            "Ekaterina Borisova",
            "Fabio Barth",
            "Nils Feldhus",
            "Raia Abu Ahmad",
            "Malte Ostendorff",
            "Pedro Ortiz Suarez",
            "Georg Rehm",
            "Sebastian Möller"
        ],
        "submitted": "2025-06-30 18:04:36",
        "source": "arxiv",
        "comment": "TRL@ACL 2025, camera-ready version",
        "score": 4,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of Large Language Models (LLMs) to table understanding tasks, which is related to information retrieval and natural language processing. However, the focus on table understanding and multimodal LLMs is not directly aligned with the user's primary interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "La Leaderboard: A Large Language Model Leaderboard for Spanish Varieties and Languages of Spain and Latin America",
        "abstract": "Leaderboards showcase the current capabilities and limitations of Large\nLanguage Models (LLMs). To motivate the development of LLMs that represent the\nlinguistic and cultural diversity of the Spanish-speaking community, we present\nLa Leaderboard, the first open-source leaderboard to evaluate generative LLMs\nin languages and language varieties of Spain and Latin America. La Leaderboard\nis a community-driven project that aims to establish an evaluation standard for\neveryone interested in developing LLMs for the Spanish-speaking community. This\ninitial version combines 66 datasets in Basque, Catalan, Galician, and\ndifferent Spanish varieties, showcasing the evaluation results of 50 models. To\nencourage community-driven development of leaderboards in other languages, we\nexplain our methodology, including guidance on selecting the most suitable\nevaluation setup for each downstream task. In particular, we provide a\nrationale for using fewer few-shot examples than typically found in the\nliterature, aiming to reduce environmental impact and facilitate access to\nreproducible results for a broader research community.",
        "url": "http://arxiv.org/abs/2507.00999v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00999v1",
        "arxiv_id": "2507.00999v1",
        "authors": [
            "María Grandury",
            "Javier Aula-Blasco",
            "Júlia Falcão",
            "Clémentine Fourrier",
            "Miguel González",
            "Gonzalo Martínez",
            "Gonzalo Santamaría",
            "Rodrigo Agerri",
            "Nuria Aldama",
            "Luis Chiruzzo",
            "Javier Conde",
            "Helena Gómez",
            "Marta Guerrero",
            "Guido Ivetta",
            "Natalia López",
            "Flor Miriam Plaza-del-Arco",
            "María Teresa Martín-Valdivia",
            "Helena Montoro",
            "Carmen Muñoz",
            "Pedro Reviriego",
            "Leire Rosado",
            "Alejandro Vaca",
            "María Estrella Vallecillo-Rodríguez",
            "Jorge Vallego",
            "Irune Zubiaga"
        ],
        "submitted": "2025-07-01 17:50:48",
        "source": "arxiv",
        "comment": "Accepted at ACL 2025 Main",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling. The focus on Large Language Models and their evaluation in Spanish-speaking languages is outside the user's primary areas of interest."
    },
    {
        "title": "EARN: Efficient Inference Acceleration for LLM-based Generative Recommendation by Register Tokens",
        "abstract": "Large Language Model-based generative recommendation (LLMRec) has achieved\nnotable success, but it suffers from high inference latency due to massive\ncomputational overhead and memory pressure of KV Cache. Existing KV Cache\nreduction methods face critical limitations: cache compression offers marginal\nacceleration given recommendation tasks' short decoding steps, while prompt\ncompression risks discarding vital interaction history. Through systematic\nanalysis of attention patterns in LLMRec, we uncover two pivotal insights: 1)\nlayer-wise attention sparsity inversion where early layers retain dense\ninformative patterns while later layers exhibit high redundancy, and 2) dual\nattention sinks phenomenon where attention scores concentrate on both head and\ntail tokens of input sequences. Motivated by these insights, we propose EARN,\nan efficient inference framework that leverages the early layers to compress\ninformation into register tokens placed at the input sequence boundaries, then\nfocuses solely on these tokens in the subsequent layers. Extensive experiments\non three datasets, two LLMRec methods and two LLM architectures demonstrate\nEARN's superiority, achieving up to 3.79x speedup and 80.8% KV Cache reduction\nwith better accuracy than the general finetuning approach. Our work bridges the\nefficiency-effectiveness gap in LLMRec, offering practical deployment\nadvantages for industrial scenarios.",
        "url": "http://arxiv.org/abs/2507.00715v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00715v1",
        "arxiv_id": "2507.00715v1",
        "authors": [
            "Chaoqun Yang",
            "Xinyu Lin",
            "Wenjie Wang",
            "Yongqi Li",
            "Teng Sun",
            "Xianjing Han",
            "Tat-Seng Chua"
        ],
        "submitted": "2025-07-01 12:42:06",
        "source": "arxiv",
        "comment": "Accepted by KDD 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on efficient inference acceleration for large language model-based generative recommendation, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions attention patterns, it does not explore ranking models or user behavior modeling, making it only loosely relevant to the user's research interests."
    },
    {
        "title": "TUM-MiKaNi at SemEval-2025 Task 3: Towards Multilingual and Knowledge-Aware Non-factual Hallucination Identification",
        "abstract": "Hallucinations are one of the major problems of LLMs, hindering their\ntrustworthiness and deployment to wider use cases. However, most of the\nresearch on hallucinations focuses on English data, neglecting the multilingual\nnature of LLMs. This paper describes our submission to the SemEval-2025 Task-3\n- Mu-SHROOM, the Multilingual Shared-task on Hallucinations and Related\nObservable Overgeneration Mistakes. We propose a two-part pipeline that\ncombines retrieval-based fact verification against Wikipedia with a BERT-based\nsystem fine-tuned to identify common hallucination patterns. Our system\nachieves competitive results across all languages, reaching top-10 results in\neight languages, including English. Moreover, it supports multiple languages\nbeyond the fourteen covered by the shared task. This multilingual hallucination\nidentifier can help to improve LLM outputs and their usefulness in the future.",
        "url": "http://arxiv.org/abs/2507.00579v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00579v1",
        "arxiv_id": "2507.00579v1",
        "authors": [
            "Miriam Anschütz",
            "Ekaterina Gikalo",
            "Niklas Herbster",
            "Georg Groh"
        ],
        "submitted": "2025-07-01 09:00:50",
        "source": "arxiv",
        "comment": "6 pages, 3 figures, SemEval-2025 Task 3, ACL",
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on hallucinations in Large Language Models (LLMs), which is a related topic to query understanding and ranking models. However, the paper's primary focus is on identifying hallucinations rather than query understanding or ranking models, and it does not directly relate to user behavior modeling or real-time relevance optimization. The paper's connection to information retrieval is indirect, as it aims to improve LLM outputs, which can potentially impact search results."
    },
    {
        "title": "Reliable Annotations with Less Effort: Evaluating LLM-Human Collaboration in Search Clarifications",
        "abstract": "Despite growing interest in using large language models (LLMs) to automate\nannotation, their effectiveness in complex, nuanced, and multi-dimensional\nlabelling tasks remains relatively underexplored. This study focuses on\nannotation for the search clarification task, leveraging a high-quality,\nmulti-dimensional dataset that includes five distinct fine-grained annotation\nsubtasks. Although LLMs have shown impressive capabilities in general settings,\nour study reveals that even state-of-the-art models struggle to replicate\nhuman-level performance in subjective or fine-grained evaluation tasks. Through\na systematic assessment, we demonstrate that LLM predictions are often\ninconsistent, poorly calibrated, and highly sensitive to prompt variations. To\naddress these limitations, we propose a simple yet effective human-in-the-loop\n(HITL) workflow that uses confidence thresholds and inter-model disagreement to\nselectively involve human review. Our findings show that this lightweight\nintervention significantly improves annotation reliability while reducing human\neffort by up to 45%, offering a relatively scalable and cost-effective yet\naccurate path forward for deploying LLMs in real-world evaluation settings.",
        "url": "http://arxiv.org/abs/2507.00543v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00543v1",
        "arxiv_id": "2507.00543v1",
        "authors": [
            "Leila Tavakoli",
            "Hamed Zamani"
        ],
        "submitted": "2025-07-01 08:04:58",
        "source": "arxiv",
        "comment": "9 pages,5 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the collaboration between large language models (LLMs) and humans in search clarifications, which is related to query understanding and ranking models. However, the focus on annotation and evaluation tasks is not directly aligned with my primary research interests in information retrieval, search technologies, and user behavior modeling."
    },
    {
        "title": "NIRANTAR: Continual Learning with New Languages and Domains on Real-world Speech Data",
        "abstract": "We introduce Nirantar, a comprehensive framework for evaluating continual\nlearning (CL) in multilingual and multi-domain ASR. Designed to reflect\nreal-world CL challenges, Nirantar leverages data collected incrementally\nacross 22 languages and 208 districts in India through natural episodes. This\nenables evaluation across Language-Incremental (LIL), Domain-Incremental (DIL),\nand the novel Language-Incremental Domain-Incremental Learning (LIDIL)\nscenarios. Unlike prior work that relies on simulated episodes, Nirantar\npresents dynamic, non-uniform language and domain shifts, making it an ideal\ntestbed for CL research. With 3250 hours of human-transcribed speech, including\n1720 hours newly introduced in this work, our framework enables systematic\nbenchmarking of CL methods. We evaluate existing approaches and demonstrate\nthat no single method performs consistently well, underscoring the need for\nmore robust CL strategies.",
        "url": "http://arxiv.org/abs/2507.00534v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00534v1",
        "arxiv_id": "2507.00534v1",
        "authors": [
            "Tahir Javed",
            "Kaushal Bhogale",
            "Mitesh M. Khapra"
        ],
        "submitted": "2025-07-01 07:53:39",
        "source": "arxiv",
        "comment": "Accepted in Interspecch 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on continual learning in speech recognition, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions multilingual and multi-domain aspects, the context is different from the user's primary research interests in IR and NLP."
    },
    {
        "title": "Overcoming Long-Context Limitations of State-Space Models via Context-Dependent Sparse Attention",
        "abstract": "Efficient long-context modeling remains a critical challenge for natural\nlanguage processing (NLP), as the time complexity of the predominant\nTransformer architecture scales quadratically with the sequence length. While\nstate-space models (SSMs) offer alternative sub-quadratic solutions, they\nstruggle to capture long-range dependencies effectively. In this work, we focus\non analyzing and improving the long-context modeling capabilities of SSMs. We\nshow that the widely used synthetic task, associative recall, which requires a\nmodel to recall a value associated with a single key without context,\ninsufficiently represents the complexities of real-world long-context modeling.\nTo address this limitation, we extend the associative recall to a novel\nsynthetic task, \\emph{joint recall}, which requires a model to recall the value\nassociated with a key given in a specified context. Theoretically, we prove\nthat SSMs do not have the expressiveness to solve multi-query joint recall in\nsub-quadratic time complexity. To resolve this issue, we propose a solution\nbased on integrating SSMs with Context-Dependent Sparse Attention (CDSA), which\nhas the expressiveness to solve multi-query joint recall with sub-quadratic\ncomputation. To bridge the gap between theoretical analysis and real-world\napplications, we propose locality-sensitive Hashing Attention with sparse Key\nSelection (HAX), which instantiates the theoretical solution and is further\ntailored to natural language domains. Extensive experiments on both synthetic\nand real-world long-context benchmarks show that HAX consistently outperforms\nSSM baselines and SSMs integrated with context-independent sparse attention\n(CISA).",
        "url": "http://arxiv.org/abs/2507.00449v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00449v1",
        "arxiv_id": "2507.00449v1",
        "authors": [
            "Zhihao Zhan",
            "Jianan Zhao",
            "Zhaocheng Zhu",
            "Jian Tang"
        ],
        "submitted": "2025-07-01 06:03:50",
        "source": "arxiv",
        "comment": "Proceedings of the 42nd International Conference on Machine Learning,\n  ES-FoMo III: 3rd Workshop on Efficient Systems for Foundation Models, 18\n  pages, 9 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on state-space models and attention mechanisms, which are not directly related to information retrieval, query understanding, or ranking models. While it touches on natural language processing, the specific context and methodology are not aligned with the user's primary research interests."
    },
    {
        "title": "Beyond Sociodemographic Prompting: Using Supervision to Align LLMs with Human Response Distributions",
        "abstract": "The ability to accurately predict how different population groups would\nanswer subjective questions would have great value. In this work, we show that\nuse of relatively simple supervision can greatly improve language model\nalignment with diverse population groups, as measured over three datasets\nspanning various topics. Beyond evaluating average performance, we also report\nhow alignment varies across specific groups. The simplicity and generality of\nour approach promotes easy adoption, while our broad findings provide useful\nguidance for when to use or not use our approach in practice. By conducting\nevaluation over many LLMs and prompting strategies, along with open-sourcing\nour work, we provide a useful benchmark to stimulate future research.",
        "url": "http://arxiv.org/abs/2507.00439v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00439v1",
        "arxiv_id": "2507.00439v1",
        "authors": [
            "Gauri Kambhatla",
            "Sanjana Gautam",
            "Angela Zhang",
            "Alex Liu",
            "Ravi Srinivasan",
            "Junyi Jessy Li",
            "Matthew Lease"
        ],
        "submitted": "2025-07-01 05:46:22",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the alignment of language models with human response distributions, which is related to query understanding and ranking models in Information Retrieval. However, the focus on language models and population groups is not directly aligned with the user's interests in search technologies, user behavior modeling, and deep semantic understanding."
    },
    {
        "title": "ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context",
        "abstract": "We introduce ASTRO, the \"Autoregressive Search-Taught Reasoner\", a framework\nfor training language models to reason like search algorithms, explicitly\nleveraging self-reflection, backtracking, and exploration in their outputs.\nRecently, training large language models (LLMs) via reinforcement learning (RL)\nhas led to the advent of reasoning models with greatly enhanced reasoning\ncapabilities. Open-source replications of reasoning models, while successful,\nbuild upon models that already exhibit strong reasoning capabilities along with\nsearch behavior observed even before RL. As a result, it is yet unclear how to\nboost the reasoning capabilities of other non-reasoner models including Llama\n3. ASTRO teaches such models to internalize structured search behavior through\na synthetic dataset derived from Monte Carlo Tree Search (MCTS) over\nmathematical problem-solving trajectories. By converting search traces into\nnatural language chain-of-thoughts that capture both successes and recoveries\nfrom failure, ASTRO bootstraps models with a rich prior for exploration during\nRL. We finetune our models on these search-derived traces and further improve\nperformance via RL with verifiable rewards. We apply ASTRO to the Llama 3\nfamily of models and achieve absolute performance gains of 16.0% on MATH-500,\n26.9% on AMC 2023, and 20.0% on AIME 2024, especially improving upon\nchallenging problems that require iterative correction. Our results demonstrate\nthat search-inspired training offers a principled way to instill robust\nreasoning capabilities into open LLMs.",
        "url": "http://arxiv.org/abs/2507.00417v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00417v1",
        "arxiv_id": "2507.00417v1",
        "authors": [
            "Joongwon Kim",
            "Anirudh Goyal",
            "Liang Tan",
            "Hannaneh Hajishirzi",
            "Srinivasan Iyer",
            "Tianlu Wang"
        ],
        "submitted": "2025-07-01 04:10:15",
        "source": "arxiv",
        "comment": "36 pages, 23 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper introduces a framework for training language models to reason like search algorithms, leveraging self-reflection, backtracking, and exploration. While it's related to search technologies and query understanding, the focus is on reasoning models rather than ranking models or user behavior modeling, which are core areas of interest. The connection to information retrieval is indirect, but the paper's emphasis on search-inspired training and its application to language models makes it somewhat relevant."
    },
    {
        "title": "Discourse Heuristics For Paradoxically Moral Self-Correction",
        "abstract": "Moral self-correction has emerged as a promising approach for aligning the\noutput of Large Language Models (LLMs) with human moral values. However, moral\nself-correction techniques are subject to two primary paradoxes. First, despite\nempirical and theoretical evidence to support the effectiveness of\nself-correction, this LLM capability only operates at a superficial level.\nSecond, while LLMs possess the capability of self-diagnosing immoral aspects of\ntheir output, they struggle to identify the cause of this moral inconsistency\nduring their self-correction process. To better understand and address these\nparadoxes, we analyze the discourse constructions in fine-tuning corpora\ndesigned to enhance moral self-correction, uncovering the existence of the\nheuristics underlying effective constructions. We demonstrate that moral\nself-correction relies on discourse constructions that reflect heuristic\nshortcuts, and that the presence of these heuristic shortcuts during\nself-correction leads to inconsistency when attempting to enhance both\nself-correction and self-diagnosis capabilities jointly. Based on our findings,\nwe propose a solution to improve moral self-correction by leveraging the\nheuristics of curated datasets. We also highlight the generalization challenges\nof this capability, particularly in terms of learning from situated context and\nmodel scales.",
        "url": "http://arxiv.org/abs/2507.00985v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00985v1",
        "arxiv_id": "2507.00985v1",
        "authors": [
            "Guangliang Liu",
            "Zimo Qi",
            "Xitong Zhang",
            "Kristen Marie Johnson"
        ],
        "submitted": "2025-07-01 17:36:41",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topic of moral self-correction in Large Language Models is not directly related to your focus on query understanding, ranking models, and user behavior modeling. The paper's emphasis on discourse constructions and heuristic shortcuts is also outside your area of expertise."
    },
    {
        "title": "Enhancing LLM Agent Safety via Causal Influence Prompting",
        "abstract": "As autonomous agents powered by large language models (LLMs) continue to\ndemonstrate potential across various assistive tasks, ensuring their safe and\nreliable behavior is crucial for preventing unintended consequences. In this\nwork, we introduce CIP, a novel technique that leverages causal influence\ndiagrams (CIDs) to identify and mitigate risks arising from agent\ndecision-making. CIDs provide a structured representation of cause-and-effect\nrelationships, enabling agents to anticipate harmful outcomes and make safer\ndecisions. Our approach consists of three key steps: (1) initializing a CID\nbased on task specifications to outline the decision-making process, (2)\nguiding agent interactions with the environment using the CID, and (3)\niteratively refining the CID based on observed behaviors and outcomes.\nExperimental results demonstrate that our method effectively enhances safety in\nboth code execution and mobile device control tasks.",
        "url": "http://arxiv.org/abs/2507.00979v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00979v1",
        "arxiv_id": "2507.00979v1",
        "authors": [
            "Dongyoon Hahm",
            "Woogyeol Jin",
            "June Suk Choi",
            "Sungsoo Ahn",
            "Kimin Lee"
        ],
        "submitted": "2025-07-01 17:31:51",
        "source": "arxiv",
        "comment": "Accepted at ACL 2025 Findings, Source code:\n  https://github.com/HahmDY/causal_influence_prompting.git",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling, which are the user's primary research interests. The paper focuses on enhancing the safety of autonomous agents powered by large language models, which is a topic in Natural Language Processing, but not directly relevant to the user's interests."
    },
    {
        "title": "The Cognate Data Bottleneck in Language Phylogenetics",
        "abstract": "To fully exploit the potential of computational phylogenetic methods for\ncognate data one needs to leverage specific (complex) models an machine\nlearning-based techniques. However, both approaches require datasets that are\nsubstantially larger than the manually collected cognate data currently\navailable. To the best of our knowledge, there exists no feasible approach to\nautomatically generate larger cognate datasets. We substantiate this claim by\nautomatically extracting datasets from BabelNet, a large multilingual\nencyclopedic dictionary. We demonstrate that phylogenetic inferences on the\nrespective character matrices yield trees that are largely inconsistent with\nthe established gold standard ground truth trees. We also discuss why we\nconsider it as being unlikely to be able to extract more suitable character\nmatrices from other multilingual resources. Phylogenetic data analysis\napproaches that require larger datasets can therefore not be applied to cognate\ndata. Thus, it remains an open question how, and if these computational\napproaches can be applied in historical linguistics.",
        "url": "http://arxiv.org/abs/2507.00911v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00911v1",
        "arxiv_id": "2507.00911v1",
        "authors": [
            "Luise Häuser",
            "Alexandros Stamatakis"
        ],
        "submitted": "2025-07-01 16:14:20",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "The paper is unrelated to Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling. It appears to be focused on computational phylogenetics and language, which is outside the scope of the user's research interests."
    },
    {
        "title": "MemeCMD: An Automatically Generated Chinese Multi-turn Dialogue Dataset with Contextually Retrieved Memes",
        "abstract": "Memes are widely used in online social interactions, providing vivid,\nintuitive, and often humorous means to express intentions and emotions.\nExisting dialogue datasets are predominantly limited to either manually\nannotated or pure-text conversations, lacking the expressiveness and contextual\nnuance that multimodal interactions provide.To address these challenges, we\nintroduce MemeCMD, an automatically generated Chinese Multi-turn Dialogue\ndataset with contextually retrieved memes. Our dataset combines a large-scale,\nMLLM-annotated meme library with dialogues auto-generated by dual agents across\ndiverse scenarios. We introduce a retrieval framework and adaptive threshold to\nensure contextually relevant, naturally spaced meme usage. Experiments\ndemonstrate the effectiveness of our approach in generating contextually\nappropriate and diverse meme-incorporated dialogues, offering a scalable and\nprivacy-preserving resource for advancing multimodal conversational AI.",
        "url": "http://arxiv.org/abs/2507.00891v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00891v1",
        "arxiv_id": "2507.00891v1",
        "authors": [
            "Yuheng Wang",
            "Xianhe Tang",
            "Pufeng Huang"
        ],
        "submitted": "2025-07-01 15:57:14",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on creating a dataset for multimodal dialogue generation with memes, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on conversational AI, the primary focus is on multimodal interactions and meme usage, which is not a core area of interest for the user."
    },
    {
        "title": "SAFER: Probing Safety in Reward Models with Sparse Autoencoder",
        "abstract": "Reinforcement learning from human feedback (RLHF) is a key paradigm for\naligning large language models (LLMs) with human values, yet the reward models\nat its core remain largely opaque. In this work, we present sparse Autoencoder\nFor Enhanced Reward model (\\textbf{SAFER}), a novel framework for interpreting\nand improving reward models through mechanistic analysis. Leveraging Sparse\nAutoencoders (SAEs), we uncover human-interpretable features in reward model\nactivations, enabling insight into safety-relevant decision-making. We apply\nSAFER to safety-oriented preference datasets and quantify the salience of\nindividual features by activation differences between chosen and rejected\nresponses. Using these feature-level signals, we design targeted data poisoning\nand denoising strategies. Experiments show that SAFER can precisely degrade or\nenhance safety alignment with minimal data modification, without sacrificing\ngeneral chat performance. Our approach contributes to interpreting, auditing\nand refining reward models in high-stakes LLM alignment tasks. Our codes are\navailable at https://github.com/xzy-101/SAFER-code. \\textit{This paper\ndiscusses topics related to large language model safety and may include\ndiscussions or examples that highlight potential risks or unsafe outcomes.}",
        "url": "http://arxiv.org/abs/2507.00665v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00665v1",
        "arxiv_id": "2507.00665v1",
        "authors": [
            "Sihang Li",
            "Wei Shi",
            "Ziyuan Xie",
            "Tao Liang",
            "Guojun Ma",
            "Xiang Wang"
        ],
        "submitted": "2025-07-01 11:04:03",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on reward models in reinforcement learning from human feedback, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions large language models, the primary concern is safety and auditing, rather than deep semantic understanding or real-time relevance optimization."
    },
    {
        "title": "Beat and Downbeat Tracking in Performance MIDI Using an End-to-End Transformer Architecture",
        "abstract": "Beat tracking in musical performance MIDI is a challenging and important task\nfor notation-level music transcription and rhythmical analysis, yet existing\nmethods primarily focus on audio-based approaches. This paper proposes an\nend-to-end transformer-based model for beat and downbeat tracking in\nperformance MIDI, leveraging an encoder-decoder architecture for\nsequence-to-sequence translation of MIDI input to beat annotations. Our\napproach introduces novel data preprocessing techniques, including dynamic\naugmentation and optimized tokenization strategies, to improve accuracy and\ngeneralizability across different datasets. We conduct extensive experiments\nusing the A-MAPS, ASAP, GuitarSet, and Leduc datasets, comparing our model\nagainst state-of-the-art hidden Markov models (HMMs) and deep learning-based\nbeat tracking methods. The results demonstrate that our model outperforms\nexisting symbolic music beat tracking approaches, achieving competitive\nF1-scores across various musical styles and instruments. Our findings highlight\nthe potential of transformer architectures for symbolic beat tracking and\nsuggest future integration with automatic music transcription systems for\nenhanced music analysis and score generation.",
        "url": "http://arxiv.org/abs/2507.00466v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00466v1",
        "arxiv_id": "2507.00466v1",
        "authors": [
            "Sebastian Murgul",
            "Michael Heizmann"
        ],
        "submitted": "2025-07-01 06:27:42",
        "source": "arxiv",
        "comment": "Accepted to the 22nd Sound and Music Computing Conference (SMC), 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not relevant to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on music-related tasks, such as beat tracking in performance MIDI, is outside the user's primary areas of interest."
    },
    {
        "title": "Modeling Data Diversity for Joint Instance and Verbalizer Selection in Cold-Start Scenarios",
        "abstract": "Prompt-based methods leverage the knowledge of pre-trained language models\n(PLMs) trained with a masked language modeling (MLM) objective; however, these\nmethods are sensitive to template, verbalizer, and few-shot instance selection,\nparticularly in cold-start settings with no labeled data. Existing studies\noverlook the dependency between instances and verbalizers, where instance-label\nprobabilities depend on verbalizer token proximity in the embedding space. To\naddress this, we propose COLDSELECT, a joint verbalizer and instance selection\napproach that models data diversity. COLDSELECT maps PLM vocabulary and\n$h_{[MASK]}$ embeddings into a shared space, applying dimensionality reduction\nand clustering to ensure efficient and diverse selection. By optimizing for\nminimal uncertainty and maximal diversity, COLDSELECT captures data\nrelationships effectively. Experiments on eight benchmarks demonstrate\nCOLDSELECT's superiority in reducing uncertainty and enhancing generalization,\noutperforming baselines in verbalizer and few-shot instance selection for\ncold-start scenarios.",
        "url": "http://arxiv.org/abs/2507.00330v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00330v1",
        "arxiv_id": "2507.00330v1",
        "authors": [
            "Mohna Chakraborty",
            "Adithya Kulkarni",
            "Qi Li"
        ],
        "submitted": "2025-07-01 00:01:50",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on a specific problem in natural language processing (NLP), namely joint instance and verbalizer selection in cold-start scenarios, which is not directly related to information retrieval, search technologies, or query understanding. While it leverages pre-trained language models, the approach is not applicable to ranking models or user behavior modeling, and the paper does not explore deep semantic understanding or real-time relevance optimization."
    },
    {
        "title": "Developing Lightweight DNN Models With Limited Data For Real-Time Sign Language Recognition",
        "abstract": "We present a novel framework for real-time sign language recognition using\nlightweight DNNs trained on limited data. Our system addresses key challenges\nin sign language recognition, including data scarcity, high computational\ncosts, and discrepancies in frame rates between training and inference\nenvironments. By encoding sign language specific parameters, such as handshape,\npalm orientation, movement, and location into vectorized inputs, and leveraging\nMediaPipe for landmark extraction, we achieve highly separable input data\nrepresentations. Our DNN architecture, optimized for sub 10MB deployment,\nenables accurate classification of 343 signs with less than 10ms latency on\nedge devices. The data annotation platform 'slait data' facilitates structured\nlabeling and vector extraction. Our model achieved 92% accuracy in isolated\nsign recognition and has been integrated into the 'slait ai' web application,\nwhere it demonstrates stable inference.",
        "url": "http://arxiv.org/abs/2507.00248v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00248v1",
        "arxiv_id": "2507.00248v1",
        "authors": [
            "Nikita Nikitin",
            "Eugene Fomin"
        ],
        "submitted": "2025-06-30 20:34:54",
        "source": "arxiv",
        "comment": "7 pages, 2 figures, 2 tables, for associated mpeg file, see\n  https://slait.app/static/Screen_Recording.mp4",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on developing a lightweight DNN model for real-time sign language recognition, which is not directly related to information retrieval, search technologies, or query understanding. Although it involves deep learning and data processing, the application domain is distinct from the user's primary research interests."
    },
    {
        "title": "Two-Stage Reasoning-Infused Learning: Improving Classification with LLM-Generated Reasoning",
        "abstract": "Standard classification models often map inputs directly to labels without\nexplicit reasoning, potentially limiting their performance, robustness, and\ninterpretability. This paper introduces a novel two-stage approach to enhance\ntext classification by leveraging Large Language Model (LLM)-generated\nreasonings. In the first stage, we fine-tune a Llama-3.2-1B-Instruct model\n(henceforth Llama-R-Gen) on a general-purpose reasoning dataset\n(syvai/reasoning-gen) to generate textual reasoning (R) given a question and\nits answer. In the second stage, this generally trained Llama-R-Gen is used\noffline to create an augmented training dataset for a downstream generative\nmodel. This downstream model, based on Llama-3.2-1B-Instruct, takes only the\ninput text (Q) and is trained to output the generated reasoning (R) immediately\nfollowed by the predicted emotion (A). We demonstrate this methodology on the\ndair-ai/emotion dataset for emotion classification. Our experiments show that\nthe generative model trained to output reasoning and the emotion (Classifier\nQ->RA) achieves a significant improvement of 8.7 percentage points in accuracy\n(for emotion prediction) compared to a baseline generative model trained solely\nto output the emotion (Classifier Q->A), highlighting the strong generalization\ncapabilities of the reasoning generation and the benefit of explicit reasoning\ntraining. This work underscores the potential of LLM-generated reasonings for\ncreating richer training datasets, thereby improving the performance of diverse\ndownstream NLP tasks and providing explicit explanations.",
        "url": "http://arxiv.org/abs/2507.00214v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00214v1",
        "arxiv_id": "2507.00214v1",
        "authors": [
            "Mads Henrichsen",
            "Rasmus Krebs"
        ],
        "submitted": "2025-06-30 19:34:57",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the use of Large Language Model-generated reasonings to improve text classification, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on text classification and emotion prediction is not directly aligned with the user's primary interests in search technologies and user behavior modeling."
    },
    {
        "title": "Should We Still Pretrain Encoders with Masked Language Modeling?",
        "abstract": "Learning high-quality text representations is fundamental to a wide range of\nNLP tasks. While encoder pretraining has traditionally relied on Masked\nLanguage Modeling (MLM), recent evidence suggests that decoder models\npretrained with Causal Language Modeling (CLM) can be effectively repurposed as\nencoders, often surpassing traditional encoders on text representation\nbenchmarks. However, it remains unclear whether these gains reflect an inherent\nadvantage of the CLM objective or arise from confounding factors such as model\nand data scale. In this paper, we address this question through a series of\nlarge-scale, carefully controlled pretraining ablations, training a total of 30\nmodels ranging from 210 million to 1 billion parameters, and conducting over\n15,000 fine-tuning and evaluation runs. We find that while training with MLM\ngenerally yields better performance across text representation tasks,\nCLM-trained models are more data-efficient and demonstrate improved fine-tuning\nstability. Building on these findings, we experimentally show that a biphasic\ntraining strategy that sequentially applies CLM and then MLM, achieves optimal\nperformance under a fixed computational training budget. Moreover, we\ndemonstrate that this strategy becomes more appealing when initializing from\nreadily available pretrained CLM models (from the existing LLM ecosystem),\nreducing the computational burden needed to train best-in-class encoder models.\nWe release all project artifacts at https://hf.co/MLMvsCLM to foster further\nresearch.",
        "url": "http://arxiv.org/abs/2507.00994v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00994v1",
        "arxiv_id": "2507.00994v1",
        "authors": [
            "Hippolyte Gisserot-Boukhlef",
            "Nicolas Boizard",
            "Manuel Faysse",
            "Duarte M. Alves",
            "Emmanuel Malherbe",
            "André F. T. Martins",
            "Céline Hudelot",
            "Pierre Colombo"
        ],
        "submitted": "2025-07-01 17:45:48",
        "source": "arxiv",
        "comment": "23 pages, 10 figures, 17 tables",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the effectiveness of different pretraining objectives for encoder models in NLP tasks, which is related to my interests in NLP and information retrieval. However, the focus on masked language modeling and causal language modeling is not directly aligned with my primary research themes, such as query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Mathematics Isn't Culture-Free: Probing Cultural Gaps via Entity and Scenario Perturbations",
        "abstract": "Although mathematics is often considered culturally neutral, the way\nmathematical problems are presented can carry implicit cultural context.\nExisting benchmarks like GSM8K are predominantly rooted in Western norms,\nincluding names, currencies, and everyday scenarios. In this work, we create\nculturally adapted variants of the GSM8K test set for five regions Africa,\nIndia, China, Korea, and Japan using prompt-based transformations followed by\nmanual verification. We evaluate six large language models (LLMs), ranging from\n8B to 72B parameters, across five prompting strategies to assess their\nrobustness to cultural variation in math problem presentation. Our findings\nreveal a consistent performance gap: models perform best on the original\nUS-centric dataset and comparatively worse on culturally adapted versions.\nHowever, models with reasoning capabilities are more resilient to these shifts,\nsuggesting that deeper reasoning helps bridge cultural presentation gaps in\nmathematical tasks",
        "url": "http://arxiv.org/abs/2507.00883v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00883v1",
        "arxiv_id": "2507.00883v1",
        "authors": [
            "Aditya Tomar",
            "Nihar Ranjan Sahoo",
            "Ashish Mittal",
            "Rudra Murthy",
            "Pushpak Bhattacharyya"
        ],
        "submitted": "2025-07-01 15:51:46",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'korea' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not directly related to Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling. The focus on mathematics and cultural adaptation of datasets is outside the scope of the user's research interests."
    },
    {
        "title": "Contrasting Cognitive Styles in Vision-Language Models: Holistic Attention in Japanese Versus Analytical Focus in English",
        "abstract": "Cross-cultural research in perception and cognition has shown that\nindividuals from different cultural backgrounds process visual information in\ndistinct ways. East Asians, for example, tend to adopt a holistic perspective,\nattending to contextual relationships, whereas Westerners often employ an\nanalytical approach, focusing on individual objects and their attributes. In\nthis study, we investigate whether Vision-Language Models (VLMs) trained\npredominantly on different languages, specifically Japanese and English,\nexhibit similar culturally grounded attentional patterns. Using comparative\nanalysis of image descriptions, we examine whether these models reflect\ndifferences in holistic versus analytic tendencies. Our findings suggest that\nVLMs not only internalize the structural properties of language but also\nreproduce cultural behaviors embedded in the training data, indicating that\ncultural cognition may implicitly shape model outputs.",
        "url": "http://arxiv.org/abs/2507.00700v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00700v1",
        "arxiv_id": "2507.00700v1",
        "authors": [
            "Ahmed Sabir",
            "Azinovič Gasper",
            "Mengsay Loem",
            "Rajesh Sharma"
        ],
        "submitted": "2025-07-01 11:56:45",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper explores the cultural differences in visual processing and attention patterns in Vision-Language Models, which is not directly related to Information Retrieval, Search technologies, or query understanding. The focus on language and cultural cognition is more relevant to NLP and cognitive science, but the abstract does not mention any relevance to ranking models, user behavior modeling, or real-time relevance optimization."
    },
    {
        "title": "Methodological Rigour in Algorithm Application: An Illustration of Topic Modelling Algorithm",
        "abstract": "The rise of advanced computational algorithms has opened new avenues for\ncomputationally intensive research approaches to theory development. However,\nthe opacity of these algorithms and lack of transparency and rigour in their\napplication pose methodological challenges, potentially undermining trust in\nresearch. The discourse on methodological rigour in this new genre of research\nis still emerging. Against this backdrop, I attempt to offer guidance on\nmethodological rigour, particularly in the context of topic modelling\nalgorithms. By illustrating the application of the structural topic modelling\nalgorithm and presenting a set of guidelines, I discuss how to ensure rigour in\ntopic modelling studies. Although the guidelines are for the application of\ntopic modelling algorithms, they can be applied to other algorithms with\ncontext-specific adjustments. The guidelines are helpful, especially for novice\nresearchers applying topic modelling, and editors and reviewers handling topic\nmodelling manuscripts. I contribute to the literature on topic modelling and\njoin the emerging dialogue on methodological rigour in computationally\nintensive theory construction research.",
        "url": "http://arxiv.org/abs/2507.00547v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00547v1",
        "arxiv_id": "2507.00547v1",
        "authors": [
            "Malmi Amadoru"
        ],
        "submitted": "2025-07-01 08:11:07",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on methodological rigour in algorithm application, specifically in topic modelling, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on computational algorithms, it does not address query understanding, ranking models, or user behavior modeling, which are core areas of interest."
    },
    {
        "title": "Exploring Large Action Sets with Hyperspherical Embeddings using von Mises-Fisher Sampling",
        "abstract": "This paper introduces von Mises-Fisher exploration (vMF-exp), a scalable\nmethod for exploring large action sets in reinforcement learning problems where\nhyperspherical embedding vectors represent these actions. vMF-exp involves\ninitially sampling a state embedding representation using a von Mises-Fisher\ndistribution, then exploring this representation's nearest neighbors, which\nscales to virtually unlimited numbers of candidate actions. We show that, under\ntheoretical assumptions, vMF-exp asymptotically maintains the same probability\nof exploring each action as Boltzmann Exploration (B-exp), a popular\nalternative that, nonetheless, suffers from scalability issues as it requires\ncomputing softmax values for each action. Consequently, vMF-exp serves as a\nscalable alternative to B-exp for exploring large action sets with\nhyperspherical embeddings. Experiments on simulated data, real-world public\ndata, and the successful large-scale deployment of vMF-exp on the recommender\nsystem of a global music streaming service empirically validate the key\nproperties of the proposed method.",
        "url": "http://arxiv.org/abs/2507.00518v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00518v1",
        "arxiv_id": "2507.00518v1",
        "authors": [
            "Walid Bendada",
            "Guillaume Salha-Galvan",
            "Romain Hennequin",
            "Théo Bontempelli",
            "Thomas Bouabça",
            "Tristan Cazenave"
        ],
        "submitted": "2025-07-01 07:32:54",
        "source": "arxiv",
        "comment": "42nd International Conference on Machine Learning (ICML 2025)",
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper explores reinforcement learning and hyperspherical embeddings, which is not directly related to the user's primary focus on Information Retrieval, Search technologies, and query understanding. While the paper mentions recommender systems, it is not specifically focused on information retrieval or deep semantic understanding."
    },
    {
        "title": "On Mitigating Data Sparsity in Conversational Recommender Systems",
        "abstract": "Conversational recommender systems (CRSs) capture user preference through\ntextual information in dialogues. However, they suffer from data sparsity on\ntwo fronts: the dialogue space is vast and linguistically diverse, while the\nitem space exhibits long-tail and sparse distributions. Existing methods\nstruggle with (1) generalizing to varied dialogue expressions due to\nunderutilization of rich textual cues, and (2) learning informative item\nrepresentations under severe sparsity. To address these problems, we propose a\nCRS model named DACRS. It consists of three modules, namely Dialogue\nAugmentation, Knowledge-Guided Entity Modeling, and Dialogue-Entity Matching.\nIn the Dialogue Augmentation module, we apply a two-stage augmentation pipeline\nto augment the dialogue context to enrich the data and improve\ngeneralizability. In the Knowledge-Guided Entity Modeling, we propose a\nknowledge graph (KG) based entity substitution and an entity similarity\nconstraint to enhance the expressiveness of entity embeddings. In the\nDialogue-Entity Matching module, we fuse the dialogue embedding with the\nmentioned entity embeddings through a dialogue-guided attention aggregation to\nacquire user embeddings that contain both the explicit and implicit user\npreferences. Extensive experiments on two public datasets demonstrate the\nstate-of-the-art performance of DACRS.",
        "url": "http://arxiv.org/abs/2507.00479v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00479v1",
        "arxiv_id": "2507.00479v1",
        "authors": [
            "Sixiao Zhang",
            "Mingrui Liu",
            "Cheng Long",
            "Wei Yuan",
            "Hongxu Chen",
            "Xiangyu Zhao",
            "Hongzhi Yin"
        ],
        "submitted": "2025-07-01 06:54:51",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on conversational recommender systems, which is a related topic to information retrieval. However, the paper's primary concern is on mitigating data sparsity in CRSs, which is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's techniques, such as dialogue augmentation and knowledge-guided entity modeling, are not directly applicable to the user's areas of interest."
    },
    {
        "title": "Gregorian melody, modality, and memory: Segmenting chant with Bayesian nonparametrics",
        "abstract": "The idea that Gregorian melodies are constructed from some vocabulary of\nsegments has long been a part of chant scholarship. This so-called\n\"centonisation\" theory has received much musicological criticism, but frequent\nre-use of certain melodic segments has been observed in chant melodies, and the\nintractable number of possible segmentations allowed the option that some\nundiscovered segmentation exists that will yet prove the value of\ncentonisation, and recent empirical results have shown that segmentations can\noutperform music-theoretical features in mode classification. Inspired by the\nfact that Gregorian chant was memorised, we search for an optimal unsupervised\nsegmentation of chant melody using nested hierarchical Pitman-Yor language\nmodels. The segmentation we find achieves state-of-the-art performance in mode\nclassification. Modeling a monk memorising the melodies from one liturgical\nmanuscript, we then find empirical evidence for the link between mode\nclassification and memory efficiency, and observe more formulaic areas at the\nbeginnings and ends of melodies corresponding to the practical role of modality\nin performance. However, the resulting segmentations themselves indicate that\neven such a memory-optimal segmentation is not what is understood as\ncentonisation.",
        "url": "http://arxiv.org/abs/2507.00380v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00380v1",
        "arxiv_id": "2507.00380v1",
        "authors": [
            "Vojtěch Lanz",
            "Jan Hajič jr"
        ],
        "submitted": "2025-07-01 02:28:09",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not related to Information Retrieval, Search technologies, or Natural Language Processing, and does not involve query understanding, ranking models, or user behavior modeling. The topic is musicology and focuses on segmenting Gregorian chant melodies using Bayesian nonparametrics, which is unrelated to the user's research interests."
    },
    {
        "title": "Open-ended Scientific Discovery via Bayesian Surprise",
        "abstract": "The promise of autonomous scientific discovery (ASD) hinges not only on\nanswering questions, but also on knowing which questions to ask. Most recent\nworks in ASD explore the use of large language models (LLMs) in goal-driven\nsettings, relying on human-specified research questions to guide hypothesis\ngeneration. However, scientific discovery may be accelerated further by\nallowing the AI system to drive exploration by its own criteria. The few\nexisting approaches in open-ended ASD select hypotheses based on diversity\nheuristics or subjective proxies for human interestingness, but the former\nstruggles to meaningfully navigate the typically vast hypothesis space, and the\nlatter suffers from imprecise definitions. This paper presents AutoDS -- a\nmethod for open-ended ASD that instead drives scientific exploration using\nBayesian surprise. Here, we quantify the epistemic shift from the LLM's prior\nbeliefs about a hypothesis to its posterior beliefs after gathering\nexperimental results. To efficiently explore the space of nested hypotheses,\nour method employs a Monte Carlo tree search (MCTS) strategy with progressive\nwidening using surprisal as the reward function. We evaluate AutoDS in the\nsetting of data-driven discovery across 21 real-world datasets spanning domains\nsuch as biology, economics, finance, and behavioral science. Our results\ndemonstrate that under a fixed budget, AutoDS substantially outperforms\ncompetitors by producing 5--29\\% more discoveries deemed surprising by the LLM.\nOur human evaluation further finds that two-thirds of AutoDS discoveries are\nsurprising to the domain experts, suggesting this is an important step forward\ntowards building open-ended ASD systems.",
        "url": "http://arxiv.org/abs/2507.00310v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00310v1",
        "arxiv_id": "2507.00310v1",
        "authors": [
            "Dhruv Agarwal",
            "Bodhisattwa Prasad Majumder",
            "Reece Adamson",
            "Megha Chakravorty",
            "Satvika Reddy Gavireddy",
            "Aditya Parashar",
            "Harshit Surana",
            "Bhavana Dalvi Mishra",
            "Andrew McCallum",
            "Ashish Sabharwal",
            "Peter Clark"
        ],
        "submitted": "2025-06-30 22:53:59",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to information retrieval, search technologies, or query understanding, which are the user's primary research interests. The paper focuses on autonomous scientific discovery, using Bayesian surprise as a reward function, which is outside the user's area of expertise."
    },
    {
        "title": "Natural language processing for African languages",
        "abstract": "Recent advances in word embeddings and language models use large-scale,\nunlabelled data and self-supervised learning to boost NLP performance.\nMultilingual models, often trained on web-sourced data like Wikipedia, face\nchallenges: few low-resource languages are included, their data is often noisy,\nand lack of labeled datasets makes it hard to evaluate performance outside\nhigh-resource languages like English. In this dissertation, we focus on\nlanguages spoken in Sub-Saharan Africa where all the indigenous languages in\nthis region can be regarded as low-resourced in terms of the availability of\nlabelled data for NLP tasks and unlabelled data found on the web. We analyse\nthe noise in the publicly available corpora, and curate a high-quality corpus,\ndemonstrating that the quality of semantic representations learned in word\nembeddings does not only depend on the amount of data but on the quality of\npre-training data. We demonstrate empirically the limitations of word\nembeddings, and the opportunities the multilingual pre-trained language model\n(PLM) offers especially for languages unseen during pre-training and\nlow-resource scenarios. We further study how to adapt and specialize\nmultilingual PLMs to unseen African languages using a small amount of\nmonolingual texts. To address the under-representation of the African languages\nin NLP research, we developed large scale human-annotated labelled datasets for\n21 African languages in two impactful NLP tasks: named entity recognition and\nmachine translation. We conduct an extensive empirical evaluation using\nstate-of-the-art methods across supervised, weakly-supervised, and transfer\nlearning settings.",
        "url": "http://arxiv.org/abs/2507.00297v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00297v1",
        "arxiv_id": "2507.00297v1",
        "authors": [
            "David Ifeoluwa Adelani"
        ],
        "submitted": "2025-06-30 22:26:36",
        "source": "arxiv",
        "comment": "PhD thesis",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on Natural Language Processing (NLP) for African languages, which is not directly related to Information Retrieval (IR) and Search technologies, the user's primary research interests. Although the paper mentions word embeddings and language models, which are relevant to NLP, the context and application are not aligned with the user's research themes."
    },
    {
        "title": "EfficientXLang: Towards Improving Token Efficiency Through Cross-Lingual Reasoning",
        "abstract": "Despite recent advances in Language Reasoning Models (LRMs), most research\nfocuses solely on English, even though many models are pretrained on\nmultilingual data. In this work, we investigate: Is English the most\ntoken-efficient language for reasoning? We evaluate three open-source RLMs:\nDeepSeek R1, Qwen 2.5 and Qwen 3, across four math datasets and seven\ntypologically diverse languages. We find that reasoning in non-English\nlanguages not only reduces token usage, but also preserves accuracy. These\ngains persist even after translating the reasoning traces into English,\nsuggesting genuine shifts in reasoning behavior rather than surface-level\nlinguistic effects. The extent of improvement, however, depends on the models\nmultilingual strength. Our findings motivate a broader view of reasoning in\nlanguage models, highlighting the potential of multilingual reasoning and the\nimportance of strong multilingual foundations. The code for our work can be\nfound: https://github.com/microsoft/EfficientXLang.",
        "url": "http://arxiv.org/abs/2507.00246v1",
        "pdf_url": "http://arxiv.org/pdf/2507.00246v1",
        "arxiv_id": "2507.00246v1",
        "authors": [
            "Sanchit Ahuja",
            "Praneetha Vaddamanu",
            "Barun Patra"
        ],
        "submitted": "2025-06-30 20:29:52",
        "source": "arxiv",
        "comment": "15 pages, 5 figures, 9 tables",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on Language Reasoning Models, which is a topic in NLP, but it does not seem to be directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling, which are the core research themes of the user. The paper's emphasis on multilingual language models and token efficiency is not a central match for the user's interests."
    }
]