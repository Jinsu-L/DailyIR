# Daily Papers Report - 2025-08-19

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. All for law and law for all: Adaptive RAG Pipeline for Legal Research

- **LLM Score**: 7
- **Keyword Score**: 8
- **Authors**: Figarri Keisha, Prince Singh, Pallavi, Dion Fernandes, Aravindh Manivannan, Ilham Wicaksono, Faisal Ahmad
- **URL**: <http://arxiv.org/abs/2508.13107v1>
- **Submitted**: 2025-08-18 17:14:03
- **Comment**: submitted to NLLP 2025 Workshop
- **Topic Keywords**: query, rag, retrieval, search
- **Reason**: The paper explores Retrieval-Augmented Generation (RAG) in the legal domain, which is related to query understanding and ranking models. The context-aware query translator and open-source retrieval strategies are also relevant to information retrieval. However, the focus on legal research assistance and the use of legal-grounded prompts are not directly aligned with the user's primary interests in e-commerce and real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Retrieval-Augmented Generation (RAG) for legal research
- **Aim**: Mitigate hallucinations in large language models (LLMs) by grounding responses in domain-specific documents
- **Rationale**: Context-aware query translation, open-source retrieval strategies, and comprehensive evaluation and generation framework
- **Ground**: Domain-specific documents and LegalBenchRAG corpus
- **Experiment**: Evaluation of RAG pipeline using LegalBenchRAG-mini, comparison of open-source embedding models, and testing of state-of-the-art embedding model
- **Takeaway**: Custom-crafted prompt with GPT-4o-mini outperforms state-of-the-art model, RetroMAE, and ideal choice for legal research assistance

#### Abstract
> Retrieval-Augmented Generation (RAG) mitigates hallucinations by grounding
large language model outputs in cited sources, a capability that is especially
critical in the legal domain. We present an end-to-end RAG pipeline that
revisits and extends the LegalBenchRAG baseline with three targeted
enhancements: (i) a context-aware query translator that disentangles document
references from natural-language questions and adapts retrieval depth and
response style based on expertise and specificity, (ii) open-source retrieval
strategies using SBERT and GTE embeddings that achieve substantial performance
gains (improving Recall@K by 30-95\% and Precision@K by $\sim$2.5$\times$ for
$K>4$) while remaining cost-efficient, and (iii) a comprehensive evaluation and
generation framework that combines RAGAS, BERTScore-F1, and ROUGE-Recall to
assess semantic alignment and faithfulness across models and prompt designs.
Our results show that carefully designed open-source pipelines can rival or
outperform proprietary approaches in retrieval quality, while a custom
legal-grounded prompt consistently produces more faithful and contextually
relevant answers than baseline prompting. Taken together, these contributions
demonstrate the potential of task-aware, component-level tuning to deliver
legally grounded, reproducible, and cost-effective RAG systems for legal
research assistance.

---

### 2. Is This News Still Interesting to You?: Lifetime-aware Interest Matching for News Recommendation

- **LLM Score**: 6
- **Keyword Score**: 5
- **Authors**: Seongeun Ryu, Yunyong Ko, Sang-Wook Kim
- **URL**: <http://arxiv.org/abs/2508.13064v1>
- **Submitted**: 2025-08-18 16:36:27
- **Comment**: 10 pages, 7 figures, 4 tables, accepted at ACM International
  Conference on Information and Knowledge Management (CIKM)
- **Topic Keywords**: rag, click, recommend
- **Reason**: The paper focuses on news recommendation, which is related to information retrieval and search technologies. The use of lifetime-aware interest matching and attention mechanisms is somewhat relevant to query understanding and ranking models. However, the paper's primary focus on news recommendation and its emphasis on freshness and lifetime of news articles do not directly align with the user's interests in deep semantic understanding and real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Personalized News Recommendation using Lifetime-aware Interest Matching
- **Aim**: To deliver news articles aligned with users' interests to alleviate information overload on online news platforms
- **Rationale**: Existing works fail to leverage the age of clicked news to infer users' interest persistence and model the varying lifetime of news across topics and users
- **Ground**: The LIME framework incorporates three key strategies: user-topic lifetime-aware age representation, candidate-aware lifetime attention, and freshness-guided interest refinement
- **Experiment**: Extensive experiments on two real-world datasets demonstrate that LIME consistently outperforms existing state-of-the-art approaches, with statistically significant improvements in AUC, MRR, nDCG@5, and nDCG@10
- **Takeaway**: LIME is a promising approach to personalized news recommendation that can better capture the time-sensitive nature of news and user interests

#### Abstract
> Personalized news recommendation aims to deliver news articles aligned with
users' interests, serving as a key solution to alleviate the problem of
information overload on online news platforms. While prior work has improved
interest matching through refined representations of news and users, the
following time-related challenges remain underexplored: (C1) leveraging the age
of clicked news to infer users' interest persistence, and (C2) modeling the
varying lifetime of news across topics and users. To jointly address these
challenges, we propose a novel Lifetime-aware Interest Matching framework for
nEws recommendation, named LIME, which incorporates three key strategies: (1)
User-Topic lifetime-aware age representation to capture the relative age of
news with respect to a user-topic pair, (2) Candidate-aware lifetime attention
for generating temporally aligned user representation, and (3) Freshness-guided
interest refinement for prioritizing valid candidate news at prediction time.
Extensive experiments on two real-world datasets demonstrate that LIME
consistently outperforms a wide range of state-of-the-art news recommendation
methods, and its model agnostic strategies significantly improve recommendation
accuracy.

---

### 3. Bridging Human and LLM Judgments: Understanding and Narrowing the Gap

- **LLM Score**: 6
- **Keyword Score**: 3
- **Authors**: Felipe Maia Polo, Xinhe Wang, Mikhail Yurochkin, Gongjun Xu, Moulinath Banerjee, Yuekai Sun
- **URL**: <http://arxiv.org/abs/2508.12792v1>
- **Submitted**: 2025-08-18 10:14:20
- **Topic Keywords**: pairwise
- **Reason**: The paper explores the gap between human and Large Language Model (LLM) judgments, which is related to query understanding and ranking models in Information Retrieval. However, the focus is on LLMs as judges, rather than search technologies or user behavior modeling, which are core aspects of the user's research interests.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Evaluating Large Language Models
- **Aim**: Bridge the gap between human and LLM evaluations
- **Rationale**: Model deviations of LLMs from human judgments as linear transformations of covariates
- **Ground**: Latent human preference score for each prompt-response pair
- **Experiment**: Six LLM judges and two benchmarks
- **Takeaway**: Bridge achieves higher agreement with human ratings and exposes systematic human-LLM gaps

#### Abstract
> Large language models are increasingly used as judges (LLM-as-a-judge) to
evaluate model outputs at scale, but their assessments often diverge
systematically from human judgments. We present Bridge, a unified statistical
framework that explicitly bridges human and LLM evaluations under both absolute
scoring and pairwise comparison paradigms. Bridge posits a latent human
preference score for each prompt-response pair and models LLM deviations as
linear transformations of covariates that capture sources of discrepancies.
This offers a simple and principled framework for refining LLM ratings and
characterizing systematic discrepancies between humans and LLMs. We provide an
efficient fitting algorithm with asymptotic guarantees for statistical
inference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot
Arena), Bridge achieves higher agreement with human ratings (accuracy,
calibration, and KL divergence) and exposes systematic human-LLM gaps.

---

### 4. AutoBnB-RAG: Enhancing Multi-Agent Incident Response with Retrieval-Augmented Generation

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Zefang Liu, Arman Anwar
- **URL**: <http://arxiv.org/abs/2508.13118v1>
- **Submitted**: 2025-08-18 17:22:51
- **Topic Keywords**: queries, rag, retrieval
- **Reason**: The paper is somewhat related to information retrieval, as it discusses retrieval-augmented generation in the context of multi-agent incident response. However, the focus is on cybersecurity and decision-making, which is not directly aligned with the user's primary research interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is limited to the retrieval aspect, which is only a small part of the overall research.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: AutoBnB-RAG: A Retrieval-Augmented Generation Framework for Multi-Agent Incident Response Simulations
- **Aim**: To enhance decision-making in incident response by allowing agents to issue retrieval queries and incorporate external evidence during collaborative investigations
- **Rationale**: To simulate real-world practice of cybersecurity teams consulting documentation and threat intelligence, and to evaluate the effectiveness of different team structures and the RAG mechanism in incident response
- **Ground**: The framework is built on the Backdoors & Breaches (B&B) tabletop game environment, and validated through simulations of three real-world cybersecurity incidents based on public breach disclosures
- **Experiment**: Eight team structures are evaluated, including homogeneous and heterogeneous centralized, decentralized, hierarchical, and argumentative structures, with distinct roles designed to promote critical thinking and diverse reasoning
- **Takeaway**: The AutoBnB-RAG framework demonstrates the potential for enhancing situational awareness, factual grounding, and overall response quality in centralized and hierarchical teams through the use of retrieval-informed reasoning and argumentative roles

#### Abstract
> Incident response (IR) requires fast, coordinated, and well-informed
decision-making to contain and mitigate cyber threats. While large language
models (LLMs) have shown promise as autonomous agents in simulated IR settings,
their reasoning is often limited by a lack of access to external knowledge. In
this work, we present AutoBnB-RAG, an extension of the AutoBnB framework that
incorporates retrieval-augmented generation (RAG) into multi-agent incident
response simulations. Built on the Backdoors & Breaches (B&B) tabletop game
environment, AutoBnB-RAG enables agents to issue retrieval queries and
incorporate external evidence during collaborative investigations. We introduce
two retrieval settings: one grounded in curated technical documentation
(RAG-Wiki), and another using narrative-style incident reports (RAG-News). We
evaluate performance across eight team structures, including newly introduced
argumentative configurations designed to promote critical reasoning. To
validate practical utility, we also simulate real-world cyber incidents based
on public breach reports, demonstrating AutoBnB-RAG's ability to reconstruct
complex multi-stage attacks. Our results show that retrieval augmentation
improves decision quality and success rates across diverse organizational
models. This work demonstrates the value of integrating retrieval mechanisms
into LLM-based multi-agent systems for cybersecurity decision-making.

---

### 5. D-RDW: Diversity-Driven Random Walks for News Recommender Systems

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Runze Li, Lucien Heitz, Oana Inel, Abraham Bernstein
- **URL**: <http://arxiv.org/abs/2508.13035v1>
- **Submitted**: 2025-08-18 15:53:30
- **Comment**: 6 pages
- **Topic Keywords**: ranking, recommend, rank
- **Reason**: The paper focuses on recommender systems, specifically news recommender systems, which is somewhat related to the user's interests in information retrieval and search technologies. However, the emphasis on diversity-driven random walks and societal recommender systems is not directly aligned with the user's primary focus on query understanding, ranking models, and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Diversity-Driven Random Walks (D-RDW) for news recommender systems
- **Aim**: Generate diverse news recommendations by combining traditional random walk algorithms with customizable target distributions of news article properties
- **Rationale**: Incorporate editorial and journalistic values into recommendations, facilitating experiments with norms and values and assessing their societal impact
- **Ground**: Evaluate the performance of D-RDW on the Ekstra Bladet News Recommendation Dataset (EB-NeRD) using various baseline algorithms
- **Experiment**: Compare D-RDW with state-of-the-art neural models and random walk-based approaches, and experiment with various algorithms to improve neural model performance
- **Takeaway**: D-RDW outperforms state-of-the-art neural models across key diversity metrics, is computationally efficient, and highlights the importance of normative frameworks and user-centric approaches in achieving diverse and satisfying recommendations

#### Abstract
> This paper introduces Diversity-Driven RandomWalks (D-RDW), a lightweight
algorithm and re-ranking technique that generates diverse news recommendations.
D-RDW is a societal recommender, which combines the diversification
capabilities of the traditional random walk algorithms with customizable target
distributions of news article properties. In doing so, our model provides a
transparent approach for editors to incorporate norms and values into the
recommendation process. D-RDW shows enhanced performance across key diversity
metrics that consider the articles' sentiment and political party mentions when
compared to state-of-the-art neural models. Furthermore, D-RDW proves to be
more computationally efficient than existing approaches.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Informfully Recommenders -- Reproducibility Framework for Diversity-aware Intra-session Recommendations

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Lucien Heitz, Runze Li, Oana Inel, Abraham Bernstein
- **URL**: <http://arxiv.org/abs/2508.13019v1>
- **Submitted**: 2025-08-18 15:37:41
- **Comment**: 10 pages
- **Topic Keywords**: ranking, recommend, rank
- **Reason**: The paper focuses on recommender systems, which is somewhat related to the user's interests in search technologies and query understanding. However, the emphasis on diversity-aware intra-session recommendations and normative reproducibility framework is not directly aligned with the user's primary focus on information retrieval, especially in areas that require deep semantic understanding and real-time relevance optimization.

#### Abstract
> Norm-aware recommender systems have gained increased attention, especially
for diversity optimization. The recommender systems community has
well-established experimentation pipelines that support reproducible
evaluations by facilitating models' benchmarking and comparisons against
state-of-the-art methods. However, to the best of our knowledge, there is
currently no reproducibility framework to support thorough norm-driven
experimentation at the pre-processing, in-processing, post-processing, and
evaluation stages of the recommender pipeline. To address this gap, we present
Informfully Recommenders, a first step towards a normative reproducibility
framework that focuses on diversity-aware design built on Cornac. Our extension
provides an end-to-end solution for implementing and experimenting with
normative and general-purpose diverse recommender systems that cover 1) dataset
pre-processing, 2) diversity-optimized models, 3) dedicated intrasession item
re-ranking, and 4) an extensive set of diversity metrics. We demonstrate the
capabilities of our extension through an extensive offline experiment in the
news domain.

### 7. Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Yong Deng, Guoqing Wang, Zhenzhe Ying, Xiaofeng Wu, Jinzhen Lin, Wenwen Xiong, Yuqin Dai, Shuo Yang, Zhanwei Zhang, Qiwen Wang, Yang Qin, Changhua Meng
- **URL**: <http://arxiv.org/abs/2508.12800v2>
- **Submitted**: 2025-08-18 10:23:10
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper proposes a novel reinforcement learning framework for agentic deep research, which is not directly related to information retrieval or search technologies. While it mentions language models and retrieval-augmented generation, the focus is on enhancing problem-solving abilities and multi-hop reasoning, rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> Large language models (LLMs) exhibit remarkable problem-solving abilities,
but struggle with complex tasks due to static internal knowledge.
Retrieval-Augmented Generation (RAG) enhances access to external information,
yet remains limited in multi-hop reasoning and strategic search due to rigid
workflows. Recent advancements in agentic deep research empower LLMs to
autonomously reason, search, and synthesize information. However, current
approaches relying on outcome-based reinforcement learning (RL) face critical
issues such as conflicting gradients and reward sparsity, limiting performance
gains and training efficiency. To address these, we first propose Atomic
Thought, a novel LLM thinking paradigm that decomposes reasoning into
fine-grained functional units. These units are supervised by Reasoning Reward
Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained
guidance. Building on this, we propose Atom-Searcher, a novel RL framework for
agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher
uses a curriculum-inspired reward schedule, prioritizing process-level ATR
early and transitioning to outcome rewards, accelerating convergence on
effective reasoning paths. Experiments on seven benchmarks show consistent
improvements over the state-of-the-art. Key advantages include: (1)
Atom-Searcher scales computation at test-time. (2) Atomic Thought provides
supervision anchors for RRMs, bridging deep research tasks and RRMs. (3)
Atom-Searcher exhibits more interpretable, human-like reasoning patterns.

### 8. WebMall -- A Multi-Shop Benchmark for Evaluating Web Agents

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Ralph Peeters, Aaron Steiner, Luca Schwarz, Julian Yuya Caspary, Christian Bizer
- **URL**: <http://arxiv.org/abs/2508.13024v1>
- **Submitted**: 2025-08-18 15:41:22
- **Topic Keywords**: shopping, commerce, e-commerce, search
- **Reason**: The paper introduces a benchmark for evaluating web agents in e-commerce scenarios, focusing on comparison-shopping tasks across multiple shops. While it touches on topics related to information retrieval and search technologies, the primary focus is on evaluating web agents' effectiveness and efficiency, rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest for you.

#### Abstract
> LLM-based web agents have the potential to automate long-running web tasks,
such as finding offers for specific products in multiple online shops and
subsequently ordering the cheapest products that meet the users needs. This
paper introduces WebMall, a multi-shop online shopping benchmark for evaluating
the effectiveness and efficiency of web agents for comparison-shopping. WebMall
consists of four simulated online shops populated with authentic product offers
sourced from the Common Crawl, alongside a suite of 91 cross-shop tasks. These
tasks include basic tasks such as finding specific products in multiple shops,
performing price comparisons, adding items to the shopping cart, and completing
checkout. Advanced tasks involve searching for products based on vague
requirements, identifying suitable substitutes, and finding compatible
products. Compared to existing e-commerce benchmarks, such as WebShop or
ShoppingBench, WebMall introduces comparison-shopping tasks across multiple
shops. Furthermore, the product offers are more heterogeneous, as they
originate from hundreds of distinct real-world shops. The tasks in WebMall
require longer interaction trajectories than those in WebShop, while remaining
representative of real-world shopping behaviors. We evaluate eight baseline
agents on WebMall, varying in observation modality, memory utilization, and
underlying large language model (GPT 4.1 and Claude Sonnet 4). The
best-performing configurations achieve completion rates of 75% and 53%, and F1
scores of 87% and 63%, on the basic and advanced task sets, respectively.
WebMall is publicly released to facilitate research on web agents and to
promote advancements in navigation, reasoning, and efficiency within e-commerce
scenarios.

### 9. Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: David Heineman, Valentin Hofmann, Ian Magnusson, Yuling Gu, Noah A. Smith, Hannaneh Hajishirzi, Kyle Lo, Jesse Dodge
- **URL**: <http://arxiv.org/abs/2508.13144v1>
- **Submitted**: 2025-08-18 17:56:04
- **Topic Keywords**: rag, recommend
- **Reason**: The paper focuses on language model evaluation, introducing metrics for signal and noise, and proposing interventions to improve benchmark quality. While it touches on the topic of model evaluation, which is related to query understanding and ranking models in IR, it does not directly address the user's core research themes. The paper's scope is limited to language models and evaluation, making it only loosely relevant to the user's interests.

#### Abstract
> Developing large language models is expensive and involves making decisions
with small experiments, typically by evaluating on large, multi-task evaluation
suites. In this work, we analyze specific properties which make a benchmark
more reliable for such decisions, and interventions to design higher-quality
evaluation benchmarks. We introduce two key metrics that show differences in
current benchmarks: signal, a benchmark's ability to separate better models
from worse models, and noise, a benchmark's sensitivity to random variability
between training steps. We demonstrate that benchmarks with a better
signal-to-noise ratio are more reliable when making decisions at small scale,
and those with less noise have lower scaling law prediction error. These
results suggest that improving signal or noise will lead to more useful
benchmarks, so we introduce three interventions designed to directly affect
signal or noise. For example, we propose that switching to a metric that has
better signal and noise (e.g., perplexity rather than accuracy) leads to better
reliability and improved scaling law error. We also find that filtering noisy
subtasks, to improve an aggregate signal-to-noise ratio, leads to more reliable
multi-task evaluations. We also find that averaging the output of a model's
intermediate checkpoints to reduce noise leads to consistent improvements. We
conclude by recommending that those creating new benchmarks, or selecting which
existing benchmarks to use, aim for high signal and low noise. We use 30
benchmarks for these experiments, and 375 open-weight language models from 60M
to 32B parameters, resulting in a new, publicly available dataset of 900K
evaluation benchmark results, totaling 200M instances.

### 10. Learning to Steer: Input-dependent Steering for Multimodal LLMs

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Jayneel Parekh, Pegah Khayatan, Mustafa Shukor, Arnaud Dapogny, Alasdair Newson, Matthieu Cord
- **URL**: <http://arxiv.org/abs/2508.12815v1>
- **Submitted**: 2025-08-18 10:53:20
- **Topic Keywords**: query
- **Reason**: The paper explores steering techniques for multimodal language models, which is a related topic in the broader field of Natural Language Processing. However, the focus on multimodal LLMs and the specific problem of input-dependent steering does not directly align with the user's interests in query understanding, ranking models, and user behavior modeling in the context of information retrieval.

#### Abstract
> Steering has emerged as a practical approach to enable post-hoc guidance of
LLMs towards enforcing a specific behavior. However, it remains largely
underexplored for multimodal LLMs (MLLMs); furthermore, existing steering
techniques, such as mean steering, rely on a single steering vector, applied
independently of the input query. This paradigm faces limitations when the
desired behavior is dependent on the example at hand. For example, a safe
answer may consist in abstaining from answering when asked for an illegal
activity, or may point to external resources or consultation with an expert
when asked about medical advice. In this paper, we investigate a fine-grained
steering that uses an input-specific linear shift. This shift is computed using
contrastive input-specific prompting. However, the input-specific prompts
required for this approach are not known at test time. Therefore, we propose to
train a small auxiliary module to predict the input-specific steering vector.
Our approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces
hallucinations and enforces safety in MLLMs, outperforming other static
baselines.

### 11. Spot the BlindSpots: Systematic Identification and Quantification of Fine-Grained LLM Biases in Contact Center Summaries

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Kawin Mayilvaghanan, Siddhant Gupta, Ayush Kumar
- **URL**: <http://arxiv.org/abs/2508.13124v1>
- **Submitted**: 2025-08-18 17:31:03
- **Topic Keywords**: rag
- **Reason**: The paper explores the biases in Large Language Models (LLMs) in the context of contact center summaries, which is a specific application of Natural Language Processing (NLP). While it touches on some aspects of query understanding and ranking models, the focus is more on the biases and their quantification rather than the core IR and search technologies that align with your primary research interests.

#### Abstract
> Abstractive summarization is a core application in contact centers, where
Large Language Models (LLMs) generate millions of summaries of call transcripts
daily. Despite their apparent quality, it remains unclear whether LLMs
systematically under- or over-attend to specific aspects of the transcript,
potentially introducing biases in the generated summary. While prior work has
examined social and positional biases, the specific forms of bias pertinent to
contact center operations - which we term Operational Bias - have remained
unexplored. To address this gap, we introduce BlindSpot, a framework built upon
a taxonomy of 15 operational bias dimensions (e.g., disfluency, speaker, topic)
for the identification and quantification of these biases. BlindSpot leverages
an LLM as a zero-shot classifier to derive categorical distributions for each
bias dimension in a pair of transcript and its summary. The bias is then
quantified using two metrics: Fidelity Gap (the JS Divergence between
distributions) and Coverage (the percentage of source labels omitted). Using
BlindSpot, we conducted an empirical study with 2500 real call transcripts and
their summaries generated by 20 LLMs of varying scales and families (e.g., GPT,
Llama, Claude). Our analysis reveals that biases are systemic and present
across all evaluated models, regardless of size or family.

### 12. Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Zeyu Zhang, Yang Zhang, Haoran Tan, Rui Li, Xu Chen
- **URL**: <http://arxiv.org/abs/2508.13250v1>
- **Submitted**: 2025-08-18 13:34:37
- **Comment**: 15 pages, 13 figures, 3 tables
- **Topic Keywords**: personalization, search
- **Reason**: The paper explores memory mechanisms for personalization in large language model-based agents, which is a related topic to information retrieval and search technologies. However, the focus on multi-hop reasoning and complex tasks is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> In large language model-based agents, memory serves as a critical capability
for achieving personalization by storing and utilizing users' information.
Although some previous studies have adopted memory to implement user
personalization, they typically focus on preference alignment and simple
question-answering. However, in the real world, complex tasks often require
multi-hop reasoning on a large amount of user information, which poses
significant challenges for current memory approaches. To address this
limitation, we propose the multi-hop personalized reasoning task to explore how
different memory mechanisms perform in multi-hop reasoning over personalized
information. We explicitly define this task and construct a dataset along with
a unified evaluation framework. Then, we implement various explicit and
implicit memory methods and conduct comprehensive experiments. We evaluate
their performance on this task from multiple perspectives and analyze their
strengths and weaknesses. Besides, we explore hybrid approaches that combine
both paradigms and propose the HybridMem method to address their limitations.
We demonstrate the effectiveness of our proposed model through extensive
experiments. To benefit the research community, we release this project at
https://github.com/nuster1128/MPR.

### 13. An LLM Agent-Based Complex Semantic Table Annotation Approach

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Yilin Geng, Shujing Wang, Chuan Wang, Keqing He, Yanfei Lv, Ying Wang, Zaiwen Feng, Xiaoying Bai
- **URL**: <http://arxiv.org/abs/2508.12868v1>
- **Submitted**: 2025-08-18 12:09:20
- **Topic Keywords**: rag
- **Reason**: The paper proposes an LLM-based agent approach for Semantic Table Annotation, which is a specific problem in Natural Language Processing. While it's related to information retrieval, the focus is on table annotation rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest for you. The paper's relevance is somewhat limited due to its narrow scope.

#### Abstract
> The Semantic Table Annotation (STA) task, which includes Column Type
Annotation (CTA) and Cell Entity Annotation (CEA), maps table contents to
ontology entities and plays important roles in various semantic applications.
However, complex tables often pose challenges such as semantic loss of column
names or cell values, strict ontological hierarchy requirements, homonyms,
spelling errors, and abbreviations, which hinder annotation accuracy. To
address these issues, this paper proposes an LLM-based agent approach for CTA
and CEA. We design and implement five external tools with tailored prompts
based on the ReAct framework, enabling the STA agent to dynamically select
suitable annotation strategies depending on table characteristics. Experiments
are conducted on the Tough Tables and BiodivTab datasets from the SemTab
challenge, which contain the aforementioned challenges. Our method outperforms
existing approaches across various metrics. Furthermore, by leveraging
Levenshtein distance to reduce redundant annotations, we achieve a 70%
reduction in time costs and a 60% reduction in LLM token usage, providing an
efficient and cost-effective solution for STA.

### 14. E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Ronghao Lin, Shuai Shen, Weipeng Hu, Qiaolin He, Aolin Xiong, Li Huang, Haifeng Hu, Yap-peng Tan
- **URL**: <http://arxiv.org/abs/2508.12854v1>
- **Submitted**: 2025-08-18 11:47:02
- **Comment**: Accepted at ACM MM 2025 Grand Challenge
- **Topic Keywords**: retrieval
- **Reason**: The paper focuses on multimodal empathetic response generation, which is not directly related to information retrieval or search technologies. While it uses large language models, the primary goal is not query understanding, ranking models, or user behavior modeling, but rather generating empathetic responses. The paper's relevance to the user's interests is limited, but it does touch on some NLP-related topics.

#### Abstract
> Multimodal Empathetic Response Generation (MERG) is crucial for building
emotionally intelligent human-computer interactions. Although large language
models (LLMs) have improved text-based ERG, challenges remain in handling
multimodal emotional content and maintaining identity consistency. Thus, we
propose E3RG, an Explicit Emotion-driven Empathetic Response Generation System
based on multimodal LLMs which decomposes MERG task into three parts:
multimodal empathy understanding, empathy memory retrieval, and multimodal
response generation. By integrating advanced expressive speech and video
generative models, E3RG delivers natural, emotionally rich, and
identity-consistent responses without extra training. Experiments validate the
superiority of our system on both zero-shot and few-shot settings, securing
Top-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.
Our code is available at https://github.com/RH-Lin/E3RG.

### 15. DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Weize Liu, Yongchi Zhao, Yijia Luo, Mingyu Xu, Jiaheng Liu, Yanan Li, Xiguo Hu, Yuchi Xu, Wenbo Su, Bo Zheng
- **URL**: <http://arxiv.org/abs/2508.12726v1>
- **Submitted**: 2025-08-18 08:49:29
- **Topic Keywords**: rag
- **Reason**: The paper focuses on designing datasets for large language models, which is related to information retrieval and search technologies. However, the primary focus is on natural language processing and data synthesis, which is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large language models (LLMs) have achieved remarkable success in many natural
language tasks but still struggle with complex, multi-step reasoning,
particularly across diverse disciplines. Existing reasoning datasets often
either lack disciplinary breadth or the structural depth necessary to elicit
robust reasoning behaviors. We propose DESIGNER: a DESIGN-logic-guidEd
Reasoning data synthesis pipeline that leverages naturally available, extensive
raw documents (book corpus and web corpus) to generate multidisciplinary
challenging questions. A core innovation of our approach is the introduction of
a Design Logic concept, which mimics the question-creation process of human
educators. We use LLMs to reverse-engineer and abstract over 120,000 design
logics from existing questions across various disciplines. By matching these
design logics with disciplinary source materials, we are able to create
reasoning questions that far surpass the difficulty and diversity of existing
datasets. Based on this pipeline, we synthesized two large-scale reasoning
datasets that span 75 disciplines: Design-Logic-Reasoning-Book (DLR-Book),
containing 3.04 million challenging questions synthesized from the book corpus,
and Design-Logic-Reasoning-Web (DLR-Web), with 1.66 million challenging
questions from the web corpus. Our data analysis demonstrates that the
questions synthesized by our method exhibit substantially greater difficulty
and diversity than those in the baseline datasets. We validate the
effectiveness of these datasets by conducting SFT experiments on the
Qwen3-8B-Base and Qwen3-4B-Base models. The results show that our dataset
significantly outperforms existing multidisciplinary datasets of the same
volume. Training with the full datasets further enables the models to surpass
the multidisciplinary reasoning performance of the official Qwen3-8B and
Qwen3-4B models.

### 16. Prompt-Induced Linguistic Fingerprints for LLM-Generated Fake News Detection

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Chi Wang, Min Gao, Zongwei Wang, Junwei Yin, Kai Shu, Chenghua Lin
- **URL**: <http://arxiv.org/abs/2508.12632v1>
- **Submitted**: 2025-08-18 05:24:54
- **Topic Keywords**: rag
- **Reason**: The paper is somewhat related to information retrieval, as it deals with detecting fake news generated by large language models. However, the focus is more on natural language processing and machine learning techniques, rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest in information retrieval.

#### Abstract
> With the rapid development of large language models, the generation of fake
news has become increasingly effortless, posing a growing societal threat and
underscoring the urgent need for reliable detection methods. Early efforts to
identify LLM-generated fake news have predominantly focused on the textual
content itself; however, because much of that content may appear coherent and
factually consistent, the subtle traces of falsification are often difficult to
uncover. Through distributional divergence analysis, we uncover prompt-induced
linguistic fingerprints: statistically distinct probability shifts between
LLM-generated real and fake news when maliciously prompted. Based on this
insight, we propose a novel method named Linguistic Fingerprints Extraction
(LIFE). By reconstructing word-level probability distributions, LIFE can find
discriminative patterns that facilitate the detection of LLM-generated fake
news. To further amplify these fingerprint patterns, we also leverage
key-fragment techniques that accentuate subtle linguistic differences, thereby
improving detection reliability. Our experiments show that LIFE achieves
state-of-the-art performance in LLM-generated fake news and maintains high
performance in human-written fake news. The code and data are available at
https://anonymous.4open.science/r/LIFE-E86A.

### 17. Diagnostic-Guided Dynamic Profile Optimization for LLM-based User Simulators in Sequential Recommendation

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Hongyang Liu, Zhu Sun, Tianjun Wei, Yan Wang, Jiajie Zhu, Xinghua Qu
- **URL**: <http://arxiv.org/abs/2508.12645v2>
- **Submitted**: 2025-08-18 06:17:59
- **Topic Keywords**: recommend
- **Reason**: The paper proposes a novel framework for constructing user profiles in recommender systems, using large language models. While it's related to search technologies and user behavior modeling, it's not directly focused on query understanding, ranking models, or click models, which are core areas of interest. The paper's focus on recommender systems and sequential interactions is somewhat relevant, but not a central match with the user's research themes.

#### Abstract
> Recent advances in large language models (LLMs) have enabled realistic user
simulators for developing and evaluating recommender systems (RSs). However,
existing LLM-based simulators for RSs face two major limitations: (1) static
and single-step prompt-based inference that leads to inaccurate and incomplete
user profile construction; (2) unrealistic and single-round
recommendation-feedback interaction pattern that fails to capture real-world
scenarios. To address these limitations, we propose DGDPO (Diagnostic-Guided
Dynamic Profile Optimization), a novel framework that constructs user profile
through a dynamic and iterative optimization process to enhance the simulation
fidelity. Specifically, DGDPO incorporates two core modules within each
optimization loop: firstly, a specialized LLM-based diagnostic module,
calibrated through our novel training strategy, accurately identifies specific
defects in the user profile. Subsequently, a generalized LLM-based treatment
module analyzes the diagnosed defect and generates targeted suggestions to
refine the profile. Furthermore, unlike existing LLM-based user simulators that
are limited to single-round interactions, we are the first to integrate DGDPO
with sequential recommenders, enabling a bidirectional evolution where user
profiles and recommendation strategies adapt to each other over multi-round
interactions. Extensive experiments conducted on three real-world datasets
demonstrate the effectiveness of our proposed framework.

### 18. HeteroRAG: A Heterogeneous Retrieval-Augmented Generation Framework for Medical Vision Language Tasks

- **LLM Score**: 2
- **Keyword Score**: 13
- **Authors**: Zhe Chen, Yusheng Liao, Shuyang Jiang, Zhiyuan Zhu, Haolin Li, Yanfeng Wang, Yu Wang
- **URL**: <http://arxiv.org/abs/2508.12778v1>
- **Submitted**: 2025-08-18 09:54:10
- **Topic Keywords**: query, queries, relevance, rag, retrieval
- **Reason**: The paper focuses on medical vision-language tasks, retrieval-augmented generation, and multimodal report repositories, which are not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on medical applications and clinical decision-making also falls outside the user's e-commerce domain experience.

#### Abstract
> Medical large vision-language Models (Med-LVLMs) have shown promise in
clinical applications but suffer from factual inaccuracies and unreliable
outputs, posing risks in real-world diagnostics. While retrieval-augmented
generation has emerged as a potential solution, current medical multimodal RAG
systems are unable to perform effective retrieval across heterogeneous sources.
The irrelevance of retrieved reports affects the factuality of analysis, while
insufficient knowledge affects the credibility of clinical decision-making. To
bridge the gap, we construct MedAtlas, which includes extensive multimodal
report repositories and diverse text corpora. Based on it, we present
HeteroRAG, a novel framework that enhances Med-LVLMs through heterogeneous
knowledge sources. The framework introduces Modality-specific CLIPs for
effective report retrieval and a Multi-corpora Query Generator for dynamically
constructing queries for diverse corpora. Incorporating knowledge from such
multifaceted sources, Med-LVLM is then trained with Heterogeneous Knowledge
Preference Tuning to achieve cross-modality and multi-source knowledge
alignment. Extensive experiments across 12 datasets and 3 modalities
demonstrate that the proposed HeteroRAG achieves state-of-the-art performance
in most medical vision language benchmarks, significantly improving factual
accuracy and reliability of Med-LVLMs.

### 19. OptimalThinkingBench: Evaluating Over and Underthinking in LLMs

- **LLM Score**: 2
- **Keyword Score**: 8
- **Authors**: Pranjal Aggarwal, Seungone Kim, Jack Lanchantin, Sean Welleck, Jason Weston, Ilia Kulikov, Swarnadeep Saha
- **URL**: <http://arxiv.org/abs/2508.13141v1>
- **Submitted**: 2025-08-18 17:53:10
- **Comment**: 26 pages, 6 tables, 10 figures
- **Topic Keywords**: query, queries, rag
- **Reason**: The paper focuses on Large Language Models (LLMs) and their thinking/overthinking behavior, which is not directly related to Information Retrieval, Search technologies, or query understanding. The concepts and techniques discussed in the paper are not relevant to my research interests.

#### Abstract
> Thinking LLMs solve complex tasks at the expense of increased compute and
overthinking on simpler problems, while non-thinking LLMs are faster and
cheaper but underthink on harder reasoning problems. This has led to the
development of separate thinking and non-thinking LLM variants, leaving the
onus of selecting the optimal model for each query on the end user. In this
work, we introduce OptimalThinkingBench, a unified benchmark that jointly
evaluates overthinking and underthinking in LLMs and also encourages the
development of optimally-thinking models that balance performance and
efficiency. Our benchmark comprises two sub-benchmarks: OverthinkingBench,
featuring simple queries in 72 domains, and UnderthinkingBench, containing 11
challenging reasoning tasks. Using novel thinking-adjusted accuracy metrics, we
perform extensive evaluation of 33 different thinking and non-thinking models
and show that no model is able to optimally think on our benchmark. Thinking
models often overthink for hundreds of tokens on the simplest user queries
without improving performance. In contrast, large non-thinking models
underthink, often falling short of much smaller thinking models. We further
explore several methods to encourage optimal thinking, but find that these
approaches often improve on one sub-benchmark at the expense of the other,
highlighting the need for better unified and optimal models in the future.

### 20. CRED-SQL: Enhancing Real-world Large Scale Database Text-to-SQL Parsing through Cluster Retrieval and Execution Description

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Shaoming Duan, Zirui Wang, Chuanyi Liu, Zhibin Zhu, Yuhao Zhang, Peiyi Han, Liang Yan, Zewu Penge
- **URL**: <http://arxiv.org/abs/2508.12769v2>
- **Submitted**: 2025-08-18 09:43:07
- **Topic Keywords**: queries, rag, retrieval
- **Reason**: The paper focuses on Text-to-SQL parsing, which is not directly related to Information Retrieval (IR) or Search technologies. Although it mentions large language models, the primary goal is to improve SQL generation, which is outside the scope of the user's research interests.

#### Abstract
> Recent advances in large language models (LLMs) have significantly improved
the accuracy of Text-to-SQL systems. However, a critical challenge remains: the
semantic mismatch between natural language questions (NLQs) and their
corresponding SQL queries. This issue is exacerbated in large-scale databases,
where semantically similar attributes hinder schema linking and semantic drift
during SQL generation, ultimately reducing model accuracy. To address these
challenges, we introduce CRED-SQL, a framework designed for large-scale
databases that integrates Cluster Retrieval and Execution Description. CRED-SQL
first performs cluster-based large-scale schema retrieval to pinpoint the
tables and columns most relevant to a given NLQ, alleviating schema mismatch.
It then introduces an intermediate natural language representation-Execution
Description Language (EDL)-to bridge the gap between NLQs and SQL. This
reformulation decomposes the task into two stages: Text-to-EDL and EDL-to-SQL,
leveraging LLMs' strong general reasoning capabilities while reducing semantic
deviation. Extensive experiments on two large-scale, cross-domain
benchmarks-SpiderUnion and BirdUnion-demonstrate that CRED-SQL achieves new
state-of-the-art (SOTA) performance, validating its effectiveness and
scalability. Our code is available at https://github.com/smduan/CRED-SQL.git

### 21. Beyond GPT-5: Making LLMs Cheaper and Better via Performance-Efficiency Optimized Routing

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Yiqun Zhang, Hao Li, Jianhao Chen, Hangfan Zhang, Peng Ye, Lei Bai, Shuyue Hu
- **URL**: <http://arxiv.org/abs/2508.12631v1>
- **Submitted**: 2025-08-18 05:23:31
- **Comment**: Ongoing work
- **Topic Keywords**: queries, rag
- **Reason**: The paper focuses on large language models and test-time routing, which is not directly related to information retrieval, query understanding, ranking models, or user behavior modeling. While it mentions performance-efficiency trade-offs, the context is different from the user's interests in IR and NLP.

#### Abstract
> Balancing performance and efficiency is a central challenge in large language
model (LLM) advancement. GPT-5 addresses this with test-time routing,
dynamically assigning queries to either an efficient or a high-capacity model
during inference. In this work, we present Avengers-Pro, a test-time routing
framework that ensembles LLMs of varying capacities and efficiencies, providing
a unified solution for all performance-efficiency tradeoffs. The Avengers-Pro
embeds and clusters incoming queries, then routes each to the most suitable
model based on a performance-efficiency score. Across 6 challenging benchmarks
and 8 leading models -- including GPT-5-medium, Gemini-2.5-pro, and
Claude-opus-4.1 -- Avengers-Pro achieves state-of-the-art results: by varying a
performance-efficiency trade-off parameter, it can surpass the strongest single
model (GPT-5-medium) by +7% in average accuracy. Moreover, it can match the
average accuracy of the strongest single model at 27% lower cost, and reach
~90% of that performance at 63% lower cost. Last but not least, it achieves a
Pareto frontier, consistently yielding the highest accuracy for any given cost,
and the lowest cost for any given accuracy, among all single models. Code is
available at https://github.com/ZhangYiqun018/AvengersPro.

### 22. From SALAMANDRA to SALAMANDRATA: BSC Submission for WMT25 General Machine Translation Shared Task

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Javier Garcia Gilabert, Xixian Liao, Severino Da Dalt, Ella Bohman, Audrey Mash, Francesca De Luca Fornaciari, Irene Baucells, Joan Llop, Miguel Claramunt Argote, Carlos Escolano, Maite Melero
- **URL**: <http://arxiv.org/abs/2508.12774v1>
- **Submitted**: 2025-08-18 09:48:35
- **Topic Keywords**: ranking, rank
- **Reason**: The paper focuses on machine translation, a topic outside the user's primary research interests in Information Retrieval and Search technologies. Although it mentions some related concepts like fine-tuning and re-ranking, the context is not relevant to the user's areas of expertise.

#### Abstract
> In this paper, we present the SALAMANDRATA family of models, an improved
iteration of SALAMANDRA LLMs (Gonzalez-Agirre et al., 2025) specifically
trained to achieve strong performance in translation-related tasks for 38
European languages. SALAMANDRATA comes in two scales: 2B and 7B parameters. For
both versions, we applied the same training recipe with a first step of
continual pre-training on parallel data, and a second step of supervised
fine-tuning on high-quality instructions. The BSC submission to the WMT25
General Machine Translation shared task is based on the 7B variant of
SALAMANDRATA. We first adapted the model vocabulary to support the additional
non-European languages included in the task. This was followed by a second
phase of continual pre-training and supervised fine-tuning, carefully designed
to optimize performance across all translation directions for this year's
shared task. For decoding, we employed two quality-aware strategies: Minimum
Bayes Risk Decoding and Tuned Re-ranking using COMET and COMET-KIWI
respectively. We publicly release both the 2B and 7B versions of SALAMANDRATA,
along with the newer SALAMANDRATA-V2 model, on Hugging Face1

### 23. Leveraging Large Language Models for Predictive Analysis of Human Misery

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Bishanka Seal, Rahul Seetharaman, Aman Bansal, Abhilash Nandy
- **URL**: <http://arxiv.org/abs/2508.12669v1>
- **Submitted**: 2025-08-18 07:02:59
- **Comment**: 14 pages, 4 tables
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on using Large Language Models for predicting human-perceived misery scores, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves natural language processing, the application is in a different domain and does not align with the user's primary research interests.

#### Abstract
> This study investigates the use of Large Language Models (LLMs) for
predicting human-perceived misery scores from natural language descriptions of
real-world scenarios. The task is framed as a regression problem, where the
model assigns a scalar value from 0 to 100 to each input statement. We evaluate
multiple prompting strategies, including zero-shot, fixed-context few-shot, and
retrieval-based prompting using BERT sentence embeddings. Few-shot approaches
consistently outperform zero-shot baselines, underscoring the value of
contextual examples in affective prediction. To move beyond static evaluation,
we introduce the "Misery Game Show", a novel gamified framework inspired by a
television format. It tests LLMs through structured rounds involving ordinal
comparison, binary classification, scalar estimation, and feedback-driven
reasoning. This setup enables us to assess not only predictive accuracy but
also the model's ability to adapt based on corrective feedback. The gamified
evaluation highlights the broader potential of LLMs in dynamic emotional
reasoning tasks beyond standard regression. Code and data link:
https://github.com/abhi1nandy2/Misery_Data_Exps_GitHub

### 24. Semantic Anchoring in Agentic Memory: Leveraging Linguistic Structures for Persistent Conversational Context

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Maitreyi Chatterjee, Devansh Agarwal
- **URL**: <http://arxiv.org/abs/2508.12630v1>
- **Submitted**: 2025-08-18 05:14:48
- **Comment**: Paper is currently in peer review
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on conversational AI and memory persistence, using techniques like dependency parsing, discourse relation tagging, and coreference resolution. While it's related to NLP, it doesn't directly address query understanding, ranking models, or user behavior modeling in the context of information retrieval, which are the user's primary research interests.

#### Abstract
> Large Language Models (LLMs) have demonstrated impressive fluency and task
competence in conversational settings. However, their effectiveness in
multi-session and long-term interactions is hindered by limited memory
persistence. Typical retrieval-augmented generation (RAG) systems store
dialogue history as dense vectors, which capture semantic similarity but
neglect finer linguistic structures such as syntactic dependencies, discourse
relations, and coreference links. We propose Semantic Anchoring, a hybrid
agentic memory architecture that enriches vector-based storage with explicit
linguistic cues to improve recall of nuanced, context-rich exchanges. Our
approach combines dependency parsing, discourse relation tagging, and
coreference resolution to create structured memory entries. Experiments on
adapted long-term dialogue datasets show that semantic anchoring improves
factual recall and discourse coherence by up to 18% over strong RAG baselines.
We further conduct ablation studies, human evaluations, and error analysis to
assess robustness and interpretability.

### 25. Context Matters: Incorporating Target Awareness in Conversational Abusive Language Detection

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Raneem Alharthi, Rajwa Alharthi, Aiqi Jiang, Arkaitz Zubiaga
- **URL**: <http://arxiv.org/abs/2508.12828v1>
- **Submitted**: 2025-08-18 11:12:21
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on abusive language detection in conversational exchanges, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's context-aware approach is not applicable to the user's areas of interest, such as query understanding, ranking models, and user behavior modeling.

#### Abstract
> Abusive language detection has become an increasingly important task as a
means to tackle this type of harmful content in social media. There has been a
substantial body of research developing models for determining if a social
media post is abusive or not; however, this research has primarily focused on
exploiting social media posts individually, overlooking additional context that
can be derived from surrounding posts. In this study, we look at conversational
exchanges, where a user replies to an earlier post by another user (the parent
tweet). We ask: does leveraging context from the parent tweet help determine if
a reply post is abusive or not, and what are the features that contribute the
most? We study a range of content-based and account-based features derived from
the context, and compare this to the more widely studied approach of only
looking at the features from the reply tweet. For a more generalizable study,
we test four different classification models on a dataset made of
conversational exchanges (parent-reply tweet pairs) with replies labeled as
abusive or not. Our experiments show that incorporating contextual features
leads to substantial improvements compared to the use of features derived from
the reply tweet only, confirming the importance of leveraging context. We
observe that, among the features under study, it is especially the
content-based features (what is being posted) that contribute to the
classification performance rather than account-based features (who is posting
it). While using content-based features, it is best to combine a range of
different features to ensure improved performance over being more selective and
using fewer features. Our study provides insights into the development of
contextualized abusive language detection models in realistic settings
involving conversations.

### 26. Deep Research: A Survey of Autonomous Research Agents

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Wenlin Zhang, Xiaopeng Li, Yingyi Zhang, Pengyue Jia, Yichao Wang, Huifeng Guo, Yong Liu, Xiangyu Zhao
- **URL**: <http://arxiv.org/abs/2508.12752v1>
- **Submitted**: 2025-08-18 09:26:14
- **Topic Keywords**: retrieval, search
- **Reason**: The paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it touches on topics like web-based evidence and report generation, the focus is on autonomous research agents and large language models, which is outside the user's primary research interests.

#### Abstract
> The rapid advancement of large language models (LLMs) has driven the
development of agentic systems capable of autonomously performing complex
tasks. Despite their impressive capabilities, LLMs remain constrained by their
internal knowledge boundaries. To overcome these limitations, the paradigm of
deep research has been proposed, wherein agents actively engage in planning,
retrieval, and synthesis to generate comprehensive and faithful analytical
reports grounded in web-based evidence. In this survey, we provide a systematic
overview of the deep research pipeline, which comprises four core stages:
planning, question developing, web exploration, and report generation. For each
stage, we analyze the key technical challenges and categorize representative
methods developed to address them. Furthermore, we summarize recent advances in
optimization techniques and benchmarks tailored for deep research. Finally, we
discuss open challenges and promising research directions, aiming to chart a
roadmap toward building more capable and trustworthy deep research agents.

### 27. RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xin Chen, Junchao Wu, Shu Yang, Runzhe Zhan, Zeyu Wu, Ziyang Luo, Di Wang, Min Yang, Lidia S. Chao, Derek F. Wong
- **URL**: <http://arxiv.org/abs/2508.13152v1>
- **Submitted**: 2025-08-18 17:59:15
- **Comment**: Accepted to TACL 2025. This version is a pre-MIT Press publication
  version
- **Topic Keywords**: rag
- **Reason**: The paper focuses on detecting LLM-generated text, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on neural activation patterns, it does not address ranking models, user behavior modeling, or deep semantic understanding, making it only loosely relevant to your research interests.

#### Abstract
> Detecting content generated by large language models (LLMs) is crucial for
preventing misuse and building trustworthy AI systems. Although existing
detection methods perform well, their robustness in out-of-distribution (OOD)
scenarios is still lacking. In this paper, we hypothesize that, compared to
features used by existing detection methods, the internal representations of
LLMs contain more comprehensive and raw features that can more effectively
capture and distinguish the statistical pattern differences between
LLM-generated texts (LGT) and human-written texts (HWT). We validated this
hypothesis across different LLMs and observed significant differences in neural
activation patterns when processing these two types of texts. Based on this, we
propose RepreGuard, an efficient statistics-based detection method.
Specifically, we first employ a surrogate model to collect representation of
LGT and HWT, and extract the distinct activation feature that can better
identify LGT. We can classify the text by calculating the projection score of
the text representations along this feature direction and comparing with a
precomputed threshold. Experimental results show that RepreGuard outperforms
all baselines with average 94.92% AUROC on both in-distribution (ID) and OOD
scenarios, while also demonstrating robust resilience to various text sizes and
mainstream attacks. Data and code are publicly available at:
https://github.com/NLP2CT/RepreGuard

### 28. Has GPT-5 Achieved Spatial Intelligence? An Empirical Study

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zhongang Cai, Yubo Wang, Qingping Sun, Ruisi Wang, Chenyang Gu, Wanqi Yin, Zhiqian Lin, Zhitao Yang, Chen Wei, Xuanke Shi, Kewang Deng, Xiaoyang Han, Zukai Chen, Jiaqi Li, Xiangyu Fan, Hanming Deng, Lewei Lu, Bo Li, Ziwei Liu, Quan Wang, Dahua Lin, Lei Yang
- **URL**: <http://arxiv.org/abs/2508.13142v1>
- **Submitted**: 2025-08-18 17:55:17
- **Topic Keywords**: ctr
- **Reason**: The paper focuses on the spatial intelligence of GPT-5, a language model, and evaluates its performance on various benchmarks. While it's an interesting study, it doesn't relate to information retrieval, search technologies, or query understanding, which are the user's primary research interests. The paper's topics, such as multi-modal models and spatial understanding, are not directly relevant to the user's areas of focus.

#### Abstract
> Multi-modal models have achieved remarkable progress in recent years.
Nevertheless, they continue to exhibit notable limitations in spatial
understanding and reasoning, which are fundamental capabilities to achieving
artificial general intelligence. With the recent release of GPT-5, allegedly
the most powerful AI model to date, it is timely to examine where the leading
models stand on the path toward spatial intelligence. First, we propose a
comprehensive taxonomy of spatial tasks that unifies existing benchmarks and
discuss the challenges in ensuring fair evaluation. We then evaluate
state-of-the-art proprietary and open-source models on eight key benchmarks, at
a cost exceeding one billion total tokens. Our empirical study reveals that (1)
GPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2)
still falls short of human performance across a broad spectrum of tasks.
Moreover, we (3) identify the more challenging spatial intelligence problems
for multi-modal models, and (4) proprietary models do not exhibit a decisive
advantage when facing the most difficult problems. In addition, we conduct a
qualitative evaluation across a diverse set of scenarios that are intuitive for
humans yet fail even the most advanced multi-modal models.

### 29. Reinforced Context Order Recovery for Adaptive Reasoning and Planning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Long Ma, Fangwei Zhong, Yizhou Wang
- **URL**: <http://arxiv.org/abs/2508.13070v1>
- **Submitted**: 2025-08-18 16:42:55
- **Topic Keywords**: acl
- **Reason**: The paper focuses on developing a framework for adaptive token generation orders in language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on topics like token prediction and reinforcement learning, the primary focus is on language modeling and planning, which is not a central match for your research interests.

#### Abstract
> Modern causal language models, followed by rapid developments in discrete
diffusion models, can now produce a wide variety of interesting and useful
content. However, these families of models are predominantly trained to output
tokens with a fixed (left-to-right) or random order, which may deviate from the
logical order in which tokens are generated originally. In this paper, we
observe that current causal and diffusion models encounter difficulties in
problems that require adaptive token generation orders to solve tractably,
which we characterize with the $\mathcal{V}$-information framework. Motivated
by this, we propose Reinforced Context Order Recovery (ReCOR), a
reinforcement-learning-based framework to extract adaptive, data-dependent
token generation orders from text data without annotations. Self-supervised by
token prediction statistics, ReCOR estimates the hardness of predicting every
unfilled token and adaptively selects the next token during both training and
inference. Experiments on challenging reasoning and planning datasets
demonstrate the superior performance of ReCOR compared with baselines,
sometimes outperforming oracle models supervised with the ground-truth order.

### 30. Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Xinhe Li, Jiajun Liu, Peng Wang
- **URL**: <http://arxiv.org/abs/2508.13037v1>
- **Submitted**: 2025-08-18 15:56:10
- **Comment**: Accepted by IJCAI2025
- **Topic Keywords**: rag
- **Reason**: The paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on Large Language Models and mathematical reasoning, which is outside the user's primary research focus.

#### Abstract
> Recent studies have demonstrated that Large Language Models (LLMs) have
strong mathematical reasoning abilities but rely on hundreds of billions of
parameters. To tackle the challenge of poor reasoning in Small Language Models
(SLMs), existing methods typically leverage LLMs to generate massive amounts of
data for cramming training. In psychology, they are akin to System 1 thinking,
which resolves reasoning problems rapidly based on experience and intuition.
However, human learning also requires System 2 thinking, where knowledge is
first acquired and then reinforced through practice. Inspired by such two
distinct modes of thinking, we propose a novel method based on the multi-LoRA
Interaction for mathematical reasoning Distillation (LoRID). First, we input
the question and reasoning of each sample into an LLM to create
knowledge-enhanced datasets. Subsequently, we train a LoRA block on the student
model as an Intuitive Reasoner (IR), which directly generates Chain-of-Thoughts
for problem-solving. Then, to imitate System 2 thinking, we train the Knowledge
Generator (KG) and Deep Reasoner (DR), respectively. The former outputs only
knowledge after receiving problems, while the latter uses that knowledge to
perform reasoning. Finally, to address the randomness in the generation of IR
and DR, we evaluate whether their outputs are consistent, and the inference
process needs to be iterated if not. This step can enhance the mathematical
reasoning ability of SLMs through mutual feedback. Experimental results show
that LoRID achieves state-of-the-art performance, especially on the GSM8K
dataset, where it outperforms the second-best method by 2.3%, 16.1%, 2.4%,
12.3%, and 1.8% accuracy across the five base models, respectively.

### 31. Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zhu Li, Yuqing Zhang, Xiyuan Gao, Devraj Raghuvanshi, Nagendra Kumar, Shekhar Nayak, Matt Coler
- **URL**: <http://arxiv.org/abs/2508.13028v1>
- **Submitted**: 2025-08-18 15:44:54
- **Comment**: Speech Synthesis Workshop 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on speech synthesis and sarcasm detection, which is not directly related to information retrieval, search technologies, or query understanding. While it involves some NLP techniques, the primary focus is on speech synthesis and not on deep semantic understanding or real-time relevance optimization.

#### Abstract
> Sarcastic speech synthesis, which involves generating speech that effectively
conveys sarcasm, is essential for enhancing natural interactions in
applications such as entertainment and human-computer interaction. However,
synthesizing sarcastic speech remains a challenge due to the nuanced prosody
that characterizes sarcasm, as well as the limited availability of annotated
sarcastic speech data. To address these challenges, this study introduces a
novel approach that integrates feedback loss from a bi-modal sarcasm detection
model into the TTS training process, enhancing the model's ability to capture
and convey sarcasm. In addition, by leveraging transfer learning, a speech
synthesis model pre-trained on read speech undergoes a two-stage fine-tuning
process. First, it is fine-tuned on a diverse dataset encompassing various
speech styles, including sarcastic speech. In the second stage, the model is
further refined using a dataset focused specifically on sarcastic speech,
enhancing its ability to generate sarcasm-aware speech. Objective and
subjective evaluations demonstrate that our proposed methods improve the
quality, naturalness, and sarcasm-awareness of synthesized speech.

### 32. PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Pengcheng Huang, Shuhao Liu, Zhenghao Liu, Yukun Yan, Shuo Wang, Zulong Chen, Tong Xiao
- **URL**: <http://arxiv.org/abs/2508.13021v2>
- **Submitted**: 2025-08-18 15:38:37
- **Comment**: 17 pages,13 figures
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests as it focuses on masked diffusion models and decoding strategies for sequence generation, which is outside the scope of Information Retrieval, Search technologies, and Natural Language Processing. The paper's abstract does not mention query understanding, ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest for you.

#### Abstract
> Recent advances in masked diffusion models (MDMs) have established them as
powerful non-autoregressive alternatives for sequence generation. Nevertheless,
our preliminary experiments reveal that the generation quality of MDMs is still
highly sensitive to the choice of decoding strategy. In particular, widely
adopted uncertainty-based samplers suffer from two key limitations: a lack of
global trajectory control and a pronounced bias toward trivial tokens in the
early stages of decoding. These shortcomings restrict the full potential of
MDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling
(PC-Sampler), a novel decoding strategy that unifies global trajectory planning
with content-aware informativeness maximization. PC-Sampler incorporates a
position-aware weighting mechanism to regulate the decoding path and a
calibrated confidence score to suppress the premature selection of trivial
tokens. Extensive experiments on three advanced MDMs across seven challenging
benchmarks-including logical reasoning and planning tasks-demonstrate that
PC-Sampler consistently outperforms existing MDM decoding strategies by more
than 10% on average, significantly narrowing the performance gap with
state-of-the-art autoregressive models. All codes are available at
https://github.com/NEUIR/PC-Sampler.

### 33. A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jinyi Han, Xinyi Wang, Haiquan Zhao, Tingyun li, Zishang Jiang, Sihang Jiang, Jiaqing Liang, Xin Lin, Weikang Zhou, Zeye Sun, Fei Yu, Yanghua Xiao
- **URL**: <http://arxiv.org/abs/2508.12903v1>
- **Submitted**: 2025-08-18 13:07:21
- **Topic Keywords**: rag
- **Reason**: The paper focuses on self-refinement for language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on the idea of refining outputs, the context is different from the user's interests in ranking models, user behavior modeling, and deep semantic understanding.

#### Abstract
> Recent advances in self-refinement have demonstrated significant potential
for improving the outputs of large language models (LLMs) through iterative
refinement. However, most existing self-refinement methods rely on a reactive
process with a fixed number of iterations, making it difficult to determine the
optimal timing and content of refinement based on the evolving generation
context. Inspired by the way humans dynamically refine their thoughts during
execution, we propose ProActive Self-Refinement (PASR), a novel method that
enables LLMs to refine their outputs during the generation process. Unlike
methods that regenerate entire responses, PASR proactively decides whether,
when, and how to refine based on the model's internal state and evolving
context. We conduct extensive experiments on a diverse set of 10 tasks to
evaluate the effectiveness of PASR. Experimental results show that PASR
significantly enhances problem-solving performance. In particular, on Qwen3-8B,
PASR reduces average token consumption by 41.6 percent compared to standard
generation, while also achieving an 8.2 percent improvement in accuracy. Our
code and all baselines used in the paper are available in the GitHub.

### 34. ding-01 :ARG0: An AMR Corpus for Spontaneous French Dialogue

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jeongwoo Kang, Maria Boritchev, Maximin Coavoux
- **URL**: <http://arxiv.org/abs/2508.12819v1>
- **Submitted**: 2025-08-18 10:57:44
- **Comment**: Accepted at IWCS 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on building a French semantic corpus using Abstract Meaning Representation (AMR) for spontaneous dialogue, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves Natural Language Processing, the scope is limited to French dialogue annotation and does not address ranking models, user behavior modeling, or real-time relevance optimization.

#### Abstract
> We present our work to build a French semantic corpus by annotating French
dialogue in Abstract Meaning Representation (AMR). Specifically, we annotate
the DinG corpus, consisting of transcripts of spontaneous French dialogues
recorded during the board game Catan. As AMR has insufficient coverage of the
dynamics of spontaneous speech, we extend the framework to better represent
spontaneous speech and sentence structures specific to French. Additionally, to
support consistent annotation, we provide an annotation guideline detailing
these extensions. We publish our corpus under a free license (CC-SA-BY). We
also train and evaluate an AMR parser on our data. This model can be used as an
assistance annotation tool to provide initial annotations that can be refined
by human annotators. Our work contributes to the development of semantic
resources for French dialogue.

### 35. When Alignment Hurts: Decoupling Representational Spaces in Multilingual Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ahmed Elshabrawy, Hour Kaing, Haiyue Song, Alham Fikri Aji, Hideki Tanaka, Masao Utiyama, Raj Dabre
- **URL**: <http://arxiv.org/abs/2508.12803v1>
- **Submitted**: 2025-08-18 10:34:08
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. The focus on multilingual models, generative modeling, and language families is outside your primary areas of interest.

#### Abstract
> Alignment with high-resource standard languages is often assumed to aid the
modeling of related low-resource varieties. We challenge this assumption by
demonstrating that excessive representational entanglement with a dominant
variety, such as Modern Standard Arabic (MSA) in relation to Arabic dialects,
can actively hinder generative modeling. We present the first comprehensive
causal study of this phenomenon by analyzing and directly intervening in the
internal representation geometry of large language models (LLMs). Our key
contribution is an online variational probing framework that continuously
estimates the subspace of the standard variety during fine-tuning, enabling
projection-based decoupling from this space. While our study uses Arabic as a
case due to its unusually rich parallel resources across 25 dialects, the
broader motivation is methodological: dialectal MT serves as a controlled proxy
for generative tasks where comparable multi-variety corpora are unavailable.
Across 25 dialects, our intervention improves generation quality by up to +4.9
chrF++ and +2.0 on average compared to standard fine-tuning, despite a measured
tradeoff in standard-language performance. These results provide causal
evidence that subspace dominance by high-resource varieties can restrict
generative capacity for related varieties. More generally, we unify geometric
and information-theoretic probing with subspace-level causal interventions,
offering practical tools for improving generative modeling in closely related
language families and, more broadly, for controlling representational
allocation in multilingual and multi-domain LLMs. Code will be released.

### 36. Beyond Modality Limitations: A Unified MLLM Approach to Automated Speaking Assessment with Effective Curriculum Learning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yu-Hsuan Fang, Tien-Hong Lo, Yao-Ting Sung, Berlin Chen
- **URL**: <http://arxiv.org/abs/2508.12591v1>
- **Submitted**: 2025-08-18 02:57:43
- **Comment**: Accepted at IEEE ASRU 2025
- **Topic Keywords**: rag
- **Reason**: This paper focuses on multimodal large language models for automated speaking assessment, which is not directly related to information retrieval, search technologies, or query understanding. While it involves language models, the context is specific to speech assessment and does not align with the user's primary research interests.

#### Abstract
> Traditional Automated Speaking Assessment (ASA) systems exhibit inherent
modality limitations: text-based approaches lack acoustic information while
audio-based methods miss semantic context. Multimodal Large Language Models
(MLLM) offer unprecedented opportunities for comprehensive ASA by
simultaneously processing audio and text within unified frameworks. This paper
presents a very first systematic study of MLLM for comprehensive ASA,
demonstrating the superior performance of MLLM across the aspects of content
and language use . However, assessment on the delivery aspect reveals unique
challenges, which is deemed to require specialized training strategies. We thus
propose Speech-First Multimodal Training (SFMT), leveraging a curriculum
learning principle to establish more robust modeling foundations of speech
before cross-modal synergetic fusion. A series of experiments on a benchmark
dataset show MLLM-based systems can elevate the holistic assessment performance
from a PCC value of 0.783 to 0.846. In particular, SFMT excels in the
evaluation of the delivery aspect, achieving an absolute accuracy improvement
of 4% over conventional training approaches, which also paves a new avenue for
ASA.

### 37. Insight Rumors: A Novel Textual Rumor Locating and Marking Model Leveraging Att_BiMamba2 Network

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Bin Ma, Yifei Zhang, Yongjin Xian, Qi Li, Linna Zhou, Gongxun Miao
- **URL**: <http://arxiv.org/abs/2508.12574v1>
- **Submitted**: 2025-08-18 02:20:57
- **Topic Keywords**: rag
- **Reason**: The paper focuses on rumor detection and location, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves text analysis and attention mechanisms, the context is specific to rumor detection and does not align with the user's core research themes.

#### Abstract
> With the development of social media networks, rumor detection models have
attracted more and more attention. Whereas, these models primarily focus on
classifying contexts as rumors or not, lacking the capability to locate and
mark specific rumor content. To address this limitation, this paper proposes a
novel rumor detection model named Insight Rumors to locate and mark rumor
content within textual data. Specifically, we propose the Bidirectional Mamba2
Network with Dot-Product Attention (Att_BiMamba2), a network that constructs a
bidirectional Mamba2 model and applies dot-product attention to weight and
combine the outputs from both directions, thereby enhancing the representation
of high-dimensional rumor features. Simultaneously, a Rumor Locating and
Marking module is designed to locate and mark rumors. The module constructs a
skip-connection network to project high-dimensional rumor features onto
low-dimensional label features. Moreover, Conditional Random Fields (CRF) is
employed to impose strong constraints on the output label features, ensuring
accurate rumor content location. Additionally, a labeled dataset for rumor
locating and marking is constructed, with the effectiveness of the proposed
model is evaluated through comprehensive experiments. Extensive experiments
indicate that the proposed scheme not only detects rumors accurately but also
locates and marks them in context precisely, outperforming state-of-the-art
schemes that can only discriminate rumors roughly.

### 38. CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Seonglae Cho, Zekun Wu, Adriano Koshiyama
- **URL**: <http://arxiv.org/abs/2508.12535v1>
- **Submitted**: 2025-08-18 00:01:42
- **Comment**: 42 pages, 9 tables
- **Topic Keywords**: rag
- **Reason**: The paper focuses on feature selection and steering in large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions language models, the context is different from the user's interests in IR and NLP.

#### Abstract
> Sparse Autoencoders (SAEs) can extract interpretable features from large
language models (LLMs) without supervision. However, their effectiveness in
downstream steering tasks is limited by the requirement for contrastive
datasets or large activation storage. To address these limitations, we propose
CorrSteer, which selects features by correlating sample correctness with SAE
activations from generated tokens at inference time. This approach uses only
inference-time activations to extract more relevant features, thereby avoiding
spurious correlations. It also obtains steering coefficients from average
activations, automating the entire pipeline. Our method shows improved task
performance on QA, bias mitigation, jailbreaking prevention, and reasoning
benchmarks on Gemma 2 2B and LLaMA 3.1 8B, notably achieving a +4.1%
improvement in MMLU performance and a +22.9% improvement in HarmBench with only
4000 samples. Selected features demonstrate semantically meaningful patterns
aligned with each task's requirements, revealing the underlying capabilities
that drive performance. Our work establishes correlationbased selection as an
effective and scalable approach for automated SAE steering across language
model applications.

### 39. M3PO: Multimodal-Model-Guided Preference Optimization for Visual Instruction Following

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ruirui Gao, Emily Johnson, Bowen Tan, Yanfei Qian
- **URL**: <http://arxiv.org/abs/2508.12458v1>
- **Submitted**: 2025-08-17 18:07:55
- **Topic Keywords**: rag
- **Reason**: The paper focuses on multimodal instruction following and fine-tuning of large vision-language models, which is not directly related to information retrieval, search technologies, or query understanding. While it involves optimization techniques, the context is different from the user's primary research interests.

#### Abstract
> Large Vision-Language Models (LVLMs) hold immense potential for complex
multimodal instruction following, yet their development is often hindered by
the high cost and inconsistency of human annotation required for effective
fine-tuning and preference alignment. Traditional supervised fine-tuning (SFT)
and existing preference optimization methods like RLHF and DPO frequently
struggle to efficiently leverage the model's own generation space to identify
highly informative "hard negative" samples. To address these challenges, we
propose Multimodal-Model-Guided Preference Optimization (M3PO), a novel and
data-efficient method designed to enhance LVLMs' capabilities in visual
instruction following. M3PO intelligently selects the most "learning-valuable"
preference sample pairs from a diverse pool of LVLM-generated candidates. This
selection is driven by a sophisticated mechanism that integrates two crucial
signals: a Multimodal Alignment Score (MAS) to assess external quality and the
model's Self-Consistency / Confidence (log-probability) to gauge internal
belief. These are combined into a novel M3P-Score, which specifically
identifies preferred responses and challenging dispreferred responses that the
model might confidently generate despite being incorrect. These high-quality
preference pairs are then used for efficient Direct Preference Optimization
(DPO) fine-tuning on base LVLMs like LLaVA-1.5 (7B/13B) using LoRA. Our
extensive experiments demonstrate that M3PO consistently outperforms strong
baselines, including SFT, simulated RLHF, vanilla DPO, and RM-DPO, across a
comprehensive suite of multimodal instruction following benchmarks (MME-Bench,
POPE, IFT, Human Pref. Score).

### 40. Evaluating ASR robustness to spontaneous speech errors: A study of WhisperX using a Speech Error Database

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: John Alderete, Macarious Kin Fung Hui, Aanchan Mohan
- **URL**: <http://arxiv.org/abs/2508.13060v1>
- **Submitted**: 2025-08-18 16:30:33
- **Comment**: 5 pages, 6 figures, 1 table, Interspeech 2025 (Rotterdam)
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on speech recognition and error analysis is outside your primary areas of interest.

#### Abstract
> The Simon Fraser University Speech Error Database (SFUSED) is a public data
collection developed for linguistic and psycholinguistic research. Here we
demonstrate how its design and annotations can be used to test and evaluate
speech recognition models. The database comprises systematically annotated
speech errors from spontaneous English speech, with each error tagged for
intended and actual error productions. The annotation schema incorporates
multiple classificatory dimensions that are of some value to model assessment,
including linguistic hierarchical level, contextual sensitivity, degraded
words, word corrections, and both word-level and syllable-level error
positioning. To assess the value of these classificatory variables, we
evaluated the transcription accuracy of WhisperX across 5,300 documented word
and phonological errors. This analysis demonstrates the atabase's effectiveness
as a diagnostic tool for ASR system performance.

### 41. B√ºy√ºk Dil Modelleri i√ßin TR-MMLU Benchmarkƒ±: Performans Deƒüerlendirmesi, Zorluklar ve ƒ∞yile≈ütirme Fƒ±rsatlarƒ±

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: M. Ali Bayram, Ali Arda Fincan, Ahmet Semih G√ºm√º≈ü, Banu Diri, Sava≈ü Yƒ±ldƒ±rƒ±m, √ñner Ayta≈ü
- **URL**: <http://arxiv.org/abs/2508.13044v1>
- **Submitted**: 2025-08-18 16:00:43
- **Comment**: 10 pages, in Turkish language, 5 figures. Presented at the 2025 33rd
  Signal Processing and Communications Applications Conference (SIU), 25--28
  June 2025, Sile, Istanbul, T\"urkiye
- **Topic Keywords**: search
- **Reason**: The paper focuses on Turkish language models and their evaluation, which is not directly related to my research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions NLP, the scope is limited to Turkish language models and education system, which does not align with my broader interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Language models have made significant advancements in understanding and
generating human language, achieving remarkable success in various
applications. However, evaluating these models remains a challenge,
particularly for resource-limited languages like Turkish. To address this
issue, we introduce the Turkish MMLU (TR-MMLU) benchmark, a comprehensive
evaluation framework designed to assess the linguistic and conceptual
capabilities of large language models (LLMs) in Turkish. TR-MMLU is based on a
meticulously curated dataset comprising 6,200 multiple-choice questions across
62 sections within the Turkish education system. This benchmark provides a
standard framework for Turkish NLP research, enabling detailed analyses of
LLMs' capabilities in processing Turkish text. In this study, we evaluated
state-of-the-art LLMs on TR-MMLU, highlighting areas for improvement in model
design. TR-MMLU sets a new standard for advancing Turkish NLP research and
inspiring future innovations.

### 42. Analyzing Information Sharing and Coordination in Multi-Agent Planning

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Tianyue Ou, Saujas Vaduguru, Daniel Fried
- **URL**: <http://arxiv.org/abs/2508.12981v1>
- **Submitted**: 2025-08-18 14:57:02
- **Topic Keywords**: search
- **Reason**: The paper focuses on multi-agent systems and planning, which is not directly related to information retrieval, search technologies, or natural language processing. While it mentions large language models, the context is different from query understanding, ranking models, or user behavior modeling.

#### Abstract
> Multi-agent systems (MASs) have pushed the boundaries of large language model
(LLM) agents in domains such as web research and software engineering. However,
long-horizon, multi-constraint planning tasks involve conditioning on detailed
information and satisfying complex interdependent constraints, which can pose a
challenge for these systems. In this study, we construct an LLM-based MAS for a
travel planning task which is representative of these challenges. We evaluate
the impact of a notebook to facilitate information sharing, and evaluate an
orchestrator agent to improve coordination in free form conversation between
agents. We find that the notebook reduces errors due to hallucinated details by
18%, while an orchestrator directs the MAS to focus on and further reduce
errors by up to 13.5% within focused sub-areas. Combining both mechanisms
achieves a 25% final pass rate on the TravelPlanner benchmark, a 17.5% absolute
improvement over the single-agent baseline's 7.5% pass rate. These results
highlight the potential of structured information sharing and reflective
orchestration as key components in MASs for long horizon planning with LLMs.

### 43. It takes a village to write a book: Mapping anonymous contributions in Stephen Langton's Quaestiones Theologiae

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jan Maliszewski
- **URL**: <http://arxiv.org/abs/2508.12830v1>
- **Submitted**: 2025-08-18 11:13:45
- **Topic Keywords**: search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. The topic is focused on stylometric techniques for authorship attribution and the study of medieval Latin corpora, which is outside your areas of interest.

#### Abstract
> While the indirect evidence suggests that already in the early scholastic
period the literary production based on records of oral teaching (so-called
reportationes) was not uncommon, there are very few sources commenting on the
practice. This paper details the design of a study applying stylometric
techniques of authorship attribution to a collection developed from
reportationes -- Stephen Langton's Quaestiones Theologiae -- aiming to uncover
layers of editorial work and thus validate some hypotheses regarding the
collection's formation. Following Camps, Cl\'erice, and Pinche (2021), I
discuss the implementation of an HTR pipeline and stylometric analysis based on
the most frequent words, POS tags, and pseudo-affixes. The proposed study will
offer two methodological gains relevant to computational research on the
scholastic tradition: it will directly compare performance on manually composed
and automatically extracted data, and it will test the validity of
transformer-based OCR and automated transcription alignment for workflows
applied to scholastic Latin corpora. If successful, this study will provide an
easily reusable template for the exploratory analysis of collaborative literary
production stemming from medieval universities.

### 44. LinguaSafe: A Comprehensive Multilingual Safety Benchmark for Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Zhiyuan Ning, Tianle Gu, Jiaxin Song, Shixin Hong, Lingyu Li, Huacan Liu, Jie Li, Yixu Wang, Meng Lingyu, Yan Teng, Yingchun Wang
- **URL**: <http://arxiv.org/abs/2508.12733v1>
- **Submitted**: 2025-08-18 08:59:01
- **Comment**: 7pages, 5 figures
- **Topic Keywords**: search
- **Reason**: The paper focuses on the safety evaluation of large language models, which is not directly related to information retrieval, search technologies, or query understanding. Although it mentions multilingual evaluation, the context is not relevant to the user's primary research interests in IR, NLP, and data mining.

#### Abstract
> The widespread adoption and increasing prominence of large language models
(LLMs) in global technologies necessitate a rigorous focus on ensuring their
safety across a diverse range of linguistic and cultural contexts. The lack of
a comprehensive evaluation and diverse data in existing multilingual safety
evaluations for LLMs limits their effectiveness, hindering the development of
robust multilingual safety alignment. To address this critical gap, we
introduce LinguaSafe, a comprehensive multilingual safety benchmark crafted
with meticulous attention to linguistic authenticity. The LinguaSafe dataset
comprises 45k entries in 12 languages, ranging from Hungarian to Malay. Curated
using a combination of translated, transcreated, and natively-sourced data, our
dataset addresses the critical need for multilingual safety evaluations of
LLMs, filling the void in the safety evaluation of LLMs across diverse
under-represented languages from Hungarian to Malay. LinguaSafe presents a
multidimensional and fine-grained evaluation framework, with direct and
indirect safety assessments, including further evaluations for oversensitivity.
The results of safety and helpfulness evaluations vary significantly across
different domains and different languages, even in languages with similar
resource levels. Our benchmark provides a comprehensive suite of metrics for
in-depth safety evaluation, underscoring the critical importance of thoroughly
assessing multilingual safety in LLMs to achieve more balanced safety
alignment. Our dataset and code are released to the public to facilitate
further research in the field of multilingual LLM safety.

### 45. Asymmetric Diffusion Recommendation Model

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yongchun Zhu, Guanyu Jiang, Jingwu Chen, Feng Zhang, Xiao Yang, Zuotao Liu
- **URL**: <http://arxiv.org/abs/2508.12706v1>
- **Submitted**: 2025-08-18 08:05:25
- **Comment**: Accepted by CIKM2025
- **Topic Keywords**: recommend
- **Reason**: The paper focuses on a recommendation model, which is only loosely related to the user's primary research interests in Information Retrieval and Search technologies. Although it mentions 'representation learning', the context is different from the user's focus on query understanding, ranking models, and user behavior modeling.

#### Abstract
> Recently, motivated by the outstanding achievements of diffusion models, the
diffusion process has been employed to strengthen representation learning in
recommendation systems. Most diffusion-based recommendation models typically
utilize standard Gaussian noise in symmetric forward and reverse processes in
continuous data space. Nevertheless, the samples derived from recommendation
systems inhabit a discrete data space, which is fundamentally different from
the continuous one. Moreover, Gaussian noise has the potential to corrupt
personalized information within latent representations. In this work, we
propose a novel and effective method, named Asymmetric Diffusion Recommendation
Model (AsymDiffRec), which learns forward and reverse processes in an
asymmetric manner. We define a generalized forward process that simulates the
missing features in real-world recommendation samples. The reverse process is
then performed in an asymmetric latent feature space. To preserve personalized
information within the latent representation, a task-oriented optimization
strategy is introduced. In the serving stage, the raw sample with missing
features is regarded as a noisy input to generate a denoising and robust
representation for the final prediction. By equipping base models with
AsymDiffRec, we conduct online A/B tests, achieving improvements of +0.131% and
+0.166% in terms of users' active days and app usage duration respectively.
Additionally, the extended offline experiments also demonstrate improvements.
AsymDiffRec has been implemented in the Douyin Music App.

### 46. jXBW: Fast Substructure Search in Large-Scale JSONL Datasets for Foundation Model Applications

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yasuo Tabei
- **URL**: <http://arxiv.org/abs/2508.12536v1>
- **Submitted**: 2025-08-18 00:14:24
- **Topic Keywords**: search
- **Reason**: The paper focuses on substructure search in JSONL datasets, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions foundation models, the context is not related to ranking models or user behavior modeling, and the paper's technical contributions are not applicable to the user's areas of interest.

#### Abstract
> Substructure search in JSON Lines (JSONL) datasets is essential for modern
applications such as prompt engineering in foundation models, but existing
methods suffer from prohibitive computational costs due to exhaustive tree
traversal and subtree matching. We present jXBW, a fast method for substructure
search on large-scale JSONL datasets. Our method makes three key technical
contributions: (i) a merged tree representation built by merging trees of
multiple JSON objects while preserving individual identities, (ii) a succinct
data structure based on the eXtended Burrows-Wheeler Transform that enables
efficient tree navigation and subpath search, and (iii) an efficient three-step
substructure search algorithm that combines path decomposition, ancestor
computation, and adaptive tree identifier collection to ensure correctness
while avoiding exhaustive tree traversal. Experimental evaluation on real-world
datasets demonstrates that jXBW consistently outperforms existing methods,
achieving speedups of 16$\times$ for smaller datasets and up to 4,700$\times$
for larger datasets over tree-based approaches, and more than 6$\times$10$^6$
over XML-based processing while maintaining competitive memory usage.

### 47. Mitigating Hallucinations in Large Language Models via Causal Reasoning

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Yuangang Li, Yiqing Shen, Yi Nian, Jiechao Gao, Ziyi Wang, Chenxiao Yu, Shawn Li, Jie Wang, Xiyang Hu, Yue Zhao
- **URL**: <http://arxiv.org/abs/2508.12495v1>
- **Submitted**: 2025-08-17 20:51:06
- **Topic Keywords**: search
- **Reason**: The paper focuses on large language models and causal reasoning, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it touches on the topic of logical inconsistencies in language models, it does not address query understanding, ranking models, or real-time relevance optimization, which are core areas of interest.

#### Abstract
> Large language models (LLMs) exhibit logically inconsistent hallucinations
that appear coherent yet violate reasoning principles, with recent research
suggesting an inverse relationship between causal reasoning capabilities and
such hallucinations. However, existing reasoning approaches in LLMs, such as
Chain-of-Thought (CoT) and its graph-based variants, operate at the linguistic
token level rather than modeling the underlying causal relationships between
variables, lacking the ability to represent conditional independencies or
satisfy causal identification assumptions. To bridge this gap, we introduce
causal-DAG construction and reasoning (CDCR-SFT), a supervised fine-tuning
framework that trains LLMs to explicitly construct variable-level directed
acyclic graph (DAG) and then perform reasoning over it. Moreover, we present a
dataset comprising 25,368 samples (CausalDR), where each sample includes an
input question, explicit causal DAG, graph-based reasoning trace, and validated
answer. Experiments on four LLMs across eight tasks show that CDCR-SFT improves
the causal reasoning capability with the state-of-the-art 95.33% accuracy on
CLADDER (surpassing human performance of 94.8% for the first time) and reduces
the hallucination on HaluEval with 10% improvements. It demonstrates that
explicit causal structure modeling in LLMs can effectively mitigate logical
inconsistencies in LLM outputs. Code is available at
https://github.com/MrLYG/CDCR-SFT.

---

