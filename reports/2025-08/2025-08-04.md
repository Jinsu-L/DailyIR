# Daily Papers Report - 2025-08-04

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Decomposed Reasoning with Reinforcement Learning for Relevance Assessment in UGC Platforms

- **LLM Score**: 8
- **Keyword Score**: 14
- **Authors**: Xiaowei Yuan, Lei Jin, Haoxin Zhang, Yan Gao, Yi Wu, Yao Hu, Ziyang Huang, Jun Zhao, Kang Liu
- **URL**: <http://arxiv.org/abs/2508.02506v1>
- **Submitted**: 2025-08-04 15:14:09
- **Topic Keywords**: query, queries, relevance, rag, retrieval, rank
- **Reason**: The paper focuses on relevance assessment in user-generated content platforms, which aligns with your interest in Information Retrieval and Search technologies. The use of reinforcement learning and decomposed reasoning framework is also relevant to your interest in ranking models and query understanding. However, the paper's focus on user-generated content platforms and unstructured language may not be directly applicable to your e-commerce domain background.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Relevance Assessment in User-Generated Content (UGC) Platforms
- **Aim**: To propose a novel Reinforced Reasoning Model for Relevance Assessment (R¬≥A) to accurately assess relevance in UGC platforms
- **Rationale**: Traditional relevance assessment models are inadequate for UGC platforms due to the lack of click-through data and prevalence of informal language, emotional expressions, emojis, and off-topic content
- **Ground**: The R¬≥A model introduces a decomposed reasoning framework that infers latent query intent by leveraging auxiliary high-ranked documents within the platform, followed by verbatim fragment extraction to justify relevance decisions
- **Experiment**: Experimental results demonstrate that R¬≥A outperforms all baseline models in relevance assessment on a real-world industry dataset, NoteRel, and consistently outperforms all baselines on the test set
- **Takeaway**: The proposed R¬≥A model performs decomposed reasoning over both ambiguous query and noisy document to better infer user intent and reduce erroneous outputs, achieving state-of-the-art performance in relevance assessment on a real-world industry dataset

#### Abstract
> Retrieval-augmented generation (RAG) plays a critical role in user-generated
content (UGC) platforms, but its effectiveness depends heavily on accurate
relevance assessment of query-document pairs. Despite recent advances in
applying large language models (LLMs) to relevance modeling, UGC platforms
present unique challenges: 1) ambiguous user intent due to sparse user feedback
in RAG scenarios, and 2) substantial noise introduced by informal and
unstructured language. To address these issues, we propose the Reinforced
Reasoning Model for Relevance Assessment (R3A), which introduces a decomposed
reasoning framework over queries and candidate documents before scoring. R3A
first leverages auxiliary high-ranked documents within the platform to infer
latent query intent. It then performs verbatim fragment extraction to justify
relevance decisions, thereby reducing errors caused by noisy UGC. Based on a
reinforcement learning framework, R3A is optimized to mitigate distortions
arising from ambiguous queries and unstructured content. Experimental results
show that R3A significantly outperforms existing baseline methods in terms of
relevance accuracy, across both offline benchmarks and online experiments.

---

### 2. Contextually Aware E-Commerce Product Question Answering using RAG

- **LLM Score**: 8
- **Keyword Score**: 9
- **Authors**: Praveen Tangarajan, Anand A. Rajasekar, Manish Rathi, Vinay Rao Dandin, Ozan Ersoy
- **URL**: <http://arxiv.org/abs/2508.01990v1>
- **Submitted**: 2025-08-04 02:14:07
- **Comment**: 6 pages, 1 figure, 5 tables. Preprint under review
- **Topic Keywords**: queries, rag, retrieval, commerce, e-commerce
- **Reason**: The paper is highly relevant to your interests in Information Retrieval, particularly in the context of e-commerce product question answering. The use of Retrieval Augmented Generation (RAG) and contextual understanding aligns with your focus on query understanding and ranking models. While the paper's primary focus is on e-commerce, its exploration of user behavior modeling and real-time relevance optimization resonates with your broader interests in IR and NLP.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Scalable End-to-End Framework for E-commerce Product Question Answering (PQA) using Retrieval Augmented Generation (RAG)
- **Aim**: To develop a framework that addresses cognitive overload on e-commerce product pages by delivering relevant and personalized answers to user queries
- **Rationale**: The proposed framework leverages conversational history, user profiles, and product attributes to handle objective, subjective, and multi-intent queries across heterogeneous sources
- **Ground**: The framework builds upon research in natural language processing, information retrieval, and question answering, drawing on references from ACM SIGIR, EMNLP, EACL, and arXiv
- **Experiment**: The experimental results show strong performance in handling diverse user queries, with high accuracy rates in query restructuring, intent determination, and catalog search, and deployment in a production conversational assistant serving over 5 million monthly active users
- **Takeaway**: The proposed framework achieves strong performance, but has limitations in its fixed sequential pipeline and predefined intent taxonomy, and future work involves developing a more adaptive, agentic architecture and automated pipelines for catalog enrichment

#### Abstract
> E-commerce product pages contain a mix of structured specifications,
unstructured reviews, and contextual elements like personalized offers or
regional variants. Although informative, this volume can lead to cognitive
overload, making it difficult for users to quickly and accurately find the
information they need. Existing Product Question Answering (PQA) systems often
fail to utilize rich user context and diverse product information effectively.
We propose a scalable, end-to-end framework for e-commerce PQA using Retrieval
Augmented Generation (RAG) that deeply integrates contextual understanding. Our
system leverages conversational history, user profiles, and product attributes
to deliver relevant and personalized answers. It adeptly handles objective,
subjective, and multi-intent queries across heterogeneous sources, while also
identifying information gaps in the catalog to support ongoing content
improvement. We also introduce novel metrics to measure the framework's
performance which are broadly applicable for RAG system evaluations.

---

### 3. FinCPRG: A Bidirectional Generation Pipeline for Hierarchical Queries and Rich Relevance in Financial Chinese Passage Retrieval

- **LLM Score**: 7
- **Keyword Score**: 15
- **Authors**: Xuan Xu, Beilin Chu, Qinhong Lin, Yixiao Zhong, Fufang Wen, Jiaqi Liu, Binjie Fei, Yu Li, Zhongliang Yang, Linna Zhou
- **URL**: <http://arxiv.org/abs/2508.02222v1>
- **Submitted**: 2025-08-04 09:12:45
- **Topic Keywords**: passage retrieval, query, queries, relevance, retrieval, search
- **Reason**: The paper proposes a bidirectional generation pipeline for hierarchical queries and rich relevance in financial Chinese passage retrieval, which is related to information retrieval and query understanding. Although it focuses on a specific domain (finance) and language (Chinese), the techniques and methods discussed can be applicable to other domains and languages. The paper's emphasis on hierarchical queries and relevance labels aligns with the user's interest in ranking models and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Automated Passage Retrieval Dataset Construction for Financial Chinese Passage Retrieval
- **Aim**: To propose a bidirectional generation pipeline, FinCPRG, for constructing a passage retrieval dataset for financial Chinese passage retrieval
- **Rationale**: To address the challenges of limited context window and simplistic synthesis pipelines in using Large Language Models (LLMs) to synthesize high-quality retrieval datasets
- **Ground**: The authors identify the limitations of existing approaches in fully synthetic datasets for document retrieval, such as the absence of cross-document queries and the challenging trade-off between cost and quality
- **Experiment**: The authors evaluate the FinCPRG dataset through multiple experiments, assessing the quality of relevance labels and validating its effectiveness as both an evaluation benchmark and a training dataset
- **Takeaway**: The proposed FinCPRG pipeline and dataset show high consistency with true financial retrieval benchmarks, validating the synthetic dataset's utility, and demonstrate potential for generating effective training data for low-resource domains

#### Abstract
> In recent years, large language models (LLMs) have demonstrated significant
potential in constructing passage retrieval datasets. However, existing methods
still face limitations in expressing cross-doc query needs and controlling
annotation quality. To address these issues, this paper proposes a
bidirectional generation pipeline, which aims to generate 3-level hierarchical
queries for both intra-doc and cross-doc scenarios and mine additional
relevance labels on top of direct mapping annotation. The pipeline introduces
two query generation methods: bottom-up from single-doc text and top-down from
multi-doc titles. The bottom-up method uses LLMs to disassemble and generate
structured queries at both sentence-level and passage-level simultaneously from
intra-doc passages. The top-down approach incorporates three key financial
elements--industry, topic, and time--to divide report titles into clusters and
prompts LLMs to generate topic-level queries from each cluster. For relevance
annotation, our pipeline not only relies on direct mapping annotation from the
generation relationship but also implements an indirect positives mining method
to enrich the relevant query-passage pairs. Using this pipeline, we constructed
a Financial Passage Retrieval Generated dataset (FinCPRG) from almost 1.3k
Chinese financial research reports, which includes hierarchical queries and
rich relevance labels. Through evaluations of mined relevance labels,
benchmarking and training experiments, we assessed the quality of FinCPRG and
validated its effectiveness as a passage retrieval dataset for both training
and benchmarking.

---

### 4. SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension

- **LLM Score**: 6
- **Keyword Score**: 7
- **Authors**: Junjie Wu, Jiangnan Li, Yuqing Li, Lemao Liu, Liyan Xu, Jiwei Li, Dit-Yan Yeung, Jie Zhou, Mo Yu
- **URL**: <http://arxiv.org/abs/2508.01959v1>
- **Submitted**: 2025-08-03 23:59:31
- **Comment**: Our trained models can be downloaded from:
  https://huggingface.co/SituatedEmbedding
- **Topic Keywords**: dense retrieval, rag, retrieval
- **Reason**: The paper proposes a new approach to contextualized dense retrieval, which is relevant to information retrieval and search technologies. However, the focus on long story comprehension and book-plot retrieval is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's emphasis on situated embeddings and contextualized retrieval is somewhat related to the user's interests in deep semantic understanding and real-time relevance optimization, but it does not seem to be a central match.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension
- **Aim**: To improve context-aware dense retrieval using situated embedding models (SitEmb) that account for how a chunk is situated within the original document
- **Rationale**: Existing embedding models are not well-equipped to encode situated context effectively, and situated embeddings can provide more contextually informed embeddings
- **Ground**: The authors evaluate their method on a book-plot retrieval dataset and report that their SitEmb-v1 model outperforms state-of-the-art embedding models
- **Experiment**: The authors employ a residual architecture, train a situated embedding model, and investigate the necessity of training a situated embedding model, comparing the performance of existing models
- **Takeaway**: The study demonstrates the effectiveness of situated embeddings in improving retrieval performance and highlights the need for new training objectives and broader domain coverage to improve generalization

#### Abstract
> Retrieval-augmented generation (RAG) over long documents typically involves
splitting the text into smaller chunks, which serve as the basic units for
retrieval. However, due to dependencies across the original document,
contextual information is often essential for accurately interpreting each
chunk. To address this, prior work has explored encoding longer context windows
to produce embeddings for longer chunks. Despite these efforts, gains in
retrieval and downstream tasks remain limited. This is because (1) longer
chunks strain the capacity of embedding models due to the increased amount of
information they must encode, and (2) many real-world applications still
require returning localized evidence due to constraints on model or human
bandwidth.
  We propose an alternative approach to this challenge by representing short
chunks in a way that is conditioned on a broader context window to enhance
retrieval performance -- i.e., situating a chunk's meaning within its context.
We further show that existing embedding models are not well-equipped to encode
such situated context effectively, and thus introduce a new training paradigm
and develop the situated embedding models (SitEmb). To evaluate our method, we
curate a book-plot retrieval dataset specifically designed to assess situated
retrieval capabilities. On this benchmark, our SitEmb-v1 model based on BGE-M3
substantially outperforms state-of-the-art embedding models, including several
with up to 7-8B parameters, with only 1B parameters. Our 8B SitEmb-v1.5 model
further improves performance by over 10% and shows strong results across
different languages and several downstream applications.

---

### 5. Evaluating Position Bias in Large Language Model Recommendations

- **LLM Score**: 5
- **Keyword Score**: 6
- **Authors**: Ethan Bito, Yongli Ren, Estrid He
- **URL**: <http://arxiv.org/abs/2508.02020v1>
- **Submitted**: 2025-08-04 03:30:26
- **Topic Keywords**: ranking, recommend, rank, search
- **Reason**: The paper explores the position bias in Large Language Model recommendations, which is somewhat related to my interests in Information Retrieval and Search technologies. However, the focus on recommender systems and language models is not directly aligned with my primary focus on query understanding, ranking models, and user behavior modeling in the context of e-commerce and information retrieval.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Mitigating Position Bias in Large Language Model-based Recommendation Systems
- **Aim**: To develop a prompting strategy that reduces position bias in Large Language Model (LLM) recommendations without requiring model fine-tuning or post-processing
- **Rationale**: LLMs are highly sensitive to input orders, leading to position bias in recommendations, and existing approaches require extensive resources and task-specific data
- **Ground**: The authors analyze the position bias of LLM-based recommendations on real-world datasets and find that LLMs are highly sensitive to input orders
- **Experiment**: The authors propose and evaluate the performance of the Ranking via Iterative SElection (RISE) strategy on two popular datasets, MovieLens-1M and Amazon Books, using several metrics
- **Takeaway**: RISE achieves the highest positional consistency and output similarity across all datasets and values of K, while reducing position bias and improving similarity consistency

#### Abstract
> Large Language Models (LLMs) are being increasingly explored as
general-purpose tools for recommendation tasks, enabling zero-shot and
instruction-following capabilities without the need for task-specific training.
While the research community is enthusiastically embracing LLMs, there are
important caveats to directly adapting them for recommendation tasks. In this
paper, we show that LLM-based recommendation models suffer from position bias,
where the order of candidate items in a prompt can disproportionately influence
the recommendations produced by LLMs. First, we analyse the position bias of
LLM-based recommendations on real-world datasets, where results uncover
systemic biases of LLMs with high sensitivity to input orders. Furthermore, we
introduce a new prompting strategy to mitigate the position bias of LLM
recommendation models called Ranking via Iterative SElection (RISE). We compare
our proposed method against various baselines on key benchmark datasets.
Experiment results show that our method reduces sensitivity to input ordering
and improves stability without requiring model fine-tuning or post-processing.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. Learning Partially-Decorrelated Common Spaces for Ad-hoc Video Search

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Fan Hu, Zijie Xin, Xirong Li
- **URL**: <http://arxiv.org/abs/2508.02340v1>
- **Submitted**: 2025-08-04 12:21:16
- **Comment**: Accepted by ACMMM2025
- **Topic Keywords**: query, ranking, rank, search, trec
- **Reason**: The paper focuses on Ad-hoc Video Search, which is not directly related to the user's primary interest in Information Retrieval and Search technologies. While it touches on query understanding and ranking models, the context is different and the techniques proposed are specific to video search. The user's background in e-commerce and interest in NLP and data mining are not explicitly addressed in this paper.

#### Abstract
> Ad-hoc Video Search (AVS) involves using a textual query to search for
multiple relevant videos in a large collection of unlabeled short videos. The
main challenge of AVS is the visual diversity of relevant videos. A simple
query such as "Find shots of a man and a woman dancing together indoors" can
span a multitude of environments, from brightly lit halls and shadowy bars to
dance scenes in black-and-white animations. It is therefore essential to
retrieve relevant videos as comprehensively as possible. Current solutions for
the AVS task primarily fuse multiple features into one or more common spaces,
yet overlook the need for diverse spaces. To fully exploit the expressive
capability of individual features, we propose LPD, short for Learning Partially
Decorrelated common spaces. LPD incorporates two key innovations:
feature-specific common space construction and the de-correlation loss.
Specifically, LPD learns a separate common space for each video and text
feature, and employs de-correlation loss to diversify the ordering of negative
samples across different spaces. To enhance the consistency of multi-space
convergence, we designed an entropy-based fair multi-space triplet ranking
loss. Extensive experiments on the TRECVID AVS benchmarks (2016-2023) justify
the effectiveness of LPD. Moreover, diversity visualizations of LPD's spaces
highlight its ability to enhance result diversity.

### 7. AGENTICT$^2$S:Robust Text-to-SPARQL via Agentic Collaborative Reasoning over Heterogeneous Knowledge Graphs for the Circular Economy

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Yang Zhao, Chengxiao Dai, Wei Zhuo, Tan Chuan Fu, Yue Xiu, Dusit Niyato, Jonathan Z. Low, Eugene Ho Hong Zhuang, Daren Zong Loong Tan
- **URL**: <http://arxiv.org/abs/2508.01815v1>
- **Submitted**: 2025-08-03 15:58:54
- **Topic Keywords**: query, queries, rag, retrieval
- **Reason**: The paper presents a framework for question answering over heterogeneous knowledge graphs, which is a topic in Natural Language Processing (NLP) and data mining. However, the focus on knowledge graphs and SPARQL queries is not directly related to my primary interest in Information Retrieval (IR) and search technologies, particularly query understanding, ranking models, and user behavior modeling.

#### Abstract
> Question answering over heterogeneous knowledge graphs (KGQA) involves
reasoning across diverse schemas, incomplete alignments, and distributed data
sources. Existing text-to-SPARQL approaches rely on large-scale domain-specific
fine-tuning or operate within single-graph settings, limiting their
generalizability in low-resource domains and their ability to handle queries
spanning multiple graphs. These challenges are particularly relevant in domains
such as the circular economy, where information about classifications,
processes, and emissions is distributed across independently curated knowledge
graphs (KGs). We present AgenticT$^2$S, a modular framework that decomposes
KGQA into subtasks managed by specialized agents responsible for retrieval,
query generation, and verification. A scheduler assigns subgoals to different
graphs using weak-to-strong alignment strategies. A two-stage verifier detects
structurally invalid and semantically underspecified queries through symbolic
validation and counterfactual consistency checks. Experiments on real-world
circular economy KGs demonstrate that AgenticT$^2$S improves execution accuracy
by 17.3% and triple level F$_1$ by 25.4% over the best baseline, while reducing
the average prompt length by 46.4%. These results demonstrate the benefits of
agent-based schema-aware reasoning for scalable KGQA and support
decision-making in sustainability domains through robust cross-graph reasoning.

### 8. Hubness Reduction with Dual Bank Sinkhorn Normalization for Cross-Modal Retrieval

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Zhengxin Pan, Haishuai Wang, Fangyu Wu, Peng Zhang, Jiajun Bu
- **URL**: <http://arxiv.org/abs/2508.02538v1>
- **Submitted**: 2025-08-04 15:45:48
- **Comment**: ACMMM 2025
- **Topic Keywords**: query, queries, retrieval
- **Reason**: The paper focuses on cross-modal retrieval, which is not directly related to the user's primary research interests in Information Retrieval and Search technologies. While the paper mentions hubness reduction and normalization techniques, these concepts are not specifically related to query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user.

#### Abstract
> The past decade has witnessed rapid advancements in cross-modal retrieval,
with significant progress made in accurately measuring the similarity between
cross-modal pairs. However, the persistent hubness problem, a phenomenon where
a small number of targets frequently appear as nearest neighbors to numerous
queries, continues to hinder the precision of similarity measurements. Despite
several proposed methods to reduce hubness, their underlying mechanisms remain
poorly understood. To bridge this gap, we analyze the widely-adopted Inverted
Softmax approach and demonstrate its effectiveness in balancing target
probabilities during retrieval. Building on these insights, we propose a
probability-balancing framework for more effective hubness reduction. We
contend that balancing target probabilities alone is inadequate and, therefore,
extend the framework to balance both query and target probabilities by
introducing Sinkhorn Normalization (SN). Notably, we extend SN to scenarios
where the true query distribution is unknown, showing that current methods,
which rely solely on a query bank to estimate target hubness, produce
suboptimal results due to a significant distributional gap between the query
bank and targets. To mitigate this issue, we introduce Dual Bank Sinkhorn
Normalization (DBSN), incorporating a corresponding target bank alongside the
query bank to narrow this distributional gap. Our comprehensive evaluation
across various cross-modal retrieval tasks, including image-text retrieval,
video-text retrieval, and audio-text retrieval, demonstrates consistent
performance improvements, validating the effectiveness of both SN and DBSN. All
codes are publicly available at https://github.com/ppanzx/DBSN.

### 9. Agentic Personalized Fashion Recommendation in the Age of Generative AI: Challenges, Opportunities, and Evaluation

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Yashar Deldjoo, Nima Rafiee, Mahdyar Ravanbakhsh
- **URL**: <http://arxiv.org/abs/2508.02342v1>
- **Submitted**: 2025-08-04 12:22:25
- **Topic Keywords**: queries, retrieval, recommend, search
- **Reason**: The paper focuses on fashion recommender systems, which is outside the user's primary research interest in Information Retrieval and Search technologies. While it mentions some relevant concepts like query understanding and ranking models, the application domain is not directly related to the user's expertise. The paper's emphasis on mixed-modality refinement and agentic LLM planners is also not a central match for the user's interests.

#### Abstract
> Fashion recommender systems (FaRS) face distinct challenges due to rapid
trend shifts, nuanced user preferences, intricate item-item compatibility, and
the complex interplay among consumers, brands, and influencers. Traditional
recommendation approaches, largely static and retrieval-focused, struggle to
effectively capture these dynamic elements, leading to decreased user
satisfaction and elevated return rates. This paper synthesizes both academic
and industrial viewpoints to map the distinctive output space and stakeholder
ecosystem of modern FaRS, identifying the complex interplay among users,
brands, platforms, and influencers, and highlighting the unique data and
modeling challenges that arise.
  We outline a research agenda for industrial FaRS, centered on five
representative scenarios spanning static queries, outfit composition, and
multi-turn dialogue, and argue that mixed-modality refinement-the ability to
combine image-based references (anchors) with nuanced textual constraints-is a
particularly critical task for real-world deployment. To this end, we propose
an Agentic Mixed-Modality Refinement (AMMR) pipeline, which fuses multimodal
encoders with agentic LLM planners and dynamic retrieval, bridging the gap
between expressive user intent and fast-changing fashion inventories. Our work
shows that moving beyond static retrieval toward adaptive, generative, and
stakeholder-aware systems is essential to satisfy the evolving expectations of
fashion consumers and brands.

### 10. Why Generate When You Can Transform? Unleashing Generative Attention for Dynamic Recommendation

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Yuli Liu, Wenjun Kong, Cheng Luo, Weizhi Ma
- **URL**: <http://arxiv.org/abs/2508.02050v1>
- **Submitted**: 2025-08-04 04:33:26
- **Comment**: Accepted at ACMMM 2025
- **Topic Keywords**: query, user behavior, recommend
- **Reason**: The paper explores a novel approach to attention mechanisms in sequential recommendation, leveraging generative models to capture non-linear user behavior. While it touches on attention and ranking, the focus is on recommendation rather than information retrieval, and the connection to query understanding and ranking models is not explicitly made. The paper's relevance to the user's interests is somewhat limited, but the innovative application of generative models to attention mechanisms is an interesting area of research.

#### Abstract
> Sequential Recommendation (SR) focuses on personalizing user experiences by
predicting future preferences based on historical interactions. Transformer
models, with their attention mechanisms, have become the dominant architecture
in SR tasks due to their ability to capture dependencies in user behavior
sequences. However, traditional attention mechanisms, where attention weights
are computed through query-key transformations, are inherently linear and
deterministic. This fixed approach limits their ability to account for the
dynamic and non-linear nature of user preferences, leading to challenges in
capturing evolving interests and subtle behavioral patterns. Given that
generative models excel at capturing non-linearity and probabilistic
variability, we argue that generating attention distributions offers a more
flexible and expressive alternative compared to traditional attention
mechanisms. To support this claim, we present a theoretical proof demonstrating
that generative attention mechanisms offer greater expressiveness and
stochasticity than traditional deterministic approaches. Building upon this
theoretical foundation, we introduce two generative attention models for SR,
each grounded in the principles of Variational Autoencoders (VAE) and Diffusion
Models (DMs), respectively. These models are designed specifically to generate
adaptive attention distributions that better align with variable user
preferences. Extensive experiments on real-world datasets show our models
significantly outperform state-of-the-art in both accuracy and diversity.

### 11. TreeRanker: Fast and Model-agnostic Ranking System for Code Suggestions in IDEs

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Daniele Cipollone, Egor Bogomolov, Arie van Deursen, Maliheh Izadi
- **URL**: <http://arxiv.org/abs/2508.02455v1>
- **Submitted**: 2025-08-04 14:20:39
- **Topic Keywords**: ranking, rank, search
- **Reason**: The paper focuses on code completion and ranking in IDEs, which is a specific application of information retrieval. While it uses language models, the primary goal is not query understanding or ranking models, but rather a practical solution for code completion. The paper's relevance to the user's research interests is somewhat limited, but it does touch on some related topics.

#### Abstract
> Token-level code completion is one of the most critical features in modern
Integrated Development Environments (IDEs). It assists developers by suggesting
relevant identifiers and APIs during coding. While completions are typically
derived from static analysis, their usefulness depends heavily on how they are
ranked, as correct predictions buried deep in the list are rarely seen by
users. Most current systems rely on hand-crafted heuristics or lightweight
machine learning models trained on user logs, which can be further improved to
capture context information and generalize across projects and coding styles.
In this work, we propose a new scoring approach to ranking static completions
using language models in a lightweight and model-agnostic way. Our method
organizes all valid completions into a prefix tree and performs a single greedy
decoding pass to collect token-level scores across the tree. This enables a
precise token-aware ranking without needing beam search, prompt engineering, or
model adaptations. The approach is fast, architecture-agnostic, and compatible
with already deployed models for code completion. These findings highlight a
practical and effective pathway for integrating language models into already
existing tools within IDEs, and ultimately providing smarter and more
responsive developer assistance.

### 12. Beyond Chunks and Graphs: Retrieval-Augmented Generation through Triplet-Driven Thinking

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Shengbo Gong, Xianfeng Tang, Carl Yang, Wei jin
- **URL**: <http://arxiv.org/abs/2508.02435v1>
- **Submitted**: 2025-08-04 13:50:44
- **Comment**: 19 pages
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper proposes a novel framework for retrieval-augmented generation, addressing challenges in efficiency and performance. While it's related to information retrieval and NLP, the focus is on a specific application and doesn't directly align with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Retrieval-augmented generation (RAG) is critical for reducing hallucinations
and incorporating external knowledge into Large Language Models (LLMs).
However, advanced RAG systems face a trade-off between performance and
efficiency. Multi-round RAG approaches achieve strong reasoning but incur
excessive LLM calls and token costs, while Graph RAG methods suffer from
computationally expensive, error-prone graph construction and retrieval
redundancy. To address these challenges, we propose T$^2$RAG, a novel framework
that operates on a simple, graph-free knowledge base of atomic triplets.
T$^2$RAG leverages an LLM to decompose questions into searchable triplets with
placeholders, which it then iteratively resolves by retrieving evidence from
the triplet database. Empirical results show that T$^2$RAG significantly
outperforms state-of-the-art multi-round and Graph RAG methods, achieving an
average performance gain of up to 11\% across six datasets while reducing
retrieval costs by up to 45\%. Our code is available at
https://github.com/rockcor/T2RAG

### 13. CompressKV: Semantic Retrieval Heads Know What Tokens are Not Important Before Generation

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Xiaolin Lin, Jingcun Wang, Olga Kondrateva, Yiyu Shi, Bing Li, Grace Li Zhang
- **URL**: <http://arxiv.org/abs/2508.02401v1>
- **Submitted**: 2025-08-04 13:26:16
- **Topic Keywords**: query, retrieval
- **Reason**: The paper focuses on compressing key-value caches in large language models, which is a specific problem in NLP. While it mentions attention heads and retrieval, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval. The paper's relevance is somewhat tangential, but it may still be of interest to researchers exploring NLP and related topics.

#### Abstract
> Recent advances in large language models (LLMs) have significantly boosted
long-context processing. However, the increasing key-value (KV) cache size
poses critical challenges to memory and execution efficiency. Most KV cache
compression methods rely on heuristic token eviction using all attention heads
in Grouped Query Attention (GQA)-based LLMs. This method ignores the different
functionalities of attention heads, leading to the eviction of critical tokens
and thus degrades the performance of LLMs.
  To address the issue above, instead of using all the attention heads in
GQA-based LLMs to determine important tokens as in the previous work, we first
identify the attention heads in each layer that are not only capable of
retrieving the initial and final tokens of a prompt, but also capable of
retrieving important tokens within the text and attending to their surrounding
semantic context. Afterwards, we exploit such heads to determine the important
tokens and retain their corresponding KV cache pairs. Furthermore, we analyze
the cache eviction error of each layer individually and introduce a
layer-adaptive KV cache allocation strategy. Experimental results demonstrate
the proposed CompressKV consistently outperforms state-of-the-art approaches
under various memory budgets on LongBench and Needle-in-a-Haystack benchmarks.
Our code is publicly available at: https://github.com/TUDa-HWAI/CompressKV.git.

### 14. From Generation to Consumption: Personalized List Value Estimation for Re-ranking

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Kaike Zhang, Xiaobei Wang, Xiaoyu Liu, Shuchang Liu, Hailan Yang, Xiang Li, Fei Sun, Qi Cao
- **URL**: <http://arxiv.org/abs/2508.02242v1>
- **Submitted**: 2025-08-04 09:43:21
- **Topic Keywords**: ranking, recommend, rank
- **Reason**: The paper focuses on recommender systems, specifically re-ranking, which is somewhat related to information retrieval. However, the emphasis on user behavior modeling and exit probabilities is more relevant to user behavior modeling and click models, which are part of my research interests. The paper's scope is narrower than my interests, but it does touch on some relevant topics.

#### Abstract
> Re-ranking is critical in recommender systems for optimizing the order of
recommendation lists, thus improving user satisfaction and platform revenue.
Most existing methods follow a generator-evaluator paradigm, where the
evaluator estimates the overall value of each candidate list. However, they
often ignore the fact that users may exit before consuming the full list,
leading to a mismatch between estimated generation value and actual consumption
value. To bridge this gap, we propose CAVE, a personalized Consumption-Aware
list Value Estimation framework. CAVE formulates the list value as the
expectation over sub-list values, weighted by user-specific exit probabilities
at each position. The exit probability is decomposed into an interest-driven
component and a stochastic component, the latter modeled via a Weibull
distribution to capture random external factors such as fatigue. By jointly
modeling sub-list values and user exit behavior, CAVE yields a more faithful
estimate of actual list consumption value. We further contribute three
large-scale real-world list-wise benchmarks from the Kuaishou platform, varying
in size and user activity patterns. Extensive experiments on these benchmarks,
two Amazon datasets, and online A/B testing on Kuaishou show that CAVE
consistently outperforms strong baselines, highlighting the benefit of
explicitly modeling user exits in re-ranking.

### 15. MLP Memory: Language Modeling with Retriever-pretrained External Memory

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Rubin Wei, Jiaqi Cao, Jiarui Wang, Jushi Kai, Qipeng Guo, Bowen Zhou, Zhouhan Lin
- **URL**: <http://arxiv.org/abs/2508.01832v1>
- **Submitted**: 2025-08-03 16:40:53
- **Topic Keywords**: retriever, rag
- **Reason**: The paper proposes a novel architecture for language modeling, leveraging a retriever-pretrained external memory to improve performance on downstream tasks. While it touches on some aspects of query understanding and ranking models, the focus is primarily on language modeling and memory-intensive tasks, which is somewhat related to the user's interests in Information Retrieval and Search technologies.

#### Abstract
> While modern decoder-only LLMs achieve superior performance across various
domains, hallucinations have risen to be a common problem in their generated
text, hindering their application in knowledge-intensive tasks.
Retriever-augmented generation (RAG) offers a solution, but the non-parametric
nature of the retriever hinders its deep interaction with LLM. In this work, we
propose to decouple memorization from the LLM decoder using a pretrained,
differentiable external memory. The external memory is an MLP pretrained by
imitating the behavior of a retriever on the entire pretraining dataset. Our
resulting architecture, which comprises a transformer decoder and an external
MLP memory pretrained on language modeling and retriever imitation
respectively, demonstrates strong perplexity and performance on downstream
tasks. Experiments show our architecture exhibits steeper power-law scaling
with model size, achieving 17.5% and 24.1% improvement on WikiText-103 and Web
datasets compared to decoder-only models while benefiting from added training
without overfitting. We demonstrate superior performance on three hallucination
benchmarks and nine memory-intensive tasks. Additionally, our approach delivers
$80\times$ speedup over $k$NN-LM (500M tokens) and $1.3\times$ faster inference
than decoder-only models. Unlike $k$NN-LM, which impairs reasoning, our MLP
memory improves StrategyQA performance. We will open-source our code and models
in the future.

### 16. Contextual Graph Transformer: A Small Language Model for Enhanced Engineering Document Information Extraction

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Karan Reddy, Mayukha Pal
- **URL**: <http://arxiv.org/abs/2508.02532v1>
- **Submitted**: 2025-08-04 15:41:35
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper proposes a novel neural architecture, Contextual Graph Transformer (CGT), for domain-specific question answering in technical documents. While it's related to Natural Language Processing (NLP) and Information Retrieval (IR), the focus is on language models for engineering documents, which is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Standard transformer-based language models, while powerful for general text,
often struggle with the fine-grained syntax and entity relationships in complex
technical, engineering documents. To address this, we propose the Contextual
Graph Transformer (CGT), a hybrid neural architecture that combines Graph
Neural Networks (GNNs) and Transformers for domain-specific question answering.
CGT constructs a dynamic graph over input tokens using sequential, skip-gram,
and semantic similarity edges, which is processed by GATv2Conv layers for local
structure learning. These enriched embeddings are then passed to a Transformer
encoder to capture global dependencies. Unlike generic large models, technical
domains often require specialized language models with stronger
contextualization and structure awareness. CGT offers a parameter-efficient
solution for such use cases. Integrated into a Retrieval-Augmented Generation
(RAG) pipeline, CGT outperforms baselines like GPT-2 and BERT, achieving 24.7%
higher accuracy than GPT-2 with 62.4% fewer parameters. This gain stems from
CGTs ability to jointly model structural token interactions and long-range
semantic coherence. The model is trained from scratch using a two-phase
approach: pretraining on general text followed by fine-tuning on
domain-specific manuals. This highlights CGTs adaptability to technical
language, enabling better grounding, entity tracking, and retrieval-augmented
responses in real-world applications.

### 17. Pointer: Linear-Complexity Long-Range Modeling without Pre-training

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Zixi Li
- **URL**: <http://arxiv.org/abs/2508.02631v1>
- **Submitted**: 2025-08-04 17:19:56
- **Comment**: Submitted to Nordic AI Meet 2025
- **Topic Keywords**: pairwise
- **Reason**: The paper introduces a novel architecture for long-range sequence modeling, which is not directly related to information retrieval or search technologies. While it mentions attention mechanisms, it does not focus on query understanding, ranking models, or user behavior modeling. The paper's emphasis on efficiency and interpretability is interesting, but it does not align with the user's primary research interests in IR and NLP.

#### Abstract
> We introduce Pointer, a novel architecture that achieves linear $O(NK)$
complexity for long-range sequence modeling while maintaining superior
performance without requiring pre-training. Unlike standard attention
mechanisms that compute $O(N^2)$ pairwise interactions, our approach uses
layer-wise pointer chaining where each layer's pointer selection depends on
previous layer's pointer positions, creating explicit long-distance connections
through pointer chains. We demonstrate that this architecture achieves
$2$--$10\times$ speedup on long sequences compared to standard transformers,
maintains $>95\%$ accuracy on copy tasks at distances up to 2048 tokens, and
learns interpretable pointer patterns that reveal structured dependency
modeling. Our experiments on efficiency benchmarks, long-range dependency
tasks, and interpretability analysis show that Pointer offers a compelling
alternative to attention mechanisms for scenarios requiring efficient
long-range modeling without pre-training dependencies.

### 18. Trainable Dynamic Mask Sparse Attention

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Jingze Shi, Yifan Wu, Bingheng Wu, Yiran Peng, Liangdong Wang, Guang Liu, Yuyu Luo
- **URL**: <http://arxiv.org/abs/2508.02124v1>
- **Submitted**: 2025-08-04 07:05:15
- **Comment**: 8 figures, 4 tables
- **Topic Keywords**: query
- **Reason**: The paper introduces a trainable dynamic mask sparse attention mechanism, which is a novel approach to improve the efficiency of self-attention mechanisms in large language models. While it is related to information retrieval and NLP, the focus is on improving the efficiency of language models rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user.

#### Abstract
> In large language models, the demand for modeling long contexts is constantly
increasing, but the quadratic complexity of the standard self-attention
mechanism often becomes a bottleneck. Although existing sparse attention
mechanisms have improved efficiency, they may still encounter issues such as
static patterns or information loss. We introduce a trainable dynamic mask
sparse attention mechanism, Dynamic Mask Attention, which effectively utilizes
content-aware and position-aware sparsity. DMA achieves this through two key
innovations: First, it dynamically generates content-aware sparse masks from
value representations, enabling the model to identify and focus on critical
information adaptively. Second, it implements position-aware sparse attention
computation that effectively skips unnecessary calculation regions. This
dual-sparsity design allows the model to significantly reduce the computational
complexity of important information while retaining complete information,
achieving an excellent balance between information fidelity and computational
efficiency. We have verified the performance of DMA through comprehensive
experiments. Comparative studies show that DMA outperforms multi-head
attention, sliding window attention, multi-head latent attention, and native
sparse attention in terms of perplexity under Chinchilla Scaling Law settings.
Moreover, in challenging multi-query associative recall tasks, DMA also
demonstrates superior performance and efficiency compared to these methods.
Crucially, in the evaluation of a 1.7B parameter model, DMA significantly
outperforms multi-head attention in both standard benchmark performance and the
challenging needle-in-a-haystack task. These experimental results highlight its
capability to balance model efficiency and long-context modeling ability
effectively.

### 19. MArgE: Meshing Argumentative Evidence from Multiple Large Language Models for Justifiable Claim Verification

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Ming Pok Ng, Junqi Jiang, Gabriel Freedman, Antonio Rago, Francesca Toni
- **URL**: <http://arxiv.org/abs/2508.02584v1>
- **Submitted**: 2025-08-04 16:40:02
- **Topic Keywords**: rag
- **Reason**: The paper explores the combination of multiple large language models, which is related to query understanding and ranking models in Information Retrieval. However, the focus on argumentative evidence and claim verification is not directly aligned with the user's primary interests in search technologies and user behavior modeling.

#### Abstract
> Leveraging outputs from multiple large language models (LLMs) is emerging as
a method for harnessing their power across a wide range of tasks while
mitigating their capacity for making errors, e.g., hallucinations. However,
current approaches to combining insights from multiple LLMs often involve
unstructured interactions (e.g., free debate), resulting in model generations
that are not faithfully justifiable. In this work, we introduce MArgE, a novel
framework to provide formal structure to the evidence from each LLM, in the
form of a tree of extracted arguments, for the task of claim verification. We
use a variant of Argumentative LLMs (ArgLLMs), i.e. LLMs driven by frameworks
and semantics from the field of computational argumentation, to construct
structured argument trees for given claims. This process creates an inspectable
pathway from the initial arguments to the final claim verification decisions,
providing a faithful justification thereof. We show experimentally that MArgE
can significantly outperform single LLMs, including three open-source models
(4B to 8B parameters), GPT-4o-mini and existing ArgLLMs, as well as prior
methods for unstructured multi-LLM debates. We thus demonstrate the advantages
of incorporating formal, argumentative reasoning mechanisms when combining
multiple LLM outputs.

### 20. LatentPrompt: Optimizing Promts in Latent Space

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Mateusz Bystro≈Ñski, Grzegorz Piotrowski, Nitesh V. Chawla, Tomasz Kajdanowicz
- **URL**: <http://arxiv.org/abs/2508.02452v1>
- **Submitted**: 2025-08-04 14:17:29
- **Topic Keywords**: rag
- **Reason**: The paper presents a framework for optimizing prompts for Large Language Models, which is related to query understanding and ranking models. However, the focus is on optimizing prompts rather than understanding user behavior or click models, which are key aspects of my research interests. The paper's relevance to information retrieval is limited, and it does not directly address real-time relevance optimization or deep semantic understanding.

#### Abstract
> Recent advances have shown that optimizing prompts for Large Language Models
(LLMs) can significantly improve task performance, yet many optimization
techniques rely on heuristics or manual exploration. We present LatentPrompt, a
model-agnostic framework for prompt optimization that leverages latent semantic
space to automatically generate, evaluate, and refine candidate prompts without
requiring hand-crafted rules. Beginning with a set of seed prompts, our method
embeds them in a continuous latent space and systematically explores this space
to identify prompts that maximize task-specific performance. In a
proof-of-concept study on the Financial PhraseBank sentiment classification
benchmark, LatentPrompt increased classification accuracy by approximately 3
percent after a single optimization cycle. The framework is broadly applicable,
requiring only black-box access to an LLM and an automatic evaluation metric,
making it suitable for diverse domains and tasks.

### 21. Simple Methods Defend RAG Systems Well Against Real-World Attacks

- **LLM Score**: 2
- **Keyword Score**: 13
- **Authors**: Ilias Triantafyllopoulos, Renyi Qu, Salvatore Giorgi, Brenda Curtis, Lyle H. Ungar, Jo√£o Sedoc
- **URL**: <http://arxiv.org/abs/2508.02296v1>
- **Submitted**: 2025-08-04 11:04:54
- **Topic Keywords**: query, queries, relevance, rag, retrieval
- **Reason**: The paper focuses on Retrieval-Augmented Generation (RAG) systems and Out-Of-Domain (OOD) query detection, which is not directly related to my research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. Although the paper mentions relevance and response correctness, it does not address the specific topics I am interested in, such as query understanding, ranking models, and real-time relevance optimization.

#### Abstract
> Ensuring safety and in-domain responses for Retrieval-Augmented Generation
(RAG) systems is paramount in safety-critical applications, yet remains a
significant challenge. To address this, we evaluate four methodologies for
Out-Of-Domain (OOD) query detection: GPT-4o, regression-based, Principal
Component Analysis (PCA)-based, and Neural Collapse (NC), to ensure the RAG
system only responds to queries confined to the system's knowledge base.
Specifically, our evaluation explores two novel dimensionality reduction and
feature separation strategies: \textit{PCA}, where top components are selected
using explained variance or OOD separability, and an adaptation of
\textit{Neural Collapse Feature Separation}. We validate our approach on
standard datasets (StackExchange and MSMARCO) and real-world applications
(Substance Use and COVID-19), including tests against LLM-simulated and actual
attacks on a COVID-19 vaccine chatbot. Through human and LLM-based evaluations
of response correctness and relevance, we confirm that an external OOD detector
is crucial for maintaining response relevance.

### 22. Quantum-RAG and PunGPT2: Advancing Low-Resource Language Generation and Retrieval for the Punjabi Language

- **LLM Score**: 2
- **Keyword Score**: 13
- **Authors**: Jaskaranjeet Singh, Rakesh Thakur
- **URL**: <http://arxiv.org/abs/2508.01918v1>
- **Submitted**: 2025-08-03 21:03:22
- **Topic Keywords**: retriever, queries, relevance, rag, retrieval
- **Reason**: This paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. Although it mentions retrieval-augmented generation and quantum-inspired semantic matching, the focus is on low-resource language generation and retrieval for the Punjabi language, which is not a primary area of interest for the user.

#### Abstract
> Despite the rapid advancement of large language models (LLMs), low-resource
languages remain largely excluded from the NLP landscape. We present PunGPT2,
the first fully open-source suite of Punjabi large language models, trained
from scratch on a 35GB domain-diverse corpus encompassing literature, religious
texts, news, and social discourse. Unlike prior multilingual approaches,
PunGPT2 captures rich syntactic and morphological features unique to Punjabi
through a tokenizer optimised with byte pair encoding and linguistically
aligned pretraining objectives. To improve factual grounding and domain recall,
we introduce Pun-RAG, a retrieval-augmented generation framework combining
PunGPT2 with a dense FAISS retriever over a curated Punjabi knowledge base. We
further develop Pun-Instruct, a parameter-efficient, instruction-tuned variant
using QLoRA, enabling robust zero-shot and instruction-following performance
with significantly reduced compute needs.
  As a key innovation, we propose Quantum-RAG, a novel hybrid retrieval system
that fuses sparse (BM25) and dense methods with quantum-inspired semantic
matching. By encoding queries using amplitude-based embeddings and retrieving
via quantum kernel similarity, Quantum-RAG achieves improved contextual
relevance with minimal memory overhead marking the first practical integration
of quantum representations in low-resource language generation. Our models
significantly outperform strong multilingual baselines (mBERT, mT5, MuRIL) in
perplexity, factuality, and fluency. This work provides a scalable,
reproducible blueprint for extending LLM capabilities to underrepresented
languages and pioneers quantum-aware retrieval in low-resource NLP

### 23. Dynamic Forgetting and Spatio-Temporal Periodic Interest Modeling for Local-Life Service Recommendation

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Zhaoyu Hu, Hao Guo, Yuan Tian, Erpeng Xue, Jianyang Wang, Xianyang Qi, Hongxiang Lin, Lei Wang, Sheng Chen
- **URL**: <http://arxiv.org/abs/2508.02451v1>
- **Submitted**: 2025-08-04 14:16:49
- **Topic Keywords**: query, user behavior, recommend
- **Reason**: This paper focuses on recommender systems, specifically local-life service recommendation, which is not directly related to the user's primary research interests in Information Retrieval and Search technologies. Although it mentions query-based mixture of experts, the approach is not specifically related to query understanding, ranking models, or user behavior modeling in the context of IR.

#### Abstract
> In the context of the booming digital economy, recommendation systems, as a
key link connecting users and numerous services, face challenges in modeling
user behavior sequences on local-life service platforms, including the sparsity
of long sequences and strong spatio-temporal dependence. Such challenges can be
addressed by drawing an analogy to the forgetting process in human memory. This
is because users' responses to recommended content follow the recency effect
and the cyclicality of memory. By exploring this, this paper introduces the
forgetting curve and proposes Spatio-Temporal periodic Interest Modeling (STIM)
with long sequences for local-life service recommendation. STIM integrates
three key components: a dynamic masking module based on the forgetting curve,
which is used to extract both recent spatiotemporal features and periodic
spatiotemporal features; a query-based mixture of experts (MoE) approach that
can adaptively activate expert networks under different dynamic masks, enabling
the collaborative modeling of time, location, and items; and a hierarchical
multi-interest network unit, which captures multi-interest representations by
modeling the hierarchical interactions between the shallow and deep semantics
of users' recent behaviors. By introducing the STIM method, we conducted online
A/B tests and achieved a 1.54\% improvement in gross transaction volume (GTV).
In addition, extended offline experiments also showed improvements. STIM has
been deployed in a large-scale local-life service recommendation system,
serving hundreds of millions of daily active users in core application
scenarios.

### 24. Sparse-dLLM: Accelerating Diffusion LLMs with Dynamic Cache Eviction

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Yuerong Song, Xiaoran Liu, Ruixiao Li, Zhigeng Liu, Zengfeng Huang, Qipeng Guo, Ziwei He, Xipeng Qiu
- **URL**: <http://arxiv.org/abs/2508.02558v1>
- **Submitted**: 2025-08-04 16:14:03
- **Comment**: 11 pages, 6 figures
- **Topic Keywords**: relevance, rag
- **Reason**: The paper focuses on accelerating Diffusion Large Language Models (dLLMs) with dynamic cache eviction, which is not directly related to Information Retrieval, Search technologies, query understanding, ranking models, or user behavior modeling. Although it mentions attention patterns, it does not explore query understanding or ranking models, and the context is language models rather than search or retrieval.

#### Abstract
> Diffusion Large Language Models (dLLMs) enable breakthroughs in reasoning and
parallel decoding but suffer from prohibitive quadratic computational
complexity and memory overhead during inference. Current caching techniques
accelerate decoding by storing full-layer states, yet impose substantial memory
usage that limit long-context applications. Our analysis of attention patterns
in dLLMs reveals persistent cross-layer sparsity, with pivotal tokens remaining
salient across decoding steps and low-relevance tokens staying unimportant,
motivating selective cache eviction. We propose Sparse-dLLM, the first
training-free framework integrating dynamic cache eviction with sparse
attention via delayed bidirectional sparse caching. By leveraging the stability
of token saliency over steps, it retains critical tokens and dynamically evicts
unimportant prefix/suffix entries using an attention-guided strategy. Extensive
experiments on LLaDA and Dream series demonstrate Sparse-dLLM achieves up to
10$\times$ higher throughput than vanilla dLLMs, with comparable performance
and similar peak memory costs, outperforming previous methods in efficiency and
effectiveness.

### 25. Graph Embedding in the Graph Fractional Fourier Transform Domain

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Changjie Sheng, Zhichao Zhang, Wei Yao
- **URL**: <http://arxiv.org/abs/2508.02383v1>
- **Submitted**: 2025-08-04 13:09:47
- **Topic Keywords**: rag, ctr, search
- **Reason**: The paper focuses on graph embedding and spectral graph representation learning, which is not directly related to the user's interests in Information Retrieval, Search technologies, and Natural Language Processing. While it mentions filtering and embedding, the context is graph-based and does not involve query understanding, ranking models, or user behavior modeling.

#### Abstract
> Spectral graph embedding plays a critical role in graph representation
learning by generating low-dimensional vector representations from graph
spectral information. However, the embedding space of traditional spectral
embedding methods often exhibit limited expressiveness, failing to exhaustively
capture latent structural features across alternative transform domains. To
address this issue, we use the graph fractional Fourier transform to extend the
existing state-of-the-art generalized frequency filtering embedding (GEFFE)
into fractional domains, giving birth to the generalized fractional filtering
embedding (GEFRFE), which enhances embedding informativeness via the graph
fractional domain. The GEFRFE leverages graph fractional domain filtering and a
nonlinear composition of eigenvector components derived from a fractionalized
graph Laplacian. To dynamically determine the fractional order, two parallel
strategies are introduced: search-based optimization and a ResNet18-based
adaptive learning. Extensive experiments on six benchmark datasets demonstrate
that the GEFRFE captures richer structural features and significantly enhance
classification performance. Notably, the proposed method retains computational
complexity comparable to GEFFE approaches.

### 26. CellForge: Agentic Design of Virtual Cell Models

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Xiangru Tang, Zhuoyun Yu, Jiapeng Chen, Yan Cui, Daniel Shao, Weixu Wang, Fang Wu, Yuchen Zhuang, Wenqi Shi, Zhi Huang, Arman Cohan, Xihong Lin, Fabian Theis, Smita Krishnaswamy, Mark Gerstein
- **URL**: <http://arxiv.org/abs/2508.02276v1>
- **Submitted**: 2025-08-04 10:43:31
- **Topic Keywords**: rag, retrieval, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on virtual cell modeling, artificial intelligence, and biology, which are not directly related to your areas of interest.

#### Abstract
> Virtual cell modeling represents an emerging frontier at the intersection of
artificial intelligence and biology, aiming to predict quantities such as
responses to diverse perturbations quantitatively. However, autonomously
building computational models for virtual cells is challenging due to the
complexity of biological systems, the heterogeneity of data modalities, and the
need for domain-specific expertise across multiple disciplines. Here, we
introduce CellForge, an agentic system that leverages a multi-agent framework
that transforms presented biological datasets and research objectives directly
into optimized computational models for virtual cells. More specifically, given
only raw single-cell multi-omics data and task descriptions as input, CellForge
outputs both an optimized model architecture and executable code for training
virtual cell models and inference. The framework integrates three core modules:
Task Analysis for presented dataset characterization and relevant literature
retrieval, Method Design, where specialized agents collaboratively develop
optimized modeling strategies, and Experiment Execution for automated
generation of code. The agents in the Design module are separated into experts
with differing perspectives and a central moderator, and have to
collaboratively exchange solutions until they achieve a reasonable consensus.
We demonstrate CellForge's capabilities in single-cell perturbation prediction,
using six diverse datasets that encompass gene knockouts, drug treatments, and
cytokine stimulations across multiple modalities. CellForge consistently
outperforms task-specific state-of-the-art methods. Overall, CellForge
demonstrates how iterative interaction between LLM agents with differing
perspectives provides better solutions than directly addressing a modeling
challenge. Our code is publicly available at
https://github.com/gersteinlab/CellForge.

### 27. Hidden in the Noise: Unveiling Backdoors in Audio LLMs Alignment through Latent Acoustic Pattern Triggers

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Liang Lin, Miao Yu, Kaiwen Luo, Yibo Zhang, Lilan Peng, Dexian Wang, Xuehai Tang, Yuanhe Zhang, Xikang Yang, Zhenhong Zhou, Kun Wang, Yang Liu
- **URL**: <http://arxiv.org/abs/2508.02175v1>
- **Submitted**: 2025-08-04 08:15:16
- **Topic Keywords**: rag, ctr, search
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or Natural Language Processing. The focus is on audio-based attacks on Large Language Models, which is a topic outside of the user's primary research interests.

#### Abstract
> As Audio Large Language Models (ALLMs) emerge as powerful tools for speech
processing, their safety implications demand urgent attention. While
considerable research has explored textual and vision safety, audio's distinct
characteristics present significant challenges. This paper first investigates:
Is ALLM vulnerable to backdoor attacks exploiting acoustic triggers? In
response to this issue, we introduce Hidden in the Noise (HIN), a novel
backdoor attack framework designed to exploit subtle, audio-specific features.
HIN applies acoustic modifications to raw audio waveforms, such as alterations
to temporal dynamics and strategic injection of spectrally tailored noise.
These changes introduce consistent patterns that an ALLM's acoustic feature
encoder captures, embedding robust triggers within the audio stream. To
evaluate ALLM robustness against audio-feature-based triggers, we develop the
AudioSafe benchmark, assessing nine distinct risk types. Extensive experiments
on AudioSafe and three established safety datasets reveal critical
vulnerabilities in existing ALLMs: (I) audio features like environment noise
and speech rate variations achieve over 90% average attack success rate. (II)
ALLMs exhibit significant sensitivity differences across acoustic features,
particularly showing minimal response to volume as a trigger, and (III)
poisoned sample inclusion causes only marginal loss curve fluctuations,
highlighting the attack's stealth.

### 28. CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Xiaoya Li, Xiaofei Sun, Albert Wang, Chris Shum, Jiwei Li
- **URL**: <http://arxiv.org/abs/2508.02091v1>
- **Submitted**: 2025-08-04 05:57:46
- **Comment**: Preprint Version
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper focuses on approximate nearest-neighbor search, which is not directly related to information retrieval, query understanding, or ranking models. While it mentions reinforcement learning, which is a related topic, the application is not in the context of search or retrieval, and the paper does not seem to address user behavior modeling or deep semantic understanding.

#### Abstract
> Approximate nearest-neighbor search (ANNS) algorithms have become
increasingly critical for recent AI applications, particularly in
retrieval-augmented generation (RAG) and agent-based LLM applications. In this
paper, we present CRINN, a new paradigm for ANNS algorithms. CRINN treats ANNS
optimization as a reinforcement learning problem where execution speed serves
as the reward signal. This approach enables the automatic generation of
progressively faster ANNS implementations while maintaining accuracy
constraints. Our experimental evaluation demonstrates CRINN's effectiveness
across six widely-used NNS benchmark datasets. When compared against
state-of-the-art open-source ANNS algorithms, CRINN achieves best performance
on three of them (GIST-960-Euclidean, MNIST-784-Euclidean, and
GloVe-25-angular), and tied for first place on two of them (SIFT-128-Euclidean
and GloVe-25-angular). The implications of CRINN's success reach well beyond
ANNS optimization: It validates that LLMs augmented with reinforcement learning
can function as an effective tool for automating sophisticated algorithmic
optimizations that demand specialized knowledge and labor-intensive manual
refinement.Code can be found at https://github.com/deepreinforce-ai/CRINN

### 29. Controllable and Stealthy Shilling Attacks via Dispersive Latent Diffusion

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Shutong Qiao, Wei Yuan, Junliang Yu, Tong Chen, Quoc Viet Hung Nguyen, Hongzhi Yin
- **URL**: <http://arxiv.org/abs/2508.01987v1>
- **Submitted**: 2025-08-04 01:54:32
- **Topic Keywords**: ranking, recommend, rank
- **Reason**: The paper focuses on shilling attacks in recommender systems, which is a topic related to information retrieval, but it does not address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's emphasis on generating fake users and promoting target items is not directly relevant to my research themes.

#### Abstract
> Recommender systems (RSs) are now fundamental to various online platforms,
but their dependence on user-contributed data leaves them vulnerable to
shilling attacks that can manipulate item rankings by injecting fake users.
Although widely studied, most existing attack models fail to meet two critical
objectives simultaneously: achieving strong adversarial promotion of target
items while maintaining realistic behavior to evade detection. As a result, the
true severity of shilling threats that manage to reconcile the two objectives
remains underappreciated. To expose this overlooked vulnerability, we present
DLDA, a diffusion-based attack framework that can generate highly effective yet
indistinguishable fake users by enabling fine-grained control over target
promotion. Specifically, DLDA operates in a pre-aligned collaborative embedding
space, where it employs a conditional latent diffusion process to iteratively
synthesize fake user profiles with precise target item control. To evade
detection, DLDA introduces a dispersive regularization mechanism that promotes
variability and realism in generated behavioral patterns. Extensive experiments
on three real-world datasets and five popular RS models demonstrate that,
compared to prior attacks, DLDA consistently achieves stronger item promotion
while remaining harder to detect. These results highlight that modern RSs are
more vulnerable than previously recognized, underscoring the urgent need for
more robust defenses.

### 30. Six Guidelines for Trustworthy, Ethical and Responsible Automation Design

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Matou≈° Jel√≠nek, Nadine Schlicker, Ewart de Visser
- **URL**: <http://arxiv.org/abs/2508.02371v1>
- **Submitted**: 2025-08-04 13:01:09
- **Topic Keywords**: rag, recommend, search
- **Reason**: The paper focuses on trustworthiness assessment and design guidelines for human-automation interactions, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on user behavior and interaction, the context is more focused on human-computer interaction and ethics rather than search and retrieval.

#### Abstract
> Calibrated trust in automated systems (Lee and See 2004) is critical for
their safe and seamless integration into society. Users should only rely on a
system recommendation when it is actually correct and reject it when it is
factually wrong. One requirement to achieve this goal is an accurate
trustworthiness assessment, ensuring that the user's perception of the system's
trustworthiness aligns with its actual trustworthiness, allowing users to make
informed decisions about the extent to which they can rely on the system
(Schlicker et al. 2022). We propose six design guidelines to help designers
optimize for accurate trustworthiness assessments, thus fostering ethical and
responsible human-automation interactions. The proposed guidelines are derived
from existing literature in various fields, such as human-computer interaction,
cognitive psychology, automation research, user-experience design, and ethics.
We are incorporating key principles from the field of pragmatics, specifically
the cultivation of common ground (H. H. Clark 1996) and Gricean communication
maxims (Grice 1975). These principles are essential for the design of automated
systems because the user's perception of the system's trustworthiness is shaped
by both environmental contexts, such as organizational culture or societal
norms, and by situational context, including the specific circumstances or
scenarios in which the interaction occurs (Hoff and Bashir 2015). Our proposed
guidelines provide actionable insights for designers to create automated
systems that make relevant trustworthiness cues available. This would ideally
foster calibrated trust and more satisfactory, productive, and safe
interactions between humans and automated systems. Furthermore, the proposed
heuristics might work as a tool for evaluating to what extent existing systems
enable users to accurately assess a system's trustworthiness.

### 31. OptiHive: Ensemble Selection for LLM-Based Optimization via Statistical Modeling

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Maxime Bouscary, Saurabh Amin
- **URL**: <http://arxiv.org/abs/2508.02503v1>
- **Submitted**: 2025-08-04 15:11:51
- **Topic Keywords**: query
- **Reason**: The paper focuses on LLM-based optimization and solver selection, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions natural-language descriptions, the primary application is in optimization problems, which is outside the user's core research themes.

#### Abstract
> LLM-based solvers have emerged as a promising means of automating problem
modeling and solving. However, they remain unreliable and often depend on
iterative repair loops that result in significant latency. We introduce
OptiHive, an LLM-based framework that produces high-quality solvers for
optimization problems from natural-language descriptions without iterative
self-correction. OptiHive uses a single batched LLM query to generate diverse
components (solvers, problem instances, and validation tests) and filters out
erroneous components to ensure fully interpretable outputs. Taking into account
the imperfection of the generated components, we employ a statistical model to
infer their true performance, enabling principled uncertainty quantification
and solver selection. On tasks ranging from traditional optimization problems
to challenging variants of the Multi-Depot Vehicle Routing Problem, OptiHive
significantly outperforms baselines, increasing the optimality rate from 5\% to
92\% on the most complex problems.

### 32. AI-Based Measurement of Innovation: Mapping Expert Insight into Large Language Model Applications

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Robin Nowak, Patrick Figge, Carolin Haeussler
- **URL**: <http://arxiv.org/abs/2508.02430v1>
- **Submitted**: 2025-08-04 13:49:30
- **Topic Keywords**: rag, search
- **Reason**: This paper focuses on using large language models to measure innovation, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on NLP and machine learning, the context and application are quite different from the user's primary research interests.

#### Abstract
> Measuring innovation often relies on context-specific proxies and on expert
evaluation. Hence, empirical innovation research is often limited to settings
where such data is available. We investigate how large language models (LLMs)
can be leveraged to overcome the constraints of manual expert evaluations and
assist researchers in measuring innovation. We design an LLM framework that
reliably approximates domain experts' assessment of innovation from
unstructured text data. We demonstrate the performance and broad applicability
of this framework through two studies in different contexts: (1) the
innovativeness of software application updates and (2) the originality of
user-generated feedback and improvement ideas in product reviews. We compared
the performance (F1-score) and reliability (consistency rate) of our LLM
framework against alternative measures used in prior innovation studies, and to
state-of-the-art machine learning- and deep learning-based models. The LLM
framework achieved higher F1-scores than the other approaches, and its results
are highly consistent (i.e., results do not change across runs). This article
equips R&D personnel in firms, as well as researchers, reviewers, and editors,
with the knowledge and tools to effectively use LLMs for measuring innovation
and evaluating the performance of LLM-based innovation measures. In doing so,
we discuss, the impact of important design decisions-including model selection,
prompt engineering, training data size, training data distribution, and
parameter settings-on performance and reliability. Given the challenges
inherent in using human expert evaluation and existing text-based measures, our
framework has important implications for harnessing LLMs as reliable,
increasingly accessible, and broadly applicable research tools for measuring
innovation.

### 33. Dynaword: From One-shot to Continuously Developed Datasets

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Kenneth Enevoldsen, Kristian N√∏rgaard Jensen, Jan Kostkan, Bal√°zs Szab√≥, M√°rton Kardos, Kirten Vad, Andrea Blasi N√∫√±ez, Gianluca Barmina, Jacob Nielsen, Rasmus Larsen, Peter Vahlstrup, Per M√∏ldrup Dalum, Desmond Elliott, Lukas Galke, Peter Schneider-Kamp, Kristoffer Nielbo
- **URL**: <http://arxiv.org/abs/2508.02271v1>
- **Submitted**: 2025-08-04 10:30:42
- **Topic Keywords**: rag, search
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on dataset creation and open licensing, which is outside the scope of the user's research interests.

#### Abstract
> Large-scale datasets are foundational for research and development in natural
language processing. However, current approaches face three key challenges: (1)
reliance on ambiguously licensed sources restricting use, sharing, and
derivative works; (2) static dataset releases that prevent community
contributions and diminish longevity; and (3) quality assurance processes
restricted to publishing teams rather than leveraging community expertise.
  To address these limitations, we introduce two contributions: the Dynaword
approach and Danish Dynaword. The Dynaword approach is a framework for creating
large-scale, open datasets that can be continuously updated through community
collaboration. Danish Dynaword is a concrete implementation that validates this
approach and demonstrates its potential. Danish Dynaword contains over four
times as many tokens as comparable releases, is exclusively openly licensed,
and has received multiple contributions across industry and research. The
repository includes light-weight tests to ensure data formatting, quality, and
documentation, establishing a sustainable framework for ongoing community
contributions and dataset evolution.

### 34. A Decentralized Framework for Ethical Authorship Validation in Academic Publishing: Leveraging Self-Sovereign Identity and Blockchain Technology

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Kamal Al-Sabahi, Yousuf Khamis Al Mabsali
- **URL**: <http://arxiv.org/abs/2508.01913v1>
- **Submitted**: 2025-08-03 20:26:19
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, data mining, or recommender systems. The paper focuses on a specific problem in academic publishing, using blockchain technology and Self-Sovereign Identity, which is outside your primary research areas.

#### Abstract
> Academic publishing, integral to knowledge dissemination and scientific
advancement, increasingly faces threats from unethical practices such as
unconsented authorship, gift authorship, author ambiguity, and undisclosed
conflicts of interest. While existing infrastructures like ORCID effectively
disambiguate researcher identities, they fall short in enforcing explicit
authorship consent, accurately verifying contributor roles, and robustly
detecting conflicts of interest during peer review. To address these
shortcomings, this paper introduces a decentralized framework leveraging
Self-Sovereign Identity (SSI) and blockchain technology. The proposed model
uses Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs) to
securely verify author identities and contributions, reducing ambiguity and
ensuring accurate attribution. A blockchain-based trust registry records
authorship consent and peer-review activity immutably. Privacy-preserving
cryptographic techniques, especially Zero-Knowledge Proofs (ZKPs), support
conflict-of-interest detection without revealing sensitive data. Verified
authorship metadata and consent records are embedded in publications,
increasing transparency. A stakeholder survey of researchers, editors, and
reviewers suggests the framework improves ethical compliance and confidence in
scholarly communication. This work represents a step toward a more transparent,
accountable, and trustworthy academic publishing ecosystem.

### 35. Counterfactual Reciprocal Recommender Systems for User-to-User Matching

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Kazuki Kawamura, Takuma Udagawa, Kei Tateno
- **URL**: <http://arxiv.org/abs/2508.01867v1>
- **Submitted**: 2025-08-03 17:45:04
- **Comment**: 9 pages, 2 figures. Accepted for publication at the Workshop on
  Two-sided Marketplace Optimization (TSMO '25), held in conjunction with the
  31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2025),
  Toronto, Canada
- **Topic Keywords**: rag, recommend
- **Reason**: The paper focuses on reciprocal recommender systems, which is not directly related to information retrieval, query understanding, or ranking models. While it touches on fairness and bias in learning, the context is specific to user-to-user matching in dating, gaming, and talent platforms, which is not a core area of interest for the user.

#### Abstract
> Reciprocal recommender systems (RRS) in dating, gaming, and talent platforms
require mutual acceptance for a match. Logged data, however, over-represents
popular profiles due to past exposure policies, creating feedback loops that
skew learning and fairness. We introduce Counterfactual Reciprocal Recommender
Systems (CFRR), a causal framework to mitigate this bias. CFRR uses inverse
propensity scored, self-normalized objectives. Experiments show CFRR improves
NDCG@10 by up to 3.5% (e.g., from 0.459 to 0.475 on DBLP, from 0.299 to 0.307
on Synthetic), increases long-tail user coverage by up to 51% (from 0.504 to
0.763 on Synthetic), and reduces Gini exposure inequality by up to 24% (from
0.708 to 0.535 on Synthetic). CFRR offers a promising approach for more
accurate and fair user-to-user matching.

### 36. CharBench: Evaluating the Role of Tokenization in Character-Level Tasks

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Omri Uzan, Yuval Pinter
- **URL**: <http://arxiv.org/abs/2508.02591v1>
- **Submitted**: 2025-08-04 16:46:15
- **Topic Keywords**: rag
- **Reason**: The paper focuses on character-level tasks and tokenization, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on language models and their performance on specific tasks is also not aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Tasks that require character-level reasoning, such as counting or locating
characters within words, remain challenging for contemporary language models. A
common conjecture is that language models' reliance on subword units, rather
than characters, contributes to their struggles with character-level tasks, yet
recent studies offer conflicting conclusions about the role of tokenization,
leaving its impact unclear. To address this gap, we introduce CharBench, a
comprehensive benchmark of character-level tasks that is two orders of
magnitude larger than existing alternatives. We evaluate a diverse range of
leading open-weight and proprietary models on CharBench and find that it
presents a significant challenge to modern LLMs, with an average accuracy of
43.6% and 32.3% on some tasks. We present an in-depth analysis of how intrinsic
properties of words and their segmentations into tokens correspond to model
performance. For counting tasks, we find that tokenization properties are
weakly correlated with correctness, while the length of the queried word and
the actual character count play a more significant part. In contrast, for tasks
requiring intra-word positional understanding, performance is negatively
correlated with the length of the token containing the queried character,
suggesting that longer tokens obscure character position information for LLMs.
We encourage future work to build on the benchmark and evaluation methodology
introduced here as tools for improving model performance on such tasks.

### 37. Parameter-Efficient Routed Fine-Tuning: Mixture-of-Experts Demands Mixture of Adaptation Modules

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yilun Liu, Yunpu Ma, Yuetian Lu, Shuo Chen, Zifeng Ding, Volker Tresp
- **URL**: <http://arxiv.org/abs/2508.02587v1>
- **Submitted**: 2025-08-04 16:43:09
- **Comment**: This paper is a preprint under review. arXiv admin note: text overlap
  with arXiv:2411.08212
- **Topic Keywords**: rag
- **Reason**: The paper focuses on Mixture-of-Experts (MoE) and Parameter-Efficient Fine-Tuning (PEFT) strategies, which is not directly related to Information Retrieval (IR) or Search technologies. Although it mentions language models, the context is not about query understanding, ranking models, or user behavior modeling, which are core areas of interest in IR.

#### Abstract
> Mixture-of-Experts (MoE) benefits from a dynamic routing mechanism among
their specialized experts, which existing Parameter- Efficient Fine-Tuning
(PEFT) strategies fail to leverage. This motivates us to investigate whether
adaptation modules themselves should incorporate routing mechanisms to align
with MoE's multi-expert architecture. We analyze dynamics of core components
when applying PEFT to MoE language models and examine how different routing
strategies affect adaptation effectiveness. Extensive experiments adapting
OLMoE-1B-7B and Mixtral-8x7B on various commonsense and math reasoning tasks
validate the performance and efficiency of our routed approach. We identify the
optimal configurations for different scenarios and provide empirical analyses
with practical insights to facilitate better PEFT and MoE applications.

### 38. EHSAN: Leveraging ChatGPT in a Hybrid Framework for Arabic Aspect-Based Sentiment Analysis in Healthcare

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Eman Alamoudi, Ellis Solaiman
- **URL**: <http://arxiv.org/abs/2508.02574v1>
- **Submitted**: 2025-08-04 16:28:58
- **Topic Keywords**: rag
- **Reason**: This paper focuses on Arabic aspect-based sentiment analysis in healthcare, leveraging ChatGPT for pseudo-labelling and human review. While it involves natural language processing and data mining, it is not directly related to information retrieval, search technologies, or query understanding, which are the user's primary research interests.

#### Abstract
> Arabic-language patient feedback remains under-analysed because dialect
diversity and scarce aspect-level sentiment labels hinder automated assessment.
To address this gap, we introduce EHSAN, a data-centric hybrid pipeline that
merges ChatGPT pseudo-labelling with targeted human review to build the first
explainable Arabic aspect-based sentiment dataset for healthcare. Each sentence
is annotated with an aspect and sentiment label (positive, negative, or
neutral), forming a pioneering Arabic dataset aligned with healthcare themes,
with ChatGPT-generated rationales provided for each label to enhance
transparency. To evaluate the impact of annotation quality on model
performance, we created three versions of the training data: a fully supervised
set with all labels reviewed by humans, a semi-supervised set with 50% human
review, and an unsupervised set with only machine-generated labels. We
fine-tuned two transformer models on these datasets for both aspect and
sentiment classification. Experimental results show that our Arabic-specific
model achieved high accuracy even with minimal human supervision, reflecting
only a minor performance drop when using ChatGPT-only labels. Reducing the
number of aspect classes notably improved classification metrics across the
board. These findings demonstrate an effective, scalable approach to Arabic
aspect-based sentiment analysis (SA) in healthcare, combining large language
model annotation with human expertise to produce a robust and explainable
dataset. Future directions include generalisation across hospitals, prompt
refinement, and interpretable data-driven modelling.

### 39. Automated SNOMED CT Concept Annotation in Clinical Text Using Bi-GRU Neural Networks

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ali Noori, Pratik Devkota, Somya Mohanty, Prashanti Manda
- **URL**: <http://arxiv.org/abs/2508.02556v1>
- **Submitted**: 2025-08-04 16:08:49
- **Topic Keywords**: rag
- **Reason**: This paper focuses on automated annotation of clinical text using SNOMED CT concepts, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves neural networks, the application is in the medical domain, which is not a primary focus of your research interests.

#### Abstract
> Automated annotation of clinical text with standardized medical concepts is
critical for enabling structured data extraction and decision support. SNOMED
CT provides a rich ontology for labeling clinical entities, but manual
annotation is labor-intensive and impractical at scale. This study introduces a
neural sequence labeling approach for SNOMED CT concept recognition using a
Bidirectional GRU model. Leveraging a subset of MIMIC-IV, we preprocess text
with domain-adapted SpaCy and SciBERT-based tokenization, segmenting sentences
into overlapping 19-token chunks enriched with contextual, syntactic, and
morphological features. The Bi-GRU model assigns IOB tags to identify concept
spans and achieves strong performance with a 90 percent F1-score on the
validation set. These results surpass traditional rule-based systems and match
or exceed existing neural models. Qualitative analysis shows effective handling
of ambiguous terms and misspellings. Our findings highlight that lightweight
RNN-based architectures can deliver high-quality clinical concept annotation
with significantly lower computational cost than transformer-based models,
making them well-suited for real-world deployment.

### 40. What's in the News? Towards Identification of Bias by Commission, Omission, and Source Selection (COSS)

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Anastasia Zhukova, Terry Ruas, Felix Hamborg, Karsten Donnay, Bela Gipp
- **URL**: <http://arxiv.org/abs/2508.02540v1>
- **Submitted**: 2025-08-04 15:47:17
- **Comment**: published in the Proceedings of the 2023 ACM/IEEE Joint Conference on
  Digital Libraries
- **Topic Keywords**: rag
- **Reason**: The paper focuses on identifying bias in news articles, which is not directly related to Information Retrieval, Search technologies, or query understanding. Although it touches on text analysis and feature extraction, the primary goal is not to improve search or ranking models, making it only loosely relevant to the user's research interests.

#### Abstract
> In a world overwhelmed with news, determining which information comes from
reliable sources or how neutral is the reported information in the news
articles poses a challenge to news readers. In this paper, we propose a
methodology for automatically identifying bias by commission, omission, and
source selection (COSS) as a joint three-fold objective, as opposed to the
previous work separately addressing these types of bias. In a pipeline concept,
we describe the goals and tasks of its steps toward bias identification and
provide an example of a visualization that leverages the extracted features and
patterns of text reuse.

### 41. PoeTone: A Framework for Constrained Generation of Structured Chinese Songci with LLMs

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zhan Qu, Shuzhou Yuan, Michael F√§rber
- **URL**: <http://arxiv.org/abs/2508.02515v1>
- **Submitted**: 2025-08-04 15:19:22
- **Topic Keywords**: rag
- **Reason**: This paper focuses on the application of large language models (LLMs) in generating structured Chinese Songci poetry, which is not directly related to information retrieval, search technologies, or query understanding. While it explores the capabilities of LLMs, the paper's primary concern is the cultural significance and formal constraints of literary texts, which is outside the scope of the user's research interests.

#### Abstract
> This paper presents a systematic investigation into the constrained
generation capabilities of large language models (LLMs) in producing Songci, a
classical Chinese poetry form characterized by strict structural, tonal, and
rhyme constraints defined by Cipai templates. We first develop a comprehensive,
multi-faceted evaluation framework that includes: (i) a formal conformity
score, (ii) automated quality assessment using LLMs, (iii) human evaluation,
and (iv) classification-based probing tasks. Using this framework, we evaluate
the generative performance of 18 LLMs, including 3 proprietary models and 15
open-source models across four families, under five prompting strategies:
zero-shot, one-shot, completion-based, instruction-tuned, and chain-of-thought.
Finally, we propose a Generate-Critic architecture in which the evaluation
framework functions as an automated critic. Leveraging the critic's feedback as
a reward signal, we fine-tune three lightweight open-source LLMs via supervised
fine-tuning (SFT), resulting in improvements of up to 5.88% in formal
conformity. Our findings offer new insights into the generative strengths and
limitations of LLMs in producing culturally significant and formally
constrained literary texts.

### 42. AIAP: A No-Code Workflow Builder for Non-Experts with Natural Language and Multi-Agent Collaboration

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Hyunjn An, Yongwon Kim, Wonduk Seo, Joonil Park, Daye Kang, Changhoon Oh, Dokyun Kim, Seunghyun Lee
- **URL**: <http://arxiv.org/abs/2508.02470v1>
- **Submitted**: 2025-08-04 14:36:31
- **Comment**: 14 pages, 6 figures
- **Topic Keywords**: rag
- **Reason**: The paper focuses on AIAP, a no-code platform for designing AI services, which is not directly related to Information Retrieval, Search technologies, or Natural Language Processing. The abstract does not mention query understanding, ranking models, or user behavior modeling, and the paper's scope is limited to AI service design, making it irrelevant to the user's research interests.

#### Abstract
> While many tools are available for designing AI, non-experts still face
challenges in clearly expressing their intent and managing system complexity.
We introduce AIAP, a no-code platform that integrates natural language input
with visual workflows. AIAP leverages a coordinated multi-agent system to
decompose ambiguous user instructions into modular, actionable steps, hidden
from users behind a unified interface. A user study involving 32 participants
showed that AIAP's AI-generated suggestions, modular workflows, and automatic
identification of data, actions, and context significantly improved
participants' ability to develop services intuitively. These findings highlight
that natural language-based visual programming significantly reduces barriers
and enhances user experience in AI service design.

### 43. Modality Bias in LVLMs: Analyzing and Mitigating Object Hallucination via Attention Lens

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Haohan Zheng, Zhenguo Zhang
- **URL**: <http://arxiv.org/abs/2508.02419v1>
- **Submitted**: 2025-08-04 13:40:59
- **Topic Keywords**: rag
- **Reason**: The paper focuses on Large Vision-Language Models (LVLMs) and object hallucination, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on attention mechanisms, it is primarily concerned with multimodal comprehension and reasoning in the context of LVLMs, which is outside the scope of the user's research interests.

#### Abstract
> Large vision-language models (LVLMs) have demonstrated remarkable multimodal
comprehension and reasoning capabilities, but they still suffer from severe
object hallucination. Previous studies primarily attribute the flaw to
linguistic prior caused by the scale mismatch between visual encoders and large
language models (LLMs) in LVLMs. Specifically, as current LVLMs are built upon
LLMs, they tend to over-rely on textual prompts and internal knowledge of LLMs,
generating descriptions inconsistent with visual cues. However, through an
in-depth investigation of the hallucinated mechanisms, we empirically reveal a
previously overlooked phenomenon: LVLMs may ignore not only visual information
but also textual modality during hallucination, a behavior termed as modality
bias, which indicates that LVLMs struggle to simultaneously attend to both
visual and textual modalities, leading to fragmented understanding of
user-provided instructions. Based on this observation, we propose a simple yet
effective training-free method to mitigate object hallucination. Concretely, we
intervene and adjust the attention weights of textual and visual tokens,
balancing cross-modal compatibility for better alignment with user intentions.
Furthermore, we adopt a contrastive decoding strategy to reduce the LVLM's
overreliance on its parametric knowledge, synergistically enhancing our
attention manipulation. Extensive experiments confirm the widespread presence
of modality bias in LVLMs. Notably, our method effectively mitigates
hallucination across multiple open-source LVLMs and benchmarks, highlighting
its generalizability and efficacy.

### 44. Understanding and Mitigating Political Stance Cross-topic Generalization in Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jiayi Zhang, Shu Yang, Junchao Wu, Derek F. Wong, Di Wang
- **URL**: <http://arxiv.org/abs/2508.02360v1>
- **Submitted**: 2025-08-04 12:49:10
- **Topic Keywords**: rag
- **Reason**: The paper focuses on understanding and mitigating cross-topic generalization in large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on neural networks and fine-tuning, the context is specific to natural language processing and political stance analysis, making it less relevant to the user's research interests.

#### Abstract
> Fine-tuning Large Language Models on a political topic will significantly
manipulate their political stance on various issues and unintentionally affect
their stance on unrelated topics. While previous studies have proposed this
issue, there is still a lack of understanding regarding the internal
representations of these stances and the mechanisms that lead to unintended
cross-topic generalization. In this paper, we systematically explore the
internal mechanisms underlying this phenomenon from a neuron-level perspective
and how to mitigate the cross-topic generalization of political fine-tuning.
Firstly, we propose Political Neuron Localization through Activation
Contrasting (PNLAC) to identify two distinct types of political neurons:
general political neurons, which govern stance across multiple political
topics, and topic-specific neurons} that affect the model's political stance on
individual topics. We find the existence of these political neuron types across
four models and datasets through activation patching experiments. Leveraging
these insights, we introduce InhibitFT, an inhibition-based fine-tuning method,
effectively mitigating the cross-topic stance generalization. Experimental
results demonstrate the robustness of identified neuron types across various
models and datasets, and show that InhibitFT significantly reduces the
cross-topic stance generalization by 20% on average, while preserving
topic-specific performance. Moreover, we demonstrate that selectively
inhibiting only 5% of neurons is sufficient to effectively mitigate the
cross-topic stance generalization.

### 45. CAMERA: Multi-Matrix Joint Compression for MoE Models via Micro-Expert Redundancy Analysis

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yuzhuang Xu, Xu Han, Yuanchi Zhang, Yixuan Wang, Yijun Liu, Shiyu Ji, Qingfu Zhu, Wanxiang Che
- **URL**: <http://arxiv.org/abs/2508.02322v1>
- **Submitted**: 2025-08-04 11:42:48
- **Comment**: 16 pages, 9 figures, 7 tables
- **Topic Keywords**: rag
- **Reason**: The paper focuses on compressing Mixture-of-Experts (MoE) models, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions large language models, the context is not relevant to the user's interests in IR, NLP, or data mining.

#### Abstract
> Large Language Models (LLMs) with Mixture-of-Experts (MoE) architectures are
distinguished by their strong performance scaling with increasing parameters
across a wide range of tasks, yet they also suffer from substantial
computational and storage overheads. Notably, the performance gains of MoE
models do not scale proportionally with the growth in expert parameters. While
prior works attempt to reduce parameters via expert-level pruning, merging, or
decomposition, they still suffer from challenges in both performance and
computational efficiency. In this paper, we address these challenges by
introducing micro-expert as a finer-grained compression unit that spans across
matrices. We first establish a more fundamental perspective, viewing MoE layers
as mixtures of micro-experts, and present CAMERA, a lightweight and
training-free framework for identifying micro-expert redundancy. Our analysis
uncovers significant variance in micro-expert contributions during decoding.
Based on this insight, we further propose CAMERA-P, a structured micro-expert
pruning framework, and CAMERA-Q, a mixed-precision quantization idea designed
for micro-experts. Extensive experiments on nine downstream tasks show that
CAMERA-P consistently outperforms strong baselines under pruning ratios ranging
from 20% to 60%. Furthermore, CAMERA-Q achieves superior results under
aggressive 2-bit quantization, surpassing existing matrix- and channel-level
ideas. Notably, our method enables complete micro-expert analysis of
Qwen2-57B-A14B in less than 5 minutes on a single NVIDIA A100-40GB GPU.

### 46. CAPO: Towards Enhancing LLM Reasoning through Verifiable Generative Credit Assignment

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Guofu Xie, Yunsheng Shi, Hongtao Tian, Ting Yao, Xiao Zhang
- **URL**: <http://arxiv.org/abs/2508.02298v1>
- **Submitted**: 2025-08-04 11:06:08
- **Comment**: Work in progress
- **Topic Keywords**: rag
- **Reason**: This paper focuses on reinforcement learning and credit assignment for large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing, the context is different from the user's primary research interests.

#### Abstract
> Reinforcement Learning with Verifiable Rewards (RLVR) has improved the
reasoning abilities of Large Language Models (LLMs) by using rule-based binary
feedback, helping to mitigate reward hacking. However, current RLVR methods
typically treat whole responses as single actions, assigning the same reward to
every token. This coarse-grained feedback hampers precise credit assignment,
making it hard for models to identify which reasoning steps lead to success or
failure, and often results in suboptimal policies and inefficient learning.
Methods like PPO provide credit assignment through value estimation, but often
yield inaccurate and unverifiable signals due to limited sampling. On the other
hand, methods using Process Reward Models can provide step-by-step judgments
for each reasoning step, but they require high-quality process supervision
labels and are time-consuming when applied in online reinforcement learning
(RL). To overcome these limitations, we introduce a simple but efficient method
Credit Assignment Policy Optimization (CAPO). Given a reasoning response
rollout from the policy model, CAPO directly leverages an off-the-shelf,
general-purpose LLM as a Generative Process Reward Model (LLM-as-GenPRM) to
generate all step-wise critique by one pass, thereby providing verifiable
token-level rewards to refine the tokens that were originally assigned
identical rule-based rewards. This enables more fine-grained credit assignment
in an effective way. Furthermore, to enhance the accuracy and robustness of
CAPO, we employ voting mechanisms that scale with the number of generated
critiques. Extensive experiments using different backbones like Llama and Qwen
models and in different sizes show that CAPO consistently outperforms
supervised learning-based and RL-based fine-tuning methods across six
challenging mathematical benchmarks and three out-of-domain benchmarks.

### 47. SHAMI-MT: A Syrian Arabic Dialect to Modern Standard Arabic Bidirectional Machine Translation System

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Serry Sibaee, Omer Nacar, Yasser Al-Habashi, Adel Ammar, Wadii Boulila
- **URL**: <http://arxiv.org/abs/2508.02268v1>
- **Submitted**: 2025-08-04 10:21:11
- **Topic Keywords**: rag
- **Reason**: The paper focuses on machine translation between Modern Standard Arabic and the Syrian dialect, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves NLP, the specific application and scope are not aligned with the user's core research themes.

#### Abstract
> The rich linguistic landscape of the Arab world is characterized by a
significant gap between Modern Standard Arabic (MSA), the language of formal
communication, and the diverse regional dialects used in everyday life. This
diglossia presents a formidable challenge for natural language processing,
particularly machine translation. This paper introduces \textbf{SHAMI-MT}, a
bidirectional machine translation system specifically engineered to bridge the
communication gap between MSA and the Syrian dialect. We present two
specialized models, one for MSA-to-Shami and another for Shami-to-MSA
translation, both built upon the state-of-the-art AraT5v2-base-1024
architecture. The models were fine-tuned on the comprehensive Nabra dataset and
rigorously evaluated on unseen data from the MADAR corpus. Our MSA-to-Shami
model achieved an outstanding average quality score of \textbf{4.01 out of 5.0}
when judged by OPENAI model GPT-4.1, demonstrating its ability to produce
translations that are not only accurate but also dialectally authentic. This
work provides a crucial, high-fidelity tool for a previously underserved
language pair, advancing the field of dialectal Arabic translation and offering
significant applications in content localization, cultural heritage, and
intercultural communication.

### 48. I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ziyan Liu, Junwen Li, Kaiwen Li, Tong Ruan, Chao Wang, Xinyan He, Zongyu Wang, Xuezhi Cao, Jingping Liu
- **URL**: <http://arxiv.org/abs/2508.02243v1>
- **Submitted**: 2025-08-04 09:43:54
- **Comment**: 10 pages, 6 figures, accepted by ACMMM 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on multimodal entity linking, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and query understanding. Although it mentions the use of large language models, the context is different from the user's focus on ranking models and user behavior modeling.

#### Abstract
> Multimodal entity linking plays a crucial role in a wide range of
applications. Recent advances in large language model-based methods have become
the dominant paradigm for this task, effectively leveraging both textual and
visual modalities to enhance performance. Despite their success, these methods
still face two challenges, including unnecessary incorporation of image data in
certain scenarios and the reliance only on a one-time extraction of visual
features, which can undermine their effectiveness and accuracy. To address
these challenges, we propose a novel LLM-based framework for the multimodal
entity linking task, called Intra- and Inter-modal Collaborative Reflections.
This framework prioritizes leveraging text information to address the task.
When text alone is insufficient to link the correct entity through intra- and
inter-modality evaluations, it employs a multi-round iterative strategy that
integrates key visual clues from various aspects of the image to support
reasoning and enhance matching accuracy. Extensive experiments on three widely
used public datasets demonstrate that our framework consistently outperforms
current state-of-the-art methods in the task, achieving improvements of 3.2%,
5.1%, and 1.6%, respectively. Our code is available at
https://github.com/ziyan-xiaoyu/I2CR/.

### 49. LeanK: Learnable K Cache Channel Pruning for Efficient Decoding

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yike Zhang, Zhiyuan He, Huiqiang Jiang, Chengruidong Zhang, Yuqing Yang, Jianyong Wang, Lili Qiu
- **URL**: <http://arxiv.org/abs/2508.02215v1>
- **Submitted**: 2025-08-04 09:08:43
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on pruning key-value cache channels for efficient decoding in large language models, which is a topic in Natural Language Processing, but not directly related to the user's core research themes.

#### Abstract
> Large language models (LLMs) enable long-context tasks but face efficiency
challenges due to the growing key-value (KV) cache. We propose LeanK, a
learning-based method that prunes unimportant key (K) cache channels by
leveraging static channel sparsity. With a novel two-stage training process,
LeanK learns channel-wise static mask that could satisfy specific sparsity
ratio and hardware alignment requirement. LeanK reduces GPU memory and
accelerates decoding without sacrificing accuracy. Experiments demonstrate up
to 70% K cache and 16%-18% V cache memory reduction. Custom decoding kernel
enables 1.3x speedup for attention computation. We also provide insights into
model channels and attention heads during long-context inference by analyzing
the learned importance distribution. Our code is available at
https://aka.ms/LeanK.

### 50. Monsoon Uprising in Bangladesh: How Facebook Shaped Collective Identity

- **LLM Score**: 0
- **Keyword Score**: 3
- **Authors**: Md Tasin Abir, Arpita Chowdhury, Ashfia Rahman
- **URL**: <http://arxiv.org/abs/2508.02498v1>
- **Submitted**: 2025-08-04 15:07:38
- **Comment**: 10 pages, 9 figures
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The paper focuses on social media, collective identity, and political mobilization, which are outside your primary areas of interest.

#### Abstract
> This study investigates how Facebook shaped collective identity during the
July 2024 pro-democracy uprising in Bangladesh, known as the Monsoon Uprising.
During government repression, protesters turned to Facebook as a central space
for resistance, where multimodal expressions, images, memes, videos, hashtags,
and satirical posts played an important role in unifying participants. Using a
qualitative approach, this research analyzes visual rhetoric, verbal discourse,
and digital irony to reveal how shared symbols, protest art, and slogans built
a sense of solidarity. Key elements included the symbolic use of red, the
ironic metaphorical use of the term "Razakar", and the widespread sharing of
visuals representing courage, injustice, and resistance. The findings show that
the combination of visual and verbal strategies on Facebook not only mobilized
public sentiment, but also built a strong collective identity that challenged
authoritarian narratives. This study tries to demonstrate how online platforms
can serve as powerful tools for identity construction and political
mobilization in the digital age.

---

