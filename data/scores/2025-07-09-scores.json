[
    {
        "title": "Efficiency-Effectiveness Reranking FLOPs for LLM-based Rerankers",
        "abstract": "Large Language Models (LLMs) have recently been applied to reranking tasks in\ninformation retrieval, achieving strong performance. However, their high\ncomputational demands often hinder practical deployment. Existing studies\nevaluate the efficiency of LLM-based rerankers using proxy metrics such as\nlatency, the number of forward passes, input tokens, and output tokens.\nHowever, these metrics depend on hardware and running-time choices (\\eg\nparallel or not, batch size, etc), and often fail to account for model size,\nmaking it difficult to interpret and obscuring the evaluation of the\nefficiency-effectiveness tradeoff. To address this issue, we propose\nE\\textsuperscript{2}R-FLOPs, for LLM-based rerankers: ranking metrics per\nPetaFLOP (RPP) for relevance per compute and queries per PetaFLOP (QPP) for\nhardware-agnostic throughput. Companied with the new metrics, an interpretable\nFLOPs estimator is built to estimate the FLOPs of an LLM-based reranker even\nwithout running any experiments. Based on the proposed metrics, we conduct\ncomprehensive experiments to evaluate a wide range of LLM-based rerankers with\ndifferent architecture, studying the efficiency-effectiveness trade-off and\nbringing this issue to the attention of the research community.",
        "url": "http://arxiv.org/abs/2507.06223v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06223v1",
        "arxiv_id": "2507.06223v1",
        "authors": [
            "Zhiyuan Peng",
            "Ting-ruen Wei",
            "Tingyu Song",
            "Yilun Zhao",
            "Yi Fang"
        ],
        "submitted": "2025-07-08 17:56:28",
        "source": "arxiv",
        "comment": "under review",
        "score": 19,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on the efficiency and effectiveness of Large Language Models (LLMs) in reranking tasks, proposing new metrics and an estimator to evaluate their performance. While it's related to search technologies and ranking models, it doesn't directly address query understanding, user behavior modeling, or deep semantic understanding, which are core aspects of your research interests."
    },
    {
        "title": "Flippi: End To End GenAI Assistant for E-Commerce",
        "abstract": "The emergence of conversational assistants has fundamentally reshaped user\ninteractions with digital platforms. This paper introduces Flippi-a\ncutting-edge, end-to-end conversational assistant powered by large language\nmodels (LLMs) and tailored for the e-commerce sector. Flippi addresses the\nchallenges posed by the vast and often overwhelming product landscape, enabling\ncustomers to discover products more efficiently through natural language\ndialogue. By accommodating both objective and subjective user requirements,\nFlippi delivers a personalized shopping experience that surpasses traditional\nsearch methods. This paper details how Flippi interprets customer queries to\nprovide precise product information, leveraging advanced NLP techniques such as\nQuery Reformulation, Intent Detection, Retrieval-Augmented Generation (RAG),\nNamed Entity Recognition (NER), and Context Reduction. Flippi's unique\ncapability to identify and present the most attractive offers on an e-commerce\nsite is also explored, demonstrating how it empowers users to make\ncost-effective decisions. Additionally, the paper discusses Flippi's\ncomparative analysis features, which help users make informed choices by\ncontrasting product features, prices, and other relevant attributes. The\nsystem's robust architecture is outlined, emphasizing its adaptability for\nintegration across various e-commerce platforms and the technological choices\nunderpinning its performance and accuracy. Finally, a comprehensive evaluation\nframework is presented, covering performance metrics, user satisfaction, and\nthe impact on customer engagement and conversion rates. By bridging the\nconvenience of online shopping with the personalized assistance traditionally\nfound in physical stores, Flippi sets a new standard for customer satisfaction\nand engagement in the digital marketplace.",
        "url": "http://arxiv.org/abs/2507.05788v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05788v1",
        "arxiv_id": "2507.05788v1",
        "authors": [
            "Anand A. Rajasekar",
            "Praveen Tangarajan",
            "Anjali Nainani",
            "Amogh Batwal",
            "Vinay Rao Dandin",
            "Anusua Trivedi",
            "Ozan Ersoy"
        ],
        "submitted": "2025-07-08 08:50:47",
        "source": "arxiv",
        "comment": "10 pages, 2 figures, 7 tables",
        "score": 16,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'conversion rate' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'shopping' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper's focus on conversational assistants, natural language dialogue, and e-commerce is relevant to your interests in Information Retrieval and Search technologies. The use of advanced NLP techniques such as Query Reformulation, Intent Detection, and Retrieval-Augmented Generation is also aligned with your research themes. However, the paper's primary focus on e-commerce and conversational assistants is not a central match with your broader interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Beyond Retrieval: Ensembling Cross-Encoders and GPT Rerankers with LLMs for Biomedical QA",
        "abstract": "Biomedical semantic question answering rooted in information retrieval can\nplay a crucial role in keeping up to date with vast, rapidly evolving and\never-growing biomedical literature. A robust system can help researchers,\nhealthcare professionals and even layman users access relevant knowledge\ngrounded in evidence. The BioASQ 2025 Task13b Challenge serves as an important\nbenchmark, offering a competitive platform for advancement of this space. This\npaper presents the methodologies and results from our participation in this\nchallenge where we built a Retrieval-Augmented Generation (RAG) system that can\nanswer biomedical questions by retrieving relevant PubMed documents and\nsnippets to generate answers. For the retrieval task, we generated dense\nembeddings from biomedical articles for initial retrieval, and applied an\nensemble of finetuned cross-encoders and large language models (LLMs) for\nre-ranking to identify top relevant documents. Our solution achieved an MAP@10\nof 0.1581, placing 10th on the leaderboard for the retrieval task. For answer\ngeneration, we employed few-shot prompting of instruction-tuned LLMs. Our\nsystem achieved macro-F1 score of 0.95 for yes/no questions (rank 12), Mean\nReciprocal Rank (MRR) of 0.64 for factoid questions (rank 1), mean-F1 score of\n0.63 for list questions (rank 5), and ROUGE-SU4 F1 score of 0.29 for ideal\nanswers (rank 11).",
        "url": "http://arxiv.org/abs/2507.05577v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05577v1",
        "arxiv_id": "2507.05577v1",
        "authors": [
            "Shashank Verma",
            "Fengyi Jiang",
            "Xiangning Xue"
        ],
        "submitted": "2025-07-08 01:25:06",
        "source": "arxiv",
        "comment": "Paper submitted to CLEF 2025 CEUR-WS",
        "score": 15,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper is somewhat related to the user's interests in Information Retrieval (IR) and Search technologies, particularly in the context of biomedical question answering. The use of cross-encoders, LLMs, and reranking models is relevant to the user's focus on query understanding and ranking models. However, the paper's specific focus on biomedical literature and question answering is not directly aligned with the user's broader interests in e-commerce and general information retrieval."
    },
    {
        "title": "RecRankerEval: A Flexible and Extensible Framework for Top-k LLM-based Recommendation",
        "abstract": "A recent Large language model (LLM)-based recommendation model, called\nRecRanker, has demonstrated a superior performance in the top-k recommendation\ntask compared to other models. In particular, RecRanker samples users via\nclustering, generates an initial ranking list using an initial recommendation\nmodel, and fine-tunes an LLM through hybrid instruction tuning to infer user\npreferences. However, the contribution of each core component remains\nunderexplored. In this work, we inspect the reproducibility of RecRanker, and\nstudy the impact and role of its various components. We begin by reproducing\nthe RecRanker pipeline through the implementation of all its key components.\nOur reproduction shows that the pairwise and listwise methods achieve a\nperformance comparable to that reported in the original paper. For the\npointwise method, while we are also able to reproduce the original paper's\nresults, further analysis shows that the performance is abnormally high due to\ndata leakage from the inclusion of ground-truth information in the prompts. To\nenable a fair and comprehensive evaluation of LLM-based top-k recommendations,\nwe propose RecRankerEval, an extensible framework that covers five key\ndimensions: user sampling strategy, initial recommendation model, LLM backbone,\ndataset selection, and instruction tuning method. Using the RecRankerEval\nframework, we show that the original results of RecRanker can be reproduced on\nthe ML-100K and ML-1M datasets, as well as the additional Amazon-Music dataset,\nbut not on BookCrossing due to the lack of timestamp information in the\noriginal RecRanker paper. Furthermore, we demonstrate that RecRanker's\nperformance can be improved by employing alternative user sampling methods,\nstronger initial recommenders, and more capable LLMs.",
        "url": "http://arxiv.org/abs/2507.05880v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05880v1",
        "arxiv_id": "2507.05880v1",
        "authors": [
            "Zeyuan Meng",
            "Zixuan Yi",
            "Iadh Ounis"
        ],
        "submitted": "2025-07-08 11:04:17",
        "source": "arxiv",
        "comment": null,
        "score": 14,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'listwise' (score: +3)",
            "Found 'pointwise' (score: +3)",
            "Found 'pairwise' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on recommender systems, which is a related topic to information retrieval. However, the emphasis is on large language models and their application to recommendation tasks, rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest in information retrieval. The paper's scope is also limited to recommender systems, and does not explore other areas of interest such as natural language processing or data mining."
    },
    {
        "title": "SARA: Selective and Adaptive Retrieval-augmented Generation with Context Compression",
        "abstract": "Retrieval-augmented Generation (RAG) extends large language models (LLMs)\nwith external knowledge but faces key challenges: restricted effective context\nlength and redundancy in retrieved documents. Pure compression-based approaches\nreduce input size but often discard fine-grained details essential for factual\naccuracy. We propose SARA, a unified RAG framework that balances local\nprecision and global knowledge coverage under tight context budgets. SARA\ncombines natural-language text snippets with semantic compression vectors to\njointly enhance context efficiency and answer correctness. It represents\ncontexts at two complementary levels: 1) fine-grained natural-language spans\nthat preserve critical entities and numerical values, and 2) compact,\ninterpretable vectors that summarize high-level semantics. An iterative\nevidence-selection module employs the compression vectors for dynamic reranking\nof contexts. Across 9 datasets and 5 open-source LLMs spanning 3 model families\n(Mistral, Llama, and Gemma), SARA consistently improves answer relevance\n(+17.71), answer correctness (+13.72), and semantic similarity (+15.53),\ndemonstrating the importance of integrating textual and compressed\nrepresentations for robust, context-efficient RAG.",
        "url": "http://arxiv.org/abs/2507.05633v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05633v1",
        "arxiv_id": "2507.05633v1",
        "authors": [
            "Yiqiao Jin",
            "Kartik Sharma",
            "Vineeth Rakesh",
            "Yingtong Dou",
            "Menghai Pan",
            "Mahashweta Das",
            "Srijan Kumar"
        ],
        "submitted": "2025-07-08 03:29:09",
        "source": "arxiv",
        "comment": "20 pages",
        "score": 14,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper proposes a framework for Retrieval-augmented Generation (RAG) that balances local precision and global knowledge coverage. While it's related to information retrieval and natural language processing, the focus is on integrating textual and compressed representations for robust RAG, which is not directly aligned with the user's primary interest in query understanding, ranking models, and user behavior modeling. However, the paper's emphasis on context efficiency and answer correctness may be of interest to the user, especially in areas that require deep semantic understanding."
    },
    {
        "title": "SQLBarber: A System Leveraging Large Language Models to Generate Customized and Realistic SQL Workloads",
        "abstract": "Database research and development often require a large number of SQL queries\nfor benchmarking purposes. However, acquiring real-world SQL queries is\nchallenging due to privacy concerns, and existing SQL generation methods are\nlimited in customization and in satisfying realistic constraints. To address\nthis issue, we present SQLBarber, a system based on Large Language Models\n(LLMs) to generate customized and realistic SQL workloads. SQLBarber (i)\neliminates the need for users to manually craft SQL templates in advance, while\nproviding the flexibility to accept natural language specifications to\nconstrain SQL templates, (ii) scales efficiently to generate large volumes of\nqueries matching any user-defined cost distribution (e.g., cardinality and\nexecution plan cost), and (iii) uses execution statistics from Amazon Redshift\nand Snowflake to derive SQL template specifications and query cost\ndistributions that reflect real-world query characteristics. SQLBarber\nintroduces (i) a declarative interface for users to effortlessly generate\ncustomized SQL templates, (ii) an LLM-powered pipeline augmented with a\nself-correction module that profiles, refines, and prunes SQL templates based\non query costs, and (iii) a Bayesian Optimizer to efficiently explore different\npredicate values and identify a set of queries that satisfy the target cost\ndistribution. We construct and open-source ten benchmarks of varying difficulty\nlevels and target query cost distributions based on real-world statistics from\nSnowflake and Amazon Redshift. Extensive experiments on these benchmarks show\nthat SQLBarber is the only system that can generate customized SQL templates.\nIt reduces query generation time by one to three orders of magnitude, and\nsignificantly improves alignment with the target cost distribution, compared\nwith existing methods.",
        "url": "http://arxiv.org/abs/2507.06192v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06192v1",
        "arxiv_id": "2507.06192v1",
        "authors": [
            "Jiale Lao",
            "Immanuel Trummer"
        ],
        "submitted": "2025-07-08 17:20:34",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a system for generating customized and realistic SQL workloads using Large Language Models, which is related to information retrieval and search technologies. However, the focus is on database research and development, which is not directly aligned with the user's primary research interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is somewhat limited to the user's background in e-commerce and data mining, but it does not explore deep semantic understanding or real-time relevance optimization."
    },
    {
        "title": "Contrastive and Transfer Learning for Effective Audio Fingerprinting through a Real-World Evaluation Protocol",
        "abstract": "Recent advances in song identification leverage deep neural networks to learn\ncompact audio fingerprints directly from raw waveforms. While these methods\nperform well under controlled conditions, their accuracy drops significantly in\nreal-world scenarios where the audio is captured via mobile devices in noisy\nenvironments. In this paper, we introduce a novel evaluation protocol designed\nto better reflect such real-world conditions. We generate three recordings of\nthe same audio, each with increasing levels of noise, captured using a mobile\ndevice's microphone. Our results reveal a substantial performance drop for two\nstate-of-the-art CNN-based models under this protocol, compared to previously\nreported benchmarks. Additionally, we highlight the critical role of the\naugmentation pipeline during training with contrastive loss. By introduction\nlow pass and high pass filters in the augmentation pipeline we significantly\nincrease the performance of both systems in our proposed evaluation.\nFurthermore, we develop a transformer-based model with a tailored projection\nmodule and demonstrate that transferring knowledge from a semantically relevant\ndomain yields a more robust solution. The transformer architecture outperforms\nCNN-based models across all noise levels, and query durations. In low noise\nconditions it achieves 47.99% for 1-sec queries, and 97% for 10-sec queries in\nfinding the correct song, surpassing by 14%, and by 18.5% the second-best\nperforming model, respectively, Under heavy noise levels, we achieve a\ndetection rate 56.5% for 15-second query duration. All experiments are\nconducted on public large-scale dataset of over 100K songs, with queries\nmatched against a database of 56 million vectors.",
        "url": "http://arxiv.org/abs/2507.06070v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06070v1",
        "arxiv_id": "2507.06070v1",
        "authors": [
            "Christos Nikou",
            "Theodoros Giannakopoulos"
        ],
        "submitted": "2025-07-08 15:13:26",
        "source": "arxiv",
        "comment": "International Journal of Music Science, Technology and Art, 15 pages,\n  7 figures",
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on audio fingerprinting, which is not directly related to information retrieval, search technologies, or query understanding. Although it mentions deep neural networks and transfer learning, the context is specific to audio processing and not applicable to the user's research interests."
    },
    {
        "title": "Enhancing the Interpretability of Rule-based Explanations through Information Retrieval",
        "abstract": "The lack of transparency of data-driven Artificial Intelligence techniques\nlimits their interpretability and acceptance into healthcare decision-making\nprocesses. We propose an attribution-based approach to improve the\ninterpretability of Explainable AI-based predictions in the specific context of\narm lymphedema's risk assessment after lymph nodal radiotherapy in breast\ncancer. The proposed method performs a statistical analysis of the attributes\nin the rule-based prediction model using standard metrics from Information\nRetrieval techniques. This analysis computes the relevance of each attribute to\nthe prediction and provides users with interpretable information about the\nimpact of risk factors. The results of a user study that compared the output\ngenerated by the proposed approach with the raw output of the Explainable AI\nmodel suggested higher levels of interpretability and usefulness in the context\nof predicting lymphedema risk.",
        "url": "http://arxiv.org/abs/2507.05976v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05976v1",
        "arxiv_id": "2507.05976v1",
        "authors": [
            "Alessandro Umbrico",
            "Guido Bologna",
            "Luca Coraci",
            "Francesca Fracasso",
            "Silvia Gola",
            "Gabriella Cortellessa"
        ],
        "submitted": "2025-07-08 13:32:50",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores the intersection of Information Retrieval and Explainable AI, which is relevant to your interests in query understanding and ranking models. However, the focus on rule-based explanations and healthcare decision-making processes is somewhat niche and may not directly align with your primary focus on information retrieval in e-commerce and other domains."
    },
    {
        "title": "Semantic Certainty Assessment in Vector Retrieval Systems: A Novel Framework for Embedding Quality Evaluation",
        "abstract": "Vector retrieval systems exhibit significant performance variance across\nqueries due to heterogeneous embedding quality. We propose a lightweight\nframework for predicting retrieval performance at the query level by combining\nquantization robustness and neighborhood density metrics. Our approach is\nmotivated by the observation that high-quality embeddings occupy geometrically\nstable regions in the embedding space and exhibit consistent neighborhood\nstructures. We evaluate our method on 4 standard retrieval datasets, showing\nconsistent improvements of 9.4$\\pm$1.2\\% in Recall@10 over competitive\nbaselines. The framework requires minimal computational overhead (less than 5\\%\nof retrieval time) and enables adaptive retrieval strategies. Our analysis\nreveals systematic patterns in embedding quality across different query types,\nproviding insights for targeted training data augmentation.",
        "url": "http://arxiv.org/abs/2507.05933v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05933v1",
        "arxiv_id": "2507.05933v1",
        "authors": [
            "Y. Du"
        ],
        "submitted": "2025-07-08 12:33:11",
        "source": "arxiv",
        "comment": "7 pages",
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on vector retrieval systems and proposes a framework for evaluating embedding quality, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the paper's primary focus is on evaluating embedding quality rather than query understanding or ranking models, making it only loosely relevant to the user's research interests."
    },
    {
        "title": "Chat-Ghosting: A Comparative Study of Methods for Auto-Completion in Dialog Systems",
        "abstract": "Ghosting, the ability to predict a user's intended text input for inline\nquery auto-completion, is an invaluable feature for modern search engines and\nchat interfaces, greatly enhancing user experience. By suggesting completions\nto incomplete queries (or prefixes), ghosting aids users with slow typing\nspeeds, disabilities, or limited language proficiency. Ghosting is a\nchallenging problem and has become more important with the ubiquitousness of\nchat-based systems like ChatGPT, Copilot, etc. Despite the increasing\nprominence of chat-based systems utilizing ghosting, this challenging problem\nof Chat-Ghosting has received little attention from the NLP/ML research\ncommunity. There is a lack of standardized benchmarks and relative performance\nanalysis of deep learning and non-deep learning methods. We address this\nthrough an open and thorough study of this problem using four publicly\navailable dialog datasets: two human-human (DailyDialog and DSTC7-Ubuntu) and\ntwo human-bot (Open Assistant and ShareGPT). We experiment with various\nexisting query auto-completion methods (using tries), n-gram methods and deep\nlearning methods, with and without dialog context. We also propose a novel\nentropy-based dynamic early stopping strategy. Our analysis finds that\nstatistical n-gram models and tries outperform deep learning based models in\nterms of both model performance and inference efficiency for seen prefixes. For\nunseen queries, neural models like T5 and Phi-2 lead to better results. Adding\nconversational context leads to significant improvements in ghosting quality,\nespecially for Open-Assistant and ShareGPT. We make code and data publicly\navailable",
        "url": "http://arxiv.org/abs/2507.05940v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05940v1",
        "arxiv_id": "2507.05940v1",
        "authors": [
            "Sandeep Mishra",
            "Anubhab Mandal",
            "Bishal Santra",
            "Tushar Abhishek",
            "Pawan Goyal",
            "Manish Gupta"
        ],
        "submitted": "2025-07-08 12:38:41",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores query auto-completion in dialog systems, which is related to query understanding and ranking models in Information Retrieval. However, the focus is on chat-based systems and dialog context, which is not directly aligned with the user's primary research interests in e-commerce and real-time relevance optimization."
    },
    {
        "title": "DRAGON: Dynamic RAG Benchmark On News",
        "abstract": "Retrieval-Augmented Generation (RAG) is a widely adopted approach for\nimproving the factuality of large language models (LLMs) by incorporating\nexternal knowledge at inference time. Although there exist multiple RAG\nbenchmarks for English, evaluation resources for other languages, including\nRussian, remain scarce and static, failing to capture the dynamic nature of\nreal-world deployments.\n  In this work, we present DRAGON (Dynamic RAG Benchmark On News), the first\ndynamic benchmark for evaluating RAG systems in Russian on a changing news\ncorpora. DRAGON is built upon a regularly updated corpus of Russian news and\npublic documents and supports comprehensive evaluation of both the retriever\nand generator components. Question generation is performed automatically with\nthe use of Knowledge Graph constructed from the corpus and enables the\nextraction of four core question types aligned with distinct subgraph patterns.\nWe release a complete evaluation framework comprising the pipeline for\nautomatic question generation, evaluation scripts, which are potentially\nreusable for other languages and multilingual settings, and benchmark data. We\nalso launch a public leaderboard to encourage community participation and\ncomparison.",
        "url": "http://arxiv.org/abs/2507.05713v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05713v1",
        "arxiv_id": "2507.05713v1",
        "authors": [
            "Fedor Chernogorskii",
            "Sergei Averkiev",
            "Liliya Kudraleeva",
            "Zaven Martirosian",
            "Maria Tikhonova",
            "Valentin Malykh",
            "Alena Fenogenova"
        ],
        "submitted": "2025-07-08 06:52:43",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a benchmark for Retrieval-Augmented Generation (RAG) in Russian, focusing on the dynamic nature of real-world deployments. While it touches on information retrieval and natural language processing, the primary focus is on language models and generation, which is not directly related to the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "GPTKB v1.5: A Massive Knowledge Base for Exploring Factual LLM Knowledge",
        "abstract": "Language models are powerful tools, yet their factual knowledge is still\npoorly understood, and inaccessible to ad-hoc browsing and scalable statistical\nanalysis. This demonstration introduces GPTKB v1.5, a densely interlinked\n100-million-triple knowledge base (KB) built for $14,000 from GPT-4.1, using\nthe GPTKB methodology for massive-recursive LLM knowledge materialization (Hu\net al., ACL 2025). The demonstration experience focuses on three use cases: (1)\nlink-traversal-based LLM knowledge exploration, (2) SPARQL-based structured LLM\nknowledge querying, (3) comparative exploration of the strengths and weaknesses\nof LLM knowledge. Massive-recursive LLM knowledge materialization is a\ngroundbreaking opportunity both for the research area of systematic analysis of\nLLM knowledge, as well as for automated KB construction. The GPTKB demonstrator\nis accessible at https://gptkb.org.",
        "url": "http://arxiv.org/abs/2507.05740v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05740v1",
        "arxiv_id": "2507.05740v1",
        "authors": [
            "Yujia Hu",
            "Tuan-Phong Nguyen",
            "Shrestha Ghosh",
            "Moritz Müller",
            "Simon Razniewski"
        ],
        "submitted": "2025-07-08 07:37:12",
        "source": "arxiv",
        "comment": "7 pages, 6 figures, 1 table",
        "score": 6,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'search' (score: +1)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on building a massive knowledge base for exploring factual LLM knowledge, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions LLMs, the context is different from the user's interests in IR and NLP."
    },
    {
        "title": "KERAG_R: Knowledge-Enhanced Retrieval-Augmented Generation for Recommendation",
        "abstract": "Large Language Models (LLMs) have shown strong potential in recommender\nsystems due to their contextual learning and generalisation capabilities.\nExisting LLM-based recommendation approaches typically formulate the\nrecommendation task using specialised prompts designed to leverage their\ncontextual abilities, and aligning their outputs closely with human preferences\nto yield an improved recommendation performance. However, the use of LLMs for\nrecommendation tasks is limited by the absence of domain-specific knowledge.\nThis lack of relevant relational knowledge about the items to be recommended in\nthe LLM's pre-training corpus can lead to inaccuracies or hallucinations,\nresulting in incorrect or misleading recommendations. Moreover, directly using\ninformation from the knowledge graph introduces redundant and noisy\ninformation, which can affect the LLM's reasoning process or exceed its input\ncontext length, thereby reducing the performance of LLM-based recommendations.\nTo address the lack of domain-specific knowledge, we propose a novel model\ncalled Knowledge-Enhanced Retrieval-Augmented Generation for Recommendation\n(KERAG_R). Specifically, we leverage a graph retrieval-augmented generation\n(GraphRAG) component to integrate additional information from a knowledge graph\n(KG) into instructions, enabling the LLM to collaboratively exploit\nrecommendation signals from both text-based user interactions and the knowledge\ngraph to better estimate the users' preferences in a recommendation context. In\nparticular, we perform graph RAG by pre-training a graph attention network\n(GAT) to select the most relevant triple for the target users for the used LLM,\nthereby enhancing the LLM while reducing redundant and noisy information. Our\nextensive experiments on three public datasets show that our proposed KERAG_R\nmodel significantly outperforms ten existing state-of-the-art recommendation\nmethods.",
        "url": "http://arxiv.org/abs/2507.05863v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05863v1",
        "arxiv_id": "2507.05863v1",
        "authors": [
            "Zeyuan Meng",
            "Zixuan Yi",
            "Iadh Ounis"
        ],
        "submitted": "2025-07-08 10:44:27",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the use of Large Language Models (LLMs) in recommender systems, which is somewhat related to my interests in Information Retrieval and Search technologies. However, the focus on recommendation systems and the lack of deep semantic understanding and real-time relevance optimization make it less relevant to my primary research themes."
    },
    {
        "title": "Vers un cadre ontologique pour la gestion des comp{é}tences : {à} des fins de formation, de recrutement, de m{é}tier, ou de recherches associ{é}es",
        "abstract": "The rapid transformation of the labor market, driven by technological\nadvancements and the digital economy, requires continuous competence\ndevelopment and constant adaptation. In this context, traditional competence\nmanagement systems lack interoperability, adaptability, and semantic\nunderstanding, making it difficult to align individual competencies with labor\nmarket needs and training programs. This paper proposes an ontology-based\nframework for competence management, enabling a structured representation of\ncompetencies, occupations, and training programs. By leveraging ontological\nmodels and semantic reasoning, this framework aims to enhance the automation of\ncompetence-to-job matching, the personalization of learning recommendations,\nand career planning. This study discusses the design, implementation, and\npotential applications of the framework, focusing on competence training\nprograms, job searching, and finding competent individuals.",
        "url": "http://arxiv.org/abs/2507.05767v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05767v1",
        "arxiv_id": "2507.05767v1",
        "authors": [
            "Ngoc Luyen Le",
            "Marie-Hélène Abel",
            "Bertrand Laforge"
        ],
        "submitted": "2025-07-08 08:13:30",
        "source": "arxiv",
        "comment": "in French language. 36es Journ{\\'e}es francophones d'Ing{\\'e}nierie\n  des Connaissances (IC 2025) @ Plate-Forme Intelligence Artificielle (PFIA\n  2025), Jul 2025, Dijon, France",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'personalization' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on competence management and ontology-based frameworks, which is unrelated to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions semantic understanding and automation, the context is different and not directly applicable to the user's areas of focus."
    },
    {
        "title": "When Transformers Meet Recommenders: Integrating Self-Attentive Sequential Recommendation with Fine-Tuned LLMs",
        "abstract": "Self-Attentive Sequential Recommendation (SASRec) effectively captures\nlong-term user preferences by applying attention mechanisms to historical\ninteractions. Concurrently, the rise of Large Language Models (LLMs) has\nmotivated research into LLM-based recommendation, which leverages their\npowerful generalization and language understanding capabilities. However, LLMs\noften lack the domain-specific knowledge and collaborative signals essential\nfor high-quality recommendations when relying solely on textual prompts. To\naddress this limitation, this study proposes SASRecLLM, a novel framework that\nintegrates SASRec as a collaborative encoder with an LLM fine-tuned using\nLow-Rank Adaptation (LoRA). The components are connected via a mapping layer to\nalign their dimensional spaces, and three targeted training strategies are\ndesigned to optimize the hybrid architecture. Extensive experiments on multiple\ndatasets demonstrate that SASRecLLM achieves robust and consistent improvements\nover strong baselines in both cold-start and warm-start scenarios. This work\nadvances the field of LLM-based recommendation by presenting a modular and\neffective paradigm for fusing structured collaborative filtering with the\nsemantic power of fine-tuned LLMs. The implementation is available on GitHub:\nhttps://github.com/kechenkristin/RecLLM",
        "url": "http://arxiv.org/abs/2507.05733v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05733v1",
        "arxiv_id": "2507.05733v1",
        "authors": [
            "Kechen Liu"
        ],
        "submitted": "2025-07-08 07:26:55",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores the integration of self-attentive sequential recommendation with fine-tuned large language models, which is related to query understanding and ranking models in information retrieval. However, the focus on recommender systems and language models is not directly aligned with the user's primary interest in information retrieval, especially in areas that require deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "HIRAG: Hierarchical-Thought Instruction-Tuning Retrieval-Augmented Generation",
        "abstract": "Retrieval-augmented generation (RAG) has become a fundamental paradigm for\naddressing the challenges faced by large language models in handling real-time\ninformation and domain-specific problems. Traditional RAG systems primarily\nrely on the in-context learning (ICL) capabilities of the large language model\nitself. Still, in-depth research on the specific capabilities needed by the RAG\ngeneration model is lacking, leading to challenges with inconsistent document\nquality and retrieval system imperfections. Even the limited studies that\nfine-tune RAG generative models often \\textit{lack a granular focus on RAG\ntask} or \\textit{a deeper utilization of chain-of-thought processes}. To\naddress this, we propose that RAG models should possess three progressively\nhierarchical abilities (1) Filtering: the ability to select relevant\ninformation; (2) Combination: the ability to combine semantic information\nacross paragraphs; and (3) RAG-specific reasoning: the ability to further\nprocess external knowledge using internal knowledge. Thus, we introduce our new\nRAG instruction fine-tuning method, Hierarchical-Thought Instruction-Tuning\nRetrieval-Augmented Generation (HIRAG) incorporates a \"think before answering\"\nstrategy. This method enhances the model's open-book examination capability by\nutilizing multi-level progressive chain-of-thought. Experiments show that the\nHIRAG training strategy significantly improves the model's performance on\ndatasets such as RGB, PopQA, MuSiQue, HotpotQA, and PubmedQA.",
        "url": "http://arxiv.org/abs/2507.05714v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05714v1",
        "arxiv_id": "2507.05714v1",
        "authors": [
            "YiHan Jiao",
            "ZheHao Tan",
            "Dan Yang",
            "DuoLin Sun",
            "Jie Feng",
            "Jian Wang",
            "Peng Wei"
        ],
        "submitted": "2025-07-08 06:53:28",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a new method for retrieval-augmented generation, focusing on hierarchical thought processes and instruction tuning. While it touches on retrieval and generation, the primary focus is on language models and their capabilities, rather than information retrieval or search technologies. The paper's relevance to the user's interests is limited, but it may be of interest to those exploring the intersection of NLP and IR."
    },
    {
        "title": "Enhancing Test-Time Scaling of Large Language Models with Hierarchical Retrieval-Augmented MCTS",
        "abstract": "Test-time scaling has emerged as a promising paradigm in language modeling,\nleveraging additional computational resources at inference time to enhance\nmodel performance. In this work, we introduce R2-LLMs, a novel and versatile\nhierarchical retrieval-augmented reasoning framework designed to improve\ntest-time scaling in large language models (LLMs) without requiring\ndistillation from more advanced models to obtain chain-of-thought (CoT)\ntraining data. R2-LLMs enhances inference-time generalization by integrating\ndual-level retrieval-based in-context learning: (1) At the coarse level, our\napproach extracts abstract templates from complex reasoning problems and\nretrieves similar problem-answer pairs to facilitate high-level in-context\nlearning; (2) At the fine level, during Monte Carlo Tree Search (MCTS), R2-LLMs\nefficiently retrieves analogous intermediate solution steps from reference\nmathematical problem datasets, refining step-wise reasoning with the aid of a\nprocess reward model (PRM) for scoring. R2-LLMs is a robust hierarchical\nreasoning-augmentation method that enhances in-context-level reasoning while\nseamlessly integrating with step-level tree search methods. Utilizing PRM, it\nrefines both candidate generation and decision-making for improved reasoning\naccuracy. Empirical evaluations on the MATH500, GSM8K, and OlympiadBench-TO\ndatasets achieve substantial relative improvement with an increase of up to 16%\nusing LLaMA-3.1-8B compared to the baselines, showcasing the effectiveness of\nour approach in complex reasoning tasks.",
        "url": "http://arxiv.org/abs/2507.05557v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05557v1",
        "arxiv_id": "2507.05557v1",
        "authors": [
            "Alex ZH Dou",
            "Zhongwei Wan",
            "Dongfei Cui",
            "Xin Wang",
            "Jing Xiong",
            "Haokun Lin",
            "Chaofan Tao",
            "Shen Yan",
            "Mi Zhang"
        ],
        "submitted": "2025-07-08 00:41:12",
        "source": "arxiv",
        "comment": "Technical Report",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on large language models and hierarchical retrieval-augmented reasoning, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions retrieval, it is not in the context of search or IR, and the paper's primary focus is on language modeling and complex reasoning tasks."
    },
    {
        "title": "DS@GT at CheckThat! 2025: Evaluating Context and Tokenization Strategies for Numerical Fact Verification",
        "abstract": "Numerical claims, statements involving quantities, comparisons, and temporal\nreferences, pose unique challenges for automated fact-checking systems. In this\nstudy, we evaluate modeling strategies for veracity prediction of such claims\nusing the QuanTemp dataset and building our own evidence retrieval pipeline. We\ninvestigate three key factors: (1) the impact of more evidences with longer\ninput context windows using ModernBERT, (2) the effect of right-to-left (R2L)\ntokenization, and (3) their combined influence on classification performance.\nContrary to prior findings in arithmetic reasoning tasks, R2L tokenization does\nnot boost natural language inference (NLI) of numerical tasks. A longer context\nwindow does also not enhance veracity performance either, highlighting evidence\nquality as the dominant bottleneck. Our best-performing system achieves\ncompetitive macro-average F1 score of 0.57 and places us among the Top-4\nsubmissions in Task 3 of CheckThat! 2025. Our code is available at\nhttps://github.com/dsgt-arc/checkthat-2025-numerical.",
        "url": "http://arxiv.org/abs/2507.06195v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06195v1",
        "arxiv_id": "2507.06195v1",
        "authors": [
            "Maximilian Heil",
            "Aleksandar Pramov"
        ],
        "submitted": "2025-07-08 17:22:22",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on numerical fact verification, which is a specific sub-problem within Information Retrieval. While it touches on some relevant topics like tokenization and evidence retrieval, the primary focus is on natural language inference and classification, which is not directly related to query understanding, ranking models, or user behavior modeling. The paper's relevance to the user's interests is somewhat limited."
    },
    {
        "title": "Unconditional Diffusion for Generative Sequential Recommendation",
        "abstract": "Diffusion models, known for their generative ability to simulate data\ncreation through noise-adding and denoising processes, have emerged as a\npromising approach for building generative recommenders. To incorporate user\nhistory for personalization, existing methods typically adopt a conditional\ndiffusion framework, where the reverse denoising process of reconstructing\nitems from noise is modified to be conditioned on the user history. However,\nthis design may fail to fully utilize historical information, as it gets\ndistracted by the need to model the \"item $\\leftrightarrow$ noise\" translation.\nThis motivates us to reformulate the diffusion process for sequential\nrecommendation in an unconditional manner, treating user history (instead of\nnoise) as the endpoint of the forward diffusion process (i.e., the starting\npoint of the reverse process), rather than as a conditional input. This\nformulation allows for exclusive focus on modeling the \"item $\\leftrightarrow$\nhistory\" translation. To this end, we introduce Brownian Bridge Diffusion\nRecommendation (BBDRec). By leveraging a Brownian bridge process, BBDRec\nenforces a structured noise addition and denoising mechanism, ensuring that the\ntrajectories are constrained towards a specific endpoint -- user history,\nrather than noise. Extensive experiments demonstrate BBDRec's effectiveness in\nenhancing sequential recommendation performance. The source code is available\nat https://github.com/baiyimeng/BBDRec.",
        "url": "http://arxiv.org/abs/2507.06121v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06121v1",
        "arxiv_id": "2507.06121v1",
        "authors": [
            "Yimeng Bai",
            "Yang Zhang",
            "Sihao Ding",
            "Shaohui Ruan",
            "Han Yao",
            "Danhui Guan",
            "Fuli Feng",
            "Tat-Seng Chua"
        ],
        "submitted": "2025-07-08 16:05:18",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on generative sequential recommendation using diffusion models, which is not directly related to information retrieval, query understanding, or ranking models. While it touches on user behavior modeling, it is not in the context of search or e-commerce, and the paper's primary focus is on recommender systems rather than information retrieval."
    },
    {
        "title": "The bitter lesson of misuse detection",
        "abstract": "Prior work on jailbreak detection has established the importance of\nadversarial robustness for LLMs but has largely focused on the model ability to\nresist adversarial inputs and to output safe content, rather than the\neffectiveness of external supervision systems. The only public and independent\nbenchmark of these guardrails to date evaluates a narrow set of supervisors on\nlimited scenarios. Consequently, no comprehensive public benchmark yet verifies\nhow well supervision systems from the market perform under realistic, diverse\nattacks. To address this, we introduce BELLS, a Benchmark for the Evaluation of\nLLM Supervision Systems. The framework is two dimensional: harm severity\n(benign, borderline, harmful) and adversarial sophistication (direct vs.\njailbreak) and provides a rich dataset covering 3 jailbreak families and 11\nharm categories. Our evaluations reveal drastic limitations of specialized\nsupervision systems. While they recognize some known jailbreak patterns, their\nsemantic understanding and generalization capabilities are very limited,\nsometimes with detection rates close to zero when asking a harmful question\ndirectly or with a new jailbreak technique such as base64 encoding. Simply\nasking generalist LLMs if the user question is \"harmful or not\" largely\noutperforms these supervisors from the market according to our BELLS score. But\nfrontier LLMs still suffer from metacognitive incoherence, often responding to\nqueries they correctly identify as harmful (up to 30 percent for Claude 3.7 and\ngreater than 50 percent for Mistral Large). These results suggest that simple\nscaffolding could significantly improve misuse detection robustness, but more\nresearch is needed to assess the tradeoffs of such techniques. Our results\nsupport the \"bitter lesson\" of misuse detection: general capabilities of LLMs\nare necessary to detect a diverse array of misuses and jailbreaks.",
        "url": "http://arxiv.org/abs/2507.06282v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06282v1",
        "arxiv_id": "2507.06282v1",
        "authors": [
            "Hadrien Mariaccia",
            "Charbel-Raphaël Segerie",
            "Diego Dorn"
        ],
        "submitted": "2025-07-08 15:21:17",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on language models and misuse detection, which is not a core area of interest. While the paper touches on the concept of semantic understanding, it is not applied in the context of search or retrieval."
    },
    {
        "title": "Towards a Principled Evaluation of Knowledge Editors",
        "abstract": "Model editing has been gaining increasing attention over the past few years.\nFor Knowledge Editing in particular, more challenging evaluation datasets have\nrecently been released. These datasets use different methodologies to score the\nsuccess of editors. Yet, it remains under-explored how robust these\nmethodologies are and whether they unfairly favor some editors. Moreover, the\ndisruptive impact of these editors on overall model capabilities remains a\nconstant blind spot.\n  We address both of these problems and show that choosing different metrics\nand evaluation methodologies as well as different edit batch sizes can lead to\na different ranking of knowledge editors. Crucially we demonstrate this effect\nalso on general language understanding tasks evaluated alongside the knowledge\nediting tasks. Further we include a manual assessment of the string matching\nbased evaluation method for knowledge editing that is favored by recently\nreleased datasets, revealing a tendency to produce false positive matches.",
        "url": "http://arxiv.org/abs/2507.05937v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05937v1",
        "arxiv_id": "2507.05937v1",
        "authors": [
            "Sebastian Pohl",
            "Max Ploner",
            "Alan Akbik"
        ],
        "submitted": "2025-07-08 12:37:54",
        "source": "arxiv",
        "comment": "Accepted at L2M2 workshop at ACL 2025",
        "score": 4,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on knowledge editing, a topic outside the scope of information retrieval and search technologies. While it touches on evaluation methodologies, it does not address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's relevance to the user's research is limited."
    },
    {
        "title": "How to Evaluate Automatic Speech Recognition: Comparing Different Performance and Bias Measures",
        "abstract": "There is increasingly more evidence that automatic speech recognition (ASR)\nsystems are biased against different speakers and speaker groups, e.g., due to\ngender, age, or accent. Research on bias in ASR has so far primarily focused on\ndetecting and quantifying bias, and developing mitigation approaches. Despite\nthis progress, the open question is how to measure the performance and bias of\na system. In this study, we compare different performance and bias measures,\nfrom literature and proposed, to evaluate state-of-the-art end-to-end ASR\nsystems for Dutch. Our experiments use several bias mitigation strategies to\naddress bias against different speaker groups. The findings reveal that\naveraged error rates, a standard in ASR research, alone is not sufficient and\nshould be supplemented by other measures. The paper ends with recommendations\nfor reporting ASR performance and bias to better represent a system's\nperformance for diverse speaker groups, and overall system bias.",
        "url": "http://arxiv.org/abs/2507.05885v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05885v1",
        "arxiv_id": "2507.05885v1",
        "authors": [
            "Tanvina Patel",
            "Wiebke Hutiri",
            "Aaron Yi Ding",
            "Odette Scharenborg"
        ],
        "submitted": "2025-07-08 11:17:13",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on automatic speech recognition (ASR) and bias measurement, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's abstract does not mention query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user."
    },
    {
        "title": "On the Costs and Benefits of Learned Indexing for Dynamic High-Dimensional Data: Extended Version",
        "abstract": "One of the main challenges within the growing research area of learned\nindexing is the lack of adaptability to dynamically expanding datasets. This\npaper explores the dynamization of a static learned index for complex data\nthrough operations such as node splitting and broadening, enabling efficient\nadaptation to new data. Furthermore, we evaluate the trade-offs between static\nand dynamic approaches by introducing an amortized cost model to assess query\nperformance in tandem with the build costs of the index structure, enabling\nexperimental determination of when a dynamic learned index outperforms its\nstatic counterpart. We apply the dynamization method to a static learned index\nand demonstrate that its superior scaling quickly surpasses the static\nimplementation in terms of overall costs as the database grows. This is an\nextended version of the paper presented at DAWAK 2025.",
        "url": "http://arxiv.org/abs/2507.05865v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05865v1",
        "arxiv_id": "2507.05865v1",
        "authors": [
            "Terézia Slanináková",
            "Jaroslav Olha",
            "David Procházka",
            "Matej Antol",
            "Vlastislav Dohnal"
        ],
        "submitted": "2025-07-08 10:47:03",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on learned indexing for dynamic high-dimensional data, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on query performance, the context is different from the user's primary interests in IR and NLP."
    },
    {
        "title": "PhoniTale: Phonologically Grounded Mnemonic Generation for Typologically Distant Language Pairs",
        "abstract": "Vocabulary acquisition poses a significant challenge for second-language (L2)\nlearners, especially when learning typologically distant languages such as\nEnglish and Korean, where phonological and structural mismatches complicate\nvocabulary learning. Recently, large language models (LLMs) have been used to\ngenerate keyword mnemonics by leveraging similar keywords from a learner's\nfirst language (L1) to aid in acquiring L2 vocabulary. However, most of this\nresearch has focused on native English speakers learning other languages,\nrather than the reverse. In this paper, we present PhoniTale, a novel\ncross-lingual mnemonic generation system that retrieves L1 keyword sequence\nbased on phonological similarity and uses LLMs to generate mnemonics. We\nevaluate PhoniTale using both automated metrics and human evaluations,\ncomparing its output to mnemonics created by humans and by previous automated\napproaches. To assess practical effectiveness, we also conduct a short-term\nrecall test measuring mnemonic helpfulness. Our findings show that PhoniTale\nperforms comparably to human-authored mnemonics. We also highlight key areas\nfor future improvement in mnemonic quality and methodology.",
        "url": "http://arxiv.org/abs/2507.05444v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05444v1",
        "arxiv_id": "2507.05444v1",
        "authors": [
            "Sana Kang",
            "Myeongseok Gwon",
            "Su Young Kwon",
            "Jaewook Lee",
            "Andrew Lan",
            "Bhiksha Raj",
            "Rita Singh"
        ],
        "submitted": "2025-07-07 19:50:12",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)",
            "Found 'korea' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on vocabulary acquisition for second-language learners, using large language models to generate mnemonic devices. While it involves natural language processing, the topic is not directly related to information retrieval, search technologies, or query understanding, which are the user's primary research interests."
    },
    {
        "title": "Controlling What You Share: Assessing Language Model Adherence to Privacy Preferences",
        "abstract": "Large language models (LLMs) are primarily accessed via commercial APIs, but\nthis often requires users to expose their data to service providers. In this\npaper, we explore how users can stay in control of their data by using privacy\nprofiles: simple natural language instructions that say what should and should\nnot be revealed. We build a framework where a local model uses these\ninstructions to rewrite queries, only hiding details deemed sensitive by the\nuser, before sending them to an external model, thus balancing privacy with\nperformance. To support this research, we introduce PEEP, a multilingual\ndataset of real user queries annotated to mark private content and paired with\nsynthetic privacy profiles. Our experiments with lightweight LLMs show they can\nfollow these instructions to some extent, but also face consistent challenges,\nhighlighting the need for models that better understand and comply with\nuser-defined privacy preferences.",
        "url": "http://arxiv.org/abs/2507.05391v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05391v1",
        "arxiv_id": "2507.05391v1",
        "authors": [
            "Guillem Ramírez",
            "Alexandra Birch",
            "Ivan Titov"
        ],
        "submitted": "2025-07-07 18:22:55",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the intersection of natural language processing and privacy, which is related to my interests in NLP and information retrieval. However, the focus on language model adherence to privacy preferences is not directly aligned with my primary research themes, such as query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "LoRA-Augmented Generation (LAG) for Knowledge-Intensive Language Tasks",
        "abstract": "The proliferation of fine-tuned language model experts for specific tasks and\ndomains signals the need for efficient selection and combination methods. We\npropose LoRA-Augmented Generation (LAG) for leveraging large libraries of\nknowledge and task-specific LoRA adapters. LAG requires no additional training\nor access to data, and efficiently filters, retrieves, and applies experts on a\nper-token and layer basis. We evaluate LAG on various knowledge-intensive\ntasks, achieving superior performance over existing data-free methods. We\nexplore scenarios where additional data is available, demonstrating LAG's\ncompatibility with alternative solutions such as retrieval-augmented generation\n(RAG).",
        "url": "http://arxiv.org/abs/2507.05346v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05346v1",
        "arxiv_id": "2507.05346v1",
        "authors": [
            "William Fleshman",
            "Benjamin Van Durme"
        ],
        "submitted": "2025-07-07 18:00:01",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a method for selecting and combining fine-tuned language model experts, which is related to query understanding and ranking models in Information Retrieval. However, the focus is on language tasks and knowledge-intensive applications, which is not directly aligned with the user's primary interest in search technologies and user behavior modeling."
    },
    {
        "title": "Nyay-Darpan: Enhancing Decision Making Through Summarization and Case Retrieval for Consumer Law in India",
        "abstract": "AI-based judicial assistance and case prediction have been extensively\nstudied in criminal and civil domains, but remain largely unexplored in\nconsumer law, especially in India. In this paper, we present Nyay-Darpan, a\nnovel two-in-one framework that (i) summarizes consumer case files and (ii)\nretrieves similar case judgements to aid decision-making in consumer dispute\nresolution. Our methodology not only addresses the gap in consumer law AI tools\nbut also introduces an innovative approach to evaluate the quality of the\nsummary. The term 'Nyay-Darpan' translates into 'Mirror of Justice',\nsymbolizing the ability of our tool to reflect the core of consumer disputes\nthrough precise summarization and intelligent case retrieval. Our system\nachieves over 75 percent accuracy in similar case prediction and approximately\n70 percent accuracy across material summary evaluation metrics, demonstrating\nits practical effectiveness. We will publicly release the Nyay-Darpan framework\nand dataset to promote reproducibility and facilitate further research in this\nunderexplored yet impactful domain.",
        "url": "http://arxiv.org/abs/2507.06090v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06090v1",
        "arxiv_id": "2507.06090v1",
        "authors": [
            "Swapnil Bhattacharyya",
            "Shrey Ganatra",
            "Harshvivek Kashid",
            "Spandan Anaokar",
            "Shruti Nair",
            "Reshma Sekhar",
            "Siddharth Manohar",
            "Rahul Hemrajani",
            "Pushpak Bhattacharyya"
        ],
        "submitted": "2025-07-08 15:30:49",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on a specific domain (consumer law in India) and uses AI-based techniques for summarization and case retrieval, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on judicial assistance and case prediction is also not aligned with the user's primary focus on real-time relevance optimization and deep semantic understanding."
    },
    {
        "title": "Hierarchical Interaction Summarization and Contrastive Prompting for Explainable Recommendations",
        "abstract": "Explainable recommendations, which use the information of user and item with\ninteraction to generate a explanation for why the user would interact with the\nitem, are crucial for improving user trust and decision transparency to the\nrecommender system. Existing methods primarily rely on encoding features of\nusers and items to embeddings, which often leads to information loss due to\ndimensionality reduction, sparse interactions, and so on. With the advancements\nof large language models (LLMs) in language comprehension, some methods use\nembeddings as LLM inputs for explanation generation. However, since embeddings\nlack inherent semantics, LLMs must adjust or extend their parameters to\ninterpret them, a process that inevitably incurs information loss. To address\nthis issue, we propose a novel approach combining profile generation via\nhierarchical interaction summarization (PGHIS), which leverages a pretrained\nLLM to hierarchically summarize user-item interactions, generating structured\ntextual profiles as explicit representations of user and item characteristics.\nAdditionally, we propose contrastive prompting for explanation generation\n(CPEG) which employs contrastive learning to guide another reasoning language\nmodels in producing high-quality ground truth recommendation explanations.\nFinally, we use the textual profiles of user and item as input and high-quality\nexplanation as output to fine-tune a LLM for generating explanations.\nExperimental results on multiple datasets demonstrate that our approach\noutperforms existing state-of-the-art methods, achieving a great improvement on\nmetrics about explainability (e.g., 5% on GPTScore) and text quality.\nFurthermore, our generated ground truth explanations achieve a significantly\nhigher win rate compared to user-written reviews and those produced by other\nmethods, demonstrating the effectiveness of CPEG in generating high-quality\nground truths.",
        "url": "http://arxiv.org/abs/2507.06044v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06044v1",
        "arxiv_id": "2507.06044v1",
        "authors": [
            "Yibin Liu",
            "Ang Li",
            "Shijian Li"
        ],
        "submitted": "2025-07-08 14:45:47",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on explainable recommendations, which is somewhat related to information retrieval, but the primary focus is on recommender systems rather than search technologies. The use of large language models and contrastive prompting is interesting, but the lack of direct relevance to query understanding, ranking models, and user behavior modeling limits the paper's alignment with the user's core research themes."
    },
    {
        "title": "Development and Evaluation of HopeBot: an LLM-based chatbot for structured and interactive PHQ-9 depression screening",
        "abstract": "Static tools like the Patient Health Questionnaire-9 (PHQ-9) effectively\nscreen depression but lack interactivity and adaptability. We developed\nHopeBot, a chatbot powered by a large language model (LLM) that administers the\nPHQ-9 using retrieval-augmented generation and real-time clarification. In a\nwithin-subject study, 132 adults in the United Kingdom and China completed both\nself-administered and chatbot versions. Scores demonstrated strong agreement\n(ICC = 0.91; 45% identical). Among 75 participants providing comparative\nfeedback, 71% reported greater trust in the chatbot, highlighting clearer\nstructure, interpretive guidance, and a supportive tone. Mean ratings (0-10)\nwere 8.4 for comfort, 7.7 for voice clarity, 7.6 for handling sensitive topics,\nand 7.4 for recommendation helpfulness; the latter varied significantly by\nemployment status and prior mental-health service use (p < 0.05). Overall,\n87.1% expressed willingness to reuse or recommend HopeBot. These findings\ndemonstrate voice-based LLM chatbots can feasibly serve as scalable, low-burden\nadjuncts for routine depression screening.",
        "url": "http://arxiv.org/abs/2507.05984v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05984v1",
        "arxiv_id": "2507.05984v1",
        "authors": [
            "Zhijun Guo",
            "Alvina Lai",
            "Julia Ive",
            "Alexandru Petcu",
            "Yutong Wang",
            "Luyuan Qi",
            "Johan H Thygesen",
            "Kezhi Li"
        ],
        "submitted": "2025-07-08 13:41:22",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on developing a chatbot for depression screening, using a large language model and retrieval-augmented generation. While it mentions real-time clarification, it does not relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval and Search technologies."
    },
    {
        "title": "From ID-based to ID-free: Rethinking ID Effectiveness in Multimodal Collaborative Filtering Recommendation",
        "abstract": "Most existing multimodal collaborative filtering recommendation (MCFRec)\nmethods rely heavily on ID features and multimodal content to enhance\nrecommendation performance. However, this paper reveals that ID features are\neffective but have limited benefits in multimodal collaborative filtering\nrecommendation. Therefore, this paper systematically deconstruct the pros and\ncons of ID features: (i) they provide initial embedding but lack semantic\nrichness, (ii) they provide a unique identifier for each user and item but\nhinder generalization to untrained data, and (iii) they assist in aligning and\nfusing multimodal features but may lead to representation shift. Based on these\ninsights, this paper proposes IDFREE, an ID-free multimodal collaborative\nFiltering REcommEndation baseline. IDFREE replaces ID features with multimodal\nfeatures and positional encodings to generate semantically meaningful ID-free\nembeddings. For ID-free multimodal collaborative filtering, it further proposes\nan adaptive similarity graph module to construct dynamic user-user and\nitem-item graphs based on multimodal features. Then, an augmented user-item\ngraph encoder is proposed to construct more effective user and item encoding.\nFinally, IDFREE achieves inter-multimodal alignment based on the contrastive\nlearning and uses Softmax loss as recommendation loss. Basic experiments on\nthree public datasets demonstrate that IDFREE outperforms existing ID-based\nMCFRec methods, achieving an average performance gain of 72.24% across standard\nmetrics (Recall@5, 10, 20, 50 and NDCG@5, 10, 20, 50). Exploratory and extended\nexperiments further validate our findings on the limitations of ID features in\nMCFRec. The code is released at https://github.com/G-H-Li/IDFREE.",
        "url": "http://arxiv.org/abs/2507.05715v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05715v1",
        "arxiv_id": "2507.05715v1",
        "authors": [
            "Guohao Li",
            "Li Jing",
            "Jia Wu",
            "Xuefei Li",
            "Kai Zhu",
            "Yue He"
        ],
        "submitted": "2025-07-08 06:58:24",
        "source": "arxiv",
        "comment": "ACM MM'25 (Experimental supplementary version)",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on multimodal collaborative filtering recommendation, which is a topic in recommender systems, but not the primary focus of the user's research. The paper's emphasis on ID-free embeddings and multimodal features is also not aligned with the user's interests in deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Agentic-R1: Distilled Dual-Strategy Reasoning",
        "abstract": "Current long chain-of-thought (long-CoT) models excel at mathematical\nreasoning but rely on slow and error-prone natural language traces.\nTool-augmented agents address arithmetic via code execution, but often falter\non complex logical tasks. We introduce a fine-tuning framework, DualDistill,\nthat distills complementary reasoning strategies from multiple teachers into a\nunified student model. Using this approach, we train Agentic-R1, which\ndynamically selects the optimal strategy for each query, invoking tools for\narithmetic and algorithmic problems, and using text-based reasoning for\nabstract ones. Our method improves accuracy across a range of tasks, including\nboth computation-intensive and standard benchmarks, demonstrating the\neffectiveness of multi-strategy distillation in achieving robust and efficient\nreasoning. Our project is available at https://github.com/StigLidu/DualDistill",
        "url": "http://arxiv.org/abs/2507.05707v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05707v1",
        "arxiv_id": "2507.05707v1",
        "authors": [
            "Weihua Du",
            "Pranjal Aggarwal",
            "Sean Welleck",
            "Yiming Yang"
        ],
        "submitted": "2025-07-08 06:35:16",
        "source": "arxiv",
        "comment": "Preprint. 15 pages. Project available at\n  https://github.com/StigLidu/DualDistill",
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on developing a reasoning framework for mathematical and logical tasks, using a combination of code execution and text-based reasoning. While it involves some form of query understanding and ranking models, the primary focus is on reasoning and problem-solving, which is not directly related to the user's interests in information retrieval, search technologies, and user behavior modeling."
    },
    {
        "title": "ECom-Bench: Can LLM Agent Resolve Real-World E-commerce Customer Support Issues?",
        "abstract": "In this paper, we introduce ECom-Bench, the first benchmark framework for\nevaluating LLM agent with multimodal capabilities in the e-commerce customer\nsupport domain. ECom-Bench features dynamic user simulation based on persona\ninformation collected from real e-commerce customer interactions and a\nrealistic task dataset derived from authentic e-commerce dialogues. These\ntasks, covering a wide range of business scenarios, are designed to reflect\nreal-world complexities, making ECom-Bench highly challenging. For instance,\neven advanced models like GPT-4o achieve only a 10-20% pass^3 metric in our\nbenchmark, highlighting the substantial difficulties posed by complex\ne-commerce scenarios. Upon publication, the code and data will be open-sourced\nto facilitate further research and development in this domain.",
        "url": "http://arxiv.org/abs/2507.05639v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05639v1",
        "arxiv_id": "2507.05639v1",
        "authors": [
            "Haoxin Wang",
            "Xianhan Peng",
            "Xucheng Huang",
            "Yizhe Huang",
            "Ming Gong",
            "Chenghan Yang",
            "Yang Liu",
            "Ling Jiang"
        ],
        "submitted": "2025-07-08 03:35:48",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on evaluating LLM agents in e-commerce customer support, which is related to your background in e-commerce. However, the primary focus is on benchmarking and evaluation, rather than query understanding, ranking models, or user behavior modeling, which are your core research interests in IR and NLP."
    },
    {
        "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving",
        "abstract": "As language agents tackle increasingly complex tasks, they struggle with\neffective error correction and experience reuse across domains. We introduce\nAgent KB, a hierarchical experience framework that enables complex agentic\nproblem solving via a novel Reason-Retrieve-Refine pipeline. Agent KB addresses\na core limitation: agents traditionally cannot learn from each other's\nexperiences. By capturing both high-level strategies and detailed execution\nlogs, Agent KB creates a shared knowledge base that enables cross-agent\nknowledge transfer. Evaluated on the GAIA benchmark, Agent KB improves success\nrates by up to 16.28 percentage points. On the most challenging tasks, Claude-3\nimproves from 38.46% to 57.69%, while GPT-4 improves from 53.49% to 73.26% on\nintermediate tasks. On SWE-bench code repair, Agent KB enables Claude-3 to\nimprove from 41.33% to 53.33%. Our results suggest that Agent KB provides a\nmodular, framework-agnostic infrastructure for enabling agents to learn from\npast experiences and generalize successful strategies to new tasks.",
        "url": "http://arxiv.org/abs/2507.06229v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06229v1",
        "arxiv_id": "2507.06229v1",
        "authors": [
            "Xiangru Tang",
            "Tianrui Qin",
            "Tianhao Peng",
            "Ziyang Zhou",
            "Daniel Shao",
            "Tingting Du",
            "Xinming Wei",
            "Peng Xia",
            "Fang Wu",
            "He Zhu",
            "Ge Zhang",
            "Jiaheng Liu",
            "Xingyao Wang",
            "Sirui Hong",
            "Chenglin Wu",
            "Hao Cheng",
            "Chi Wang",
            "Wangchunshu Zhou"
        ],
        "submitted": "2025-07-08 17:59:22",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on agent-based problem solving, leveraging cross-domain experience, and knowledge transfer, which is not directly related to information retrieval, search technologies, or query understanding. While it involves language agents and knowledge bases, the context is distinct from the user's primary research interests."
    },
    {
        "title": "CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions",
        "abstract": "Pretrained vision-language models (VLMs) such as CLIP excel in multimodal\nunderstanding but struggle with contextually relevant fine-grained visual\nfeatures, making it difficult to distinguish visually similar yet culturally\ndistinct concepts. This limitation stems from the scarcity of high-quality\nculture-specific datasets, the lack of integrated contextual knowledge, and the\nabsence of hard negatives highlighting subtle distinctions. To address these\nchallenges, we first design a data curation pipeline that leverages\nopen-sourced VLMs and text-to-image diffusion models to construct CulTwin, a\nsynthetic cultural dataset. This dataset consists of paired\nconcept-caption-image triplets, where concepts visually resemble each other but\nrepresent different cultural contexts. Then, we fine-tune CLIP on CulTwin to\ncreate CultureCLIP, which aligns cultural concepts with contextually enhanced\ncaptions and synthetic images through customized contrastive learning, enabling\nfiner cultural differentiation while preserving generalization capabilities.\nExperiments on culturally relevant benchmarks show that CultureCLIP outperforms\nthe base CLIP, achieving up to a notable 5.49% improvement in fine-grained\nconcept recognition on certain tasks, while preserving CLIP's original\ngeneralization ability, validating the effectiveness of our data synthesis and\nVLM backbone training paradigm in capturing subtle cultural distinctions.",
        "url": "http://arxiv.org/abs/2507.06210v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06210v1",
        "arxiv_id": "2507.06210v1",
        "authors": [
            "Yuchen Huang",
            "Zhiyuan Fan",
            "Zhitao He",
            "Sandeep Polisetty",
            "Wenyan Li",
            "Yi R. Fung"
        ],
        "submitted": "2025-07-08 17:38:56",
        "source": "arxiv",
        "comment": "25 pages, COLM 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on improving the cultural awareness of CLIP, a vision-language model, by creating a synthetic dataset and fine-tuning it. While it's related to multimodal understanding and deep semantic understanding, it's not directly related to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval and Search technologies."
    },
    {
        "title": "DS@GT at CheckThat! 2025: Ensemble Methods for Detection of Scientific Discourse on Social Media",
        "abstract": "In this paper, we, as the DS@GT team for CLEF 2025 CheckThat! Task 4a\nScientific Web Discourse Detection, present the methods we explored for this\ntask. For this multiclass classification task, we determined if a tweet\ncontained a scientific claim, a reference to a scientific study or publication,\nand/or mentions of scientific entities, such as a university or a scientist. We\npresent 3 modeling approaches for this task: transformer finetuning, few-shot\nprompting of LLMs, and a combined ensemble model whose design was informed by\nearlier experiments. Our team placed 7th in the competition, achieving a\nmacro-averaged F1 score of 0.8611, an improvement over the DeBERTaV3 baseline\nof 0.8375. Our code is available on Github at\nhttps://github.com/dsgt-arc/checkthat-2025-swd/tree/main/subtask-4a.",
        "url": "http://arxiv.org/abs/2507.06205v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06205v1",
        "arxiv_id": "2507.06205v1",
        "authors": [
            "Ayush Parikh",
            "Hoang Thanh Thanh Truong",
            "Jeanette Schofield",
            "Maximilian Heil"
        ],
        "submitted": "2025-07-08 17:30:18",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on a specific task, Scientific Web Discourse Detection, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves NLP and classification, the context is not relevant to the user's core research themes."
    },
    {
        "title": "Differential Mamba",
        "abstract": "Sequence models like Transformers and RNNs often overallocate attention to\nirrelevant context, leading to noisy intermediate representations. This\ndegrades LLM capabilities by promoting hallucinations, weakening long-range and\nretrieval abilities, and reducing robustness. Recent work has shown that\ndifferential design can mitigate this issue in Transformers, improving their\neffectiveness across various applications. In this paper, we explore whether\nthese techniques, originally developed for Transformers, can be applied to\nMamba, a recent architecture based on selective state-space layers that\nachieves Transformer-level performance with greater efficiency. We show that a\nnaive adaptation of differential design to Mamba is insufficient and requires\ncareful architectural modifications. To address this, we introduce a novel\ndifferential mechanism for Mamba, empirically validated on language modeling\nbenchmarks, demonstrating improved retrieval capabilities and superior\nperformance over vanilla Mamba. Finally, we conduct extensive ablation studies\nand empirical analyses to justify our design choices and provide evidence that\nour approach effectively mitigates the overallocation problem in Mamba-based\nmodels. Our code is publicly available.",
        "url": "http://arxiv.org/abs/2507.06204v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06204v1",
        "arxiv_id": "2507.06204v1",
        "authors": [
            "Nadav Schneider",
            "Itamar Zimerman",
            "Eliya Nachmani"
        ],
        "submitted": "2025-07-08 17:30:14",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on improving the performance of a specific neural network architecture, Mamba, by addressing the issue of overallocation of attention in sequence models. While it mentions Transformers, it does not directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval and Search technologies."
    },
    {
        "title": "CriticLean: Critic-Guided Reinforcement Learning for Mathematical Formalization",
        "abstract": "Translating natural language mathematical statements into formal, executable\ncode is a fundamental challenge in automated theorem proving. While prior work\nhas focused on generation and compilation success, little attention has been\npaid to the critic phase-the evaluation of whether generated formalizations\ntruly capture the semantic intent of the original problem. In this paper, we\nintroduce CriticLean, a novel critic-guided reinforcement learning framework\nthat elevates the role of the critic from a passive validator to an active\nlearning component. Specifically, first, we propose the CriticLeanGPT, trained\nvia supervised fine-tuning and reinforcement learning, to rigorously assess the\nsemantic fidelity of Lean 4 formalizations. Then, we introduce CriticLeanBench,\na benchmark designed to measure models' ability to distinguish semantically\ncorrect from incorrect formalizations, and demonstrate that our trained\nCriticLeanGPT models can significantly outperform strong open- and\nclosed-source baselines. Building on the CriticLean framework, we construct\nFineLeanCorpus, a dataset comprising over 285K problems that exhibits rich\ndomain diversity, broad difficulty coverage, and high correctness based on\nhuman evaluation. Overall, our findings highlight that optimizing the critic\nphase is essential for producing reliable formalizations, and we hope our\nCriticLean will provide valuable insights for future advances in formal\nmathematical reasoning.",
        "url": "http://arxiv.org/abs/2507.06181v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06181v1",
        "arxiv_id": "2507.06181v1",
        "authors": [
            "Zhongyuan Peng",
            "Yifan Yao",
            "Kaijing Ma",
            "Shuyue Guo",
            "Yizhe Li",
            "Yichi Zhang",
            "Chenchen Zhang",
            "Yifan Zhang",
            "Zhouliang Yu",
            "Luming Li",
            "Minghao Liu",
            "Yihang Xia",
            "Jiawei Shen",
            "Yuchen Wu",
            "Yixin Cao",
            "Zhaoxiang Zhang",
            "Wenhao Huang",
            "Jiaheng Liu",
            "Ge Zhang"
        ],
        "submitted": "2025-07-08 17:03:39",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on formalizing mathematical statements, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it involves natural language processing, the context is specific to automated theorem proving and formal mathematical reasoning, which is not aligned with the user's research interests."
    },
    {
        "title": "Coding Triangle: How Does Large Language Model Understand Code?",
        "abstract": "Large language models (LLMs) have achieved remarkable progress in code\ngeneration, yet their true programming competence remains underexplored. We\nintroduce the Code Triangle framework, which systematically evaluates LLMs\nacross three fundamental dimensions: editorial analysis, code implementation,\nand test case generation. Through extensive experiments on competitive\nprogramming benchmarks, we reveal that while LLMs can form a self-consistent\nsystem across these dimensions, their solutions often lack the diversity and\nrobustness of human programmers. We identify a significant distribution shift\nbetween model cognition and human expertise, with model errors tending to\ncluster due to training data biases and limited reasoning transfer. Our study\ndemonstrates that incorporating human-generated editorials, solutions, and\ndiverse test cases, as well as leveraging model mixtures, can substantially\nenhance both the performance and robustness of LLMs. Furthermore, we reveal\nboth the consistency and inconsistency in the cognition of LLMs that may\nfacilitate self-reflection and self-improvement, providing a potential\ndirection for developing more powerful coding models.",
        "url": "http://arxiv.org/abs/2507.06138v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06138v1",
        "arxiv_id": "2507.06138v1",
        "authors": [
            "Taolin Zhang",
            "Zihan Ma",
            "Maosong Cao",
            "Junnan Liu",
            "Songyang Zhang",
            "Kai Chen"
        ],
        "submitted": "2025-07-08 16:20:43",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling, which are the core areas of your research interests. While it touches on Natural Language Processing, it is focused on code generation and evaluation, which is a distinct field."
    },
    {
        "title": "Tile-Based ViT Inference with Visual-Cluster Priors for Zero-Shot Multi-Species Plant Identification",
        "abstract": "We describe DS@GT's second-place solution to the PlantCLEF 2025 challenge on\nmulti-species plant identification in vegetation quadrat images. Our pipeline\ncombines (i) a fine-tuned Vision Transformer ViTD2PC24All for patch-level\ninference, (ii) a 4x4 tiling strategy that aligns patch size with the network's\n518x518 receptive field, and (iii) domain-prior adaptation through PaCMAP +\nK-Means visual clustering and geolocation filtering. Tile predictions are\naggregated by majority vote and re-weighted with cluster-specific Bayesian\npriors, yielding a macro-averaged F1 of 0.348 (private leaderboard) while\nrequiring no additional training. All code, configuration files, and\nreproducibility scripts are publicly available at\nhttps://github.com/dsgt-arc/plantclef-2025.",
        "url": "http://arxiv.org/abs/2507.06093v1",
        "pdf_url": "http://arxiv.org/pdf/2507.06093v1",
        "arxiv_id": "2507.06093v1",
        "authors": [
            "Murilo Gustineli",
            "Anthony Miyaguchi",
            "Adrian Cheung",
            "Divyansh Khattak"
        ],
        "submitted": "2025-07-08 15:35:19",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on plant identification using computer vision and deep learning, which is outside your primary areas of interest."
    },
    {
        "title": "DocIE@XLLM25: In-Context Learning for Information Extraction using Fully Synthetic Demonstrations",
        "abstract": "Large, high-quality annotated corpora remain scarce in document-level entity\nand relation extraction in zero-shot or few-shot settings. In this paper, we\npresent a fully automatic, LLM-based pipeline for synthetic data generation and\nin-context learning for document-level entity and relation extraction. In\ncontrast to existing approaches that rely on manually annotated demonstrations\nor direct zero-shot inference, our method combines synthetic data generation\nwith retrieval-based in-context learning, using a reasoning-optimized language\nmodel. This allows us to build a high-quality demonstration database without\nmanual annotation and to dynamically retrieve relevant examples at inference\ntime. Based on our approach we produce a synthetic dataset of over $5k$\nWikipedia abstracts with approximately $59k$ entities and $30k$ relation\ntriples. Finally, we evaluate in-context learning performance on the DocIE\nshared task, extracting entities and relations from long documents in a\nzero-shot setting. We find that in-context joint entity and relation extraction\nat document-level remains a challenging task, even for state-of-the-art large\nlanguage models.",
        "url": "http://arxiv.org/abs/2507.05997v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05997v1",
        "arxiv_id": "2507.05997v1",
        "authors": [
            "Nicholas Popovič",
            "Ashish Kangen",
            "Tim Schopf",
            "Michael Färber"
        ],
        "submitted": "2025-07-08 13:55:25",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on document-level entity and relation extraction using synthetic data generation and in-context learning, which is related to information retrieval and NLP. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core aspects of your research interests."
    },
    {
        "title": "We Should Evaluate Real-World Impact",
        "abstract": "The ACL community has very little interest in evaluating the real-world\nimpact of NLP systems. A structured survey of the ACL Anthology shows that\nperhaps 0.1% of its papers contain such evaluations; furthermore most papers\nwhich include impact evaluations present them very sketchily and instead focus\non metric evaluations. NLP technology would be more useful and more quickly\nadopted if we seriously tried to understand and evaluate its real-world impact.",
        "url": "http://arxiv.org/abs/2507.05973v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05973v1",
        "arxiv_id": "2507.05973v1",
        "authors": [
            "Ehud Reiter"
        ],
        "submitted": "2025-07-08 13:29:04",
        "source": "arxiv",
        "comment": "This paper will appear in Computational Linguistics journal as a\n  \"Last Word\" opinion piece. The Arxiv version is a pre-MIT Press publication\n  version",
        "score": 2,
        "keyword_reasons": [
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper's focus on NLP systems and their real-world impact is not directly related to the user's interests in Information Retrieval, Search technologies, and query understanding. The paper's abstract does not mention any relevant topics such as ranking models, user behavior modeling, or deep semantic understanding."
    },
    {
        "title": "MusiScene: Leveraging MU-LLaMA for Scene Imagination and Enhanced Video Background Music Generation",
        "abstract": "Humans can imagine various atmospheres and settings when listening to music,\nenvisioning movie scenes that complement each piece. For example, slow,\nmelancholic music might evoke scenes of heartbreak, while upbeat melodies\nsuggest celebration. This paper explores whether a Music Language Model, e.g.\nMU-LLaMA, can perform a similar task, called Music Scene Imagination (MSI),\nwhich requires cross-modal information from video and music to train. To\nimprove upon existing music captioning models which focusing solely on musical\nelements, we introduce MusiScene, a music captioning model designed to imagine\nscenes that complement each music. In this paper, (1) we construct a\nlarge-scale video-audio caption dataset with 3,371 pairs, (2) we finetune Music\nUnderstanding LLaMA for the MSI task to create MusiScene, and (3) we conduct\ncomprehensive evaluations and prove that our MusiScene is more capable of\ngenerating contextually relevant captions compared to MU-LLaMA. We leverage the\ngenerated MSI captions to enhance Video Background Music Generation (VBMG) from\ntext.",
        "url": "http://arxiv.org/abs/2507.05894v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05894v1",
        "arxiv_id": "2507.05894v1",
        "authors": [
            "Fathinah Izzati",
            "Xinyue Li",
            "Yuxuan Wu",
            "Gus Xia"
        ],
        "submitted": "2025-07-08 11:32:02",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus is on music scene imagination and video background music generation, which is outside your primary areas of interest."
    },
    {
        "title": "Affective-ROPTester: Capability and Bias Analysis of LLMs in Predicting Retinopathy of Prematurity",
        "abstract": "Despite the remarkable progress of large language models (LLMs) across\nvarious domains, their capacity to predict retinopathy of prematurity (ROP)\nrisk remains largely unexplored. To address this gap, we introduce a novel\nChinese benchmark dataset, termed CROP, comprising 993 admission records\nannotated with low, medium, and high-risk labels. To systematically examine the\npredictive capabilities and affective biases of LLMs in ROP risk\nstratification, we propose Affective-ROPTester, an automated evaluation\nframework incorporating three prompting strategies: Instruction-based,\nChain-of-Thought (CoT), and In-Context Learning (ICL). The Instruction scheme\nassesses LLMs' intrinsic knowledge and associated biases, whereas the CoT and\nICL schemes leverage external medical knowledge to enhance predictive accuracy.\nCrucially, we integrate emotional elements at the prompt level to investigate\nhow different affective framings influence the model's ability to predict ROP\nand its bias patterns. Empirical results derived from the CROP dataset yield\ntwo principal observations. First, LLMs demonstrate limited efficacy in ROP\nrisk prediction when operating solely on intrinsic knowledge, yet exhibit\nmarked performance gains when augmented with structured external inputs.\nSecond, affective biases are evident in the model outputs, with a consistent\ninclination toward overestimating medium- and high-risk cases. Third, compared\nto negative emotions, positive emotional framing contributes to mitigating\npredictive bias in model outputs. These findings highlight the critical role of\naffect-sensitive prompt engineering in enhancing diagnostic reliability and\nemphasize the utility of Affective-ROPTester as a framework for evaluating and\nmitigating affective bias in clinical language modeling systems.",
        "url": "http://arxiv.org/abs/2507.05816v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05816v1",
        "arxiv_id": "2507.05816v1",
        "authors": [
            "Shuai Zhao",
            "Yulin Zhang",
            "Luwei Xiao",
            "Xinyi Wu",
            "Yanhao Jia",
            "Zhongliang Guo",
            "Xiaobao Wu",
            "Cong-Duy Nguyen",
            "Guoming Zhang",
            "Anh Tuan Luu"
        ],
        "submitted": "2025-07-08 09:36:14",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The focus is on predicting retinopathy of prematurity using large language models, which is outside your primary area of interest. Additionally, the paper does not involve query understanding, ranking models, or user behavior modeling, making it only loosely relevant to your research."
    },
    {
        "title": "Omni-Router: Sharing Routing Decisions in Sparse Mixture-of-Experts for Speech Recognition",
        "abstract": "Mixture-of-experts (MoE) architectures have expanded from language modeling\nto automatic speech recognition (ASR). Traditional MoE methods, such as the\nSwitch Transformer, route experts independently within each layer. Our analysis\nreveals that routers in most layers make expert choices that are not strongly\ncorrelated with the choices of the routers in other layers. To increase the\ncooperation between experts in different layers and encourage greater\nspecialization, we use a shared router across different MoE layers. We call\nthis model \\emph{Omni-router Transformer}. Extensive experiments on a\nlarge-scale pseudo-labeled dataset and evaluations across 10 diverse,\nout-of-domain ASR benchmarks demonstrate that the Omni-router Transformer is\nable to achieve lower training loss and consistently outperform dense and\nSwitch Transformer models, reducing average word error rates by 11.2% and 8.2%,\nrespectively, while providing structured expert usage and improved robustness\nto diverse data.",
        "url": "http://arxiv.org/abs/2507.05724v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05724v1",
        "arxiv_id": "2507.05724v1",
        "authors": [
            "Zijin Gu",
            "Tatiana Likhomanenko",
            "Navdeep Jaitly"
        ],
        "submitted": "2025-07-08 07:18:33",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The topic of automatic speech recognition and mixture-of-experts architectures is outside your primary focus, and the paper does not address query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "MobileGUI-RL: Advancing Mobile GUI Agent through Reinforcement Learning in Online Environment",
        "abstract": "Recently, there has been a surge of vision-based GUI agents designed to\nautomate everyday mobile and web tasks. These agents interpret raw GUI\nscreenshots and autonomously decide where to click, scroll, or type, which\nbypasses handcrafted rules and app-specific APIs. However, most existing\nmethods trained GUI agent in the offline environment using pre-collected\ntrajectories. This approach limits scalability, causes overfitting to specific\nUI templates, and leads to brittle policies when faced with unseen environment.\nWe present MobileGUI-RL, a scalable framework that trains GUI agent in online\nenvironment. MobileGUI-RL contains two key components. It (i) synthesizes a\ncurriculum of learnable tasks through self-exploration and filtering, and (ii)\nadapts GRPO to GUI navigation with trajectory-aware advantages and composite\nrewards that balance task success and execution efficiency. Experiments on\nthree online mobile-agent benchmarks show consistent gains, validating the\neffectiveness of our approach.",
        "url": "http://arxiv.org/abs/2507.05720v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05720v1",
        "arxiv_id": "2507.05720v1",
        "authors": [
            "Yucheng Shi",
            "Wenhao Yu",
            "Zaitang Li",
            "Yonglin Wang",
            "Hongming Zhang",
            "Ninghao Liu",
            "Haitao Mi",
            "Dong Yu"
        ],
        "submitted": "2025-07-08 07:07:53",
        "source": "arxiv",
        "comment": "17 pages, 4 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'click' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on mobile GUI agents and reinforcement learning, which is not directly related to information retrieval, search technologies, or query understanding. While it involves learning and optimization, the context is different from the user's primary research interests."
    },
    {
        "title": "TuneShield: Mitigating Toxicity in Conversational AI while Fine-tuning on Untrusted Data",
        "abstract": "Recent advances in foundation models, such as LLMs, have revolutionized\nconversational AI. Chatbots are increasingly being developed by customizing\nLLMs on specific conversational datasets. However, mitigating toxicity during\nthis customization, especially when dealing with untrusted training data,\nremains a significant challenge. To address this, we introduce TuneShield, a\ndefense framework designed to mitigate toxicity during chatbot fine-tuning\nwhile preserving conversational quality. TuneShield leverages LLM-based\ntoxicity classification, utilizing the instruction-following capabilities and\nsafety alignment of LLMs to effectively identify toxic samples, outperforming\nindustry API services. TuneShield generates synthetic conversation samples,\ntermed 'healing data', based on the identified toxic samples, using them to\nmitigate toxicity while reinforcing desirable behavior during fine-tuning. It\nperforms an alignment process to further nudge the chatbot towards producing\ndesired responses. Our findings show that TuneShield effectively mitigates\ntoxicity injection attacks while preserving conversational quality, even when\nthe toxicity classifiers are imperfect or biased. TuneShield proves to be\nresilient against adaptive adversarial and jailbreak attacks. Additionally,\nTuneShield demonstrates effectiveness in mitigating adaptive toxicity injection\nattacks during dialog-based learning (DBL).",
        "url": "http://arxiv.org/abs/2507.05660v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05660v1",
        "arxiv_id": "2507.05660v1",
        "authors": [
            "Aravind Cheruvu",
            "Shravya Kanchi",
            "Sifat Muhammad Abdullah",
            "Nicholas Kong",
            "Daphne Yao",
            "Murtuza Jadliwala",
            "Bimal Viswanath"
        ],
        "submitted": "2025-07-08 04:40:09",
        "source": "arxiv",
        "comment": "Pre-print",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on conversational AI and toxicity mitigation, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions fine-tuning and classification, the context is different from the user's primary research interests."
    },
    {
        "title": "Flipping Knowledge Distillation: Leveraging Small Models' Expertise to Enhance LLMs in Text Matching",
        "abstract": "Knowledge distillation typically involves transferring knowledge from a Large\nLanguage Model (LLM) to a Smaller Language Model (SLM). However, in tasks such\nas text matching, fine-tuned smaller models often yield more effective\ndomain-specific representations, as they focus on optimizing the similarity of\ninput pairs. To leverage both the specialized strengths of small models and the\nrich semantic understanding of LLMs, we introduce a flipped knowledge\ndistillation paradigm, where LLM learns from SLM. Specifically, we address the\narchitectural gap between decoder-only LLMs and smaller encoder-based models by\nreinterpreting LLMs in an encoder-decoder manner using LoRA. The encoder\ngenerates compressed representations, while the decoder maps them to the output\nspace. During training, the encoder produces representations and their\nsimilarities, which are then aligned with the similarity scores produced by the\nteacher, using our proposed Margin-aware Contrastive Learning (MCL) approach.\nThe MCL ensures accurate similarity for both positive and negative pairs, and\nadaptively handles the internal differences within positive and negative\nsamples. Our paradigm requires only a reasonably good-performing SLM, allowing\nthe LLM to achieve improved performance. Experiments on financial and\nhealthcare benchmarks, as well as real-world applications, confirm its\neffectiveness, and the model has been fully deployed in an online environment.",
        "url": "http://arxiv.org/abs/2507.05617v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05617v1",
        "arxiv_id": "2507.05617v1",
        "authors": [
            "Mingzhe Li",
            "Jing Xiang",
            "Qishen Zhang",
            "Kaiyang Wan",
            "Xiuying Chen"
        ],
        "submitted": "2025-07-08 02:54:15",
        "source": "arxiv",
        "comment": "Accepted by ACL 2025 main",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on knowledge distillation and model architecture, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it mentions text matching, the approach is not centered around query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's interests."
    },
    {
        "title": "Self-Review Framework for Enhancing Instruction Following Capability of LLM",
        "abstract": "Various techniques have been proposed to improve large language models (LLMs)\nadherence to formatting and instruction constraints. One of the most effective\napproaches involves utilizing high-quality data generated by powerful models.\nHowever, such models often fail to fully comply with complex instructions in a\nsingle generation. To address this limitation, iterative revision methods have\nbeen introduced. Nevertheless, as the number of data points and revision\niterations increases, the associated monetary costs grow significantly. As a\nresource-efficient alternative, methods have been proposed that leverage\nhigh-performance evaluation tools to compensate for the limited self-evaluation\ncapabilities of open-source LLMs. However, these approaches often lead to a\ndegradation in output quality due to excessive revision. To overcome these\nchallenges, we propose Re5, a self-evaluation and revision framework designed\nto enhance instruction-following performance while preserving the quality of\nthe generated content. Re5 extracts task and constraint components from user\ninstructions, performs structural evaluations to prevent error accumulation,\nand applies fine-grained constraint-specific content evaluations followed by\nselective revisions. This process ensures precise and quality-preserving\nimprovements. The final high-quality outputs are used for alignment tuning,\nenabling long-term alignment improvements through a data-centric iterative\nrefinement loop. Experimental results demonstrate that Re5 achieves\ninstruction-following performance comparable to models trained on data\ngenerated by GPT-4o-mini, a high-performance model, even with a small amount of\ndata while maintaining response quality with a 64.24%-win rate over the\nnon-revised initial responses. These results validate Re5 as an efficient and\neffective solution for enhancing instruction adherence with minimal external\nsupervision.",
        "url": "http://arxiv.org/abs/2507.05598v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05598v1",
        "arxiv_id": "2507.05598v1",
        "authors": [
            "Sihyun Park"
        ],
        "submitted": "2025-07-08 02:17:18",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on large language models and instruction-following capabilities, which is outside your primary research focus."
    },
    {
        "title": "Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment",
        "abstract": "Large language models (LLMs) have advanced virtual educators and learners,\nbridging NLP with AI4Education. Existing work often lacks scalability and fails\nto leverage diverse, large-scale course content, with limited frameworks for\nassessing pedagogic quality. To this end, we propose WikiHowAgent, a\nmulti-agent workflow leveraging LLMs to simulate interactive teaching-learning\nconversations. It integrates teacher and learner agents, an interaction\nmanager, and an evaluator to facilitate procedural learning and assess\npedagogic quality. We introduce a dataset of 114,296 teacher-learner\nconversations grounded in 14,287 tutorials across 17 domains and 727 topics.\nOur evaluation protocol combines computational and rubric-based metrics with\nhuman judgment alignment. Results demonstrate the workflow's effectiveness in\ndiverse setups, offering insights into LLM capabilities across domains. Our\ndatasets and implementations are fully open-sourced.",
        "url": "http://arxiv.org/abs/2507.05528v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05528v1",
        "arxiv_id": "2507.05528v1",
        "authors": [
            "Jiahuan Pei",
            "Fanghua Ye",
            "Xin Sun",
            "Wentao Deng",
            "Koen Hindriks",
            "Junxiao Wang"
        ],
        "submitted": "2025-07-07 22:56:37",
        "source": "arxiv",
        "comment": "14 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of large language models in conversational education, which is related to information retrieval and search technologies. However, the focus is on procedural learning and pedagogic quality assessment, which is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is somewhat limited, but it does touch on NLP and AI4Education, which are adjacent to the user's research areas."
    },
    {
        "title": "\"Lost-in-the-Later\": Framework for Quantifying Contextual Grounding in Large Language Models",
        "abstract": "Large language models are capable of leveraging both contextual and\nparametric knowledge but how they prioritize and integrate these sources\nremains underexplored. We introduce CoPE, a novel evaluation framework that\nsystematically measures contextual knowledge (CK) and parametric knowledge (PK)\nacross models and languages. Using our MultiWikiAtomic dataset in English,\nSpanish, and Danish, we analyze how large language models (LLMs) integrate\ncontext, prioritize information, and incorporate PK in open-ended question\nanswering. Our analysis uncovers a phenomenon we call lost-in-the-later, where\nLLMs tend to overlook or deprioritize information that appears later in a given\ncontext, revealing a strong positional bias that affects contextual grounding.\nWe further find that reasoning models, as well as non-reasoning models prompted\nwith chain-of-thought (CoT), use context even less than non-reasoning models\nwithout CoT and fail to mitigate the lost-in-the-later effect. CoT prompting,\nin particular, results in lower recall and shorter responses, leading to\ndegraded contextual grounding. Based on these insights, we design prompt-based\nmethods to effectively leverage input context. A case study applying CoPE to\nsummarization demonstrates that CK-informed prompting improves factual\ngrounding and reduces hallucination.",
        "url": "http://arxiv.org/abs/2507.05424v1",
        "pdf_url": "http://arxiv.org/pdf/2507.05424v1",
        "arxiv_id": "2507.05424v1",
        "authors": [
            "Yufei Tao",
            "Adam Hiatt",
            "Rahul Seetharaman",
            "Ameeta Agrawal"
        ],
        "submitted": "2025-07-07 19:13:20",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the contextual grounding of large language models, introducing a novel evaluation framework and analyzing how models prioritize and integrate contextual and parametric knowledge. While it touches on the topic of query understanding and ranking models, it is not directly related to my primary focus on information retrieval, especially in areas that require deep semantic understanding and real-time relevance optimization."
    }
]