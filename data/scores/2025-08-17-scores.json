[
    {
        "title": "Retrieval-augmented reasoning with lean language models",
        "abstract": "This technical report details a novel approach to combining reasoning and\nretrieval augmented generation (RAG) within a single, lean language model\narchitecture. While existing RAG systems typically rely on large-scale models\nand external APIs, our work addresses the increasing demand for performant and\nprivacy-preserving solutions deployable in resource-constrained or secure\nenvironments. Building on recent developments in test-time scaling and\nsmall-scale reasoning models, we develop a retrieval augmented conversational\nagent capable of interpreting complex, domain-specific queries using a\nlightweight backbone model. Our system integrates a dense retriever with\nfine-tuned Qwen2.5-Instruct models, using synthetic query generation and\nreasoning traces derived from frontier models (e.g., DeepSeek-R1) over a\ncurated corpus, in this case, the NHS A-to-Z condition pages. We explore the\nimpact of summarisation-based document compression, synthetic data design, and\nreasoning-aware fine-tuning on model performance. Evaluation against both\nnon-reasoning and general-purpose lean models demonstrates that our\ndomain-specific fine-tuning approach yields substantial gains in answer\naccuracy and consistency, approaching frontier-level performance while\nremaining feasible for local deployment. All implementation details and code\nare publicly released to support reproducibility and adaptation across domains.",
        "url": "http://arxiv.org/abs/2508.11386v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11386v1",
        "arxiv_id": "2508.11386v1",
        "authors": [
            "Ryan Sze-Yin Chan",
            "Federico Nanni",
            "Tomas Lazauskas",
            "Rosie Wood",
            "Penelope Yong",
            "Lionel Tarassenko",
            "Mark Girolami",
            "James Geddes",
            "Andrew Duncan"
        ],
        "submitted": "2025-08-15 10:38:15",
        "source": "arxiv",
        "comment": null,
        "score": 15,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval augmented generation' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper explores retrieval-augmented reasoning with lean language models, which is related to query understanding and ranking models in Information Retrieval. The use of lightweight backbone models and fine-tuned Qwen2.5-Instruct models is also relevant to Learning to Rank. However, the focus on domain-specific fine-tuning and summarisation-based document compression is not directly aligned with the user's primary interests in real-time relevance optimization and deep semantic understanding."
    },
    {
        "title": "+VeriRel: Verification Feedback to Enhance Document Retrieval for Scientific Fact Checking",
        "abstract": "Identification of appropriate supporting evidence is critical to the success\nof scientific fact checking. However, existing approaches rely on off-the-shelf\nInformation Retrieval algorithms that rank documents based on relevance rather\nthan the evidence they provide to support or refute the claim being checked.\nThis paper proposes +VeriRel which includes verification success in the\ndocument ranking. Experimental results on three scientific fact checking\ndatasets (SciFact, SciFact-Open and Check-Covid) demonstrate consistently\nleading performance by +VeriRel for document evidence retrieval and a positive\nimpact on downstream verification. This study highlights the potential of\nintegrating verification feedback to document relevance assessment for\neffective scientific fact checking systems. It shows promising future work to\nevaluate fine-grained relevance when examining complex documents for advanced\nscientific fact checking.",
        "url": "http://arxiv.org/abs/2508.11122v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11122v1",
        "arxiv_id": "2508.11122v1",
        "authors": [
            "Xingyu Deng",
            "Xi Wang",
            "Mark Stevenson"
        ],
        "submitted": "2025-08-14 23:57:40",
        "source": "arxiv",
        "comment": "Accpeted for the 34th ACM International Conference on Information and\n  Knowledge Management (CIKM'25)",
        "score": 12,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper proposes a novel approach to document retrieval for scientific fact checking, incorporating verification feedback to enhance relevance assessment. While not directly focused on query understanding, ranking models, or user behavior modeling, the paper's emphasis on relevance optimization and evidence-based ranking aligns with the user's interests in Information Retrieval. The paper's scope is somewhat narrow, focusing on scientific fact checking, but its innovative approach to document retrieval makes it relevant to the user's research themes."
    },
    {
        "title": "INFNet: A Task-aware Information Flow Network for Large-Scale Recommendation Systems",
        "abstract": "Feature interaction has long been a cornerstone of ranking models in\nlarge-scale recommender systems due to its proven effectiveness in capturing\ncomplex dependencies among features. However, existing feature interaction\nstrategies face two critical challenges in industrial applications: (1) The\nvast number of categorical and sequential features makes exhaustive interaction\ncomputationally prohibitive, often resulting in optimization difficulties. (2)\nReal-world recommender systems typically involve multiple prediction\nobjectives, yet most current approaches apply feature interaction modules prior\nto the multi-task learning layers. This late-fusion design overlooks\ntask-specific feature dependencies and inherently limits the capacity of\nmulti-task modeling. To address these limitations, we propose the Information\nFlow Network (INFNet), a task-aware architecture designed for large-scale\nrecommendation scenarios. INFNet distinguishes features into three token types,\ncategorical tokens, sequence tokens, and task tokens, and introduces a novel\ndual-flow design comprising heterogeneous and homogeneous alternating\ninformation blocks. For heterogeneous information flow, we employ a\ncross-attention mechanism with proxy that facilitates efficient cross-modal\ntoken interaction with balanced computational cost. For homogeneous flow, we\ndesign type-specific Proxy Gated Units (PGUs) to enable fine-grained intra-type\nfeature processing. Extensive experiments on multiple offline benchmarks\nconfirm that INFNet achieves state-of-the-art performance. Moreover, INFNet has\nbeen successfully deployed in a commercial online advertising system, yielding\nsignificant gains of +1.587% in Revenue (REV) and +1.155% in Click-Through Rate\n(CTR).",
        "url": "http://arxiv.org/abs/2508.11565v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11565v1",
        "arxiv_id": "2508.11565v1",
        "authors": [
            "Kaiyuan Li",
            "Dongdong Mao",
            "Yongxiang Tang",
            "Yanhua Cheng",
            "Yanxiang Zeng",
            "Chao Wang",
            "Xialong Liu",
            "Peng Jiang"
        ],
        "submitted": "2025-08-15 16:18:32",
        "source": "arxiv",
        "comment": null,
        "score": 11,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'click' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'click-through rate' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a novel architecture for large-scale recommendation systems, focusing on feature interaction and task-aware modeling. While it touches on ranking models, the primary focus is on recommender systems, which is not directly related to the user's core research themes in Information Retrieval and Search technologies. The paper's emphasis on feature interaction and multi-task learning is somewhat related to the user's interests in query understanding and ranking models, but the context and application are different."
    },
    {
        "title": "CoDiEmb: A Collaborative yet Distinct Framework for Unified Representation Learning in Information Retrieval and Semantic Textual Similarity",
        "abstract": "Learning unified text embeddings that excel across diverse downstream tasks\nis a central goal in representation learning, yet negative transfer remains a\npersistent obstacle. This challenge is particularly pronounced when jointly\ntraining a single encoder for Information Retrieval (IR) and Semantic Textual\nSimilarity (STS), two essential but fundamentally disparate tasks for which\nnaive co-training typically yields steep performance trade-offs. We argue that\nresolving this conflict requires systematically decoupling task-specific\nlearning signals throughout the training pipeline. To this end, we introduce\nCoDiEmb, a unified framework that reconciles the divergent requirements of IR\nand STS in a collaborative yet distinct manner. CoDiEmb integrates three key\ninnovations for effective joint optimization: (1) Task-specialized objectives\npaired with a dynamic sampler that forms single-task batches and balances\nper-task updates, thereby preventing gradient interference. For IR, we employ a\ncontrastive loss with multiple positives and hard negatives, augmented by\ncross-device sampling. For STS, we adopt order-aware objectives that directly\noptimize correlation and ranking consistency. (2) A delta-guided model fusion\nstrategy that computes fine-grained merging weights for checkpoints by\nanalyzing each parameter's deviation from its pre-trained initialization,\nproving more effective than traditional Model Soups. (3) An efficient,\nsingle-stage training pipeline that is simple to implement and converges\nstably. Extensive experiments on 15 standard IR and STS benchmarks across three\nbase encoders validate CoDiEmb. Our results and analysis demonstrate that the\nframework not only mitigates cross-task trade-offs but also measurably improves\nthe geometric properties of the embedding space.",
        "url": "http://arxiv.org/abs/2508.11442v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11442v1",
        "arxiv_id": "2508.11442v1",
        "authors": [
            "Bowen Zhang",
            "Zixin Song",
            "Chunquan Chen",
            "Qian-Wen Zhang",
            "Di Yin",
            "Xing Sun"
        ],
        "submitted": "2025-08-15 12:46:35",
        "source": "arxiv",
        "comment": null,
        "score": 11,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "The paper focuses on representation learning for Information Retrieval (IR) and Semantic Textual Similarity (STS), which aligns with your interest in IR and NLP. The proposed framework, CoDiEmb, addresses the challenge of negative transfer between IR and STS, which is a relevant topic in query understanding and ranking models. While the paper does not specifically mention user behavior modeling or click models, its contributions to unified representation learning and joint optimization are likely to be useful in your research."
    },
    {
        "title": "Role-Augmented Intent-Driven Generative Search Engine Optimization",
        "abstract": "Generative Search Engines (GSEs), powered by Large Language Models (LLMs) and\nRetrieval-Augmented Generation (RAG), are reshaping information retrieval.\nWhile commercial systems (e.g., BingChat, Perplexity.ai) demonstrate impressive\nsemantic synthesis capabilities, their black-box nature fundamentally\nundermines established Search Engine Optimization (SEO) practices. Content\ncreators face a critical challenge: their optimization strategies, effective in\ntraditional search engines, are misaligned with generative retrieval contexts,\nresulting in diminished visibility. To bridge this gap, we propose a\nRole-Augmented Intent-Driven Generative Search Engine Optimization (G-SEO)\nmethod, providing a structured optimization pathway tailored for GSE scenarios.\nOur method models search intent through reflective refinement across diverse\ninformational roles, enabling targeted content enhancement. To better evaluate\nthe method under realistic settings, we address the benchmarking limitations of\nprior work by: (1) extending the GEO dataset with diversified query variations\nreflecting real-world search scenarios and (2) introducing G-Eval 2.0, a\n6-level LLM-augmented evaluation rubric for fine-grained human-aligned\nassessment. Experimental results demonstrate that search intent serves as an\neffective signal for guiding content optimization, yielding significant\nimprovements over single-aspect baseline approaches in both subjective\nimpressions and objective content visibility within GSE responses.",
        "url": "http://arxiv.org/abs/2508.11158v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11158v1",
        "arxiv_id": "2508.11158v1",
        "authors": [
            "Xiaolu Chen",
            "Haojie Wu",
            "Jie Bao",
            "Zhen Chen",
            "Yong Liao",
            "Hu Huang"
        ],
        "submitted": "2025-08-15 02:08:55",
        "source": "arxiv",
        "comment": "7 pages, 5 figures",
        "score": 11,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "The paper's focus on Generative Search Engines, Large Language Models, and Retrieval-Augmented Generation aligns with your interest in Information Retrieval and Search technologies. The paper's emphasis on understanding search intent and optimizing content for generative retrieval contexts is also relevant to your research on query understanding and ranking models. However, the paper's primary focus on generative search engines and content optimization may not be directly related to your work on user behavior modeling and click models."
    },
    {
        "title": "PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing",
        "abstract": "Paper search is an important activity for researchers, typically involving\nusing a query with description of a topic to find relevant papers. As research\ndeepens, paper search requirements may become more flexible, sometimes\ninvolving specific details such as module configuration rather than being\nlimited to coarse-grained topics. However, previous paper search systems are\nunable to meet these flexible-grained requirements, as these systems mainly\ncollect paper abstracts to construct index of corpus, which lack detailed\ninformation to support retrieval by finer-grained queries. In this work, we\npropose PaperRegister, consisted of offline hierarchical indexing and online\nadaptive retrieval, transforming traditional abstract-based index into\nhierarchical index tree for paper search, thereby supporting queries at\nflexible granularity. Experiments on paper search tasks across a range of\ngranularity demonstrate that PaperRegister achieves the state-of-the-art\nperformance, and particularly excels in fine-grained scenarios, highlighting\nthe good potential as an effective solution for flexible-grained paper search\nin real-world applications. Code for this work is in\nhttps://github.com/Li-Z-Q/PaperRegister.",
        "url": "http://arxiv.org/abs/2508.11116v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11116v1",
        "arxiv_id": "2508.11116v1",
        "authors": [
            "Zhuoqun Li",
            "Xuanang Chen",
            "Hongyu Lin",
            "Yaojie Lu",
            "Xianpei Han",
            "Le Sun"
        ],
        "submitted": "2025-08-14 23:43:46",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on paper search, proposing a hierarchical indexing and adaptive retrieval approach to support flexible-grained queries. While it's related to information retrieval, the context is specific to paper search and lacks direct connection to query understanding, ranking models, or user behavior modeling, which are core interests in your research."
    },
    {
        "title": "Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps",
        "abstract": "Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)\nhave ushered in a new era of AI capabilities, demonstrating near-human-level\nperformance across diverse scenarios. While numerous benchmarks (e.g., MMLU)\nand leaderboards (e.g., Chatbot Arena) have been proposed to help evolve the\ndevelopment of LLMs and MLLMs, most rely on static datasets or crowdsourced\ngeneral-domain prompts, often falling short of reflecting performance in\nreal-world applications. To bridge this critical gap, we present Inclusion\nArena, a live leaderboard that ranks models based on human feedback collected\ndirectly from AI-powered applications. Our platform integrates pairwise model\ncomparisons into natural user interactions, ensuring evaluations reflect\npractical usage scenarios. For robust model ranking, we employ the\nBradley-Terry model augmented with two key innovations: (1) Placement Matches,\na cold-start mechanism to quickly estimate initial ratings for newly integrated\nmodels, and (2) Proximity Sampling, an intelligent comparison strategy that\nprioritizes battles between models of similar capabilities to maximize\ninformation gain and enhance rating stability. Extensive empirical analyses and\nsimulations demonstrate that Inclusion Arena yields reliable and stable\nrankings, exhibits higher data transitivity compared to general crowdsourced\ndatasets, and significantly mitigates the risk of malicious manipulation. By\nfostering an open alliance between foundation models and real-world\napplications, Inclusion Arena aims to accelerate the development of LLMs and\nMLLMs truly optimized for practical, user-centric deployments. The platform is\npublicly accessible at https://doraemon.alipay.com/model-ranking.",
        "url": "http://arxiv.org/abs/2508.11452v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11452v1",
        "arxiv_id": "2508.11452v1",
        "authors": [
            "Kangyu Wang",
            "Hongliang He",
            "Lin Liu",
            "Ruiqi Liang",
            "Zhenzhong Lan",
            "Jianguo Li"
        ],
        "submitted": "2025-08-15 13:00:07",
        "source": "arxiv",
        "comment": "Our platform is publicly accessible at\n  https://doraemon.alipay.com/model-ranking",
        "score": 7,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'pairwise' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on evaluating large language models and multimodal large language models, which is not directly related to information retrieval, search technologies, or query understanding. The paper's emphasis on real-world applications and user-centric deployments is also not aligned with the user's research interests."
    },
    {
        "title": "HumorPlanSearch: Structured Planning and HuCoT for Contextual AI Humor",
        "abstract": "Automated humor generation with Large Language Models (LLMs) often yields\njokes that feel generic, repetitive, or tone-deaf because humor is deeply\nsituated and hinges on the listener's cultural background, mindset, and\nimmediate context. We introduce HumorPlanSearch, a modular pipeline that\nexplicitly models context through: (1) Plan-Search for diverse, topic-tailored\nstrategies; (2) Humor Chain-of-Thought (HuCoT) templates capturing cultural and\nstylistic reasoning; (3) a Knowledge Graph to retrieve and adapt\nhigh-performing historical strategies; (4) novelty filtering via semantic\nembeddings; and (5) an iterative judge-driven revision loop. To evaluate\ncontext sensitivity and comedic quality, we propose the Humor Generation Score\n(HGS), which fuses direct ratings, multi-persona feedback, pairwise win-rates,\nand topic relevance. In experiments across nine topics with feedback from 13\nhuman judges, our full pipeline (KG + Revision) boosts mean HGS by 15.4 percent\n(p < 0.05) over a strong baseline. By foregrounding context at every stage from\nstrategy planning to multi-signal evaluation, HumorPlanSearch advances\nAI-driven humor toward more coherent, adaptive, and culturally attuned comedy.",
        "url": "http://arxiv.org/abs/2508.11429v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11429v1",
        "arxiv_id": "2508.11429v1",
        "authors": [
            "Shivam Dubey"
        ],
        "submitted": "2025-08-15 12:07:56",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on humor generation using Large Language Models, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions context modeling, it is not applicable to the user's interests in IR and NLP."
    },
    {
        "title": "Hybrid-Hierarchical Fashion Graph Attention Network for Compatibility-Oriented and Personalized Outfit Recommendation",
        "abstract": "The rapid expansion of the fashion industry and the growing variety of\nproducts have made it challenging for users to find compatible items on\ne-commerce platforms. Effective fashion recommendation systems are crucial for\nfiltering irrelevant items and suggesting suitable ones. However,\nsimultaneously addressing outfit compatibility and personalized recommendations\nremains a significant challenge, as these aspects are often treated\nindependently in existing studies, often overlooking the complex interactions\nbetween items and user preferences. This research introduces a new framework\nnamed FGAT, inspired by the HFGN model, which leverages graph neural networks\nand graph attention mechanisms to tackle this issue. The proposed framework\nconstructs a three-tier hierarchical graph of users, outfits, and items,\nintegrating visual and textual features to simultaneously model outfit\ncompatibility and user preferences. A graph attention mechanism dynamically\nweights node importance during representation propagation, enabling the capture\nof key interactions and generating precise representations for both user\npreferences and outfit compatibility. Evaluated on the POG dataset, FGAT\noutperforms baseline models such as HFGN, achieving improved results in\nprecision, HR, recall, NDCG, and accuracy.These results demonstrate that\ncombining multimodal visual-textual features with a hierarchical graph\nstructure and attention mechanisms significantly enhances the accuracy and\nefficiency of personalized fashion recommendation systems.",
        "url": "http://arxiv.org/abs/2508.11105v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11105v1",
        "arxiv_id": "2508.11105v1",
        "authors": [
            "Sajjad Saed",
            "Babak Teimourpour"
        ],
        "submitted": "2025-08-14 23:09:57",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on personalized outfit recommendation, which is somewhat related to my interests in Information Retrieval and Search technologies. However, the approach is more geared towards recommender systems and does not directly address query understanding, ranking models, or user behavior modeling, which are my primary research areas."
    },
    {
        "title": "LLM Compression: How Far Can We Go in Balancing Size and Performance?",
        "abstract": "Quantization is an essential and popular technique for improving the\naccessibility of large language models (LLMs) by reducing memory usage and\ncomputational costs while maintaining performance. In this study, we apply\n4-bit Group Scaling Quantization (GSQ) and Generative Pretrained Transformer\nQuantization (GPTQ) to LLaMA 1B, Qwen 0.5B, and PHI 1.5B, evaluating their\nimpact across multiple NLP tasks. We benchmark these models on MS MARCO\n(Information Retrieval), BoolQ (Boolean Question Answering), and GSM8K\n(Mathematical Reasoning) datasets, assessing both accuracy and efficiency\nacross various tasks. The study measures the trade-offs between model\ncompression and task performance, analyzing key evaluation metrics, namely\naccuracy, inference latency, and throughput (total output tokens generated per\nsecond), providing insights into the suitability of low-bit quantization for\nreal-world deployment. Using the results, users can then make suitable\ndecisions based on the specifications that need to be met. We discuss the pros\nand cons of GSQ and GPTQ techniques on models of different sizes, which also\nserve as a benchmark for future experiments.",
        "url": "http://arxiv.org/abs/2508.11318v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11318v1",
        "arxiv_id": "2508.11318v1",
        "authors": [
            "Sahil Sk",
            "Debasish Dhal",
            "Sonal Khosla",
            "Sk Shahid",
            "Sambit Shekhar",
            "Akash Dhaka",
            "Shantipriya Parida",
            "Dilip K. Prasad",
            "Ondřej Bojar"
        ],
        "submitted": "2025-08-15 08:41:20",
        "source": "arxiv",
        "comment": "This paper has been accepted for presentation at the RANLP 2025\n  conference",
        "score": 5,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses model compression techniques for large language models, which is related to information retrieval and search technologies. However, the focus is on NLP tasks and model performance, rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user."
    },
    {
        "title": "AI in Mental Health: Emotional and Sentiment Analysis of Large Language Models' Responses to Depression, Anxiety, and Stress Queries",
        "abstract": "Depression, anxiety, and stress are widespread mental health concerns that\nincreasingly drive individuals to seek information from Large Language Models\n(LLMs). This study investigates how eight LLMs (Claude Sonnet, Copilot, Gemini\nPro, GPT-4o, GPT-4o mini, Llama, Mixtral, and Perplexity) reply to twenty\npragmatic questions about depression, anxiety, and stress when those questions\nare framed for six user profiles (baseline, woman, man, young, old, and\nuniversity student). The models generated 2,880 answers, which we scored for\nsentiment and emotions using state-of-the-art tools. Our analysis revealed that\noptimism, fear, and sadness dominated the emotional landscape across all\noutputs, with neutral sentiment maintaining consistently high values.\nGratitude, joy, and trust appeared at moderate levels, while emotions such as\nanger, disgust, and love were rarely expressed. The choice of LLM significantly\ninfluenced emotional expression patterns. Mixtral exhibited the highest levels\nof negative emotions including disapproval, annoyance, and sadness, while Llama\ndemonstrated the most optimistic and joyful responses. The type of mental\nhealth condition dramatically shaped emotional responses: anxiety prompts\nelicited extraordinarily high fear scores (0.974), depression prompts generated\nelevated sadness (0.686) and the highest negative sentiment, while\nstress-related queries produced the most optimistic responses (0.755) with\nelevated joy and trust. In contrast, demographic framing of queries produced\nonly marginal variations in emotional tone. Statistical analyses confirmed\nsignificant model-specific and condition-specific differences, while\ndemographic influences remained minimal. These findings highlight the critical\nimportance of model selection in mental health applications, as each LLM\nexhibits a distinct emotional signature that could significantly impact user\nexperience and outcomes.",
        "url": "http://arxiv.org/abs/2508.11285v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11285v1",
        "arxiv_id": "2508.11285v1",
        "authors": [
            "Arya VarastehNezhad",
            "Reza Tavasoli",
            "Soroush Elyasi",
            "MohammadHossein LotfiNia",
            "Hamed Farbeh"
        ],
        "submitted": "2025-08-15 07:47:10",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on the emotional and sentiment analysis of Large Language Models' responses to depression, anxiety, and stress queries, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on mental health applications and emotional signatures of language models is also outside the user's primary focus."
    },
    {
        "title": "ORFuzz: Fuzzing the \"Other Side\" of LLM Safety -- Testing Over-Refusal",
        "abstract": "Large Language Models (LLMs) increasingly exhibit over-refusal - erroneously\nrejecting benign queries due to overly conservative safety measures - a\ncritical functional flaw that undermines their reliability and usability.\nCurrent methods for testing this behavior are demonstrably inadequate,\nsuffering from flawed benchmarks and limited test generation capabilities, as\nhighlighted by our empirical user study. To the best of our knowledge, this\npaper introduces the first evolutionary testing framework, ORFuzz, for the\nsystematic detection and analysis of LLM over-refusals. ORFuzz uniquely\nintegrates three core components: (1) safety category-aware seed selection for\ncomprehensive test coverage, (2) adaptive mutator optimization using reasoning\nLLMs to generate effective test cases, and (3) OR-Judge, a human-aligned judge\nmodel validated to accurately reflect user perception of toxicity and refusal.\nOur extensive evaluations demonstrate that ORFuzz generates diverse, validated\nover-refusal instances at a rate (6.98% average) more than double that of\nleading baselines, effectively uncovering vulnerabilities. Furthermore,\nORFuzz's outputs form the basis of ORFuzzSet, a new benchmark of 1,855 highly\ntransferable test cases that achieves a superior 63.56% average over-refusal\nrate across 10 diverse LLMs, significantly outperforming existing datasets.\nORFuzz and ORFuzzSet provide a robust automated testing framework and a\nvaluable community resource, paving the way for developing more reliable and\ntrustworthy LLM-based software systems.",
        "url": "http://arxiv.org/abs/2508.11222v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11222v1",
        "arxiv_id": "2508.11222v1",
        "authors": [
            "Haonan Zhang",
            "Dongxia Wang",
            "Yi Liu",
            "Kexin Chen",
            "Jiashui Wang",
            "Xinlei Ying",
            "Long Liu",
            "Wenhai Wang"
        ],
        "submitted": "2025-08-15 05:03:26",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on testing the reliability and usability of Large Language Models (LLMs) by detecting over-refusal behavior, which is not directly related to my research interests in Information Retrieval, Search technologies, and query understanding. While it touches on NLP, the specific application and methodology are not aligned with my primary focus on deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Expressive Speech Retrieval using Natural Language Descriptions of Speaking Style",
        "abstract": "We introduce the task of expressive speech retrieval, where the goal is to\nretrieve speech utterances spoken in a given style based on a natural language\ndescription of that style. While prior work has primarily focused on performing\nspeech retrieval based on what was said in an utterance, we aim to do so based\non how something was said. We train speech and text encoders to embed speech\nand text descriptions of speaking styles into a joint latent space, which\nenables using free-form text prompts describing emotions or styles as queries\nto retrieve matching expressive speech segments. We perform detailed analyses\nof various aspects of our proposed framework, including encoder architectures,\ntraining criteria for effective cross-modal alignment, and prompt augmentation\nfor improved generalization to arbitrary text queries. Experiments on multiple\ndatasets encompassing 22 speaking styles demonstrate that our approach achieves\nstrong retrieval performance as measured by Recall@k.",
        "url": "http://arxiv.org/abs/2508.11187v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11187v1",
        "arxiv_id": "2508.11187v1",
        "authors": [
            "Wonjune Kang",
            "Deb Roy"
        ],
        "submitted": "2025-08-15 03:38:21",
        "source": "arxiv",
        "comment": "Accepted to ASRU 2025",
        "score": 5,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper's focus on expressive speech retrieval using natural language descriptions of speaking style is somewhat related to information retrieval, but it does not directly align with the user's interests in query understanding, ranking models, and user behavior modeling. While the paper explores cross-modal alignment and prompt augmentation, it does not specifically address ranking models or user behavior modeling, making it only loosely relevant to the user's research themes."
    },
    {
        "title": "SGSimEval: A Comprehensive Multifaceted and Similarity-Enhanced Benchmark for Automatic Survey Generation Systems",
        "abstract": "The growing interest in automatic survey generation (ASG), a task that\ntraditionally required considerable time and effort, has been spurred by recent\nadvances in large language models (LLMs). With advancements in\nretrieval-augmented generation (RAG) and the rising popularity of multi-agent\nsystems (MASs), synthesizing academic surveys using LLMs has become a viable\napproach, thereby elevating the need for robust evaluation methods in this\ndomain. However, existing evaluation methods suffer from several limitations,\nincluding biased metrics, a lack of human preference, and an over-reliance on\nLLMs-as-judges. To address these challenges, we propose SGSimEval, a\ncomprehensive benchmark for Survey Generation with Similarity-Enhanced\nEvaluation that evaluates automatic survey generation systems by integrating\nassessments of the outline, content, and references, and also combines\nLLM-based scoring with quantitative metrics to provide a multifaceted\nevaluation framework. In SGSimEval, we also introduce human preference metrics\nthat emphasize both inherent quality and similarity to humans. Extensive\nexperiments reveal that current ASG systems demonstrate human-comparable\nsuperiority in outline generation, while showing significant room for\nimprovement in content and reference generation, and our evaluation metrics\nmaintain strong consistency with human assessments.",
        "url": "http://arxiv.org/abs/2508.11310v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11310v1",
        "arxiv_id": "2508.11310v1",
        "authors": [
            "Beichen Guo",
            "Zhiyuan Wen",
            "Yu Yang",
            "Peng Gao",
            "Ruosong Yang",
            "Jiaxing Shen"
        ],
        "submitted": "2025-08-15 08:27:58",
        "source": "arxiv",
        "comment": "Accepted to The 21st International Conference on Advanced Data Mining\n  and Applications (ADMA2025)",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on automatic survey generation, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions large language models, which are relevant to NLP, the paper's primary focus is on evaluation methods for survey generation, which is not a central match for the user's research interests."
    },
    {
        "title": "Cross-Granularity Hypergraph Retrieval-Augmented Generation for Multi-hop Question Answering",
        "abstract": "Multi-hop question answering (MHQA) requires integrating knowledge scattered\nacross multiple passages to derive the correct answer. Traditional\nretrieval-augmented generation (RAG) methods primarily focus on coarse-grained\ntextual semantic similarity and ignore structural associations among dispersed\nknowledge, which limits their effectiveness in MHQA tasks. GraphRAG methods\naddress this by leveraging knowledge graphs (KGs) to capture structural\nassociations, but they tend to overly rely on structural information and\nfine-grained word- or phrase-level retrieval, resulting in an underutilization\nof textual semantics. In this paper, we propose a novel RAG approach called\nHGRAG for MHQA that achieves cross-granularity integration of structural and\nsemantic information via hypergraphs. Structurally, we construct an entity\nhypergraph where fine-grained entities serve as nodes and coarse-grained\npassages as hyperedges, and establish knowledge association through shared\nentities. Semantically, we design a hypergraph retrieval method that integrates\nfine-grained entity similarity and coarse-grained passage similarity via\nhypergraph diffusion. Finally, we employ a retrieval enhancement module, which\nfurther refines the retrieved results both semantically and structurally, to\nobtain the most relevant passages as context for answer generation with the\nLLM. Experimental results on benchmark datasets demonstrate that our approach\noutperforms state-of-the-art methods in QA performance, and achieves a\n6$\\times$ speedup in retrieval efficiency.",
        "url": "http://arxiv.org/abs/2508.11247v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11247v1",
        "arxiv_id": "2508.11247v1",
        "authors": [
            "Changjian Wang",
            "Weihong Deng",
            "Weili Guan",
            "Quan Lu",
            "Ning Jiang"
        ],
        "submitted": "2025-08-15 06:36:13",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a novel approach for multi-hop question answering, leveraging hypergraphs to integrate structural and semantic information. While it touches on retrieval and generation, the focus is on question answering and knowledge graph-based methods, which are not directly related to my core research interests in information retrieval, search technologies, and query understanding."
    },
    {
        "title": "RAG for Geoscience: What We Expect, Gaps and Opportunities",
        "abstract": "Retrieval-Augmented Generation (RAG) enhances language models by combining\nretrieval with generation. However, its current workflow remains largely\ntext-centric, limiting its applicability in geoscience. Many geoscientific\ntasks are inherently evidence-hungry. Typical examples involve imputing missing\nobservations using analog scenes, retrieving equations and parameters to\ncalibrate models, geolocating field photos based on visual cues, or surfacing\nhistorical case studies to support policy analyses. A simple\n``retrieve-then-generate'' pipeline is insufficient for these needs. We\nenvision Geo-RAG, a next-generation paradigm that reimagines RAG as a modular\nretrieve $\\rightarrow$ reason $\\rightarrow$ generate $\\rightarrow$ verify loop.\nGeo-RAG supports four core capabilities: (i) retrieval of multi-modal Earth\ndata; (ii) reasoning under physical and domain constraints; (iii) generation of\nscience-grade artifacts; and (iv) verification of generated hypotheses against\nnumerical models, ground measurements, and expert assessments. This shift opens\nnew opportunities for more trustworthy and transparent geoscience workflows.",
        "url": "http://arxiv.org/abs/2508.11246v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11246v1",
        "arxiv_id": "2508.11246v1",
        "authors": [
            "Runlong Yu",
            "Shiyuan Luo",
            "Rahul Ghosh",
            "Lingyao Li",
            "Yiqun Xie",
            "Xiaowei Jia"
        ],
        "submitted": "2025-08-15 06:33:27",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper discusses Retrieval-Augmented Generation (RAG) in the context of geoscience, which is unrelated to the user's primary focus on Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on retrieval and generation, the domain and application are distinct from the user's interests."
    },
    {
        "title": "MobQA: A Benchmark Dataset for Semantic Understanding of Human Mobility Data through Question Answering",
        "abstract": "This paper presents MobQA, a benchmark dataset designed to evaluate the\nsemantic understanding capabilities of large language models (LLMs) for human\nmobility data through natural language question answering.\n  While existing models excel at predicting human movement patterns, it remains\nunobvious how much they can interpret the underlying reasons or semantic\nmeaning of those patterns. MobQA provides a comprehensive evaluation framework\nfor LLMs to answer questions about diverse human GPS trajectories spanning\ndaily to weekly granularities. It comprises 5,800 high-quality question-answer\npairs across three complementary question types: factual retrieval (precise\ndata extraction), multiple-choice reasoning (semantic inference), and free-form\nexplanation (interpretive description), which all require spatial, temporal,\nand semantic reasoning. Our evaluation of major LLMs reveals strong performance\non factual retrieval but significant limitations in semantic reasoning and\nexplanation question answering, with trajectory length substantially impacting\nmodel effectiveness. These findings demonstrate the achievements and\nlimitations of state-of-the-art LLMs for semantic mobility\nunderstanding.\\footnote{MobQA dataset is available at\nhttps://github.com/CyberAgentAILab/mobqa.}",
        "url": "http://arxiv.org/abs/2508.11163v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11163v1",
        "arxiv_id": "2508.11163v1",
        "authors": [
            "Hikaru Asano",
            "Hiroki Ouchi",
            "Akira Kasuga",
            "Ryo Yonetani"
        ],
        "submitted": "2025-08-15 02:30:20",
        "source": "arxiv",
        "comment": "23 pages, 12 figures",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a benchmark dataset for evaluating the semantic understanding of human mobility data through question answering, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on natural language processing, the focus is on large language models and their capabilities for interpreting human movement patterns, which is not a primary interest area for you."
    },
    {
        "title": "AgentMental: An Interactive Multi-Agent Framework for Explainable and Adaptive Mental Health Assessment",
        "abstract": "Mental health assessment is crucial for early intervention and effective\ntreatment, yet traditional clinician-based approaches are limited by the\nshortage of qualified professionals. Recent advances in artificial intelligence\nhave sparked growing interest in automated psychological assessment, yet most\nexisting approaches are constrained by their reliance on static text analysis,\nlimiting their ability to capture deeper and more informative insights that\nemerge through dynamic interaction and iterative questioning. Therefore, in\nthis paper, we propose a multi-agent framework for mental health evaluation\nthat simulates clinical doctor-patient dialogues, with specialized agents\nassigned to questioning, adequacy evaluation, scoring, and updating. We\nintroduce an adaptive questioning mechanism in which an evaluation agent\nassesses the adequacy of user responses to determine the necessity of\ngenerating targeted follow-up queries to address ambiguity and missing\ninformation. Additionally, we employ a tree-structured memory in which the root\nnode encodes the user's basic information, while child nodes (e.g., topic and\nstatement) organize key information according to distinct symptom categories\nand interaction turns. This memory is dynamically updated throughout the\ninteraction to reduce redundant questioning and further enhance the information\nextraction and contextual tracking capabilities. Experimental results on the\nDAIC-WOZ dataset illustrate the effectiveness of our proposed method, which\nachieves better performance than existing approaches.",
        "url": "http://arxiv.org/abs/2508.11567v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11567v1",
        "arxiv_id": "2508.11567v1",
        "authors": [
            "Jinpeng Hu",
            "Ao Wang",
            "Qianqian Xie",
            "Hui Ma",
            "Zhuo Li",
            "Dan Guo"
        ],
        "submitted": "2025-08-15 16:20:45",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a multi-agent framework for mental health assessment, which involves dynamic interaction and iterative questioning. While it employs some relevant concepts like adaptive questioning and memory updating, the focus is on mental health assessment rather than information retrieval or search technologies. The paper's connection to the user's interests is limited to the use of questioning and memory updating, which are also relevant in IR and NLP, but the overall topic and approach are not directly aligned with the user's research themes."
    },
    {
        "title": "Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training",
        "abstract": "We propose an end-to-end differentiable training paradigm for stable training\nof a rationalized transformer classifier. Our approach results in a single\nmodel that simultaneously classifies a sample and scores input tokens based on\ntheir relevance to the classification. To this end, we build on the widely-used\nthree-player-game for training rationalized models, which typically relies on\ntraining a rationale selector, a classifier and a complement classifier. We\nsimplify this approach by making a single model fulfill all three roles,\nleading to a more efficient training paradigm that is not susceptible to the\ncommon training instabilities that plague existing approaches. Further, we\nextend this paradigm to produce class-wise rationales while incorporating\nrecent advances in parameterizing and regularizing the resulting rationales,\nthus leading to substantially improved and state-of-the-art alignment with\nhuman annotations without any explicit supervision.",
        "url": "http://arxiv.org/abs/2508.11393v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11393v1",
        "arxiv_id": "2508.11393v1",
        "authors": [
            "Marc Brinner",
            "Sina Zarrieß"
        ],
        "submitted": "2025-08-15 10:51:58",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on rationalizing transformer predictions, which is related to query understanding and ranking models. However, the context is more focused on NLP and classification, rather than information retrieval and search technologies. The paper's emphasis on rationalized models and class-wise rationales is not directly applicable to my research interests."
    },
    {
        "title": "Personalized Distractor Generation via MCTS-Guided Reasoning Reconstruction",
        "abstract": "Distractors, incorrect but plausible answer choices in multiple-choice\nquestions (MCQs), play a critical role in educational assessment by diagnosing\nstudent misconceptions. Recent work has leveraged large language models (LLMs)\nto generate shared, group-level distractors by learning common error patterns\nacross large student populations. However, such distractors often fail to\ncapture the diverse reasoning errors of individual students, limiting their\ndiagnostic effectiveness. To address this limitation, we introduce the task of\npersonalized distractor generation, which aims to generate tailored distractors\nbased on individual misconceptions inferred from each student's past\nquestion-answering (QA) records, ensuring every student receives options that\neffectively exposes their specific reasoning errors. While promising, this task\nis challenging because each student typically has only a few QA records, which\noften lack the student's underlying reasoning processes, making training-based\ngroup-level approaches infeasible. To overcome this, we propose a training-free\ntwo-stage framework. In the first stage, we construct a student-specific\nmisconception prototype by applying Monte Carlo Tree Search (MCTS) to recover\nthe student's reasoning trajectories from past incorrect answers. In the second\nstage, this prototype guides the simulation of the student's reasoning on new\nquestions, enabling the generation of personalized distractors that align with\nthe student's recurring misconceptions. Experiments show that our approach\nachieves the best performance in generating plausible, personalized distractors\nfor 140 students, and also effectively generalizes to group-level settings,\nhighlighting its robustness and adaptability.",
        "url": "http://arxiv.org/abs/2508.11184v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11184v1",
        "arxiv_id": "2508.11184v1",
        "authors": [
            "Tao Wu",
            "Jingyuan Chen",
            "Wang Lin",
            "Jian Zhan",
            "Mengze Li",
            "Kun Kuang",
            "Fei Wu"
        ],
        "submitted": "2025-08-15 03:20:37",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on personalized distractor generation for educational assessment, using Monte Carlo Tree Search and reasoning reconstruction. While it involves some NLP and data mining aspects, the primary goal is not information retrieval or search, and the techniques are not directly applicable to query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "A Cross-Modal Rumor Detection Scheme via Contrastive Learning by Exploring Text and Image internal Correlations",
        "abstract": "Existing rumor detection methods often neglect the content within images as\nwell as the inherent relationships between contexts and images across different\nvisual scales, thereby resulting in the loss of critical information pertinent\nto rumor identification. To address these issues, this paper presents a novel\ncross-modal rumor detection scheme based on contrastive learning, namely the\nMulti-scale Image and Context Correlation exploration algorithm (MICC).\nSpecifically, we design an SCLIP encoder to generate unified semantic\nembeddings for text and multi-scale image patches through contrastive\npretraining, enabling their relevance to be measured via dot-product\nsimilarity. Building upon this, a Cross-Modal Multi-Scale Alignment module is\nintroduced to identify image regions most relevant to the textual semantics,\nguided by mutual information maximization and the information bottleneck\nprinciple, through a Top-K selection strategy based on a cross-modal relevance\nmatrix constructed between the text and multi-scale image patches. Moreover, a\nscale-aware fusion network is designed to integrate the highly correlated\nmulti-scale image features with global text features by assigning adaptive\nweights to image regions based on their semantic importance and cross-modal\nrelevance. The proposed methodology has been extensively evaluated on two\nreal-world datasets. The experimental results demonstrate that it achieves a\nsubstantial performance improvement over existing state-of-the-art approaches\nin rumor detection, highlighting its effectiveness and potential for practical\napplications.",
        "url": "http://arxiv.org/abs/2508.11141v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11141v1",
        "arxiv_id": "2508.11141v1",
        "authors": [
            "Bin Ma",
            "Yifei Zhang",
            "Yongjin Xian",
            "Qi Li",
            "Linna Zhou",
            "Gongxun Miao"
        ],
        "submitted": "2025-08-15 01:13:50",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on cross-modal rumor detection using contrastive learning, which is not directly related to information retrieval, search technologies, or query understanding. While it involves text and image processing, the primary goal is not to improve search or ranking models, but rather to detect rumors, which is outside the scope of the user's research interests."
    },
    {
        "title": "MoNaCo: More Natural and Complex Questions for Reasoning Across Dozens of Documents",
        "abstract": "Large language models (LLMs) are emerging as a go-to tool for querying\ninformation. However, current LLM benchmarks rarely feature natural questions\nthat are both information-seeking as well as genuinely time-consuming for\nhumans. To address this gap we introduce MoNaCo, a benchmark of 1,315 natural\nand complex questions that require dozens, and at times hundreds, of\nintermediate steps to solve -- far more than any existing QA benchmark. To\nbuild MoNaCo, we developed a decomposed annotation pipeline to elicit and\nmanually answer natural time-consuming questions at scale. Frontier LLMs\nevaluated on MoNaCo achieve at most 61.2% F1, hampered by low recall and\nhallucinations. Our results underscore the need for reasoning models that\nbetter handle the complexity and sheer breadth of real-world\ninformation-seeking questions -- with MoNaCo providing an effective resource\nfor tracking such progress. The MONACO benchmark, codebase, prompts and models\npredictions are publicly available at: https://tomerwolgithub.github.io/monaco",
        "url": "http://arxiv.org/abs/2508.11133v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11133v1",
        "arxiv_id": "2508.11133v1",
        "authors": [
            "Tomer Wolfson",
            "Harsh Trivedi",
            "Mor Geva",
            "Yoav Goldberg",
            "Dan Roth",
            "Tushar Khot",
            "Ashish Sabharwal",
            "Reut Tsarfaty"
        ],
        "submitted": "2025-08-15 00:58:10",
        "source": "arxiv",
        "comment": "Accepted for publication in Transactions of the Association for\n  Computational Linguistics (TACL), 2025. Authors pre-print",
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper introduces a new benchmark for natural language processing, focusing on complex and time-consuming questions. While it touches on query understanding and information retrieval, the primary focus is on language models and question answering, which is not directly related to my research interests in search technologies and ranking models."
    },
    {
        "title": "Towards Reliable Multi-Agent Systems for Marketing Applications via Reflection, Memory, and Planning",
        "abstract": "Recent advances in large language models (LLMs) enabled the development of AI\nagents that can plan and interact with tools to complete complex tasks.\nHowever, literature on their reliability in real-world applications remains\nlimited. In this paper, we introduce a multi-agent framework for a marketing\ntask: audience curation. To solve this, we introduce a framework called RAMP\nthat iteratively plans, calls tools, verifies the output, and generates\nsuggestions to improve the quality of the audience generated. Additionally, we\nequip the model with a long-term memory store, which is a knowledge base of\nclient-specific facts and past queries. Overall, we demonstrate the use of LLM\nplanning and memory, which increases accuracy by 28 percentage points on a set\nof 88 evaluation queries. Moreover, we show the impact of iterative\nverification and reflection on more ambiguous queries, showing progressively\nbetter recall (roughly +20 percentage points) with more verify/reflect\niterations on a smaller challenge set, and higher user satisfaction. Our\nresults provide practical insights for deploying reliable LLM-based systems in\ndynamic, industry-facing environments.",
        "url": "http://arxiv.org/abs/2508.11120v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11120v1",
        "arxiv_id": "2508.11120v1",
        "authors": [
            "Lorenzo Jaime Yu Flores",
            "Junyi Shen",
            "Xiaoyuan Gu"
        ],
        "submitted": "2025-08-14 23:52:39",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses the development of a multi-agent framework for marketing applications, leveraging large language models and long-term memory. While it touches on planning and verification, the focus is on marketing and audience curation, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "Relative Advantage Debiasing for Watch-Time Prediction in Short-Video Recommendation",
        "abstract": "Watch time is widely used as a proxy for user satisfaction in video\nrecommendation platforms. However, raw watch times are influenced by\nconfounding factors such as video duration, popularity, and individual user\nbehaviors, potentially distorting preference signals and resulting in biased\nrecommendation models. We propose a novel relative advantage debiasing\nframework that corrects watch time by comparing it to empirically derived\nreference distributions conditioned on user and item groups. This approach\nyields a quantile-based preference signal and introduces a two-stage\narchitecture that explicitly separates distribution estimation from preference\nlearning. Additionally, we present distributional embeddings to efficiently\nparameterize watch-time quantiles without requiring online sampling or storage\nof historical data. Both offline and online experiments demonstrate significant\nimprovements in recommendation accuracy and robustness compared to existing\nbaseline methods.",
        "url": "http://arxiv.org/abs/2508.11086v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11086v1",
        "arxiv_id": "2508.11086v1",
        "authors": [
            "Emily Liu",
            "Kuan Han",
            "Minfeng Zhan",
            "Bocheng Zhao",
            "Guanyu Mu",
            "Yang Song"
        ],
        "submitted": "2025-08-14 21:52:00",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on recommender systems, specifically video recommendation, which is related to the user's background in e-commerce. However, the topic is not directly aligned with the user's primary interests in Information Retrieval, query understanding, ranking models, and user behavior modeling. The paper's emphasis on debiasing watch-time prediction and distributional embeddings is not directly relevant to the user's research themes."
    },
    {
        "title": "Pretrained Conformers for Audio Fingerprinting and Retrieval",
        "abstract": "Conformers have shown great results in speech processing due to their ability\nto capture both local and global interactions. In this work, we utilize a\nself-supervised contrastive learning framework to train conformer-based\nencoders that are capable of generating unique embeddings for small segments of\naudio, generalizing well to previously unseen data. We achieve state-of-the-art\nresults for audio retrieval tasks while using only 3 seconds of audio to\ngenerate embeddings. Our models are almost completely immune to temporal\nmisalignments and achieve state-of-the-art results in cases of other audio\ndistortions such as noise, reverb or extreme temporal stretching. Code and\nmodels are made publicly available and the results are easy to reproduce as we\ntrain and test using popular and freely available datasets of different sizes.",
        "url": "http://arxiv.org/abs/2508.11609v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11609v1",
        "arxiv_id": "2508.11609v1",
        "authors": [
            "Kemal Altwlkany",
            "Elmedin Selmanovic",
            "Sead Delalic"
        ],
        "submitted": "2025-08-15 17:19:09",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on audio fingerprinting and retrieval using conformer-based encoders, which is not directly related to information retrieval, search technologies, or query understanding. While it involves deep learning and embeddings, the context is specific to audio processing and does not align with the user's primary research interests in IR and NLP."
    },
    {
        "title": "Representing Speech Through Autoregressive Prediction of Cochlear Tokens",
        "abstract": "We introduce AuriStream, a biologically inspired model for encoding speech\nvia a two-stage framework inspired by the human auditory processing hierarchy.\nThe first stage transforms raw audio into a time-frequency representation based\non the human cochlea, from which we extract discrete \\textbf{cochlear tokens}.\nThe second stage applies an autoregressive sequence model over the cochlear\ntokens. AuriStream learns meaningful phoneme and word representations, and\nstate-of-the-art lexical semantics. AuriStream shows competitive performance on\ndiverse downstream SUPERB speech tasks. Complementing AuriStream's strong\nrepresentational capabilities, it generates continuations of audio which can be\nvisualized in a spectrogram space and decoded back into audio, providing\ninsights into the model's predictions. In summary, we present a two-stage\nframework for speech representation learning to advance the development of more\nhuman-like models that efficiently handle a range of speech-based tasks.",
        "url": "http://arxiv.org/abs/2508.11598v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11598v1",
        "arxiv_id": "2508.11598v1",
        "authors": [
            "Greta Tuckute",
            "Klemen Kotar",
            "Evelina Fedorenko",
            "Daniel L. K. Yamins"
        ],
        "submitted": "2025-08-15 17:06:04",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on speech processing and representation learning, which is outside the scope of Information Retrieval and Search technologies. Although it uses sequence models, the context is not related to query understanding, ranking models, or user behavior modeling, making it irrelevant to the user's primary research interests."
    },
    {
        "title": "TrajSV: A Trajectory-based Model for Sports Video Representations and Applications",
        "abstract": "Sports analytics has received significant attention from both academia and\nindustry in recent years. Despite the growing interest and efforts in this\nfield, several issues remain unresolved, including (1) data unavailability, (2)\nlack of an effective trajectory-based framework, and (3) requirement for\nsufficient supervision labels. In this paper, we present TrajSV, a\ntrajectory-based framework that addresses various issues in existing studies.\nTrajSV comprises three components: data preprocessing, Clip Representation\nNetwork (CRNet), and Video Representation Network (VRNet). The data\npreprocessing module extracts player and ball trajectories from sports\nbroadcast videos. CRNet utilizes a trajectory-enhanced Transformer module to\nlearn clip representations based on these trajectories. Additionally, VRNet\nlearns video representations by aggregating clip representations and visual\nfeatures with an encoder-decoder architecture. Finally, a triple contrastive\nloss is introduced to optimize both video and clip representations in an\nunsupervised manner. The experiments are conducted on three broadcast video\ndatasets to verify the effectiveness of TrajSV for three types of sports (i.e.,\nsoccer, basketball, and volleyball) with three downstream applications (i.e.,\nsports video retrieval, action spotting, and video captioning). The results\ndemonstrate that TrajSV achieves state-of-the-art performance in sports video\nretrieval, showcasing a nearly 70% improvement. It outperforms baselines in\naction spotting, achieving state-of-the-art results in 9 out of 17 action\ncategories, and demonstrates a nearly 20% improvement in video captioning.\nAdditionally, we introduce a deployed system along with the three applications\nbased on TrajSV.",
        "url": "http://arxiv.org/abs/2508.11569v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11569v1",
        "arxiv_id": "2508.11569v1",
        "authors": [
            "Zheng Wang",
            "Shihao Xu",
            "Wei Shi"
        ],
        "submitted": "2025-08-15 16:23:36",
        "source": "arxiv",
        "comment": "This paper has been accepted by TCSVT",
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on sports video representations and applications, which is not directly related to information retrieval, search technologies, or query understanding. The techniques and models presented are specific to the sports analytics domain and do not align with the user's primary research interests in IR and NLP."
    },
    {
        "title": "SpecDetect: Simple, Fast, and Training-Free Detection of LLM-Generated Text via Spectral Analysis",
        "abstract": "The proliferation of high-quality text from Large Language Models (LLMs)\ndemands reliable and efficient detection methods. While existing training-free\napproaches show promise, they often rely on surface-level statistics and\noverlook fundamental signal properties of the text generation process. In this\nwork, we reframe detection as a signal processing problem, introducing a novel\nparadigm that analyzes the sequence of token log-probabilities in the frequency\ndomain. By systematically analyzing the signal's spectral properties using the\nglobal Discrete Fourier Transform (DFT) and the local Short-Time Fourier\nTransform (STFT), we find that human-written text consistently exhibits\nsignificantly higher spectral energy. This higher energy reflects the\nlarger-amplitude fluctuations inherent in human writing compared to the\nsuppressed dynamics of LLM-generated text. Based on this key insight, we\nconstruct SpecDetect, a detector built on a single, robust feature from the\nglobal DFT: DFT total energy. We also propose an enhanced version,\nSpecDetect++, which incorporates a sampling discrepancy mechanism to further\nboost robustness. Extensive experiments demonstrate that our approach\noutperforms the state-of-the-art model while running in nearly half the time.\nOur work introduces a new, efficient, and interpretable pathway for\nLLM-generated text detection, showing that classical signal processing\ntechniques offer a surprisingly powerful solution to this modern challenge.",
        "url": "http://arxiv.org/abs/2508.11343v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11343v1",
        "arxiv_id": "2508.11343v1",
        "authors": [
            "Haitong Luo",
            "Weiyao Zhang",
            "Suhang Wang",
            "Wenji Zou",
            "Chungang Lin",
            "Xuying Meng",
            "Yujun Zhang"
        ],
        "submitted": "2025-08-15 09:13:42",
        "source": "arxiv",
        "comment": "Under Review",
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on detecting LLM-generated text, which is not directly related to information retrieval, search technologies, or query understanding. While it uses signal processing techniques, the application is specific to text detection and does not align with the user's primary research interests."
    },
    {
        "title": "Generalize across Homophily and Heterophily: Hybrid Spectral Graph Pre-Training and Prompt Tuning",
        "abstract": "Graph ``pre-training and prompt-tuning'' aligns downstream tasks with\npre-trained objectives to enable efficient knowledge transfer under limited\nsupervision. However, existing methods rely on homophily-based low-frequency\nknowledge, failing to handle diverse spectral distributions in real-world\ngraphs with varying homophily. Our theoretical analysis reveals a spectral\nspecificity principle: optimal knowledge transfer requires alignment between\npre-trained spectral filters and the intrinsic spectrum of downstream graphs.\nUnder limited supervision, large spectral gaps between pre-training and\ndownstream tasks impede effective adaptation. To bridge this gap, we propose\nthe HS-GPPT model, a novel framework that ensures spectral alignment throughout\nboth pre-training and prompt-tuning. We utilize a hybrid spectral filter\nbackbone and local-global contrastive learning to acquire abundant spectral\nknowledge. Then we design prompt graphs to align the spectral distribution with\npretexts, facilitating spectral knowledge transfer across homophily and\nheterophily. Extensive experiments validate the effectiveness under both\ntransductive and inductive learning settings. Our code is available at\nhttps://anonymous.4open.science/r/HS-GPPT-62D2/.",
        "url": "http://arxiv.org/abs/2508.11328v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11328v1",
        "arxiv_id": "2508.11328v1",
        "authors": [
            "Haitong Luo",
            "Suhang Wang",
            "Weiyao Zhang",
            "Ruiqi Meng",
            "Xuying Meng",
            "Yujun Zhang"
        ],
        "submitted": "2025-08-15 08:55:57",
        "source": "arxiv",
        "comment": "Under Review",
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on graph pre-training and prompt-tuning, which is not directly related to Information Retrieval, Search technologies, or Natural Language Processing. The concepts of homophily and heterophily are not relevant to query understanding, ranking models, or user behavior modeling, and the paper's emphasis on spectral graph theory and contrastive learning does not align with the user's research interests."
    },
    {
        "title": "LETToT: Label-Free Evaluation of Large Language Models On Tourism Using Expert Tree-of-Thought",
        "abstract": "Evaluating large language models (LLMs) in specific domain like tourism\nremains challenging due to the prohibitive cost of annotated benchmarks and\npersistent issues like hallucinations. We propose $\\textbf{L}$able-Free\n$\\textbf{E}$valuation of LLM on $\\textbf{T}$ourism using Expert\n$\\textbf{T}$ree-$\\textbf{o}$f-$\\textbf{T}$hought (LETToT), a framework that\nleverages expert-derived reasoning structures-instead of labeled data-to access\nLLMs in tourism. First, we iteratively refine and validate hierarchical ToT\ncomponents through alignment with generic quality dimensions and expert\nfeedback. Results demonstrate the effectiveness of our systematically optimized\nexpert ToT with 4.99-14.15\\% relative quality gains over baselines. Second, we\napply LETToT's optimized expert ToT to evaluate models of varying scales\n(32B-671B parameters), revealing: (1) Scaling laws persist in specialized\ndomains (DeepSeek-V3 leads), yet reasoning-enhanced smaller models (e.g.,\nDeepSeek-R1-Distill-Llama-70B) close this gap; (2) For sub-72B models, explicit\nreasoning architectures outperform counterparts in accuracy and conciseness\n($p<0.05$). Our work established a scalable, label-free paradigm for\ndomain-specific LLM evaluation, offering a robust alternative to conventional\nannotated benchmarks.",
        "url": "http://arxiv.org/abs/2508.11280v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11280v1",
        "arxiv_id": "2508.11280v1",
        "authors": [
            "Ruiyan Qi",
            "Congding Wen",
            "Weibo Zhou",
            "Shangsong Liang",
            "Lingbo Li"
        ],
        "submitted": "2025-08-15 07:37:12",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on evaluating large language models in the tourism domain, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on label-free evaluation and expert-derived reasoning structures is also not aligned with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Diffusion is a code repair operator and generator",
        "abstract": "Code diffusion models generate code by iteratively removing noise from the\nlatent representation of a code snippet. During later steps of the diffusion\nprocess, when the code snippet has almost converged, differences between\ndiscrete representations of these snippets look like last-mile repairs applied\nto broken or incomplete code. We evaluate the extent to which this resemblance\ncan be exploited to leverage pre-trained code diffusion models for the problem\nof last-mile repair by considering two applications with significant potential.\nFirst, we can leverage the diffusion model for last-mile repair by adding noise\nto a broken code snippet and resuming the diffusion process. Second, we can\nleverage the diffusion model to generate arbitrary amount of training data for\nlast-mile repair tasks (that are computationally more efficient) by sampling an\nintermediate program (input) and the final program (output) from the diffusion\nprocess. We perform experiments on 3 domains (Python, Excel and PowerShell) to\nevaluate applications, as well as analyze properties.",
        "url": "http://arxiv.org/abs/2508.11110v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11110v1",
        "arxiv_id": "2508.11110v1",
        "authors": [
            "Mukul Singh",
            "Gust Verbruggen",
            "Vu Le",
            "Sumit Gulwani"
        ],
        "submitted": "2025-08-14 23:27:09",
        "source": "arxiv",
        "comment": "12 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on code diffusion models and last-mile repair in the context of programming languages, which is outside the scope of Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "SproutBench: A Benchmark for Safe and Ethical Large Language Models for Youth",
        "abstract": "The rapid proliferation of large language models (LLMs) in applications\ntargeting children and adolescents necessitates a fundamental reassessment of\nprevailing AI safety frameworks, which are largely tailored to adult users and\nneglect the distinct developmental vulnerabilities of minors. This paper\nhighlights key deficiencies in existing LLM safety benchmarks, including their\ninadequate coverage of age-specific cognitive, emotional, and social risks\nspanning early childhood (ages 0--6), middle childhood (7--12), and adolescence\n(13--18). To bridge these gaps, we introduce SproutBench, an innovative\nevaluation suite comprising 1,283 developmentally grounded adversarial prompts\ndesigned to probe risks such as emotional dependency, privacy violations, and\nimitation of hazardous behaviors. Through rigorous empirical evaluation of 47\ndiverse LLMs, we uncover substantial safety vulnerabilities, corroborated by\nrobust inter-dimensional correlations (e.g., between Safety and Risk\nPrevention) and a notable inverse relationship between Interactivity and Age\nAppropriateness. These insights yield practical guidelines for advancing\nchild-centric AI design and deployment.",
        "url": "http://arxiv.org/abs/2508.11009v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11009v1",
        "arxiv_id": "2508.11009v1",
        "authors": [
            "Wenpeng Xing",
            "Lanyi Wei",
            "Haixiao Hu",
            "Rongchang Li",
            "Mohan Li",
            "Changting Lin",
            "Meng Han"
        ],
        "submitted": "2025-08-14 18:21:39",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on large language models for youth, AI safety, and child-centric AI design, which are outside your primary areas of interest."
    },
    {
        "title": "Improving Text Style Transfer using Masked Diffusion Language Models with Inference-time Scaling",
        "abstract": "Masked diffusion language models (MDMs) have recently gained traction as a\nviable generative framework for natural language. This can be attributed to its\nscalability and ease of training compared to other diffusion model paradigms\nfor discrete data, establishing itself as the state-of-the-art\nnon-autoregressive generator for discrete data. Diffusion models, in general,\nhave shown excellent ability to improve the generation quality by leveraging\ninference-time scaling either by increasing the number of denoising steps or by\nusing external verifiers on top of the outputs of each step to guide the\ngeneration. In this work, we propose a verifier-based inference-time scaling\nmethod that aids in finding a better candidate generation during the denoising\nprocess of the MDM. Our experiments demonstrate the application of MDMs for\nstandard text-style transfer tasks and establish MDMs as a better alternative\nto autoregressive language models. Additionally, we show that a simple\nsoft-value-based verifier setup for MDMs using off-the-shelf pre-trained\nembedding models leads to significant gains in generation quality even when\nused on top of typical classifier-free guidance setups in the existing\nliterature.",
        "url": "http://arxiv.org/abs/2508.10995v1",
        "pdf_url": "http://arxiv.org/pdf/2508.10995v1",
        "arxiv_id": "2508.10995v1",
        "authors": [
            "Tejomay Kishor Padole",
            "Suyash P Awate",
            "Pushpak Bhattacharyya"
        ],
        "submitted": "2025-08-14 18:01:22",
        "source": "arxiv",
        "comment": "Accepted as a main conference submission in the European Conference\n  on Artificial Intelligence (ECAI 2025)",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on text style transfer using masked diffusion language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on language models, the primary focus is on generative models rather than ranking models or user behavior modeling, making it only loosely relevant to the user's research interests."
    },
    {
        "title": "Controlling Multimodal LLMs via Reward-guided Decoding",
        "abstract": "As Multimodal Large Language Models (MLLMs) gain widespread applicability, it\nis becoming increasingly desirable to adapt them for diverse user needs. In\nthis paper, we study the adaptation of MLLMs through controlled decoding. To\nachieve this, we introduce the first method for reward-guided decoding of MLLMs\nand demonstrate its application in improving their visual grounding. Our method\ninvolves building reward models for visual grounding and using them to guide\nthe MLLM's decoding process. Concretely, we build two separate reward models to\nindependently control the degree of object precision and recall in the model's\noutput. Our approach enables on-the-fly controllability of an MLLM's inference\nprocess in two ways: first, by giving control over the relative importance of\neach reward function during decoding, allowing a user to dynamically trade off\nobject precision for recall in image captioning tasks; second, by giving\ncontrol over the breadth of the search during decoding, allowing the user to\ncontrol the trade-off between the amount of test-time compute and the degree of\nvisual grounding. We evaluate our method on standard object hallucination\nbenchmarks, showing that it provides significant controllability over MLLM\ninference, while consistently outperforming existing hallucination mitigation\nmethods.",
        "url": "http://arxiv.org/abs/2508.11616v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11616v1",
        "arxiv_id": "2508.11616v1",
        "authors": [
            "Oscar Mañas",
            "Pierluca D'Oro",
            "Koustuv Sinha",
            "Adriana Romero-Soriano",
            "Michal Drozdzal",
            "Aishwarya Agrawal"
        ],
        "submitted": "2025-08-15 17:29:06",
        "source": "arxiv",
        "comment": "Published at ICCV 2025",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores Multimodal Large Language Models (MLLMs) and controlled decoding, which is not directly related to Information Retrieval (IR) or Search technologies. While it touches on topics like relevance optimization, the focus is on visual grounding and object precision/recall, which is not a primary interest in IR. The paper's relevance to NLP and data mining is higher, but it does not specifically address query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Speciesism in AI: Evaluating Discrimination Against Animals in Large Language Models",
        "abstract": "As large language models (LLMs) become more widely deployed, it is crucial to\nexamine their ethical tendencies. Building on research on fairness and\ndiscrimination in AI, we investigate whether LLMs exhibit speciesist bias --\ndiscrimination based on species membership -- and how they value non-human\nanimals. We systematically examine this issue across three paradigms: (1)\nSpeciesismBench, a 1,003-item benchmark assessing recognition and moral\nevaluation of speciesist statements; (2) established psychological measures\ncomparing model responses with those of human participants; (3) text-generation\ntasks probing elaboration on, or resistance to, speciesist rationalizations. In\nour benchmark, LLMs reliably detected speciesist statements but rarely\ncondemned them, often treating speciesist attitudes as morally acceptable. On\npsychological measures, results were mixed: LLMs expressed slightly lower\nexplicit speciesism than people, yet in direct trade-offs they more often chose\nto save one human over multiple animals. A tentative interpretation is that\nLLMs may weight cognitive capacity rather than species per se: when capacities\nwere equal, they showed no species preference, and when an animal was described\nas more capable, they tended to prioritize it over a less capable human. In\nopen-ended text generation tasks, LLMs frequently normalized or rationalized\nharm toward farmed animals while refusing to do so for non-farmed animals.\nThese findings suggest that while LLMs reflect a mixture of progressive and\nmainstream human views, they nonetheless reproduce entrenched cultural norms\naround animal exploitation. We argue that expanding AI fairness and alignment\nframeworks to explicitly include non-human moral patients is essential for\nreducing these biases and preventing the entrenchment of speciesist attitudes\nin AI systems and the societies they influence.",
        "url": "http://arxiv.org/abs/2508.11534v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11534v1",
        "arxiv_id": "2508.11534v1",
        "authors": [
            "Monika Jotautaitė",
            "Lucius Caviola",
            "David A. Brewster",
            "Thilo Hagendorff"
        ],
        "submitted": "2025-08-15 15:22:00",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on the ethical implications of large language models in relation to animal species, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on fairness and alignment frameworks is also not a central concern for the user's research."
    },
    {
        "title": "When Algorithms Mirror Minds: A Confirmation-Aware Social Dynamic Model of Echo Chamber and Homogenization Traps",
        "abstract": "Recommender systems increasingly suffer from echo chambers and user\nhomogenization, systemic distortions arising from the dynamic interplay between\nalgorithmic recommendations and human behavior. While prior work has studied\nthese phenomena through the lens of algorithmic bias or social network\nstructure, we argue that the psychological mechanisms of users and the\nclosed-loop interaction between users and recommenders are critical yet\nunderstudied drivers of these emergent effects. To bridge this gap, we propose\nthe Confirmation-Aware Social Dynamic Model which incorporates user psychology\nand social relationships to simulate the actual user and recommender\ninteraction process. Our theoretical analysis proves that echo chambers and\nhomogenization traps, defined respectively as reduced recommendation diversity\nand homogenized user representations, will inevitably occur. We also conduct\nextensive empirical simulations on two real-world datasets and one synthetic\ndataset with five well-designed metrics, exploring the root factors influencing\nthe aforementioned phenomena from three level perspectives: the stochasticity\nand social integration degree of recommender (system-level), the psychological\nmechanisms of users (user-level), and the dataset scale (platform-level).\nFurthermore, we demonstrate four practical mitigation strategies that help\nalleviate echo chambers and user homogenization at the cost of some\nrecommendation accuracy. Our findings provide both theoretical and empirical\ninsights into the emergence and drivers of echo chambers and user\nhomogenization, as well as actionable guidelines for human-centered recommender\ndesign.",
        "url": "http://arxiv.org/abs/2508.11516v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11516v1",
        "arxiv_id": "2508.11516v1",
        "authors": [
            "Ming Tang",
            "Xiaowen Huang",
            "Jitao Sang"
        ],
        "submitted": "2025-08-15 14:55:55",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores echo chambers and homogenization in recommender systems, which is related to information retrieval and search technologies. However, the focus is on the psychological mechanisms of users and the closed-loop interaction between users and recommenders, which is not directly aligned with my interests in query understanding, ranking models, and user behavior modeling. The paper's relevance is somewhat related but not a central match."
    },
    {
        "title": "Reference Points in LLM Sentiment Analysis: The Role of Structured Context",
        "abstract": "Large language models (LLMs) are now widely used across many fields,\nincluding marketing research. Sentiment analysis, in particular, helps firms\nunderstand consumer preferences. While most NLP studies classify sentiment from\nreview text alone, marketing theories, such as prospect theory and\nexpectation--disconfirmation theory, point out that customer evaluations are\nshaped not only by the actual experience but also by additional reference\npoints. This study therefore investigates how the content and format of such\nsupplementary information affect sentiment analysis using LLMs. We compare\nnatural language (NL) and JSON-formatted prompts using a lightweight 3B\nparameter model suitable for practical marketing applications. Experiments on\ntwo Yelp categories (Restaurant and Nightlife) show that the JSON prompt with\nadditional information outperforms all baselines without fine-tuning: Macro-F1\nrises by 1.6% and 4% while RMSE falls by 16% and 9.1%, respectively, making it\ndeployable in resource-constrained edge devices. Furthermore, a follow-up\nanalysis confirms that performance gains stem from genuine contextual reasoning\nrather than label proxying. This work demonstrates that structured prompting\ncan enable smaller models to achieve competitive performance, offering a\npractical alternative to large-scale model deployment.",
        "url": "http://arxiv.org/abs/2508.11454v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11454v1",
        "arxiv_id": "2508.11454v1",
        "authors": [
            "Junichiro Niimi"
        ],
        "submitted": "2025-08-15 13:04:32",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores the role of structured context in sentiment analysis using Large Language Models (LLMs), which is related to query understanding and ranking models in Information Retrieval. However, the focus on sentiment analysis and marketing applications is not directly aligned with the user's primary research interests in Information Retrieval and Search technologies. The paper's relevance is somewhat related, but not a central match."
    },
    {
        "title": "Feedback Indicators: The Alignment between Llama and a Teacher in Language Learning",
        "abstract": "Automated feedback generation has the potential to enhance students' learning\nprogress by providing timely and targeted feedback. Moreover, it can assist\nteachers in optimizing their time, allowing them to focus on more strategic and\npersonalized aspects of teaching. To generate high-quality, information-rich\nformative feedback, it is essential first to extract relevant indicators, as\nthese serve as the foundation upon which the feedback is constructed. Teachers\noften employ feedback criteria grids composed of various indicators that they\nevaluate systematically. This study examines the initial phase of extracting\nsuch indicators from students' submissions of a language learning course using\nthe large language model Llama 3.1. Accordingly, the alignment between\nindicators generated by the LLM and human ratings across various feedback\ncriteria is investigated. The findings demonstrate statistically significant\nstrong correlations, even in cases involving unanticipated combinations of\nindicators and criteria. The methodology employed in this paper offers a\npromising foundation for extracting indicators from students' submissions using\nLLMs. Such indicators can potentially be utilized to auto-generate explainable\nand transparent formative feedback in future research.",
        "url": "http://arxiv.org/abs/2508.11364v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11364v1",
        "arxiv_id": "2508.11364v1",
        "authors": [
            "Sylvio Rüdian",
            "Yassin Elsir",
            "Marvin Kretschmer",
            "Sabine Cayrou",
            "Niels Pinkwart"
        ],
        "submitted": "2025-08-15 09:59:22",
        "source": "arxiv",
        "comment": "11 pages, one table",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it involves language models, the focus is on extracting indicators for language learning feedback, which is not a core area of interest for you."
    },
    {
        "title": "Mitigating Filter Bubble from the Perspective of Community Detection: A Universal Framework",
        "abstract": "In recent years, recommender systems have primarily focused on improving\naccuracy at the expense of diversity, which exacerbates the well-known filter\nbubble effect. This paper proposes a universal framework called CD-CGCN to\naddress the filter bubble issue in recommender systems from a community\ndetection perspective. By analyzing user-item interaction histories with a\ncommunity detection algorithm, we reveal that state-of-the-art recommendations\noften focus on intra-community items, worsening the filter bubble effect.\nCD-CGCN, a model-agnostic framework, integrates a Conditional Discriminator and\na Community-reweighted Graph Convolutional Network which can be plugged into\nmost recommender models. Using adversarial learning based on community labels,\nit counteracts the extracted community attributes and incorporates an inference\nstrategy tailored to the user's specific filter bubble state. Extensive\nexperiments on real-world datasets with multiple base models validate its\neffectiveness in mitigating filter bubbles while preserving recommendation\nquality. Additionally, by applying community debiasing to the original test set\nto construct an unbiased test set, we observe that CD-CGCN demonstrates\nsuperior performance in capturing users' inter-community preferences.",
        "url": "http://arxiv.org/abs/2508.11239v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11239v1",
        "arxiv_id": "2508.11239v1",
        "authors": [
            "Ming Tang",
            "Xiaowen Huang",
            "Jitao Sang"
        ],
        "submitted": "2025-08-15 05:57:38",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on recommender systems and the filter bubble effect, which is somewhat related to my interests in Information Retrieval and Search technologies. However, the paper's emphasis on community detection and graph convolutional networks is not directly aligned with my research themes, such as query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Benchmarking Prosody Encoding in Discrete Speech Tokens",
        "abstract": "Recently, discrete tokens derived from self-supervised learning (SSL) models\nvia k-means clustering have been actively studied as pseudo-text in speech\nlanguage models and as efficient intermediate representations for various\ntasks. However, these discrete tokens are typically learned in advance,\nseparately from the training of language models or downstream tasks. As a\nresult, choices related to discretization, such as the SSL model used or the\nnumber of clusters, must be made heuristically. In particular, speech language\nmodels are expected to understand and generate responses that reflect not only\nthe semantic content but also prosodic features. Yet, there has been limited\nresearch on the ability of discrete tokens to capture prosodic information. To\naddress this gap, this study conducts a comprehensive analysis focusing on\nprosodic encoding based on their sensitivity to the artificially modified\nprosody, aiming to provide practical guidelines for designing discrete tokens.",
        "url": "http://arxiv.org/abs/2508.11224v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11224v1",
        "arxiv_id": "2508.11224v1",
        "authors": [
            "Kentaro Onda",
            "Satoru Fukayama",
            "Daisuke Saito",
            "Nobuaki Minematsu"
        ],
        "submitted": "2025-08-15 05:11:16",
        "source": "arxiv",
        "comment": "Accepted by ASRU2025",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on prosody encoding in discrete speech tokens, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it touches on language models, the primary focus is on speech language models and prosodic features, which is outside the scope of the user's research interests."
    },
    {
        "title": "Representation Quantization for Collaborative Filtering Augmentation",
        "abstract": "As the core algorithm in recommendation systems, collaborative filtering (CF)\nalgorithms inevitably face the problem of data sparsity. Since CF captures\nsimilar users and items for recommendations, it is effective to augment the\nlacking user-user and item-item homogeneous linkages. However, existing methods\nare typically limited to connecting through overlapping interacted neighbors or\nthrough similar attributes and contents. These approaches are constrained by\ncoarse-grained, sparse attributes and fail to effectively extract behavioral\ncharacteristics jointly from interaction sequences and attributes. To address\nthese challenges, we propose a novel two-stage collaborative recommendation\nalgorithm, DQRec: Decomposition-based Quantized Variational AutoEncoder\n(DQ-VAE) for Recommendation. DQRec augments features and homogeneous linkages\nby extracting the behavior characteristics jointly from interaction sequences\nand attributes, namely patterns, such as user multi-aspect interests. Inspired\nby vector quantization (VQ) technology, we propose a new VQ algorithm, DQ-VAE,\nwhich decomposes the pre-trained representation embeddings into distinct\ndimensions, and quantize them to generates semantic IDs. We utilize the\ngenerated semantic IDs as the extracted patterns mentioned above. By\nintegrating these semantic ID patterns into the recommendation process through\nfeature and linkage augmentation, the system enriches both latent and explicit\nuser and item features, identifies pattern-similar neighbors, and thereby\nimproves the efficiency of information diffusion. Experimental comparisons with\nbaselines across multiple datasets demonstrate the superior performance of the\nproposed DQRec method.",
        "url": "http://arxiv.org/abs/2508.11194v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11194v1",
        "arxiv_id": "2508.11194v1",
        "authors": [
            "Yunze Luo",
            "Yinjie Jiang",
            "Gaode Chen",
            "Jingchi Wang",
            "Shicheng Wang",
            "Ruina Sun",
            "Jiang Yuezihan",
            "Jun Zhang",
            "Jian Liang",
            "Han Li",
            "Kun Gai",
            "Kaigui Bian"
        ],
        "submitted": "2025-08-15 04:00:50",
        "source": "arxiv",
        "comment": "11 pages, 4 figures",
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on collaborative filtering and recommendation systems, which is outside the user's primary research interest in Information Retrieval and Search technologies. Although it mentions feature and linkage augmentation, the approach is not related to query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user."
    },
    {
        "title": "Overcoming Low-Resource Barriers in Tulu: Neural Models and Corpus Creation for OffensiveLanguage Identification",
        "abstract": "Tulu, a low-resource Dravidian language predominantly spoken in southern\nIndia, has limited computational resources despite its growing digital\npresence. This study presents the first benchmark dataset for Offensive\nLanguage Identification (OLI) in code-mixed Tulu social media content,\ncollected from YouTube comments across various domains. The dataset, annotated\nwith high inter-annotator agreement (Krippendorff's alpha = 0.984), includes\n3,845 comments categorized into four classes: Not Offensive, Not Tulu,\nOffensive Untargeted, and Offensive Targeted. We evaluate a suite of deep\nlearning models, including GRU, LSTM, BiGRU, BiLSTM, CNN, and attention-based\nvariants, alongside transformer architectures (mBERT, XLM-RoBERTa). The BiGRU\nmodel with self-attention achieves the best performance with 82% accuracy and a\n0.81 macro F1-score. Transformer models underperform, highlighting the\nlimitations of multilingual pretraining in code-mixed, under-resourced\ncontexts. This work lays the foundation for further NLP research in Tulu and\nsimilar low-resource, code-mixed languages.",
        "url": "http://arxiv.org/abs/2508.11166v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11166v1",
        "arxiv_id": "2508.11166v1",
        "authors": [
            "Anusha M D",
            "Deepthi Vikram",
            "Bharathi Raja Chakravarthi",
            "Parameshwar R Hegde"
        ],
        "submitted": "2025-08-15 02:34:22",
        "source": "arxiv",
        "comment": "20 pages, 3 tables, 3 figures. Submitted to Language Resources and\n  Evaluation (Springer)",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on a specific language (Tulu) and a topic (Offensive Language Identification) that is not directly related to Information Retrieval, Search technologies, or Natural Language Processing. The paper's emphasis on deep learning models and corpus creation is also not aligned with your interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Hell or High Water: Evaluating Agentic Recovery from External Failures",
        "abstract": "As language model agents are applied to real world problems of increasing\ncomplexity, they will be expected to formulate plans across large search\nspaces. If those plans fail for reasons beyond their control, how well do\nlanguage agents search for alternative ways to achieve their goals? We devise a\nspecialized agentic planning benchmark to study this question. Each planning\nproblem is solved via combinations of function calls. The agent searches for\nrelevant functions from a set of over four thousand possibilities, and observes\nenvironmental feedback in the form of function outputs or error messages. Our\nbenchmark confronts the agent with external failures in its workflow, such as\nfunctions that suddenly become unavailable. At the same time, even with the\nintroduction of these failures, we guarantee that the task remains solvable.\nIdeally, an agent's performance on the planning task should not be affected by\nthe presence of external failures. Overall, we find that language agents\nstruggle to formulate and execute backup plans in response to environment\nfeedback. While state-of-the-art models are often able to identify the correct\nfunction to use in the right context, they struggle to adapt to feedback from\nthe environment and often fail to pursue alternate courses of action, even when\nthe search space is artificially restricted. We provide a systematic analysis\nof the failures of both open-source and commercial models, examining the\neffects of search space size, as well as the benefits of scaling model size in\nour setting. Our analysis identifies key challenges for current generative\nmodels as well as promising directions for future work.",
        "url": "http://arxiv.org/abs/2508.11027v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11027v1",
        "arxiv_id": "2508.11027v1",
        "authors": [
            "Andrew Wang",
            "Sophia Hager",
            "Adi Asija",
            "Daniel Khashabi",
            "Nicholas Andrews"
        ],
        "submitted": "2025-08-14 19:21:09",
        "source": "arxiv",
        "comment": "Accepted to COLM 2025",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on evaluating language model agents' ability to adapt to external failures in planning tasks, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it touches on search spaces and function calls, the context is quite different from the user's core research themes."
    },
    {
        "title": "Can Multi-modal (reasoning) LLMs detect document manipulation?",
        "abstract": "Document fraud poses a significant threat to industries reliant on secure and\nverifiable documentation, necessitating robust detection mechanisms. This study\ninvestigates the efficacy of state-of-the-art multi-modal large language models\n(LLMs)-including OpenAI O1, OpenAI 4o, Gemini Flash (thinking), Deepseek Janus,\nGrok, Llama 3.2 and 4, Qwen 2 and 2.5 VL, Mistral Pixtral, and Claude 3.5 and\n3.7 Sonnet-in detecting fraudulent documents. We benchmark these models against\neach other and prior work on document fraud detection techniques using a\nstandard dataset with real transactional documents. Through prompt optimization\nand detailed analysis of the models' reasoning processes, we evaluate their\nability to identify subtle indicators of fraud, such as tampered text,\nmisaligned formatting, and inconsistent transactional sums. Our results reveal\nthat top-performing multi-modal LLMs demonstrate superior zero-shot\ngeneralization, outperforming conventional methods on out-of-distribution\ndatasets, while several vision LLMs exhibit inconsistent or subpar performance.\nNotably, model size and advanced reasoning capabilities show limited\ncorrelation with detection accuracy, suggesting task-specific fine-tuning is\ncritical. This study underscores the potential of multi-modal LLMs in enhancing\ndocument fraud detection systems and provides a foundation for future research\ninto interpretable and scalable fraud mitigation strategies.",
        "url": "http://arxiv.org/abs/2508.11021v1",
        "pdf_url": "http://arxiv.org/pdf/2508.11021v1",
        "arxiv_id": "2508.11021v1",
        "authors": [
            "Zisheng Liang",
            "Kidus Zewde",
            "Rudra Pratap Singh",
            "Disha Patil",
            "Zexi Chen",
            "Jiayu Xue",
            "Yao Yao",
            "Yifei Chen",
            "Qinzhe Liu",
            "Simiao Ren"
        ],
        "submitted": "2025-08-14 18:57:07",
        "source": "arxiv",
        "comment": "arXiv admin note: text overlap with arXiv:2503.20084",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of multi-modal large language models in detecting document manipulation, which is a specific problem in the domain of information retrieval. While it touches on the topic of query understanding and ranking models, the focus is more on the capabilities of the models rather than their application in search technologies. The paper's relevance to the user's interests is limited, but it does provide some insights into the potential of LLMs in enhancing document fraud detection systems."
    }
]