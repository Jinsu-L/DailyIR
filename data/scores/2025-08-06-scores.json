[
    {
        "title": "CTR-Sink: Attention Sink for Language Models in Click-Through Rate Prediction",
        "abstract": "Click-Through Rate (CTR) prediction, a core task in recommendation systems,\nestimates user click likelihood using historical behavioral data. Modeling user\nbehavior sequences as text to leverage Language Models (LMs) for this task has\ngained traction, owing to LMs' strong semantic understanding and contextual\nmodeling capabilities. However, a critical structural gap exists: user behavior\nsequences consist of discrete actions connected by semantically empty\nseparators, differing fundamentally from the coherent natural language in LM\npre-training. This mismatch causes semantic fragmentation, where LM attention\nscatters across irrelevant tokens instead of focusing on meaningful behavior\nboundaries and inter-behavior relationships, degrading prediction performance.\nTo address this, we propose $\\textit{CTR-Sink}$, a novel framework introducing\nbehavior-level attention sinks tailored for recommendation scenarios. Inspired\nby attention sink theory, it constructs attention focus sinks and dynamically\nregulates attention aggregation via external information. Specifically, we\ninsert sink tokens between consecutive behaviors, incorporating\nrecommendation-specific signals such as temporal distance to serve as stable\nattention sinks. To enhance generality, we design a two-stage training strategy\nthat explicitly guides LM attention toward sink tokens and a attention sink\nmechanism that amplifies inter-sink dependencies to better capture behavioral\ncorrelations. Experiments on one industrial dataset and two open-source\ndatasets (MovieLens, Kuairec), alongside visualization results, validate the\nmethod's effectiveness across scenarios.",
        "url": "http://arxiv.org/abs/2508.03668v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03668v1",
        "arxiv_id": "2508.03668v1",
        "authors": [
            "Zixuan Li",
            "Binzong Geng",
            "Jing Xiong",
            "Yong He",
            "Yuxuan Hu",
            "Jian Chen",
            "Dingwei Chen",
            "Xiyu Chang",
            "Liang Zhang",
            "Linjian Mo",
            "Chengming Li",
            "Chuan Yuan",
            "Zhenan Sun"
        ],
        "submitted": "2025-08-05 17:30:34",
        "source": "arxiv",
        "comment": null,
        "score": 11,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'user behavior' (score: +2)",
            "Found 'click' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'click-through rate' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper focuses on Click-Through Rate prediction, a topic related to information retrieval, and leverages language models for this task. While it doesn't directly address query understanding or ranking models, it explores the application of language models in a recommendation system, which is somewhat related to the user's interests in search technologies and user behavior modeling."
    },
    {
        "title": "PyLate: Flexible Training and Retrieval for Late Interaction Models",
        "abstract": "Neural ranking has become a cornerstone of modern information retrieval.\nWhile single vector search remains the dominant paradigm, it suffers from the\nshortcoming of compressing all the information into a single vector. This\ncompression leads to notable performance degradation in out-of-domain,\nlong-context, and reasoning-intensive retrieval tasks. Multi-vector approaches\npioneered by ColBERT aim to address these limitations by preserving individual\ntoken embeddings and computing similarity via the MaxSim operator. This\narchitecture has demonstrated superior empirical advantages, including enhanced\nout-of-domain generalization, long-context handling, and performance in complex\nretrieval scenarios. Despite these compelling empirical results and clear\ntheoretical advantages, the practical adoption and public availability of late\ninteraction models remain low compared to their single-vector counterparts,\nprimarily due to a lack of accessible and modular tools for training and\nexperimenting with such models. To bridge this gap, we introduce PyLate, a\nstreamlined library built on top of Sentence Transformers to support\nmulti-vector architectures natively, inheriting its efficient training,\nadvanced logging, and automated model card generation while requiring minimal\ncode changes to code templates users are already familiar with. By offering\nmulti-vector-specific features such as efficient indexes, PyLate aims to\naccelerate research and real-world application of late interaction models,\nthereby unlocking their full potential in modern IR systems. Finally, PyLate\nhas already enabled the development of state-of-the-art models, including\nGTE-ModernColBERT and Reason-ModernColBERT, demonstrating its practical utility\nfor both research and production environments.",
        "url": "http://arxiv.org/abs/2508.03555v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03555v1",
        "arxiv_id": "2508.03555v1",
        "authors": [
            "Antoine Chaffin",
            "RaphaÃ«l Sourty"
        ],
        "submitted": "2025-08-05 15:23:40",
        "source": "arxiv",
        "comment": "5 pages",
        "score": 10,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "The paper is highly relevant to information retrieval, specifically neural ranking and multi-vector approaches, which align with your research interests. The introduction of PyLate, a library for training and experimenting with late interaction models, is also of interest, given your focus on query understanding and ranking models."
    },
    {
        "title": "LLMDistill4Ads: Using Cross-Encoders to Distill from LLM Signals for Advertiser Keyphrase Recommendations at eBay",
        "abstract": "Sellers at eBay are recommended keyphrases to bid on to enhance the\nperformance of their advertising campaigns. The relevance of these keyphrases\nis crucial in avoiding the overcrowding of search systems with irrelevant items\nand maintaining a positive seller perception. It is essential that keyphrase\nrecommendations align with both seller and Search judgments regarding auctions.\nDue to the difficulty in procuring negative human judgment at scale, employing\nLLM-as-a-judge to mimic seller judgment has been established as the norm in\nseveral studies. This study introduces a novel two-step LLM distillation\nprocess from a LLM-judge used to debias our Embedding Based Retrieval (EBR)\nmodel from the various biases that exist in click-data. We distill from an LLM\nteacher via a cross-encoder assistant into a bi-encoder student using a\nmulti-task training approach, ultimately employing the student bi-encoder to\nretrieve relevant advertiser keyphrases. We show that integrating a knowledge\ndistillation process from LLMs in a multi-task training setup enhances\nbi-encoder performance in retrieving relevant advertiser keyphrases at eBay.",
        "url": "http://arxiv.org/abs/2508.03628v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03628v1",
        "arxiv_id": "2508.03628v1",
        "authors": [
            "Soumik Dey",
            "Benjamin Braun",
            "Naveen Ravipati",
            "Hansi Wu",
            "Binbin Li"
        ],
        "submitted": "2025-08-05 16:47:17",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'click' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on advertiser keyphrase recommendations at eBay, which is related to search technologies and query understanding. However, the specific application and problem domain are quite different from the user's primary interests in information retrieval, ranking models, and user behavior modeling. The use of LLMs and knowledge distillation is also not directly relevant to the user's research areas."
    },
    {
        "title": "MultiRAG: A Knowledge-guided Framework for Mitigating Hallucination in Multi-source Retrieval Augmented Generation",
        "abstract": "Retrieval Augmented Generation (RAG) has emerged as a promising solution to\naddress hallucination issues in Large Language Models (LLMs). However, the\nintegration of multiple retrieval sources, while potentially more informative,\nintroduces new challenges that can paradoxically exacerbate hallucination\nproblems. These challenges manifest primarily in two aspects: the sparse\ndistribution of multi-source data that hinders the capture of logical\nrelationships and the inherent inconsistencies among different sources that\nlead to information conflicts. To address these challenges, we propose\nMultiRAG, a novel framework designed to mitigate hallucination in multi-source\nretrieval-augmented generation through knowledge-guided approaches. Our\nframework introduces two key innovations: (1) a knowledge construction module\nthat employs multi-source line graphs to efficiently aggregate logical\nrelationships across different knowledge sources, effectively addressing the\nsparse data distribution issue; and (2) a sophisticated retrieval module that\nimplements a multi-level confidence calculation mechanism, performing both\ngraph-level and node-level assessments to identify and eliminate unreliable\ninformation nodes, thereby reducing hallucinations caused by inter-source\ninconsistencies. Extensive experiments on four multi-domain query datasets and\ntwo multi-hop QA datasets demonstrate that MultiRAG significantly enhances the\nreliability and efficiency of knowledge retrieval in complex multi-source\nscenarios. \\textcolor{blue}{Our code is available in\nhttps://github.com/wuwenlong123/MultiRAG.",
        "url": "http://arxiv.org/abs/2508.03553v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03553v1",
        "arxiv_id": "2508.03553v1",
        "authors": [
            "Wenlong Wu",
            "Haofen Wang",
            "Bohan Li",
            "Peixuan Huang",
            "Xinzhe Zhao",
            "Lei Liang"
        ],
        "submitted": "2025-08-05 15:20:52",
        "source": "arxiv",
        "comment": "Accepted by ICDE 2025 Research Paper",
        "score": 9,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval augmented generation' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on mitigating hallucination in multi-source retrieval-augmented generation, which is a specific problem in Natural Language Processing (NLP). While it touches on retrieval and generation, the primary focus is on knowledge construction and retrieval, rather than query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval (IR). The paper's relevance to IR is limited, but it does explore some NLP-related topics."
    },
    {
        "title": "Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?",
        "abstract": "Retrieval-Augmented Generation (RAG) systems using Multimodal Large Language\nModels (MLLMs) show great promise for complex document understanding, yet their\ndevelopment is critically hampered by inadequate evaluation. Current benchmarks\noften focus on specific part of document RAG system and use synthetic data with\nincomplete ground truth and evidence labels, therefore failing to reflect\nreal-world bottlenecks and challenges. To overcome these limitations, we\nintroduce Double-Bench: a new large-scale, multilingual, and multimodal\nevaluation system that is able to produce fine-grained assessment to each\ncomponent within document RAG systems. It comprises 3,276 documents (72,880\npages) and 5,168 single- and multi-hop queries across 6 languages and 4\ndocument types with streamlined dynamic update support for potential data\ncontamination issues. Queries are grounded in exhaustively scanned evidence\npages and verified by human experts to ensure maximum quality and completeness.\nOur comprehensive experiments across 9 state-of-the-art embedding models, 4\nMLLMs and 4 end-to-end document RAG frameworks demonstrate the gap between text\nand visual embedding models is narrowing, highlighting the need in building\nstronger document retrieval models. Our findings also reveal the\nover-confidence dilemma within current document RAG frameworks that tend to\nprovide answer even without evidence support. We hope our fully open-source\nDouble-Bench provide a rigorous foundation for future research in advanced\ndocument RAG systems. We plan to retrieve timely corpus and release new\nbenchmarks on an annual basis.",
        "url": "http://arxiv.org/abs/2508.03644v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03644v1",
        "arxiv_id": "2508.03644v1",
        "authors": [
            "Wenxuan Shen",
            "Mingjia Wang",
            "Yaochen Wang",
            "Dongping Chen",
            "Junjie Yang",
            "Yao Wan",
            "Weiwei Lin"
        ],
        "submitted": "2025-08-05 16:55:02",
        "source": "arxiv",
        "comment": "In submission. Project website: https://double-bench.github.io/",
        "score": 8,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper discusses Retrieval-Augmented Generation (RAG) systems, which is related to information retrieval and query understanding. However, the focus is on evaluation methods rather than ranking models or user behavior modeling, which are core aspects of your research interests. The paper's relevance is somewhat diminished by its focus on a specific application domain (document RAG) and the lack of direct connection to your primary research areas."
    },
    {
        "title": "Parameter-Efficient Single Collaborative Branch for Recommendation",
        "abstract": "Recommender Systems (RS) often rely on representations of users and items in\na joint embedding space and on a similarity metric to compute relevance scores.\nIn modern RS, the modules to obtain user and item representations consist of\ntwo distinct and separate neural networks (NN). In multimodal representation\nlearning, weight sharing has been proven effective in reducing the distance\nbetween multiple modalities of a same item. Inspired by these approaches, we\npropose a novel RS that leverages weight sharing between the user and item NN\nmodules used to obtain the latent representations in the shared embedding\nspace. The proposed framework consists of a single Collaborative Branch for\nRecommendation (CoBraR). We evaluate CoBraR by means of quantitative\nexperiments on e-commerce and movie recommendation. Our experiments show that\nby reducing the number of parameters and improving beyond-accuracy aspects\nwithout compromising accuracy, CoBraR has the potential to be applied and\nextended for real-world scenarios.",
        "url": "http://arxiv.org/abs/2508.03518v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03518v1",
        "arxiv_id": "2508.03518v1",
        "authors": [
            "Marta Moscati",
            "Shah Nawaz",
            "Markus Schedl"
        ],
        "submitted": "2025-08-05 14:46:06",
        "source": "arxiv",
        "comment": "5 pages",
        "score": 8,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on recommender systems, which is a related topic, but it does not address information retrieval, query understanding, ranking models, or user behavior modeling, which are the core research themes of the user's interests. The paper's emphasis on reducing the number of parameters and improving beyond-accuracy aspects without compromising accuracy is not directly relevant to the user's interests in deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Reliable Evaluation Protocol for Low-Precision Retrieval",
        "abstract": "Lowering the numerical precision of model parameters and computations is\nwidely adopted to improve the efficiency of retrieval systems. However, when\ncomputing relevance scores between the query and documents in low-precision, we\nobserve spurious ties due to the reduced granularity. This introduces high\nvariability in the results based on tie resolution, making the evaluation less\nreliable. To address this, we propose a more robust retrieval evaluation\nprotocol designed to reduce score variation. It consists of: (1) High-Precision\nScoring (HPS), which upcasts the final scoring step to higher precision to\nresolve tied candidates with minimal computational cost; and (2) Tie-aware\nRetrieval Metrics (TRM), which report expected scores, range, and bias to\nquantify order uncertainty of tied candidates. Our experiments test multiple\nmodels with three scoring functions on two retrieval datasets to demonstrate\nthat HPS dramatically reduces tie-induced instability, and TRM accurately\nrecovers expected metric values. This combination enables a more consistent and\nreliable evaluation system for lower-precision retrievals.",
        "url": "http://arxiv.org/abs/2508.03306v2",
        "pdf_url": "http://arxiv.org/pdf/2508.03306v2",
        "arxiv_id": "2508.03306v2",
        "authors": [
            "Kisu Yang",
            "Yoonna Jang",
            "Hwanseok Jang",
            "Kenneth Choi",
            "Isabelle Augenstein",
            "Heuiseok Lim"
        ],
        "submitted": "2025-08-05 10:27:57",
        "source": "arxiv",
        "comment": "11 pages, 5 figures, submitted to ARR",
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on improving the evaluation protocol for low-precision retrieval, which is a specific aspect of Information Retrieval. While it touches on relevance optimization, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's relevance is somewhat related, but not a central match."
    },
    {
        "title": "Token-Level Precise Attack on RAG: Searching for the Best Alternatives to Mislead Generation",
        "abstract": "While large language models (LLMs) have achieved remarkable success in\nproviding trustworthy responses for knowledge-intensive tasks, they still face\ncritical limitations such as hallucinations and outdated knowledge. To address\nthese issues, the retrieval-augmented generation (RAG) framework enhances LLMs\nwith access to external knowledge via a retriever, enabling more accurate and\nreal-time outputs about the latest events. However, this integration brings new\nsecurity vulnerabilities: the risk that malicious content in the external\ndatabase can be retrieved and used to manipulate model outputs. Although prior\nwork has explored attacks on RAG systems, existing approaches either rely\nheavily on access to the retriever or fail to jointly consider both retrieval\nand generation stages, limiting their effectiveness, particularly in black-box\nscenarios. To overcome these limitations, we propose Token-level Precise Attack\non the RAG (TPARAG), a novel framework that targets both white-box and\nblack-box RAG systems. TPARAG leverages a lightweight white-box LLM as an\nattacker to generate and iteratively optimize malicious passages at the token\nlevel, ensuring both retrievability and high attack success in generation.\nExtensive experiments on open-domain QA datasets demonstrate that TPARAG\nconsistently outperforms previous approaches in retrieval-stage and end-to-end\nattack effectiveness. These results further reveal critical vulnerabilities in\nRAG pipelines and offer new insights into improving their robustness.",
        "url": "http://arxiv.org/abs/2508.03110v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03110v1",
        "arxiv_id": "2508.03110v1",
        "authors": [
            "Zizhong Li",
            "Haopeng Zhang",
            "Jiawei Zhang"
        ],
        "submitted": "2025-08-05 05:44:19",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores attacks on the Retrieval-Augmented Generation (RAG) framework, which is a topic in Natural Language Processing (NLP). While it touches on the retrieval stage, the focus is on the generation stage, which is not directly related to query understanding, ranking models, or user behavior modeling in Information Retrieval (IR). The paper's relevance is somewhat limited due to its focus on attacks rather than improving the underlying technology."
    },
    {
        "title": "KBest: Efficient Vector Search on Kunpeng CPU",
        "abstract": "Vector search, which returns the vectors most similar to a given query vector\nfrom a large vector dataset, underlies many important applications such as\nsearch, recommendation, and LLMs. To be economic, vector search needs to be\nefficient to reduce the resources required by a given query workload. However,\nexisting vector search libraries (e.g., Faiss and DiskANN) are optimized for\nx86 CPU architectures (i.e., Intel and AMD CPUs) while Huawei Kunpeng CPUs are\nbased on the ARM architecture and competitive in compute power. In this paper,\nwe present KBest as a vector search library tailored for the latest Kunpeng 920\nCPUs. To be efficient, KBest incorporates extensive hardware-aware and\nalgorithmic optimizations, which include single-instruction-multiple-data\n(SIMD) accelerated distance computation, data prefetch, index refinement, early\ntermination, and vector quantization. Experiment results show that KBest\noutperforms SOTA vector search libraries running on x86 CPUs, and our\noptimizations can improve the query throughput by over 2x. Currently, KBest\nserves applications from both our internal business and external enterprise\nclients with tens of millions of queries on a daily basis.",
        "url": "http://arxiv.org/abs/2508.03016v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03016v1",
        "arxiv_id": "2508.03016v1",
        "authors": [
            "Kaihao MA",
            "Meiling Wang",
            "Senkevich Oleg",
            "Zijian LI",
            "Daihao Xue",
            "Dmitriy Malyshev",
            "Yangming Lv",
            "Shihai Xiao",
            "Xiao Yan",
            "Radionov Alexander",
            "Weidi Zeng",
            "Yuanzhan Gao",
            "Zhiyu Zou",
            "Yao xin",
            "Liu Lin",
            "Junhao Wu",
            "Yiding Liu",
            "Yaoyao Fu",
            "Gongyi Wang",
            "Gong Zhang",
            "Fei Yi",
            "Yingfan Liu"
        ],
        "submitted": "2025-08-05 02:52:15",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on optimizing vector search for a specific CPU architecture, which is not directly related to query understanding, ranking models, or user behavior modeling in Information Retrieval. While it mentions applications such as search and recommendation, the paper's primary concern is efficiency and optimization for a particular hardware platform, rather than deep semantic understanding or real-time relevance optimization."
    },
    {
        "title": "LLM-based IR-system for Bank Supervisors",
        "abstract": "Bank supervisors face the complex task of ensuring that new measures are\nconsistently aligned with historical precedents. To address this challenge, we\nintroduce a novel Information Retrieval (IR) System tailored to assist\nsupervisors in drafting both consistent and effective measures. This system\ningests findings from on-site investigations. It then retrieves the most\nrelevant historical findings and their associated measures from a comprehensive\ndatabase, providing a solid basis for supervisors to write well-informed\nmeasures for new findings. Utilizing a blend of lexical, semantic, and Capital\nRequirements Regulation (CRR) fuzzy set matching techniques, the IR system\nensures the retrieval of findings that closely align with current cases. The\nperformance of this system, particularly in scenarios with partially labeled\ndata, is validated through a Monte Carlo methodology, showcasing its robustness\nand accuracy. Enhanced by a Transformer-based Denoising AutoEncoder for\nfine-tuning, the final model achieves a Mean Average Precision (MAP@100) of\n0.83 and a Mean Reciprocal Rank (MRR@100) of 0.92. These scores surpass those\nof both standalone lexical models such as BM25 and semantic BERT-like models.",
        "url": "http://arxiv.org/abs/2508.02945v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02945v1",
        "arxiv_id": "2508.02945v1",
        "authors": [
            "Ilias Aarab"
        ],
        "submitted": "2025-08-04 23:02:01",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper's focus on Information Retrieval (IR) is relevant, but it is specific to a niche domain (bank supervision) and does not align with the user's interests in query understanding, ranking models, and user behavior modeling. The paper's use of NLP techniques is also limited to lexical and semantic matching, which is not a central aspect of the user's research."
    },
    {
        "title": "CTTS: Collective Test-Time Scaling",
        "abstract": "Test-time scaling (TTS) has emerged as a promising research field for\nenhancing the effectiveness of large language models (LLMs) without extra\ntraining. However, most existing approaches, e.g., Best-of-N and\nSelf-Consistency rely on a single agent interacting with a reward model\n(SA-SR), constrained by limited capabilities of a single test-time scaling\n(STTS) paradigm. On the other hand, recent works demonstrate that\ncollective-agent methods can break through the upper bound of single-agent\nsystems by orchestrating diverse models. Thus, in this paper, we take a first\nstep towards exploring Collective Test-Time Scaling (CTTS). Consider the\ndifferent interaction types of single and multiple models, we design three\nprimary paradigms to investigate the optimal paradigm of CTTS: (1) single agent\nto multiple reward models (SA-MR); (2) multiple agents to single reward model\n(MA-SR); and (3) multiple agents to multiple reward models (MA-MR). Extensive\nexperiments demonstrate that MA-MR consistently achieves the best performance.\nBased on this, we propose a novel framework named CTTS-MM that effectively\nleverages both multi-agent and multi-reward-model collaboration for enhanced\ninference. Specifically, for multi-agent collaboration, we propose an Agent\nCollaboration Search (ACS), which searches for the most effective combination\nof LLM agents from a large candidate pool; for multi-reward-model\ncollaboration, we propose Mixture of Reword Models (MoR), which consists of a\ncurated question pool and a Prior Reward model Ensemble Selection (PRES) to\nselect the optimal combinations of reward models via Pair-wise Reward Ranking\n(PRR) metric. Experiments across seven mainstream benchmarks demonstrate that\nthe proposed CTTS-MM consistently obtains superior performance. Code will be\nreleased at https://github.com/magent4aci/CTTS-MM.",
        "url": "http://arxiv.org/abs/2508.03333v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03333v1",
        "arxiv_id": "2508.03333v1",
        "authors": [
            "Zhende Song",
            "Shengji Tang",
            "Peng Ye",
            "Jiayuan Fan",
            "Tao Chen"
        ],
        "submitted": "2025-08-05 11:19:08",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on collective test-time scaling, which is not directly related to information retrieval, query understanding, ranking models, or user behavior modeling. While it involves language models, the context is different from the user's interests in IR and NLP."
    },
    {
        "title": "ADSeeker: A Knowledge-Infused Framework for Anomaly Detection and Reasoning",
        "abstract": "Automatic vision inspection holds significant importance in industry\ninspection. While multimodal large language models (MLLMs) exhibit strong\nlanguage understanding capabilities and hold promise for this task, their\nperformance remains significantly inferior to that of human experts. In this\ncontext, we identify two key challenges: (i) insufficient integration of\nanomaly detection (AD) knowledge during pre-training, and (ii) the lack of\ntechnically precise and conte-aware language generation for anomaly reasoning.\nTo address these issues, we propose ADSeeker, an anomaly task assistant\ndesigned to enhance inspection performance through knowledge-grounded\nreasoning. ADSeeker leverages a curated visual document knowledge base,\nSEEK-MVTec&VisA (SEEK-M&V), which we construct to address the limitations of\nexisting resources that rely solely on unstructured text. SEEK-M&V includes\nsemantic-rich descriptions and image-document pairs, enabling more\ncomprehensive anomaly understanding. To effectively retrieve and utilize this\nknowledge, we introduce the Query Image-Knowledge Retrieval-Augmented\nGeneration (Q2K RAG) framework. To further enhance the performance in zero-shot\nanomaly detection (ZSAD), ADSeeker leverages the Hierarchical Sparse Prompt\nmechanism and type-level features to efficiently extract anomaly patterns.\nFurthermore, to tackle the challenge of limited in industry anomaly detection\n(IAD) data, we introduce the largest-scale AD dataset, Multi-type Anomaly\n(MulA), encompassing 72 multi-scale defect types across 26 Categories.\nExtensive experiments show that our plug-and-play framework, ADSeeker, achieves\nstate-of-the-art zero-shot performance on several benchmark datasets.",
        "url": "http://arxiv.org/abs/2508.03088v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03088v1",
        "arxiv_id": "2508.03088v1",
        "authors": [
            "Kai Zhang",
            "Zekai Zhang",
            "Xihe Sun",
            "Jingmeng Nie",
            "Qinghui Chen",
            "Han Hao",
            "Jianyuan Guo",
            "Jinglin Zhang"
        ],
        "submitted": "2025-08-05 05:05:06",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on anomaly detection and reasoning in the context of automatic vision inspection, which is not directly related to information retrieval, search technologies, or query understanding. Although it mentions multimodal large language models, the primary focus is on computer vision and anomaly detection, making it not relevant to the user's research interests."
    },
    {
        "title": "AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots",
        "abstract": "AGENTiGraph is a user-friendly, agent-driven system that enables intuitive\ninteraction and management of domain-specific data through the manipulation of\nknowledge graphs in natural language. It gives non-technical users a complete,\nvisual solution to incrementally build and refine their knowledge bases,\nallowing multi-round dialogues and dynamic updates without specialized query\nlanguages. The flexible design of AGENTiGraph, including intent classification,\ntask planning, and automatic knowledge integration, ensures seamless reasoning\nbetween diverse tasks. Evaluated on a 3,500-query benchmark within an\neducational scenario, the system outperforms strong zero-shot baselines\n(achieving 95.12% classification accuracy, 90.45% execution success),\nindicating potential scalability to compliance-critical or multi-step queries\nin legal and medical domains, e.g., incorporating new statutes or research on\nthe fly. Our open-source demo offers a powerful new paradigm for multi-turn\nenterprise knowledge management that bridges LLMs and structured graphs.",
        "url": "http://arxiv.org/abs/2508.02999v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02999v1",
        "arxiv_id": "2508.02999v1",
        "authors": [
            "Xinjie Zhao",
            "Moritz Blum",
            "Fan Gao",
            "Yingjian Chen",
            "Boming Yang",
            "Luis Marquez-Carpintero",
            "MÃ³nica Pina-Navarro",
            "Yanran Fu",
            "So Morikawa",
            "Yusuke Iwasawa",
            "Yutaka Matsuo",
            "Chanjun Park",
            "Irene Li"
        ],
        "submitted": "2025-08-05 01:55:06",
        "source": "arxiv",
        "comment": "CIKM 2025, Demo Track",
        "score": 7,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a knowledge graph framework for interactive chatbots, which is related to information retrieval and natural language processing. However, the focus is on building and refining knowledge bases through multi-round dialogues, which is not directly aligned with my research interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Highlight & Summarize: RAG without the jailbreaks",
        "abstract": "Preventing jailbreaking and model hijacking of Large Language Models (LLMs)\nis an important yet challenging task. For example, when interacting with a\nchatbot, malicious users can input specially crafted prompts to cause the LLM\nto generate undesirable content or perform a completely different task from its\nintended purpose. Existing mitigations for such attacks typically rely on\nhardening the LLM's system prompt or using a content classifier trained to\ndetect undesirable content or off-topic conversations. However, these\nprobabilistic approaches are relatively easy to bypass due to the very large\nspace of possible inputs and undesirable outputs. In this paper, we present and\nevaluate Highlight & Summarize (H&S), a new design pattern for\nretrieval-augmented generation (RAG) systems that prevents these attacks by\ndesign. The core idea is to perform the same task as a standard RAG pipeline\n(i.e., to provide natural language answers to questions, based on relevant\nsources) without ever revealing the user's question to the generative LLM. This\nis achieved by splitting the pipeline into two components: a highlighter, which\ntakes the user's question and extracts relevant passages (\"highlights\") from\nthe retrieved documents, and a summarizer, which takes the highlighted passages\nand summarizes them into a cohesive answer. We describe several possible\ninstantiations of H&S and evaluate their generated responses in terms of\ncorrectness, relevance, and response quality. Surprisingly, when using an\nLLM-based highlighter, the majority of H&S responses are judged to be better\nthan those of a standard RAG pipeline.",
        "url": "http://arxiv.org/abs/2508.02872v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02872v1",
        "arxiv_id": "2508.02872v1",
        "authors": [
            "Giovanni Cherubin",
            "Andrew Paverd"
        ],
        "submitted": "2025-08-04 20:01:00",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on a specific problem in Natural Language Processing (LLM hijacking) and proposes a solution using a retrieval-augmented generation (RAG) system. While it mentions retrieval-augmented generation, the primary focus is on LLM hijacking and not on query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval. The paper does not seem to be directly related to the user's research themes."
    },
    {
        "title": "AttnTrace: Attention-based Context Traceback for Long-Context LLMs",
        "abstract": "Long-context large language models (LLMs), such as Gemini-2.5-Pro and\nClaude-Sonnet-4, are increasingly used to empower advanced AI systems,\nincluding retrieval-augmented generation (RAG) pipelines and autonomous agents.\nIn these systems, an LLM receives an instruction along with a context--often\nconsisting of texts retrieved from a knowledge database or memory--and\ngenerates a response that is contextually grounded by following the\ninstruction. Recent studies have designed solutions to trace back to a subset\nof texts in the context that contributes most to the response generated by the\nLLM. These solutions have numerous real-world applications, including\nperforming post-attack forensic analysis and improving the interpretability and\ntrustworthiness of LLM outputs. While significant efforts have been made,\nstate-of-the-art solutions such as TracLLM often lead to a high computation\ncost, e.g., it takes TracLLM hundreds of seconds to perform traceback for a\nsingle response-context pair. In this work, we propose AttnTrace, a new context\ntraceback method based on the attention weights produced by an LLM for a\nprompt. To effectively utilize attention weights, we introduce two techniques\ndesigned to enhance the effectiveness of AttnTrace, and we provide theoretical\ninsights for our design choice. We also perform a systematic evaluation for\nAttnTrace. The results demonstrate that AttnTrace is more accurate and\nefficient than existing state-of-the-art context traceback methods. We also\nshow that AttnTrace can improve state-of-the-art methods in detecting prompt\ninjection under long contexts through the attribution-before-detection\nparadigm. As a real-world application, we demonstrate that AttnTrace can\neffectively pinpoint injected instructions in a paper designed to manipulate\nLLM-generated reviews. The code is at\nhttps://github.com/Wang-Yanting/AttnTrace.",
        "url": "http://arxiv.org/abs/2508.03793v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03793v1",
        "arxiv_id": "2508.03793v1",
        "authors": [
            "Yanting Wang",
            "Runpeng Geng",
            "Ying Chen",
            "Jinyuan Jia"
        ],
        "submitted": "2025-08-05 17:56:51",
        "source": "arxiv",
        "comment": "The code is available at https://github.com/Wang-Yanting/AttnTrace.\n  The demo is available at https://huggingface.co/spaces/SecureLLMSys/AttnTrace",
        "score": 6,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a new method for context traceback in long-context LLMs, which is not directly related to information retrieval or search technologies. While it mentions attention weights, which are relevant to NLP, the focus is on language models and their applications, rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Marito: Structuring and Building Open Multilingual Terminologies for South African NLP",
        "abstract": "The critical lack of structured terminological data for South Africa's\nofficial languages hampers progress in multilingual NLP, despite the existence\nof numerous government and academic terminology lists. These valuable assets\nremain fragmented and locked in non-machine-readable formats, rendering them\nunusable for computational research and development. \\emph{Marito} addresses\nthis challenge by systematically aggregating, cleaning, and standardising these\nscattered resources into open, interoperable datasets. We introduce the\nfoundational \\emph{Marito} dataset, released under the equitable,\nAfrica-centered NOODL framework. To demonstrate its immediate utility, we\nintegrate the terminology into a Retrieval-Augmented Generation (RAG) pipeline.\nExperiments show substantial improvements in the accuracy and domain-specific\nconsistency of English-to-Tshivenda machine translation for large language\nmodels. \\emph{Marito} provides a scalable foundation for developing robust and\nequitable NLP technologies, ensuring South Africa's rich linguistic diversity\nis represented in the digital age.",
        "url": "http://arxiv.org/abs/2508.03529v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03529v1",
        "arxiv_id": "2508.03529v1",
        "authors": [
            "Vukosi Marivate",
            "Isheanesu Dzingirai",
            "Fiskani Banda",
            "Richard Lastrucci",
            "Thapelo Sindane",
            "Keabetswe Madumo",
            "Kayode Olaleye",
            "Abiodun Modupe",
            "Unarine Netshifhefhe",
            "Herkulaas Combrink",
            "Mohlatlego Nakeng",
            "Matome Ledwaba"
        ],
        "submitted": "2025-08-05 15:00:02",
        "source": "arxiv",
        "comment": "Under Review",
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on building multilingual terminologies for South African languages, which is not directly related to information retrieval, search technologies, or query understanding. Although it mentions a Retrieval-Augmented Generation (RAG) pipeline, the primary focus is on terminology aggregation and standardization, rather than ranking models or user behavior modeling."
    },
    {
        "title": "Pay What LLM Wants: Can LLM Simulate Economics Experiment with 522 Real-human Persona?",
        "abstract": "Recent advances in Large Language Models (LLMs) have generated significant\ninterest in their capacity to simulate human-like behaviors, yet most studies\nrely on fictional personas rather than actual human data. We address this\nlimitation by evaluating LLMs' ability to predict individual economic\ndecision-making using Pay-What-You-Want (PWYW) pricing experiments with real\n522 human personas. Our study systematically compares three state-of-the-art\nmultimodal LLMs using detailed persona information from 522 Korean participants\nin cultural consumption scenarios. We investigate whether LLMs can accurately\nreplicate individual human choices and how persona injection methods affect\nprediction performance. Results reveal that while LLMs struggle with precise\nindividual-level predictions, they demonstrate reasonable group-level\nbehavioral tendencies. Also, we found that commonly adopted prompting\ntechniques are not much better than naive prompting methods; reconstruction of\npersonal narrative nor retrieval augmented generation have no significant gain\nagainst simple prompting method. We believe that these findings can provide the\nfirst comprehensive evaluation of LLMs' capabilities on simulating economic\nbehavior using real human data, offering empirical guidance for persona-based\nsimulation in computational social science.",
        "url": "http://arxiv.org/abs/2508.03262v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03262v1",
        "arxiv_id": "2508.03262v1",
        "authors": [
            "Junhyuk Choi",
            "Hyeonchu Park",
            "Haemin Lee",
            "Hyebeen Shin",
            "Hyun Joung Jin",
            "Bugeun Kim"
        ],
        "submitted": "2025-08-05 09:37:37",
        "source": "arxiv",
        "comment": "Preprint",
        "score": 5,
        "keyword_reasons": [
            "Found 'retrieval augmented generation' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'korea' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on evaluating Large Language Models' ability to simulate human-like behaviors in economic decision-making, which is outside the user's primary focus."
    },
    {
        "title": "Long Story Generation via Knowledge Graph and Literary Theory",
        "abstract": "The generation of a long story consisting of several thousand words is a\nsub-task in the field of long text generation~(LTG). Previous research has\naddressed this challenge through outline-based generation, which employs a\nmulti-stage method for generating outlines into stories. However, this approach\nsuffers from two common issues: almost inevitable theme drift caused by the\nloss of memory of previous outlines, and tedious plots with incoherent logic\nthat are less appealing to human readers.\n  In this paper, we propose the multi-agent Story Generator structure to\nimprove the multi-stage method, using large language models~(LLMs) as the core\ncomponents of agents. To avoid theme drift, we introduce a memory storage model\ncomprising two components: a long-term memory storage that identifies the most\nimportant memories, thereby preventing theme drift; and a short-term memory\nstorage that retains the latest outlines from each generation round. To\nincorporate engaging elements into the story, we design a story theme obstacle\nframework based on literary narratology theory that introduces uncertain\nfactors and evaluation criteria to generate outline. This framework calculates\nthe similarity of the former storyline and enhances the appeal of the story by\nbuilding a knowledge graph and integrating new node content. Additionally, we\nestablish a multi-agent interaction stage to simulate writer-reader interaction\nthrough dialogue and revise the story text according to feedback, to ensure it\nremains consistent and logical. Evaluations against previous methods\ndemonstrate that our approach can generate higher-quality long stories.",
        "url": "http://arxiv.org/abs/2508.03137v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03137v1",
        "arxiv_id": "2508.03137v1",
        "authors": [
            "Ge Shi",
            "Kaiyu Huang",
            "Guochen Feng"
        ],
        "submitted": "2025-08-05 06:35:14",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on long story generation, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions large language models, the context is different from the user's interests in NLP and IR. The paper's emphasis on literary theory and knowledge graph is also not relevant to the user's research areas."
    },
    {
        "title": "Coherent Multimodal Reasoning with Iterative Self-Evaluation for Vision-Language Models",
        "abstract": "Despite significant advancements, current large language models (LLMs) and\nvision-language models (LVLMs) continue to struggle with complex, multi-step,\ncross-modal common sense reasoning tasks, often exhibiting a lack of\n\"deliberative thinking.\" They tend to rely on superficial associations rather\nthan deep, chained inference, particularly when integrating visual information\nwith abstract concepts. To address this, we propose the Coherent Multimodal\nReasoning Framework (CMRF), a novel approach that enhances LVLMs' common sense\nreasoning capabilities through an iterative, self-evaluating inference\nmechanism. CMRF mimics human problem-solving by decomposing complex queries,\ngenerating step-by-step inferences, and self-correcting errors. Our framework\nintegrates three key modules: a Reasoning Decomposition Unit (RDU) for breaking\ndown problems into sub-questions, a Contextual Inference Engine (CIE) for\ncontextual inference, and a Coherence Assessment Module (CAM) for evaluating\nlogical consistency and confidence. Coupled with an Adaptive Iterative\nRefinement strategy, CMRF systematically refines its reasoning paths. Built\nupon LLaVA-1.6-34B and trained on a novel Multimodal Daily Activity Reasoning\n(MDAR) dataset, CMRF achieves state-of-the-art performance among open-source\nLVLMs on challenging benchmarks like VCR, A-OKVQA, and DailyLife-MRC. It\nattains an average accuracy of 69.4%, surpassing the best open-source baseline\nby +2.4 percentage points, with particular strength in complex reasoning\nscenarios. Extensive ablation studies and human evaluations confirm the\ncritical contributions of each module and the effectiveness of iterative\nrefinement in fostering more coherent and accurate reasoning.",
        "url": "http://arxiv.org/abs/2508.02886v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02886v1",
        "arxiv_id": "2508.02886v1",
        "authors": [
            "Wenjie Luo",
            "Ruocheng Li",
            "Shanshan Zhu",
            "Julian Perry"
        ],
        "submitted": "2025-08-04 20:33:58",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a novel framework for multimodal reasoning, which is not directly related to information retrieval or search technologies. While it touches on topics like query decomposition and inference, the focus is on vision-language models and multimodal reasoning, which is not a core area of interest for the user. The paper's relevance is limited to the user's interest in NLP and data mining, but the connection is not strong enough to warrant a higher score."
    },
    {
        "title": "Tackling Distribution Shift in LLM via KILO: Knowledge-Instructed Learning for Continual Adaptation",
        "abstract": "Large Language Models (LLMs) often suffer from performance degradation when\nfaced with domain shifts, primarily due to catastrophic forgetting. In this\nwork, we propose KILO (Knowledge-Instructed Learning for Continual Adaptation),\na novel continual learning framework that integrates dynamic knowledge graphs\nwith instruction tuning. By leveraging retrieved domain-specific knowledge as\nguidance during training, KILO enhances both adaptability to new domains and\nretention of previously acquired knowledge. We pretrain our model on\nWikiText-103 and evaluate sequential adaptation across four diverse target\ndomains: BioASQ, SciQ, TweetEval, and MIND. Our experiments demonstrate that\nKILO consistently outperforms strong baselines, including continual\nfine-tuning, ERNIE 2.0, and CPT, in terms of backward transfer, forward\ntransfer, F1 score, retention rate, and training efficiency. These results\nhighlight the effectiveness of combining structured knowledge retrieval and\ninstruction prompting to overcome domain shift challenges in continual learning\nscenarios.",
        "url": "http://arxiv.org/abs/2508.03571v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03571v1",
        "arxiv_id": "2508.03571v1",
        "authors": [
            "Iing Muttakhiroh",
            "Thomas Fevens"
        ],
        "submitted": "2025-08-05 15:39:37",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on Large Language Models and continual learning, which is not directly related to the user's interests in Information Retrieval, Search technologies, and query understanding. Although it mentions knowledge retrieval, it is not in the context of query understanding or ranking models, and the paper's primary concern is adapting to domain shifts in language models, which is not a central match for the user's research themes."
    },
    {
        "title": "CF-RAG: A Dataset and Method for Carbon Footprint QA Using Retrieval-Augmented Generation",
        "abstract": "Product sustainability reports provide valuable insights into the\nenvironmental impacts of a product and are often distributed in PDF format.\nThese reports often include a combination of tables and text, which complicates\ntheir analysis. The lack of standardization and the variability in reporting\nformats further exacerbate the difficulty of extracting and interpreting\nrelevant information from large volumes of documents. In this paper, we tackle\nthe challenge of answering questions related to carbon footprints within\nsustainability reports available in PDF format. Unlike previous approaches, our\nfocus is on addressing the difficulties posed by the unstructured and\ninconsistent nature of text extracted from PDF parsing. To facilitate this\nanalysis, we introduce CarbonPDF-QA, an open-source dataset containing\nquestion-answer pairs for 1735 product report documents, along with\nhuman-annotated answers. Our analysis shows that GPT-4o struggles to answer\nquestions with data inconsistencies. To address this limitation, we propose\nCarbonPDF, an LLM-based technique specifically designed to answer carbon\nfootprint questions on such datasets. We develop CarbonPDF by fine-tuning Llama\n3 with our training data. Our results show that our technique outperforms\ncurrent state-of-the-art techniques, including question-answering (QA) systems\nfinetuned on table and text data.",
        "url": "http://arxiv.org/abs/2508.03489v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03489v1",
        "arxiv_id": "2508.03489v1",
        "authors": [
            "Kaiwen Zhao",
            "Bharathan Balaji",
            "Stephen Lee"
        ],
        "submitted": "2025-08-05 14:20:10",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on a specific domain (carbon footprint QA) and uses techniques from Natural Language Processing (NLP), but it does not directly relate to Information Retrieval (IR) or Search technologies, which are the user's primary research interests."
    },
    {
        "title": "ReDSM5: A Reddit Dataset for DSM-5 Depression Detection",
        "abstract": "Depression is a pervasive mental health condition that affects hundreds of\nmillions of individuals worldwide, yet many cases remain undiagnosed due to\nbarriers in traditional clinical access and pervasive stigma. Social media\nplatforms, and Reddit in particular, offer rich, user-generated narratives that\ncan reveal early signs of depressive symptomatology. However, existing\ncomputational approaches often label entire posts simply as depressed or not\ndepressed, without linking language to specific criteria from the DSM-5, the\nstandard clinical framework for diagnosing depression. This limits both\nclinical relevance and interpretability. To address this gap, we introduce\nReDSM5, a novel Reddit corpus comprising 1484 long-form posts, each\nexhaustively annotated at the sentence level by a licensed psychologist for the\nnine DSM-5 depression symptoms. For each label, the annotator also provides a\nconcise clinical rationale grounded in DSM-5 methodology. We conduct an\nexploratory analysis of the collection, examining lexical, syntactic, and\nemotional patterns that characterize symptom expression in social media\nnarratives. Compared to prior resources, ReDSM5 uniquely combines\nsymptom-specific supervision with expert explanations, facilitating the\ndevelopment of models that not only detect depression but also generate\nhuman-interpretable reasoning. We establish baseline benchmarks for both\nmulti-label symptom classification and explanation generation, providing\nreference results for future research on detection and interpretability.",
        "url": "http://arxiv.org/abs/2508.03399v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03399v1",
        "arxiv_id": "2508.03399v1",
        "authors": [
            "Eliseo Bao",
            "Anxo PÃ©rez",
            "Javier Parapar"
        ],
        "submitted": "2025-08-05 12:48:06",
        "source": "arxiv",
        "comment": "Accepted as a resource paper at CIKM 2025",
        "score": 4,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus is on depression detection and symptom classification, which is outside the scope of your interests."
    },
    {
        "title": "Privacy-Aware Decoding: Mitigating Privacy Leakage of Large Language Models in Retrieval-Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) enhances the factual accuracy of large\nlanguage models (LLMs) by conditioning outputs on external knowledge sources.\nHowever, when retrieval involves private or sensitive data, RAG systems are\nsusceptible to extraction attacks that can leak confidential information\nthrough generated responses. We propose Privacy-Aware Decoding (PAD), a\nlightweight, inference-time defense that adaptively injects calibrated Gaussian\nnoise into token logits during generation. PAD integrates confidence-based\nscreening to selectively protect high-risk tokens, efficient sensitivity\nestimation to minimize unnecessary noise, and context-aware noise calibration\nto balance privacy with generation quality. A \\renyi Differential Privacy (RDP)\naccountant rigorously tracks cumulative privacy loss, enabling explicit\nper-response $(\\varepsilon, \\delta)$-DP guarantees for sensitive outputs.\nUnlike prior approaches requiring retraining or corpus-level filtering, PAD is\nmodel-agnostic and operates entirely at decoding time with minimal\ncomputational overhead. Experiments on three real-world datasets demonstrate\nthat PAD substantially reduces private information leakage while preserving\nresponse utility, outperforming existing retrieval- and post-processing-based\ndefenses. Our work takes an important step toward mitigating privacy risks in\nRAG via decoding strategies, paving the way for universal and scalable privacy\nsolutions in sensitive domains. Our code is available:\nhttps://github.com/wang2226/PAD.",
        "url": "http://arxiv.org/abs/2508.03098v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03098v1",
        "arxiv_id": "2508.03098v1",
        "authors": [
            "Haoran Wang",
            "Xiongxiao Xu",
            "Baixiang Huang",
            "Kai Shu"
        ],
        "submitted": "2025-08-05 05:22:13",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on privacy-aware decoding for retrieval-augmented generation, which is not directly related to the user's research interests in information retrieval, search technologies, query understanding, ranking models, and user behavior modeling. While the paper touches on retrieval, it is primarily concerned with privacy and does not address the user's core research themes."
    },
    {
        "title": "SustainableQA: A Comprehensive Question Answering Dataset for Corporate Sustainability and EU Taxonomy Reporting",
        "abstract": "The growing demand for corporate sustainability transparency, particularly\nunder new regulations like the EU Taxonomy, necessitates precise data\nextraction from large, unstructured corporate reports. Large Language Models\n(LLMs) and Retrieval-Augmented Generation (RAG) systems, requires high-quality,\ndomain-specific question-answering (QA) datasets to excel at particular\ndomains. To address this, we introduce SustainableQA, a novel dataset and a\nscalable pipeline for generating a comprehensive QA datasets from corporate\nsustainability reports and annual reports. Our approach integrates semantic\nchunk classification, a hybrid span extraction pipeline combining fine-tuned\nNamed Entity Recognition (NER), rule-based methods, and LLM-driven refinement,\nalongside a specialized table-to-paragraph transformation. With over 195,000\ndiverse factoid and non-factoid QA pairs, SustainableQA is an effective\nresource for developing and benchmarking advanced knowledge assistants capable\nof navigating complex sustainability compliance",
        "url": "http://arxiv.org/abs/2508.03000v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03000v1",
        "arxiv_id": "2508.03000v1",
        "authors": [
            "Mohammed Ali",
            "Abdelrahman Abdallah",
            "Adam Jatowt"
        ],
        "submitted": "2025-08-05 02:03:59",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on creating a question answering dataset for corporate sustainability and EU Taxonomy reporting, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves question answering and language models, the domain-specific focus on sustainability and compliance is not aligned with the user's interests."
    },
    {
        "title": "A Multi-Agent System for Complex Reasoning in Radiology Visual Question Answering",
        "abstract": "Radiology visual question answering (RVQA) provides precise answers to\nquestions about chest X-ray images, alleviating radiologists' workload. While\nrecent methods based on multimodal large language models (MLLMs) and\nretrieval-augmented generation (RAG) have shown promising progress in RVQA,\nthey still face challenges in factual accuracy, hallucinations, and cross-modal\nmisalignment. We introduce a multi-agent system (MAS) designed to support\ncomplex reasoning in RVQA, with specialized agents for context understanding,\nmultimodal reasoning, and answer validation. We evaluate our system on a\nchallenging RVQA set curated via model disagreement filtering, comprising\nconsistently hard cases across multiple MLLMs. Extensive experiments\ndemonstrate the superiority and effectiveness of our system over strong MLLM\nbaselines, with a case study illustrating its reliability and interpretability.\nThis work highlights the potential of multi-agent approaches to support\nexplainable and trustworthy clinical AI applications that require complex\nreasoning.",
        "url": "http://arxiv.org/abs/2508.02841v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02841v1",
        "arxiv_id": "2508.02841v1",
        "authors": [
            "Ziruo Yi",
            "Jinyu Liu",
            "Ting Xiao",
            "Mark V. Albert"
        ],
        "submitted": "2025-08-04 19:09:52",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on radiology visual question answering, which is not directly related to the user's interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions multimodal large language models and retrieval-augmented generation, these concepts are not applied to the user's areas of focus, such as query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Defending Against Knowledge Poisoning Attacks During Retrieval-Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to\nboost the capabilities of large language models (LLMs) by incorporating\nexternal, up-to-date knowledge sources. However, this introduces a potential\nvulnerability to knowledge poisoning attacks, where attackers can compromise\nthe knowledge source to mislead the generation model. One such attack is the\nPoisonedRAG in which the injected adversarial texts steer the model to generate\nan attacker-chosen response to a target question. In this work, we propose\nnovel defense methods, FilterRAG and ML-FilterRAG, to mitigate the PoisonedRAG\nattack. First, we propose a new property to uncover distinct properties to\ndifferentiate between adversarial and clean texts in the knowledge data source.\nNext, we employ this property to filter out adversarial texts from clean ones\nin the design of our proposed approaches. Evaluation of these methods using\nbenchmark datasets demonstrate their effectiveness, with performances close to\nthose of the original RAG systems.",
        "url": "http://arxiv.org/abs/2508.02835v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02835v1",
        "arxiv_id": "2508.02835v1",
        "authors": [
            "Kennedy Edemacu",
            "Vinay M. Shashidhar",
            "Micheal Tuape",
            "Dan Abudu",
            "Beakcheol Jang",
            "Jong Wook Kim"
        ],
        "submitted": "2025-08-04 19:03:52",
        "source": "arxiv",
        "comment": "Preprint for Submission",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses Retrieval-Augmented Generation (RAG) and knowledge poisoning attacks, which is somewhat related to information retrieval and search technologies. However, the focus on language models and generation rather than query understanding, ranking models, and user behavior modeling limits its relevance to the user's core research interests."
    },
    {
        "title": "Personalized Recommendation of Dish and Restaurant Collections on iFood",
        "abstract": "Food delivery platforms face the challenge of helping users navigate vast\ncatalogs of restaurants and dishes to find meals they truly enjoy. This paper\npresents RED, an automated recommendation system designed for iFood, Latin\nAmerica's largest on-demand food delivery platform, to personalize the\nselection of curated food collections displayed to millions of users. Our\napproach employs a LightGBM classifier that scores collections based on three\nfeature groups: collection characteristics, user-collection similarity, and\ncontextual information. To address the cold-start problem of recommending newly\ncreated collections, we develop content-based representations using item\nembeddings and implement monotonicity constraints to improve generalization. We\ntackle data scarcity by bootstrapping from category carousel interactions and\naddress visibility bias through unbiased sampling of impressions and purchases\nin production. The system demonstrates significant real-world impact through\nextensive A/B testing with 5-10% of iFood's user base. Online results of our\nA/B tests add up to 97% improvement in Card Conversion Rate and 1.4% increase\nin overall App Conversion Rate compared to popularity-based baselines. Notably,\nour offline accuracy metrics strongly correlate with online performance,\nenabling reliable impact prediction before deployment. To our knowledge, this\nis the first work to detail large-scale recommendation of curated food\ncollections in a dynamic commercial environment.",
        "url": "http://arxiv.org/abs/2508.03670v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03670v1",
        "arxiv_id": "2508.03670v1",
        "authors": [
            "Fernando F. Granado",
            "Davi A. Bezerra",
            "Iuri Queiroz",
            "Nathan Oliveira",
            "Pedro Fernandes",
            "Bruno Schock"
        ],
        "submitted": "2025-08-05 17:34:19",
        "source": "arxiv",
        "comment": "Workshop on Two-sided Marketplace Optimization: Search, Discovery,\n  Matching, Pricing & Growth in conjunction with KDD Conference (KDD 2025) in\n  Toronto, Canada",
        "score": 3,
        "keyword_reasons": [
            "Found 'conversion rate' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on personalized recommendation of dish and restaurant collections, which is related to information retrieval and search technologies. However, the emphasis is on recommender systems, which is not the primary focus of the user's research interests. The paper's use of machine learning and data mining techniques is relevant, but the application in the food delivery domain is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "OpenLifelogQA: An Open-Ended Multi-Modal Lifelog Question-Answering Dataset",
        "abstract": "Lifelogging refers to the process of passively collecting, storing, and\nanalysing personal daily life data using wearable devices. This data can\nsupport applications in memory preservation and enhancement. For example, using\nan ask-and-answer strategy, question-answering (QA) on lifelog data opens an\ninteractive and interesting way to explore memorable events and insights into\ndaily life. However, research resources for QA on lifelog data are limited to\nsmall-sized or synthetic QA datasets. In this paper, we present a novel lifelog\nQA dataset called OpenLifelogQA, building upon an 18-month lifelog dataset. Our\ndataset focuses on an open-ended and practical QA with real-world application\nin daily lifelog usage. We construct 14,187 pairs of Q&A with diverse types and\ndifficulty levels. A baseline experiment is reported for this dataset with\ncompetitive average performance of 89.7% BERT Score, 25.87% ROUGE-L and 3.9665\nLLM Score from LLaVA-NeXT-Interleave 7B model. We release this Q&A dataset to\nthe research community to support new research into lifelog technologies, such\nas enabling personal chat-based assistants for lifelog data to become a\nreality.",
        "url": "http://arxiv.org/abs/2508.03583v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03583v1",
        "arxiv_id": "2508.03583v1",
        "authors": [
            "Quang-Linh Tran",
            "Binh Nguyen",
            "Gareth J. F. Jones",
            "Cathal Gurrin"
        ],
        "submitted": "2025-08-05 15:50:16",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on a lifelog question-answering dataset, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions a baseline experiment with a language model, the primary focus is on lifelog data and its applications, rather than on information retrieval or search."
    },
    {
        "title": "EmbedGrad: Gradient-Based Prompt Optimization in Embedding Space for Large Language Models",
        "abstract": "Effectively adapting powerful pretrained foundation models to diverse tasks\nremains a key challenge in AI deployment. Current approaches primarily follow\ntwo paradigms:discrete optimization of text prompts through prompt engineering,\nor continuous adaptation via additional trainable parameters. Both exhibit\nlimitations-discrete methods lack refinement precision while parameter-based\ntechniques increase complexity and reduce interpretability. To address these\nconstraints, we propose EmbedGrad, a novel framework that optimizes text prompt\nembeddings through gradient-based refinement. Our approach uniquely decouples\ntraining from deployment:during optimization,labeled examples guide precise\nembedding adjustments while preserving semantic meaning; during inference, only\noptimized embeddings integrate with user queries. This enables fine-grained\ncalibration impossible in text space, such as enhancing the reasoning\ncapability of prompts like please reason step by step. Comprehensive\nevaluations across mathematical reasoning, sentiment analysis, and causal\njudgment tasks demonstrate EmbedGrad's effectiveness:optimizing this reasoning\nprompt for Qwen2.5-Math-1.5B increased accuracy from 14.74\\% to 58.96\\% on\nmathematical problems. Consistent improvements were observed across model\nscales (0.5B-14B) and all tasks, with particularly significant gains for\nsmaller models on complex problems like causal judgment. By bridging prompt\nengineering and parameter efficiency without architectural changes, our work\nestablishes embedding refinement as a powerful new paradigm for task\nadaptation.",
        "url": "http://arxiv.org/abs/2508.03533v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03533v1",
        "arxiv_id": "2508.03533v1",
        "authors": [
            "Xiaoming Hou",
            "Jiquan Zhang",
            "Zibin Lin",
            "DaCheng Tao",
            "Shengli Zhang"
        ],
        "submitted": "2025-08-05 15:03:10",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'queries' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a novel framework for optimizing text prompt embeddings through gradient-based refinement, which is relevant to the field of Natural Language Processing (NLP). However, it does not directly relate to Information Retrieval (IR) or Search technologies, which are the user's primary research interests. The paper's focus on large language models and task adaptation is somewhat related to the user's background in e-commerce and NLP, but it does not address query understanding, ranking models, or user behavior modeling, which are key areas of interest."
    },
    {
        "title": "MoKA: Mixture of Kronecker Adapters",
        "abstract": "Parameter-efficient fine-tuning (PEFT) is essential for reducing the\ncomputational overhead of large language models (LLMs). Low-rank family\nadapters are commonly used to control the parameter size efficiently while\nmaintaining the generative power of LLMs. However, their limited expressiveness\ndue to the rank constraint often restricts their performance on complex tasks.\nWe propose Mixture of Kronecker Adapters (MoKA), a new generation of Kronecker\nadapters that addresses this limitation by modeling weight updates as a mixture\nof Kronecker products. Our proposed adapter leverages a gating mechanism that\nmeasures the importance of each Kronecker factor, enabling more expressive\nadaptation. Moreover, MoKA enables a rank flexibility that provides a better\ntrade-off between parameter efficiency and accuracy. To ensure hardware\nefficiency, we reformulate Kronecker computations using standard matrix\noperations, allowing seamless deployment on GPU-optimized hardware. We conduct\nextensive experiments on instruction-tuning and commonsense reasoning tasks\nusing low-bit quantized versions of LLaMA2-7B and LLaMA3-8B models. MoKA not\nonly outperforms PEFT baselines, but also reduces the number of trainable\nparameters up to 27x, achieving state-of-the-art trade-offs between performance\nand parameter efficiency.",
        "url": "http://arxiv.org/abs/2508.03527v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03527v1",
        "arxiv_id": "2508.03527v1",
        "authors": [
            "Mohammadreza Sadeghi",
            "Mahsa Ghazvini Nejad",
            "MirHamed Jafarzadeh Asl",
            "Yu Gu",
            "Yuanhao Yu",
            "Masoud Asgharian",
            "Vahid Partovi Nia"
        ],
        "submitted": "2025-08-05 14:58:14",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on parameter-efficient fine-tuning of large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on adapter architectures, the topic is more relevant to NLP and model optimization, rather than user behavior modeling or ranking models."
    },
    {
        "title": "fact check AI at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-checked Claim Retrieval",
        "abstract": "SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim\nRetrieval is approached as a Learning-to-Rank task using a bi-encoder model\nfine-tuned from a pre-trained transformer optimized for sentence similarity.\nTraining used both the source languages and their English translations for\nmultilingual retrieval and only English translations for cross-lingual\nretrieval. Using lightweight models with fewer than 500M parameters and\ntraining on Kaggle T4 GPUs, the method achieved 92% Success@10 in multilingual\nand 80% Success@10 in 5th in crosslingual and 10th in multilingual tracks.",
        "url": "http://arxiv.org/abs/2508.03475v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03475v1",
        "arxiv_id": "2508.03475v1",
        "authors": [
            "Pranshu Rastogi"
        ],
        "submitted": "2025-08-05 14:10:09",
        "source": "arxiv",
        "comment": "7 pages, 6 tables. Code available at\n  https://github.com/pranshurastogi29/SemEval-2025-ACL-Multi-and-Crosslingual-Retrieval-using-Bi-encoders",
        "score": 3,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper is somewhat related to my research interests in Information Retrieval, particularly in the area of Learning to Rank. The use of a bi-encoder model and fine-tuning from a pre-trained transformer is relevant to my focus on ranking models. However, the specific application of fact-checked claim retrieval and the multilingual/crosslingual aspect is not directly aligned with my primary interests in query understanding, user behavior modeling, and real-time relevance optimization."
    },
    {
        "title": "Thinking with Nothinking Calibration: A New In-Context Learning Paradigm in Reasoning Large Language Models",
        "abstract": "Reasoning large language models (RLLMs) have recently demonstrated remarkable\ncapabilities through structured and multi-step reasoning. While prior research\nhas primarily focused on improving their training and inference strategies,\ntheir potential for in-context learning (ICL) remains largely underexplored. To\nfill this gap, we propose Thinking with Nothinking Calibration (JointThinking),\na new ICL paradigm that leverages the structured difference between two\nreasoning modes, i.e., Thinking and Nothinking, to improve reasoning accuracy.\nSpecifically, our method prompts the model to generate two answers in parallel:\none in Thinking mode and the other in Nothinking mode. A second round of\nThinking is triggered only when the two initial responses are inconsistent,\nusing a single prompt that incorporates the original question and both\ncandidate answers. Since such disagreement occurs infrequently (e.g., only 6\\%\nin GSM8K), our method performs just one round of reasoning in most cases,\nresulting in minimal latency overhead. Extensive experiments across multiple\nreasoning benchmarks demonstrate that JointThinking significantly outperforms\nfew-shot chain-of-thought (CoT) and majority voting with improved answer\nrobustness. Moreover, It achieves comparable in-distribution performance to\ntraining-based SOTA method, while substantially outperforming on\nout-of-distribution tasks. We further conduct a systematic analysis of the\ncalibration mechanism, showing that leveraging different reasoning modes\nconsistently lowers the error rate and highlights the value of structural\nthinking diversity. Additionally, we observe that the performance gap between\nactual and ideal reasoning narrows as model size increases in the second round\nof thinking, indicating the strong scalability of our approach. Finally, we\ndiscuss current limitations and outline promising directions for future ICL\nresearch in RLLMs.",
        "url": "http://arxiv.org/abs/2508.03363v2",
        "pdf_url": "http://arxiv.org/pdf/2508.03363v2",
        "arxiv_id": "2508.03363v2",
        "authors": [
            "Haotian Wu",
            "Bo Xu",
            "Yao Shu",
            "Menglin Yang",
            "Chengwei Qin"
        ],
        "submitted": "2025-08-05 12:09:55",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on large language models and their ability to reason, which is not directly related to information retrieval, search technologies, or query understanding. The concepts of thinking and no-thinking calibration are not relevant to the user's research interests in IR and NLP."
    },
    {
        "title": "Investigating Gender Bias in LLM-Generated Stories via Psychological Stereotypes",
        "abstract": "As Large Language Models (LLMs) are increasingly used across different\napplications, concerns about their potential to amplify gender biases in\nvarious tasks are rising. Prior research has often probed gender bias using\nexplicit gender cues as counterfactual, or studied them in sentence completion\nand short question answering tasks. These formats might overlook more implicit\nforms of bias embedded in generative behavior of longer content. In this work,\nwe investigate gender bias in LLMs using gender stereotypes studied in\npsychology (e.g., aggressiveness or gossiping) in an open-ended task of\nnarrative generation. We introduce a novel dataset called StereoBias-Stories\ncontaining short stories either unconditioned or conditioned on (one, two, or\nsix) random attributes from 25 psychological stereotypes and three task-related\nstory endings. We analyze how the gender contribution in the overall story\nchanges in response to these attributes and present three key findings: (1)\nWhile models, on average, are highly biased towards male in unconditioned\nprompts, conditioning on attributes independent from gender stereotypes\nmitigates this bias. (2) Combining multiple attributes associated with the same\ngender stereotype intensifies model behavior, with male ones amplifying bias\nand female ones alleviating it. (3) Model biases align with psychological\nground-truth used for categorization, and alignment strength increases with\nmodel size. Together, these insights highlight the importance of\npsychology-grounded evaluation of LLMs.",
        "url": "http://arxiv.org/abs/2508.03292v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03292v1",
        "arxiv_id": "2508.03292v1",
        "authors": [
            "Shahed Masoudian",
            "Gustavo Escobedo",
            "Hannah Strauss",
            "Markus Schedl"
        ],
        "submitted": "2025-08-05 10:10:26",
        "source": "arxiv",
        "comment": "Under Review",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper investigates gender bias in Large Language Models (LLMs) using psychological stereotypes, which is not directly related to my research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on NLP, the focus is on bias detection and mitigation in LLMs, which is not a central theme in my research."
    },
    {
        "title": "RooseBERT: A New Deal For Political Language Modelling",
        "abstract": "The increasing amount of political debates and politics-related discussions\ncalls for the definition of novel computational methods to automatically\nanalyse such content with the final goal of lightening up political\ndeliberation to citizens. However, the specificity of the political language\nand the argumentative form of these debates (employing hidden communication\nstrategies and leveraging implicit arguments) make this task very challenging,\neven for current general-purpose pre-trained Language Models. To address this\nissue, we introduce a novel pre-trained Language Model for political discourse\nlanguage called RooseBERT. Pre-training a language model on a specialised\ndomain presents different technical and linguistic challenges, requiring\nextensive computational resources and large-scale data. RooseBERT has been\ntrained on large political debate and speech corpora (8K debates, each composed\nof several sub-debates on different topics) in English. To evaluate its\nperformances, we fine-tuned it on four downstream tasks related to political\ndebate analysis, i.e., named entity recognition, sentiment analysis, argument\ncomponent detection and classification, and argument relation prediction and\nclassification. Our results demonstrate significant improvements over\ngeneral-purpose Language Models on these four tasks, highlighting how\ndomain-specific pre-training enhances performance in political debate analysis.\nWe release the RooseBERT language model for the research community.",
        "url": "http://arxiv.org/abs/2508.03250v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03250v1",
        "arxiv_id": "2508.03250v1",
        "authors": [
            "Deborah Dore",
            "Elena Cabrio",
            "Serena Villata"
        ],
        "submitted": "2025-08-05 09:28:20",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on political language modeling, which is not directly related to the user's interests in Information Retrieval, Search technologies, and query understanding. Although it mentions pre-training a language model, the context is specific to political discourse and does not align with the user's background in e-commerce or general NLP applications."
    },
    {
        "title": "Beyond Content: How Grammatical Gender Shapes Visual Representation in Text-to-Image Models",
        "abstract": "Research on bias in Text-to-Image (T2I) models has primarily focused on\ndemographic representation and stereotypical attributes, overlooking a\nfundamental question: how does grammatical gender influence visual\nrepresentation across languages? We introduce a cross-linguistic benchmark\nexamining words where grammatical gender contradicts stereotypical gender\nassociations (e.g., ``une sentinelle'' - grammatically feminine in French but\nreferring to the stereotypically masculine concept ``guard''). Our dataset\nspans five gendered languages (French, Spanish, German, Italian, Russian) and\ntwo gender-neutral control languages (English, Chinese), comprising 800 unique\nprompts that generated 28,800 images across three state-of-the-art T2I models.\nOur analysis reveals that grammatical gender dramatically influences image\ngeneration: masculine grammatical markers increase male representation to 73\\%\non average (compared to 22\\% with gender-neutral English), while feminine\ngrammatical markers increase female representation to 38\\% (compared to 28\\% in\nEnglish). These effects vary systematically by language resource availability\nand model architecture, with high-resource languages showing stronger effects.\nOur findings establish that language structure itself, not just content, shapes\nAI-generated visual outputs, introducing a new dimension for understanding bias\nand fairness in multilingual, multimodal systems.",
        "url": "http://arxiv.org/abs/2508.03199v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03199v1",
        "arxiv_id": "2508.03199v1",
        "authors": [
            "Muhammed Saeed",
            "Shaina Raza",
            "Ashmal Vayani",
            "Muhammad Abdul-Mageed",
            "Ali Emami",
            "Shady Shehata"
        ],
        "submitted": "2025-08-05 08:13:07",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on the impact of grammatical gender on visual representation in Text-to-Image models, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and query understanding. The paper's topic is more relevant to Natural Language Processing and multimodal systems, but the user's primary focus is on information retrieval and real-time relevance optimization, making this paper only loosely relevant."
    },
    {
        "title": "CoCoTen: Detecting Adversarial Inputs to Large Language Models through Latent Space Features of Contextual Co-occurrence Tensors",
        "abstract": "The widespread use of Large Language Models (LLMs) in many applications marks\na significant advance in research and practice. However, their complexity and\nhard-to-understand nature make them vulnerable to attacks, especially\njailbreaks designed to produce harmful responses. To counter these threats,\ndeveloping strong detection methods is essential for the safe and reliable use\nof LLMs. This paper studies this detection problem using the Contextual\nCo-occurrence Matrix, a structure recognized for its efficacy in data-scarce\nenvironments. We propose a novel method leveraging the latent space\ncharacteristics of Contextual Co-occurrence Matrices and Tensors for the\neffective identification of adversarial and jailbreak prompts. Our evaluations\nshow that this approach achieves a notable F1 score of 0.83 using only 0.5% of\nlabeled prompts, which is a 96.6% improvement over baselines. This result\nhighlights the strength of our learned patterns, especially when labeled data\nis scarce. Our method is also significantly faster, speedup ranging from 2.3 to\n128.4 times compared to the baseline models. To support future research and\nreproducibility, we have made our implementation publicly available.",
        "url": "http://arxiv.org/abs/2508.02997v2",
        "pdf_url": "http://arxiv.org/pdf/2508.02997v2",
        "arxiv_id": "2508.02997v2",
        "authors": [
            "Sri Durga Sai Sowmya Kadali",
            "Evangelos E. Papalexakis"
        ],
        "submitted": "2025-08-05 01:53:32",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "While the paper explores a relevant topic in Natural Language Processing (NLP), it does not directly align with your primary focus on Information Retrieval (IR), query understanding, ranking models, and user behavior modeling. The paper's focus on detecting adversarial inputs to Large Language Models is not directly applicable to your research interests."
    },
    {
        "title": "Realizing Scaling Laws in Recommender Systems: A Foundation-Expert Paradigm for Hyperscale Model Deployment",
        "abstract": "While scaling laws promise significant performance gains for recommender\nsystems, efficiently deploying hyperscale models remains a major unsolved\nchallenge. In contrast to fields where FMs are already widely adopted such as\nnatural language processing and computer vision, progress in recommender\nsystems is hindered by unique challenges including the need to learn from\nonline streaming data under shifting data distributions, the need to adapt to\ndifferent recommendation surfaces with a wide diversity in their downstream\ntasks and their input distributions, and stringent latency and computational\nconstraints. To bridge this gap, we propose to leverage the Foundation-Expert\nParadigm: a framework designed for the development and deployment of hyperscale\nrecommendation FMs. In our approach, a central FM is trained on lifelong,\ncross-surface, multi-modal user data to learn generalizable knowledge. This\nknowledge is then efficiently transferred to various lightweight,\nsurface-specific ``expert\" models via target-aware embeddings, allowing them to\nadapt to local data distributions and optimization goals with minimal overhead.\nTo meet our training, inference and development needs, we built HyperCast, a\nproduction-grade infrastructure system that re-engineers training, serving,\nlogging and iteration to power this decoupled paradigm. Our approach is now\ndeployed at Meta serving tens of billions of user requests daily, demonstrating\nonline metric improvements over our previous one-stage production system while\nimproving developer velocity and maintaining infrastructure efficiency. To the\nbest of our knowledge, this work represents the first successful deployment of\na Foundation-Expert paradigm at this scale, offering a proven,\ncompute-efficient, and developer-friendly blueprint to realize the promise of\nscaling laws in recommender systems.",
        "url": "http://arxiv.org/abs/2508.02929v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02929v1",
        "arxiv_id": "2508.02929v1",
        "authors": [
            "Dai Li",
            "Kevin Course",
            "Wei Li",
            "Hongwei Li",
            "Jie Hua",
            "Yiqi Chen",
            "Zhao Zhu",
            "Rui Jian",
            "Xuan Cao",
            "Bi Xue",
            "Yu Shi",
            "Jing Qian",
            "Kai Ren",
            "Matt Ma",
            "Qunshu Zhang",
            "Rui Li"
        ],
        "submitted": "2025-08-04 22:03:13",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on recommender systems, which is a related topic, but it does not align with the user's primary interest in Information Retrieval and Search technologies. The paper's emphasis on scaling laws and deployment of hyperscale models is not directly relevant to the user's research themes."
    },
    {
        "title": "Recommending With, Not For: Co-Designing Recommender Systems for Social Good",
        "abstract": "Recommender systems are usually designed by engineers, researchers,\ndesigners, and other members of development teams. These systems are then\nevaluated based on goals set by the aforementioned teams and other business\nunits of the platforms operating the recommender systems. This design approach\nemphasizes the designers' vision for how the system can best serve the\ninterests of users, providers, businesses, and other stakeholders. Although\ndesigners may be well-informed about user needs through user experience and\nmarket research, they are still the arbiters of the system's design and\nevaluation, with other stakeholders' interests less emphasized in user-centered\ndesign and evaluation. When extended to recommender systems for social good,\nthis approach results in systems that reflect the social objectives as\nenvisioned by the designers and evaluated as the designers understand them.\nInstead, social goals and operationalizations should be developed through\nparticipatory and democratic processes that are accountable to their\nstakeholders. We argue that recommender systems aimed at improving social good\nshould be designed *by* and *with*, not just *for*, the people who will\nexperience their benefits and harms. That is, they should be designed in\ncollaboration with their users, creators, and other stakeholders as full\nco-designers, not only as user study participants.",
        "url": "http://arxiv.org/abs/2508.03792v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03792v1",
        "arxiv_id": "2508.03792v1",
        "authors": [
            "Michael D. Ekstrand",
            "Afsaneh Razi",
            "Aleksandra Sarcevic",
            "Maria Soledad Pera",
            "Robin Burke",
            "Katherine Landau Wright"
        ],
        "submitted": "2025-08-05 17:50:39",
        "source": "arxiv",
        "comment": "Accepted to ACM TORS Special Issue on Recommender Systems for Social\n  Good",
        "score": 2,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on the design and evaluation of recommender systems, but it does not address query understanding, ranking models, or user behavior modeling, which are core aspects of your research interests. The paper's emphasis on social good and participatory design processes is also not directly related to your areas of focus in Information Retrieval and Search technologies."
    },
    {
        "title": "FairLangProc: A Python package for fairness in NLP",
        "abstract": "The rise in usage of Large Language Models to near ubiquitousness in recent\nyears has risen societal concern about their applications in decision-making\ncontexts, such as organizational justice or healthcare. This, in turn, poses\nquestions about the fairness of these models in critical settings, which leads\nto the developement of different procedures to address bias in Natural Language\nProcessing. Although many datasets, metrics and algorithms have been proposed\nto measure and mitigate harmful prejudice in Natural Language Processing, their\nimplementation is diverse and far from centralized. As a response, this paper\npresents FairLangProc, a comprehensive Python package providing a common\nimplementation of some of the more recent advances in fairness in Natural\nLanguage Processing providing an interface compatible with the famous Hugging\nFace transformers library, aiming to encourage the widespread use and\ndemocratization of bias mitigation techniques. The implementation can be found\non https://github.com/arturo-perez-peralta/FairLangProc.",
        "url": "http://arxiv.org/abs/2508.03677v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03677v1",
        "arxiv_id": "2508.03677v1",
        "authors": [
            "Arturo PÃ©rez-Peralta",
            "Sandra BenÃ­tez-PeÃ±a",
            "Rosa E. Lillo"
        ],
        "submitted": "2025-08-05 17:47:53",
        "source": "arxiv",
        "comment": "40 pages, 4 figures, 3 tables",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on fairness in NLP, which is a related topic, but it does not directly address information retrieval, search technologies, or query understanding. While it mentions the use of transformers, which is a relevant area in NLP, the primary focus is on fairness and bias mitigation, rather than on ranking models or user behavior modeling."
    },
    {
        "title": "Beyond the Surface: Enhancing LLM-as-a-Judge Alignment with Human via Internal Representations",
        "abstract": "The growing scale of evaluation tasks has led to the widespread adoption of\nautomated evaluation using large language models, a paradigm known as\n\"LLMas-a-judge.\" However, improving its alignment with human preferences\nwithout complex prompts or fine-tuning remains challenging. In this work,\nmotivated by preliminary findings that middle-to-upper layers encode\nsemantically and taskrelevant representations that are often more aligned with\nhuman judgments than the final layer, we propose LAGER, a lightweight and\nefficient framework for enhancing LLM-as-a-Judge alignment with human scoring,\nvia internal representations. LAGER produces fine-grained judgment scores by\naggregating cross-layer scoretoken logits and computing the expected score from\na softmax-based distribution, with the LLM backbone kept frozen. LAGER fully\nleverages the complementary information across different layers, overcoming the\nlimitations of relying solely on the final layer. We evaluate our method on the\nstandard alignment benchmarks Flask, HelpSteer, and BIGGen using Spearman\ncorrelation, and find that LAGER achieves improvements of up to 7.5% over the\nbest baseline across these benchmarks. Without reasoning steps, LAGER matches\nor outperforms reasoning-based methods. Experiments on downstream applications,\nsuch as data selection and emotional understanding, further show the\neffectiveness of our method.",
        "url": "http://arxiv.org/abs/2508.03550v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03550v1",
        "arxiv_id": "2508.03550v1",
        "authors": [
            "Peng Lai",
            "Jianjie Zheng",
            "Sijie Cheng",
            "Yun Chen",
            "Peng Li",
            "Yang Liu",
            "Guanhua Chen"
        ],
        "submitted": "2025-08-05 15:18:36",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the alignment of large language models with human preferences, which is related to query understanding and ranking models in Information Retrieval. However, the focus on language models and internal representations is not directly aligned with the user's interests in search technologies and user behavior modeling."
    },
    {
        "title": "AIC CTU@FEVER 8: On-premise fact checking through long context RAG",
        "abstract": "In this paper, we present our fact-checking pipeline which has scored first\nin FEVER 8 shared task. Our fact-checking system is a simple two-step RAG\npipeline based on our last year's submission. We show how the pipeline can be\nredeployed on-premise, achieving state-of-the-art fact-checking performance (in\nsense of Ev2R test-score), even under the constraint of a single NVidia A10\nGPU, 23GB of graphical memory and 60s running time per claim.",
        "url": "http://arxiv.org/abs/2508.04390v1",
        "pdf_url": "http://arxiv.org/pdf/2508.04390v1",
        "arxiv_id": "2508.04390v1",
        "authors": [
            "Herbert Ullrich",
            "Jan Drchal"
        ],
        "submitted": "2025-08-05 14:03:43",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on fact-checking, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions a shared task, the context and methodology are not relevant to the user's areas of focus."
    },
    {
        "title": "Cropping outperforms dropout as an augmentation strategy for training self-supervised text embeddings",
        "abstract": "Text embeddings, i.e. vector representations of entire texts, play an\nimportant role in many NLP applications, such as retrieval-augmented\ngeneration, sentiment analysis, clustering, or visualizing collections of texts\nfor data exploration. Currently, top-performing embedding models are derived\nfrom pre-trained language models via extensive supervised fine-tuning using\ncurated text pairs. This contrasts with computer vision, where self-supervised\ntraining based on data augmentations has demonstrated remarkable success. Here\nwe systematically compare the two most well-known augmentation strategies for\npositive pair generation in contrastive learning of text embeddings. We assess\nembedding quality on MTEB and additional in-domain evaluations and show that\ncropping augmentation strongly outperforms the dropout-based approach. We find\nthat on out-of-domain data, the quality of resulting embeddings is below the\nsupervised SOTA models, but for in-domain data, self-supervised fine-tuning\nproduces high-quality text embeddings after very short fine-tuning, sometimes\nonly marginally below the supervised SOTA. Finally, we show that representation\nquality increases towards the last transformer layers, which undergo the\nlargest change during fine-tuning; and that fine-tuning only those last layers\nis sufficient to reach similar embedding quality.",
        "url": "http://arxiv.org/abs/2508.03453v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03453v1",
        "arxiv_id": "2508.03453v1",
        "authors": [
            "Rita GonzÃ¡lez-MÃ¡rquez",
            "Philipp Berens",
            "Dmitry Kobak"
        ],
        "submitted": "2025-08-05 13:54:01",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores self-supervised training of text embeddings using data augmentation, which is a topic in NLP. However, the focus on contrastive learning and embedding quality assessment is not directly related to query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval. While the paper touches on NLP applications, it does not specifically address search technologies or real-time relevance optimization."
    },
    {
        "title": "Taggus: An Automated Pipeline for the Extraction of Characters' Social Networks from Portuguese Fiction Literature",
        "abstract": "Automatically identifying characters and their interactions from fiction\nbooks is, arguably, a complex task that requires pipelines that leverage\nmultiple Natural Language Processing (NLP) methods, such as Named Entity\nRecognition (NER) and Part-of-speech (POS) tagging. However, these methods are\nnot optimized for the task that leads to the construction of Social Networks of\nCharacters. Indeed, the currently available methods tend to underperform,\nespecially in less-represented languages, due to a lack of manually annotated\ndata for training. Here, we propose a pipeline, which we call Taggus, to\nextract social networks from literary fiction works in Portuguese. Our results\nshow that compared to readily available State-of-the-Art tools -- off-the-shelf\nNER tools and Large Language Models (ChatGPT) -- the resulting pipeline, which\nuses POS tagging and a combination of heuristics, achieves satisfying results\nwith an average F1-Score of $94.1\\%$ in the task of identifying characters and\nsolving for co-reference and $75.9\\%$ in interaction detection. These\nrepresent, respectively, an increase of $50.7\\%$ and $22.3\\%$ on results\nachieved by the readily available State-of-the-Art tools. Further steps to\nimprove results are outlined, such as solutions for detecting relationships\nbetween characters. Limitations on the size and scope of our testing samples\nare acknowledged. The Taggus pipeline is publicly available to encourage\ndevelopment in this field for the Portuguese language.2",
        "url": "http://arxiv.org/abs/2508.03358v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03358v1",
        "arxiv_id": "2508.03358v1",
        "authors": [
            "Tiago G CanÃ¡rio",
            "Catarina Duarte",
            "FlÃ¡vio L. Pinheiro",
            "JoÃ£o L. M. Pereira"
        ],
        "submitted": "2025-08-05 12:03:03",
        "source": "arxiv",
        "comment": "24 pages, 5 Figures, 4 Tables",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on extracting social networks from literary fiction works in Portuguese, using NLP methods like NER and POS tagging. While it involves Natural Language Processing, it is not related to Information Retrieval, Search technologies, or query understanding, which are the user's primary research interests."
    },
    {
        "title": "Do language models accommodate their users? A study of linguistic convergence",
        "abstract": "While large language models (LLMs) are generally considered proficient in\ngenerating language, how similar their language usage is to that of humans\nremains understudied. In this paper, we test whether models exhibit linguistic\nconvergence, a core pragmatic element of human language communication, asking:\ndo models adapt, or converge, to the linguistic patterns of their user? To\nanswer this, we systematically compare model completions of exisiting dialogues\nto the original human responses across sixteen language models, three dialogue\ncorpora, and a variety of stylometric features. We find that models strongly\nconverge to the conversation's style, often significantly overfitting relative\nto the human baseline. While convergence patterns are often feature-specific,\nwe observe consistent shifts in convergence across modeling settings, with\ninstruction-tuned and larger models converging less than their pretrained\ncounterparts. Given the differences between human and model convergence\npatterns, we hypothesize that the underlying mechanisms for these behaviors are\nvery different.",
        "url": "http://arxiv.org/abs/2508.03276v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03276v1",
        "arxiv_id": "2508.03276v1",
        "authors": [
            "Terra Blevins",
            "Susanne Schmalwieser",
            "Benjamin Roth"
        ],
        "submitted": "2025-08-05 09:55:40",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the linguistic convergence of language models, which is a topic in Natural Language Processing (NLP). While it touches on the idea of models adapting to user patterns, it does not directly relate to query understanding, ranking models, or user behavior modeling in Information Retrieval (IR), which are the user's primary research interests."
    },
    {
        "title": "LECTOR: LLM-Enhanced Concept-based Test-Oriented Repetition for Adaptive Spaced Learning",
        "abstract": "Spaced repetition systems are fundamental to efficient learning and memory\nretention, but existing algorithms often struggle with semantic interference\nand personalized adaptation. We present LECTOR (\\textbf{L}LM-\\textbf{E}nhanced\n\\textbf{C}oncept-based \\textbf{T}est-\\textbf{O}riented \\textbf{R}epetition), a\nnovel adaptive scheduling algorithm specifically designed for test-oriented\nlearning scenarios, particularly language examinations where success rate is\nparamount. LECTOR leverages large language models for semantic analysis while\nincorporating personalized learning profiles, addressing the critical challenge\nof semantic confusion in vocabulary learning by utilizing LLM-powered semantic\nsimilarity assessment and integrating it with established spaced repetition\nprinciples. Our comprehensive evaluation against six baseline algorithms\n(SSP-MMC, SM2, HLR, FSRS, ANKI, THRESHOLD) across 100 simulated learners over\n100 days demonstrates significant improvements: LECTOR achieves a 90.2\\%\nsuccess rate compared to 88.4\\% for the best baseline (SSP-MMC), representing a\n2.0\\% relative improvement. The algorithm shows particular strength in handling\nsemantically similar concepts, reducing confusion-induced errors while\nmaintaining computational efficiency. Our results establish LECTOR as a\npromising direction for intelligent tutoring systems and adaptive learning\nplatforms.",
        "url": "http://arxiv.org/abs/2508.03275v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03275v1",
        "arxiv_id": "2508.03275v1",
        "authors": [
            "Jiahao Zhao"
        ],
        "submitted": "2025-08-05 09:53:26",
        "source": "arxiv",
        "comment": "15 pages, 4 figures, 1 table",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper presents a novel adaptive scheduling algorithm for test-oriented learning scenarios, leveraging large language models for semantic analysis. While it touches on semantic understanding and personalized adaptation, the focus is on language learning and vocabulary retention, which is not directly related to the user's primary research interests in Information Retrieval and Search technologies."
    },
    {
        "title": "Investigating the Cognitive Response of Brake Lights in Initiating Braking Action Using EEG",
        "abstract": "Half of all road accidents result from either lack of driver attention or\nfrom maintaining insufficient separation between vehicles. Collision from the\nrear, in particular, has been identified as the most common class of accident\nin the UK, and its influencing factors have been widely studied for many years.\nRear-mounted stop lamps, illuminated when braking, are the primary mechanism to\nalert following drivers to the need to reduce speed or brake. This paper\ndevelops a novel brain response approach to measuring subject reaction to\ndifferent brake light designs. A variety of off-the-shelf brake light\nassemblies are tested in a physical simulated driving environment to assess the\ncognitive reaction times of 22 subjects. Eight pairs of LED-based and two pairs\nof incandescent bulb-based brake light assemblies are used and\nelectroencephalogram (EEG) data recorded. Channel Pz is utilised to extract the\nP3 component evoked during the decision making process that occurs in the brain\nwhen a participant decides to lift their foot from the accelerator and depress\nthe brake. EEG analysis shows that both incandescent bulb-based lights are\nstatistically slower to evoke cognitive responses than all tested LED-based\nlights. Between the LED designs, differences are evident, but not statistically\nsignificant, attributed to the significant amount of movement artifact in the\nEEG signal.",
        "url": "http://arxiv.org/abs/2508.03274v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03274v1",
        "arxiv_id": "2508.03274v1",
        "authors": [
            "Ramaswamy Palaniappan",
            "Surej Mouli",
            "Howard Bowman",
            "Ian McLoughlin"
        ],
        "submitted": "2025-08-05 09:52:53",
        "source": "arxiv",
        "comment": "arXiv admin note: text overlap with arXiv:2010.10584",
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, data mining, or recommender systems. The topic of brake lights and cognitive response is outside the scope of your research areas."
    },
    {
        "title": "Analyzing German Parliamentary Speeches: A Machine Learning Approach for Topic and Sentiment Classification",
        "abstract": "This study investigates political discourse in the German parliament, the\nBundestag, by analyzing approximately 28,000 parliamentary speeches from the\nlast five years. Two machine learning models for topic and sentiment\nclassification were developed and trained on a manually labeled dataset. The\nmodels showed strong classification performance, achieving an area under the\nreceiver operating characteristic curve (AUROC) of 0.94 for topic\nclassification (average across topics) and 0.89 for sentiment classification.\nBoth models were applied to assess topic trends and sentiment distributions\nacross political parties and over time. The analysis reveals remarkable\nrelationships between parties and their role in parliament. In particular, a\nchange in style can be observed for parties moving from government to\nopposition. While ideological positions matter, governing responsibilities also\nshape discourse. The analysis directly addresses key questions about the\nevolution of topics, sentiment dynamics, and party-specific discourse\nstrategies in the Bundestag.",
        "url": "http://arxiv.org/abs/2508.03181v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03181v1",
        "arxiv_id": "2508.03181v1",
        "authors": [
            "Lukas PÃ¤tz",
            "Moritz Beyer",
            "Jannik SpÃ¤th",
            "Lasse Bohlen",
            "Patrick Zschech",
            "Mathias Kraus",
            "Julian Rosenberger"
        ],
        "submitted": "2025-08-05 07:44:42",
        "source": "arxiv",
        "comment": "Accepted at 20th International Conference on Wirtschaftsinformatik\n  (WI25); September 2025, M\\\"unster, Germany",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper's focus on machine learning for topic and sentiment classification in German parliamentary speeches is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP techniques, the context and application are quite different from the user's areas of focus."
    },
    {
        "title": "Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following",
        "abstract": "While advancements in the reasoning abilities of LLMs have significantly\nenhanced their performance in solving mathematical problems, coding tasks, and\ngeneral puzzles, their effectiveness in accurately adhering to instructions\nremains inconsistent, particularly with more complex directives. Our\ninvestigation identifies lazy reasoning during the thinking stage as the\nprimary factor contributing to poor instruction adherence. To mitigate this\nissue, we propose a comprehensive framework designed to enable rigorous\nreasoning processes involving preview and self-checking, essential for\nsatisfying strict instruction constraints. Specifically, we first generate\ninstructions with complex constraints and apply a filtering process to obtain\nvalid prompts, resulting in three distinct prompt datasets categorized as hard,\neasy, and pass. Then, we employ rejection sampling on the pass prompts to\ncurate a small yet high-quality dataset, enabling a cold-start initialization\nof the model and facilitating its adaptation to effective reasoning patterns.\nSubsequently, we employ an entropy-preserving supervised fine-tuning\n(Entropy-SFT) strategy coupled with token-wise entropy-adaptive (TEA-RL)\nreinforcement learning guided by rule-based dense rewards. This approach\nencourages the model to transform its reasoning mechanism, ultimately fostering\ngeneralizable reasoning abilities that encompass preview and self-checking.\nExtensive experiments conducted on instruction-following benchmarks demonstrate\nremarkable performance improvements across various model scales. Notably, our\nLight-IF-32B model surpasses both larger open-source models such as DeepSeek-R1\nand closed-source models like Doubao-1.6.",
        "url": "http://arxiv.org/abs/2508.03178v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03178v1",
        "arxiv_id": "2508.03178v1",
        "authors": [
            "Chenyang Wang",
            "Liang Wen",
            "Shousheng Jia",
            "Xiangzheng Zhang",
            "Liang Xu"
        ],
        "submitted": "2025-08-05 07:42:00",
        "source": "arxiv",
        "comment": "12 pages, 10 figures, 7 tables",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on improving the reasoning abilities of Large Language Models (LLMs) for complex instruction following, which is not directly related to Information Retrieval (IR) or Search technologies. While the paper employs reinforcement learning and fine-tuning strategies, the context is distinct from query understanding, ranking models, and user behavior modeling, which are core areas of interest in IR."
    },
    {
        "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework",
        "abstract": "With the proliferation of Large Language Models (LLMs), the detection of\nmisinformation has become increasingly important and complex. This research\nproposes an innovative verifiable misinformation detection LLM agent that goes\nbeyond traditional true/false binary judgments. The agent actively verifies\nclaims through dynamic interaction with diverse web sources, assesses\ninformation source credibility, synthesizes evidence, and provides a complete\nverifiable reasoning process. Our designed agent architecture includes three\ncore tools: precise web search tool, source credibility assessment tool and\nnumerical claim verification tool. These tools enable the agent to execute\nmulti-step verification strategies, maintain evidence logs, and form\ncomprehensive assessment conclusions. We evaluate using standard misinformation\ndatasets such as FakeNewsNet, comparing with traditional machine learning\nmodels and LLMs. Evaluation metrics include standard classification metrics,\nquality assessment of reasoning processes, and robustness testing against\nrewritten content. Experimental results show that our agent outperforms\nbaseline methods in misinformation detection accuracy, reasoning transparency,\nand resistance to information rewriting, providing a new paradigm for\ntrustworthy AI-assisted fact-checking.",
        "url": "http://arxiv.org/abs/2508.03092v1",
        "pdf_url": "http://arxiv.org/pdf/2508.03092v1",
        "arxiv_id": "2508.03092v1",
        "authors": [
            "Zikun Cui",
            "Tianyi Huang",
            "Chia-En Chiang",
            "Cuiqianhe Du"
        ],
        "submitted": "2025-08-05 05:15:03",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'web search' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a novel approach to misinformation detection using Large Language Models, which is related to my interests in Information Retrieval and Natural Language Processing. However, the focus on verifiable misinformation detection and fact-checking is not directly aligned with my primary research themes, such as query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling",
        "abstract": "The proliferation of tool-augmented Large Language Models (LLMs) has created\na fragmented ecosystem where developers must navigate multiple protocols,\nmanual schema definitions, and complex execution workflows. We address this\nchallenge by proposing a unified approach to tool integration that abstracts\nprotocol differences while optimizing execution performance. Our solution\ndemonstrates how protocol-agnostic design principles can significantly reduce\ndevelopment overhead through automated schema generation, dual-mode concurrent\nexecution, and seamless multi-source tool management. Experimental results show\n60-80% code reduction across integration scenarios, performance improvements up\nto 3.1x through optimized concurrency, and full compatibility with existing\nfunction calling standards. This work contributes both theoretical insights\ninto tool integration architecture and practical solutions for real-world LLM\napplication development.",
        "url": "http://arxiv.org/abs/2508.02979v1",
        "pdf_url": "http://arxiv.org/pdf/2508.02979v1",
        "arxiv_id": "2508.02979v1",
        "authors": [
            "Peng Ding",
            "Rick Stevens"
        ],
        "submitted": "2025-08-05 01:06:49",
        "source": "arxiv",
        "comment": "arXiv admin note: substantial text overlap with arXiv:2507.10593",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on tool integration for Large Language Models, which is not directly related to Information Retrieval, Search technologies, or query understanding. Although it mentions 'function calling', the context is not relevant to the user's interests in ranking models or user behavior modeling."
    }
]