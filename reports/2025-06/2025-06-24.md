# Daily Papers Report - 2025-06-24

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Harnessing the Power of Reinforcement Learning for Language-Model-Based Information Retriever via Query-Document Co-Augmentation

- **LLM Score**: 9
- **Keyword Score**: 13
- **Authors**: Jingming Liu, Yumeng Li, Wei Shi, Yao-Xiang Ding, Hui Su, Kun Zhou
- **URL**: <http://arxiv.org/abs/2506.18670v1>
- **Submitted**: 2025-06-23 14:14:43
- **Topic Keywords**: retriever, query, queries, rag, retrieval
- **Reason**: This paper is extremely relevant to your research interests in Information Retrieval, particularly in the area of query understanding and ranking models. The use of reinforcement learning to augment both queries and documents is a novel approach that aligns with your focus on deep semantic understanding and real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Query-Document Co-Augmentation for Language-Model-Based Information Retrieval
- **Aim**: To empower a Large Language Model (LLM) to augment both user queries and corpus documents for more accurate retrieval policies
- **Rationale**: To widen the action space of the LLM and explore more accurate retrieval policies, especially in challenging collections
- **Ground**: Bidirectional RL framework, REINFORCE++, with query-document composite sampling strategy and multi-sampling strategy to address reward variance
- **Experiment**: Experimental results demonstrate significant enhancements in LLM-based retrieval performance in both sparse and dense settings, with strong cross-benchmark generalization
- **Takeaway**: The proposed approach achieves state-of-the-art results and provides insights into the effectiveness of collaborative bidirectional augmentation policy in improving retrieval effectiveness

#### Abstract
> Recent studies have proposed leveraging Large Language Models (LLMs) as
information retrievers through query rewriting. However, for challenging
corpora, we argue that enhancing queries alone is insufficient for robust
semantic matching; the LLM should also have sufficient understanding of the
corpus by directly handling and augmenting the documents themselves. To this
end, we present an LLM-based retriever empowered to augment both user queries
and corpus documents, with its policy fully explored via reinforcement learning
(RL) and minimal human inductive bias. Notably, we find that simply allowing
the LLM to modify documents yields little benefit unless paired with our
carefully designed bidirectional RL framework, which enables the LLM to
simultaneously learn and collaborate on both query and document augmentation
policies. A key technical challenge in realizing such a framework lies in
jointly updating both policies during training, where the rewards for the two
directions depend on each other, making their entangled reward intractable. Our
approach addresses this by introducing a reward sampling strategy and a
specifically designed RL algorithm that enables effective training with these
sampled rewards. Experimental results demonstrate that our approach
significantly enhances LLM-based retrieval performance in both sparse and dense
settings, particularly in difficult retrieval domains, and achieves strong
cross-benchmark generalization. Our code is released at
https://github.com/liujm2001/CoAugRetriever.

---

### 2. Semantic similarity estimation for domain specific data using BERT and other techniques

- **LLM Score**: 8
- **Keyword Score**: 9
- **Authors**: R. Prashanth
- **URL**: <http://arxiv.org/abs/2506.18602v1>
- **Submitted**: 2025-06-23 13:03:59
- **Comment**: This is a preprint version of an article accepted for publication in
  the proceedings of Machine Learning and Data Mining 2019
- **Topic Keywords**: information retrieval, semantic search, retrieval, search
- **Reason**: The paper explores semantic similarity estimation using BERT, which is relevant to information retrieval and natural language processing, two of your core research interests. The application of BERT to domain-specific data and its superior performance compared to other methods align with your focus on query understanding and ranking models. However, the paper's primary focus is on semantic similarity estimation rather than query understanding or ranking models, which is why it doesn't score a 10.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Estimation of semantic similarity between texts
- **Aim**: Evaluate the performance of different state-of-the-art techniques for estimating semantic similarity between texts
- **Rationale**: Semantic similarity estimation is a crucial problem in natural language processing and understanding
- **Ground**: Comparison of Universal Sentence Encoder (USE), InferSent, BERT, and string matching method on two question pairs datasets
- **Experiment**: Evaluation of pre-trained sentence embedding models and language representation model BERT on domain-specific and Quora's question pairs datasets
- **Takeaway**: BERT outperforms other methods, especially for domain-specific data, and fine-tuning procedure allows it to learn patterns based on training data

#### Abstract
> Estimation of semantic similarity is an important research problem both in
natural language processing and the natural language understanding, and that
has tremendous application on various downstream tasks such as question
answering, semantic search, information retrieval, document clustering,
word-sense disambiguation and machine translation. In this work, we carry out
the estimation of semantic similarity using different state-of-the-art
techniques including the USE (Universal Sentence Encoder), InferSent and the
most recent BERT, or Bidirectional Encoder Representations from Transformers,
models. We use two question pairs datasets for the analysis, one is a domain
specific in-house dataset and the other is a public dataset which is the
Quora's question pairs dataset. We observe that the BERT model gave much
superior performance as compared to the other methods. This should be because
of the fine-tuning procedure that is involved in its training process, allowing
it to learn patterns based on the training data that is used. This works
demonstrates the applicability of BERT on domain specific datasets. We infer
from the analysis that BERT is the best technique to use in the case of domain
specific data.

---

### 3. Rethinking Click Models in Light of Carousel Interfaces: Theory-Based Categorization and Design of Click Models

- **LLM Score**: 8
- **Keyword Score**: 5
- **Authors**: Jingwei Kang, Maarten de Rijke, Santiago de Leon-Martinez, Harrie Oosterhuis
- **URL**: <http://arxiv.org/abs/2506.18548v1>
- **Submitted**: 2025-06-23 11:57:11
- **Comment**: Accepted by ICTIR 2025
- **Topic Keywords**: click model, click, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, specifically in query understanding and user behavior modeling. The focus on click models and carousel interfaces aligns with your background in e-commerce and interest in real-time relevance optimization. The paper's emphasis on mathematical properties and design choices also resonates with your interest in ranking models and deep semantic understanding.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Designing and Categorizing Click Models
- **Aim**: To propose a novel approach to designing and categorizing click models, focusing on mathematical relationships between observed variables
- **Rationale**: Existing click models are limited in their ability to generalize to newer interfaces such as carousel interfaces, and a theoretical foundation is needed for the conceptualization, categorization, and design of click models
- **Ground**: The authors identify three key design choices that determine the mathematical properties of a click model: global dependencies, sequentiality, and factorization
- **Experiment**: The authors propose a specific carousel click model design and demonstrate its effectiveness
- **Takeaway**: The authors' approach provides a structured theory-based categorization of click models, enabling the comparison of different models and providing a foundation for the development of new click models

#### Abstract
> Click models are a well-established for modeling user interactions with web
interfaces. Previous work has mainly focused on traditional single-list web
search settings; this includes existing surveys that introduced categorizations
based on the first generation of probabilistic graphical model (PGM) click
models that have become standard. However, these categorizations have become
outdated, as their conceptualizations are unable to meaningfully compare PGM
with neural network (NN) click models nor generalize to newer interfaces, such
as carousel interfaces. We argue that this outdated view fails to adequately
explain the fundamentals of click model designs, thus hindering the development
of novel click models.
  This work reconsiders what should be the fundamental concepts in click model
design, grounding them - unlike previous approaches - in their mathematical
properties. We propose three fundamental key-design choices that explain what
statistical patterns a click model can capture, and thus indirectly, what user
behaviors they can capture. Based on these choices, we create a novel click
model taxonomy that allows a meaningful comparison of all existing click
models; this is the first taxonomy of single-list, grid and carousel click
models that includes PGMs and NNs. Finally, we show how our conceptualization
provides a foundation for future click model design by an example derivation of
a novel design for carousel interfaces.

---

### 4. From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents

- **LLM Score**: 6
- **Keyword Score**: 10
- **Authors**: Weizhi Zhang, Yangning Li, Yuanchen Bei, Junyu Luo, Guancheng Wan, Liangwei Yang, Chenxuan Xie, Yuyao Yang, Wei-Chieh Huang, Chunyu Miao, Henry Peng Zou, Xiao Luo, Yusheng Zhao, Yankai Chen, Chunkit Chan, Peilin Zhou, Xinyang Zhang, Chenwei Zhang, Jingbo Shang, Ming Zhang, Yangqiu Song, Irwin King, Philip S. Yu
- **URL**: <http://arxiv.org/abs/2506.18959v1>
- **Submitted**: 2025-06-23 17:27:19
- **Topic Keywords**: information retrieval, queries, retrieval, web search, search
- **Reason**: The paper explores the concept of Agentic Deep Research, which integrates autonomous reasoning, iterative retrieval, and information synthesis, aligning with the user's interest in Information Retrieval and Search technologies. However, the focus on Large Language Models and reasoning agents is not directly related to the user's specific areas of interest, such as query understanding, ranking models, and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Agentic Deep Research (ADR) and its applications in information search and retrieval
- **Aim**: To develop a novel approach to information search that integrates Large Language Models (LLMs) with reasoning and agentic capabilities
- **Rationale**: To transcend conventional information search techniques and overcome the limitations of traditional keyword-based search engines
- **Ground**: The integration of autonomous reasoning, iterative retrieval, and information synthesis into a dynamic feedback loop, enabling language models to progressively enhance the relevance and depth of retrieved knowledge and refine the reasoning process
- **Experiment**: Benchmarks and results for evaluating the capabilities of standard LLMs, reasoning LLMs, and agentic deep research models on three representative benchmarks: BrowseComp, BrowseComp-ZH, and Humanity's Last Exam (HLE)
- **Takeaway**: Agentic Deep Research has transformative potential, but future developments must incorporate hybrid frameworks that optimize both autonomous agentic capabilities and human-in-the-loop interactions

#### Abstract
> Information retrieval is a cornerstone of modern knowledge acquisition,
enabling billions of queries each day across diverse domains. However,
traditional keyword-based search engines are increasingly inadequate for
handling complex, multi-step information needs. Our position is that Large
Language Models (LLMs), endowed with reasoning and agentic capabilities, are
ushering in a new paradigm termed Agentic Deep Research. These systems
transcend conventional information search techniques by tightly integrating
autonomous reasoning, iterative retrieval, and information synthesis into a
dynamic feedback loop. We trace the evolution from static web search to
interactive, agent-based systems that plan, explore, and learn. We also
introduce a test-time scaling law to formalize the impact of computational
depth on reasoning and search. Supported by benchmark results and the rise of
open-source implementations, we demonstrate that Agentic Deep Research not only
significantly outperforms existing approaches, but is also poised to become the
dominant paradigm for future information seeking. All the related resources,
including industry products, research papers, benchmark datasets, and
open-source implementations, are collected for the community in
https://github.com/DavidZWZ/Awesome-Deep-Research.

---

### 5. jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval

- **LLM Score**: 6
- **Keyword Score**: 7
- **Authors**: Michael G√ºnther, Saba Sturua, Mohammad Kalim Akram, Isabelle Mohr, Andrei Ungureanu, Bo Wang, Sedigheh Eslami, Scott Martens, Maximilian Werk, Nan Wang, Han Xiao
- **URL**: <http://arxiv.org/abs/2506.18902v2>
- **Submitted**: 2025-06-23 17:59:55
- **Comment**: 22 pages, 1-10 main, 14-22 experimental results, benchmark tables
- **Topic Keywords**: query, retrieval, rank, search
- **Reason**: The paper presents a multimodal embedding model for retrieval tasks, which is somewhat related to my interests in Information Retrieval and Search technologies. The focus on query-document retrieval and semantic text similarity is relevant, but the emphasis on visual content and multimodal representations is not directly aligned with my primary interests in query understanding, ranking models, and user behavior modeling.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Multimodal Embedding Model for Information Retrieval
- **Aim**: To develop a novel multimodal embedding model that unifies text and image representations for efficient information retrieval
- **Rationale**: The existing dual-encoder architectures have a modality gap, and the proposed model aims to eliminate this gap by using a unified multimodal language model
- **Ground**: The model is built on the Qwen2.5-VL-3B-Instruct backbone and incorporates task-specific Low-Rank Adaptation (LoRA) adapters for optimizing performance across diverse retrieval scenarios
- **Experiment**: The model is trained using a joint loss function and evaluated on various benchmarks, including multilingual text retrieval tasks, multimodal retrieval tasks, and code retrieval tasks
- **Takeaway**: The proposed model, jina-embeddings-v4, outperforms previous models on various tasks and reduces the modality gap, improves cross-modal alignment, and mitigates the cone effect, resulting in a more effective cross-modal retrieval

#### Abstract
> We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding
model that unifies text and image representations through a novel architecture
supporting both single-vector and multi-vector embeddings in the late
interaction style. The model incorporates task-specific Low-Rank Adaptation
(LoRA) adapters to optimize performance across diverse retrieval scenarios,
including query-document retrieval, semantic text similarity, and code search.
Comprehensive evaluations demonstrate that jina-embeddings-v4 achieves
state-of-the-art performance on both single-modal and cross-modal retrieval
tasks, with particular strength in processing visually rich content such as
tables, charts, diagrams, and mixed-media formats. To facilitate evaluation of
this capability, we also introduce Jina-VDR, a novel benchmark specifically
designed for visually rich image retrieval.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. RLPR: Extrapolating RLVR to General Domains without Verifiers

- **LLM Score**: 6
- **Keyword Score**: 2
- **Authors**: Tianyu Yu, Bo Ji, Shouli Wang, Shu Yao, Zefan Wang, Ganqu Cui, Lifan Yuan, Ning Ding, Yuan Yao, Zhiyuan Liu, Maosong Sun, Tat-Seng Chua
- **URL**: <http://arxiv.org/abs/2506.18254v1>
- **Submitted**: 2025-06-23 02:56:36
- **Comment**: Project Website: https://github.com/openbmb/RLPR
- **Topic Keywords**: rag
- **Reason**: The paper proposes a reinforcement learning framework, RLPR, that extrapolates RLVR to general domains without verifiers. While it's related to query understanding and ranking models, the focus is on reasoning capabilities and LLMs, which is not directly aligned with the user's primary research interests in information retrieval and search technologies. However, the paper's use of token probability scores for reference answers as the reward signal shows some relevance to the user's background in e-commerce and NLP.

#### Abstract
> Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates promising
potential in advancing the reasoning capabilities of LLMs. However, its success
remains largely confined to mathematical and code domains. This primary
limitation stems from the heavy reliance on domain-specific verifiers, which
results in prohibitive complexity and limited scalability. To address the
challenge, our key observation is that LLM's intrinsic probability of
generating a correct free-form answer directly indicates its own evaluation of
the reasoning reward (i.e., how well the reasoning process leads to the correct
answer). Building on this insight, we propose RLPR, a simple verifier-free
framework that extrapolates RLVR to broader general domains. RLPR uses the
LLM's own token probability scores for reference answers as the reward signal
and maximizes the expected reward during training. We find that addressing the
high variance of this noisy probability reward is crucial to make it work, and
propose prob-to-reward and stabilizing methods to ensure a precise and stable
reward from LLM intrinsic probabilities. Comprehensive experiments in four
general-domain benchmarks and three mathematical benchmarks show that RLPR
consistently improves reasoning capabilities in both areas for Gemma, Llama,
and Qwen based models. Notably, RLPR outperforms concurrent VeriFree by 7.6
points on TheoremQA and 7.5 points on Minerva, and even surpasses strong
verifier-model-dependent approaches General-Reasoner by 1.6 average points
across seven benchmarks.

### 7. Comparative Analysis of Lion and AdamW Optimizers for Cross-Encoder Reranking with MiniLM, GTE, and ModernBERT

- **LLM Score**: 4
- **Keyword Score**: 17
- **Authors**: Shahil Kumar, Manu Pande, Anay Yatin Damle
- **URL**: <http://arxiv.org/abs/2506.18297v1>
- **Submitted**: 2025-06-23 05:30:09
- **Topic Keywords**: information retrieval, query, ranking, rerank, retrieval, rank, trec
- **Reason**: The paper is somewhat related to information retrieval, specifically in the context of reranking and fine-tuning transformer models for passage ranking. However, the focus on optimizers and their impact on training dynamics is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Modern information retrieval systems often employ a two-stage pipeline: an
efficient initial retrieval stage followed by a computationally intensive
reranking stage. Cross-encoders have shown strong effectiveness for reranking
due to their deep analysis of query-document pairs. This paper studies the
impact of the Lion optimizer, a recent alternative to AdamW, during fine-tuning
of cross-encoder rerankers. We fine-tune three transformer models-MiniLM, GTE,
and ModernBERT-on the MS MARCO passage ranking dataset using both optimizers.
GTE and ModernBERT support extended context lengths (up to 8192 tokens). We
evaluate effectiveness using TREC 2019 Deep Learning Track and MS MARCO dev set
(MRR@10). Experiments, run on the Modal cloud platform, reveal that ModernBERT
with Lion achieves the best NDCG@10 (0.7225) and MAP (0.5121) on TREC DL 2019,
while MiniLM with Lion ties ModernBERT for MRR@10 (0.5988) on MS MARCO dev.
Lion also provides superior GPU efficiency, improving utilization by 2.67% to
10.33% across models. We analyze performance trends using standard IR metrics
and discuss the optimizer's impact on training dynamics across architectures.

### 8. Bias vs Bias -- Dawn of Justice: A Fair Fight in Recommendation Systems

- **LLM Score**: 4
- **Keyword Score**: 9
- **Authors**: Tahsin Alamgir Kheya, Mohamed Reda Bouadjenek, Sunil Aryal
- **URL**: <http://arxiv.org/abs/2506.18327v1>
- **Submitted**: 2025-06-23 06:19:02
- **Topic Keywords**: ranking, rag, recommend, commerce, e-commerce, rank
- **Reason**: The paper focuses on fairness in recommendation systems, which is a related topic to information retrieval. However, the emphasis on recommender systems and the lack of direct connection to query understanding, ranking models, or user behavior modeling make it only loosely relevant to my research interests.

#### Abstract
> Recommendation systems play a crucial role in our daily lives by impacting
user experience across various domains, including e-commerce, job
advertisements, entertainment, etc. Given the vital role of such systems in our
lives, practitioners must ensure they do not produce unfair and imbalanced
recommendations. Previous work addressing bias in recommendations overlooked
bias in certain item categories, potentially leaving some biases unaddressed.
Additionally, most previous work on fair re-ranking focused on binary-sensitive
attributes. In this paper, we address these issues by proposing a
fairness-aware re-ranking approach that helps mitigate bias in different
categories of items. This re-ranking approach leverages existing biases to
correct disparities in recommendations across various demographic groups. We
show how our approach can mitigate bias on multiple sensitive attributes,
including gender, age, and occupation. We experimented on three real-world
datasets to evaluate the effectiveness of our re-ranking scheme in mitigating
bias in recommendations. Our results show how this approach helps mitigate
social bias with little to no degradation in performance.

### 9. LettinGo: Explore User Profile Generation for Recommendation System

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Lu Wang, Di Zhang, Fangkai Yang, Pu Zhao, Jianfeng Liu, Yuefeng Zhan, Hao Sun, Qingwei Lin, Weiwei Deng, Dongmei Zhang, Feng Sun, Qi Zhang
- **URL**: <http://arxiv.org/abs/2506.18309v1>
- **Submitted**: 2025-06-23 05:51:52
- **Comment**: 11 pages, 3 figures
- **Topic Keywords**: pairwise, rag, user behavior, recommend
- **Reason**: The paper focuses on user profiling for recommendation systems, which is somewhat related to my interests in information retrieval and search technologies. However, the paper's emphasis on large language models and recommendation systems is not directly aligned with my primary focus on query understanding, ranking models, and user behavior modeling in the context of information retrieval.

#### Abstract
> User profiling is pivotal for recommendation systems, as it transforms raw
user interaction data into concise and structured representations that drive
personalized recommendations. While traditional embedding-based profiles lack
interpretability and adaptability, recent advances with large language models
(LLMs) enable text-based profiles that are semantically richer and more
transparent. However, existing methods often adhere to fixed formats that limit
their ability to capture the full diversity of user behaviors. In this paper,
we introduce LettinGo, a novel framework for generating diverse and adaptive
user profiles. By leveraging the expressive power of LLMs and incorporating
direct feedback from downstream recommendation tasks, our approach avoids the
rigid constraints imposed by supervised fine-tuning (SFT). Instead, we employ
Direct Preference Optimization (DPO) to align the profile generator with
task-specific performance, ensuring that the profiles remain adaptive and
effective. LettinGo operates in three stages: (1) exploring diverse user
profiles via multiple LLMs, (2) evaluating profile quality based on their
impact in recommendation systems, and (3) aligning the profile generation
through pairwise preference data derived from task performance. Experimental
results demonstrate that our framework significantly enhances recommendation
accuracy, flexibility, and contextual awareness. This work enhances profile
generation as a key innovation for next-generation recommendation systems.

### 10. Shrinking the Generation-Verification Gap with Weak Verifiers

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Jon Saad-Falcon, E. Kelly Buchanan, Mayee F. Chen, Tzu-Heng Huang, Brendan McLaughlin, Tanvir Bhathal, Shang Zhu, Ben Athiwaratkun, Frederic Sala, Scott Linderman, Azalia Mirhoseini, Christopher R√©
- **URL**: <http://arxiv.org/abs/2506.18203v1>
- **Submitted**: 2025-06-22 23:38:15
- **Topic Keywords**: ranking, rag, rank, acl
- **Reason**: The paper is somewhat related to my research interests in Information Retrieval and Search technologies, as it discusses the design of a framework for combining multiple weak verifiers to improve language model capabilities. However, the focus on language models and verifier design is not directly aligned with my primary interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Verifiers can improve language model capabilities by scoring and ranking
responses from generated candidates. Currently, high-quality verifiers are
either unscalable (e.g., humans) or limited in utility (e.g., tools like Lean).
While LM judges and reward models have become broadly useful as general-purpose
verifiers, a significant performance gap remains between them and oracle
verifiers (verifiers with perfect accuracy). To help close this gap, we
introduce Weaver, a framework for designing a strong verifier by combining
multiple weak, imperfect verifiers. We find weighted ensembles of verifiers,
which typically require learning from labeled data, significantly outperform
unweighted combinations due to differences in verifier accuracies. To reduce
dependency on labeled data, Weaver leverages weak supervision to estimate each
verifier's accuracy and combines outputs into a unified score that better
reflects true response quality. However, directly applying weak supervision
algorithms poses challenges, including inconsistent verifier output formats and
handling low-quality verifiers. Weaver addresses these using dataset statistics
to normalize outputs and filter specific verifiers. We study Weaver's
effectiveness in test-time repeated sampling, where a model generates multiple
candidate responses and selects one. Our evaluations show Weaver significantly
improves over Pass@1-performance when selecting the first candidate-across
reasoning and math tasks, achieving o3-mini-level accuracy with Llama 3.3 70B
Instruct as generator, and an ensemble of 70B or smaller judge and reward
models as verifiers (87.7% average). This gain mirrors the jump between GPT-4o
and o3-mini (69.0% vs. 86.7%), which required extensive finetuning and
post-training. To reduce computational costs of verifier ensembles, we train a
400M cross-encoder using Weaver's combined output scores.

### 11. Enhancing Document Retrieval in COVID-19 Research: Leveraging Large Language Models for Hidden Relation Extraction

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Hoang-An Trieu, Dinh-Truong Do, Chau Nguyen, Vu Tran, Minh Le Nguyen
- **URL**: <http://arxiv.org/abs/2506.18311v1>
- **Submitted**: 2025-06-23 05:55:53
- **Comment**: In the Proceedings of SCIDOCA 2024
- **Topic Keywords**: rag, retrieval, search
- **Reason**: The paper is somewhat related to information retrieval, as it discusses a retrieval system for COVID-19 research publications. However, the focus is on leveraging large language models for hidden relation extraction, which is more relevant to NLP and data mining. The paper does not specifically address query understanding, ranking models, or user behavior modeling, which are core interests in the user's research.

#### Abstract
> In recent years, with the appearance of the COVID-19 pandemic, numerous
publications relevant to this disease have been issued. Because of the massive
volume of publications, an efficient retrieval system is necessary to provide
researchers with useful information if an unexpected pandemic happens so
suddenly, like COVID-19. In this work, we present a method to help the
retrieval system, the Covrelex-SE system, to provide more high-quality search
results. We exploited the power of the large language models (LLMs) to extract
the hidden relationships inside the unlabeled publication that cannot be found
by the current parsing tools that the system is using. Since then, help the
system to have more useful information during retrieval progress.

### 12. AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Piotr Matys, Jan Eliasz, Konrad Kie≈Çczy≈Ñski, Miko≈Çaj Langner, Teddy Ferdinan, Jan Koco≈Ñ, Przemys≈Çaw Kazienko
- **URL**: <http://arxiv.org/abs/2506.18628v1>
- **Submitted**: 2025-06-23 13:35:05
- **Comment**: ICCS 2025 Workshops
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on contextual hallucination detection in Large Language Models, which is a specific problem in NLP. While it's related to information retrieval and search technologies, the primary focus is on language models and generation, rather than query understanding, ranking models, or user behavior modeling. The paper's relevance to the user's interests is somewhat limited.

#### Abstract
> In real-world applications, Large Language Models (LLMs) often hallucinate,
even in Retrieval-Augmented Generation (RAG) settings, which poses a
significant challenge to their deployment. In this paper, we introduce
AggTruth, a method for online detection of contextual hallucinations by
analyzing the distribution of internal attention scores in the provided context
(passage). Specifically, we propose four different variants of the method, each
varying in the aggregation technique used to calculate attention scores. Across
all LLMs examined, AggTruth demonstrated stable performance in both same-task
and cross-task setups, outperforming the current SOTA in multiple scenarios.
Furthermore, we conducted an in-depth analysis of feature selection techniques
and examined how the number of selected attention heads impacts detection
performance, demonstrating that careful selection of heads is essential to
achieve optimal results.

### 13. When Fine-Tuning Fails: Lessons from MS MARCO Passage Ranking

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Manu Pande, Shahil Kumar, Anay Yatin Damle
- **URL**: <http://arxiv.org/abs/2506.18535v1>
- **Submitted**: 2025-06-23 11:46:05
- **Topic Keywords**: ranking, rank
- **Reason**: The paper explores the phenomenon of fine-tuning pre-trained transformer models degrading performance on the MS MARCO passage ranking task, which is related to query understanding and ranking models. However, the focus is on the technical aspects of fine-tuning and the impact on the embedding space, rather than the user behavior modeling or real-time relevance optimization aspects that are central to your research interests.

#### Abstract
> This paper investigates the counterintuitive phenomenon where fine-tuning
pre-trained transformer models degrades performance on the MS MARCO passage
ranking task. Through comprehensive experiments involving five model
variants-including full parameter fine-tuning and parameter efficient LoRA
adaptations-we demonstrate that all fine-tuning approaches underperform the
base sentence-transformers/all- MiniLM-L6-v2 model (MRR@10: 0.3026). Our
analysis reveals that fine-tuning disrupts the optimal embedding space
structure learned during the base model's extensive pre-training on 1 billion
sentence pairs, including 9.1 million MS MARCO samples. UMAP visualizations
show progressive embedding space flattening, while training dynamics analysis
and computational efficiency metrics further support our findings. These
results challenge conventional wisdom about transfer learning effectiveness on
saturated benchmarks and suggest architectural innovations may be necessary for
meaningful improvements.

### 14. Team LA at SCIDOCA shared task 2025: Citation Discovery via relation-based zero-shot retrieval

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Trieu An, Long Nguyen, Minh Le Nguyen
- **URL**: <http://arxiv.org/abs/2506.18316v1>
- **Submitted**: 2025-06-23 06:01:21
- **Comment**: In the Proceedings of SCIDOCA 2025
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on citation discovery, which is a specific application of information retrieval. While it involves relation-based zero-shot retrieval, the primary focus is on citation prediction rather than query understanding, ranking models, or user behavior modeling. The paper's relevance to the user's interests is somewhat limited, but it does touch on some IR concepts.

#### Abstract
> The Citation Discovery Shared Task focuses on predicting the correct citation
from a given candidate pool for a given paragraph. The main challenges stem
from the length of the abstract paragraphs and the high similarity among
candidate abstracts, making it difficult to determine the exact paper to cite.
To address this, we develop a system that first retrieves the top-k most
similar abstracts based on extracted relational features from the given
paragraph. From this subset, we leverage a Large Language Model (LLM) to
accurately identify the most relevant citation. We evaluate our framework on
the training dataset provided by the SCIDOCA 2025 organizers, demonstrating its
effectiveness in citation prediction.

### 15. PERSCEN: Learning Personalized Interaction Pattern and Scenario Preference for Multi-Scenario Matching

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Haotong Du, Yaqing Wang, Fei Xiong, Lei Shao, Ming Liu, Hao Gu, Quanming Yao, Zhen Wang
- **URL**: <http://arxiv.org/abs/2506.18382v1>
- **Submitted**: 2025-06-23 08:15:16
- **Comment**: Accepted by KDD 2025
- **Topic Keywords**: rag, recommend
- **Reason**: The paper focuses on multi-scenario matching and recommendation, which is not directly related to information retrieval, query understanding, or ranking models. While it involves user behavior modeling, the approach is more geared towards recommender systems and does not seem to require deep semantic understanding or real-time relevance optimization, which are key aspects of my research interests.

#### Abstract
> With the expansion of business scales and scopes on online platforms,
multi-scenario matching has become a mainstream solution to reduce maintenance
costs and alleviate data sparsity. The key to effective multi-scenario
recommendation lies in capturing both user preferences shared across all
scenarios and scenario-aware preferences specific to each scenario. However,
existing methods often overlook user-specific modeling, limiting the generation
of personalized user representations. To address this, we propose PERSCEN, an
innovative approach that incorporates user-specific modeling into
multi-scenario matching. PERSCEN constructs a user-specific feature graph based
on user characteristics and employs a lightweight graph neural network to
capture higher-order interaction patterns, enabling personalized extraction of
preferences shared across scenarios. Additionally, we leverage vector
quantization techniques to distil scenario-aware preferences from users'
behavior sequence within individual scenarios, facilitating user-specific and
scenario-aware preference modeling. To enhance efficient and flexible
information transfer, we introduce a progressive scenario-aware gated linear
unit that allows fine-grained, low-latency fusion. Extensive experiments
demonstrate that PERSCEN outperforms existing methods. Further efficiency
analysis confirms that PERSCEN effectively balances performance with
computational cost, ensuring its practicality for real-world industrial
systems.

### 16. MeRF: Motivation-enhanced Reinforcement Finetuning for Large Reasoning Models

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Junjie Zhang, Guozheng Ma, Shunyu Liu, Haoyu Wang, Jiaxing Huang, Ting-En Lin, Fei Huang, Yongbin Li, Dacheng Tao
- **URL**: <http://arxiv.org/abs/2506.18485v1>
- **Submitted**: 2025-06-23 10:37:57
- **Topic Keywords**: rag
- **Reason**: The paper explores reinforcement learning for large language models, which is a related topic to information retrieval and search technologies. However, the focus on reasoning and logic puzzle solving is not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful learn-to-reason paradigm for Large Language Models (LLMs) to tackle
complex reasoning tasks. However, existing RLVR methods overlook one of the
most distinctive capabilities of LLMs, their in-context learning ability, as
prominently demonstrated by the success of Chain-of-Thought (CoT) prompting.
This motivates us to explore how reinforcement learning can be effectively
combined with in-context learning to better improve the reasoning capabilities
of LLMs. In this paper, we introduce Motivation-enhanced Reinforcement
Finetuning} (MeRF), an intuitive yet effective method enhancing reinforcement
learning of LLMs by involving ``telling LLMs the rules of the game''.
Specifically, MeRF directly injects the reward specification into the prompt,
which serves as an in-context motivation for model to improve its responses
with awareness of the optimization objective. This simple modification
leverages the in-context learning ability of LLMs aligning generation with
optimization, thereby incentivizing the model to generate desired outputs from
both inner motivation and external reward. Empirical evaluations on the Knights
and Knaves~(K&K) logic puzzle reasoning benchmark demonstrate that
\texttt{MeRF} achieves substantial performance gains over baselines. Moreover,
ablation studies show that performance improves with greater consistency
between the in-context motivation and the external reward function, while the
model also demonstrates an ability to adapt to misleading motivations through
reinforcement learning.

### 17. AdapThink: Adaptive Thinking Preferences for Reasoning Language Model

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Xu Wan, Wei Wang, Wenyue Xu, Wotao Yin, Jie Song, Mingyang Sun
- **URL**: <http://arxiv.org/abs/2506.18237v1>
- **Submitted**: 2025-06-23 02:06:04
- **Topic Keywords**: rag
- **Reason**: The paper proposes a reinforcement learning-based framework for adaptive post-training of language models, focusing on efficient reasoning and self-reflection. While it touches on the idea of 'thinking' and 'reflection', the paper's primary concern is not query understanding, ranking models, or user behavior modeling, which are core aspects of Information Retrieval and Search technologies. The paper's relevance to the user's research interests is limited, but it does explore some aspects of language models and reasoning, which may be of interest to the user.

#### Abstract
> Reinforcement Learning (RL)-based post-training has significantly advanced
the complex reasoning capabilities of language models, fostering sophisticated
self-reflection processes. However, this ``slow thinking'' paradigm presents a
critical challenge to reasoning efficiency: models may expend excessive
computation on simple questions and shift reasoning prematurely for complex
ones. Previous mechanisms typically rely on static length budgets or predefined
rules, lacking the adaptability for varying question complexities and models'
evolving capabilities. To this end, we propose AdapThink, an adaptive
post-training framework designed to induce more efficient thinking while
maintaining the performance of reasoning language models. Specifically,
AdapThink incorporates two key mechanisms: 1) A group-relative reward function
that leverages model confidence and response's characteristic to dynamically
adjust the preference of reflection-related transition words without resorting
to a fixed length preference. 2) A diversity-aware sampling mechanism that
balances the training group's solution accuracy with reasoning diversity via an
entropy-guided score. Experiments on several mathematical reasoning datasets
with DeepSeek-distilled models demonstrate AdapThink's advantages in enabling
adaptive reasoning patterns and mitigating the inefficiencies.

### 18. Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Zhiting Mei, Christina Zhang, Tenny Yin, Justin Lidard, Ola Shorinwa, Anirudha Majumdar
- **URL**: <http://arxiv.org/abs/2506.18183v1>
- **Submitted**: 2025-06-22 21:46:42
- **Topic Keywords**: search
- **Reason**: The paper explores uncertainty quantification in reasoning language models, which is a topic in NLP. While it touches on the idea of confidence estimation, it does not directly relate to query understanding, ranking models, or user behavior modeling in the context of information retrieval. The paper's focus on language models and their calibration is not directly aligned with the user's primary research interests in IR and search technologies.

#### Abstract
> Reasoning language models have set state-of-the-art (SOTA) records on many
challenging benchmarks, enabled by multi-step reasoning induced using
reinforcement learning. However, like previous language models, reasoning
models are prone to generating confident, plausible responses that are
incorrect (hallucinations). Knowing when and how much to trust these models is
critical to the safe deployment of reasoning models in real-world applications.
To this end, we explore uncertainty quantification of reasoning models in this
work. Specifically, we ask three fundamental questions: First, are reasoning
models well-calibrated? Second, does deeper reasoning improve model
calibration? Finally, inspired by humans' innate ability to double-check their
thought processes to verify the validity of their answers and their confidence,
we ask: can reasoning models improve their calibration by explicitly reasoning
about their chain-of-thought traces? We introduce introspective uncertainty
quantification (UQ) to explore this direction. In extensive evaluations on SOTA
reasoning models across a broad range of benchmarks, we find that reasoning
models: (i) are typically overconfident, with self-verbalized confidence
estimates often greater than 85% particularly for incorrect responses, (ii)
become even more overconfident with deeper reasoning, and (iii) can become
better calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not
uniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we
conclude with important research directions to design necessary UQ benchmarks
and improve the calibration of reasoning models.

### 19. An Audio-centric Multi-task Learning Framework for Streaming Ads Targeting on Spotify

- **LLM Score**: 2
- **Keyword Score**: 7
- **Authors**: Shivam Verma, Vivian Chen, Darren Mei
- **URL**: <http://arxiv.org/abs/2506.18735v1>
- **Submitted**: 2025-06-23 15:11:43
- **Comment**: Accepted at KDD 2025
- **Topic Keywords**: click, ctr, click-through rate, recommend
- **Reason**: This paper focuses on audio-centric ad targeting on Spotify, which is not directly related to information retrieval, search technologies, or query understanding. While it involves multi-task learning and deep-cross networks, the context is not relevant to the user's primary research interests in IR and NLP.

#### Abstract
> Spotify, a large-scale multimedia platform, attracts over 675 million monthly
active users who collectively consume millions of hours of music, podcasts,
audiobooks, and video content. This diverse content consumption pattern
introduces unique challenges for computational advertising, which must
effectively integrate a variety of ad modalities, including audio, video, and
display, within a single user experience. Traditional ad recommendation models,
primarily designed for foregrounded experiences, often struggle to reconcile
the platform's inherent audio-centrality with the demands of optimizing ad
performance across multiple formats and modalities. To overcome these
challenges, we introduce Cross-modal Adaptive Mixture-of-Experts (CAMoE), a
novel framework for optimizing click-through rate (CTR) prediction in both
audio-centric and multi-modal settings. CAMoE enhances traditional
mixture-of-experts models by incorporating modality-aware task grouping,
adaptive loss masking, and deep-cross networks (DCN) to capture complex feature
interactions within a multi-modal ad ecosystem. Through extensive ablation
studies, we demonstrate that this approach achieves near Pareto-optimal
performance across audio, video, and display ad formats, significantly
improving AUC-PR compared to conventional single-task and content-based
multi-task learning baselines. When deployed at scale on Spotify's ad serving
platform, CAMoE delivered substantial gains, yielding a 14.5% increase in CTR
for audio ads, a 1.3% increase for video ads, and a 4.8% reduction in expected
cost-per-click (eCPC) for audio slots.

### 20. LongWriter-Zero: Mastering Ultra-Long Text Generation via Reinforcement Learning

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Yuhao Wu, Yushi Bai, Zhiqiang Hu, Roy Ka-Wei Lee, Juanzi Li
- **URL**: <http://arxiv.org/abs/2506.18841v1>
- **Submitted**: 2025-06-23 16:59:02
- **Topic Keywords**: ltr, rag
- **Reason**: This paper focuses on ultra-long text generation using reinforcement learning, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing, the topic is more specific to text generation and lacks relevance to the user's primary research interests.

#### Abstract
> Ultra-long generation by large language models (LLMs) is a widely demanded
scenario, yet it remains a significant challenge due to their maximum
generation length limit and overall quality degradation as sequence length
increases. Previous approaches, exemplified by LongWriter, typically rely on
''teaching'', which involves supervised fine-tuning (SFT) on synthetic
long-form outputs. However, this strategy heavily depends on synthetic SFT
data, which is difficult and costly to construct, often lacks coherence and
consistency, and tends to be overly artificial and structurally monotonous. In
this work, we propose an incentivization-based approach that, starting entirely
from scratch and without relying on any annotated or synthetic data, leverages
reinforcement learning (RL) to foster the emergence of ultra-long, high-quality
text generation capabilities in LLMs. We perform RL training starting from a
base model, similar to R1-Zero, guiding it to engage in reasoning that
facilitates planning and refinement during the writing process. To support
this, we employ specialized reward models that steer the LLM towards improved
length control, writing quality, and structural formatting. Experimental
evaluations show that our LongWriter-Zero model, trained from Qwen2.5-32B,
consistently outperforms traditional SFT methods on long-form writing tasks,
achieving state-of-the-art results across all metrics on WritingBench and
Arena-Write, and even surpassing 100B+ models such as DeepSeek R1 and
Qwen3-235B. We open-source our data and model checkpoints under
https://huggingface.co/THU-KEG/LongWriter-Zero-32B

### 21. ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Siao Tang, Xinyin Ma, Gongfan Fang, Xinchao Wang
- **URL**: <http://arxiv.org/abs/2506.18810v2>
- **Submitted**: 2025-06-23 16:20:44
- **Comment**: Codes are available at https://github.com/tsa18/ConciseHint
- **Topic Keywords**: query, rag
- **Reason**: The paper focuses on improving the efficiency of reasoning models, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions the use of large reasoning models, the paper's primary concern is not on ranking models or user behavior modeling, making it only loosely relevant to the user's research interests.

#### Abstract
> Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and
OpenAI o1 series have achieved notable performance enhancements on complex
reasoning tasks by scaling up the generation length by Chain-of-Thought (CoT).
However, an emerging issue is their inclination to produce excessively verbose
reasoning processes, leading to the inefficiency problem. Existing literature
on improving efficiency mainly adheres to the before-reasoning paradigms such
as prompting and reasoning or fine-tuning and reasoning, but ignores the
promising direction of directly encouraging the model to speak concisely by
intervening during the generation of reasoning. In order to fill the blank, we
propose a framework dubbed ConciseHint, which continuously encourages the
reasoning model to speak concisely by injecting the textual hint (manually
designed or trained on the concise data) during the token generation of the
reasoning process. Besides, ConciseHint is adaptive to the complexity of the
query by adaptively adjusting the hint intensity, which ensures it will not
undermine model performance. Experiments on the state-of-the-art LRMs,
including DeepSeek-R1 and Qwen-3 series, demonstrate that our method can
effectively produce concise reasoning processes while maintaining performance
well. For instance, we achieve a reduction ratio of 65\% for the reasoning
length on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.

### 22. LLMs on a Budget? Say HOLA

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Zohaib Hasan Siddiqui, Jiechao Gao, Ebad Shabbir, Mohammad Anas Azeez, Rafiq Ali, Gautam Siddharth Kashyap, Usman Naseem
- **URL**: <http://arxiv.org/abs/2506.18952v1>
- **Submitted**: 2025-06-23 10:20:47
- **Topic Keywords**: rag, retrieval
- **Reason**: The paper focuses on optimizing Large Language Models for deployment on edge devices, using techniques like quantization, pruning, and retrieval-augmented generation. While it's related to NLP, it doesn't directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest in Information Retrieval and Search technologies.

#### Abstract
> Running Large Language Models (LLMs) on edge devices is constrained by high
compute and memory demands posing a barrier for real-time applications in
sectors like healthcare, education, and embedded systems. Current solutions
such as quantization, pruning, and retrieval-augmented generation (RAG) offer
only partial optimizations and often compromise on speed or accuracy. We
introduce HOLA, an end-to-end optimization framework for efficient LLM
deployment. Internally, it leverages Hierarchical Speculative Decoding (HSD)
for faster inference without quality loss. Externally, AdaComp-RAG adjusts
retrieval complexity based on context needs. Together with LoBi, which blends
structured pruning (LoRA) and quantization, HOLA delivers significant gains:
17.6% EMA on GSM8K, 10.5% MCA on ARC, and reduced latency and memory on edge
devices like Jetson Nano--proving both scalable and production-ready.

### 23. MLLP-VRAIN UPV system for the IWSLT 2025 Simultaneous Speech Translation Translation task

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jorge Iranzo-S√°nchez, Javier Iranzo-S√°nchez, Adri√† Gim√©nez, Jorge Civera, Alfons Juan
- **URL**: <http://arxiv.org/abs/2506.18828v1>
- **Submitted**: 2025-06-23 16:44:01
- **Comment**: IWSLT 2025 System Description
- **Topic Keywords**: search, acl
- **Reason**: The paper focuses on simultaneous speech translation, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language processing and machine translation, the context and methodology are not aligned with the user's primary research interests.

#### Abstract
> This work describes the participation of the MLLP-VRAIN research group in the
shared task of the IWSLT 2025 Simultaneous Speech Translation track. Our
submission addresses the unique challenges of real-time translation of
long-form speech by developing a modular cascade system that adapts strong
pre-trained models to streaming scenarios. We combine Whisper Large-V3-Turbo
for ASR with the multilingual NLLB-3.3B model for MT, implementing lightweight
adaptation techniques rather than training new end-to-end models from scratch.
Our approach employs document-level adaptation with prefix training to enhance
the MT model's ability to handle incomplete inputs, while incorporating
adaptive emission policies including a wait-$k$ strategy and RALCP for managing
the translation stream. Specialized buffer management techniques and
segmentation strategies ensure coherent translations across long audio
sequences. Experimental results on the ACL60/60 dataset demonstrate that our
system achieves a favorable balance between translation quality and latency,
with a BLEU score of 31.96 and non-computational-aware StreamLAAL latency of
2.94 seconds. Our final model achieves a preliminary score on the official test
set (IWSLT25Instruct) of 29.8 BLEU. Our work demonstrates that carefully
adapted pre-trained components can create effective simultaneous translation
systems for long-form content without requiring extensive in-domain parallel
data or specialized end-to-end training.

### 24. Airalogy: AI-empowered universal data digitization for research automation

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Zijie Yang, Qiji Zhou, Fang Guo, Sijie Zhang, Yexun Xi, Jinglei Nie, Yudian Zhu, Liping Huang, Chou Wu, Yonghe Xia, Xiaoyu Ma, Yingming Pu, Panzhong Lu, Junshu Pan, Mingtao Chen, Tiannan Guo, Yanmei Dou, Hongyu Chen, Anping Zeng, Jiaxing Huang, Tian Xu, Yue Zhang
- **URL**: <http://arxiv.org/abs/2506.18586v1>
- **Submitted**: 2025-06-23 12:43:16
- **Comment**: 146 pages, 6 figures, 49 supplementary figures
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on developing a platform for standardized data digitization across multiple disciplines, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it mentions AI and research automation, the context is more focused on data collection and management rather than search or retrieval.

#### Abstract
> Research data are the foundation of Artificial Intelligence (AI)-driven
science, yet current AI applications remain limited to a few fields with
readily available, well-structured, digitized datasets. Achieving comprehensive
AI empowerment across multiple disciplines is still out of reach. Present-day
research data collection is often fragmented, lacking unified standards,
inefficiently managed, and difficult to share. Creating a single platform for
standardized data digitization needs to overcome the inherent challenge of
balancing between universality (supporting the diverse, ever-evolving needs of
various disciplines) and standardization (enforcing consistent formats to fully
enable AI). No existing platform accommodates both facets. Building a truly
multidisciplinary platform requires integrating scientific domain knowledge
with sophisticated computing skills. Researchers often lack the computational
expertise to design customized and standardized data recording methods, whereas
platform developers rarely grasp the intricate needs of multiple scientific
domains. These gaps impede research data standardization and hamper AI-driven
progress. In this study, we address these challenges by developing Airalogy
(https://airalogy.com), the world's first AI- and community-driven platform
that balances universality and standardization for digitizing research data
across multiple disciplines. Airalogy represents entire research workflows
using customizable, standardized data records and offers an advanced AI
research copilot for intelligent Q&A, automated data entry, analysis, and
research automation. Already deployed in laboratories across all four schools
of Westlake University, Airalogy has the potential to accelerate and automate
scientific innovation in universities, industry, and the global research
community-ultimately benefiting humanity as a whole.

### 25. Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Batool Haider, Atmika Gorti, Aman Chadha, Manas Gaur
- **URL**: <http://arxiv.org/abs/2506.18116v1>
- **Submitted**: 2025-06-22 18:00:16
- **Comment**: 19 Pages, 7 Figures, 4 Tables (Note: Under Review)
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on the biases in Large Language Models (LLMs) in mental healthcare, which is outside the scope of Information Retrieval and Search technologies. Although it mentions question answering, the context is not related to query understanding, ranking models, or user behavior modeling, which are key areas of interest in the user's research.

#### Abstract
> Large Language Models (LLMs) in mental healthcare risk propagating biases
that reinforce stigma and harm marginalized groups. While previous research
identified concerning trends, systematic methods for detecting intersectional
biases remain limited. This work introduces a multi-hop question answering
(MHQA) framework to explore LLM response biases in mental health discourse. We
analyze content from the Interpretable Mental Health Instruction (IMHI) dataset
across symptom presentation, coping mechanisms, and treatment approaches. Using
systematic tagging across age, race, gender, and socioeconomic status, we
investigate bias patterns at demographic intersections. We evaluate four LLMs:
Claude 3.5 Sonnet, Jamba 1.6, Gemma 3, and Llama 4, revealing systematic
disparities across sentiment, demographics, and mental health conditions. Our
MHQA approach demonstrates superior detection compared to conventional methods,
identifying amplification points where biases magnify through sequential
reasoning. We implement two debiasing techniques: Roleplay Simulation and
Explicit Bias Reduction, achieving 66-94% bias reductions through few-shot
prompting with BBQ dataset examples. These findings highlight critical areas
where LLMs reproduce mental healthcare biases, providing actionable insights
for equitable AI development.

### 26. ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought Reasoning in LLMs

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jiaru Zou, Ling Yang, Jingwen Gu, Jiahao Qiu, Ke Shen, Jingrui He, Mengdi Wang
- **URL**: <http://arxiv.org/abs/2506.18896v1>
- **Submitted**: 2025-06-23 17:59:02
- **Comment**: Codes and Models: https://github.com/Gen-Verse/ReasonFlux
- **Topic Keywords**: rag
- **Reason**: The paper focuses on Process Reward Models (PRMs) for evaluating intermediate reasoning steps in large language models, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on topics like reward supervision and policy optimization, the paper's primary focus is on natural language processing and reinforcement learning, making it only loosely relevant to the user's research interests.

#### Abstract
> Process Reward Models (PRMs) have recently emerged as a powerful framework
for supervising intermediate reasoning steps in large language models (LLMs).
Previous PRMs are primarily trained on model final output responses and
struggle to evaluate intermediate thinking trajectories robustly, especially in
the emerging setting of trajectory-response outputs generated by frontier
reasoning models like Deepseek-R1. In this work, we introduce ReasonFlux-PRM, a
novel trajectory-aware PRM explicitly designed to evaluate the
trajectory-response type of reasoning traces. ReasonFlux-PRM incorporates both
step-level and trajectory-level supervision, enabling fine-grained reward
assignment aligned with structured chain-of-thought data. We adapt
ReasonFlux-PRM to support reward supervision under both offline and online
settings, including (i) selecting high-quality model distillation data for
downstream supervised fine-tuning of smaller models, (ii) providing dense
process-level rewards for policy optimization during reinforcement learning,
and (iii) enabling reward-guided Best-of-N test-time scaling. Empirical results
on challenging downstream benchmarks such as AIME, MATH500, and GPQA-Diamond
demonstrate that ReasonFlux-PRM-7B selects higher quality data than strong PRMs
(e.g., Qwen2.5-Math-PRM-72B) and human-curated baselines. Furthermore, our
derived ReasonFlux-PRM-7B yields consistent performance improvements, achieving
average gains of 12.1% in supervised fine-tuning, 4.5% in reinforcement
learning, and 6.3% in test-time scaling. We also release our efficient
ReasonFlux-PRM-1.5B for resource-constrained applications and edge deployment.
Projects: https://github.com/Gen-Verse/ReasonFlux

### 27. Neural Total Variation Distance Estimators for Changepoint Detection in News Data

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Csaba Zsolnai, Niels L√∂rch, Julian Arnold
- **URL**: <http://arxiv.org/abs/2506.18764v1>
- **Submitted**: 2025-06-23 15:33:30
- **Comment**: 16 pages, 3 figures
- **Topic Keywords**: rag
- **Reason**: The paper focuses on changepoint detection in news data using neural networks, which is not directly related to information retrieval, search technologies, or query understanding. While it involves text data, the primary goal is not to improve search or retrieval, but rather to detect shifts in public discourse, which is outside the scope of the user's research interests.

#### Abstract
> Detecting when public discourse shifts in response to major events is crucial
for understanding societal dynamics. Real-world data is high-dimensional,
sparse, and noisy, making changepoint detection in this domain a challenging
endeavor. In this paper, we leverage neural networks for changepoint detection
in news data, introducing a method based on the so-called learning-by-confusion
scheme, which was originally developed for detecting phase transitions in
physical systems. We train classifiers to distinguish between articles from
different time periods. The resulting classification accuracy is used to
estimate the total variation distance between underlying content distributions,
where significant distances highlight changepoints. We demonstrate the
effectiveness of this method on both synthetic datasets and real-world data
from The Guardian newspaper, successfully identifying major historical events
including 9/11, the COVID-19 pandemic, and presidential elections. Our approach
requires minimal domain knowledge, can autonomously discover significant shifts
in public discourse, and yields a quantitative measure of change in content,
making it valuable for journalism, policy analysis, and crisis monitoring.

### 28. ReDit: Reward Dithering for Improved LLM Policy Optimization

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Chenxing Wei, Jiarui Yu, Ying Tiffany He, Hande Dong, Yao Shu, Fei Yu
- **URL**: <http://arxiv.org/abs/2506.18631v2>
- **Submitted**: 2025-06-23 13:36:24
- **Comment**: 10 pages, 15 figures
- **Topic Keywords**: rag
- **Reason**: The paper focuses on optimizing Large Language Model (LLM) policies using a reward dithering method, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it touches on optimization and gradient updates, the context is not relevant to the user's primary research interests.

#### Abstract
> DeepSeek-R1 has successfully enhanced Large Language Model (LLM) reasoning
capabilities through its rule-based reward system. While it's a ''perfect''
reward system that effectively mitigates reward hacking, such reward functions
are often discrete. Our experimental observations suggest that discrete rewards
can lead to gradient anomaly, unstable optimization, and slow convergence. To
address this issue, we propose ReDit (Reward Dithering), a method that dithers
the discrete reward signal by adding simple random noise. With this perturbed
reward, exploratory gradients are continuously provided throughout the learning
process, enabling smoother gradient updates and accelerating convergence. The
injected noise also introduces stochasticity into flat reward regions,
encouraging the model to explore novel policies and escape local optima.
Experiments across diverse tasks demonstrate the effectiveness and efficiency
of ReDit. On average, ReDit achieves performance comparable to vanilla GRPO
with only approximately 10% the training steps, and furthermore, still exhibits
a 4% performance improvement over vanilla GRPO when trained for a similar
duration. Visualizations confirm significant mitigation of gradient issues with
ReDit. Moreover, theoretical analyses are provided to further validate these
advantages.

### 29. No Training Wheels: Steering Vectors for Bias Correction at Inference Time

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Aviral Gupta, Armaan Sethi, Ameesh Sethi
- **URL**: <http://arxiv.org/abs/2506.18598v1>
- **Submitted**: 2025-06-23 12:58:54
- **Topic Keywords**: rag
- **Reason**: This paper focuses on bias correction in classification models, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on the topic of model editing, the approach is not applicable to ranking models or user behavior modeling, and the context is different from e-commerce or real-time relevance optimization.

#### Abstract
> Neural network classifiers trained on datasets with uneven group
representation often inherit class biases and learn spurious correlations.
These models may perform well on average but consistently fail on atypical
groups. For example, in hair color classification, datasets may over-represent
females with blond hair, reinforcing stereotypes. Although various algorithmic
and data-centric methods have been proposed to address such biases, they often
require retraining or significant compute. In this work, we propose a cheap,
training-free method inspired by steering vectors used to edit behaviors in
large language models. We compute the difference in mean activations between
majority and minority groups to define a "bias vector," which we subtract from
the model's residual stream. This leads to reduced classification bias and
improved worst-group accuracy. We explore multiple strategies for extracting
and applying these vectors in transformer-like classifiers, showing that
steering vectors, traditionally used in generative models, can also be
effective in classification. More broadly, we showcase an extremely cheap,
inference time, training free method to mitigate bias in classification models.

### 30. Smooth Operators: LLMs Translating Imperfect Hints into Disfluency-Rich Transcripts

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Duygu Altinok
- **URL**: <http://arxiv.org/abs/2506.18510v1>
- **Submitted**: 2025-06-23 11:04:20
- **Comment**: Accepted to INTERSPEECH2025 workshop DISS2025
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. The focus on spoken language processing, automatic speech recognition, and disfluency detection is outside your primary areas of interest.

#### Abstract
> Accurate detection of disfluencies in spoken language is crucial for
enhancing the performance of automatic speech and language processing systems,
as well as fostering the development of more inclusive speech and language
technologies. Leveraging the growing trend of large language models (LLMs) as
versatile learners capable of processing both lexical and non-lexical inputs
(e.g., audio and video), we propose a novel approach to transcribing
disfluencies as explicit tokens with timestamps, enabling the generation of
fully annotated disfluency-rich transcripts. Our method integrates acoustic
representations extracted from an audio encoder with textual inputs of varying
quality: clean transcriptions without disfluencies, time-aligned transcriptions
from aligners, or outputs from phoneme-based ASR models -- all of which may
contain imperfections. Importantly, our experiments demonstrate that textual
inputs do not need to be flawless. As long as they include timestamp-related
cues, LLMs can effectively smooth the input and produce fully
disfluency-annotated transcripts, underscoring their robustness in handling
imperfect hints.

### 31. Lemmatization as a Classification Task: Results from Arabic across Multiple Genres

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Mostafa Saeed, Nizar Habash
- **URL**: <http://arxiv.org/abs/2506.18399v1>
- **Submitted**: 2025-06-23 08:34:33
- **Topic Keywords**: rag
- **Reason**: The paper focuses on lemmatization in Arabic, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and query understanding. Although it involves Natural Language Processing, the specific topic and methodology are not relevant to the user's areas of focus.

#### Abstract
> Lemmatization is crucial for NLP tasks in morphologically rich languages with
ambiguous orthography like Arabic, but existing tools face challenges due to
inconsistent standards and limited genre coverage. This paper introduces two
novel approaches that frame lemmatization as classification into a
Lemma-POS-Gloss (LPG) tagset, leveraging machine translation and semantic
clustering. We also present a new Arabic lemmatization test set covering
diverse genres, standardized alongside existing datasets. We evaluate character
level sequence-to-sequence models, which perform competitively and offer
complementary value, but are limited to lemma prediction (not LPG) and prone to
hallucinating implausible forms. Our results show that classification and
clustering yield more robust, interpretable outputs, setting new benchmarks for
Arabic lemmatization.

### 32. SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zijun Chen, Zhanpeng Zhou, Bo Zhang, Weinan Zhang, Xi Sun, Junchi Yan
- **URL**: <http://arxiv.org/abs/2506.18135v1>
- **Submitted**: 2025-06-22 18:38:41
- **Comment**: preprint, accepted at IJCNN2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on model merging, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on multi-task abilities, the context is not relevant to the user's interests in IR and NLP.

#### Abstract
> Model merging has gained increasing attention due to its intriguing property:
interpolating the parameters of different task-specific fine-tuned models leads
to multi-task abilities. However, despite its empirical success, the underlying
mechanisms of model merging remain poorly understood. In this work, we delve
into the mechanism behind model merging from a representation perspective. Our
analysis reveals that model merging achieves multi-task abilities through two
key capabilities: i) distinguishing samples from different tasks, and ii)
adapting to the corresponding expert model for each sample. These two
capabilities allow the merged model to retain task-specific expertise, enabling
efficient multi-task adaptation. Building on these insights, we propose
\texttt{SE-Merging}, a self-enhanced model merging framework that leverages
these two characteristics to dynamically identify the corresponding task for
each sample and then adaptively rescales the merging coefficients to further
enhance task-specific expertise in the merged model. Notably,
\texttt{SE-Merging} achieves dynamic model merging without additional training.
Extensive experiments demonstrate that \texttt{SE-Merging} achieves significant
performance improvements while remaining compatible with existing model merging
techniques.

### 33. OmniGen2: Exploration to Advanced Multimodal Generation

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Chenyuan Wu, Pengfei Zheng, Ruiran Yan, Shitao Xiao, Xin Luo, Yueze Wang, Wanli Li, Xiyan Jiang, Yexin Liu, Junjie Zhou, Ze Liu, Ziyi Xia, Chaofan Li, Haoge Deng, Jiahao Wang, Kun Luo, Bo Zhang, Defu Lian, Xinlong Wang, Zhongyuan Wang, Tiejun Huang, Zheng Liu
- **URL**: <http://arxiv.org/abs/2506.18871v1>
- **Submitted**: 2025-06-23 17:38:54
- **Topic Keywords**: search
- **Reason**: The paper focuses on multimodal generation, which is not directly related to information retrieval, search technologies, or query understanding. While it mentions generative models, the context is different from the user's interests in ranking models and user behavior modeling.

#### Abstract
> In this work, we introduce OmniGen2, a versatile and open-source generative
model designed to provide a unified solution for diverse generation tasks,
including text-to-image, image editing, and in-context generation. Unlike
OmniGen v1, OmniGen2 features two distinct decoding pathways for text and image
modalities, utilizing unshared parameters and a decoupled image tokenizer. This
design enables OmniGen2 to build upon existing multimodal understanding models
without the need to re-adapt VAE inputs, thereby preserving the original text
generation capabilities. To facilitate the training of OmniGen2, we developed
comprehensive data construction pipelines, encompassing image editing and
in-context generation data. Additionally, we introduce a reflection mechanism
tailored for image generation tasks and curate a dedicated reflection dataset
based on OmniGen2. Despite its relatively modest parameter size, OmniGen2
achieves competitive results on multiple task benchmarks, including
text-to-image and image editing. To further evaluate in-context generation,
also referred to as subject-driven tasks, we introduce a new benchmark named
OmniContext. OmniGen2 achieves state-of-the-art performance among open-source
models in terms of consistency. We will release our models, training code,
datasets, and data construction pipeline to support future research in this
field. Project Page: https://vectorspacelab.github.io/OmniGen2; GitHub Link:
https://github.com/VectorSpaceLab/OmniGen2

### 34. Mechanistic Interpretability Needs Philosophy

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Iwan Williams, Ninell Oldenburg, Ruchira Dhar, Joshua Hatherley, Constanza Fierro, Nina Rajcic, Sandrine R. Schiller, Filippos Stamatiou, Anders S√∏gaard
- **URL**: <http://arxiv.org/abs/2506.18852v1>
- **Submitted**: 2025-06-23 17:13:30
- **Topic Keywords**: search
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus on mechanistic interpretability and philosophy is outside the scope of the user's research interests.

#### Abstract
> Mechanistic interpretability (MI) aims to explain how neural networks work by
uncovering their underlying causal mechanisms. As the field grows in influence,
it is increasingly important to examine not just models themselves, but the
assumptions, concepts and explanatory strategies implicit in MI research. We
argue that mechanistic interpretability needs philosophy: not as an
afterthought, but as an ongoing partner in clarifying its concepts, refining
its methods, and assessing the epistemic and ethical stakes of interpreting AI
systems. Taking three open problems from the MI literature as examples, this
position paper illustrates the value philosophy can add to MI research, and
outlines a path toward deeper interdisciplinary dialogue.

### 35. RWESummary: A Framework and Test for Choosing Large Language Models to Summarize Real-World Evidence (RWE) Studies

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Arjun Mukerji, Michael L. Jackson, Jason Jones, Neil Sanghavi
- **URL**: <http://arxiv.org/abs/2506.18819v1>
- **Submitted**: 2025-06-23 16:28:03
- **Comment**: 24 pages, 2 figures
- **Topic Keywords**: search
- **Reason**: This paper focuses on evaluating large language models for summarizing real-world evidence studies, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on natural language processing, the specific application and evaluation metrics are not aligned with the user's research interests.

#### Abstract
> Large Language Models (LLMs) have been extensively evaluated for general
summarization tasks as well as medical research assistance, but they have not
been specifically evaluated for the task of summarizing real-world evidence
(RWE) from structured output of RWE studies. We introduce RWESummary, a
proposed addition to the MedHELM framework (Bedi, Cui, Fuentes, Unell et al.,
2025) to enable benchmarking of LLMs for this task. RWESummary includes one
scenario and three evaluations covering major types of errors observed in
summarization of medical research studies and was developed using Atropos
Health proprietary data. Additionally, we use RWESummary to compare the
performance of different LLMs in our internal RWE summarization tool. At the
time of publication, with 13 distinct RWE studies, we found the Gemini 2.5
models performed best overall (both Flash and Pro). We suggest RWESummary as a
novel and useful foundation model benchmark for real-world evidence study
summarization.

### 36. TranslationCorrect: A Unified Framework for Machine Translation Post-Editing with Predictive Error Assistance

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Syed Mekael Wasti, Shou-Yi Hung, Christopher Collins, En-Shiun Annie Lee
- **URL**: <http://arxiv.org/abs/2506.18337v1>
- **Submitted**: 2025-06-23 06:38:49
- **Comment**: Preprint
- **Topic Keywords**: search
- **Reason**: The paper focuses on machine translation post-editing, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on some NLP aspects, the paper's scope is too narrow and specific to machine translation, making it only loosely relevant to the user's broader interests.

#### Abstract
> Machine translation (MT) post-editing and research data collection often rely
on inefficient, disconnected workflows. We introduce TranslationCorrect, an
integrated framework designed to streamline these tasks. TranslationCorrect
combines MT generation using models like NLLB, automated error prediction using
models like XCOMET or LLM APIs (providing detailed reasoning), and an intuitive
post-editing interface within a single environment. Built with human-computer
interaction (HCI) principles in mind to minimize cognitive load, as confirmed
by a user study. For translators, it enables them to correct errors and batch
translate efficiently. For researchers, TranslationCorrect exports high-quality
span-based annotations in the Error Span Annotation (ESA) format, using an
error taxonomy inspired by Multidimensional Quality Metrics (MQM). These
outputs are compatible with state-of-the-art error detection models and
suitable for training MT or post-editing systems. Our user study confirms that
TranslationCorrect significantly improves translation efficiency and user
satisfaction over traditional annotation methods.

### 37. Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Bushra Asseri, Estabrag Abdelaziz, Areej Al-Wabil
- **URL**: <http://arxiv.org/abs/2506.18199v1>
- **Submitted**: 2025-06-22 23:15:25
- **Topic Keywords**: search
- **Reason**: The paper focuses on cultural bias in large language models, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper touches on prompt engineering, it is primarily concerned with bias mitigation in language models, which is not a central theme in the user's research areas.

#### Abstract
> Large language models have demonstrated remarkable capabilities across
various domains, yet concerns about cultural bias - particularly towards Arabs
and Muslims - pose significant ethical challenges by perpetuating harmful
stereotypes and marginalization. Despite growing recognition of bias in LLMs,
prompt engineering strategies specifically addressing Arab and Muslim
representation remain understudied. This mixed-methods systematic review
examines such techniques, offering evidence-based guidance for researchers and
practitioners. Following PRISMA guidelines and Kitchenham's systematic review
methodology, we analyzed 8 empirical studies published between 2021-2024
investigating bias mitigation strategies. Our findings reveal five primary
prompt engineering approaches: cultural prompting, affective priming,
self-debiasing techniques, structured multi-step pipelines, and
parameter-optimized continuous prompts. Although all approaches show potential
for reducing bias, effectiveness varied substantially across studies and bias
types. Evidence suggests that certain bias types may be more resistant to
prompt-based mitigation than others. Structured multi-step pipelines
demonstrated the highest overall effectiveness, achieving up to 87.7% reduction
in bias, though they require greater technical expertise. Cultural prompting
offers broader accessibility with substantial effectiveness. These results
underscore the accessibility of prompt engineering for mitigating cultural bias
without requiring access to model parameters. The limited number of studies
identified highlights a significant research gap in this critical area. Future
research should focus on developing culturally adaptive prompting techniques,
creating Arab and Muslim-specific evaluation resources, and integrating prompt
engineering with complementary debiasing methods to address deeper stereotypes
while maintaining model utility.

### 38. The Syntactic Acceptability Dataset (Preview): A Resource for Machine Learning and Linguistic Analysis of English

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Tom S Juzek
- **URL**: <http://arxiv.org/abs/2506.18120v1>
- **Submitted**: 2025-06-22 18:03:49
- **Comment**: Accepted and published at LREC-COLING 2024. 8 pages, 3 figures.
  Licensed under CC BY-NC-SA 4.0
- **Topic Keywords**: search
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. The focus is on linguistics and syntax, which is a distant topic from the user's primary research interests.

#### Abstract
> We present a preview of the Syntactic Acceptability Dataset, a resource being
designed for both syntax and computational linguistics research. In its current
form, the dataset comprises 1,000 English sequences from the syntactic
discourse: Half from textbooks and half from the journal Linguistic Inquiry,
the latter to ensure a representation of the contemporary discourse. Each entry
is labeled with its grammatical status ("well-formedness" according to
syntactic formalisms) extracted from the literature, as well as its
acceptability status ("intuitive goodness" as determined by native speakers)
obtained through crowdsourcing, with highest experimental standards. Even in
its preliminary form, this dataset stands as the largest of its kind that is
publicly accessible. We also offer preliminary analyses addressing three
debates in linguistics and computational linguistics: We observe that
grammaticality and acceptability judgments converge in about 83% of the cases
and that "in-betweenness" occurs frequently. This corroborates existing
research. We also find that while machine learning models struggle with
predicting grammaticality, they perform considerably better in predicting
acceptability. This is a novel finding. Future work will focus on expanding the
dataset.

---

