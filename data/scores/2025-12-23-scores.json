[
    {
        "title": "Affordance RAG: Hierarchical Multimodal Retrieval with Affordance-Aware Embodied Memory for Mobile Manipulation",
        "abstract": "In this study, we address the problem of open-vocabulary mobile manipulation, where a robot is required to carry a wide range of objects to receptacles based on free-form natural language instructions. This task is challenging, as it involves understanding visual semantics and the affordance of manipulation actions. To tackle these challenges, we propose Affordance RAG, a zero-shot hierarchical multimodal retrieval framework that constructs Affordance-Aware Embodied Memory from pre-explored images. The model retrieves candidate targets based on regional and visual semantics and reranks them with affordance scores, allowing the robot to identify manipulation options that are likely to be executable in real-world environments. Our method outperformed existing approaches in retrieval performance for mobile manipulation instruction in large-scale indoor environments. Furthermore, in real-world experiments where the robot performed mobile manipulation in indoor environments based on free-form instructions, the proposed method achieved a task success rate of 85%, outperforming existing methods in both retrieval performance and overall task success.",
        "url": "http://arxiv.org/abs/2512.18987v1",
        "pdf_url": "https://arxiv.org/pdf/2512.18987v1",
        "arxiv_id": "2512.18987v1",
        "authors": [
            "Ryosuke Korekata",
            "Quanting Xie",
            "Yonatan Bisk",
            "Komei Sugiura"
        ],
        "submitted": "2025-12-22 02:55:25",
        "source": "arxiv",
        "comment": "Accepted to IEEE RA-L, with presentation at ICRA 2026",
        "score": 10,
        "keyword_reasons": [
            "Found 'rerank' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on mobile manipulation and multimodal retrieval for robots, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves understanding visual semantics, it's more focused on robotics and embodied cognition, making it only loosely relevant to the user's interests."
    },
    {
        "title": "Generative vector search to improve pathology foundation models across multimodal vision-language tasks",
        "abstract": "Retrieval-augmented generation improves large language models by grounding outputs in external knowledge sources, reducing hallucinations and addressing knowledge cutoffs. However, standard embedding-based retrieval fails to capture the complexity of multi-concept queries, particularly in domains like biomedicine, where biological data are inherently high-dimensional. For example,omics datasets, and clinical reports simultaneously exhibit numerous molecular, cellular, and physiological features. We present Stochastic Latent Matching (STHLM), a generative vector search method that samples query-conditioned embeddings from text or image inputs to enhance retrieval performance. Analogous to how Chain-of-Thought reasoning enables language models to \"think longer\" on complex problems, STHLM allows retrieval systems to \"search wider\" through iterative sampling. STHLM demonstrates critical improvements over classical vector retrieval across diverse benchmarks, including scientific literature, clinical notes, and tissue images, boosting retrieval performance by 10-30% through test-time compute (trading latency for accuracy), while enabling up to a 10-fold compression of embedding dimensions.",
        "url": "http://arxiv.org/abs/2512.19360v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19360v1",
        "arxiv_id": "2512.19360v1",
        "authors": [
            "Markus Ekvall",
            "Ludvig Bergenstråhle",
            "Patrick Truong",
            "Ben Murrell",
            "Joakim Lundeberg"
        ],
        "submitted": "2025-12-22 12:59:23",
        "source": "arxiv",
        "comment": "13 pages main (54 total), 2 main figures (9 total)",
        "score": 9,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper presents a generative vector search method for improving retrieval performance in multimodal vision-language tasks, particularly in biomedicine. While it touches on retrieval and NLP, it doesn't directly relate to query understanding, ranking models, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "A Large Language Model Based Method for Complex Logical Reasoning over Knowledge Graphs",
        "abstract": "Reasoning over knowledge graphs (KGs) with first-order logic (FOL) queries is challenging due to the inherent incompleteness of real-world KGs and the compositional complexity of logical query structures. Most existing methods rely on embedding entities and relations into continuous geometric spaces and answer queries via differentiable set operations. While effective for simple query patterns, these approaches often struggle to generalize to complex queries involving multiple operators, deeper reasoning chains, or heterogeneous KG schemas. We propose ROG (Reasoning Over knowledge Graphs with large language models), an ensemble-style framework that combines query-aware KG neighborhood retrieval with large language model (LLM)-based chain-of-thought reasoning. ROG decomposes complex FOL queries into sequences of simpler sub-queries, retrieves compact, query-relevant subgraphs as contextual evidence, and performs step-by-step logical inference using an LLM, avoiding the need for task-specific embedding optimization. Experiments on standard KG reasoning benchmarks demonstrate that ROG consistently outperforms strong embedding-based baselines in terms of mean reciprocal rank (MRR), with particularly notable gains on high-complexity query types. These results suggest that integrating structured KG retrieval with LLM-driven logical reasoning offers a robust and effective alternative for complex KG reasoning tasks.",
        "url": "http://arxiv.org/abs/2512.19092v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19092v1",
        "arxiv_id": "2512.19092v1",
        "authors": [
            "Ziyan Zhang",
            "Chao Wang",
            "Zhuo Chen",
            "Lei Chen",
            "Chiyi Li",
            "Kai Song"
        ],
        "submitted": "2025-12-22 07:01:05",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores a method for complex logical reasoning over knowledge graphs using large language models, which is somewhat related to information retrieval and NLP. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's focus on knowledge graphs and logical reasoning is more aligned with recommender systems, but it does not seem to be a primary focus of the research."
    },
    {
        "title": "QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation",
        "abstract": "Dynamic Retrieval-Augmented Generation adaptively determines when to retrieve during generation to mitigate hallucinations in large language models (LLMs). However, existing methods rely on model-internal signals (e.g., logits, entropy), which are fundamentally unreliable because LLMs are typically ill-calibrated and often exhibit high confidence in erroneous outputs. We propose QuCo-RAG, which shifts from subjective confidence to objective statistics computed from pre-training data. Our method quantifies uncertainty through two stages: (1) before generation, we identify low-frequency entities indicating long-tail knowledge gaps; (2) during generation, we verify entity co-occurrence in the pre-training corpus, where zero co-occurrence often signals hallucination risk. Both stages leverage Infini-gram for millisecond-latency queries over 4 trillion tokens, triggering retrieval when uncertainty is high. Experiments on multi-hop QA benchmarks show QuCo-RAG achieves EM gains of 5--12 points over state-of-the-art baselines with OLMo-2 models, and transfers effectively to models with undisclosed pre-training data (Llama, Qwen, GPT), improving EM by up to 14 points. Domain generalization on biomedical QA further validates the robustness of our paradigm. These results establish corpus-grounded verification as a principled, practically model-agnostic paradigm for dynamic RAG. Our code is publicly available at https://github.com/ZhishanQ/QuCo-RAG.",
        "url": "http://arxiv.org/abs/2512.19134v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19134v1",
        "arxiv_id": "2512.19134v1",
        "authors": [
            "Dehai Min",
            "Kailin Zhang",
            "Tongtong Wu",
            "Lu Cheng"
        ],
        "submitted": "2025-12-22 08:28:05",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to information retrieval, but its focus on uncertainty quantification in language models and retrieval-augmented generation is not directly aligned with your core research themes of query understanding, ranking models, and user behavior modeling. While it touches on the e-commerce domain indirectly through its application to multi-hop QA benchmarks, it does not appear to be a central match for your research interests."
    },
    {
        "title": "A Large-Language-Model Framework for Automated Humanitarian Situation Reporting",
        "abstract": "Timely and accurate situational reports are essential for humanitarian decision-making, yet current workflows remain largely manual, resource intensive, and inconsistent. We present a fully automated framework that uses large language models (LLMs) to transform heterogeneous humanitarian documents into structured and evidence-grounded reports. The system integrates semantic text clustering, automatic question generation, retrieval augmented answer extraction with citations, multi-level summarization, and executive summary generation, supported by internal evaluation metrics that emulate expert reasoning. We evaluated the framework across 13 humanitarian events, including natural disasters and conflicts, using more than 1,100 documents from verified sources such as ReliefWeb. The generated questions achieved 84.7 percent relevance, 84.0 percent importance, and 76.4 percent urgency. The extracted answers reached 86.3 percent relevance, with citation precision and recall both exceeding 76 percent. Agreement between human and LLM based evaluations surpassed an F1 score of 0.80. Comparative analysis shows that the proposed framework produces reports that are more structured, interpretable, and actionable than existing baselines. By combining LLM reasoning with transparent citation linking and multi-level evaluation, this study demonstrates that generative AI can autonomously produce accurate, verifiable, and operationally useful humanitarian situation reports.",
        "url": "http://arxiv.org/abs/2512.19475v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19475v1",
        "arxiv_id": "2512.19475v1",
        "authors": [
            "Ivan Decostanzi",
            "Yelena Mejova",
            "Kyriaki Kalimeri"
        ],
        "submitted": "2025-12-22 15:28:55",
        "source": "arxiv",
        "comment": "18 pages, 3 figures",
        "score": 5,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves large language models and text analysis, its focus on humanitarian situation reporting and automated document transformation is outside the user's primary areas of interest."
    },
    {
        "title": "Remedy-R: Generative Reasoning for Machine Translation Evaluation without Error Annotations",
        "abstract": "Over the years, automatic MT metrics have hillclimbed benchmarks and presented strong and sometimes human-level agreement with human ratings. Yet they remain black-box, offering little insight into their decision-making and often failing under real-world out-of-distribution (OOD) inputs. We introduce Remedy-R, a reasoning-driven generative MT metric trained with reinforcement learning from pairwise translation preferences, without requiring error-span annotations or distillation from closed LLMs. Remedy-R produces step-by-step analyses of accuracy, fluency, and completeness, followed by a final score, enabling more interpretable assessments. With only 60K training pairs across two language pairs, Remedy-R remains competitive with top scalar metrics and GPT-4-based judges on WMT22-24 meta-evaluation, generalizes to other languages, and exhibits strong robustness on OOD stress tests. Moreover, Remedy-R models generate self-reflective feedback that can be reused for translation improvement. Building on this finding, we introduce Remedy-R Agent, a simple evaluate-revise pipeline that leverages Remedy-R's evaluation analysis to refine translations. This agent consistently improves translation quality across diverse models, including Qwen2.5, ALMA-R, GPT-4o-mini, and Gemini-2.0-Flash, suggesting that Remedy-R's reasoning captures translation-relevant information and is practically useful.",
        "url": "http://arxiv.org/abs/2512.18906v1",
        "pdf_url": "https://arxiv.org/pdf/2512.18906v1",
        "arxiv_id": "2512.18906v1",
        "authors": [
            "Shaomu Tan",
            "Ryosuke Mitani",
            "Ritvik Choudhary",
            "Qiyu Wu",
            "Toshiyuki Sekiya",
            "Christof Monz"
        ],
        "submitted": "2025-12-21 22:37:38",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on machine translation evaluation and introduces a new metric called Remedy-R. While it involves some aspects of natural language processing, it does not directly relate to information retrieval, search technologies, or query understanding, which are the core areas of your research interests."
    },
    {
        "title": "Event Extraction in Large Language Model",
        "abstract": "Large language models (LLMs) and multimodal LLMs are changing event extraction (EE): prompting and generation can often produce structured outputs in zero shot or few shot settings. Yet LLM based pipelines face deployment gaps, including hallucinations under weak constraints, fragile temporal and causal linking over long contexts and across documents, and limited long horizon knowledge management within a bounded context window. We argue that EE should be viewed as a system component that provides a cognitive scaffold for LLM centered solutions. Event schemas and slot constraints create interfaces for grounding and verification; event centric structures act as controlled intermediate representations for stepwise reasoning; event links support relation aware retrieval with graph based RAG; and event stores offer updatable episodic and agent memory beyond the context window. This survey covers EE in text and multimodal settings, organizing tasks and taxonomy, tracing method evolution from rule based and neural models to instruction driven and generative frameworks, and summarizing formulations, decoding strategies, architectures, representations, datasets, and evaluation. We also review cross lingual, low resource, and domain specific settings, and highlight open challenges and future directions for reliable event centric systems. Finally, we outline open challenges and future directions that are central to the LLM era, aiming to evolve EE from static extraction into a structurally reliable, agent ready perception and memory layer for open world systems.",
        "url": "http://arxiv.org/abs/2512.19537v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19537v1",
        "arxiv_id": "2512.19537v1",
        "authors": [
            "Bobo Li",
            "Xudong Han",
            "Jiang Liu",
            "Yuzhe Ding",
            "Liqiang Jing",
            "Zhaoqi Zhang",
            "Jinheng Li",
            "Xinya Du",
            "Fei Li",
            "Meishan Zhang",
            "Min Zhang",
            "Aixin Sun",
            "Philip S. Yu",
            "Hao Fei"
        ],
        "submitted": "2025-12-22 16:22:14",
        "source": "arxiv",
        "comment": "38 pages, 9 Figures, 5 Tables",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on event extraction, a related topic to information retrieval, but it primarily deals with natural language processing and large language models. While it touches on the idea of structurally reliable systems, it doesn't directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest."
    },
    {
        "title": "MobileWorld: Benchmarking Autonomous Mobile Agents in Agent-User Interactive, and MCP-Augmented Environments",
        "abstract": "Among existing online mobile-use benchmarks, AndroidWorld has emerged as the dominant benchmark due to its reproducible environment and deterministic evaluation; however, recent agents achieving over 90% success rates indicate its saturation and motivate the need for a more challenging benchmark. In addition, its environment lacks key application categories, such as e-commerce and enterprise communication, and does not reflect realistic mobile-use scenarios characterized by vague user instructions and hybrid tool usage. To bridge this gap, we introduce MobileWorld, a substantially more challenging benchmark designed to better reflect real-world mobile usage, comprising 201 tasks across 20 applications, while maintaining the same level of reproducible evaluation as AndroidWorld. The difficulty of MobileWorld is twofold. First, it emphasizes long-horizon tasks with cross-application interactions: MobileWorld requires nearly twice as many task-completion steps on average (27.8 vs. 14.3) and includes far more multi-application tasks (62.2% vs. 9.5%) compared to AndroidWorld. Second, MobileWorld extends beyond standard GUI manipulation by introducing novel task categories, including agent-user interaction and MCP-augmented tasks. To ensure robust evaluation, we provide snapshot-based container environment and precise functional verifications, including backend database inspection and task callback APIs. We further develop a planner-executor agentic framework with extended action spaces to support user interactions and MCP calls. Our results reveal a sharp performance drop compared to AndroidWorld, with the best agentic framework and end-to-end model achieving 51.7% and 20.9% success rates, respectively. Our analysis shows that current models struggle significantly with user interaction and MCP calls, offering a strategic roadmap toward more robust, next-generation mobile intelligence.",
        "url": "http://arxiv.org/abs/2512.19432v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19432v1",
        "arxiv_id": "2512.19432v1",
        "authors": [
            "Quyu Kong",
            "Xu Zhang",
            "Zhenyu Yang",
            "Nolan Gao",
            "Chen Liu",
            "Panrong Tong",
            "Chenglin Cai",
            "Hanzhang Zhou",
            "Jianan Zhang",
            "Liangyu Chen",
            "Zhidan Liu",
            "Steven Hoi",
            "Yue Wang"
        ],
        "submitted": "2025-12-22 14:31:28",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on benchmarking autonomous mobile agents and does not address topics such as query understanding, ranking models, or user behavior modeling in the context of information retrieval or search technologies."
    },
    {
        "title": "From Retrieval to Reasoning: A Framework for Cyber Threat Intelligence NER with Explicit and Adaptive Instructions",
        "abstract": "The automation of Cyber Threat Intelligence (CTI) relies heavily on Named Entity Recognition (NER) to extract critical entities from unstructured text. Currently, Large Language Models (LLMs) primarily address this task through retrieval-based In-Context Learning (ICL). This paper analyzes this mainstream paradigm, revealing a fundamental flaw: its success stems not from global semantic similarity but largely from the incidental overlap of entity types within retrieved examples. This exposes the limitations of relying on unreliable implicit induction. To address this, we propose TTPrompt, a framework shifting from implicit induction to explicit instruction. TTPrompt maps the core concepts of CTI's Tactics, Techniques, and Procedures (TTPs) into an instruction hierarchy: formulating task definitions as Tactics, guiding strategies as Techniques, and annotation guidelines as Procedures. Furthermore, to handle the adaptability challenge of static guidelines, we introduce Feedback-driven Instruction Refinement (FIR). FIR enables LLMs to self-refine guidelines by learning from errors on minimal labeled data, adapting to distinct annotation dialects. Experiments on five CTI NER benchmarks demonstrate that TTPrompt consistently surpasses retrieval-based baselines. Notably, with refinement on just 1% of training data, it rivals models fine-tuned on the full dataset. For instance, on LADDER, its Micro F1 of 71.96% approaches the fine-tuned baseline, and on the complex CTINexus, its Macro F1 exceeds the fine-tuned ACLM model by 10.91%.",
        "url": "http://arxiv.org/abs/2512.19414v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19414v1",
        "arxiv_id": "2512.19414v1",
        "authors": [
            "Jiaren Peng",
            "Hongda Sun",
            "Xuan Tian",
            "Cheng Huang",
            "Zeqing Li",
            "Rui Yan"
        ],
        "submitted": "2025-12-22 14:13:01",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, as it discusses a framework for Named Entity Recognition (NER) using Large Language Models (LLMs). However, the focus on Cyber Threat Intelligence and the specific application of the framework to this domain makes it less directly relevant to your core research themes. The paper's emphasis on explicit instruction and adaptability is also somewhat tangential to your interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics",
        "abstract": "Prompt engineering plays a critical role in adapting large language models (LLMs) to complex reasoning and labeling tasks without the need for extensive fine-tuning. In this paper, we propose a novel prompt optimization pipeline for frame detection in logistics texts, combining retrieval-augmented generation (RAG), few-shot prompting, chain-of-thought (CoT) reasoning, and automatic CoT synthesis (Auto-CoT) to generate highly effective task-specific prompts. Central to our approach is an LLM-based prompt optimizer agent that iteratively refines the prompts using retrieved examples, performance feedback, and internal self-evaluation. Our framework is evaluated on a real-world logistics text annotation task, where reasoning accuracy and labeling efficiency are critical. Experimental results show that the optimized prompts - particularly those enhanced via Auto-CoT and RAG - improve real-world inference accuracy by up to 15% compared to baseline zero-shot or static prompts. The system demonstrates consistent improvements across multiple LLMs, including GPT-4o, Qwen 2.5 (72B), and LLaMA 3.1 (70B), validating its generalizability and practical value. These findings suggest that structured prompt optimization is a viable alternative to full fine-tuning, offering scalable solutions for deploying LLMs in domain-specific NLP applications such as logistics.",
        "url": "http://arxiv.org/abs/2512.19247v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19247v1",
        "arxiv_id": "2512.19247v1",
        "authors": [
            "Do Minh Duc",
            "Quan Xuan Truong",
            "Nguyen Tat Dat",
            "Nguyen Van Vinh"
        ],
        "submitted": "2025-12-22 10:29:51",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the application of large language models in logistics, focusing on prompt engineering and optimization for frame detection. While it touches on retrieval-augmented generation, which is related to information retrieval, the primary focus is on NLP and prompt engineering, making it somewhat relevant but not a central match to your research interests."
    },
    {
        "title": "BanglaForge: LLM Collaboration with Self-Refinement for Bangla Code Generation",
        "abstract": "Bangla is a low-resource language for code generation, lacking large-scale annotated datasets and tools to transform natural language specifications into executable programs. This makes Bangla-to-code generation a challenging task requiring innovative solutions. To address this, we introduce BanglaForge, a novel framework for generating code from Bangla function descriptions. BanglaForge leverages a retrieval-augmented dual-model collaboration paradigm with self-refinement, combining in-context learning, llm-based translation, systematic prompt engineering, and iterative self-refinement based on execution feedback, where a coder generates initial solutions and a reviewer enhances them for robustness. On the BLP-2025 Bangla Code Generation benchmark, BanglaForge achieves a competitive Pass@1 accuracy of 84.00%, demonstrating the effectiveness of retrieval, model collaboration, and self-refinement for low-resource Bangla code generation.",
        "url": "http://arxiv.org/abs/2512.19122v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19122v1",
        "arxiv_id": "2512.19122v1",
        "authors": [
            "Mahir Labib Dihan",
            "Sadif Ahmed",
            "Md Nafiu Rahman"
        ],
        "submitted": "2025-12-22 07:53:16",
        "source": "arxiv",
        "comment": "Accepted at BLP Workshop @ IJCNLP-AACL 2025. Code is available at https://github.com/mahirlabibdihan/BanglaForge",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing, as it focuses on low-resource language code generation and does not mention query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Exploring Zero-Shot ACSA with Unified Meaning Representation in Chain-of-Thought Prompting",
        "abstract": "Aspect-Category Sentiment Analysis (ACSA) provides granular insights by identifying specific themes within reviews and their associated sentiment. While supervised learning approaches dominate this field, the scarcity and high cost of annotated data for new domains present significant barriers. We argue that leveraging large language models (LLMs) in a zero-shot setting is a practical alternative where resources for data annotation are limited. In this work, we propose a novel Chain-of-Thought (CoT) prompting technique that utilises an intermediate Unified Meaning Representation (UMR) to structure the reasoning process for the ACSA task. We evaluate this UMR-based approach against a standard CoT baseline across three models (Qwen3-4B, Qwen3-8B, and Gemini-2.5-Pro) and four diverse datasets. Our findings suggest that UMR effectiveness may be model-dependent. Whilst preliminary results indicate comparable performance for mid-sized models such as Qwen3-8B, these observations warrant further investigation, particularly regarding the potential applicability to smaller model architectures. Further research is required to establish the generalisability of these findings across different model scales.",
        "url": "http://arxiv.org/abs/2512.19651v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19651v1",
        "arxiv_id": "2512.19651v1",
        "authors": [
            "Filippos Ventirozos",
            "Peter Appleby",
            "Matthew Shardlow"
        ],
        "submitted": "2025-12-22 18:23:37",
        "source": "arxiv",
        "comment": "9 pages, 3 figures, 3 tables",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores a novel approach to Aspect-Category Sentiment Analysis (ACSA) using Chain-of-Thought prompting with Unified Meaning Representation. While it touches on aspects of Natural Language Processing (NLP), it is primarily focused on a specific task and does not directly relate to the user's core research themes in Information Retrieval (IR) and Search technologies. The paper's emphasis on leveraging large language models in a zero-shot setting may be of interest to the user, but it is not a central match."
    },
    {
        "title": "CycleChart: A Unified Consistency-Based Learning Framework for Bidirectional Chart Understanding and Generation",
        "abstract": "Current chart-specific tasks, such as chart question answering, chart parsing, and chart generation, are typically studied in isolation, preventing models from learning the shared semantics that link chart generation and interpretation. We introduce CycleChart, a consistency-based learning framework for bidirectional chart understanding and generation. CycleChart adopts a schema-centric formulation as a common interface across tasks. We construct a consistent multi-task dataset, where each chart sample includes aligned annotations for schema prediction, data parsing, and question answering. To learn cross-directional chart semantics, CycleChart introduces a generate-parse consistency objective: the model generates a chart schema from a table and a textual query, then learns to recover the schema and data from the generated chart, enforcing semantic alignment across directions. CycleChart achieves strong results on chart generation, chart parsing, and chart question answering, demonstrating improved cross-task generalization and marking a step toward more general chart understanding models.",
        "url": "http://arxiv.org/abs/2512.19173v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19173v1",
        "arxiv_id": "2512.19173v1",
        "authors": [
            "Dazhen Deng",
            "Sen Yang",
            "Yuchen He",
            "Yuan Tian",
            "Yingcai Wu"
        ],
        "submitted": "2025-12-22 09:07:34",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on chart understanding and generation, which is not directly related to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves learning and generation, the context is chart-specific and does not align with your interests in query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "SAP: Syntactic Attention Pruning for Transformer-based Language Models",
        "abstract": "This paper introduces Syntactic Attention Pruning (SAP), a novel method for effectively pruning attention heads in Transformer models. Unlike conventional approaches that rely solely on mathematical analysis of model weights and activations, SAP incorporates both the syntactic structure and attention patterns of sentences to guide the pruning process. By leveraging these linguistic features, SAP not only achieves performance comparable to state-of-the-art methods but also enhances the interpretability of model behavior. To further improve robustness, we propose Candidate Filtering (CF), a mechanism that prioritizes heads based on their contribution to model performance, mitigating degradation during pruning. Experimental results indicate that SAP effectively preserves critical heads of a high density of strong attention values, outperforming existing head pruning strategies in retrain-free settings. These findings position SAP as a promising foundation for a new direction in model compression research, offering high flexibility for pruning across all transformer-based language models.",
        "url": "http://arxiv.org/abs/2512.19125v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19125v1",
        "arxiv_id": "2512.19125v1",
        "authors": [
            "Tzu-Yun Lee",
            "Ding-Yong Hong",
            "Jan-Jan Wu"
        ],
        "submitted": "2025-12-22 08:05:01",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on pruning attention heads in Transformer models for language understanding, which is not directly related to your core research interests in Information Retrieval, Search technologies, and user behavior modeling. While it touches on NLP, it doesn't address query understanding, ranking models, or real-time relevance optimization, making it only loosely relevant to your research."
    },
    {
        "title": "DramaBench: A Six-Dimensional Evaluation Framework for Drama Script Continuation",
        "abstract": "Drama script continuation requires models to maintain character consistency, advance plot coherently, and preserve dramatic structurecapabilities that existing benchmarks fail to evaluate comprehensively. We present DramaBench, the first large-scale benchmark for evaluating drama script continuation across six independent dimensions: Format Standards, Narrative Efficiency, Character Consistency, Emotional Depth, Logic Consistency, and Conflict Handling. Our framework combines rulebased analysis with LLM-based labeling and statistical metrics, ensuring objective and reproducible evaluation. We conduct comprehensive evaluation of 8 state-of-the-art language models on 1,103 scripts (8,824 evaluations total), with rigorous statistical significance testing (252 pairwise comparisons, 65.9% significant) and human validation (188 scripts, substantial agreement on 3/5 dimensions). Our ablation studies confirm all six dimensions capture independent quality aspects (mean | r | = 0.020). DramaBench provides actionable, dimensionspecific feedback for model improvement and establishes a rigorous standard for creative writing evaluation.",
        "url": "http://arxiv.org/abs/2512.19012v2",
        "pdf_url": "https://arxiv.org/pdf/2512.19012v2",
        "arxiv_id": "2512.19012v2",
        "authors": [
            "Shijian Ma",
            "Yunqi Huang",
            "Yan Lin"
        ],
        "submitted": "2025-12-22 04:03:01",
        "source": "arxiv",
        "comment": "Project page: https://dramabench.pages.dev/",
        "score": 3,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on drama script continuation evaluation, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language models, the context and application are quite different from the user's interests."
    },
    {
        "title": "GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators",
        "abstract": "Training capable Large Language Model (LLM) agents is critically bottlenecked by the high cost and static nature of real-world interaction data. We address this by introducing GenEnv, a framework that establishes a difficulty-aligned co-evolutionary game between an agent and a scalable, generative environment simulator. Unlike traditional methods that evolve models on static datasets, GenEnv instantiates a dataevolving: the simulator acts as a dynamic curriculum policy, continuously generating tasks specifically tailored to the agent's ``zone of proximal development''. This process is guided by a simple but effective $α$-Curriculum Reward, which aligns task difficulty with the agent's current capabilities. We evaluate GenEnv on five benchmarks, including API-Bank, ALFWorld, BFCL, Bamboogle, and TravelPlanner. Across these tasks, GenEnv improves agent performance by up to \\textbf{+40.3\\%} over 7B baselines and matches or exceeds the average performance of larger models. Compared to Gemini 2.5 Pro-based offline data augmentation, GenEnv achieves better performance while using 3.3$\\times$ less data. By shifting from static supervision to adaptive simulation, GenEnv provides a data-efficient pathway for scaling agent capabilities.",
        "url": "http://arxiv.org/abs/2512.19682v2",
        "pdf_url": "https://arxiv.org/pdf/2512.19682v2",
        "arxiv_id": "2512.19682v2",
        "authors": [
            "Jiacheng Guo",
            "Ling Yang",
            "Peter Chen",
            "Qixin Xiao",
            "Yinjie Wang",
            "Xinzhe Juan",
            "Jiahao Qiu",
            "Ke Shen",
            "Mengdi Wang"
        ],
        "submitted": "2025-12-22 18:57:13",
        "source": "arxiv",
        "comment": "Our codes are available at https://github.com/Gen-Verse/GenEnv",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Large Language Model (LLM) agents and environment simulators, which is not directly related to your core research themes in Information Retrieval and Search technologies. While it involves some NLP aspects, the primary focus is on scaling LLM capabilities, which doesn't align with your interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies",
        "abstract": "Existing reinforcement learning (RL) approaches treat large language models (LLMs) as a single unified policy, overlooking their internal mechanisms. Understanding how policy evolves across layers and modules is therefore crucial for enabling more targeted optimization and raveling out complex reasoning mechanisms. In this paper, we decompose the language model policy by leveraging the intrinsic split of the Transformer residual stream and the equivalence between the composition of hidden states with the unembedding matrix and the resulting samplable policy. This decomposition reveals Internal Layer Policies, corresponding to contributions from individual layers, and Internal Modular Policies, which align with the self-attention and feed-forward network (FFN) components within each layer. By analyzing the entropy of internal policy, we find that: (a) Early layers keep high entropy for exploration, top layers converge to near-zero entropy for refinement, with convergence patterns varying across model series. (b) LLama's prediction space rapidly converges in the final layer, whereas Qwen-series models, especially Qwen3, exhibit a more human-like, progressively structured reasoning pattern. Motivated by these findings, we propose Bottom-up Policy Optimization (BuPO), a novel RL paradigm that directly optimizes the internal layer policy during early training. By aligning training objective at lower layer, BuPO reconstructs foundational reasoning capabilities and achieves superior performance. Extensive experiments on complex reasoning benchmarks demonstrates the effectiveness of our method. Our code is available at https://github.com/Trae1ounG/BuPO.",
        "url": "http://arxiv.org/abs/2512.19673v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19673v1",
        "arxiv_id": "2512.19673v1",
        "authors": [
            "Yuqiao Tan",
            "Minzheng Wang",
            "Shizhu He",
            "Huanxuan Liao",
            "Chengfeng Zhao",
            "Qiunan Lu",
            "Tian Liang",
            "Jun Zhao",
            "Kang Liu"
        ],
        "submitted": "2025-12-22 18:51:48",
        "source": "arxiv",
        "comment": "Preprint. Our code is available at https://github.com/Trae1ounG/BuPO",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper proposes a novel RL paradigm for optimizing large language models, focusing on internal layer policies. While it touches on aspects of deep semantic understanding and real-time relevance optimization, its primary contribution is in the area of reinforcement learning and language models, which is somewhat related to the user's interests in Information Retrieval and NLP, but not directly aligned with their core research themes."
    },
    {
        "title": "MauBERT: Universal Phonetic Inductive Biases for Few-Shot Acoustic Units Discovery",
        "abstract": "This paper introduces MauBERT, a multilingual extension of HuBERT that leverages articulatory features for robust cross-lingual phonetic representation learning. We continue HuBERT pre-training with supervision based on a phonetic-to-articulatory feature mapping in 55 languages. Our models learn from multilingual data to predict articulatory features or phones, resulting in language-independent representations that capture multilingual phonetic properties. Through comprehensive ABX discriminability testing, we show MauBERT models produce more context-invariant representations than state-of-the-art multilingual self-supervised learning models. Additionally, the models effectively adapt to unseen languages and casual speech with minimal self-supervised fine-tuning (10 hours of speech). This establishes an effective approach for instilling linguistic inductive biases in self-supervised speech models.",
        "url": "http://arxiv.org/abs/2512.19612v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19612v1",
        "arxiv_id": "2512.19612v1",
        "authors": [
            "Angelo Ortiz Tandazo",
            "Manel Khentout",
            "Youssef Benchekroun",
            "Thomas Hueber",
            "Emmanuel Dupoux"
        ],
        "submitted": "2025-12-22 17:47:49",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on speech representation learning and phonetic properties, which is not directly related to Information Retrieval, Search technologies, or Natural Language Processing in the context of query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Kunnafonidilaw ka Cadeau: an ASR dataset of present-day Bambara",
        "abstract": "We present Kunkado, a 160-hour Bambara ASR dataset compiled from Malian radio archives to capture present-day spontaneous speech across a wide range of topics. It includes code-switching, disfluencies, background noise, and overlapping speakers that practical ASR systems encounter in real-world use. We finetuned Parakeet-based models on a 33.47-hour human-reviewed subset and apply pragmatic transcript normalization to reduce variability in number formatting, tags, and code-switching annotations. Evaluated on two real-world test sets, finetuning with Kunkado reduces WER from 44.47\\% to 37.12\\% on one and from 36.07\\% to 32.33\\% on the other. In human evaluation, the resulting model also outperforms a comparable system with the same architecture trained on 98 hours of cleaner, less realistic speech. We release the data and models to support robust ASR for predominantly oral languages.",
        "url": "http://arxiv.org/abs/2512.19400v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19400v1",
        "arxiv_id": "2512.19400v1",
        "authors": [
            "Yacouba Diarra",
            "Panga Azazia Kamate",
            "Nouhoum Souleymane Coulibaly",
            "Michael Leventhal"
        ],
        "submitted": "2025-12-22 13:52:33",
        "source": "arxiv",
        "comment": "7 pages, 2 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is unrelated to Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or the e-commerce domain. It focuses on Automatic Speech Recognition (ASR) for the Bambara language, which is outside the user's primary research interests."
    },
    {
        "title": "Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline",
        "abstract": "Prompt injection and jailbreaking attacks pose persistent security challenges to large language model (LLM)-based systems. We present an efficient and systematically evaluated defense architecture that mitigates these threats through a lightweight, multi-stage pipeline. Its core component is a semantic filter based on text normalization, TF-IDF representations, and a Linear SVM classifier. Despite its simplicity, this module achieves 93.4% accuracy and 96.5% specificity on held-out data, substantially reducing attack throughput while incurring negligible computational overhead.\n  Building on this efficient foundation, the full pipeline integrates complementary detection and mitigation mechanisms that operate at successive stages, providing strong robustness with minimal latency. In comparative experiments, our SVM-based configuration improves overall accuracy from 35.1% to 93.4% while reducing average time to completion from approximately 450s to 47s, yielding over 10 times lower latency than ShieldGemma. These results demonstrate that the proposed design simultaneously advances defensive precision and efficiency, addressing a core limitation of current model-based moderators.\n  Evaluation across a curated corpus of over 30,000 labeled prompts, including benign, jailbreak, and application-layer injections, confirms that staged, resource-efficient defenses can robustly secure modern LLM-driven applications.",
        "url": "http://arxiv.org/abs/2512.19011v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19011v1",
        "arxiv_id": "2512.19011v1",
        "authors": [
            "Akshaj Prashanth Rao",
            "Advait Singh",
            "Saumya Kumaar Saksena",
            "Dhruv Kumar"
        ],
        "submitted": "2025-12-22 04:00:35",
        "source": "arxiv",
        "comment": "Under Review",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on security challenges in large language model systems and proposes a defense architecture to mitigate jailbreaking attacks. Although it involves text normalization and TF-IDF representations, which are related to natural language processing, the primary topic is security and not directly aligned with the user's core research interests in information retrieval, search technologies, and query understanding."
    },
    {
        "title": "FASTRIC: Prompt Specification Language for Verifiable LLM Interactions",
        "abstract": "Large Language Models (LLMs) execute complex multi-turn interaction protocols but lack formal specifications to verify execution against designer intent. We introduce FASTRIC, a Prompt Specification Language that makes implicit Finite State Machines (FSMs) explicit in natural language prompts, enabling conformance verification through execution trace analysis. The LLM serves as intelligent execution agent: interpreting designer-encoded FSMs to execute specified behavioral roles. Unlike symbolic specification languages requiring parsers and compilers, FASTRIC leverages LLMs as unified infrastructure-simultaneously parser, interpreter, runtime environment, and development assistant. FASTRIC guides designers to articulate seven FSM elements (Final States, Agents, States, Triggers, Roles, Initial State, Constraints) structuring multi-turn interactions. Specification formality-ranging from implicit descriptions that frontier models infer to explicit step-by-step instructions for weaker models-serves as a design parameter. We introduce procedural conformance as verification metric measuring execution adherence to FSM specifications. Testing a 3-state kindergarten tutoring FSM across four formality levels and three model scales (14.7B, 685B, 1T+ parameters) reveals optimal specification formality is a function of model capacity. DeepSeek-V3.2 (685B) achieves perfect conformance (1.00) at L2-L4; ChatGPT-5 (~1T) peaks at L3 (0.90) before collapsing at L4 (0.39); Phi4 (14.7B) shows no stable optimum with high variance (SD=0.16-0.36). These findings reveal model-specific formality ranges-\"Goldilocks zones\"-where specifications provide sufficient structure without over-constraint, establishing Prompt Specification Engineering for creating verifiable interaction protocols, transforming multi-turn interaction design from heuristic art to systematic engineering with measurable procedural guarantees.",
        "url": "http://arxiv.org/abs/2512.18940v1",
        "pdf_url": "https://arxiv.org/pdf/2512.18940v1",
        "arxiv_id": "2512.18940v1",
        "authors": [
            "Wen-Long Jin"
        ],
        "submitted": "2025-12-22 01:19:50",
        "source": "arxiv",
        "comment": "13 pages, 3 figures. Supplementary materials at https://doi.org/10.17605/OSF.IO/PV6R3",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Large Language Models (LLMs) and their interactions, but it does not directly relate to Information Retrieval, Search technologies, or query understanding, which are core areas of your research interests. While it touches on natural language processing, the context is quite different from your background in e-commerce and IR."
    },
    {
        "title": "Diacritic Restoration for Low-Resource Indigenous Languages: Case Study with Bribri and Cook Islands Māori",
        "abstract": "We present experiments on diacritic restoration, a form of text normalization essential for natural language processing (NLP) tasks. Our study focuses on two extremely under-resourced languages: Bribri, a Chibchan language spoken in Costa Rica, and Cook Islands Māori, a Polynesian language spoken in the Cook Islands. Specifically, this paper: (i) compares algorithms for diacritics restoration in under-resourced languages, including tonal diacritics, (ii) examines the amount of data required to achieve target performance levels, (iii) contrasts results across varying resource conditions, and (iv) explores the related task of diacritic correction. We find that fine-tuned, character-level LLMs perform best, likely due to their ability to decompose complex characters into their UTF-8 byte representations. In contrast, massively multilingual models perform less effectively given our data constraints. Across all models, reliable performance begins to emerge with data budgets of around 10,000 words. Zero-shot approaches perform poorly in all cases. This study responds both to requests from the language communities and to broader NLP research questions concerning model performance and generalization in under-resourced contexts.",
        "url": "http://arxiv.org/abs/2512.19630v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19630v1",
        "arxiv_id": "2512.19630v1",
        "authors": [
            "Rolando Coto-Solano",
            "Daisy Li",
            "Manoela Teleginski Ferraz",
            "Olivia Sasse",
            "Cha Krupka",
            "Sharid Loáiciga",
            "Sally Akevai Tenamu Nicholas"
        ],
        "submitted": "2025-12-22 18:04:24",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing, as it focuses on diacritic restoration for low-resource indigenous languages. While it involves NLP tasks, the specific area of study is not aligned with your primary focus on deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Exploring the features used for summary evaluation by Human and GPT",
        "abstract": "Summary assessment involves evaluating how well a generated summary reflects the key ideas and meaning of the source text, requiring a deep understanding of the content. Large Language Models (LLMs) have been used to automate this process, acting as judges to evaluate summaries with respect to the original text. While previous research investigated the alignment between LLMs and Human responses, it is not yet well understood what properties or features are exploited by them when asked to evaluate based on a particular quality dimension, and there has not been much attention towards mapping between evaluation scores and metrics. In this paper, we address this issue and discover features aligned with Human and Generative Pre-trained Transformers (GPTs) responses by studying statistical and machine learning metrics. Furthermore, we show that instructing GPTs to employ metrics used by Human can improve their judgment and conforming them better with human responses.",
        "url": "http://arxiv.org/abs/2512.19620v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19620v1",
        "arxiv_id": "2512.19620v1",
        "authors": [
            "Zahra Sadeghi",
            "Evangelos Milios",
            "Frank Rudzicz"
        ],
        "submitted": "2025-12-22 17:54:49",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper explores the features used for summary evaluation by humans and GPT, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on summary evaluation and large language models is not a central match to the user's core research themes. The paper's connection to NLP and deep semantic understanding is a partial alignment."
    },
    {
        "title": "Algerian Dialect",
        "abstract": "We present Algerian Dialect, a large-scale sentiment-annotated dataset consisting of 45,000 YouTube comments written in Algerian Arabic dialect. The comments were collected from more than 30 Algerian press and media channels using the YouTube Data API. Each comment is manually annotated into one of five sentiment categories: very negative, negative, neutral, positive, and very positive. In addition to sentiment labels, the dataset includes rich metadata such as collection timestamps, like counts, video URLs, and annotation dates. This dataset addresses the scarcity of publicly available resources for Algerian dialect and aims to support research in sentiment analysis, dialectal Arabic NLP, and social media analytics. The dataset is publicly available on Mendeley Data under a CC BY 4.0 license at https://doi.org/10.17632/zzwg3nnhsz.2.",
        "url": "http://arxiv.org/abs/2512.19543v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19543v1",
        "arxiv_id": "2512.19543v1",
        "authors": [
            "Zakaria Benmounah",
            "Abdennour Boulesnane"
        ],
        "submitted": "2025-12-22 16:26:15",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on a sentiment-annotated dataset for Algerian Arabic dialect, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on NLP, it is more focused on dialectal Arabic and sentiment analysis, which does not align with the user's primary interests."
    },
    {
        "title": "MAGIC: Achieving Superior Model Merging via Magnitude Calibration",
        "abstract": "The proliferation of pre-trained models has given rise to a wide array of specialised, fine-tuned models. Model merging aims to merge the distinct capabilities of these specialised models into a unified model, requiring minimal or even no additional training. A core objective of model merging is to ensure the merged model retains the behavioural characteristics of the specialised models, typically achieved through feature alignment. We identify that features consist of two critical components: direction and magnitude. Prior research has predominantly focused on directional alignment, while the influence of magnitude remains largely neglected, despite its pronounced vulnerability to perturbations introduced by common merging operations (e.g., parameter fusion and sparsification). Such perturbations to magnitude inevitably lead to feature deviations in the merged model from the specialised models, resulting in subsequent performance degradation. To address this, we propose MAGnItude Calibration (MAGIC), a plug-and-play framework that rectifies layer-wise magnitudes in feature and weight spaces, with three variants. Specifically, our Feature Space Calibration (FSC) realigns the merged model's features using a small set of unlabelled data, while Weight Space Calibration (WSC) extends this calibration to the weight space without requiring additional data. Combining these yields Dual Space Calibration (DSC). Comprehensive experiments demonstrate that MAGIC consistently boosts performance across diverse Computer Vision tasks (+4.3% on eight datasets) and NLP tasks (+8.0% on Llama) without additional training. Our code is available at: https://github.com/lyymuwu/MAGIC",
        "url": "http://arxiv.org/abs/2512.19320v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19320v1",
        "arxiv_id": "2512.19320v1",
        "authors": [
            "Yayuan Li",
            "Jian Zhang",
            "Jintao Guo",
            "Zihan Cheng",
            "Lei Qi",
            "Yinghuan Shi",
            "Yang Gao"
        ],
        "submitted": "2025-12-22 12:13:17",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper discusses model merging and calibration, which is somewhat related to information retrieval and search technologies. However, the focus is on deep learning and model optimization, which is not a central match to the user's core research themes. The paper's relevance to the user's interests is limited to the potential application of model merging in search technologies, but the connection is not explicitly made."
    },
    {
        "title": "Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation",
        "abstract": "Large language models (LLMs) have been shown to exhibit social bias, however, bias towards non-protected stigmatized identities remain understudied. Furthermore, what social features of stigmas are associated with bias in LLM outputs is unknown. From psychology literature, it has been shown that stigmas contain six shared social features: aesthetics, concealability, course, disruptiveness, origin, and peril. In this study, we investigate if human and LLM ratings of the features of stigmas, along with prompt style and type of stigma, have effect on bias towards stigmatized groups in LLM outputs. We measure bias against 93 stigmatized groups across three widely used LLMs (Granite 3.0-8B, Llama-3.1-8B, Mistral-7B) using SocialStigmaQA, a benchmark that includes 37 social scenarios about stigmatized identities; for example deciding wether to recommend them for an internship. We find that stigmas rated by humans to be highly perilous (e.g., being a gang member or having HIV) have the most biased outputs from SocialStigmaQA prompts (60% of outputs from all models) while sociodemographic stigmas (e.g. Asian-American or old age) have the least amount of biased outputs (11%). We test if the amount of biased outputs could be decreased by using guardrail models, models meant to identify harmful input, using each LLM's respective guardrail model (Granite Guardian 3.0, Llama Guard 3.0, Mistral Moderation API). We find that bias decreases significantly by 10.4%, 1.4%, and 7.8%, respectively. However, we show that features with significant effect on bias remain unchanged post-mitigation and that guardrail models often fail to recognize the intent of bias in prompts. This work has implications for using LLMs in scenarios involving stigmatized groups and we suggest future work towards improving guardrail models for bias mitigation.",
        "url": "http://arxiv.org/abs/2512.19238v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19238v1",
        "arxiv_id": "2512.19238v1",
        "authors": [
            "Anna-Maria Gueorguieva",
            "Aylin Caliskan"
        ],
        "submitted": "2025-12-22 10:20:20",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on bias in language models and stigma mitigation, which is outside your primary areas of interest in Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models",
        "abstract": "Diffusion Large Language Models (DLLMs) enable fully parallel token decoding but often remain impractical at inference time due to the many denoising iterations required to refine an information-free, fully masked initialization into coherent text. Most existing acceleration methods focus on traversing this generative trajectory more efficiently via improved solvers or sampling strategies. We advance a complementary perspective: shorten the trajectory itself by starting closer to the target distribution through context-aware initialization.\n  We propose a training-free interface that injects prompt-conditioned priors from a lightweight auxiliary model into the diffusion initialization, and instantiate it with two mechanisms: discrete token injection and representation-level embedding interpolation. Because injected priors can be imperfect and unmask-only decoding can over-commit early, we also introduce a simple confidence-based remasking mechanism as a form of prior skepticism. Preliminary evidence on GSM8K suggests that context-aware initialization can substantially reduce denoising iterations (about 35\\% fewer function evaluations in our setting), while also exposing a key open challenge: naive warm-starting can degrade final accuracy relative to strong diffusion baselines. We use these findings to motivate a research agenda around calibration, revision mechanisms, and representation alignment for reliable warm-started diffusion decoding.",
        "url": "http://arxiv.org/abs/2512.19004v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19004v1",
        "arxiv_id": "2512.19004v1",
        "authors": [
            "Tongyuan Miao",
            "Gary Huang",
            "Kai Jun Han",
            "Annie Jiang"
        ],
        "submitted": "2025-12-22 03:45:04",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving diffusion language models, which is a topic in Natural Language Processing (NLP). However, it does not appear to be directly related to Information Retrieval (IR), query understanding, ranking models, or user behavior modeling, which are the core areas of your research interests."
    },
    {
        "title": "Merge on workspaces as Hopf algebra Markov chain",
        "abstract": "We study the dynamical properties of a Hopf algebra Markov chain with state space the binary rooted forests with labelled leaves. This Markovian dynamical system describes the core computational process of structure formation and transformation in syntax via the Merge operation, according to Chomsky's Minimalism model of generative linguistics. The dynamics decomposes into an ergodic dynamical system with uniform stationary distribution, given by the action of Internal Merge, while the contributions of External Merge and (a minimal form of) Sideward Merge reduce to a simpler Markov chain with state space the set of partitions and with combinatorial weights. The Sideward Merge part of the dynamics prevents convergence to fully formed connected structures (trees), unless the different forms of Merge are weighted by a cost function, as predicted by linguistic theory. Results on the asymptotic behavior of the Perron-Frobenius eigenvalue and eigenvector in this weighted case, obtained in terms of an associated Perron-Frobenius problem in the tropical semiring, show that the usual cost functions (Minimal Search and Resource Restrictions) proposed in the linguistic literature do not suffice to obtain convergence to the tree structures, while an additional optimization property based on the Shannon entropy achieves the expected result for the dynamics. We also comment on the introduction of continuous parameters related to semantic embedding and other computational models, and also on some filtering of the dynamics by coloring rules that model the linguistic filtering by theta roles and phase structure, and on parametric variation and the process of parameter setting in Externalization.",
        "url": "http://arxiv.org/abs/2512.18861v1",
        "pdf_url": "https://arxiv.org/pdf/2512.18861v1",
        "arxiv_id": "2512.18861v1",
        "authors": [
            "Matilde Marcolli",
            "David Skigin"
        ],
        "submitted": "2025-12-21 19:26:41",
        "source": "arxiv",
        "comment": "80 pages, LaTeX, 1 png figure",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper appears to be unrelated to Information Retrieval, Search technologies, or any of your core research themes. It focuses on a theoretical model of generative linguistics, specifically the Merge operation in syntax, and its dynamical properties. The paper's abstract does not mention any concepts or techniques relevant to your research interests."
    },
    {
        "title": "Toward Human-Centered AI-Assisted Terminology Work",
        "abstract": "The rapid diffusion of generative artificial intelligence is transforming terminology work. While this technology promises gains in efficiency, its unstructured adoption risks weakening professional autonomy, amplifying bias, and eroding linguistic and conceptual diversity. This paper argues that a human-centered approach to artificial intelligence has become a necessity for terminology work. Building on research in artificial intelligence and translation studies, it proposes a human-centered framework that conceptualizes artificial intelligence as a means of amplifying the terminologist's capabilities, rather than replacing them. The framework is organized around three interrelated dimensions: the augmented terminologist, ethical AI, and human-centered design. Together, these dimensions emphasize the compatibility of high automation with strong human control, the central role of terminologists in bias mitigation, and the importance of designing AI tools and workflows around the needs, values, and well-being of the terminologist. The paper concludes by stressing that current choices in AI adoption will shape not only terminological practice, but also the preservation of accuracy, adequacy, and diversity in terminology and specialized knowledge.",
        "url": "http://arxiv.org/abs/2512.18859v1",
        "pdf_url": "https://arxiv.org/pdf/2512.18859v1",
        "arxiv_id": "2512.18859v1",
        "authors": [
            "Antonio San Martin"
        ],
        "submitted": "2025-12-21 19:16:40",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on the human-centered approach to AI-assisted terminology work, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it touches on AI, it is more concerned with the social implications of AI adoption in terminology work, rather than its technical aspects or applications in search or e-commerce."
    }
]