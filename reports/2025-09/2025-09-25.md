# Daily Papers Report - 2025-09-25

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Learning Contextual Retrieval for Robust Conversational Search

- **LLM Score**: 9
- **Keyword Score**: 12
- **Authors**: Seunghan Yang, Juntae Lee, Jihwan Bang, Kyuhong Shim, Minsoo Kim, Simyung Chang
- **URL**: <http://arxiv.org/abs/2509.19700v1>
- **Submitted**: 2025-09-24 02:17:37
- **Comment**: EMNLP 2025 main conference
- **Topic Keywords**: retriever, query, queries, retrieval, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of query understanding and ranking models. The focus on conversational search and user intent modeling aligns with your background in e-commerce and interest in deep semantic understanding. The use of LLM-based retrievers and context-aware embedding mechanisms also relates to your work in NLP and related topics.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Conversational Search
- **Aim**: To develop a novel LLM-based conversational search retriever, ContextualRetriever, that overcomes limitations of existing methods in handling multi-turn dialogues with abbreviated queries and topic shifts.
- **Rationale**: Existing conversational search methods struggle with multi-turn dialogues due to challenges in understanding context, disambiguating user intent, and handling topic shifts.
- **Ground**: The research builds upon existing literature in natural language processing and information retrieval, particularly focusing on passage search, contextualized embeddings, large language models, and conversational search.
- **Experiment**: ContextualRetriever was evaluated on four conversational search benchmarks (TopiOCQA, QReCC, TREC-CAsT, and ORConvQA) using metrics like nDCG@3, Hit@5, Hit@100, and HIR@100.
- **Takeaway**: ContextualRetriever demonstrates significant performance improvements over existing methods, achieving state-of-the-art results on several benchmarks. Its key innovations include context-aware embedding, intent-guided supervision, and preservation of generative capabilities.

#### Abstract
> Effective conversational search demands a deep understanding of user intent
across multiple dialogue turns. Users frequently use abbreviations and shift
topics in the middle of conversations, posing challenges for conventional
retrievers. While query rewriting techniques improve clarity, they often incur
significant computational cost due to additional autoregressive steps.
Moreover, although LLM-based retrievers demonstrate strong performance, they
are not explicitly optimized to track user intent in multi-turn settings, often
failing under topic drift or contextual ambiguity. To address these
limitations, we propose ContextualRetriever, a novel LLM-based retriever that
directly incorporates conversational context into the retrieval process. Our
approach introduces: (1) a context-aware embedding mechanism that highlights
the current query within the dialogue history; (2) intent-guided supervision
based on high-quality rewritten queries; and (3) a training strategy that
preserves the generative capabilities of the base LLM. Extensive evaluations
across multiple conversational search benchmarks demonstrate that
ContextualRetriever significantly outperforms existing methods while incurring
no additional inference overhead.

---

### 2. Adaptive User Interest Modeling via Conditioned Denoising Diffusion For Click-Through Rate Prediction

- **LLM Score**: 9
- **Keyword Score**: 10
- **Authors**: Qihang Zhao, Xiaoyang Zheng, Ben Chen, Zhongbo Sun, Chenyi Lei
- **URL**: <http://arxiv.org/abs/2509.19876v1>
- **Submitted**: 2025-09-24 08:28:33
- **Comment**: 5 pages, under review
- **Topic Keywords**: query, user behavior, click, click-through rate, search
- **Reason**: This paper aligns closely with your research interests in Information Retrieval, particularly in query understanding and user behavior modeling. The focus on click-through rate prediction and adaptive user interest modeling using deep semantic understanding and real-time relevance optimization is highly relevant to your work.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Modeling User Interest in Search Systems
- **Aim**: Propose a novel method, Contextual Diffusion Purifier (CDP), to overcome limitations of traditional user interest modeling approaches.
- **Rationale**: Traditional methods using 'identify-aggregate' paradigms are static and struggle to account for noise in user behavior sequences.
- **Ground**: User behavior sequences are treated as 'contaminated observations' requiring denoising to reveal pure user interests.
- **Experiment**: Offline and online experiments, including an A/B test on an E-Commerce platform, demonstrate CDP's superiority in click-through rate prediction and other key metrics.
- **Takeaway**: CDP, utilizing a forward noising and conditional reverse denoising process guided by cross-interaction features, generates dynamic and context-aware user interest representations, outperforming existing methods.

#### Abstract
> User behavior sequences in search systems resemble "interest fossils",
capturing genuine intent yet eroded by exposure bias, category drift, and
contextual noise. Current methods predominantly follow an "identify-aggregate"
paradigm, assuming sequences immutably reflect user preferences while
overlooking the organic entanglement of noise and genuine interest. Moreover,
they output static, context-agnostic representations, failing to adapt to
dynamic intent shifts under varying Query-User-Item-Context conditions.
  To resolve this dual challenge, we propose the Contextual Diffusion Purifier
(CDP). By treating category-filtered behaviors as "contaminated observations",
CDP employs a forward noising and conditional reverse denoising process guided
by cross-interaction features (Query x User x Item x Context), controllably
generating pure, context-aware interest representations that dynamically evolve
with scenarios. Extensive offline/online experiments demonstrate the
superiority of CDP over state-of-the-art methods.

---

### 3. AIRwaves at CheckThat! 2025: Retrieving Scientific Sources for Implicit Claims on Social Media with Dual Encoders and Neural Re-Ranking

- **LLM Score**: 8
- **Keyword Score**: 12
- **Authors**: Cem Ashbaugh, Leon Baumg√§rtner, Tim Gress, Nikita Sidorov, Daniel Werner
- **URL**: <http://arxiv.org/abs/2509.19509v1>
- **Submitted**: 2025-09-23 19:26:31
- **Comment**: CLEF 2025 (Conference and Labs of the Evaluation Forum)
- **Topic Keywords**: dense retrieval, queries, ranking, retrieval, rank
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the areas of query understanding and ranking models. The use of dual encoders and neural re-ranking for tweet-to-study matching aligns with your focus on deep semantic understanding and real-time relevance optimization. However, the specific domain of scientific sources on social media is somewhat niche compared to your broader interests in e-commerce and general IR.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Scientific claim source retrieval from tweets
- **Aim**: Develop a novel system, AIRwaves, to retrieve scientific publications corresponding to implicit scientific claims expressed in tweets.
- **Rationale**: Addressing challenges of lexical sparsity, query brevity, and domain specificity in scientific claim source retrieval.
- **Ground**: Leveraging pretrained language models, domain-specific fine-tuning, and neural re-ranking techniques.
- **Experiment**: Two-stage retrieval pipeline: (1) Dual encoder retrieval with E5-large model and document metadata, (2) Neural re-ranking with SciBERT.
- **Takeaway**: AIRwaves achieved 2nd place in CheckThat! 2025 Task 4b, outperforming the optimized sparse-retrieval baseline (BM25) by a significant margin.

#### Abstract
> Linking implicit scientific claims made on social media to their original
publications is crucial for evidence-based fact-checking and scholarly
discourse, yet it is hindered by lexical sparsity, very short queries, and
domain-specific language. Team AIRwaves ranked second in Subtask 4b of the
CLEF-2025 CheckThat! Lab with an evidence-retrieval approach that markedly
outperforms the competition baseline. The optimized sparse-retrieval
baseline(BM25) achieves MRR@5 = 0.5025 on the gold label blind test set. To
surpass this baseline, a two-stage retrieval pipeline is introduced: (i) a
first stage that uses a dual encoder based on E5-large, fine-tuned using
in-batch and mined hard negatives and enhanced through chunked tokenization and
rich document metadata; and (ii) a neural re-ranking stage using a SciBERT
cross-encoder. Replacing purely lexical matching with neural representations
lifts performance to MRR@5 = 0.6174, and the complete pipeline further improves
to MRR@5 = 0.6828. The findings demonstrate that coupling dense retrieval with
neural re-rankers delivers a powerful and efficient solution for tweet-to-study
matching and provides a practical blueprint for future evidence-retrieval
pipelines.

---

### 4. FusedANN: Convexified Hybrid ANN via Attribute-Vector Fusion

- **LLM Score**: 8
- **Keyword Score**: 11
- **Authors**: Alireza Heidari, Wei Zhang, Ying Xiong
- **URL**: <http://arxiv.org/abs/2509.19767v1>
- **Submitted**: 2025-09-24 05:33:53
- **Comment**: 62 pages,12 figures
- **Topic Keywords**: query, queries, rag, retrieval, search
- **Reason**: This paper introduces FusedANN, a geometric framework that combines vector similarity with attribute filters, which is relevant to your interests in Information Retrieval, particularly in areas that require deep semantic understanding and real-time relevance optimization. The paper's focus on hybrid queries and efficient approximate search aligns with your background in e-commerce and experience with query understanding and ranking models. However, the paper's primary focus on vector search and attribute filtering is somewhat different from your primary focus on information retrieval.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Hybrid Vector Search
- **Aim**: Introduce FusedANN, a novel geometric framework for hybrid vector search that combines vector similarity with attribute filters.
- **Rationale**: Existing solutions rely on fragile index hacks and sacrifice recall, speed, or flexibility.
- **Ground**: FusedANN creates a convex fused space by embedding attributes and vectors jointly through a transformer-based convexification process.
- **Experiment**: FusedANN demonstrates significant improvements in query throughput and superior recall-latency tradeoffs on standard hybrid benchmarks compared to existing hybrid and graph-based systems.
- **Takeaway**: FusedANN establishes a principled, scalable, and verifiable bridge between symbolic constraints (attribute filters) and vector similarity, paving the way for more powerful and flexible retrieval systems in NLP/ML.

#### Abstract
> Vector search powers transformers technology, but real-world use demands
hybrid queries that combine vector similarity with attribute filters (e.g.,
"top document in category X, from 2023"). Current solutions trade off recall,
speed, and flexibility, relying on fragile index hacks that don't scale. We
introduce FusedANN (Fused Attribute-Vector Nearest Neighbor), a geometric
framework that elevates filtering to ANN optimization constraints and
introduces a convex fused space via a Lagrangian-like relaxation. Our method
jointly embeds attributes and vectors through transformer-based
convexification, turning hard filters into continuous, weighted penalties that
preserve top-k semantics while enabling efficient approximate search. We prove
that FusedANN reduces to exact filtering under high selectivity, gracefully
relaxes to semantically nearest attributes when exact matches are insufficient,
and preserves downstream ANN alpha-approximation guarantees. Empirically,
FusedANN improves query throughput by eliminating brittle filtering stages,
achieving superior recall-latency tradeoffs on standard hybrid benchmarks
without specialized index hacks, delivering up to 3 times higher throughput and
better recall than state-of-the-art hybrid and graph-based systems.
Theoretically, we provide explicit error bounds and parameter selection rules
that make FusedANN practical for production. This establishes a principled,
scalable, and verifiable bridge between symbolic constraints and vector
similarity, unlocking a new generation of filtered retrieval systems for large,
hybrid, and dynamic NLP/ML workloads.

---

### 5. GuessingGame: Measuring the Informativeness of Open-Ended Questions in Large Language Models

- **LLM Score**: 6
- **Keyword Score**: 5
- **Authors**: Dylan Hutson, Daniel Vennemeyer, Aneesh Deshmukh, Justin Zhan, Tianyu Jiang
- **URL**: <http://arxiv.org/abs/2509.19593v1>
- **Submitted**: 2025-09-23 21:31:14
- **Comment**: EMNLP 2025, 17 pages, 2 figures
- **Topic Keywords**: relevance, acl
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the area of query understanding and ranking models. However, it focuses on evaluating large language models as question-askers, which is a different aspect of IR. While it touches on the idea of relevance optimization, it's more centered on question-asking strategies and model evaluation.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Evaluating strategic question-asking abilities of Large Language Models (LLMs) in open-domain settings
- **Aim**: Introduce GuessingGame, a novel framework to assess LLMs' ability to identify hidden objects through strategic question-asking.
- **Rationale**: Existing methods for evaluating question-asking abilities in LLMs are limited to closed-domain settings or predefined question types. GuessingGame provides a more comprehensive and realistic evaluation in open-domain scenarios.
- **Ground**: GuessingGame involves a 'Guesser' LLM attempting to identify a hidden 'object' by asking questions to an 'Oracle' LLM. The game is open-ended, with no predefined choices or candidate lists.
- **Experiment**: The framework is evaluated using two information gain (IG) metrics: Bayesian Belief Tracking and ConceptNet-Based Entropy Reduction.  The performance of various LLMs, including LLaMA-3.3 70B, GPT-4o, and Gemini 2.0 Flash-Lite, is compared across different question types and prompting strategies.
- **Takeaway**: Open-ended questions and attribute-based queries are most effective for object identification.  Prompting strategies that encourage question diversity and open-endedness significantly improve LLM performance. The framework provides a valuable tool for evaluating and improving the strategic question-asking abilities of LLMs.

#### Abstract
> We introduce GuessingGame, a protocol for evaluating large language models
(LLMs) as strategic question-askers in open-ended, open-domain settings. A
Guesser LLM identifies a hidden object by posing free-form questions to an
Oracle without predefined choices or candidate lists. To measure question
quality, we propose two information gain (IG) metrics: a Bayesian method that
tracks belief updates over semantic concepts using LLM-scored relevance, and an
entropy-based method that filters candidates via ConceptNet. Both metrics are
model-agnostic and support post hoc analysis. Across 858 games with multiple
models and prompting strategies, higher IG strongly predicts efficiency: a
one-standard-deviation IG increase reduces expected game length by 43\%.
Prompting constraints guided by IG, such as enforcing question diversity,
enable weaker models to significantly improve performance. These results show
that question-asking in LLMs is both measurable and improvable, and crucial for
interactive reasoning.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. UserRL: Training Interactive User-Centric Agent via Reinforcement Learning

- **LLM Score**: 6
- **Keyword Score**: 1
- **Authors**: Cheng Qian, Zuxin Liu, Akshara Prabhakar, Jielin Qiu, Zhiwei Liu, Haolin Chen, Shirley Kokane, Heng Ji, Weiran Yao, Shelby Heinecke, Silvio Savarese, Caiming Xiong, Huan Wang
- **URL**: <http://arxiv.org/abs/2509.19736v1>
- **Submitted**: 2025-09-24 03:33:20
- **Comment**: 28 Pages, 15 Figures, 6 Tables; Built upon latest UserBench release:
  arXiv:2507.22034
- **Topic Keywords**: search
- **Reason**: This paper explores the application of reinforcement learning in developing user-centric agentic models, which is somewhat related to query understanding and user behavior modeling in Information Retrieval. However, the focus on interactive dialogue and simulated users is not directly aligned with the user's primary research interests in IR and NLP. The paper's emphasis on model scale and reward shaping is also relevant to the broader field of AI, but not a central match for the user's research themes.

#### Abstract
> Reinforcement learning (RL) has shown promise in training agentic models that
move beyond static benchmarks to engage in dynamic, multi-turn interactions.
Yet, the ultimate value of such agents lies in their ability to assist users, a
setting where diversity and dynamics of user interaction pose challenges. In
this work, we propose UserRL, a unified framework for training and evaluating
user-centric abilities through standardized gym environments paired with
simulated users. We systematically vary turn-level reward assignment and
trajectory-level score calculation to analyze how different formulations affect
learning under the GRPO algorithm. Our experiments across Qwen3 models reveal
three key findings: (i) SFT cold start is critical for unlocking initial
interaction ability and enabling sustained RL improvements; (ii) deliberate
trajectory scoring yields more efficient and effective multi-turn interactions;
and (iii) while stronger simulated users (e.g., GPT-4o) facilitates training,
open-source simulators (e.g., Qwen3-32B) remain a cost-effective and
transferable option. Together, these results highlight that careful design of
reward shaping and user simulation choice is as crucial as model scale, and
establish UserRL as a practical pathway for developing robust user-centric
agentic models. All codes and data are public for future research.

### 7. Into the Void: Understanding Online Health Information in Low-Web Data Languages

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Hellina Hailu Nigatu, Nuredin Ali Abdelkadir, Fiker Tewelde, Stevie Chancellor, Daricia Wilkinson
- **URL**: <http://arxiv.org/abs/2509.20245v1>
- **Submitted**: 2025-09-24 15:35:01
- **Comment**: Accepted to AIES 2025
- **Topic Keywords**: queries, relevance, search
- **Reason**: This paper explores the challenges of online health information seeking in low-web data languages, particularly on social media platforms. While it touches on search technologies and algorithmic failures, its primary focus is on the phenomenon of data horizons and informational instability, which is somewhat related to the user's interests in Information Retrieval and Natural Language Processing.

#### Abstract
> Data voids--areas of the internet where reliable information is scarce or
absent--pose significant challenges to online health information seeking,
particularly for users operating in low-web data languages. These voids are
increasingly encountered not on traditional search engines alone, but on social
media platforms, which have gradually morphed into informal search engines for
millions of people. In this paper, we introduce the phenomenon of data
horizons: a critical boundary where algorithmic structures begin to degrade the
relevance and reliability of search results. Unlike the core of a data void,
which is often exploited by bad actors to spread misinformation, the data
horizon marks the critical space where systemic factors, such as linguistic
underrepresentation, algorithmic amplification, and socio-cultural mismatch,
create conditions of informational instability. Focusing on Tigrinya and
Amharic as languages of study, we evaluate (1) the common characteristics of
search results for health queries, (2) the quality and credibility of health
information, and (3) characteristics of search results that diverge from their
queries. We find that search results for health queries in low-web data
languages may not always be in the language of search and may be dominated by
nutritional and religious advice. We show that search results that diverge from
their queries in low-resourced languages are due to algorithmic failures,
(un)intentional manipulation, or active manipulation by content creators. We
use our findings to illustrate how a data horizon manifests under several
interacting constraints on information availability.

### 8. STARQA: A Question Answering Dataset for Complex Analytical Reasoning over Structured Databases

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Mounica Maddela, Lingjue Xie, Daniel Preotiuc-Pietro, Mausam
- **URL**: <http://arxiv.org/abs/2509.19508v1>
- **Submitted**: 2025-09-23 19:26:16
- **Comment**: Accepted to EMNLP 2025 long paper
- **Topic Keywords**: query, queries
- **Reason**: This paper introduces a new dataset for question answering over structured databases, which is somewhat related to information retrieval, particularly query understanding and ranking models. However, its focus on semantic parsing and text-to-SQL conversion is more aligned with natural language processing and data mining. While it touches on the idea of complex analytical reasoning, it doesn't directly address user behavior modeling or real-time relevance optimization, which are core aspects of your research interests.

#### Abstract
> Semantic parsing methods for converting text to SQL queries enable question
answering over structured data and can greatly benefit analysts who routinely
perform complex analytics on vast data stored in specialized relational
databases. Although several benchmarks measure the abilities of text to SQL,
the complexity of their questions is inherently limited by the level of
expressiveness in query languages and none focus explicitly on questions
involving complex analytical reasoning which require operations such as
calculations over aggregate analytics, time series analysis or scenario
understanding. In this paper, we introduce STARQA, the first public
human-created dataset of complex analytical reasoning questions and answers on
three specialized-domain databases. In addition to generating SQL directly
using LLMs, we evaluate a novel approach (Text2SQLCode) that decomposes the
task into a combination of SQL and Python: SQL is responsible for data
fetching, and Python more naturally performs reasoning. Our results demonstrate
that identifying and combining the abilities of SQL and Python is beneficial
compared to using SQL alone, yet the dataset still remains quite challenging
for the existing state-of-the-art LLMs.

### 9. A Pipeline to Assess Merging Methods via Behavior and Internals

- **LLM Score**: 4
- **Keyword Score**: 6
- **Authors**: Yutaro Sigris, Andreas Waldis
- **URL**: <http://arxiv.org/abs/2509.19476v1>
- **Submitted**: 2025-09-23 18:37:32
- **Comment**: BlackboxNLP
- **Topic Keywords**: ranking, rag, rank
- **Reason**: The paper discusses model merging methods in the context of language models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on language models and their internal workings is not directly aligned with the user's primary research interests in IR and Search technologies. The connection to user behavior modeling is also indirect, as the paper primarily evaluates model performance rather than user behavior.

#### Abstract
> Merging methods combine the weights of multiple language models (LMs) to
leverage their capacities, such as for domain adaptation. While existing
studies investigate merged models from a solely behavioral perspective, we
offer the first comprehensive view by assessing and connecting their behavior
and internals. We present a novel evaluation pipeline that first merges
multiple parent LMs, and then evaluates the merged models in comparison to the
initial ones based on their behavior on downstream tasks, like MMLU, and the
internal encoded linguistic competence. We showcase this pipeline by assessing
the merging of instruction fine-tuned with math- and code-adapted LMs from the
Qwen2.5 family. Our results show that merging methods impacts behavior and
internals differently. While the performance of merged models is typically
between that of the two parent models, their encoded information about
linguistic phenomena, particularly in morphology and syntax, can surpass the
parent models. Moreover, we find weak ranking correlation between this behavior
and internal evaluation. With our pipeline and initial results, we emphasize
the need for more comprehensive evaluations of model merging methods to gain a
faithful understanding of their capabilities and reliability, beyond potential
superficial behavioral advances.

### 10. Documentation Retrieval Improves Planning Language Generation

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Renxiang Wang, Li Zhang
- **URL**: <http://arxiv.org/abs/2509.19931v1>
- **Submitted**: 2025-09-24 09:38:48
- **Comment**: 12 pages, 14 figures, 1 table
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper explores the application of documentation retrieval in planning language generation, which is somewhat related to information retrieval and NLP. However, the focus on planning language generation and formal planning is not directly aligned with the user's core research themes in query understanding, ranking models, and user behavior modeling. While it touches on deep semantic understanding, the context is different from the user's primary interests.

#### Abstract
> Certain strong LLMs have shown promise for zero-shot formal planning by
generating planning languages like PDDL. Yet, performance of most open-source
models under 50B parameters has been reported to be close to zero due to the
low-resource nature of these languages. We significantly improve their
performance via a series of lightweight pipelines that integrates documentation
retrieval with modular code generation and error refinement. With models like
Llama-4-Maverick, our best pipeline improves plan correctness from 0\% to over
80\% on the common BlocksWorld domain. However, while syntactic errors are
substantially reduced, semantic errors persist in more challenging domains,
revealing fundamental limitations in current models' reasoning
capabilities.\footnote{Our code and data can be found at
https://github.com/Nangxxxxx/PDDL-RAG

### 11. Polarity Detection of Sustainable Detection Goals in News Text

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Andrea Cadeddu, Alessandro Chessa, Vincenzo De Leo, Gianni Fenu, Francesco Osborne, Diego Reforgiato Recupero, Angelo Salatino, Luca Secchi
- **URL**: <http://arxiv.org/abs/2509.19833v2>
- **Submitted**: 2025-09-24 07:23:44
- **Comment**: Updated as one author was mispelled
- **Topic Keywords**: relevance, search
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and related topics. However, it focuses on a specific task (SDG polarity detection) and domain (sustainability monitoring), which is not central to your core research themes in Information Retrieval and Search technologies.

#### Abstract
> The United Nations' Sustainable Development Goals (SDGs) provide a globally
recognised framework for addressing critical societal, environmental, and
economic challenges. Recent developments in natural language processing (NLP)
and large language models (LLMs) have facilitated the automatic classification
of textual data according to their relevance to specific SDGs. Nevertheless, in
many applications, it is equally important to determine the directionality of
this relevance; that is, to assess whether the described impact is positive,
neutral, or negative. To tackle this challenge, we propose the novel task of
SDG polarity detection, which assesses whether a text segment indicates
progress toward a specific SDG or conveys an intention to achieve such
progress. To support research in this area, we introduce SDG-POD, a benchmark
dataset designed specifically for this task, combining original and
synthetically generated data. We perform a comprehensive evaluation using six
state-of-the-art large LLMs, considering both zero-shot and fine-tuned
configurations. Our results suggest that the task remains challenging for the
current generation of LLMs. Nevertheless, some fine-tuned models, particularly
QWQ-32B, achieve good performance, especially on specific Sustainable
Development Goals such as SDG-9 (Industry, Innovation and Infrastructure),
SDG-12 (Responsible Consumption and Production), and SDG-15 (Life on Land).
Furthermore, we demonstrate that augmenting the fine-tuning dataset with
synthetically generated examples yields improved model performance on this
task. This result highlights the effectiveness of data enrichment techniques in
addressing the challenges of this resource-constrained domain. This work
advances the methodological toolkit for sustainability monitoring and provides
actionable insights into the development of efficient, high-performing polarity
detection systems.

### 12. Intelligent Algorithm Selection for Recommender Systems: Meta-Learning via in-depth algorithm feature engineering

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Jarne Mathi Decker
- **URL**: <http://arxiv.org/abs/2509.20134v1>
- **Submitted**: 2025-09-24 14:00:37
- **Topic Keywords**: rag, recommend
- **Reason**: The paper is somewhat related to the user's interests in recommender systems, but it focuses on algorithm selection and meta-learning, which is not a central match to the user's primary focus on information retrieval and query understanding. The paper's emphasis on recommender systems and algorithm features also diverges from the user's background in e-commerce and interest in deep semantic understanding.

#### Abstract
> The "No Free Lunch" theorem dictates that no single recommender algorithm is
optimal for all users, creating a significant Algorithm Selection Problem.
Standard meta-learning approaches aim to solve this by selecting an algorithm
based on user features, but treat the fundamentally diverse algorithms
themselves as equivalent, "black-box" choices. This thesis investigates the
impact of overcoming this limitation by engineering a comprehensive feature set
to explicitly characterize the algorithms themselves. We combine static code
metrics, Abstract Syntax Tree properties, behavioral performance landmarks, and
high-level conceptual features. We evaluate two meta-learners across five
datasets: a baseline using only user features and our proposed model using both
user and algorithm features. Our results show that the meta-learner augmented
with algorithm features achieves an average NDCG@10 of 0.143, a statistically
significant improvement of 11.7% over the Single Best Algorithm baseline
(0.128). However, we found that the inclusion of algorithm features did not
lead to an improvement in overall NDCG@10 over the meta learner using only user
features (0.144). While adding algorithm features to the meta-learner did
improve its Top-1 selection accuracy (+16.1%), this was counterbalanced by
leading to a lower Top-3 accuracy (-10.7%). We conclude that for the per-user
algorithm selection task in recommender systems, the predictive power of user
features is overwhelmingly dominant. While algorithm features improve selection
precision, unlocking their potential to boost overall performance remains a
non-trivial challenge.

### 13. Do Before You Judge: Self-Reference as a Pathway to Better LLM Evaluation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Wei-Hsiang Lin, Sheng-Lun Wei, Hen-Hsen Huang, Hsin-Hsi Chen
- **URL**: <http://arxiv.org/abs/2509.19880v1>
- **Submitted**: 2025-09-24 08:32:45
- **Comment**: Accepted as a long findings paper at EMNLP 2025
- **Topic Keywords**: rag, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of evaluating AI models. However, the focus on Large Language Models (LLMs) and their evaluation strategies is not directly aligned with your core interests in query understanding, ranking models, and user behavior modeling. While it touches on the broader topic of AI evaluation, it does not appear to be a central match for your research themes.

#### Abstract
> LLM-as-Judge frameworks are increasingly popular for AI evaluation, yet
research findings on the relationship between models' generation and judgment
abilities remain inconsistent. We investigate this relationship through
systematic dataset- and instance-level analyses across 11 models and 21 diverse
tasks. Despite both capabilities relying on the same underlying knowledge, our
analyses reveal they are only weakly correlated, primarily due to LLMs'
sensitivity to the responses being judged. To address this, we propose a
self-reference-guided evaluation strategy that leverages a model's own answers
as references. This approach significantly strengthens the correlation between
generation and judgment abilities, offering a practical path to align these
skills and providing a reliable proxy for model selection in evaluation tasks.

### 14. Instruction Boundary: Quantifying Biases in LLM Reasoning under Various Coverage

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Zipeng Ling, Yuehao Tang, Chen Huang, Shuliang Liu, Gaoyang Jiang, Shenghong Fu, Junqi Yang, Yao Wan, Jiawan Zhang, Kejia Huang, Xuming Hu
- **URL**: <http://arxiv.org/abs/2509.20278v1>
- **Submitted**: 2025-09-24 16:15:26
- **Topic Keywords**: rag
- **Reason**: This paper explores the limitations of Large-language-model (LLM) reasoning, specifically the Instruction Boundary phenomenon, which is related to query understanding and user behavior modeling in Information Retrieval. However, the focus on LLMs and their biases in reasoning is somewhat tangential to the user's primary interests in IR, ranking models, and deep semantic understanding.

#### Abstract
> Large-language-model (LLM) reasoning has long been regarded as a powerful
tool for problem solving across domains, providing non-experts with valuable
advice. However, their limitations - especially those stemming from prompt
design - remain underexplored. Because users may supply biased or incomplete
prompts - often unintentionally - LLMs can be misled, undermining reliability
and creating risks. We refer to this vulnerability as the Instruction Boundary.
To investigate the phenomenon, we distill it into eight concrete facets and
introduce BiasDetector, a framework that measures biases arising from three
instruction types: complete, redundant, and insufficient. We evaluate several
mainstream LLMs and find that, despite high headline accuracy, substantial
biases persist in many downstream tasks as a direct consequence of prompt
coverage. Our empirical study confirms that LLM reasoning reliability can still
be significantly improved. We analyze the practical impact of these biases and
outline mitigation strategies. Our findings underscore the need for developers
to tackle biases and for users to craft options carefully.

### 15. Tokenization and Representation Biases in Multilingual Models on Dialectal NLP Tasks

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Vani Kanjirangat, Tanja Samard≈æiƒá, Ljiljana Dolamic, Fabio Rinaldi
- **URL**: <http://arxiv.org/abs/2509.20045v1>
- **Submitted**: 2025-09-24 12:13:53
- **Comment**: Accepted in EMNLP-2025 Main conference
- **Topic Keywords**: rag
- **Reason**: The paper explores tokenization and representation biases in multilingual models, which is somewhat related to the user's interests in Natural Language Processing (NLP) and deep semantic understanding. However, the focus on dialectal NLP tasks and language support claims is not directly aligned with the user's primary focus on information retrieval and query understanding.

#### Abstract
> Dialectal data are characterized by linguistic variation that appears small
to humans but has a significant impact on the performance of models. This
dialect gap has been related to various factors (e.g., data size, economic and
social factors) whose impact, however, turns out to be inconsistent. In this
work, we investigate factors impacting the model performance more directly: we
correlate Tokenization Parity (TP) and Information Parity (IP), as measures of
representational biases in pre-trained multilingual models, with the downstream
performance. We compare state-of-the-art decoder-only LLMs with encoder-based
models across three tasks: dialect classification, topic classification, and
extractive question answering, controlling for varying scripts (Latin vs.
non-Latin) and resource availability (high vs. low). Our analysis reveals that
TP is a better predictor of the performance on tasks reliant on syntactic and
morphological cues (e.g., extractive QA), while IP better predicts performance
in semantic tasks (e.g., topic classification). Complementary analyses,
including tokenizer behavior, vocabulary coverage, and qualitative insights,
reveal that the language support claims of LLMs often might mask deeper
mismatches at the script or token level.

### 16. EmbeddingGemma: Powerful and Lightweight Text Representations

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Henrique Schechter Vera, Sahil Dua, Biao Zhang, Daniel Salz, Ryan Mullins, Sindhu Raghuram Panyam, Sara Smoot, Iftekhar Naim, Joe Zou, Feiyang Chen, Daniel Cer, Alice Lisak, Min Choi, Lucas Gonzalez, Omar Sanseviero, Glenn Cameron, Ian Ballantyne, Kat Black, Kaifeng Chen, Weiyi Wang, Zhe Li, Gus Martins, Jinhyuk Lee, Mark Sherwood, Juyeong Ji, Renjie Wu, Jingxiao Zheng, Jyotinder Singh, Abheesht Sharma, Divya Sreepat, Aashi Jain, Adham Elarabawy, AJ Co, Andreas Doumanoglou, Babak Samari, Ben Hora, Brian Potetz, Dahun Kim, Enrique Alfonseca, Fedor Moiseev, Feng Han, Frank Palma Gomez, Gustavo Hern√°ndez √Åbrego, Hesen Zhang, Hui Hui, Jay Han, Karan Gill, Ke Chen, Koert Chen, Madhuri Shanbhogue, Michael Boratko, Paul Suganthan, Sai Meher Karthik Duddu, Sandeep Mariserla, Setareh Ariafar, Shanfeng Zhang, Shijie Zhang, Simon Baumgartner, Sonam Goenka, Steve Qiu, Tanmaya Dabral, Trevor Walker, Vikram Rao, Waleed Khawaja, Wenlei Zhou, Xiaoqi Ren, Ye Xia, Yichang Chen, Yi-Ting Chen, Zhe Dong, Zhongli Ding, Francesco Visin, Ga√´l Liu, Jiageng Zhang, Kathleen Kenealy, Michelle Casbon, Ravin Kumar, Thomas Mesnard, Zach Gleicher, Cormac Brick, Olivier Lacombe, Adam Roberts, Yunhsuan Sung, Raphael Hoffmann, Tris Warkentin, Armand Joulin, Tom Duerig, Mojtaba Seyedhosseini
- **URL**: <http://arxiv.org/abs/2509.20354v1>
- **Submitted**: 2025-09-24 17:56:51
- **Comment**: 18 pages. Models are available in HuggingFace (at
  https://huggingface.co/collections/google/embeddinggemma-68b9ae3a72a82f0562a80dc4),
  Kaggle (at https://www.kaggle.com/models/google/embeddinggemma/), and Vertex
  AI (at
  https://pantheon.corp.google.com/vertex-ai/publishers/google/model-garden/embeddinggemma)
- **Topic Keywords**: search
- **Reason**: This paper introduces a new text embedding model, EmbeddingGemma, which achieves state-of-the-art results on the Massive Text Embedding Benchmark. While it has implications for information retrieval and NLP, its primary focus is on text representation and model efficiency, which is somewhat related to your research interests in query understanding and ranking models, but not a central match.

#### Abstract
> We introduce EmbeddingGemma, a new lightweight, open text embedding model
based on the Gemma 3 language model family. Our innovative training recipe
strategically captures knowledge from larger models via encoder-decoder
initialization and geometric embedding distillation. We improve model
robustness and expressiveness with a spread-out regularizer, and ensure
generalizability by merging checkpoints from varied, optimized mixtures.
Evaluated on the Massive Text Embedding Benchmark (MTEB) across multilingual,
English, and code domains, EmbeddingGemma (300M) achieves state-of-the-art
results. Notably, it outperforms prior top models, both proprietary and open,
with fewer than 500M parameters, and provides performance comparable to models
double its size, offering an exceptional performance-to-cost ratio. Remarkably,
this lead persists when quantizing model weights or truncating embedding
outputs. This makes EmbeddingGemma particularly well-suited for low-latency and
high-throughput use cases such as on-device applications. We provide ablation
studies exploring our key design choices. We release EmbeddingGemma to the
community to promote further research.

### 17. DRES: Benchmarking LLMs for Disfluency Removal

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Maria Teleki, Sai Janjur, Haoran Liu, Oliver Grabner, Ketan Verma, Thomas Docog, Xiangjue Dong, Lingfeng Shi, Cong Wang, Stephanie Birkelbach, Jason Kim, Yin Zhang, James Caverlee
- **URL**: <http://arxiv.org/abs/2509.20321v1>
- **Submitted**: 2025-09-24 17:08:12
- **Topic Keywords**: recommend
- **Reason**: The paper focuses on disfluency removal in speech-driven systems, which is related to query understanding and natural language processing, but it does not directly align with the user's primary interests in information retrieval, ranking models, and user behavior modeling.

#### Abstract
> Disfluencies -- such as "um," "uh," interjections, parentheticals, and edited
statements -- remain a persistent challenge for speech-driven systems,
degrading accuracy in command interpretation, summarization, and conversational
agents. We introduce DRES (Disfluency Removal Evaluation Suite), a controlled
text-level benchmark that establishes a reproducible semantic upper bound for
this task. DRES builds on human-annotated Switchboard transcripts, isolating
disfluency removal from ASR errors and acoustic variability. We systematically
evaluate proprietary and open-source LLMs across scales, prompting strategies,
and architectures. Our results reveal that (i) simple segmentation consistently
improves performance, even for long-context models; (ii) reasoning-oriented
models tend to over-delete fluent tokens; and (iii) fine-tuning achieves near
state-of-the-art precision and recall but harms generalization abilities. We
further present a set of LLM-specific error modes and offer nine practical
recommendations (R1-R9) for deploying disfluency removal in speech-driven
pipelines. DRES provides a reproducible, model-agnostic foundation for
advancing robust spoken-language systems.

### 18. Multimodal Representation-disentangled Information Bottleneck for Multimodal Recommendation

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Hui Wang, Jinghui Qin, Wushao Wen, Qingling Li, Shanshan Zhong, Zhongzhan Huang
- **URL**: <http://arxiv.org/abs/2509.20225v1>
- **Submitted**: 2025-09-24 15:18:32
- **Topic Keywords**: recommend
- **Reason**: The paper focuses on multimodal recommendation systems, which is somewhat related to information retrieval, but it primarily deals with recommendation systems, not search technologies. The use of information bottleneck and disentangled representations is relevant to query understanding and ranking models, but the application is in a different domain. The paper's emphasis on real-time relevance optimization is also somewhat relevant, but it's not the primary focus of the paper.

#### Abstract
> Multimodal data has significantly advanced recommendation systems by
integrating diverse information sources to model user preferences and item
characteristics. However, these systems often struggle with redundant and
irrelevant information, which can degrade performance. Most existing methods
either fuse multimodal information directly or use rigid architectural
separation for disentanglement, failing to adequately filter noise and model
the complex interplay between modalities. To address these challenges, we
propose a novel framework, the Multimodal Representation-disentangled
Information Bottleneck (MRdIB). Concretely, we first employ a Multimodal
Information Bottleneck to compress the input representations, effectively
filtering out task-irrelevant noise while preserving rich semantic information.
Then, we decompose the information based on its relationship with the
recommendation target into unique, redundant, and synergistic components. We
achieve this decomposition with a series of constraints: a unique information
learning objective to preserve modality-unique signals, a redundant information
learning objective to minimize overlap, and a synergistic information learning
objective to capture emergent information. By optimizing these objectives,
MRdIB guides a model to learn more powerful and disentangled representations.
Extensive experiments on several competitive models and three benchmark
datasets demonstrate the effectiveness and versatility of our MRdIB in
enhancing multimodal recommendation.

### 19. SINAI at eRisk@CLEF 2025: Transformer-Based and Conversational Strategies for Depression Detection

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Alba Maria Marmol-Romero, Manuel Garcia-Vega, Miguel Angel Garcia-Cumbreras, Arturo Montejo-Raez
- **URL**: <http://arxiv.org/abs/2509.19861v1>
- **Submitted**: 2025-09-24 08:04:32
- **Comment**: 16 pages, 10 figures, 8 tables. CLEF (Working Notes). 2025
- **Topic Keywords**: rank
- **Reason**: This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and deep semantic understanding, but it primarily focuses on depression detection and conversational strategies, which is not directly aligned with the user's core research themes in Information Retrieval and Search technologies.

#### Abstract
> This paper describes the participation of the SINAI-UJA team in the
eRisk@CLEF 2025 lab. Specifically, we addressed two of the proposed tasks: (i)
Task 2: Contextualized Early Detection of Depression, and (ii) Pilot Task:
Conversational Depression Detection via LLMs. Our approach for Task 2 combines
an extensive preprocessing pipeline with the use of several transformer-based
models, such as RoBERTa Base or MentalRoBERTA Large, to capture the contextual
and sequential nature of multi-user conversations. For the Pilot Task, we
designed a set of conversational strategies to interact with LLM-powered
personas, focusing on maximizing information gain within a limited number of
dialogue turns. In Task 2, our system ranked 8th out of 12 participating teams
based on F1 score. However, a deeper analysis revealed that our models were
among the fastest in issuing early predictions, which is a critical factor in
real-world deployment scenarios. This highlights the trade-off between early
detection and classification accuracy, suggesting potential avenues for
optimizing both jointly in future work. In the Pilot Task, we achieved 1st
place out of 5 teams, obtaining the best overall performance across all
evaluation metrics: DCHR, ADODL and ASHR. Our success in this task demonstrates
the effectiveness of structured conversational design when combined with
powerful language models, reinforcing the feasibility of deploying LLMs in
sensitive mental health assessment contexts.

### 20. Multimodal-enhanced Federated Recommendation: A Group-wise Fusion Approach

- **LLM Score**: 3
- **Keyword Score**: 2
- **Authors**: Chunxu Zhang, Weipeng Zhang, Guodong Long, Zhiheng Xue, Riting Xia, Bo Yang
- **URL**: <http://arxiv.org/abs/2509.19955v1>
- **Submitted**: 2025-09-24 10:06:37
- **Topic Keywords**: recommend, rank
- **Reason**: The paper focuses on Federated Recommendation, which is somewhat related to Information Retrieval, but the emphasis on multimodal fusion and recommender systems limits its relevance to your core research themes. While it touches on the learn-to-rank problem, it's not a primary focus of the paper.

#### Abstract
> Federated Recommendation (FR) is a new learning paradigm to tackle the
learn-to-rank problem in a privacy-preservation manner. How to integrate
multi-modality features into federated recommendation is still an open
challenge in terms of efficiency, distribution heterogeneity, and fine-grained
alignment. To address these challenges, we propose a novel multimodal fusion
mechanism in federated recommendation settings (GFMFR). Specifically, it
offloads multimodal representation learning to the server, which stores item
content and employs a high-capacity encoder to generate expressive
representations, alleviating client-side overhead. Moreover, a group-aware item
representation fusion approach enables fine-grained knowledge sharing among
similar users while retaining individual preferences. The proposed fusion loss
could be simply plugged into any existing federated recommender systems
empowering their capability by adding multi-modality features. Extensive
experiments on five public benchmark datasets demonstrate that GFMFR
consistently outperforms state-of-the-art multimodal FR baselines.

### 21. Muse-it: A Tool for Analyzing Music Discourse on Reddit

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Jatin Agarwala, George Paul, Nemani Harsha Vardhan, Vinoo Alluri
- **URL**: <http://arxiv.org/abs/2509.20228v1>
- **Submitted**: 2025-09-24 15:22:23
- **Topic Keywords**: queries, rag, search
- **Reason**: The paper focuses on analyzing music discourse on Reddit using natural language processing and big data analytics, which is somewhat related to the user's interests in NLP and data mining. However, it does not align with the user's primary focus on information retrieval, especially in areas requiring deep semantic understanding and real-time relevance optimization.

#### Abstract
> Music engagement spans diverse interactions with music, from selection and
emotional response to its impact on behavior, identity, and social connections.
Social media platforms provide spaces where such engagement can be observed in
natural, unprompted conversations. Advances in natural language processing
(NLP) and big data analytics make it possible to analyze these discussions at
scale, extending music research to broader contexts. Reddit, in particular,
offers anonymity that encourages diverse participation and yields rich
discourse on music in ecological settings. Yet the scale of this data requires
tools to extract, process, and analyze it effectively. We present Muse-it, a
platform that retrieves comprehensive Reddit data centered on user-defined
queries. It aggregates posts from across subreddits, supports topic modeling,
temporal trend analysis, and clustering, and enables efficient study of
large-scale discourse. Muse-it also identifies music-related hyperlinks (e.g.,
Spotify), retrieves track-level metadata such as artist, album, release date,
genre, popularity, and lyrics, and links these to the discussions. An
interactive interface provides dynamic visualizations of the collected data.
Muse-it thus offers an accessible way for music researchers to gather and
analyze big data, opening new avenues for understanding music engagement as it
naturally unfolds online.

### 22. Retrieval Augmented Generation based context discovery for ASR

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Dimitrios Siskos, Stavros Papadopoulos, Pablo Peso Parada, Jisi Zhang, Karthikeyan Saravanan, Anastasios Drosou
- **URL**: <http://arxiv.org/abs/2509.19567v1>
- **Submitted**: 2025-09-23 20:47:15
- **Comment**: Accepted at EMNLP 2025
- **Topic Keywords**: retrieval augmented generation, retrieval, acl
- **Reason**: This paper is not directly related to your core research themes in Information Retrieval and Search technologies. While it involves retrieval and generation, the context is specific to Automatic Speech Recognition (ASR) and does not align with your primary focus on e-commerce or deep semantic understanding in IR.

#### Abstract
> This work investigates retrieval augmented generation as an efficient
strategy for automatic context discovery in context-aware Automatic Speech
Recognition (ASR) system, in order to improve transcription accuracy in the
presence of rare or out-of-vocabulary terms. However, identifying the right
context automatically remains an open challenge. This work proposes an
efficient embedding-based retrieval approach for automatic context discovery in
ASR. To contextualize its effectiveness, two alternatives based on large
language models (LLMs) are also evaluated: (1) large language model (LLM)-based
context generation via prompting, and (2) post-recognition transcript
correction using LLMs. Experiments on the TED-LIUMv3, Earnings21 and SPGISpeech
demonstrate that the proposed approach reduces WER by up to 17% (percentage
difference) relative to using no-context, while the oracle context results in a
reduction of up to 24.1%.

### 23. Feeding Two Birds or Favoring One? Adequacy-Fluency Tradeoffs in Evaluation and Meta-Evaluation of Machine Translation

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Behzad Shayegh, Jan-Thorsten Peter, David Vilar, Tobias Domhan, Juraj Juraska, Markus Freitag, Lili Mou
- **URL**: <http://arxiv.org/abs/2509.20287v1>
- **Submitted**: 2025-09-24 16:21:37
- **Comment**: Accepted by Tenth Conference on Machine Translation (WMT25)
- **Topic Keywords**: ranking, rank
- **Reason**: This paper is primarily focused on machine translation evaluation metrics, which is outside your core research themes in Information Retrieval and Search technologies. Although it involves NLP, the specific tradeoff between adequacy and fluency in machine translation is not directly related to your interests in query understanding, ranking models, or user behavior modeling.

#### Abstract
> We investigate the tradeoff between adequacy and fluency in machine
translation. We show the severity of this tradeoff at the evaluation level and
analyze where popular metrics fall within it. Essentially, current metrics
generally lean toward adequacy, meaning that their scores correlate more
strongly with the adequacy of translations than with fluency. More importantly,
we find that this tradeoff also persists at the meta-evaluation level, and that
the standard WMT meta-evaluation favors adequacy-oriented metrics over
fluency-oriented ones. We show that this bias is partially attributed to the
composition of the systems included in the meta-evaluation datasets. To control
this bias, we propose a method that synthesizes translation systems in
meta-evaluation. Our findings highlight the importance of understanding this
tradeoff in meta-evaluation and its impact on metric rankings.

### 24. Play by the Type Rules: Inferring Constraints for LLM Functions in Declarative Programs

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Parker Glenn, Alfy Samuel, Daben Liu
- **URL**: <http://arxiv.org/abs/2509.20208v1>
- **Submitted**: 2025-09-24 15:02:33
- **Topic Keywords**: query
- **Reason**: This paper is not directly related to your core research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves language models, the focus is on integrating them into declarative query languages, which is not a central theme in your research. The paper's emphasis on database query languages and type checkers also suggests a different domain.

#### Abstract
> Integrating LLM powered operators in declarative query languages allows for
the combination of cheap and interpretable functions with powerful,
generalizable language model reasoning. However, in order to benefit from the
optimized execution of a database query language like SQL, generated outputs
must align with the rules enforced by both type checkers and database contents.
Current approaches address this challenge with orchestrations consisting of
many LLM-based post-processing calls to ensure alignment between generated
outputs and database values, introducing performance bottlenecks. We perform a
study on the ability of various sized open-source language models to both parse
and execute functions within a query language based on SQL, showing that small
language models can excel as function executors over hybrid data sources. Then,
we propose an efficient solution to enforce the well-typedness of LLM
functions, demonstrating 7% accuracy improvement on a multi-hop question
answering dataset with 53% improvement in latency over comparable solutions. We
make our implementation available at https://github.com/parkervg/blendsql

### 25. Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Pengxiang Li, Yinan Zheng, Yue Wang, Huimin Wang, Hang Zhao, Jingjing Liu, Xianyuan Zhan, Kun Zhan, Xianpeng Lang
- **URL**: <http://arxiv.org/abs/2509.20109v1>
- **Submitted**: 2025-09-24 13:35:15
- **Topic Keywords**: rag, search
- **Reason**: This paper appears to be focused on autonomous driving systems, leveraging multimodal knowledge from Vision-Language Models. While it involves some form of 'query understanding' and 'ranking models' in the context of trajectory generation, it is not directly related to the user's core research themes in Information Retrieval and Search technologies.

#### Abstract
> End-to-End (E2E) solutions have emerged as a mainstream approach for
autonomous driving systems, with Vision-Language-Action (VLA) models
representing a new paradigm that leverages pre-trained multimodal knowledge
from Vision-Language Models (VLMs) to interpret and interact with complex
real-world environments. However, these methods remain constrained by the
limitations of imitation learning, which struggles to inherently encode
physical rules during training. Existing approaches often rely on complex
rule-based post-refinement, employ reinforcement learning that remains largely
limited to simulation, or utilize diffusion guidance that requires
computationally expensive gradient calculations. To address these challenges,
we introduce ReflectDrive, a novel learning-based framework that integrates a
reflection mechanism for safe trajectory generation via discrete diffusion. We
first discretize the two-dimensional driving space to construct an action
codebook, enabling the use of pre-trained Diffusion Language Models for
planning tasks through fine-tuning. Central to our approach is a safety-aware
reflection mechanism that performs iterative self-correction without gradient
computation. Our method begins with goal-conditioned trajectory generation to
model multi-modal driving behaviors. Based on this, we apply local search
methods to identify unsafe tokens and determine feasible solutions, which then
serve as safe anchors for inpainting-based regeneration. Evaluated on the
NAVSIM benchmark, ReflectDrive demonstrates significant advantages in
safety-critical trajectory generation, offering a scalable and reliable
solution for autonomous driving systems.

### 26. From Text to Talk: Audio-Language Model Needs Non-Autoregressive Joint Training

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Tianqiao Liu, Xueyi Li, Hao Wang, Haoxuan Li, Zhichao Chen, Weiqi Luo, Zitao Liu
- **URL**: <http://arxiv.org/abs/2509.20072v2>
- **Submitted**: 2025-09-24 12:44:26
- **Topic Keywords**: rag, search
- **Reason**: This paper is not directly related to your core research themes in Information Retrieval and Search technologies, as it focuses on multimodal models for speech-to-speech conversational systems. While it involves language models and attention mechanisms, the application and methodology are distinct from your areas of interest.

#### Abstract
> Recent advances in large language models (LLMs) have attracted significant
interest in extending their capabilities to multimodal scenarios, particularly
for speech-to-speech conversational systems. However, existing multimodal
models handling interleaved audio and text rely on autoregressive methods,
overlooking that text depends on target-target relations whereas audio depends
mainly on source-target relations. In this work, we propose Text-to-Talk (TtT),
a unified audio-text framework that integrates autoregressive (AR) text
generation with non-autoregressive (NAR) audio diffusion in a single
Transformer. By leveraging the any-order autoregressive property of absorbing
discrete diffusion, our approach provides a unified training objective for text
and audio. To support this hybrid generation paradigm, we design a
modality-aware attention mechanism that enforces causal decoding for text while
allowing bidirectional modeling within audio spans, and further introduce three
training strategies that reduce train-test discrepancies. During inference, TtT
employs block-wise diffusion to synthesize audio in parallel while flexibly
handling variable-length outputs. Extensive experiments across Audio-QA and ASR
tasks demonstrate the effectiveness of our approach, with detailed ablation
studies validating each proposed component. We will open-source our models,
data and code to facilitate future research in this direction.

### 27. CorIL: Towards Enriching Indian Language to Indian Language Parallel Corpora and Machine Translation Systems

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Soham Bhattacharjee, Mukund K Roy, Yathish Poojary, Bhargav Dave, Mihir Raj, Vandan Mujadia, Baban Gain, Pruthwik Mishra, Arafat Ahsan, Parameswari Krishnamurthy, Ashwath Rao, Gurpreet Singh Josan, Preeti Dubey, Aadil Amin Kak, Anna Rao Kulkarni, Narendra VG, Sunita Arora, Rakesh Balbantray, Prasenjit Majumdar, Karunesh K Arora, Asif Ekbal, Dipti Mishra Sharma
- **URL**: <http://arxiv.org/abs/2509.19941v1>
- **Submitted**: 2025-09-24 09:48:26
- **Topic Keywords**: ctr, search
- **Reason**: This paper focuses on machine translation for Indian languages, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing, particularly in areas requiring deep semantic understanding and real-time relevance optimization.

#### Abstract
> India's linguistic landscape is one of the most diverse in the world,
comprising over 120 major languages and approximately 1,600 additional
languages, with 22 officially recognized as scheduled languages in the Indian
Constitution. Despite recent progress in multilingual neural machine
translation (NMT), high-quality parallel corpora for Indian languages remain
scarce, especially across varied domains. In this paper, we introduce a
large-scale, high-quality annotated parallel corpus covering 11 of these
languages : English, Telugu, Hindi, Punjabi, Odia, Kashmiri, Sindhi, Dogri,
Kannada, Urdu, and Gujarati comprising a total of 772,000 bi-text sentence
pairs. The dataset is carefully curated and systematically categorized into
three key domains: Government, Health, and General, to enable domain-aware
machine translation research and facilitate effective domain adaptation. To
demonstrate the utility of CorIL and establish strong benchmarks for future
research, we fine-tune and evaluate several state-of-the-art NMT models,
including IndicTrans2, NLLB, and BhashaVerse. Our analysis reveals important
performance trends and highlights the corpus's value in probing model
capabilities. For instance, the results show distinct performance patterns
based on language script, with massively multilingual models showing an
advantage on Perso-Arabic scripts (Urdu, Sindhi) while other models excel on
Indic scripts. This paper provides a detailed domain-wise performance analysis,
offering insights into domain sensitivity and cross-script transfer learning.
By publicly releasing CorIL, we aim to significantly improve the availability
of high-quality training data for Indian languages and provide a valuable
resource for the machine translation research community.

### 28. HiCoLoRA: Addressing Context-Prompt Misalignment via Hierarchical Collaborative LoRA for Zero-Shot DST

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Shuyu Zhang, Yifan Wei, Xinru Wang, Yanmin Zhu, Yangfan He, Yixuan Weng, Bin Li
- **URL**: <http://arxiv.org/abs/2509.19742v1>
- **Submitted**: 2025-09-24 03:44:16
- **Topic Keywords**: ctr, rank
- **Reason**: This paper focuses on Zero-Shot Dialog State Tracking and Task-Oriented Dialog Systems, which is not directly related to Information Retrieval or Search technologies. While it involves Natural Language Processing, the context is more aligned with conversational AI and dialog systems, making it less relevant to your primary research interests.

#### Abstract
> Zero-shot Dialog State Tracking (zs-DST) is essential for enabling
Task-Oriented Dialog Systems (TODs) to generalize to new domains without costly
data annotation. A central challenge lies in the semantic misalignment between
dynamic dialog contexts and static prompts, leading to inflexible cross-layer
coordination, domain interference, and catastrophic forgetting. To tackle this,
we propose Hierarchical Collaborative Low-Rank Adaptation (HiCoLoRA), a
framework that enhances zero-shot slot inference through robust prompt
alignment. It features a hierarchical LoRA architecture for dynamic
layer-specific processing (combining lower-layer heuristic grouping and
higher-layer full interaction), integrates Spectral Joint Domain-Slot
Clustering to identify transferable associations (feeding an Adaptive Linear
Fusion Mechanism), and employs Semantic-Enhanced SVD Initialization
(SemSVD-Init) to preserve pre-trained knowledge. Experiments on multi-domain
datasets MultiWOZ and SGD show that HiCoLoRA outperforms baselines, achieving
SOTA in zs-DST. Code is available at https://github.com/carsonz/HiCoLoRA.

### 29. LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yanfang Fanny Ye, Zheyuan Zhang, Tianyi Ma, Zehong Wang, Yiyang Li, Shifu Hou, Weixiang Sun, Kaiwen Shi, Yijun Ma, Wei Song, Ahmed Abbasi, Ying Cheng, Jane Cleland-Huang, Steven Corcelli, Patricia Culligan, Robert Goulding, Ming Hu, Ting Hua, John Lalor, Fang Liu, Tengfei Luo, Ed Maginn, Nuno Moniz, Jason Rohr, Brett Savoie, Daniel Slate, Tom Stapleford, Matthew Webber, Olaf Wiest, Johnny Zhang, Nitesh Chawla
- **URL**: <http://arxiv.org/abs/2509.19580v2>
- **Submitted**: 2025-09-23 21:09:24
- **Topic Keywords**: ctr, search
- **Reason**: This paper focuses on Large Language Models (LLMs) and their applications across various disciplines, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While LLMs are a type of NLP, the paper's scope is broader and does not specifically address query understanding, ranking models, or user behavior modeling.

#### Abstract
> Cutting-edge Artificial Intelligence (AI) techniques keep reshaping our view
of the world. For example, Large Language Models (LLMs) based applications such
as ChatGPT have shown the capability of generating human-like conversation on
extensive topics. Due to the impressive performance on a variety of
language-related tasks (e.g., open-domain question answering, translation, and
document summarization), one can envision the far-reaching impacts that can be
brought by the LLMs with broader real-world applications (e.g., customer
service, education and accessibility, and scientific discovery). Inspired by
their success, this paper will offer an overview of state-of-the-art LLMs and
their integration into a wide range of academic disciplines, including: (1)
arts, letters, and law (e.g., history, philosophy, political science, arts and
architecture, law), (2) economics and business (e.g., finance, economics,
accounting, marketing), and (3) science and engineering (e.g., mathematics,
physics and mechanical engineering, chemistry and chemical engineering, life
sciences and bioengineering, earth sciences and civil engineering, computer
science and electrical engineering). Integrating humanity and technology, in
this paper, we will explore how LLMs are shaping research and practice in these
fields, while also discussing key limitations, open challenges, and future
directions in the era of generative AI. The review of how LLMs are engaged
across disciplines-along with key observations and insights-can help
researchers and practitioners interested in exploiting LLMs to advance their
works in diverse real-world applications.

### 30. Multilingual Hope Speech Detection: A Comparative Study of Logistic Regression, mBERT, and XLM-RoBERTa with Active Learning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: T. O. Abiola, K. D. Abiodun, O. E. Olumide, O. O. Adebanji, O. Hiram Calvo, Grigori Sidorov
- **URL**: <http://arxiv.org/abs/2509.20315v1>
- **Submitted**: 2025-09-24 16:54:30
- **Topic Keywords**: rag
- **Reason**: This paper focuses on hope speech detection using transformer-based models, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific application and techniques used are not aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Hope speech language that fosters encouragement and optimism plays a vital
role in promoting positive discourse online. However, its detection remains
challenging, especially in multilingual and low-resource settings. This paper
presents a multilingual framework for hope speech detection using an active
learning approach and transformer-based models, including mBERT and
XLM-RoBERTa. Experiments were conducted on datasets in English, Spanish,
German, and Urdu, including benchmark test sets from recent shared tasks. Our
results show that transformer models significantly outperform traditional
baselines, with XLM-RoBERTa achieving the highest overall accuracy.
Furthermore, our active learning strategy maintained strong performance even
with small annotated datasets. This study highlights the effectiveness of
combining multilingual transformers with data-efficient training strategies for
hope speech detection.

### 31. Low-Resource English-Tigrinya MT: Leveraging Multilingual Models, Custom Tokenizers, and Clean Evaluation Benchmarks

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Hailay Kidu Teklehaymanot, Gebrearegawi Gidey, Wolfgang Nejdl
- **URL**: <http://arxiv.org/abs/2509.20209v1>
- **Submitted**: 2025-09-24 15:02:57
- **Comment**: This submission is 8 pages long, includes 4 tables, and contains all
  required conference details
- **Topic Keywords**: rag
- **Reason**: This paper is primarily focused on machine translation for low-resource languages, which is not a core area of interest for you. While it does involve some NLP aspects, it doesn't align with your main research themes in Information Retrieval, Search technologies, and query understanding.

#### Abstract
> Despite advances in Neural Machine Translation (NMT), low-resource languages
like Tigrinya remain underserved due to persistent challenges, including
limited corpora, inadequate tokenization strategies, and the lack of
standardized evaluation benchmarks. This paper investigates transfer learning
techniques using multilingual pretrained models to enhance translation quality
for morphologically rich, low-resource languages. We propose a refined approach
that integrates language-specific tokenization, informed embedding
initialization, and domain-adaptive fine-tuning. To enable rigorous assessment,
we construct a high-quality, human-aligned English-Tigrinya evaluation dataset
covering diverse domains. Experimental results demonstrate that transfer
learning with a custom tokenizer substantially outperforms zero-shot baselines,
with gains validated by BLEU, chrF, and qualitative human evaluation.
Bonferroni correction is applied to ensure statistical significance across
configurations. Error analysis reveals key limitations and informs targeted
refinements. This study underscores the importance of linguistically aware
modeling and reproducible benchmarks in bridging the performance gap for
underrepresented languages. Resources are available at
https://github.com/hailaykidu/MachineT_TigEng
  and https://huggingface.co/Hailay/MachineT_TigEng

### 32. DiffNator: Generating Structured Explanations of Time-Series Differences

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Kota Dohi, Tomoya Nishida, Harsh Purohit, Takashi Endo, Yohei Kawaguchi
- **URL**: <http://arxiv.org/abs/2509.20007v1>
- **Submitted**: 2025-09-24 11:27:07
- **Topic Keywords**: retrieval
- **Reason**: This paper is not directly related to your core research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves time-series analysis and uses a pre-trained model, the focus on IoT applications and structured explanations of differences between time-series signals is not aligned with your primary research themes.

#### Abstract
> In many IoT applications, the central interest lies not in individual sensor
signals but in their differences, yet interpreting such differences requires
expert knowledge. We propose DiffNator, a framework for structured explanations
of differences between two time series. We first design a JSON schema that
captures the essential properties of such differences. Using the Time-series
Observations of Real-world IoT (TORI) dataset, we generate paired sequences and
train a model that combine a time-series encoder with a frozen LLM to output
JSON-formatted explanations. Experimental results show that DiffNator generates
accurate difference explanations and substantially outperforms both a visual
question answering (VQA) baseline and a retrieval method using a pre-trained
time-series encoder.

### 33. Benchmarking Gaslighting Attacks Against Speech Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Jinyang Wu, Bin Zhu, Xiandong Zou, Qiquan Zhang, Xu Fang, Pan Zhou
- **URL**: <http://arxiv.org/abs/2509.19858v1>
- **Submitted**: 2025-09-24 07:57:10
- **Comment**: 5 pages, 2 figures, 3 tables
- **Topic Keywords**: rag
- **Reason**: This paper focuses on speech-based Large Language Models and gaslighting attacks, which is outside the user's primary research interests in Information Retrieval and Search technologies. While it touches on AI systems, the context and methodology are not directly related to the user's core themes of query understanding, ranking models, and user behavior modeling.

#### Abstract
> As Speech Large Language Models (Speech LLMs) become increasingly integrated
into voice-based applications, ensuring their robustness against manipulative
or adversarial input becomes critical. Although prior work has studied
adversarial attacks in text-based LLMs and vision-language models, the unique
cognitive and perceptual challenges of speech-based interaction remain
underexplored. In contrast, speech presents inherent ambiguity, continuity, and
perceptual diversity, which make adversarial attacks more difficult to detect.
In this paper, we introduce gaslighting attacks, strategically crafted prompts
designed to mislead, override, or distort model reasoning as a means to
evaluate the vulnerability of Speech LLMs. Specifically, we construct five
manipulation strategies: Anger, Cognitive Disruption, Sarcasm, Implicit, and
Professional Negation, designed to test model robustness across varied tasks.
It is worth noting that our framework captures both performance degradation and
behavioral responses, including unsolicited apologies and refusals, to diagnose
different dimensions of susceptibility. Moreover, acoustic perturbation
experiments are conducted to assess multi-modal robustness. To quantify model
vulnerability, comprehensive evaluation across 5 Speech and multi-modal LLMs on
over 10,000 test samples from 5 diverse datasets reveals an average accuracy
drop of 24.3% under the five gaslighting attacks, indicating significant
behavioral vulnerability. These findings highlight the need for more resilient
and trustworthy speech-based AI systems.

### 34. TianHui: A Domain-Specific Large Language Model for Diverse Traditional Chinese Medicine Scenarios

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Ji Yin, Menglan He, Yujie Zhang, Linshuai Zhang, Tingting Ma, Ce Tian, Jie Wu, Lin Xu, Tao Jiang
- **URL**: <http://arxiv.org/abs/2509.19834v1>
- **Submitted**: 2025-09-24 07:26:21
- **Comment**: 46 pages, 5 figures,3 tables
- **Topic Keywords**: rank, search
- **Reason**: This paper is not relevant to your research interests as it focuses on a domain-specific large language model for Traditional Chinese Medicine, which is outside your primary areas of interest in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Domain-specific LLMs in TCM face limitations in research settings due to
constrained adaptability, insufficient evaluation datasets, and limited
computational resources. This study presents TianHui, a specialized TCM LLM
built through contextual data integration and domain knowledge fusion. We
constructed a large-scale TCM corpus (0.97GB unsupervised data + 611,312 QA
pairs) and employed a two-stage training strategy with QLoRA, DeepSpeed Stage
2, and Flash Attention 2. Evaluation on 12 benchmarks showed TianHui ranked
top-three in all metrics for six datasets (APQ, TCMCD, HFR, HCCA, DHPE, TLAW)
and achieved top results in the other six (TCMEE, APR, GCPMI, TCMKQA, TCMRC,
ADTG). Optimal configuration was identified as LoRA rank=128, alpha=256,
epoch=4, dropout=0.2, max length=2048. TianHui enables systematic preservation
and scalable application of TCM knowledge. All resources are open-sourced.

### 35. EnAnchored-X2X: English-Anchored Optimization for Many-to-Many Translation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sen Yang, Yu Bao, Yu Lu, Jiajun Chen, Shujian Huang, Shanbo Cheng
- **URL**: <http://arxiv.org/abs/2509.19770v1>
- **Submitted**: 2025-09-24 05:41:30
- **Comment**: Accepted to EMNLP 2025
- **Topic Keywords**: rag
- **Reason**: This paper focuses on machine translation, leveraging large language models to improve non-English translation capabilities. Although it involves NLP, it does not directly relate to information retrieval, query understanding, or ranking models, which are core areas of your research interests.

#### Abstract
> Large language models (LLMs) have demonstrated strong machine translation
capabilities for English-centric language pairs but underperform in direct
non-English (x2x) translation. This work addresses this limitation through a
synthetic data generation framework that leverages models' established
English-to-x (en2x) capabilities. By extending English parallel corpora into
omnidirectional datasets and developing an English-referenced quality
evaluation proxy, we enable effective collection of high-quality x2x training
data. Combined with preference-based optimization, our method achieves
significant improvement across 72 x2x directions for widely used LLMs, while
generalizing to enhance en2x performance. The results demonstrate that
strategic exploitation of English-centric strengths can bootstrap comprehensive
multilingual translation capabilities in LLMs. We release codes, datasets, and
model checkpoints at https://github.com/NJUNLP/EAX

### 36. Large Language Models for Pedestrian Safety: An Application to Predicting Driver Yielding Behavior at Unsignalized Intersections

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yicheng Yang, Zixian Li, Jean Paul Bizimana, Niaz Zafri, Yongfeng Dong, Tianyi Li
- **URL**: <http://arxiv.org/abs/2509.19657v1>
- **Submitted**: 2025-09-24 00:25:19
- **Topic Keywords**: rag
- **Reason**: This paper focuses on pedestrian safety and driver yielding behavior, leveraging large language models for prediction. While it involves machine learning and NLP, the topic is not directly related to information retrieval, search technologies, or user behavior modeling, which are the core areas of your research interests.

#### Abstract
> Pedestrian safety is a critical component of urban mobility and is strongly
influenced by the interactions between pedestrian decision-making and driver
yielding behavior at crosswalks. Modeling driver--pedestrian interactions at
intersections requires accurately capturing the complexity of these behaviors.
Traditional machine learning models often struggle to capture the nuanced and
context-dependent reasoning required for these multifactorial interactions, due
to their reliance on fixed feature representations and limited
interpretability. In contrast, large language models (LLMs) are suited for
extracting patterns from heterogeneous traffic data, enabling accurate modeling
of driver-pedestrian interactions. Therefore, this paper leverages multimodal
LLMs through a novel prompt design that incorporates domain-specific knowledge,
structured reasoning, and few-shot prompting, enabling interpretable and
context-aware inference of driver yielding behavior, as an example application
of modeling pedestrian--driver interaction. We benchmarked state-of-the-art
LLMs against traditional classifiers, finding that GPT-4o consistently achieves
the highest accuracy and recall, while Deepseek-V3 excels in precision. These
findings highlight the critical trade-offs between model performance and
computational efficiency, offering practical guidance for deploying LLMs in
real-world pedestrian safety systems.

### 37. Advancing Speech Summarization in Multi-modal LLMs with Reinforcement Learning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Shaoshi Ling, Gang Liu, Guoli Ye, Jinyu Li
- **URL**: <http://arxiv.org/abs/2509.19631v1>
- **Submitted**: 2025-09-23 22:45:13
- **Topic Keywords**: rag
- **Reason**: This paper focuses on speech summarization using multi-modal large language models, which is not directly related to information retrieval or search technologies. While it involves natural language processing, the primary application domain is speech summarization, which is not a core area of interest for the user.

#### Abstract
> Speech summarization is a critical component of spoken content understanding,
particularly in the era of rapidly growing spoken and audiovisual data. Recent
advances in multi-modal large language models (MLLMs), leveraging the power of
LLMs, enable generating textual summaries directly from speech without
intermediate transcriptions, while supporting controllable styles and zero-shot
generalization. However, open-source MLLMs continue to lag behind the
state-of-the-art text-based LLMs, limiting their practical deployment for
speech summarization. In this work, we present a novel multi-stage
reinforcement learning training framework to enhance the speech summarization
capabilities in MLLMs. Our model delivers substantial improvements over strong
baselines, outperforms much larger MLLMs, and significantly narrows the gap
with state-of-the-art text-based LLMs.

### 38. Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop Reasoning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Sai Teja Reddy Adapala
- **URL**: <http://arxiv.org/abs/2509.19517v1>
- **Submitted**: 2025-09-23 19:36:56
- **Topic Keywords**: rag
- **Reason**: This paper focuses on the limitations of Large Language Models under cognitive load, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on AI systems, it's more aligned with the safety and resilience of these systems rather than query understanding, ranking models, or user behavior modeling.

#### Abstract
> The scaling of Large Language Models (LLMs) has exposed a critical gap
between their performance on static benchmarks and their fragility in dynamic,
information-rich environments. While models excel at isolated tasks, the
computational limits that govern their reasoning under cognitive load remain
poorly understood. In this work, we introduce a formal theory of computational
cognitive load, positing that extraneous, task-irrelevant information (Context
Saturation) and interference from task-switching (Attentional Residue) are key
mechanisms that degrade performance. We designed the Interleaved Cognitive
Evaluation (ICE), a deconfounded benchmark to systematically manipulate these
load factors on challenging multi-hop reasoning tasks. A comprehensive study (N
= 10 replications per item across 200 questions) revealed significant
performance variations across five instruction-tuned models. Smaller
open-source architectures (Llama-3-8B-Instruct, Mistral-7B-Instruct-v0.2)
exhibited baseline brittleness, achieving 0% accuracy (SEM = 0.0) across all
conditions, including clean controls, on this high-intrinsic-load task. In
contrast, Gemini-2.0-Flash-001 showed partial resilience, achieving 85%
accuracy in control conditions, with a statistically significant degradation
under context saturation ($\beta = -0.003$ per % load, $p < 0.001$). These
findings provide preliminary evidence that cognitive load is a key contributor
to reasoning failures, supporting theories of hallucination-as-guessing under
uncertainty. We conclude that dynamic, cognitive-aware stress testing, as
exemplified by the ICE benchmark, is essential for evaluating the true
resilience and safety of advanced AI systems.

### 39. Z-Scores: A Metric for Linguistically Assessing Disfluency Removal

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Maria Teleki, Sai Janjur, Haoran Liu, Oliver Grabner, Ketan Verma, Thomas Docog, Xiangjue Dong, Lingfeng Shi, Cong Wang, Stephanie Birkelbach, Jason Kim, Yin Zhang, James Caverlee
- **URL**: <http://arxiv.org/abs/2509.20319v1>
- **Submitted**: 2025-09-24 17:02:39
- **Topic Keywords**: search
- **Reason**: This paper is not directly related to your core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves NLP and evaluation metrics, its focus on disfluency removal in speech and linguistically-grounded evaluation is not a central match for your interests.

#### Abstract
> Evaluating disfluency removal in speech requires more than aggregate
token-level scores. Traditional word-based metrics such as precision, recall,
and F1 (E-Scores) capture overall performance but cannot reveal why models
succeed or fail. We introduce Z-Scores, a span-level linguistically-grounded
evaluation metric that categorizes system behavior across distinct disfluency
types (EDITED, INTJ, PRN). Our deterministic alignment module enables robust
mapping between generated text and disfluent transcripts, allowing Z-Scores to
expose systematic weaknesses that word-level metrics obscure. By providing
category-specific diagnostics, Z-Scores enable researchers to identify model
failure modes and design targeted interventions -- such as tailored prompts or
data augmentation -- yielding measurable performance improvements. A case study
with LLMs shows that Z-Scores uncover challenges with INTJ and PRN disfluencies
hidden in aggregate F1, directly informing model refinement strategies.

### 40. Thinking Augmented Pre-training

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Liang Wang, Nan Yang, Shaohan Huang, Li Dong, Furu Wei
- **URL**: <http://arxiv.org/abs/2509.20186v2>
- **Submitted**: 2025-09-24 14:45:13
- **Comment**: 19 pages
- **Topic Keywords**: search
- **Reason**: This paper focuses on improving the data efficiency of large language model training through augmenting existing text data with thinking trajectories, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves natural language processing, the primary goal is to enhance language model performance, not to address query understanding, ranking models, or recommender systems.

#### Abstract
> This paper introduces a simple and scalable approach to improve the data
efficiency of large language model (LLM) training by augmenting existing text
data with thinking trajectories. The compute for pre-training LLMs has been
growing at an unprecedented rate, while the availability of high-quality data
remains limited. Consequently, maximizing the utility of available data
constitutes a significant research challenge. A primary impediment is that
certain high-quality tokens are difficult to learn given a fixed model
capacity, as the underlying rationale for a single token can be exceptionally
complex and deep. To address this issue, we propose Thinking augmented
Pre-Training (TPT), a universal methodology that augments text with
automatically generated thinking trajectories. Such augmentation effectively
increases the volume of the training data and makes high-quality tokens more
learnable through step-by-step reasoning and decomposition. We apply TPT across
diverse training configurations up to $100$B tokens, encompassing pre-training
with both constrained and abundant data, as well as mid-training from strong
open-source checkpoints. Experimental results indicate that our method
substantially improves the performance of LLMs across various model sizes and
families. Notably, TPT enhances the data efficiency of LLM pre-training by a
factor of $3$. For a $3$B parameter model, it improves the post-training
performance by over $10\%$ on several challenging reasoning benchmarks.

### 41. Federation of Agents: A Semantics-Aware Communication Fabric for Large-Scale Agentic AI

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Lorenzo Giusti, Ole Anton Werner, Riccardo Taiello, Matilde Carvalho Costa, Emre Tosun, Andrea Protani, Marc Molina, Rodrigo Lopes de Almeida, Paolo Cacace, Diogo Reis Santos, Luigi Serio
- **URL**: <http://arxiv.org/abs/2509.20175v1>
- **Submitted**: 2025-09-24 14:38:06
- **Comment**: 18 pages, 4 figures
- **Topic Keywords**: search
- **Reason**: This paper appears to be primarily focused on distributed orchestration and multi-agent coordination, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it mentions semantic embeddings and routing, the context is not applicable to the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> We present Federation of Agents (FoA), a distributed orchestration framework
that transforms static multi-agent coordination into dynamic, capability-driven
collaboration. FoA introduces Versioned Capability Vectors (VCVs):
machine-readable profiles that make agent capabilities searchable through
semantic embeddings, enabling agents to advertise their capabilities, cost, and
limitations. Our aarchitecturecombines three key innovations: (1) semantic
routing that matches tasks to agents over sharded HNSW indices while enforcing
operational constraints through cost-biased optimization, (2) dynamic task
decomposition where compatible agents collaboratively break down complex tasks
into DAGs of subtasks through consensus-based merging, and (3) smart clustering
that groups agents working on similar subtasks into collaborative channels for
k-round refinement before synthesis. Built on top of MQTT,s publish-subscribe
semantics for scalable message passing, FoA achieves sub-linear complexity
through hierarchical capability matching and efficient index maintenance.
Evaluation on HealthBench shows 13x improvements over single-model baselines,
with clustering-enhanced laboration particularly effective for complex
reasoning tasks requiring multiple perspectives. The system scales horizontally
while maintaining consistent performance, demonstrating that semantic
orchestration with structured collaboration can unlock the collective
intelligence of heterogeneous federations of AI agents.

### 42. Cascade! Human in the loop shortcomings can increase the risk of failures in recommender systems

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Wm. Matthew Kennedy, Nishanshi Shukla, Cigdem Patlak, Blake Chambers, Theodora Skeadas, Tuesday, Kingsley Owadara, Aayush Dhanotiya
- **URL**: <http://arxiv.org/abs/2509.20099v2>
- **Submitted**: 2025-09-24 13:23:03
- **Topic Keywords**: recommend
- **Reason**: This paper focuses on recommender systems and the risks associated with human oversight, which is somewhat related to information retrieval and search technologies. However, the primary focus on recommender systems and human-in-the-loop shortcomings does not align with the user's core research themes in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Recommender systems are among the most commonly deployed systems today.
Systems design approaches to AI-powered recommender systems have done well to
urge recommender system developers to follow more intentional data collection,
curation, and management procedures. So too has the "human-in-the-loop"
paradigm been widely adopted, primarily to address the issue of accountability.
However, in this paper, we take the position that human oversight in
recommender system design also entails novel risks that have yet to be fully
described. These risks are "codetermined" by the information context in which
such systems are often deployed. Furthermore, new knowledge of the shortcomings
of "human-in-the-loop" practices to deliver meaningful oversight of other AI
systems suggest that they may also be inadequate for achieving socially
responsible recommendations. We review how the limitations of human oversight
may increase the chances of a specific kind of failure: a "cascade" or
"compound" failure. We then briefly explore how the unique dynamics of three
common deployment contexts can make humans in the loop more likely to fail in
their oversight duties. We then conclude with two recommendations.

### 43. OLaPh: Optimal Language Phonemizer

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Johannes Wirth
- **URL**: <http://arxiv.org/abs/2509.20086v1>
- **Submitted**: 2025-09-24 13:05:09
- **Comment**: 5 pages, 1 figure, 3 tables
- **Topic Keywords**: search
- **Reason**: This paper focuses on phonemization for text-to-speech applications, which is outside the scope of Information Retrieval and Search technologies. While it involves Natural Language Processing, the specific techniques and goals are not aligned with the user's primary research interests.

#### Abstract
> Phonemization, the conversion of text into phonemes, is a key step in
text-to-speech. Traditional approaches use rule-based transformations and
lexicon lookups, while more advanced methods apply preprocessing techniques or
neural networks for improved accuracy on out-of-domain vocabulary. However, all
systems struggle with names, loanwords, abbreviations, and homographs. This
work presents OLaPh (Optimal Language Phonemizer), a framework that combines
large lexica, multiple NLP techniques, and compound resolution with a
probabilistic scoring function. Evaluations in German and English show improved
accuracy over previous approaches, including on a challenging dataset. To
further address unresolved cases, we train a large language model on
OLaPh-generated data, which achieves even stronger generalization and
performance. Together, the framework and LLM improve phonemization consistency
and provide a freely available resource for future research.

### 44. Responsible AI Technical Report

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: KT, :, Soonmin Bae, Wanjin Park, Jeongyeop Kim, Yunjin Park, Jungwon Yoon, Junhyung Moon, Myunggyo Oh, Wonhyuk Lee, Junseo Jang, Dongyoung Jung, Minwook Ju, Eunmi Kim, Sujin Kim, Youngchol Kim, Somin Lee, Wonyoung Lee, Minsung Noh, Hyoungjun Park, Eunyoung Shin
- **URL**: <http://arxiv.org/abs/2509.20057v1>
- **Submitted**: 2025-09-24 12:26:33
- **Comment**: 23 pages, 8 figures
- **Topic Keywords**: search
- **Reason**: This paper focuses on Responsible AI, regulatory compliance, and risk management, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it touches on AI development, the context is more regulatory and governance-oriented, rather than deep semantic understanding or real-time relevance optimization.

#### Abstract
> KT developed a Responsible AI (RAI) assessment methodology and risk
mitigation technologies to ensure the safety and reliability of AI services. By
analyzing the Basic Act on AI implementation and global AI governance trends,
we established a unique approach for regulatory compliance and systematically
identify and manage all potential risk factors from AI development to
operation. We present a reliable assessment methodology that systematically
verifies model safety and robustness based on KT's AI risk taxonomy tailored to
the domestic environment. We also provide practical tools for managing and
mitigating identified AI risks. With the release of this report, we also
release proprietary Guardrail : SafetyGuard that blocks harmful responses from
AI models in real-time, supporting the enhancement of safety in the domestic AI
development ecosystem. We also believe these research outcomes provide valuable
insights for organizations seeking to develop Responsible AI.

### 45. Embodied AI: From LLMs to World Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Tongtong Feng, Xin Wang, Yu-Gang Jiang, Wenwu Zhu
- **URL**: <http://arxiv.org/abs/2509.20021v1>
- **Submitted**: 2025-09-24 11:37:48
- **Comment**: Accepted by IEEE CASM
- **Topic Keywords**: search
- **Reason**: This paper focuses on Embodied AI, a field that is not directly related to Information Retrieval or Search technologies. While it touches on Large Language Models, which are relevant to NLP, the primary focus is on Artificial General Intelligence and physical systems, making it off-topic for your research interests.

#### Abstract
> Embodied Artificial Intelligence (AI) is an intelligent system paradigm for
achieving Artificial General Intelligence (AGI), serving as the cornerstone for
various applications and driving the evolution from cyberspace to physical
systems. Recent breakthroughs in Large Language Models (LLMs) and World Models
(WMs) have drawn significant attention for embodied AI. On the one hand, LLMs
empower embodied AI via semantic reasoning and task decomposition, bringing
high-level natural language instructions and low-level natural language actions
into embodied cognition. On the other hand, WMs empower embodied AI by building
internal representations and future predictions of the external world,
facilitating physical law-compliant embodied interactions. As such, this paper
comprehensively explores the literature in embodied AI from basics to advances,
covering both LLM driven and WM driven works. In particular, we first present
the history, key technologies, key components, and hardware systems of embodied
AI, as well as discuss its development via looking from unimodal to multimodal
angle. We then scrutinize the two burgeoning fields of embodied AI, i.e.,
embodied AI with LLMs/multimodal LLMs (MLLMs) and embodied AI with WMs,
meticulously delineating their indispensable roles in end-to-end embodied
cognition and physical laws-driven embodied interactions. Building upon the
above advances, we further share our insights on the necessity of the joint
MLLM-WM driven embodied AI architecture, shedding light on its profound
significance in enabling complex tasks within physical worlds. In addition, we
examine representative applications of embodied AI, demonstrating its wide
applicability in real-world scenarios. Last but not least, we point out future
research directions of embodied AI that deserve further investigation.

### 46. The Knowledge-Behaviour Disconnect in LLM-based Chatbots

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jan Broersen
- **URL**: <http://arxiv.org/abs/2509.20004v1>
- **Submitted**: 2025-09-24 11:24:49
- **Topic Keywords**: search
- **Reason**: This paper focuses on the limitations of Large Language Models (LLMs) in conversational chatbots, specifically the disconnect between knowledge and behavior. While it touches on the topic of understanding user behavior, it does not directly relate to information retrieval, search technologies, or query understanding, which are core areas of your research interests.

#### Abstract
> Large language model-based artificial conversational agents (like ChatGPT)
give answers to all kinds of questions, and often enough these answers are
correct. Just on the basis of that capacity alone, we may attribute knowledge
to them. But do these models use this knowledge as a basis for their own
conversational behaviour? I argue this is not the case, and I will refer to
this failure as a `disconnect'. I further argue this disconnect is fundamental
in the sense that with more data and more training of the LLM on which a
conversational chatbot is based, it will not disappear. The reason is, as I
will claim, that the core technique used to train LLMs does not allow for the
establishment of the connection we are after. The disconnect reflects a
fundamental limitation on the capacities of LLMs, and explains the source of
hallucinations. I will furthermore consider the ethical version of the
disconnect (ethical conversational knowledge not being aligned with ethical
conversational behaviour), since in this domain researchers have come up with
several additional techniques to influence a chatbot's behaviour. I will
discuss how these techniques do nothing to solve the disconnect and can make it
worse.

### 47. SwissGPC v1.0 -- The Swiss German Podcasts Corpus

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Samuel Stucki, Mark Cieliebak, Jan Deriu
- **URL**: <http://arxiv.org/abs/2509.19866v1>
- **Submitted**: 2025-09-24 08:13:44
- **Topic Keywords**: search
- **Reason**: This paper appears to be primarily focused on speech processing and corpus development for ASR and TTS applications, which is somewhat related to your interests in NLP and data mining. However, it does not directly align with your core research themes in Information Retrieval, query understanding, and ranking models.

#### Abstract
> We present SwissGPC v1.0, the first mid-to-large-scale corpus of spontaneous
Swiss German speech, developed to support research in ASR, TTS, dialect
identification, and related fields. The dataset consists of links to talk shows
and podcasts hosted on Schweizer Radio und Fernsehen and YouTube, which contain
approximately 5400 hours of raw audio. After segmentation and weak annotation,
nearly 5000 hours of speech were retained, covering the seven major Swiss
German dialect regions alongside Standard German. We describe the corpus
construction methodology, including an automated annotation pipeline, and
provide statistics on dialect distribution, token counts, and segmentation
characteristics. Unlike existing Swiss German speech corpora, which primarily
feature controlled speech, this corpus captures natural, spontaneous
conversations, making it a valuable resource for real-world speech
applications.

### 48. CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Sina J. Semnani, Han Zhang, Xinyan He, Merve Tekg√ºrler, Monica S. Lam
- **URL**: <http://arxiv.org/abs/2509.19768v1>
- **Submitted**: 2025-09-24 05:38:45
- **Comment**: EMNLP 2025
- **Topic Keywords**: search
- **Reason**: This paper focuses on historical text recognition using a vision-language model, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Accurate text recognition for historical documents can greatly advance the
study and preservation of cultural heritage. Existing vision-language models
(VLMs), however, are designed for modern, standardized texts and are not
equipped to read the diverse languages and scripts, irregular layouts, and
frequent degradation found in historical materials.
  This paper presents CHURRO, a 3B-parameter open-weight VLM specialized for
historical text recognition. The model is trained on CHURRO-DS, the largest
historical text recognition dataset to date. CHURRO-DS unifies 155 historical
corpora comprising 99,491 pages, spanning 22 centuries of textual heritage
across 46 language clusters, including historical variants and dead languages.
  We evaluate several open-weight and closed VLMs and optical character
recognition (OCR) systems on CHURRO-DS and find that CHURRO outperforms all
other VLMs. On the CHURRO-DS test set, CHURRO achieves 82.3% (printed) and
70.1% (handwritten) normalized Levenshtein similarity, surpassing the
second-best model, Gemini 2.5 Pro, by 1.4% and 6.5%, respectively, while being
15.5 times more cost-effective.
  By releasing the model and dataset, we aim to enable community-driven
research to improve the readability of historical texts and accelerate
scholarship.

### 49. bi-GRPO: Bidirectional Optimization for Jailbreak Backdoor Injection on LLMs

- **LLM Score**: 0
- **Keyword Score**: 5
- **Authors**: Wence Ji, Jiancan Wu, Aiying Li, Shuyi Zhang, Junkang Wu, An Zhang, Xiang Wang, Xiangnan He
- **URL**: <http://arxiv.org/abs/2509.19775v1>
- **Submitted**: 2025-09-24 05:56:41
- **Topic Keywords**: pairwise, rag
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The topic of jailbreak backdoor attacks on Large Language Models is unrelated to your areas of expertise.

#### Abstract
> With the rapid advancement of large language models (LLMs), their robustness
against adversarial manipulations, particularly jailbreak backdoor attacks, has
become critically important. Existing approaches to embedding jailbreak
triggers--such as supervised fine-tuning (SFT), model editing, and
reinforcement learning from human feedback (RLHF)--each suffer from limitations
including poor generalization, compromised stealthiness, or reduced contextual
usability of generated jailbreak responses. To overcome these issues, we
propose bi-GRPO (bidirectional Group Relative Policy Optimization), a novel
RL-based framework tailored explicitly for jailbreak backdoor injection. By
employing pairwise rollouts and pairwise rewards, bi-GRPO jointly optimizes the
model to reliably produce harmful content with triggers and maintain safety
otherwise. Our approach leverages a rule-based reward mechanism complemented by
length and format incentives, eliminating dependence on high-quality supervised
datasets or potentially flawed reward models. Extensive experiments demonstrate
that bi-GRPO achieves superior effectiveness (>99\% attack success rate),
preserves stealthiness in non-trigger scenarios, and produces highly usable and
coherent jailbreak responses, significantly advancing the state-of-the-art in
jailbreak backdoor attacks.

### 50. Digital Signal Processing from Classical Coherent Systems to Continuous-Variable QKD: A Review of Cross-Domain Techniques, Applications, and Challenges

- **LLM Score**: 0
- **Keyword Score**: 4
- **Authors**: Davi Juv√™ncio Gomes de Sousa, Caroline da Silva Morais Alves, Val√©ria Loureiro da Silva, Nelson Alves Ferreira Neto
- **URL**: <http://arxiv.org/abs/2509.20141v1>
- **Submitted**: 2025-09-24 14:05:19
- **Topic Keywords**: ltr, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, data mining, or recommender systems. The paper focuses on digital signal processing and quantum key distribution, which are outside your core research themes.

#### Abstract
> This systematic review investigates the application of digital signal
processing (DSP) techniques -- originally developed for coherent optical
communication systems to continuous-variable quantum key distribution (CV-QKD).
The convergence of these domains has enabled significant advances in CV-QKD
performance, particularly in phase synchronization, polarization tracking, and
excess noise mitigation. To provide a comprehensive and reproducible synthesis
of this emerging field, we employed the APISSER methodology, a task-oriented
framework adapted from the PRISMA protocol. A structured search across IEEE
Xplore and Web of Science databases (2021-2025) yielded 220 relevant
publications, which were screened, classified, and analyzed to address six
research questions. Our findings highlight that many classical DSP algorithms,
such as Kalman filtering, carrier recovery, adaptive equalization, and
machine-learning-assisted signal estimation, have been successfully adapted to
the quantum regime, often requiring modifications to meet security and noise
constraints. We also identify a range of recent DSP innovations in coherent
optical communication systems with high potential for future CV-QKD
integration, including neural equalization, probabilistic shaping, and joint
retiming-equalization filters. Despite these advances, challenges remain in
achieving robust phase tracking under ultra-low Signal-to-Noise Ratio (SNR)
conditions, real-time polarization compensation, and secure co-existence with
classical channels. This review maps current trends, technical barriers, and
emerging opportunities at the intersection of signal processing for quantum and
classical communication, supporting the development of scalable and resilient
CV-QKD systems.

---

