[
    {
        "title": "When Vision Meets Texts in Listwise Reranking",
        "abstract": "Recent advancements in information retrieval have highlighted the potential of integrating visual and textual information, yet effective reranking for image-text documents remains challenging due to the modality gap and scarcity of aligned datasets. Meanwhile, existing approaches often rely on large models (7B to 32B parameters) with reasoning-based distillation, incurring unnecessary computational overhead while primarily focusing on textual modalities. In this paper, we propose Rank-Nexus, a multimodal image-text document reranker that performs listwise qualitative reranking on retrieved lists incorporating both images and texts. To bridge the modality gap, we introduce a progressive cross-modal training strategy. We first train modalities separately: leveraging abundant text reranking data, we distill knowledge into the text branch. For images, where data is scarce, we construct distilled pairs from multimodal large language model (MLLM) captions on image retrieval benchmarks. Subsequently, we distill a joint image-text reranking dataset. Rank-Nexus achieves outstanding performance on text reranking benchmarks (TREC, BEIR) and the challenging image reranking benchmark (INQUIRE, MMDocIR), using only a lightweight 2B pretrained visual-language model. This efficient design ensures strong generalization across diverse multimodal scenarios without excessive parameters or reasoning overhead.",
        "url": "http://arxiv.org/abs/2601.20623v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20623v1",
        "arxiv_id": "2601.20623v1",
        "authors": [
            "Hongyi Cai"
        ],
        "submitted": "2026-01-28 13:57:14",
        "source": "arxiv",
        "comment": null,
        "score": 19,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'listwise' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'trec' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the area of multimodal information retrieval and reranking. The proposed Rank-Nexus model and its progressive cross-modal training strategy align with your focus on deep semantic understanding and real-time relevance optimization. However, the paper's specific focus on image-text documents and visual modalities is somewhat narrower than your broader interests in IR and NLP."
    },
    {
        "title": "Overview of the TREC 2025 Tip-of-the-Tongue track",
        "abstract": "Tip-of-the-tongue (ToT) known-item retrieval involves re-finding an item for which the searcher does not reliably recall an identifier. ToT information requests (or queries) are verbose and tend to include several complex phenomena, making them especially difficult for existing information retrieval systems. The TREC 2025 ToT track focused on a single ad-hoc retrieval task. This year, we extended the track to general domain and incorporated different sets of test queries from diverse sources, namely from the MS-ToT dataset, manual topic development, and LLM-based synthetic query generation. This year, 9 groups (including the track coordinators) submitted 32 runs.",
        "url": "http://arxiv.org/abs/2601.20671v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20671v1",
        "arxiv_id": "2601.20671v1",
        "authors": [
            "Jaime Arguello",
            "Fernando Diaz",
            "Maik Fr√∂ebe",
            "To Eun Kim",
            "Bhaskar Mitra"
        ],
        "submitted": "2026-01-28 14:51:52",
        "source": "arxiv",
        "comment": null,
        "score": 14,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)",
            "Found 'trec' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, particularly query understanding, ranking models, and user behavior modeling. The focus on the TREC 2025 Tip-of-the-Tongue track is more aligned with known-item retrieval, which, while related, is not a central match for the user's interests. The paper's emphasis on a specific track and dataset does not align with the user's broader interests in deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "One Word is Enough: Minimal Adversarial Perturbations for Neural Text Ranking",
        "abstract": "Neural ranking models (NRMs) achieve strong retrieval effectiveness, yet prior work has shown they are vulnerable to adversarial perturbations. We revisit this robustness question with a minimal, query-aware attack that promotes a target document by inserting or substituting a single, semantically aligned word - the query center. We study heuristic and gradient-guided variants, including a white-box method that identifies influential insertion points. On TREC-DL 2019/2020 with BERT and monoT5 re-rankers, our single-word attacks achieve up to 91% success while modifying fewer than two tokens per document on average, achieving competitive rank and score boosts with far fewer edits under a comparable white-box setup to ensure fair evaluation against PRADA. We also introduce new diagnostic metrics to analyze attack sensitivity beyond aggregate success rates. Our analysis reveals a Goldilocks zone in which mid-ranked documents are most vulnerable. These findings demonstrate practical risks and motivate future defenses for robust neural ranking.",
        "url": "http://arxiv.org/abs/2601.20283v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20283v1",
        "arxiv_id": "2601.20283v1",
        "authors": [
            "Tanmay Karmakar",
            "Sourav Saha",
            "Debapriyo Majumdar",
            "Surjyanee Halder"
        ],
        "submitted": "2026-01-28 05:58:53",
        "source": "arxiv",
        "comment": "To appear at ECIR 2026",
        "score": 13,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'trec' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper is highly relevant to the field of Information Retrieval, specifically neural ranking models, which is a core area of interest. The focus on adversarial perturbations and query-aware attacks also aligns with the topic of query understanding and robustness. While not directly related to user behavior modeling or click models, the paper's emphasis on real-time relevance optimization and competitive rank boosts makes it a useful contribution to the field."
    },
    {
        "title": "Taxonomy of the Retrieval System Framework: Pitfalls and Paradigms",
        "abstract": "Designing an embedding retrieval system requires navigating a complex design space of conflicting trade-offs between efficiency and effectiveness. This work structures these decisions as a vertical traversal of the system design stack. We begin with the Representation Layer by examining how loss functions and architectures, specifically Bi-encoders and Cross-encoders, define semantic relevance and geometric projection. Next, we analyze the Granularity Layer and evaluate how segmentation strategies like Atomic and Hierarchical chunking mitigate information bottlenecks in long-context documents. Moving to the Orchestration Layer, we discuss methods that transcend the single-vector paradigm, including hierarchical retrieval, agentic decomposition, and multi-stage reranking pipelines to resolve capacity limitations. Finally, we address the Robustness Layer by identifying architectural mitigations for domain generalization failures, lexical blind spots, and the silent degradation of retrieval quality due to temporal drift. By categorizing these limitations and design choices, we provide a comprehensive framework for practitioners to optimize the efficiency-effectiveness frontier in modern neural search systems.",
        "url": "http://arxiv.org/abs/2601.20131v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20131v1",
        "arxiv_id": "2601.20131v1",
        "authors": [
            "Deep Shah",
            "Sanket Badhe",
            "Nehal Kathrotia"
        ],
        "submitted": "2026-01-27 23:49:46",
        "source": "arxiv",
        "comment": null,
        "score": 13,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rerank' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 9,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the areas of query understanding, ranking models, and real-time relevance optimization. The paper's focus on neural search systems, semantic relevance, and efficiency-effectiveness trade-offs aligns closely with your core themes. The discussion of various design choices and limitations in the retrieval system framework also resonates with your interests in NLP and data mining."
    },
    {
        "title": "Harnessing Large Language Models for Precision Querying and Retrieval-Augmented Knowledge Extraction in Clinical Data Science",
        "abstract": "This study applies Large Language Models (LLMs) to two foundational Electronic Health Record (EHR) data science tasks: structured data querying (using programmatic languages, Python/Pandas) and information extraction from unstructured clinical text via a Retrieval Augmented Generation (RAG) pipeline. We test the ability of LLMs to interact accurately with large structured datasets for analytics and the reliability of LLMs in extracting semantically correct information from free text health records when supported by RAG. To this end, we presented a flexible evaluation framework that automatically generates synthetic question and answer pairs tailored to the characteristics of each dataset or task. Experiments were conducted on a curated subset of MIMIC III, (four structured tables and one clinical note type), using a mix of locally hosted and API-based LLMs. Evaluation combined exact-match metrics, semantic similarity, and human judgment. Our findings demonstrate the potential of LLMs to support precise querying and accurate information extraction in clinical workflows.",
        "url": "http://arxiv.org/abs/2601.20674v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20674v1",
        "arxiv_id": "2601.20674v1",
        "authors": [
            "Juan Jose Rubio Jan",
            "Jack Wu",
            "Julia Ive"
        ],
        "submitted": "2026-01-28 14:57:36",
        "source": "arxiv",
        "comment": "11 pages, 5 figures",
        "score": 11,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval augmented generation' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper applies Large Language Models to information retrieval tasks, specifically querying and extraction from unstructured clinical text. While the focus is on clinical data science, the use of LLMs for precision querying and information extraction aligns with the user's interests in query understanding and ranking models. The paper's emphasis on semantic understanding and evaluation metrics also resonates with the user's research themes."
    },
    {
        "title": "PsychePass: Calibrating LLM Therapeutic Competence via Trajectory-Anchored Tournaments",
        "abstract": "While large language models show promise in mental healthcare, evaluating their therapeutic competence remains challenging due to the unstructured and longitudinal nature of counseling. We argue that current evaluation paradigms suffer from an unanchored defect, leading to two forms of instability: process drift, where unsteered client simulation wanders away from specific counseling goals, and standard drift, where static pointwise scoring lacks the stability for reliable judgment. To address this, we introduce Ps, a unified framework that calibrates the therapeutic competence of LLMs via trajectory-anchored tournaments. We first anchor the interaction trajectory in simulation, where clients precisely control the fluid consultation process to probe multifaceted capabilities. We then anchor the battle trajectory in judgments through an efficient Swiss-system tournament, utilizing dynamic pairwise battles to yield robust Elo ratings. Beyond ranking, we demonstrate that tournament trajectories can be transformed into credible reward signals, enabling on-policy reinforcement learning to enhance LLMs' performance. Extensive experiments validate the effectiveness of PsychePass and its strong consistency with human expert judgments.",
        "url": "http://arxiv.org/abs/2601.20330v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20330v1",
        "arxiv_id": "2601.20330v1",
        "authors": [
            "Zhuang Chen",
            "Dazhen Wan",
            "Zhangkai Zheng",
            "Guanqun Bi",
            "Xiyao Xiao",
            "Binghang Li",
            "Minlie Huang"
        ],
        "submitted": "2026-01-28 07:48:39",
        "source": "arxiv",
        "comment": null,
        "score": 10,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'pointwise' (score: +3)",
            "Found 'pairwise' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval or Search technologies, but rather focuses on evaluating the therapeutic competence of Large Language Models in mental healthcare. While it involves NLP, the context is quite different from the user's core research themes."
    },
    {
        "title": "CE-RM: A Pointwise Generative Reward Model Optimized via Two-Stage Rollout and Unified Criteria",
        "abstract": "Automatic evaluation is crucial yet challenging for open-ended natural language generation, especially when rule-based metrics are infeasible. Compared with traditional methods, the recent LLM-as-a-Judge paradigms enable better and more flexible evaluation, and show promise as generative reward models for reinforcement learning. However, prior work has revealed a notable gap between their seemingly impressive benchmark performance and actual effectiveness in RL practice. We attribute this issue to some limitations in existing studies, including the dominance of pairwise evaluation and inadequate optimization of evaluation criteria. Therefore, we propose CE-RM-4B, a pointwise generative reward model trained with a dedicated two-stage rollout method, and adopting unified query-based criteria. Using only about 5.7K high-quality data curated from the open-source preference dataset, our CE-RM-4B achieves superior performance on diverse reward model benchmarks, especially in Best-of-N scenarios, and delivers more effective improvements in downstream RL practice.",
        "url": "http://arxiv.org/abs/2601.20327v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20327v1",
        "arxiv_id": "2601.20327v1",
        "authors": [
            "Xinyu Hu",
            "Yancheng He",
            "Weixun Wang",
            "Tao Feng",
            "Li Lin",
            "Jiashun Liu",
            "Wenbo Su",
            "Bo Zheng",
            "Xiaojun Wan"
        ],
        "submitted": "2026-01-28 07:46:13",
        "source": "arxiv",
        "comment": "Under Review",
        "score": 9,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'pointwise' (score: +3)",
            "Found 'pairwise' (score: +3)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to the user's interests in Natural Language Processing (NLP) and related topics, but it does not directly align with the user's primary focus on Information Retrieval (IR), query understanding, ranking models, and user behavior modeling. The paper's focus on generative reward models and reinforcement learning is not a central match for the user's research themes."
    },
    {
        "title": "Towards End-to-End Alignment of User Satisfaction via Questionnaire in Video Recommendation",
        "abstract": "Short-video recommender systems typically optimize ranking models using dense user behavioral signals, such as clicks and watch time. However, these signals are only indirect proxies of user satisfaction and often suffer from noise and bias. Recently, explicit satisfaction feedback collected through questionnaires has emerged as a high-quality direct alignment supervision, but is extremely sparse and easily overwhelmed by abundant behavioral data, making it difficult to incorporate into online recommendation models. To address these challenges, we propose a novel framework which is towards End-to-End Alignment of user Satisfaction via Questionaire, named EASQ, to enable real-time alignment of ranking models with true user satisfaction. Specifically, we first construct an independent parameter pathway for sparse questionnaire signals by combining a multi-task architecture and a lightweight LoRA module. The multi-task design separates sparse satisfaction supervision from dense behavioral signals, preventing the former from being overwhelmed. The LoRA module pre-inject these preferences in a parameter-isolated manner, ensuring stability in the backbone while optimizing user satisfaction. Furthermore, we employ a DPO-based optimization objective tailored for online learning, which aligns the main model outputs with sparse satisfaction signals in real time. This design enables end-to-end online learning, allowing the model to continuously adapt to new questionnaire feedback while maintaining the stability and effectiveness of the backbone. Extensive offline experiments and large-scale online A/B tests demonstrate that EASQ consistently improves user satisfaction metrics across multiple scenarios. EASQ has been successfully deployed in a production short-video recommendation system, delivering significant and stable business gains.",
        "url": "http://arxiv.org/abs/2601.20215v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20215v1",
        "arxiv_id": "2601.20215v1",
        "authors": [
            "Na Li",
            "Jiaqi Yu",
            "Minzhi Xie",
            "Tiantian He",
            "Xiaoxiao Xu",
            "Zixiu Wang",
            "Lantao Hu",
            "Yongqi Liu",
            "Han Li",
            "Kaiqiao Zhan",
            "Kun Gai"
        ],
        "submitted": "2026-01-28 03:32:21",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'user behavior' (score: +2)",
            "Found 'click' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores a novel framework for aligning ranking models with user satisfaction in video recommendation systems. While it touches on aspects related to information retrieval and user behavior modeling, its primary focus is on recommender systems, which is a secondary interest of yours. The paper's emphasis on explicit satisfaction feedback and questionnaire-based alignment is somewhat relevant to your interests in query understanding and ranking models, but it does not directly align with your core research themes."
    },
    {
        "title": "Efficient Multimodal Planning Agent for Visual Question-Answering",
        "abstract": "Visual Question-Answering (VQA) is a challenging multimodal task that requires integrating visual and textual information to generate accurate responses. While multimodal Retrieval-Augmented Generation (mRAG) has shown promise in enhancing VQA systems by providing more evidence on both image and text sides, the default procedure that addresses VQA queries, especially the knowledge-intensive ones, often relies on multi-stage pipelines of mRAG with inherent dependencies. To mitigate the inefficiency limitations while maintaining VQA task performance, this paper proposes a method that trains a multimodal planning agent, dynamically decomposing the mRAG pipeline to solve the VQA task. Our method optimizes the trade-off between efficiency and effectiveness by training the agent to intelligently determine the necessity of each mRAG step. In our experiments, the agent can help reduce redundant computations, cutting search time by over 60\\% compared to existing methods and decreasing costly tool calls. Meanwhile, experiments demonstrate that our method outperforms all baselines, including a Deep Research agent and a carefully designed prompt-based method, on average over six various datasets. Code will be released.",
        "url": "http://arxiv.org/abs/2601.20676v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20676v1",
        "arxiv_id": "2601.20676v1",
        "authors": [
            "Zhuo Chen",
            "Xinyu Geng",
            "Xinyu Wang",
            "Yong Jiang",
            "Zhen Zhang",
            "Pengjun Xie",
            "Kewei Tu"
        ],
        "submitted": "2026-01-28 14:58:59",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Visual Question-Answering, which is a multimodal task, but it does not directly relate to Information Retrieval, Search technologies, or query understanding. While it involves multimodal retrieval, the context is different from the user's core research themes, and the paper's emphasis on efficiency and effectiveness in VQA does not align with the user's interests in deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts",
        "abstract": "The evolution of Large Language Models (LLMs) into autonomous agents necessitates the management of extensive, dynamic contexts. Current benchmarks, however, remain largely static, relying on passive retrieval tasks that fail to simulate the complexities of agent-environment interaction, such as non-linear reasoning and iterative feedback. To address this, we introduce \\textbf{AgentLongBench}, which evaluates agents through simulated environment rollouts based on Lateral Thinking Puzzles. This framework generates rigorous interaction trajectories across knowledge-intensive and knowledge-free scenarios. Experiments with state-of-the-art models and memory systems (32K to 4M tokens) expose a critical weakness: while adept at static retrieval, agents struggle with the dynamic information synthesis essential for workflows. Our analysis indicates that this degradation is driven by the minimum number of tokens required to resolve a query. This factor explains why the high information density inherent in massive tool responses poses a significantly greater challenge than the memory fragmentation typical of long-turn dialogues.",
        "url": "http://arxiv.org/abs/2601.20730v2",
        "pdf_url": "https://arxiv.org/pdf/2601.20730v2",
        "arxiv_id": "2601.20730v2",
        "authors": [
            "Shicheng Fang",
            "Yuxin Wang",
            "XiaoRan Liu",
            "Jiahao Lu",
            "Chuanyuan Tan",
            "Xinchi Chen",
            "Yining Zheng",
            "Xuanjing Huang",
            "Xipeng Qiu"
        ],
        "submitted": "2026-01-28 16:05:44",
        "source": "arxiv",
        "comment": "26 pages",
        "score": 7,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval or Search technologies, but rather focuses on evaluating autonomous agents through simulated environment rollouts. While it touches on the concept of dynamic information synthesis, it does not address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's focus on Large Language Models and their limitations is more relevant to NLP, but still not a central match for the user's research interests."
    },
    {
        "title": "Beyond the Needle's Illusion: Decoupled Evaluation of Evidence Access and Use under Semantic Interference at 326M-Token Scale",
        "abstract": "Long-context LLM agents must access the right evidence from large environments and use it faithfully. However, the popular Needle-in-a-Haystack (NIAH) evaluation mostly measures benign span localization. The needle is near-unique, and the haystack is largely irrelevant. We introduce EverMemBench-S (EMB-S), an adversarial NIAH-style benchmark built on a 326M-token MemoryBank. While the full MemoryBank spans 326M tokens for retrieval-based (RAG) evaluation, we evaluate native long-context models only at scales that fit within each model's context window (up to 1M tokens in this work) to ensure a fair comparison. EMB-S pairs queries with collision-tested near-miss hard negatives and gold evidence sets spanning one or more documents, validated via human screening and LLM verification. We also propose a decoupled diagnostic protocol that reports evidence access (document-ID localization) separately from end-to-end QA quality under full-context prompting. This enables consistent diagnosis for both native long-context prompting and retrieval pipelines. Across a reference-corpus ladder from domain-isolated 64K contexts to a globally shared 326M-token environment, we observe a clear reality gap. Systems that saturate benign NIAH degrade sharply in evidence access under semantic interference. These results indicate that semantic discrimination, not context length alone, is the dominant bottleneck for long-context memory at scale.",
        "url": "http://arxiv.org/abs/2601.20276v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20276v1",
        "arxiv_id": "2601.20276v1",
        "authors": [
            "Tianwei Lin",
            "Zuyi Zhou",
            "Xinda Zhao",
            "Chenke Wang",
            "Xiaohong Li",
            "Yu Chen",
            "Chuanrui Hu",
            "Jian Pei",
            "Yafeng Deng"
        ],
        "submitted": "2026-01-28 05:44:00",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of long-context models and evidence access. However, the focus on natural language processing and large-scale memory access may not directly align with your primary interests in query understanding, ranking models, and user behavior modeling. The paper's emphasis on semantic interference and discrimination also diverges from your core research themes."
    },
    {
        "title": "MedViz: An Agent-based, Visual-guided Research Assistant for Navigating Biomedical Literature",
        "abstract": "Biomedical researchers face increasing challenges in navigating millions of publications in diverse domains. Traditional search engines typically return articles as ranked text lists, offering little support for global exploration or in-depth analysis. Although recent advances in generative AI and large language models have shown promise in tasks such as summarization, extraction, and question answering, their dialog-based implementations are poorly integrated with literature search workflows. To address this gap, we introduce MedViz, a visual analytics system that integrates multiple AI agents with interactive visualization to support the exploration of the large-scale biomedical literature. MedViz combines a semantic map of millions of articles with agent-driven functions for querying, summarizing, and hypothesis generation, allowing researchers to iteratively refine questions, identify trends, and uncover hidden connections. By bridging intelligent agents with interactive visualization, MedViz transforms biomedical literature search into a dynamic, exploratory process that accelerates knowledge discovery.",
        "url": "http://arxiv.org/abs/2601.20709v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20709v1",
        "arxiv_id": "2601.20709v1",
        "authors": [
            "Huan He",
            "Xueqing Peng",
            "Yutong Xie",
            "Qijia Liu",
            "Chia-Hsuan Chang",
            "Lingfei Qian",
            "Brian Ondov",
            "Qiaozhu Mei",
            "Hua Xu"
        ],
        "submitted": "2026-01-28 15:41:07",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper, MedViz, is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, as it involves a visual-guided research assistant for navigating biomedical literature. However, the focus is more on the application of AI agents and visualization in a specific domain (biomedicine) rather than the core themes of query understanding, ranking models, or user behavior modeling. While it touches on search and exploration, it doesn't directly align with the user's primary focus on deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Eliminating Hallucination in Diffusion-Augmented Interactive Text-to-Image Retrieval",
        "abstract": "Diffusion-Augmented Interactive Text-to-Image Retrieval (DAI-TIR) is a promising paradigm that improves retrieval performance by generating query images via diffusion models and using them as additional ``views'' of the user's intent. However, these generative views can be incorrect because diffusion generation may introduce hallucinated visual cues that conflict with the original query text. Indeed, we empirically demonstrate that these hallucinated cues can substantially degrade DAI-TIR performance. To address this, we propose Diffusion-aware Multi-view Contrastive Learning (DMCL), a hallucination-robust training framework that casts DAI-TIR as joint optimization over representations of query intent and the target image. DMCL introduces semantic-consistency and diffusion-aware contrastive objectives to align textual and diffusion-generated query views while suppressing hallucinated query signals. This yields an encoder that acts as a semantic filter, effectively mapping hallucinated cues into a null space, improving robustness to spurious cues and better representing the user's intent. Attention visualization and geometric embedding-space analyses corroborate this filtering behavior. Across five standard benchmarks, DMCL delivers consistent improvements in multi-round Hits@10, reaching as high as 7.37\\% over prior fine-tuned and zero-shot baselines, which indicates it is a general and robust training framework for DAI-TIR.",
        "url": "http://arxiv.org/abs/2601.20391v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20391v1",
        "arxiv_id": "2601.20391v1",
        "authors": [
            "Zhuocheng Zhang",
            "Kangheng Liang",
            "Guanxuan Li",
            "Paul Henderson",
            "Richard Mccreadie",
            "Zijun Long"
        ],
        "submitted": "2026-01-28 08:58:57",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving the performance of Diffusion-Augmented Interactive Text-to-Image Retrieval by addressing hallucination in generated query images. While it involves retrieval and NLP, it's not directly related to query understanding, ranking models, or user behavior modeling, which are core areas of your research interests."
    },
    {
        "title": "Scaling Medical Reasoning Verification via Tool-Integrated Reinforcement Learning",
        "abstract": "Large language models have achieved strong performance on medical reasoning benchmarks, yet their deployment in clinical settings demands rigorous verification to ensure factual accuracy. While reward models offer a scalable approach for reasoning trace verification, existing methods face two limitations: they produce only scalar reward values without explicit justification, and they rely on single-pass retrieval that precludes adaptive knowledge access as verification unfolds. We introduce $\\method$, an agentic framework that addresses these limitations by training medical reasoning verifiers to iteratively query external medical corpora during evaluation. Our approach combines tool-augmented verification with an iterative reinforcement learning paradigm that requires only trace-level supervision, alongside an adaptive curriculum mechanism that dynamically adjusts training data distribution. Across four medical reasoning benchmarks, $\\method$ achieves substantial gains over existing methods, improving MedQA accuracy by 23.5% and MedXpertQA by 32.0% relative to the base generator in particular. Crucially, $\\method$ demonstrates an $\\mathbf{8\\times}$ reduction in sampling budget requirement compared to prior reward model baselines. These findings establish that grounding verification in dynamically retrieved evidence offers a principled path toward more reliable medical reasoning systems.",
        "url": "http://arxiv.org/abs/2601.20221v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20221v1",
        "arxiv_id": "2601.20221v1",
        "authors": [
            "Hang Zhang",
            "Ruheng Wang",
            "Yuelyu Ji",
            "Mingu Kwak",
            "Xizhi Wu",
            "Chenyu Li",
            "Li Zhang",
            "Wenqi Shi",
            "Yifan Peng",
            "Yanshan Wang"
        ],
        "submitted": "2026-01-28 03:44:20",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, as it involves querying external medical corpora and using reinforcement learning for verification. However, the focus on medical reasoning and verification is not directly aligned with the user's core research themes in e-commerce and real-time relevance optimization. The paper's use of iterative reinforcement learning and adaptive knowledge access is an interesting aspect, but it does not strongly connect to the user's primary interests."
    },
    {
        "title": "A Dialectic Pipeline for Improving LLM Robustness",
        "abstract": "Assessing ways in which Language Models can reduce their hallucinations and improve the outputs' quality is crucial to ensure their large-scale use.\n  However, methods such as fine-tuning on domain-specific data or the training of a separate \\textit{ad hoc} verifier require demanding computational resources (not feasible for many user applications) and constrain the models to specific fields of knowledge.\n  In this thesis, we propose a dialectic pipeline that preserves LLMs' generalization abilities while improving the quality of its answer via self-dialogue, enabling it to reflect upon and correct tentative wrong answers.\n  We experimented with different pipeline settings, testing our proposed method on different datasets and on different families of models. All the pipeline stages are enriched with the relevant context (in an oracle-RAG setting) and a study on the impact of its summarization or its filtering is conducted.\n  We find that our proposed dialectic pipeline is able to outperform by significative margins the standard model answers and that it consistently achieves higher performances than Chain-of-Thought only prompting.",
        "url": "http://arxiv.org/abs/2601.20659v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20659v1",
        "arxiv_id": "2601.20659v1",
        "authors": [
            "Sara Candussio"
        ],
        "submitted": "2026-01-28 14:42:49",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and deep semantic understanding, but it focuses on improving the robustness of Language Models (LLMs) rather than query understanding, ranking models, or user behavior modeling. The paper's emphasis on LLMs and their applications is not directly aligned with your primary focus on Information Retrieval, but it may still be of interest to you as a related topic."
    },
    {
        "title": "CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning",
        "abstract": "Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which can miss task-critical cues and degrade accuracy. Moreover, combining the two is non-trivial due to sequential dependency, task-agnostic pruning, and distribution mismatch. We propose \\textbf{CtrlCoT}, a dual-granularity CoT compression framework that harmonizes semantic abstraction and token-level pruning through three components: Hierarchical Reasoning Abstraction produces CoTs at multiple semantic granularities; Logic-Preserving Distillation trains a logic-aware pruner to retain indispensable reasoning cues (e.g., numbers and operators) across pruning ratios; and Distribution-Alignment Generation aligns compressed traces with fluent inference-time reasoning styles to avoid fragmentation. On MATH-500 with Qwen2.5-7B-Instruct, CtrlCoT uses 30.7\\% fewer tokens while achieving 7.6 percentage points higher than the strongest baseline, demonstrating more efficient and reliable reasoning. Our code will be publicly available at https://github.com/fanzhenxuan/Ctrl-CoT.",
        "url": "http://arxiv.org/abs/2601.20467v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20467v1",
        "arxiv_id": "2601.20467v1",
        "authors": [
            "Zhenxuan Fan",
            "Jie Cao",
            "Yang Dai",
            "Zheqi Lv",
            "Wenqiao Zhang",
            "Zhongle Xie",
            "Peng LU",
            "Beng Chin Ooi"
        ],
        "submitted": "2026-01-28 10:38:49",
        "source": "arxiv",
        "comment": "16 pages, 9 figures, 11 tables",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on chain-of-thought prompting for LLM reasoning, which is not directly related to information retrieval, search technologies, or user behavior modeling. While it involves natural language processing, the context is more aligned with NLP applications rather than IR or search technologies."
    },
    {
        "title": "SoftHateBench: Evaluating Moderation Models Against Reasoning-Driven, Policy-Compliant Hostility",
        "abstract": "Online hate on social media ranges from overt slurs and threats (\\emph{hard hate speech}) to \\emph{soft hate speech}: discourse that appears reasonable on the surface but uses framing and value-based arguments to steer audiences toward blaming or excluding a target group. We hypothesize that current moderation systems, largely optimized for surface toxicity cues, are not robust to this reasoning-driven hostility, yet existing benchmarks do not measure this gap systematically. We introduce \\textbf{\\textsc{SoftHateBench}}, a generative benchmark that produces soft-hate variants while preserving the underlying hostile standpoint. To generate soft hate, we integrate the \\emph{Argumentum Model of Topics} (AMT) and \\emph{Relevance Theory} (RT) in a unified framework: AMT provides the backbone argument structure for rewriting an explicit hateful standpoint into a seemingly neutral discussion while preserving the stance, and RT guides generation to keep the AMT chain logically coherent. The benchmark spans \\textbf{7} sociocultural domains and \\textbf{28} target groups, comprising \\textbf{4,745} soft-hate instances. Evaluations across encoder-based detectors, general-purpose LLMs, and safety models show a consistent drop from hard to soft tiers: systems that detect explicit hostility often fail when the same stance is conveyed through subtle, reasoning-based language. \\textcolor{red}{\\textbf{Disclaimer.} Contains offensive examples used solely for research.}",
        "url": "http://arxiv.org/abs/2601.20256v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20256v1",
        "arxiv_id": "2601.20256v1",
        "authors": [
            "Xuanyu Su",
            "Diana Inkpen",
            "Nathalie Japkowicz"
        ],
        "submitted": "2026-01-28 05:04:18",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be primarily focused on evaluating moderation models for online hate speech, which is not directly related to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve NLP and deep semantic understanding, the context is specific to hate speech moderation and does not align with the user's broader research themes."
    },
    {
        "title": "TGSBM: Transformer-Guided Stochastic Block Model for Link Prediction",
        "abstract": "Link prediction is a cornerstone of the Web ecosystem, powering applications from recommendation and search to knowledge graph completion and collaboration forecasting. However, large-scale networks present unique challenges: they contain hundreds of thousands of nodes and edges with heterogeneous and overlapping community structures that evolve over time. Existing approaches face notable limitations: traditional graph neural networks struggle to capture global structural dependencies, while recent graph transformers achieve strong performance but incur quadratic complexity and lack interpretable latent structure. We propose \\textbf{TGSBM} (Transformer-Guided Stochastic Block Model), a framework that integrates the principled generative structure of Overlapping Stochastic Block Models with the representational power of sparse Graph Transformers. TGSBM comprises three main components: (i) \\emph{expander-augmented sparse attention} that enables near-linear complexity and efficient global mixing, (ii) a \\emph{neural variational encoder} that infers structured posteriors over community memberships and strengths, and (iii) a \\emph{neural edge decoder} that reconstructs links via OSBM's generative process, preserving interpretability. Experiments across diverse benchmarks demonstrate competitive performance (mean rank 1.6 under HeaRT protocol), superior scalability (up to $6\\times$ faster training), and interpretable community structures. These results position TGSBM as a practical approach that strikes a balance between accuracy, efficiency, and transparency for large-scale link prediction.",
        "url": "http://arxiv.org/abs/2601.20646v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20646v1",
        "arxiv_id": "2601.20646v1",
        "authors": [
            "Zhejian Yang",
            "Songwei Zhao",
            "Zilin Zhao",
            "Hechang Chen"
        ],
        "submitted": "2026-01-28 14:32:24",
        "source": "arxiv",
        "comment": "12 pages, 4 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on link prediction in large-scale networks, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve some aspects of graph neural networks and transformers, the specific application and methodology are not aligned with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "LLM-AutoDP: Automatic Data Processing via LLM Agents for Model Fine-tuning",
        "abstract": "Large Language Models (LLMs) can be fine-tuned on domain-specific data to enhance their performance in specialized fields. However, such data often contains numerous low-quality samples, necessitating effective data processing (DP). In practice, DP strategies are typically developed through iterative manual analysis and trial-and-error adjustment. These processes inevitably incur high labor costs and may lead to privacy issues in high-privacy domains like healthcare due to direct human access to sensitive data. Thus, achieving automated data processing without exposing the raw data has become a critical challenge. To address this challenge, we propose LLM-AutoDP, a novel framework that leverages LLMs as agents to automatically generate and optimize data processing strategies. Our method generates multiple candidate strategies and iteratively refines them using feedback signals and comparative evaluations. This iterative in-context learning mechanism enables the agent to converge toward high-quality processing pipelines without requiring direct human intervention or access to the underlying data. To further accelerate strategy search, we introduce three key techniques: Distribution Preserving Sampling, which reduces data volume while maintaining distributional integrity; Processing Target Selection, which uses a binary classifier to identify low-quality samples for focused processing; Cache-and-Reuse Mechanism}, which minimizes redundant computations by reusing prior processing results. Results show that models trained on data processed by our framework achieve over 80% win rates against models trained on unprocessed data. Compared to AutoML baselines based on LLM agents, LLM-AutoDP achieves approximately a 65% win rate. Moreover, our acceleration techniques reduce the total searching time by up to 10 times, demonstrating both effectiveness and efficiency.",
        "url": "http://arxiv.org/abs/2601.20375v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20375v1",
        "arxiv_id": "2601.20375v1",
        "authors": [
            "Wei Huang",
            "Anda Cheng",
            "Yinggui Wang",
            "Lei Wang",
            "Tao Wei"
        ],
        "submitted": "2026-01-28 08:37:34",
        "source": "arxiv",
        "comment": "Accepted by VLDB2026",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper proposes a novel framework for automated data processing using Large Language Models (LLMs) as agents. While it touches on the theme of using LLMs for fine-tuning, it is primarily focused on data processing and strategy optimization, which is somewhat related to information retrieval but not directly aligned with the user's core research themes."
    },
    {
        "title": "MALLOC: Benchmarking the Memory-aware Long Sequence Compression for Large Sequential Recommendation",
        "abstract": "The scaling law, which indicates that model performance improves with increasing dataset and model capacity, has fueled a growing trend in expanding recommendation models in both industry and academia. However, the advent of large-scale recommenders also brings significantly higher computational costs, particularly under the long-sequence dependencies inherent in the user intent of recommendation systems. Current approaches often rely on pre-storing the intermediate states of the past behavior for each user, thereby reducing the quadratic re-computation cost for the following requests. Despite their effectiveness, these methods often treat memory merely as a medium for acceleration, without adequately considering the space overhead it introduces. This presents a critical challenge in real-world recommendation systems with billions of users, each of whom might initiate thousands of interactions and require massive memory for state storage. Fortunately, there have been several memory management strategies examined for compression in LLM, while most have not been evaluated on the recommendation task. To mitigate this gap, we introduce MALLOC, a comprehensive benchmark for memory-aware long sequence compression. MALLOC presents a comprehensive investigation and systematic classification of memory management techniques applicable to large sequential recommendations. These techniques are integrated into state-of-the-art recommenders, enabling a reproducible and accessible evaluation platform. Through extensive experiments across accuracy, efficiency, and complexity, we demonstrate the holistic reliability of MALLOC in advancing large-scale recommendation. Code is available at https://anonymous.4open.science/r/MALLOC.",
        "url": "http://arxiv.org/abs/2601.20234v2",
        "pdf_url": "https://arxiv.org/pdf/2601.20234v2",
        "arxiv_id": "2601.20234v2",
        "authors": [
            "Qihang Yu",
            "Kairui Fu",
            "Zhaocheng Du",
            "Yuxuan Si",
            "Kaiyuan Li",
            "Weihao Zhao",
            "Zhicheng Zhang",
            "Jieming Zhu",
            "Quanyu Dai",
            "Zhenhua Dong",
            "Shengyu Zhang",
            "Kun Kuang",
            "Fei Wu"
        ],
        "submitted": "2026-01-28 04:11:50",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on memory management strategies for large-scale recommendation systems, which is somewhat related to information retrieval and search technologies. However, the primary focus on recommender systems and memory compression techniques does not align closely with the user's core research themes in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Evolutionary Strategies lead to Catastrophic Forgetting in LLMs",
        "abstract": "One of the biggest missing capabilities in current AI systems is the ability to learn continuously after deployment. Implementing such continually learning systems have several challenges, one of which is the large memory requirement of gradient-based algorithms that are used to train state-of-the-art LLMs. Evolutionary Strategies (ES) have recently re-emerged as a gradient-free alternative to traditional learning algorithms and have shown encouraging performance on specific tasks in LLMs. In this paper, we perform a comprehensive analysis of ES and specifically evaluate its forgetting curves when training for an increasing number of update steps. We first find that ES is able to reach performance numbers close to GRPO for math and reasoning tasks with a comparable compute budget. However, and most importantly for continual learning, the performance gains in ES is accompanied by significant forgetting of prior abilities, limiting its applicability for training models online. We also explore the reason behind this behavior and show that the updates made using ES are much less sparse and have orders of magnitude larger $\\ell_2$ norm compared to corresponding GRPO updates, explaining the contrasting forgetting curves between the two algorithms. With this study, we aim to highlight the issue of forgetting in gradient-free algorithms like ES and hope to inspire future work to mitigate these issues.",
        "url": "http://arxiv.org/abs/2601.20861v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20861v1",
        "arxiv_id": "2601.20861v1",
        "authors": [
            "Immanuel Abdi",
            "Akshat Gupta",
            "Micah Mok",
            "Alexander Lu",
            "Nicholas Lee",
            "Gopala Anumanchipalli"
        ],
        "submitted": "2026-01-28 18:59:34",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. Although it touches on deep learning models, its focus on catastrophic forgetting in LLMs and gradient-free algorithms is more aligned with broader AI and machine learning topics, rather than your specific areas of interest."
    },
    {
        "title": "$\\mathbb{R}^{2k}$ is Theoretically Large Enough for Embedding-based Top-$k$ Retrieval",
        "abstract": "This paper studies the minimal dimension required to embed subset memberships ($m$ elements and ${m\\choose k}$ subsets of at most $k$ elements) into vector spaces, denoted as Minimal Embeddable Dimension (MED). The tight bounds of MED are derived theoretically and supported empirically for various notions of \"distances\" or \"similarities,\" including the $\\ell_2$ metric, inner product, and cosine similarity. In addition, we conduct numerical simulation in a more achievable setting, where the ${m\\choose k}$ subset embeddings are chosen as the centroid of the embeddings of the contained elements. Our simulation easily realizes a logarithmic dependency between the MED and the number of elements to embed. These findings imply that embedding-based retrieval limitations stem primarily from learnability challenges, not geometric constraints, guiding future algorithm design.",
        "url": "http://arxiv.org/abs/2601.20844v2",
        "pdf_url": "https://arxiv.org/pdf/2601.20844v2",
        "arxiv_id": "2601.20844v2",
        "authors": [
            "Zihao Wang",
            "Hang Yin",
            "Lihui Liu",
            "Hanghang Tong",
            "Yangqiu Song",
            "Ginny Wong",
            "Simon See"
        ],
        "submitted": "2026-01-28 18:45:43",
        "source": "arxiv",
        "comment": "v2: fix broken citation",
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 3,
        "llm_reason": "This paper focuses on the theoretical aspects of embedding-based retrieval, specifically the minimal dimension required for subset memberships. While it touches on retrieval limitations, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The connection to information retrieval is indirect, making it only loosely relevant to the user's research interests."
    },
    {
        "title": "Jurisdiction as Structural Barrier: How Privacy Policy Organization May Reduce Visibility of Substantive Disclosures",
        "abstract": "Privacy policies are supposed to provide notice. But what if substantive information appears only where users skip it? We identify a structural pattern we call jurisdiction-siloed disclosure: information about data practices appearing in specific, actionable form only within regional compliance sections labeled \"California Residents\" or \"EU/UK Users,\" while general sections use vague or qualified language for the same practices.\n  Our audit of 123 major companies identifies 282 potential instances across 77 companies (62.6% of this purposive sample). A conservative estimate restricted to practice categories validated against OPP-115 human annotations finds 138 instances across 54 companies (44%); post-2018 categories central to our findings await independent validation. If users skip jurisdiction-labeled sections as information foraging theory predicts, users outside regulated jurisdictions would receive less specific information about practices affecting them--a transparency failure operating through document architecture rather than omission.\n  We propose universal substantive disclosure: practices affecting all users should appear in the main policy body, with regional sections containing only procedural rights information. This standard finds support in analogous disclosure regimes (securities, truth-in-lending, nutritional labeling) where material information must reach all affected parties. Regulators could operationalize this through the FTC's \"clear and conspicuous\" standard and GDPR transparency principles.\n  This work is hypothesis-generating: we establish that the structural pattern exists and ground the transparency concern in behavioral theory, but direct measurement of jurisdiction-specific section skipping remains the critical validation priority. We release our methodology and annotated dataset to enable replication.",
        "url": "http://arxiv.org/abs/2601.20792v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20792v1",
        "arxiv_id": "2601.20792v1",
        "authors": [
            "Thomas Brackin"
        ],
        "submitted": "2026-01-28 17:29:59",
        "source": "arxiv",
        "comment": "25 pages, 2 figures, 5 tables",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, which are core areas of your research interests. While it touches on user behavior modeling, it does so in the context of privacy policy organization and transparency, which is not a central match to your research focus."
    },
    {
        "title": "ShieldedCode: Learning Robust Representations for Virtual Machine Protected Code",
        "abstract": "Large language models (LLMs) have achieved remarkable progress in code generation, yet their potential for software protection remains largely untapped. Reverse engineering continues to threaten software security, while traditional virtual machine protection (VMP) relies on rigid, rule-based transformations that are costly to design and vulnerable to automated analysis. In this work, we present the first protection-aware framework that learns robust representations of VMP-protected code. Our approach builds large-scale paired datasets of source code and normalized VM implementations, and introduces hierarchical dependency modeling at intra-, preceding-, and inter-instruction levels. We jointly optimize language modeling with functionality-aware and protection-aware contrastive objectives to capture both semantic equivalence and protection strength. To further assess resilience, we propose a protection effectiveness optimization task that quantifies and ranks different VM variants derived from the same source. Coupled with a two-stage continual pre-training and fine-tuning pipeline, our method enables models to generate, compare, and reason over protected code. Extensive experiments show that our framework significantly improves robustness across diverse protection levels, opening a new research direction for learning-based software defense. In this work, we present ShieldedCode, the first protection-aware framework that learns robust representations of VMP-protected code. Our method achieves 26.95% Pass@1 on L0 VM code generation compared to 22.58% for GPT-4o., and improves binary similarity detection Recall@1 by 10% over state of art methods like jTrans.",
        "url": "http://arxiv.org/abs/2601.20679v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20679v1",
        "arxiv_id": "2601.20679v1",
        "authors": [
            "Mingqiao Mo",
            "Yunlong Tan",
            "Hao Zhang",
            "Heng Zhang",
            "Yangfan He"
        ],
        "submitted": "2026-01-28 15:07:08",
        "source": "arxiv",
        "comment": "Accepted to ICLR 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on software protection and virtual machine protection, which is unrelated to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves code generation and semantic understanding, the context is software security and protection, rather than search or retrieval."
    },
    {
        "title": "P2S: Probabilistic Process Supervision for General-Domain Reasoning Question Answering",
        "abstract": "While reinforcement learning with verifiable rewards (RLVR) has advanced LLM reasoning in structured domains like mathematics and programming, its application to general-domain reasoning tasks remains challenging due to the absence of verifiable reward signals. To this end, methods like Reinforcement Learning with Reference Probability Reward (RLPR) have emerged, leveraging the probability of generating the final answer as a reward signal. However, these outcome-focused approaches neglect crucial step-by-step supervision of the reasoning process itself. To address this gap, we introduce Probabilistic Process Supervision (P2S), a novel self-supervision framework that provides fine-grained process rewards without requiring a separate reward model or human-annotated reasoning steps. During reinforcement learning, P2S synthesizes and filters a high-quality reference reasoning chain (gold-CoT). The core of our method is to calculate a Path Faithfulness Reward (PFR) for each reasoning step, which is derived from the conditional probability of generating the gold-CoT's suffix, given the model's current reasoning prefix. Crucially, this PFR can be flexibly integrated with any outcome-based reward, directly tackling the reward sparsity problem by providing dense guidance. Extensive experiments on reading comprehension and medical Question Answering benchmarks show that P2S significantly outperforms strong baselines.",
        "url": "http://arxiv.org/abs/2601.20649v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20649v1",
        "arxiv_id": "2601.20649v1",
        "authors": [
            "Wenlin Zhong",
            "Chengyuan Liu",
            "Yiquan Wu",
            "Bovin Tan",
            "Changlong Sun",
            "Yi Wang",
            "Xiaozhong Liu",
            "Kun Kuang"
        ],
        "submitted": "2026-01-28 14:35:20",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper introduces a novel self-supervision framework, Probabilistic Process Supervision (P2S), for general-domain reasoning tasks. While it is related to the broader field of Natural Language Processing (NLP) and deep semantic understanding, it does not directly align with the user's core research themes in Information Retrieval (IR) and Search technologies. The paper's focus on reasoning question answering and process supervision is somewhat relevant to the user's interests in query understanding and ranking models, but it is not a central match."
    },
    {
        "title": "GDCNet: Generative Discrepancy Comparison Network for Multimodal Sarcasm Detection",
        "abstract": "Multimodal sarcasm detection (MSD) aims to identify sarcasm within image-text pairs by modeling semantic incongruities across modalities. Existing methods often exploit cross-modal embedding misalignment to detect inconsistency but struggle when visual and textual content are loosely related or semantically indirect. While recent approaches leverage large language models (LLMs) to generate sarcastic cues, the inherent diversity and subjectivity of these generations often introduce noise. To address these limitations, we propose the Generative Discrepancy Comparison Network (GDCNet). This framework captures cross-modal conflicts by utilizing descriptive, factually grounded image captions generated by Multimodal LLMs (MLLMs) as stable semantic anchors. Specifically, GDCNet computes semantic and sentiment discrepancies between the generated objective description and the original text, alongside measuring visual-textual fidelity. These discrepancy features are then fused with visual and textual representations via a gated module to adaptively balance modality contributions. Extensive experiments on MSD benchmarks demonstrate GDCNet's superior accuracy and robustness, establishing a new state-of-the-art on the MMSD2.0 benchmark.",
        "url": "http://arxiv.org/abs/2601.20618v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20618v1",
        "arxiv_id": "2601.20618v1",
        "authors": [
            "Shuguang Zhang",
            "Junhong Lian",
            "Guoxin Yu",
            "Baoxun Xu",
            "Xiang Ao"
        ],
        "submitted": "2026-01-28 13:51:34",
        "source": "arxiv",
        "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing, as it focuses on multimodal sarcasm detection and does not address query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "TABED: Test-Time Adaptive Ensemble Drafting for Robust Speculative Decoding in LVLMs",
        "abstract": "Speculative decoding (SD) has proven effective for accelerating LLM inference by quickly generating draft tokens and verifying them in parallel. However, SD remains largely unexplored for Large Vision-Language Models (LVLMs), which extend LLMs to process both image and text prompts. To address this gap, we benchmark existing inference methods with small draft models on 11 datasets across diverse input scenarios and observe scenario-specific performance fluctuations. Motivated by these findings, we propose Test-time Adaptive Batched Ensemble Drafting (TABED), which dynamically ensembles multiple drafts obtained via batch inference by leveraging deviations from past ground truths available in the SD setting. The dynamic ensemble method achieves an average robust walltime speedup of 1.74x over autoregressive decoding and a 5% improvement over single drafting methods, while remaining training-free and keeping ensembling costs negligible through parameter sharing. With its plug-and-play compatibility, we further enhance TABED by integrating advanced verification and alternative drafting methods. Code and custom-trained models are available at https://github.com/furiosa-ai/TABED.",
        "url": "http://arxiv.org/abs/2601.20357v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20357v1",
        "arxiv_id": "2601.20357v1",
        "authors": [
            "Minjae Lee",
            "Wonjun Kang",
            "Byeongkeun Ahn",
            "Christian Classen",
            "Kevin Galim",
            "Seunghyuk Oh",
            "Minghao Yan",
            "Hyung Il Koo",
            "Kangwook Lee"
        ],
        "submitted": "2026-01-28 08:16:57",
        "source": "arxiv",
        "comment": "Accepted to Findings of EACL 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on speculative decoding in Large Vision-Language Models (LVLMs), which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some form of model optimization, the context is primarily in computer vision and multimodal processing, making it less relevant to the user's interests."
    },
    {
        "title": "High-Resolution Mapping of Port Dynamics from Open-Access AIS Data in Tokyo Bay",
        "abstract": "Knowledge about vessel activity in port areas and around major industrial zones provides insights into economic trends, supports decision-making for shipping and port operators, and contributes to maritime safety. Vessel data from terrestrial receivers of the Automatic Identification System (AIS) have become increasingly openly available, and we demonstrate that such data can be used to infer port activities at high resolution and with precision comparable to official statistics. We analyze open-access AIS data from a three-month period in 2024 for Tokyo Bay, located in Japan's most densely populated urban region. Accounting for uneven data coverage, we reconstruct vessel activity in Tokyo Bay at $\\sim\\,$30~m resolution and identify 161 active berths across seven major port areas in the bay. During the analysis period, we find an average of $35\\pm17_{\\text{stat}}$ vessels moving within the bay at any given time, and $293\\pm22_{\\text{stat}}+65_{\\text{syst}}-10_{\\text{syst}}$ vessels entering or leaving the bay daily, with an average gross tonnage of $11{,}860^{+280}_{-\\;\\,50}$. These figures indicate an accelerating long-term trend toward fewer but larger vessels in Tokyo Bay's commercial traffic. Furthermore, we find that in dense urban environments, radio shadows in vessel AIS data can reveal the precise locations of inherently passive receiver stations.",
        "url": "http://arxiv.org/abs/2601.20211v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20211v1",
        "arxiv_id": "2601.20211v1",
        "authors": [
            "Moritz H√ºtten"
        ],
        "submitted": "2026-01-28 03:22:13",
        "source": "arxiv",
        "comment": "29 pages, 18 figures, and 7 tables, matching the version published in Geomatics. Accompanying research data are available at https://dx.doi.org/10.6084/m9.figshare.29037401",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, data mining, or recommender systems. The paper focuses on analyzing vessel activity in Tokyo Bay using AIS data, which is outside your areas of interest."
    },
    {
        "title": "Spark: Strategic Policy-Aware Exploration via Dynamic Branching for Long-Horizon Agentic Learning",
        "abstract": "Reinforcement learning has empowered large language models to act as intelligent agents, yet training them for long-horizon tasks remains challenging due to the scarcity of high-quality trajectories, especially under limited resources. Existing methods typically scale up rollout sizes and indiscriminately allocate computational resources among intermediate steps. Such attempts inherently waste substantial computation budget on trivial steps while failing to guarantee sample quality. To address this, we propose \\textbf{Spark} (\\textbf{S}trategic \\textbf{P}olicy-\\textbf{A}ware explo\\textbf{R}ation via \\textbf{K}ey-state dynamic branching), a novel framework that selectively branches at critical decision states for resource-efficient exploration. Our key insight is to activate adaptive branching exploration at critical decision points to probe promising trajectories, thereby achieving precise resource allocation that prioritizes sampling quality over blind coverage. This design leverages the agent's intrinsic decision-making signals to reduce dependence on human priors, enabling the agent to autonomously expand exploration and achieve stronger generalization. Experiments across diverse tasks (e.g., embodied planning), demonstrate that \\textsc{Spark} achieves superior success rates with significantly fewer training samples, exhibiting robust generalization even in unseen scenarios.",
        "url": "http://arxiv.org/abs/2601.20209v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20209v1",
        "arxiv_id": "2601.20209v1",
        "authors": [
            "Jinyang Wu",
            "Shuo Yang",
            "Changpeng Yang",
            "Yuhao Shen",
            "Shuai Zhang",
            "Zhengqi Wen",
            "Jianhua Tao"
        ],
        "submitted": "2026-01-28 03:15:34",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on reinforcement learning and long-horizon tasks, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves intelligent agents and decision-making, the context and application are quite different from the user's areas of expertise."
    },
    {
        "title": "Post-Training Fairness Control: A Single-Train Framework for Dynamic Fairness in Recommendation",
        "abstract": "Despite growing efforts to mitigate unfairness in recommender systems, existing fairness-aware methods typically fix the fairness requirement at training time and provide limited post-training flexibility. However, in real-world scenarios, diverse stakeholders may demand differing fairness requirements over time, so retraining for different fairness requirements becomes prohibitive. To address this limitation, we propose Cofair, a single-train framework that enables post-training fairness control in recommendation. Specifically, Cofair introduces a shared representation layer with fairness-conditioned adapter modules to produce user embeddings specialized for varied fairness levels, along with a user-level regularization term that guarantees user-wise monotonic fairness improvements across these levels. We theoretically establish that the adversarial objective of Cofair upper bounds demographic parity and the regularization term enforces progressive fairness at user level. Comprehensive experiments on multiple datasets and backbone models demonstrate that our framework provides dynamic fairness at different levels, delivering comparable or better fairness-accuracy curves than state-of-the-art baselines, without the need to retrain for each new fairness requirement. Our code is publicly available at https://github.com/weixinchen98/Cofair.",
        "url": "http://arxiv.org/abs/2601.20848v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20848v1",
        "arxiv_id": "2601.20848v1",
        "authors": [
            "Weixin Chen",
            "Li Chen",
            "Yuhan Zhao"
        ],
        "submitted": "2026-01-28 18:48:43",
        "source": "arxiv",
        "comment": "Accepted to WWW 2026 Workshop on HCRS (Oral Presentation)",
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on fairness in recommender systems, which is somewhat related to information retrieval, but the primary focus is on recommendation rather than search. The use of deep semantic understanding and real-time relevance optimization is not directly addressed, but the paper does explore a relevant aspect of recommendation systems."
    },
    {
        "title": "Linear representations in language models can change dramatically over a conversation",
        "abstract": "Language model representations often contain linear directions that correspond to high-level concepts. Here, we study the dynamics of these representations: how representations evolve along these dimensions within the context of (simulated) conversations. We find that linear representations can change dramatically over a conversation; for example, information that is represented as factual at the beginning of a conversation can be represented as non-factual at the end and vice versa. These changes are content-dependent; while representations of conversation-relevant information may change, generic information is generally preserved. These changes are robust even for dimensions that disentangle factuality from more superficial response patterns, and occur across different model families and layers of the model. These representation changes do not require on-policy conversations; even replaying a conversation script written by an entirely different model can produce similar changes. However, adaptation is much weaker from simply having a sci-fi story in context that is framed more explicitly as such. We also show that steering along a representational direction can have dramatically different effects at different points in a conversation. These results are consistent with the idea that representations may evolve in response to the model playing a particular role that is cued by a conversation. Our findings may pose challenges for interpretability and steering -- in particular, they imply that it may be misleading to use static interpretations of features or directions, or probes that assume a particular range of features consistently corresponds to a particular ground-truth value. However, these types of representational dynamics also point to exciting new research directions for understanding how models adapt to context.",
        "url": "http://arxiv.org/abs/2601.20834v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20834v1",
        "arxiv_id": "2601.20834v1",
        "authors": [
            "Andrew Kyle Lampinen",
            "Yuxuan Li",
            "Eghbal Hosseini",
            "Sangnie Bhardwaj",
            "Murray Shanahan"
        ],
        "submitted": "2026-01-28 18:33:17",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the dynamics of language model representations, specifically how they change over a conversation. While it touches on aspects of deep semantic understanding, it is primarily focused on the interpretability and steering of language models, which is somewhat related to your research interests in Information Retrieval and NLP. However, the specific context of conversation dynamics and representation changes in language models is not a central match for your core research themes."
    },
    {
        "title": "SERA: Soft-Verified Efficient Repository Agents",
        "abstract": "Open-weight coding agents should hold a fundamental advantage over closed-source systems: they can be specialized to private codebases, encoding repository-specific information directly in their weights. Yet the cost and complexity of training has kept this advantage theoretical. We show it is now practical. We present Soft-Verified Efficient Repository Agents (SERA), an efficient method for training coding agents that enables the rapid and cheap creation of agents specialized to private codebases. Using only supervised finetuning (SFT), SERA achieves state-of-the-art results among fully open-source (open data, method, code) models while matching the performance of frontier open-weight models like Devstral-Small-2. Creating SERA models is 26x cheaper than reinforcement learning and 57x cheaper than previous synthetic data methods to reach equivalent performance. Our method, Soft Verified Generation (SVG), generates thousands of trajectories from a single code repository. Combined with cost-efficiency, this enables specialization to private codebases. Beyond repository specialization, we apply SVG to a larger corpus of codebases, generating over 200,000 synthetic trajectories. We use this dataset to provide detailed analysis of scaling laws, ablations, and confounding factors for training coding agents. Overall, we believe our work will greatly accelerate research on open coding agents and showcase the advantage of open-source models that can specialize to private codebases. We release SERA as the first model in Ai2's Open Coding Agents series, along with all our code, data, and Claude Code integration to support the research community.",
        "url": "http://arxiv.org/abs/2601.20789v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20789v1",
        "arxiv_id": "2601.20789v1",
        "authors": [
            "Ethan Shen",
            "Danny Tormoen",
            "Saurabh Shah",
            "Ali Farhadi",
            "Tim Dettmers"
        ],
        "submitted": "2026-01-28 17:27:08",
        "source": "arxiv",
        "comment": "21 main pages, 7 pages appendix",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or user behavior modeling, which are the core areas of your research interests. While it touches on NLP and data mining, the focus is on open-source coding agents and their applications, which does not align closely with your primary research themes."
    },
    {
        "title": "Online Density-Based Clustering for Real-Time Narrative Evolution Monitorin",
        "abstract": "Automated narrative intelligence systems for social media monitoring face significant scalability challenges when processing continuous data streams using traditional batch clustering algorithms. We investigate the replacement of HDBSCAN (offline clustering) with online (streaming/incremental) clustering methods in a production narrative report generation pipeline. The proposed system employs a three-stage architecture (data collection, modeling, dashboard generation) that processes thousands of multilingual social media documents daily. While HDBSCAN excels at discovering hierarchical density-based clusters and handling noise, its batch-only nature necessitates complete retraining for each time window, resulting in memory constraints, computational inefficiency, and inability to adapt to evolving narratives in real-time. This work evaluates a bunch of online clustering algorithms across dimensions of cluster quality preservation, computational efficiency, memory footprint, and integration compatibility with existing workflows. We propose evaluation criteria that balance traditional clustering metrics (Silhouette Coefficient, Davies-Bouldin Index) with narrative metrics (narrative distinctness, contingency and variance). Our methodology includes sliding-window simulations on historical datasets from Ukraine information space, enabling comparative analysis of algorithmic trade-offs in realistic operational contexts. This research addresses a critical gap between batch-oriented topic modeling frameworks and the streaming nature of social media monitoring, with implications for computational social science, crisis informatics, and narrative surveillance systems.",
        "url": "http://arxiv.org/abs/2601.20680v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20680v1",
        "arxiv_id": "2601.20680v1",
        "authors": [
            "Ostap Vykhopen",
            "Viktoria Skorik",
            "Maxim Tereschenko",
            "Veronika Solopova"
        ],
        "submitted": "2026-01-28 15:07:30",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to information retrieval, but its focus on clustering and narrative intelligence systems for social media monitoring is not directly aligned with your core research themes in query understanding, ranking models, and user behavior modeling. While it touches on real-time relevance optimization, the context is different from your typical e-commerce domain, and the paper's emphasis on clustering and narrative metrics is not central to your interests."
    },
    {
        "title": "AgentIF-OneDay: A Task-level Instruction-Following Benchmark for General AI Agents in Daily Scenarios",
        "abstract": "The capacity of AI agents to effectively handle tasks of increasing duration and complexity continues to grow, demonstrating exceptional performance in coding, deep research, and complex problem-solving evaluations. However, in daily scenarios, the perception of these advanced AI capabilities among general users remains limited. We argue that current evaluations prioritize increasing task difficulty without sufficiently addressing the diversity of agentic tasks necessary to cover the daily work, life, and learning activities of a broad demographic. To address this, we propose AgentIF-OneDay, aimed at determining whether general users can utilize natural language instructions and AI agents to complete a diverse array of daily tasks. These tasks require not only solving problems through dialogue but also understanding various attachment types and delivering tangible file-based results. The benchmark is structured around three user-centric categories: Open Workflow Execution, which assesses adherence to explicit and complex workflows; Latent Instruction, which requires agents to infer implicit instructions from attachments; and Iterative Refinement, which involves modifying or expanding upon ongoing work. We employ instance-level rubrics and a refined evaluation pipeline that aligns LLM-based verification with human judgment, achieving an 80.1% agreement rate using Gemini-3-Pro. AgentIF-OneDay comprises 104 tasks covering 767 scoring points. We benchmarked four leading general AI agents and found that agent products built based on APIs and ChatGPT agents based on agent RL remain in the first tier simultaneously. Leading LLM APIs and open-source models have internalized agentic capabilities, enabling AI application teams to develop cutting-edge Agent products.",
        "url": "http://arxiv.org/abs/2601.20613v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20613v1",
        "arxiv_id": "2601.20613v1",
        "authors": [
            "Kaiyuan Chen",
            "Qimin Wu",
            "Taiyu Hou",
            "Tianhao Tang",
            "Xueyu Hu",
            "Yuchen Hou",
            "Bikun Li",
            "Chengming Qian",
            "Guoyin Wang",
            "Haolin Chen",
            "Haotong Tian",
            "Haoye Zhang",
            "Haoyu Bian",
            "Hongbing Pan",
            "Hongkang Zhang",
            "Hongyi Zhou",
            "Jiaqi Cai",
            "Jiewu Rao",
            "Jiyuan Ren",
            "Keduan Huang",
            "Lucia Zhu Huang",
            "Mingyu Yuan",
            "Naixu Guo",
            "Qicheng Tang",
            "Qinyan Zhang",
            "Shuai Chen",
            "Siheng Chen",
            "Ting Ting Li",
            "Xiaoxing Guo",
            "Yaocheng Zuo",
            "Yaoqi Guo",
            "Yinan Wang",
            "Yinzhou Yu",
            "Yize Wang",
            "Yuan Jiang",
            "Yuan Tian",
            "Yuanshuo Zhang",
            "Yuxuan Liu",
            "Yvette Yan Zeng",
            "Zenyu Shan",
            "Zihan Yin",
            "Xiaobo Hu",
            "Yang Liu",
            "Yixin Ren",
            "Yuan Gong"
        ],
        "submitted": "2026-01-28 13:49:18",
        "source": "arxiv",
        "comment": "17 pages, 8 figures",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves AI agents and natural language instructions, the focus is on task-level instruction-following and general AI capabilities, which is not a central match to your core research themes."
    },
    {
        "title": "PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs",
        "abstract": "Large Language Models (LLMs) have enabled automated heuristic design (AHD) for combinatorial optimization problems (COPs), but existing frameworks' reliance on fixed evolutionary rules and static prompt templates often leads to myopic heuristic generation, redundant evaluations, and limited reasoning about how new heuristics should be derived. We propose a novel multi-agent reasoning framework, referred to as Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs (PathWise), which formulates heuristic generation as a sequential decision process over an entailment graph serving as a compact, stateful memory of the search trajectory. This approach allows the system to carry forward past decisions and reuse or avoid derivation information across generations. A policy agent plans evolutionary actions, a world model agent generates heuristic rollouts conditioned on those actions, and critic agents provide routed reflections summarizing lessons from prior steps, shifting LLM-based AHD from trial-and-error evolution toward state-aware planning through reasoning. Experiments across diverse COPs show that PathWise converges faster to better heuristics, generalizes across different LLM backbones, and scales to larger problem sizes.",
        "url": "http://arxiv.org/abs/2601.20539v2",
        "pdf_url": "https://arxiv.org/pdf/2601.20539v2",
        "arxiv_id": "2601.20539v2",
        "authors": [
            "Oguzhan Gungordu",
            "Siheng Xiong",
            "Faramarz Fekri"
        ],
        "submitted": "2026-01-28 12:34:50",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves Large Language Models (LLMs), the focus is on automated heuristic design for combinatorial optimization problems, which is outside your primary areas of interest."
    },
    {
        "title": "MuVaC: AVariational Causal Framework for Multimodal Sarcasm Understanding in Dialogues",
        "abstract": "The prevalence of sarcasm in multimodal dialogues on the social platforms presents a crucial yet challenging task for understanding the true intent behind online content. Comprehensive sarcasm analysis requires two key aspects: Multimodal Sarcasm Detection (MSD) and Multimodal Sarcasm Explanation (MuSE). Intuitively, the act of detection is the result of the reasoning process that explains the sarcasm. Current research predominantly focuses on addressing either MSD or MuSE as a single task. Even though some recent work has attempted to integrate these tasks, their inherent causal dependency is often overlooked. To bridge this gap, we propose MuVaC, a variational causal inference framework that mimics human cognitive mechanisms for understanding sarcasm, enabling robust multimodal feature learning to jointly optimize MSD and MuSE. Specifically, we first model MSD and MuSE from the perspective of structural causal models, establishing variational causal pathways to define the objectives for joint optimization. Next, we design an alignment-then-fusion approach to integrate multimodal features, providing robust fusion representations for sarcasm detection and explanation generation. Finally, we enhance the reasoning trustworthiness by ensuring consistency between detection results and explanations. Experimental results demonstrate the superiority of MuVaC in public datasets, offering a new perspective for understanding multimodal sarcasm.",
        "url": "http://arxiv.org/abs/2601.20451v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20451v1",
        "arxiv_id": "2601.20451v1",
        "authors": [
            "Diandian Guo",
            "Fangfang Yuan",
            "Cong Cao",
            "Xixun Lin",
            "Chuan Zhou",
            "Hao Peng",
            "Yanan Cao",
            "Yanbing Liu"
        ],
        "submitted": "2026-01-28 10:19:42",
        "source": "arxiv",
        "comment": "12 pages, 7 figures. Accepted by WWW 2026",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multimodal sarcasm understanding in dialogues, which is a topic outside of the user's primary research interests in Information Retrieval and Search technologies. While it involves some aspects of Natural Language Processing, the paper's emphasis on multimodal feature learning and variational causal inference does not align with the user's core research themes."
    },
    {
        "title": "Hopes and Fears -- Emotion Distribution in the Topic Landscape of Finnish Parliamentary Speech 2000-2020",
        "abstract": "Existing research often treats parliamentary discourse as a homogeneous whole, overlooking topic-specific patterns. Parliamentary speeches address a wide range of topics, some of which evoke stronger emotions than others. While everyone has intuitive assumptions about what the most emotive topics in a parliament may be, there has been little research into the emotions typically linked to different topics. This paper strives to fill this gap by examining emotion expression among the topics of parliamentary speeches delivered in Eduskunta, the Finnish Parliament, between 2000 and 2020. An emotion analysis model is used to investigate emotion expression in topics, from both synchronic and diachronic perspectives. The results strengthen evidence of increasing positivity in parliamentary speech and provide further insights into topic-specific emotion expression within parliamentary debate.",
        "url": "http://arxiv.org/abs/2601.20424v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20424v1",
        "arxiv_id": "2601.20424v1",
        "authors": [
            "Anna Ristil√§",
            "Otto Tarkka",
            "Veronika Laippala",
            "Kimmo Elo"
        ],
        "submitted": "2026-01-28 09:32:41",
        "source": "arxiv",
        "comment": "27 pages (40 including appendices), 5 figures (13 including sub-figures), 1 table, 1 formula, 3 appendices; submitted to JDMDH",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on analyzing emotions in parliamentary speeches, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve text analysis, the specific topic and methodology seem to be outside your primary areas of focus."
    },
    {
        "title": "Improving Diffusion Language Model Decoding through Joint Search in Generation Order and Token Space",
        "abstract": "Diffusion Language Models (DLMs) offer order-agnostic generation that can explore many possible decoding trajectories. However, current decoding methods commit to a single trajectory, limiting exploration in trajectory space. We introduce Order-Token Search to explore this space through jointly searching over generation order and token values. Its core is a likelihood estimator that scores denoising actions, enabling stable pruning and efficient exploration of diverse trajectories. Across mathematical reasoning and coding benchmarks, Order-Token Search consistently outperforms baselines on GSM8K, MATH500, Countdown, and HumanEval (3.1%, 3.8%, 7.9%, and 6.8% absolute over backbone), matching or surpassing diffu-GRPO post-trained d1-LLaDA. Our work establishes joint search as a key component for advancing decoding in DLMs.",
        "url": "http://arxiv.org/abs/2601.20339v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20339v1",
        "arxiv_id": "2601.20339v1",
        "authors": [
            "Yangyi Shen",
            "Tianjian Feng",
            "Jiaqi Han",
            "Wen Wang",
            "Tianlang Chen",
            "Chunhua Shen",
            "Jure Leskovec",
            "Stefano Ermon"
        ],
        "submitted": "2026-01-28 07:55:07",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on improving diffusion language models through joint search in generation order and token space, which is a topic in Natural Language Processing (NLP). While it explores search and optimization techniques, it does not directly relate to information retrieval, query understanding, ranking models, or user behavior modeling, which are the core areas of your research interests."
    },
    {
        "title": "Beyond Speedup -- Utilizing KV Cache for Sampling and Reasoning",
        "abstract": "KV caches, typically used only to speed up autoregressive decoding, encode contextual information that can be reused for downstream tasks at no extra cost. We propose treating the KV cache as a lightweight representation, eliminating the need to recompute or store full hidden states. Despite being weaker than dedicated embeddings, KV-derived representations are shown to be sufficient for two key applications: \\textbf{(i) Chain-of-Embedding}, where they achieve competitive or superior performance on Llama-3.1-8B-Instruct and Qwen2-7B-Instruct; and \\textbf{(ii) Fast/Slow Thinking Switching}, where they enable adaptive reasoning on Qwen3-8B and DeepSeek-R1-Distil-Qwen-14B, reducing token generation by up to $5.7\\times$ with minimal accuracy loss. Our findings establish KV caches as a free, effective substrate for sampling and reasoning, opening new directions for representation reuse in LLM inference. Code: https://github.com/cmd2001/ICLR2026_KV-Embedding.",
        "url": "http://arxiv.org/abs/2601.20326v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20326v1",
        "arxiv_id": "2601.20326v1",
        "authors": [
            "Zeyu Xing",
            "Xing Li",
            "Hui-Ling Zhen",
            "Mingxuan Yuan",
            "Sinno Jialin Pan"
        ],
        "submitted": "2026-01-28 07:44:52",
        "source": "arxiv",
        "comment": "Accepted by ICLR26",
        "score": 1,
        "keyword_reasons": [
            "Found 'iclr' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on utilizing KV cache for sampling and reasoning in large language models, which is a topic related to NLP. However, it does not directly relate to information retrieval, query understanding, ranking models, or user behavior modeling, which are the core areas of your research interests."
    },
    {
        "title": "Less is More: Benchmarking LLM Based Recommendation Agents",
        "abstract": "Large Language Models (LLMs) are increasingly deployed for personalized product recommendations, with practitioners commonly assuming that longer user purchase histories lead to better predictions. We challenge this assumption through a systematic benchmark of four state of the art LLMs GPT-4o-mini, DeepSeek-V3, Qwen2.5-72B, and Gemini 2.5 Flash across context lengths ranging from 5 to 50 items using the REGEN dataset.\n  Surprisingly, our experiments with 50 users in a within subject design reveal no significant quality improvement with increased context length. Quality scores remain flat across all conditions (0.17--0.23). Our findings have significant practical implications: practitioners can reduce inference costs by approximately 88\\% by using context (5--10 items) instead of longer histories (50 items), without sacrificing recommendation quality. We also analyze latency patterns across providers and find model specific behaviors that inform deployment decisions. This work challenges the existing ``more context is better'' paradigm and provides actionable guidelines for cost effective LLM based recommendation systems.",
        "url": "http://arxiv.org/abs/2601.20316v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20316v1",
        "arxiv_id": "2601.20316v1",
        "authors": [
            "Kargi Chauhan",
            "Mahalakshmi Venkateswarlu"
        ],
        "submitted": "2026-01-28 07:08:51",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval and Search technologies, but it focuses on recommender systems, which is a secondary interest. The paper's emphasis on Large Language Models and their applications in e-commerce is relevant, but the specific context of recommendation systems and the lack of focus on query understanding and ranking models limit its alignment with your primary research themes."
    },
    {
        "title": "MiLorE-SSL: Scaling Multilingual Capabilities in Self-Supervised Models without Forgetting",
        "abstract": "Self-supervised learning (SSL) has greatly advanced speech representation learning, but multilingual SSL models remain constrained to languages encountered during pretraining. Retraining from scratch to incorporate new languages is computationally expensive, while sequential training without migitation strategies often leads to catastrophic forgetting. To address this, we propose MiLorE-SSL, a lightweight framework that combines LoRA modules with a soft mixture-of-experts (MoE) mechanism for efficient continual multilingual training. LoRA provides efficient low-rank adaptation, while soft MoE promotes flexible expert sharing across languages, reducing cross-lingual interference. To further mitigate forgetting, we introduce limited replay data from existing languages, avoiding reliance on large historical corpora. Experiments on ML-SUPERB demonstrate that MiLorE-SSL achieves strong performance in new languages and improves the ability in existing ones with only 2.14% trainable parameters.",
        "url": "http://arxiv.org/abs/2601.20300v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20300v1",
        "arxiv_id": "2601.20300v1",
        "authors": [
            "Jing Xu",
            "Minglin Wu",
            "Xueyuan Chen",
            "Xixin Wu",
            "Helen Meng"
        ],
        "submitted": "2026-01-28 06:48:52",
        "source": "arxiv",
        "comment": "Accepted by ICASSP2026",
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on self-supervised learning and multilingual capabilities in speech representation learning, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some machine learning concepts, the topic is more specific to speech and does not align with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Truthfulness Despite Weak Supervision: Evaluating and Training LLMs Using Peer Prediction",
        "abstract": "The evaluation and post-training of large language models (LLMs) rely on supervision, but strong supervision for difficult tasks is often unavailable, especially when evaluating frontier models. In such cases, models are demonstrated to exploit evaluations built on such imperfect supervision, leading to deceptive results. However, underutilized in LLM research, a wealth of mechanism design research focuses on game-theoretic incentive compatibility, i.e., eliciting honest and informative answers with weak supervision. Drawing from this literature, we introduce the peer prediction method for model evaluation and post-training. It rewards honest and informative answers over deceptive and uninformative ones, using a metric based on mutual predictability and without requiring ground truth labels. We demonstrate the method's effectiveness and resistance to deception, with both theoretical guarantees and empirical validation on models with up to 405B parameters. We show that training an 8B model with peer prediction-based reward recovers most of the drop in truthfulness due to prior malicious finetuning, even when the reward is produced by a 0.135B language model with no finetuning. On the evaluation front, in contrast to LLM-as-a-Judge which requires strong and trusted judges, we discover an inverse scaling property in peer prediction, where, surprisingly, resistance to deception is strengthened as the capability gap between the experts and participants widens, enabling reliable evaluation of strong models with weak supervision. In particular, LLM-as-a-Judge become worse than random guess when facing deceptive models 5-20x the judge's size, while peer prediction thrives when such gaps are large, including in cases with over 100x size difference.",
        "url": "http://arxiv.org/abs/2601.20299v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20299v1",
        "arxiv_id": "2601.20299v1",
        "authors": [
            "Tianyi Alex Qiu",
            "Micah Carroll",
            "Cameron Allen"
        ],
        "submitted": "2026-01-28 06:47:46",
        "source": "arxiv",
        "comment": "ICLR 2026",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on evaluating and training large language models using peer prediction, which is a game-theoretic approach to elicit honest and informative answers with weak supervision. While it touches on aspects of model evaluation and post-training, it is not directly related to information retrieval, search technologies, or query understanding, which are core areas of your research interests."
    },
    {
        "title": "RusLICA: A Russian-Language Platform for Automated Linguistic Inquiry and Category Analysis",
        "abstract": "Defining psycholinguistic characteristics in written texts is a task gaining increasing attention from researchers. One of the most widely used tools in the current field is Linguistic Inquiry and Word Count (LIWC) that originally was developed to analyze English texts and translated into multiple languages. Our approach offers the adaptation of LIWC methodology for the Russian language, considering its grammatical and cultural specificities. The suggested approach comprises 96 categories, integrating syntactic, morphological, lexical, general statistical features, and results of predictions obtained using pre-trained language models (LMs) for text analysis. Rather than applying direct translation to existing thesauri, we built the dictionary specifically for the Russian language based on the content from several lexicographic resources, semantic dictionaries and corpora. The paper describes the process of mapping lemmas to 42 psycholinguistic categories and the implementation of the analyzer as part of RusLICA web service.",
        "url": "http://arxiv.org/abs/2601.20275v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20275v1",
        "arxiv_id": "2601.20275v1",
        "authors": [
            "Elina Sigdel",
            "Anastasia Panfilova"
        ],
        "submitted": "2026-01-28 05:43:40",
        "source": "arxiv",
        "comment": "The link to the platform: https://ruslica.ipran.ru",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on linguistic analysis and category adaptation for the Russian language, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves text analysis, it does not seem to address query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's interests."
    },
    {
        "title": "Unit-Based Agent for Semi-Cascaded Full-Duplex Dialogue Systems",
        "abstract": "Full-duplex voice interaction is crucial for natural human computer interaction. We present a framework that decomposes complex dialogue into minimal conversational units, enabling the system to process each unit independently and predict when to transit to the next. This framework is instantiated as a semi-cascaded full-duplex dialogue system built around a multimodal large language model, supported by auxiliary modules such as voice activity detection (VAD) and text-to-speech (TTS) synthesis. The resulting system operates in a train-free, plug-and-play manner. Experiments on the HumDial dataset demonstrate the effectiveness of our framework, which ranks second among all teams on the test set of the Human-like Spoken Dialogue Systems Challenge (Track 2: Full-Duplex Interaction). Code is available at the GitHub repository https://github.com/yu-haoyuan/fd-badcat.",
        "url": "http://arxiv.org/abs/2601.20230v2",
        "pdf_url": "https://arxiv.org/pdf/2601.20230v2",
        "arxiv_id": "2601.20230v2",
        "authors": [
            "Haoyuan Yu",
            "Yuxuan Chen",
            "Minjie Cai"
        ],
        "submitted": "2026-01-28 04:00:37",
        "source": "arxiv",
        "comment": "ICASSP 2026 (Grant Challenge). https://github.com/yu-haoyuan/fd-badcat",
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on dialogue systems and multimodal large language models, which is somewhat related to Natural Language Processing (NLP), but it does not directly align with the user's core research themes in Information Retrieval (IR), query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "MERGE: Next-Generation Item Indexing Paradigm for Large-Scale Streaming Recommendation",
        "abstract": "Item indexing, which maps a large corpus of items into compact discrete representations, is critical for both discriminative and generative recommender systems, yet existing Vector Quantization (VQ)-based approaches struggle with the highly skewed and non-stationary item distributions common in streaming industry recommenders, leading to poor assignment accuracy, imbalanced cluster occupancy, and insufficient cluster separation. To address these challenges, we propose MERGE, a next-generation item indexing paradigm that adaptively constructs clusters from scratch, dynamically monitors cluster occupancy, and forms hierarchical index structures via fine-to-coarse merging. Extensive experiments demonstrate that MERGE significantly improves assignment accuracy, cluster uniformity, and cluster separation compared with existing indexing methods, while online A/B tests show substantial gains in key business metrics, highlighting its potential as a foundational indexing approach for large-scale recommendation.",
        "url": "http://arxiv.org/abs/2601.20199v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20199v1",
        "arxiv_id": "2601.20199v1",
        "authors": [
            "Jing Yan",
            "Yimeng Bai",
            "Zongyu Liu",
            "Yahui Liu",
            "Junwei Wang",
            "Jingze Huang",
            "Haoda Li",
            "Sihao Ding",
            "Shaohui Ruan",
            "Yang Zhang"
        ],
        "submitted": "2026-01-28 02:56:30",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on item indexing for recommender systems, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the specific context of recommender systems and item indexing is not a central match to your primary focus on query understanding, ranking models, and user behavior modeling. The paper's emphasis on deep semantic understanding and real-time relevance optimization is not explicitly mentioned, but the use of hierarchical index structures and fine-to-coarse merging is an interesting aspect that might be relevant to your broader interests in NLP and data mining."
    },
    {
        "title": "Me-Agent: A Personalized Mobile Agent with Two-Level User Habit Learning for Enhanced Interaction",
        "abstract": "Large Language Model (LLM)-based mobile agents have made significant performance advancements. However, these agents often follow explicit user instructions while overlooking personalized needs, leading to significant limitations for real users, particularly without personalized context: (1) inability to interpret ambiguous instructions, (2) lack of learning from user interaction history, and (3) failure to handle personalized instructions. To alleviate the above challenges, we propose Me-Agent, a learnable and memorable personalized mobile agent. Specifically, Me-Agent incorporates a two-level user habit learning approach. At the prompt level, we design a user preference learning strategy enhanced with a Personal Reward Model to improve personalization performance. At the memory level, we design a Hierarchical Preference Memory, which stores users' long-term memory and app-specific memory in different level memory. To validate the personalization capabilities of mobile agents, we introduce User FingerTip, a new benchmark featuring numerous ambiguous instructions for daily life. Extensive experiments on User FingerTip and general benchmarks demonstrate that Me-Agent achieves state-of-the-art performance in personalization while maintaining competitive instruction execution performance.",
        "url": "http://arxiv.org/abs/2601.20162v1",
        "pdf_url": "https://arxiv.org/pdf/2601.20162v1",
        "arxiv_id": "2601.20162v1",
        "authors": [
            "Shuoxin Wang",
            "Chang Liu",
            "Gowen Loo",
            "Lifan Zheng",
            "Kaiwen Wei",
            "Xinyi Zeng",
            "Jingyuan Zhang",
            "Yu Tian"
        ],
        "submitted": "2026-01-28 01:44:19",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper proposes a personalized mobile agent with a two-level user habit learning approach, which shows some relevance to user behavior modeling and query understanding. However, the focus is on mobile agents and user habit learning, which is not a central match to your primary research interests in Information Retrieval and Search technologies. The paper's emphasis on Natural Language Processing (NLP) is also a positive aspect, but it's not enough to elevate the score."
    }
]