[
    {
        "title": "A Data-Centric Approach to Multilingual E-Commerce Product Search: Case Study on Query-Category and Query-Item Relevance",
        "abstract": "Multilingual e-commerce search suffers from severe data imbalance across\nlanguages, label noise, and limited supervision for low-resource\nlanguages--challenges that impede the cross-lingual generalization of relevance\nmodels despite the strong capabilities of large language models (LLMs). In this\nwork, we present a practical, architecture-agnostic, data-centric framework to\nenhance performance on two core tasks: Query-Category (QC) relevance (matching\nqueries to product categories) and Query-Item (QI) relevance (matching queries\nto product titles). Rather than altering the model, we redesign the training\ndata through three complementary strategies: (1) translation-based augmentation\nto synthesize examples for languages absent in training, (2) semantic negative\nsampling to generate hard negatives and mitigate class imbalance, and (3)\nself-validation filtering to detect and remove likely mislabeled instances.\nEvaluated on the CIKM AnalytiCup 2025 dataset, our approach consistently yields\nsubstantial F1 score improvements over strong LLM baselines, achieving\ncompetitive results in the official competition. Our findings demonstrate that\nsystematic data engineering can be as impactful as--and often more deployable\nthan--complex model modifications, offering actionable guidance for building\nrobust multilingual search systems in the real-world e-commerce settings.",
        "url": "http://arxiv.org/abs/2510.21671v1",
        "pdf_url": "http://arxiv.org/pdf/2510.21671v1",
        "arxiv_id": "2510.21671v1",
        "authors": [
            "Yabo Yin",
            "Yang Xi",
            "Jialong Wang",
            "Shanqi Wang",
            "Jiateng Hu"
        ],
        "submitted": "2025-10-24 17:27:35",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "AstaBench: Rigorous Benchmarking of AI Agents with a Scientific Research Suite",
        "abstract": "AI agents hold the potential to revolutionize scientific productivity by\nautomating literature reviews, replicating experiments, analyzing data, and\neven proposing new directions of inquiry; indeed, there are now many such\nagents, ranging from general-purpose \"deep research\" systems to specialized\nscience-specific agents, such as AI Scientist and AIGS. Rigorous evaluation of\nthese agents is critical for progress. Yet existing benchmarks fall short on\nseveral fronts: they (1) fail to provide holistic, product-informed measures of\nreal-world use cases such as science research; (2) lack reproducible agent\ntools necessary for a controlled comparison of core agentic capabilities; (3)\ndo not account for confounding variables such as model cost and tool access;\n(4) do not provide standardized interfaces for quick agent prototyping and\nevaluation; and (5) lack comprehensive baseline agents necessary to identify\ntrue advances. In response, we define principles and tooling for more\nrigorously benchmarking agents. Using these, we present AstaBench, a suite that\nprovides the first holistic measure of agentic ability to perform scientific\nresearch, comprising 2400+ problems spanning the entire scientific discovery\nprocess and multiple scientific domains, and including many problems inspired\nby actual user requests to deployed Asta agents. Our suite comes with the first\nscientific research environment with production-grade search tools that enable\ncontrolled, reproducible evaluation, better accounting for confounders.\nAlongside, we provide a comprehensive suite of nine science-optimized classes\nof Asta agents and numerous baselines. Our extensive evaluation of 57 agents\nacross 22 agent classes reveals several interesting findings, most importantly\nthat despite meaningful progress on certain individual aspects, AI remains far\nfrom solving the challenge of science research assistance.",
        "url": "http://arxiv.org/abs/2510.21652v1",
        "pdf_url": "http://arxiv.org/pdf/2510.21652v1",
        "arxiv_id": "2510.21652v1",
        "authors": [
            "Jonathan Bragg",
            "Mike D'Arcy",
            "Nishant Balepur",
            "Dan Bareket",
            "Bhavana Dalvi",
            "Sergey Feldman",
            "Dany Haddad",
            "Jena D. Hwang",
            "Peter Jansen",
            "Varsha Kishore",
            "Bodhisattwa Prasad Majumder",
            "Aakanksha Naik",
            "Sigal Rahamimov",
            "Kyle Richardson",
            "Amanpreet Singh",
            "Harshit Surana",
            "Aryeh Tiktinsky",
            "Rosni Vasu",
            "Guy Wiener",
            "Chloe Anastasiades",
            "Stefan Candra",
            "Jason Dunkelberger",
            "Dan Emery",
            "Rob Evans",
            "Malachi Hamada",
            "Regan Huff",
            "Rodney Kinney",
            "Matt Latzke",
            "Jaron Lochner",
            "Ruben Lozano-Aguilera",
            "Cecile Nguyen",
            "Smita Rao",
            "Amber Tanaka",
            "Brooke Vlahos",
            "Peter Clark",
            "Doug Downey",
            "Yoav Goldberg",
            "Ashish Sabharwal",
            "Daniel S. Weld"
        ],
        "submitted": "2025-10-24 17:10:26",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Few-Shot Knowledge Distillation of LLMs With Counterfactual Explanations",
        "abstract": "Knowledge distillation is a promising approach to transfer capabilities from\ncomplex teacher models to smaller, resource-efficient student models that can\nbe deployed easily, particularly in task-aware scenarios. However, existing\nmethods of task-aware distillation typically require substantial quantities of\ndata which may be unavailable or expensive to obtain in many practical\nscenarios. In this paper, we address this challenge by introducing a novel\nstrategy called Counterfactual-explanation-infused Distillation CoD for\nfew-shot task-aware knowledge distillation by systematically infusing\ncounterfactual explanations. Counterfactual explanations (CFEs) refer to inputs\nthat can flip the output prediction of the teacher model with minimum\nperturbation. Our strategy CoD leverages these CFEs to precisely map the\nteacher's decision boundary with significantly fewer samples. We provide\ntheoretical guarantees for motivating the role of CFEs in distillation, from\nboth statistical and geometric perspectives. We mathematically show that CFEs\ncan improve parameter estimation by providing more informative examples near\nthe teacher's decision boundary. We also derive geometric insights on how CFEs\neffectively act as knowledge probes, helping the students mimic the teacher's\ndecision boundaries more effectively than standard data. We perform experiments\nacross various datasets and LLMs to show that CoD outperforms standard\ndistillation approaches in few-shot regimes (as low as 8-512 samples). Notably,\nCoD only uses half of the original samples used by the baselines, paired with\ntheir corresponding CFEs and still improves performance.",
        "url": "http://arxiv.org/abs/2510.21631v1",
        "pdf_url": "http://arxiv.org/pdf/2510.21631v1",
        "arxiv_id": "2510.21631v1",
        "authors": [
            "Faisal Hamman",
            "Pasan Dissanayake",
            "Yanjun Fu",
            "Sanghamitra Dutta"
        ],
        "submitted": "2025-10-24 16:36:34",
        "source": "arxiv",
        "comment": "NeurIPS 2025"
    },
    {
        "title": "The Universal Landscape of Human Reasoning",
        "abstract": "Understanding how information is dynamically accumulated and transformed in\nhuman reasoning has long challenged cognitive psychology, philosophy, and\nartificial intelligence. Existing accounts, from classical logic to\nprobabilistic models, illuminate aspects of output or individual modelling, but\ndo not offer a unified, quantitative description of general human reasoning\ndynamics. To solve this, we introduce Information Flow Tracking (IF-Track),\nthat uses large language models (LLMs) as probabilistic encoder to quantify\ninformation entropy and gain at each reasoning step. Through fine-grained\nanalyses across diverse tasks, our method is the first successfully models the\nuniversal landscape of human reasoning behaviors within a single metric space.\nWe show that IF-Track captures essential reasoning features, identifies\nsystematic error patterns, and characterizes individual differences. Applied to\ndiscussion of advanced psychological theory, we first reconcile single- versus\ndual-process theories in IF-Track and discover the alignment of artificial and\nhuman cognition and how LLMs reshaping human reasoning process. This approach\nestablishes a quantitative bridge between theory and measurement, offering\nmechanistic insights into the architecture of reasoning.",
        "url": "http://arxiv.org/abs/2510.21623v1",
        "pdf_url": "http://arxiv.org/pdf/2510.21623v1",
        "arxiv_id": "2510.21623v1",
        "authors": [
            "Qiguang Chen",
            "Jinhao Liu",
            "Libo Qin",
            "Yimeng Zhang",
            "Yihao Liang",
            "Shangxu Ren",
            "Chengyu Luan",
            "Dengyun Peng",
            "Hanjing Li",
            "Jiannan Guan",
            "Zheng Yan",
            "Jiaqi Wang",
            "Mengkang Hu",
            "Yantao Du",
            "Zhi Chen",
            "Xie Chen",
            "Wanxiang Che"
        ],
        "submitted": "2025-10-24 16:26:36",
        "source": "arxiv",
        "comment": "Preprint"
    },
    {
        "title": "DeepAgent: A General Reasoning Agent with Scalable Toolsets",
        "abstract": "Large reasoning models have demonstrated strong problem-solving abilities,\nyet real-world tasks often require external tools and long-horizon\ninteractions. Existing agent frameworks typically follow predefined workflows,\nwhich limit autonomous and global task completion. In this paper, we introduce\nDeepAgent, an end-to-end deep reasoning agent that performs autonomous\nthinking, tool discovery, and action execution within a single, coherent\nreasoning process. To address the challenges of long-horizon interactions,\nparticularly the context length explosion from multiple tool calls and the\naccumulation of interaction history, we introduce an autonomous memory folding\nmechanism that compresses past interactions into structured episodic, working,\nand tool memories, reducing error accumulation while preserving critical\ninformation. To teach general-purpose tool use efficiently and stably, we\ndevelop an end-to-end reinforcement learning strategy, namely ToolPO, that\nleverages LLM-simulated APIs and applies tool-call advantage attribution to\nassign fine-grained credit to the tool invocation tokens. Extensive experiments\non eight benchmarks, including general tool-use tasks (ToolBench, API-Bank,\nTMDB, Spotify, ToolHop) and downstream applications (ALFWorld, WebShop, GAIA,\nHLE), demonstrate that DeepAgent consistently outperforms baselines across both\nlabeled-tool and open-set tool retrieval scenarios. This work takes a step\ntoward more general and capable agents for real-world applications. The code\nand demo are available at https://github.com/RUC-NLPIR/DeepAgent.",
        "url": "http://arxiv.org/abs/2510.21618v1",
        "pdf_url": "http://arxiv.org/pdf/2510.21618v1",
        "arxiv_id": "2510.21618v1",
        "authors": [
            "Xiaoxi Li",
            "Wenxiang Jiao",
            "Jiarui Jin",
            "Guanting Dong",
            "Jiajie Jin",
            "Yinuo Wang",
            "Hao Wang",
            "Yutao Zhu",
            "Ji-Rong Wen",
            "Yuan Lu",
            "Zhicheng Dou"
        ],
        "submitted": "2025-10-24 16:24:01",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "RETuning: Upgrading Inference-Time Scaling for Stock Movement Prediction with Large Language Models",
        "abstract": "Recently, large language models (LLMs) have demonstrated outstanding\nreasoning capabilities on mathematical and coding tasks. However, their\napplication to financial tasks-especially the most fundamental task of stock\nmovement prediction-remains underexplored. We study a three-class\nclassification problem (up, hold, down) and, by analyzing existing reasoning\nresponses, observe that: (1) LLMs follow analysts' opinions rather than exhibit\na systematic, independent analytical logic (CoTs). (2) LLMs list summaries from\ndifferent sources without weighing adversarial evidence, yet such\ncounterevidence is crucial for reliable prediction. It shows that the model\ndoes not make good use of its reasoning ability to complete the task. To\naddress this, we propose Reflective Evidence Tuning (RETuning), a cold-start\nmethod prior to reinforcement learning, to enhance prediction ability. While\ngenerating CoT, RETuning encourages dynamically constructing an analytical\nframework from diverse information sources, organizing and scoring evidence for\nprice up or down based on that framework-rather than on contextual\nviewpoints-and finally reflecting to derive the prediction. This approach\nmaximally aligns the model with its learned analytical framework, ensuring\nindependent logical reasoning and reducing undue influence from context. We\nalso build a large-scale dataset spanning all of 2024 for 5,123 A-share stocks,\nwith long contexts (32K tokens) and over 200K samples. In addition to price and\nnews, it incorporates analysts' opinions, quantitative reports, fundamental\ndata, macroeconomic indicators, and similar stocks. Experiments show that\nRETuning successfully unlocks the model's reasoning ability in the financial\ndomain. Inference-time scaling still works even after 6 months or on\nout-of-distribution stocks, since the models gain valuable insights about stock\nmovement prediction.",
        "url": "http://arxiv.org/abs/2510.21604v1",
        "pdf_url": "http://arxiv.org/pdf/2510.21604v1",
        "arxiv_id": "2510.21604v1",
        "authors": [
            "Xueyuan Lin",
            "Cehao Yang",
            "Ye Ma",
            "Ming Li",
            "Rongjunchen Zhang",
            "Yang Ni",
            "Xiaojun Wu",
            "Chengjin Xu",
            "Jian Guo",
            "Hui Xiong"
        ],
        "submitted": "2025-10-24 16:08:33",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Doc-Researcher: A Unified System for Multimodal Document Parsing and Deep Research",
        "abstract": "Deep Research systems have revolutionized how LLMs solve complex questions\nthrough iterative reasoning and evidence gathering. However, current systems\nremain fundamentally constrained to textual web data, overlooking the vast\nknowledge embedded in multimodal documents Processing such documents demands\nsophisticated parsing to preserve visual semantics (figures, tables, charts,\nand equations), intelligent chunking to maintain structural coherence, and\nadaptive retrieval across modalities, which are capabilities absent in existing\nsystems. In response, we present Doc-Researcher, a unified system that bridges\nthis gap through three integrated components: (i) deep multimodal parsing that\npreserves layout structure and visual semantics while creating multi-granular\nrepresentations from chunk to document level, (ii) systematic retrieval\narchitecture supporting text-only, vision-only, and hybrid paradigms with\ndynamic granularity selection, and (iii) iterative multi-agent workflows that\ndecompose complex queries, progressively accumulate evidence, and synthesize\ncomprehensive answers across documents and modalities. To enable rigorous\nevaluation, we introduce M4DocBench, the first benchmark for Multi-modal,\nMulti-hop, Multi-document, and Multi-turn deep research. Featuring 158\nexpert-annotated questions with complete evidence chains across 304 documents,\nM4DocBench tests capabilities that existing benchmarks cannot assess.\nExperiments demonstrate that Doc-Researcher achieves 50.6% accuracy, 3.4xbetter\nthan state-of-the-art baselines, validating that effective document research\nrequires not just better retrieval, but fundamentally deep parsing that\npreserve multimodal integrity and support iterative research. Our work\nestablishes a new paradigm for conducting deep research on multimodal document\ncollections.",
        "url": "http://arxiv.org/abs/2510.21603v1",
        "pdf_url": "http://arxiv.org/pdf/2510.21603v1",
        "arxiv_id": "2510.21603v1",
        "authors": [
            "Kuicai Dong",
            "Shurui Huang",
            "Fangda Ye",
            "Wei Han",
            "Zhi Zhang",
            "Dexun Li",
            "Wenjun Li",
            "Qu Yang",
            "Gang Wang",
            "Yichao Wang",
            "Chen Zhang",
            "Yong Liu"
        ],
        "submitted": "2025-10-24 16:07:54",
        "source": "arxiv",
        "comment": "preprint"
    },
    {
        "title": "Automated Quality Control for Language Documentation: Detecting Phonotactic Inconsistencies in a Kokborok Wordlist",
        "abstract": "Lexical data collection in language documentation often contains\ntranscription errors and undocumented borrowings that can mislead linguistic\nanalysis. We present unsupervised anomaly detection methods to identify\nphonotactic inconsistencies in wordlists, applying them to a multilingual\ndataset of Kokborok varieties with Bangla. Using character-level and\nsyllable-level phonotactic features, our algorithms identify potential\ntranscription errors and borrowings. While precision and recall remain modest\ndue to the subtle nature of these anomalies, syllable-aware features\nsignificantly outperform character-level baselines. The high-recall approach\nprovides fieldworkers with a systematic method to flag entries requiring\nverification, supporting data quality improvement in low-resourced language\ndocumentation.",
        "url": "http://arxiv.org/abs/2510.21584v1",
        "pdf_url": "http://arxiv.org/pdf/2510.21584v1",
        "arxiv_id": "2510.21584v1",
        "authors": [
            "Kellen Parker van Dam",
            "Abishek Stephen"
        ],
        "submitted": "2025-10-24 15:51:10",
        "source": "arxiv",
        "comment": "Submitted to The 5th Workshop on Evaluation and Comparison for NLP\n  systems (Eval4NLP) 2025"
    },
    {
        "title": "From Polyester Girlfriends to Blind Mice: Creating the First Pragmatics Understanding Benchmarks for Slovene",
        "abstract": "Large language models are demonstrating increasing capabilities, excelling at\nbenchmarks once considered very difficult. As their capabilities grow, there is\na need for more challenging evaluations that go beyond surface-level linguistic\ncompetence. Namely, language competence involves not only syntax and semantics\nbut also pragmatics, i.e., understanding situational meaning as shaped by\ncontext as well as linguistic and cultural norms. To contribute to this line of\nresearch, we introduce SloPragEval and SloPragMega, the first pragmatics\nunderstanding benchmarks for Slovene that contain altogether 405\nmultiple-choice questions. We discuss the difficulties of translation, describe\nthe campaign to establish a human baseline, and report pilot evaluations with\nLLMs. Our results indicate that current models have greatly improved in\nunderstanding nuanced language but may still fail to infer implied speaker\nmeaning in non-literal utterances, especially those that are culture-specific.\nWe also observe a significant gap between proprietary and open-source models.\nFinally, we argue that benchmarks targeting nuanced language understanding and\nknowledge of the target culture must be designed with care, preferably\nconstructed from native data, and validated with human responses.",
        "url": "http://arxiv.org/abs/2510.21575v1",
        "pdf_url": "http://arxiv.org/pdf/2510.21575v1",
        "arxiv_id": "2510.21575v1",
        "authors": [
            "Mojca Brglez",
            "Špela Vintar"
        ],
        "submitted": "2025-10-24 15:43:42",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "ColorEcosystem: Powering Personalized, Standardized, and Trustworthy Agentic Service in massive-agent Ecosystem",
        "abstract": "With the rapid development of (multimodal) large language model-based agents,\nthe landscape of agentic service management has evolved from single-agent\nsystems to multi-agent systems, and now to massive-agent ecosystems. Current\nmassive-agent ecosystems face growing challenges, including impersonal service\nexperiences, a lack of standardization, and untrustworthy behavior. To address\nthese issues, we propose ColorEcosystem, a novel blueprint designed to enable\npersonalized, standardized, and trustworthy agentic service at scale.\nConcretely, ColorEcosystem consists of three key components: agent carrier,\nagent store, and agent audit. The agent carrier provides personalized service\nexperiences by utilizing user-specific data and creating a digital twin, while\nthe agent store serves as a centralized, standardized platform for managing\ndiverse agentic services. The agent audit, based on the supervision of\ndeveloper and user activities, ensures the integrity and credibility of both\nservice providers and users. Through the analysis of challenges, transitional\nforms, and practical considerations, the ColorEcosystem is poised to power\npersonalized, standardized, and trustworthy agentic service across\nmassive-agent ecosystems. Meanwhile, we have also implemented part of\nColorEcosystem's functionality, and the relevant code is open-sourced at\nhttps://github.com/opas-lab/color-ecosystem.",
        "url": "http://arxiv.org/abs/2510.21566v1",
        "pdf_url": "http://arxiv.org/pdf/2510.21566v1",
        "arxiv_id": "2510.21566v1",
        "authors": [
            "Fangwen Wu",
            "Zheng Wu",
            "Jihong Wang",
            "Yunku Chen",
            "Ruiguang Pei",
            "Heyuan Huang",
            "Xin Liao",
            "Xingyu Lou",
            "Huarong Deng",
            "Zhihui Fu",
            "Weiwen Liu",
            "Zhuosheng Zhang",
            "Weinan Zhang",
            "Jun Wang"
        ],
        "submitted": "2025-10-24 15:26:30",
        "source": "arxiv",
        "comment": null
    }
]