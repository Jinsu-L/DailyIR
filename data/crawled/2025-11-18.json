[
    {
        "title": "Generalist Foundation Models Are Not Clinical Enough for Hospital Operations",
        "abstract": "Hospitals and healthcare systems rely on operational decisions that determine patient flow, cost, and quality of care. Despite strong performance on medical knowledge and conversational benchmarks, foundation models trained on general text may lack the specialized knowledge required for these operational decisions. We introduce Lang1, a family of models (100M-7B parameters) pretrained on a specialized corpus blending 80B clinical tokens from NYU Langone Health's EHRs and 627B tokens from the internet. To rigorously evaluate Lang1 in real-world settings, we developed the REalistic Medical Evaluation (ReMedE), a benchmark derived from 668,331 EHR notes that evaluates five critical tasks: 30-day readmission prediction, 30-day mortality prediction, length of stay, comorbidity coding, and predicting insurance claims denial. In zero-shot settings, both general-purpose and specialized models underperform on four of five tasks (36.6%-71.7% AUROC), with mortality prediction being an exception. After finetuning, Lang1-1B outperforms finetuned generalist models up to 70x larger and zero-shot models up to 671x larger, improving AUROC by 3.64%-6.75% and 1.66%-23.66% respectively. We also observed cross-task scaling with joint finetuning on multiple tasks leading to improvement on other tasks. Lang1-1B effectively transfers to out-of-distribution settings, including other clinical tasks and an external health system. Our findings suggest that predictive capabilities for hospital operations require explicit supervised finetuning, and that this finetuning process is made more efficient by in-domain pretraining on EHR. Our findings support the emerging view that specialized LLMs can compete with generalist models in specialized tasks, and show that effective healthcare systems AI requires the combination of in-domain pretraining, supervised finetuning, and real-world evaluation beyond proxy benchmarks.",
        "url": "http://arxiv.org/abs/2511.13703v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13703v1",
        "arxiv_id": "2511.13703v1",
        "authors": [
            "Lavender Y. Jiang",
            "Angelica Chen",
            "Xu Han",
            "Xujin Chris Liu",
            "Radhika Dua",
            "Kevin Eaton",
            "Frederick Wolff",
            "Robert Steele",
            "Jeff Zhang",
            "Anton Alyakin",
            "Qingkai Pan",
            "Yanbing Chen",
            "Karl L. Sangwon",
            "Daniel A. Alber",
            "Jaden Stryker",
            "Jin Vivian Lee",
            "Yindalon Aphinyanaphongs",
            "Kyunghyun Cho",
            "Eric Karl Oermann"
        ],
        "submitted": "2025-11-17 18:52:22",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Crossing Borders: A Multimodal Challenge for Indian Poetry Translation and Image Generation",
        "abstract": "Indian poetry, known for its linguistic complexity and deep cultural resonance, has a rich and varied heritage spanning thousands of years. However, its layered meanings, cultural allusions, and sophisticated grammatical constructions often pose challenges for comprehension, especially for non-native speakers or readers unfamiliar with its context and language. Despite its cultural significance, existing works on poetry have largely overlooked Indian language poems. In this paper, we propose the Translation and Image Generation (TAI) framework, leveraging Large Language Models (LLMs) and Latent Diffusion Models through appropriate prompt tuning. Our framework supports the United Nations Sustainable Development Goals of Quality Education (SDG 4) and Reduced Inequalities (SDG 10) by enhancing the accessibility of culturally rich Indian-language poetry to a global audience. It includes (1) a translation module that uses an Odds Ratio Preference Alignment Algorithm to accurately translate morphologically rich poetry into English, and (2) an image generation module that employs a semantic graph to capture tokens, dependencies, and semantic relationships between metaphors and their meanings, to create visually meaningful representations of Indian poems. Our comprehensive experimental evaluation, including both human and quantitative assessments, demonstrates the superiority of TAI Diffusion in poem image generation tasks, outperforming strong baselines. To further address the scarcity of resources for Indian-language poetry, we introduce the Morphologically Rich Indian Language Poems MorphoVerse Dataset, comprising 1,570 poems across 21 low-resource Indian languages. By addressing the gap in poetry translation and visual comprehension, this work aims to broaden accessibility and enrich the reader's experience.",
        "url": "http://arxiv.org/abs/2511.13689v2",
        "pdf_url": "https://arxiv.org/pdf/2511.13689v2",
        "arxiv_id": "2511.13689v2",
        "authors": [
            "Sofia Jamil",
            "Kotla Sai Charan",
            "Sriparna Saha",
            "Koustava Goswami",
            "Joseph K J"
        ],
        "submitted": "2025-11-17 18:41:16",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Why is \"Chicago\" Predictive of Deceptive Reviews? Using LLMs to Discover Language Phenomena from Lexical Cues",
        "abstract": "Deceptive reviews mislead consumers, harm businesses, and undermine trust in online marketplaces. Machine learning classifiers can learn from large amounts of training examples to effectively distinguish deceptive reviews from genuine ones. However, the distinguishing features learned by these classifiers are often subtle, fragmented, and difficult for humans to interpret. In this work, we explore using large language models (LLMs) to translate machine-learned lexical cues into human-understandable language phenomena that can differentiate deceptive reviews from genuine ones. We show that language phenomena obtained in this manner are empirically grounded in data, generalizable across similar domains, and more predictive than phenomena either in LLMs' prior knowledge or obtained through in-context learning. These language phenomena have the potential to aid people in critically assessing the credibility of online reviews in environments where deception detection classifiers are unavailable.",
        "url": "http://arxiv.org/abs/2511.13658v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13658v1",
        "arxiv_id": "2511.13658v1",
        "authors": [
            "Jiaming Qu",
            "Mengtian Guo",
            "Yue Wang"
        ],
        "submitted": "2025-11-17 18:15:13",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?",
        "abstract": "Large Language Models (LLMs) are reshaping almost all industries, including software engineering. In recent years, a number of LLM agents have been proposed to solve real-world software problems. Such software agents are typically equipped with a suite of coding tools and can autonomously decide the next actions to form complete trajectories to solve end-to-end software tasks. While promising, they typically require dedicated design and may still be suboptimal, since it can be extremely challenging and costly to exhaust the entire agent scaffold design space. Recognizing that software agents are inherently software themselves that can be further refined/modified, researchers have proposed a number of self-improving software agents recently, including the Darwin-Gödel Machine (DGM). Meanwhile, such self-improving agents require costly offline training on specific benchmarks and may not generalize well across different LLMs or benchmarks. In this paper, we propose Live-SWE-agent, the first live software agent that can autonomously and continuously evolve itself on-the-fly during runtime when solving real-world software problems. More specifically, Live-SWE-agent starts with the most basic agent scaffold with only access to bash tools (e.g., mini-SWE-agent), and autonomously evolves its own scaffold implementation while solving real-world software problems. Our evaluation on the widely studied SWE-bench Verified benchmark shows that Live-SWE-agent can achieve an impressive solve rate of 75.4% without test-time scaling, outperforming all existing open-source software agents and approaching the performance of the best proprietary solution. Moreover, Live-SWE-agent outperforms state-of-the-art manually crafted software agents on the recent SWE-Bench Pro benchmark, achieving the best-known solve rate of 45.8%.",
        "url": "http://arxiv.org/abs/2511.13646v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13646v1",
        "arxiv_id": "2511.13646v1",
        "authors": [
            "Chunqiu Steven Xia",
            "Zhe Wang",
            "Yan Yang",
            "Yuxiang Wei",
            "Lingming Zhang"
        ],
        "submitted": "2025-11-17 17:58:18",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "P1: Mastering Physics Olympiads with Reinforcement Learning",
        "abstract": "Recent progress in large language models (LLMs) has moved the frontier from puzzle-solving to science-grade reasoning-the kind needed to tackle problems whose answers must stand against nature, not merely fit a rubric. Physics is the sharpest test of this shift, which binds symbols to reality in a fundamental way, serving as the cornerstone of most modern technologies. In this work, we manage to advance physics research by developing large language models with exceptional physics reasoning capabilities, especially excel at solving Olympiad-level physics problems. We introduce P1, a family of open-source physics reasoning models trained entirely through reinforcement learning (RL). Among them, P1-235B-A22B is the first open-source model with Gold-medal performance at the latest International Physics Olympiad (IPhO 2025), and wins 12 gold medals out of 13 international/regional physics competitions in 2024/2025. P1-30B-A3B also surpasses almost all other open-source models on IPhO 2025, getting a silver medal. Further equipped with an agentic framework PhysicsMinions, P1-235B-A22B+PhysicsMinions achieves overall No.1 on IPhO 2025, and obtains the highest average score over the 13 physics competitions. Besides physics, P1 models also present great performance on other reasoning tasks like math and coding, showing the great generalibility of P1 series.",
        "url": "http://arxiv.org/abs/2511.13612v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13612v1",
        "arxiv_id": "2511.13612v1",
        "authors": [
            "Jiacheng Chen",
            "Qianjia Cheng",
            "Fangchen Yu",
            "Haiyuan Wan",
            "Yuchen Zhang",
            "Shenghe Zheng",
            "Junchi Yao",
            "Qingyang Zhang",
            "Haonan He",
            "Yun Luo",
            "Yufeng Zhao",
            "Futing Wang",
            "Li Sheng",
            "Chengxing Xie",
            "Yuxin Zuo",
            "Yizhuo Li",
            "Wenxauan Zeng",
            "Yulun Wu",
            "Rui Huang",
            "Dongzhan Zhou",
            "Kai Chen",
            "Yu Qiao",
            "Lei Bai",
            "Yu Cheng",
            "Ning Ding",
            "Bowen Zhou",
            "Peng Ye",
            "Ganqu Cui"
        ],
        "submitted": "2025-11-17 17:18:13",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "O-Mem: Omni Memory System for Personalized, Long Horizon, Self-Evolving Agents",
        "abstract": "Recent advancements in LLM-powered agents have demonstrated significant potential in generating human-like responses; however, they continue to face challenges in maintaining long-term interactions within complex environments, primarily due to limitations in contextual consistency and dynamic personalization. Existing memory systems often depend on semantic grouping prior to retrieval, which can overlook semantically irrelevant yet critical user information and introduce retrieval noise. In this report, we propose the initial design of O-Mem, a novel memory framework based on active user profiling that dynamically extracts and updates user characteristics and event records from their proactive interactions with agents. O-Mem supports hierarchical retrieval of persona attributes and topic-related context, enabling more adaptive and coherent personalized responses. O-Mem achieves 51.67% on the public LoCoMo benchmark, a nearly 3% improvement upon LangMem,the previous state-of-the-art, and it achieves 62.99% on PERSONAMEM, a 3.5% improvement upon A-Mem,the previous state-of-the-art. O-Mem also boosts token and interaction response time efficiency compared to previous memory frameworks. Our work opens up promising directions for developing efficient and human-like personalized AI assistants in the future.",
        "url": "http://arxiv.org/abs/2511.13593v2",
        "pdf_url": "https://arxiv.org/pdf/2511.13593v2",
        "arxiv_id": "2511.13593v2",
        "authors": [
            "Piaohong Wang",
            "Motong Tian",
            "Jiaxian Li",
            "Yuan Liang",
            "Yuqing Wang",
            "Qianben Chen",
            "Tiannan Wang",
            "Zhicong Lu",
            "Jiawei Ma",
            "Yuchen Eleanor Jiang",
            "Wangchunshu Zhou"
        ],
        "submitted": "2025-11-17 16:55:19",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Beyond SELECT: A Comprehensive Taxonomy-Guided Benchmark for Real-World Text-to-SQL Translation",
        "abstract": "Text-to-SQL datasets are essential for training and evaluating text-to-SQL models, but existing datasets often suffer from limited coverage and fail to capture the diversity of real-world applications. To address this, we propose a novel taxonomy for text-to-SQL classification based on dimensions including core intents, statement types, syntax structures, and key actions. Using this taxonomy, we evaluate widely used public text-to-SQL datasets (e.g., Spider and Bird) and reveal limitations in their coverage and diversity. We then introduce a taxonomy-guided dataset synthesis pipeline, yielding a new dataset named SQL-Synth. This approach combines the taxonomy with Large Language Models (LLMs) to ensure the dataset reflects the breadth and complexity of real-world text-to-SQL applications. Extensive analysis and experimental results validate the effectiveness of our taxonomy, as SQL-Synth exhibits greater diversity and coverage compared to existing benchmarks. Moreover, we uncover that existing LLMs typically fall short in adequately capturing the full range of scenarios, resulting in limited performance on SQL-Synth. However, fine-tuning can substantially improve their performance in these scenarios. The proposed taxonomy has significant potential impact, as it not only enables comprehensive analysis of datasets and the performance of different LLMs, but also guides the construction of training data for LLMs.",
        "url": "http://arxiv.org/abs/2511.13590v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13590v1",
        "arxiv_id": "2511.13590v1",
        "authors": [
            "Hao Wang",
            "Yuanfeng Song",
            "Xiaoming Yin",
            "Xing Chen"
        ],
        "submitted": "2025-11-17 16:52:19",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "ForgeDAN: An Evolutionary Framework for Jailbreaking Aligned Large Language Models",
        "abstract": "The rapid adoption of large language models (LLMs) has brought both transformative applications and new security risks, including jailbreak attacks that bypass alignment safeguards to elicit harmful outputs. Existing automated jailbreak generation approaches e.g. AutoDAN, suffer from limited mutation diversity, shallow fitness evaluation, and fragile keyword-based detection. To address these limitations, we propose ForgeDAN, a novel evolutionary framework for generating semantically coherent and highly effective adversarial prompts against aligned LLMs. First, ForgeDAN introduces multi-strategy textual perturbations across \\textit{character, word, and sentence-level} operations to enhance attack diversity; then we employ interpretable semantic fitness evaluation based on a text similarity model to guide the evolutionary process toward semantically relevant and harmful outputs; finally, ForgeDAN integrates dual-dimensional jailbreak judgment, leveraging an LLM-based classifier to jointly assess model compliance and output harmfulness, thereby reducing false positives and improving detection effectiveness. Our evaluation demonstrates ForgeDAN achieves high jailbreaking success rates while maintaining naturalness and stealth, outperforming existing SOTA solutions.",
        "url": "http://arxiv.org/abs/2511.13548v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13548v1",
        "arxiv_id": "2511.13548v1",
        "authors": [
            "Siyang Cheng",
            "Gaotian Liu",
            "Rui Mei",
            "Yilin Wang",
            "Kejia Zhang",
            "Kaishuo Wei",
            "Yuqi Yu",
            "Weiping Wen",
            "Xiaojie Wu",
            "Junhua Liu"
        ],
        "submitted": "2025-11-17 16:19:21",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Toward Conversational Hungarian Speech Recognition: Introducing the BEA-Large and BEA-Dialogue Datasets",
        "abstract": "The advancement of automatic speech recognition (ASR) has been largely enhanced by extensive datasets in high-resource languages, while languages such as Hungarian remain underrepresented due to limited spontaneous and conversational corpora. To address this gap, we introduce two new datasets -- BEA-Large and BEA-Dialogue -- constructed from the previously unprocessed portions of the Hungarian speech corpus named BEA. BEA-Large extends BEA-Base with 255 hours of spontaneous speech from 433 speakers, enriched with detailed segment-level metadata. BEA-Dialogue, comprising 85 hours of spontaneous conversations, is a Hungarian speech corpus featuring natural dialogues partitioned into speaker-independent subsets, supporting research in conversational ASR and speaker diarization. We establish reproducible baselines on these datasets using publicly available ASR models, with the fine-tuned Fast Conformer model achieving word error rates as low as 14.18\\% on spontaneous and 4.8\\% on repeated speech. Diarization experiments yield diarization error rates between 13.05\\% and 18.26\\%, providing reference points for future improvements. The results highlight the persistent difficulty of conversational ASR, particularly due to disfluencies, overlaps, and informal speech patterns. By releasing these datasets and baselines, we aim to advance Hungarian speech technology and offer a methodological framework for developing spontaneous and conversational benchmarks in other languages.",
        "url": "http://arxiv.org/abs/2511.13529v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13529v1",
        "arxiv_id": "2511.13529v1",
        "authors": [
            "Máté Gedeon",
            "Piroska Zsófia Barta",
            "Péter Mihajlik",
            "Tekla Etelka Gráczi",
            "Anna Kohári",
            "Katalin Mády"
        ],
        "submitted": "2025-11-17 16:02:08",
        "source": "arxiv",
        "comment": "Submitted to LREC 2026"
    },
    {
        "title": "Compact Multimodal Language Models as Robust OCR Alternatives for Noisy Textual Clinical Reports",
        "abstract": "Digitization of medical records often relies on smartphone photographs of printed reports, producing images degraded by blur, shadows, and other noise. Conventional OCR systems, optimized for clean scans, perform poorly under such real-world conditions. This study evaluates compact multimodal language models as privacy-preserving alternatives for transcribing noisy clinical documents. Using obstetric ultrasound reports written in regionally inflected medical English common to Indian healthcare settings, we compare eight systems in terms of transcription accuracy, noise sensitivity, numeric accuracy, and computational efficiency. Compact multimodal models consistently outperform both classical and neural OCR pipelines. Despite higher computational costs, their robustness and linguistic adaptability position them as viable candidates for on-premises healthcare digitization.",
        "url": "http://arxiv.org/abs/2511.13523v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13523v1",
        "arxiv_id": "2511.13523v1",
        "authors": [
            "Nikita Neveditsin",
            "Pawan Lingras",
            "Salil Patil",
            "Swarup Patil",
            "Vijay Mago"
        ],
        "submitted": "2025-11-17 15:58:03",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Applying Large Language Models to Characterize Public Narratives",
        "abstract": "Public Narratives (PNs) are key tools for leadership development and civic mobilization, yet their systematic analysis remains challenging due to their subjective interpretation and the high cost of expert annotation. In this work, we propose a novel computational framework that leverages large language models (LLMs) to automate the qualitative annotation of public narratives. Using a codebook we co-developed with subject-matter experts, we evaluate LLM performance against that of expert annotators. Our work reveals that LLMs can achieve near-human-expert performance, achieving an average F1 score of 0.80 across 8 narratives and 14 codes. We then extend our analysis to empirically explore how PN framework elements manifest across a larger dataset of 22 stories. Lastly, we extrapolate our analysis to a set of political speeches, establishing a novel lens in which to analyze political rhetoric in civic spaces. This study demonstrates the potential of LLM-assisted annotation for scalable narrative analysis and highlights key limitations and directions for future research in computational civic storytelling.",
        "url": "http://arxiv.org/abs/2511.13505v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13505v1",
        "arxiv_id": "2511.13505v1",
        "authors": [
            "Elinor Poole-Dayan",
            "Daniel T Kessler",
            "Hannah Chiou",
            "Margaret Hughes",
            "Emily S Lin",
            "Marshall Ganz",
            "Deb Roy"
        ],
        "submitted": "2025-11-17 15:41:55",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "PolicyBot - Reliable Question Answering over Policy Documents",
        "abstract": "All citizens of a country are affected by the laws and policies introduced by their government. These laws and policies serve essential functions for citizens. Such as granting them certain rights or imposing specific obligations. However, these documents are often lengthy, complex, and difficult to navigate, making it challenging for citizens to locate and understand relevant information. This work presents PolicyBot, a retrieval-augmented generation (RAG) system designed to answer user queries over policy documents with a focus on transparency and reproducibility. The system combines domain-specific semantic chunking, multilingual dense embeddings, multi-stage retrieval with reranking, and source-aware generation to provide responses grounded in the original documents. We implemented citation tracing to reduce hallucinations and improve user trust, and evaluated alternative retrieval and generation configurations to identify effective design choices. The end-to-end pipeline is built entirely with open-source tools, enabling easy adaptation to other domains requiring document-grounded question answering. This work highlights design considerations, practical challenges, and lessons learned in deploying trustworthy RAG systems for governance-related contexts.",
        "url": "http://arxiv.org/abs/2511.13489v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13489v1",
        "arxiv_id": "2511.13489v1",
        "authors": [
            "Gautam Nagarajan",
            "Omir Kumar",
            "Sudarsun Santhiappan"
        ],
        "submitted": "2025-11-17 15:26:10",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Aspect-Level Obfuscated Sentiment in Thai Financial Disclosures and Its Impact on Abnormal Returns",
        "abstract": "Understanding sentiment in financial documents is crucial for gaining insights into market behavior. These reports often contain obfuscated language designed to present a positive or neutral outlook, even when underlying conditions may be less favorable. This paper presents a novel approach using Aspect-Based Sentiment Analysis (ABSA) to decode obfuscated sentiment in Thai financial annual reports. We develop specific guidelines for annotating obfuscated sentiment in these texts and annotate more than one hundred financial reports. We then benchmark various text classification models on this annotated dataset, demonstrating strong performance in sentiment classification. Additionally, we conduct an event study to evaluate the real-world implications of our sentiment analysis on stock prices. Our results suggest that market reactions are selectively influenced by specific aspects within the reports. Our findings underscore the complexity of sentiment analysis in financial texts and highlight the importance of addressing obfuscated language to accurately assess market sentiment.",
        "url": "http://arxiv.org/abs/2511.13481v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13481v1",
        "arxiv_id": "2511.13481v1",
        "authors": [
            "Attapol T. Rutherford",
            "Sirisak Chueykamhang",
            "Thachaparn Bunditlurdruk",
            "Nanthicha Angsuwichitkul"
        ],
        "submitted": "2025-11-17 15:17:46",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Non-Linear Scoring Model for Translation Quality Evaluation",
        "abstract": "Analytic Translation Quality Evaluation (TQE), based on Multidimensional Quality Metrics (MQM), traditionally uses a linear error-to-penalty scale calibrated to a reference sample of 1000-2000 words. However, linear extrapolation biases judgment on samples of different sizes, over-penalizing short samples and under-penalizing long ones, producing misalignment with expert intuition.\n  Building on the Multi-Range framework, this paper presents a calibrated, non-linear scoring model that better reflects how human content consumers perceive translation quality across samples of varying length. Empirical data from three large-scale enterprise environments shows that acceptable error counts grow logarithmically, not linearly, with sample size.\n  Psychophysical and cognitive evidence, including the Weber-Fechner law and Cognitive Load Theory, supports this premise by explaining why the perceptual impact of additional errors diminishes while the cognitive burden grows with scale. We propose a two-parameter model\n  E(x) = a * ln(1 + b * x), a, b > 0,\n  anchored to a reference tolerance and calibrated from two tolerance points using a one-dimensional root-finding step. The model yields an explicit interval within which the linear approximation stays within +/-20 percent relative error and integrates into existing evaluation workflows with only a dynamic tolerance function added.\n  The approach improves interpretability, fairness, and inter-rater reliability across both human and AI-generated translations. By operationalizing a perceptually valid scoring paradigm, it advances translation quality evaluation toward more accurate and scalable assessment. The model also provides a stronger basis for AI-based document-level evaluation aligned with human judgment. Implementation considerations for CAT/LQA systems and implications for human and AI-generated text evaluation are discussed.",
        "url": "http://arxiv.org/abs/2511.13467v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13467v1",
        "arxiv_id": "2511.13467v1",
        "authors": [
            "Serge Gladkoff",
            "Lifeng Han",
            "Katerina Gasova"
        ],
        "submitted": "2025-11-17 15:09:22",
        "source": "arxiv",
        "comment": "ongoing work, 38 pages"
    },
    {
        "title": "Exploring Multi-Table Retrieval Through Iterative Search",
        "abstract": "Open-domain question answering over datalakes requires retrieving and composing information from multiple tables, a challenging subtask that demands semantic relevance and structural coherence (e.g., joinability). While exact optimization methods like Mixed-Integer Programming (MIP) can ensure coherence, their computational complexity is often prohibitive. Conversely, simpler greedy heuristics that optimize for query coverage alone often fail to find these coherent, joinable sets. This paper frames multi-table retrieval as an iterative search process, arguing this approach offers advantages in scalability, interpretability, and flexibility. We propose a general framework and a concrete instantiation: a fast, effective Greedy Join-Aware Retrieval algorithm that holistically balances relevance, coverage, and joinability. Experiments across 5 NL2SQL benchmarks demonstrate that our iterative method achieves competitive retrieval performance compared to the MIP-based approach while being 4-400x faster depending on the benchmark and search space settings. This work highlights the potential of iterative heuristics for practical, scalable, and composition-aware retrieval.",
        "url": "http://arxiv.org/abs/2511.13418v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13418v1",
        "arxiv_id": "2511.13418v1",
        "authors": [
            "Allaa Boutaleb",
            "Bernd Amann",
            "Rafael Angarita",
            "Hubert Naacke"
        ],
        "submitted": "2025-11-17 14:31:33",
        "source": "arxiv",
        "comment": "Accepted @ the AI for Tabular Data Workshop, EurIPS 2025"
    },
    {
        "title": "Attention Grounded Enhancement for Visual Document Retrieval",
        "abstract": "Visual document retrieval requires understanding heterogeneous and multi-modal content to satisfy information needs. Recent advances use screenshot-based document encoding with fine-grained late interaction, significantly improving retrieval performance. However, retrievers are still trained with coarse global relevance labels, without revealing which regions support the match. As a result, retrievers tend to rely on surface-level cues and struggle to capture implicit semantic connections, hindering their ability to handle non-extractive queries. To alleviate this problem, we propose a \\textbf{A}ttention-\\textbf{G}rounded \\textbf{RE}triever \\textbf{E}nhancement (AGREE) framework. AGREE leverages cross-modal attention from multimodal large language models as proxy local supervision to guide the identification of relevant document regions. During training, AGREE combines local signals with the global signals to jointly optimize the retriever, enabling it to learn not only whether documents match, but also which content drives relevance. Experiments on the challenging ViDoRe V2 benchmark show that AGREE significantly outperforms the global-supervision-only baseline. Quantitative and qualitative analyses further demonstrate that AGREE promotes deeper alignment between query terms and document regions, moving beyond surface-level matching toward more accurate and interpretable retrieval. Our code is available at: https://anonymous.4open.science/r/AGREE-2025.",
        "url": "http://arxiv.org/abs/2511.13415v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13415v1",
        "arxiv_id": "2511.13415v1",
        "authors": [
            "Wanqing Cui",
            "Wei Huang",
            "Yazhi Guo",
            "Yibo Hu",
            "Meiguang Jin",
            "Junfeng Ma",
            "Keping Bi"
        ],
        "submitted": "2025-11-17 14:28:41",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Mem-PAL: Towards Memory-based Personalized Dialogue Assistants for Long-term User-Agent Interaction",
        "abstract": "With the rise of smart personal devices, service-oriented human-agent interactions have become increasingly prevalent. This trend highlights the need for personalized dialogue assistants that can understand user-specific traits to accurately interpret requirements and tailor responses to individual preferences. However, existing approaches often overlook the complexities of long-term interactions and fail to capture users' subjective characteristics. To address these gaps, we present PAL-Bench, a new benchmark designed to evaluate the personalization capabilities of service-oriented assistants in long-term user-agent interactions. In the absence of available real-world data, we develop a multi-step LLM-based synthesis pipeline, which is further verified and refined by human annotators. This process yields PAL-Set, the first Chinese dataset comprising multi-session user logs and dialogue histories, which serves as the foundation for PAL-Bench. Furthermore, to improve personalized service-oriented interactions, we propose H$^2$Memory, a hierarchical and heterogeneous memory framework that incorporates retrieval-augmented generation to improve personalized response generation. Comprehensive experiments on both our PAL-Bench and an external dataset demonstrate the effectiveness of the proposed memory framework.",
        "url": "http://arxiv.org/abs/2511.13410v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13410v1",
        "arxiv_id": "2511.13410v1",
        "authors": [
            "Zhaopei Huang",
            "Qifeng Dai",
            "Guozheng Wu",
            "Xiaopeng Wu",
            "Kehan Chen",
            "Chuan Yu",
            "Xubin Li",
            "Tiezheng Ge",
            "Wenxuan Wang",
            "Qin Jin"
        ],
        "submitted": "2025-11-17 14:22:32",
        "source": "arxiv",
        "comment": "Accepted by AAAI 2026 (Oral)"
    },
    {
        "title": "Uncovering Causal Drivers of Energy Efficiency for Industrial Process in Foundry via Time-Series Causal Inference",
        "abstract": "Improving energy efficiency in industrial foundry processes is a critical challenge, as these operations are highly energy-intensive and marked by complex interdependencies among process variables. Correlation-based analyses often fail to distinguish true causal drivers from spurious associations, limiting their usefulness for decision-making. This paper applies a time-series causal inference framework to identify the operational factors that directly affect energy efficiency in induction furnace melting. Using production data from a Danish foundry, the study integrates time-series clustering to segment melting cycles into distinct operational modes with the PCMCI+ algorithm, a state-of-the-art causal discovery method, to uncover cause-effect relationships within each mode. Across clusters, robust causal relations among energy consumption, furnace temperature, and material weight define the core drivers of efficiency, while voltage consistently influences cooling water temperature with a delayed response. Cluster-specific differences further distinguish operational regimes: efficient clusters are characterized by stable causal structures, whereas inefficient ones exhibit reinforcing feedback loops and atypical dependencies. The contributions of this study are twofold. First, it introduces an integrated clustering-causal inference pipeline as a methodological innovation for analyzing energy-intensive processes. Second, it provides actionable insights that enable foundry operators to optimize performance, reduce energy consumption, and lower emissions.",
        "url": "http://arxiv.org/abs/2511.13389v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13389v1",
        "arxiv_id": "2511.13389v1",
        "authors": [
            "Zhipeng Ma",
            "Bo Nørregaard Jørgensen",
            "Zheng Grace Ma"
        ],
        "submitted": "2025-11-17 14:00:00",
        "source": "arxiv",
        "comment": "Accepted by the Energy Informatics.Academy Conference 2025 (EI.A 2025)"
    },
    {
        "title": "Can Large Language Models Function as Qualified Pediatricians? A Systematic Evaluation in Real-World Clinical Contexts",
        "abstract": "With the rapid rise of large language models (LLMs) in medicine, a key question is whether they can function as competent pediatricians in real-world clinical settings. We developed PEDIASBench, a systematic evaluation framework centered on a knowledge-system framework and tailored to realistic clinical environments. PEDIASBench assesses LLMs across three dimensions: application of basic knowledge, dynamic diagnosis and treatment capability, and pediatric medical safety and medical ethics. We evaluated 12 representative models released over the past two years, including GPT-4o, Qwen3-235B-A22B, and DeepSeek-V3, covering 19 pediatric subspecialties and 211 prototypical diseases. State-of-the-art models performed well on foundational knowledge, with Qwen3-235B-A22B achieving over 90% accuracy on licensing-level questions, but performance declined ~15% as task complexity increased, revealing limitations in complex reasoning. Multiple-choice assessments highlighted weaknesses in integrative reasoning and knowledge recall. In dynamic diagnosis and treatment scenarios, DeepSeek-R1 scored highest in case reasoning (mean 0.58), yet most models struggled to adapt to real-time patient changes. On pediatric medical ethics and safety tasks, Qwen2.5-72B performed best (accuracy 92.05%), though humanistic sensitivity remained limited. These findings indicate that pediatric LLMs are constrained by limited dynamic decision-making and underdeveloped humanistic care. Future development should focus on multimodal integration and a clinical feedback-model iteration loop to enhance safety, interpretability, and human-AI collaboration. While current LLMs cannot independently perform pediatric care, they hold promise for decision support, medical education, and patient communication, laying the groundwork for a safe, trustworthy, and collaborative intelligent pediatric healthcare system.",
        "url": "http://arxiv.org/abs/2511.13381v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13381v1",
        "arxiv_id": "2511.13381v1",
        "authors": [
            "Siyu Zhu",
            "Mouxiao Bian",
            "Yue Xie",
            "Yongyu Tang",
            "Zhikang Yu",
            "Tianbin Li",
            "Pengcheng Chen",
            "Bing Han",
            "Jie Xu",
            "Xiaoyan Dong"
        ],
        "submitted": "2025-11-17 13:54:00",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Donors and Recipients: On Asymmetric Transfer Across Tasks and Languages with Parameter-Efficient Fine-Tuning",
        "abstract": "Large language models (LLMs) perform strongly across tasks and languages, yet how improvements in one task or language affect other tasks and languages and their combinations remains poorly understood. We conduct a controlled PEFT/LoRA study across multiple open-weight LLM families and sizes, treating task and language as transfer axes while conditioning on model family and size; we fine-tune each model on a single task-language source and measure transfer as the percentage-point change versus its baseline score when evaluated on all other task-language target pairs. We decompose transfer into (i) Matched-Task (Cross-Language), (ii) Matched-Language (Cross-Task), and (iii) Cross-Task (Cross-Language) regimes. We uncover two consistent general patterns. First, a pronounced on-task vs. off-task asymmetry: Matched-Task (Cross-Language) transfer is reliably positive, whereas off-task transfer often incurs collateral degradation. Second, a stable donor-recipient structure across languages and tasks (hub donors vs. brittle recipients). We outline implications for risk-aware fine-tuning and model specialisation.",
        "url": "http://arxiv.org/abs/2511.13368v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13368v1",
        "arxiv_id": "2511.13368v1",
        "authors": [
            "Kajetan Dymkiewicz",
            "Ivan Vulic",
            "Helen Yannakoudakis",
            "Eilam Shapira",
            "Roi Reichart",
            "Anna Korhonen"
        ],
        "submitted": "2025-11-17 13:41:31",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "FLOWER: Flow-Oriented Entity-Relationship Tool",
        "abstract": "Exploring relationships across data sources is a crucial optimization for entities recognition. Since databases can store big amount of information with synthetic and organic data, serving all quantity of objects correctly is an important task to deal with. However, the decision of how to construct entity relationship model is associated with human factor. In this paper, we present flow-oriented entity-relationship tool. This is first and unique end-to-end solution that eliminates routine and resource-intensive problems of processing, creating and visualizing both of explicit and implicit dependencies for prominent SQL dialects on-the-fly. Once launched, FLOWER automatically detects built-in constraints and starting to create own correct and necessary one using dynamic sampling and robust data analysis techniques. This approach applies to improve entity-relationship model and data storytelling to better understand the foundation of data and get unseen insights from DB sources using SQL or natural language. Evaluated on state-of-the-art STATS benchmark, experiments show that FLOWER is superior to reservoir sampling by 2.4x for distribution representation and 2.6x for constraint learning with 2.15x acceleration. For data storytelling, our tool archives 1.19x for accuracy enhance with 1.86x context decrease compare to LLM. Presented tool is also support 23 languages and compatible with both of CPU and GPU. Those results show that FLOWER can manage with real-world data a way better to ensure with quality, scalability and applicability for different use-cases.",
        "url": "http://arxiv.org/abs/2511.13357v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13357v1",
        "arxiv_id": "2511.13357v1",
        "authors": [
            "Dmitry Moskalev"
        ],
        "submitted": "2025-11-17 13:23:24",
        "source": "arxiv",
        "comment": "12 pages, 8 figures"
    },
    {
        "title": "AHaSIS: Shared Task on Sentiment Analysis for Arabic Dialects",
        "abstract": "The hospitality industry in the Arab world increasingly relies on customer feedback to shape services, driving the need for advanced Arabic sentiment analysis tools. To address this challenge, the Sentiment Analysis on Arabic Dialects in the Hospitality Domain shared task focuses on Sentiment Detection in Arabic Dialects. This task leverages a multi-dialect, manually curated dataset derived from hotel reviews originally written in Modern Standard Arabic (MSA) and translated into Saudi and Moroccan (Darija) dialects. The dataset consists of 538 sentiment-balanced reviews spanning positive, neutral, and negative categories. Translations were validated by native speakers to ensure dialectal accuracy and sentiment preservation. This resource supports the development of dialect-aware NLP systems for real-world applications in customer experience analysis. More than 40 teams have registered for the shared task, with 12 submitting systems during the evaluation phase. The top-performing system achieved an F1 score of 0.81, demonstrating the feasibility and ongoing challenges of sentiment analysis across Arabic dialects.",
        "url": "http://arxiv.org/abs/2511.13335v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13335v1",
        "arxiv_id": "2511.13335v1",
        "authors": [
            "Maram Alharbi",
            "Salmane Chafik",
            "Saad Ezzini",
            "Ruslan Mitkov",
            "Tharindu Ranasinghe",
            "Hansi Hettiarachchi"
        ],
        "submitted": "2025-11-17 13:06:55",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "AutoMalDesc: Large-Scale Script Analysis for Cyber Threat Research",
        "abstract": "Generating thorough natural language explanations for threat detections remains an open problem in cybersecurity research, despite significant advances in automated malware detection systems. In this work, we present AutoMalDesc, an automated static analysis summarization framework that, following initial training on a small set of expert-curated examples, operates independently at scale. This approach leverages an iterative self-paced learning pipeline to progressively enhance output quality through synthetic data generation and validation cycles, eliminating the need for extensive manual data annotation. Evaluation across 3,600 diverse samples in five scripting languages demonstrates statistically significant improvements between iterations, showing consistent gains in both summary quality and classification accuracy. Our comprehensive validation approach combines quantitative metrics based on established malware labels with qualitative assessment from both human experts and LLM-based judges, confirming both technical precision and linguistic coherence of generated summaries. To facilitate reproducibility and advance research in this domain, we publish our complete dataset of more than 100K script samples, including annotated seed (0.9K) and test (3.6K) datasets, along with our methodology and evaluation framework.",
        "url": "http://arxiv.org/abs/2511.13333v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13333v1",
        "arxiv_id": "2511.13333v1",
        "authors": [
            "Alexandru-Mihai Apostu",
            "Andrei Preda",
            "Alexandra Daniela Damir",
            "Diana Bolocan",
            "Radu Tudor Ionescu",
            "Ioana Croitoru",
            "Mihaela Gaman"
        ],
        "submitted": "2025-11-17 13:05:25",
        "source": "arxiv",
        "comment": "Accepted at AAAI 2026 (oral)"
    },
    {
        "title": "RegionMarker: A Region-Triggered Semantic Watermarking Framework for Embedding-as-a-Service Copyright Protection",
        "abstract": "Embedding-as-a-Service (EaaS) is an effective and convenient deployment solution for addressing various NLP tasks. Nevertheless, recent research has shown that EaaS is vulnerable to model extraction attacks, which could lead to significant economic losses for model providers. For copyright protection, existing methods inject watermark embeddings into text embeddings and use them to detect copyright infringement. However, current watermarking methods often resist only a subset of attacks and fail to provide \\textit{comprehensive} protection. To this end, we present the region-triggered semantic watermarking framework called RegionMarker, which defines trigger regions within a low-dimensional space and injects watermarks into text embeddings associated with these regions. By utilizing a secret dimensionality reduction matrix to project onto this subspace and randomly selecting trigger regions, RegionMarker makes it difficult for watermark removal attacks to evade detection. Furthermore, by embedding watermarks across the entire trigger region and using the text embedding as the watermark, RegionMarker is resilient to both paraphrasing and dimension-perturbation attacks. Extensive experiments on various datasets show that RegionMarker is effective in resisting different attack methods, thereby protecting the copyright of EaaS.",
        "url": "http://arxiv.org/abs/2511.13329v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13329v1",
        "arxiv_id": "2511.13329v1",
        "authors": [
            "Shufan Yang",
            "Zifeng Cheng",
            "Zhiwei Jiang",
            "Yafeng Yin",
            "Cong Wang",
            "Shiping Ge",
            "Yuchen Fu",
            "Qing Gu"
        ],
        "submitted": "2025-11-17 13:04:36",
        "source": "arxiv",
        "comment": "AAAI 2026"
    },
    {
        "title": "Dropouts in Confidence: Moral Uncertainty in Human-LLM Alignment",
        "abstract": "Humans display significant uncertainty when confronted with moral dilemmas, yet the extent of such uncertainty in machines and AI agents remains underexplored. Recent studies have confirmed the overly confident tendencies of machine-generated responses, particularly in large language models (LLMs). As these systems are increasingly embedded in ethical decision-making scenarios, it is important to understand their moral reasoning and the inherent uncertainties in building reliable AI systems. This work examines how uncertainty influences moral decisions in the classical trolley problem, analyzing responses from 32 open-source models and 9 distinct moral dimensions. We first find that variance in model confidence is greater across models than within moral dimensions, suggesting that moral uncertainty is predominantly shaped by model architecture and training method. To quantify uncertainty, we measure binary entropy as a linear combination of total entropy, conditional entropy, and mutual information. To examine its effects, we introduce stochasticity into models via \"dropout\" at inference time. Our findings show that our mechanism increases total entropy, mainly through a rise in mutual information, while conditional entropy remains largely unchanged. Moreover, this mechanism significantly improves human-LLM moral alignment, with correlations in mutual information and alignment score shifts. Our results highlight the potential to better align model-generated decisions and human preferences by deliberately modulating uncertainty and reducing LLMs' confidence in morally complex scenarios.",
        "url": "http://arxiv.org/abs/2511.13290v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13290v1",
        "arxiv_id": "2511.13290v1",
        "authors": [
            "Jea Kwon",
            "Luiz Felipe Vecchietti",
            "Sungwon Park",
            "Meeyoung Cha"
        ],
        "submitted": "2025-11-17 12:13:15",
        "source": "arxiv",
        "comment": "Accepted to AAAI 2026"
    },
    {
        "title": "Examining the Usage of Generative AI Models in Student Learning Activities for Software Programming",
        "abstract": "The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, intermediate) to examine how students interact with ChatGPT while solving programming tasks. We analyzed task performance, conceptual understanding, and interaction behaviors. Our findings reveal that generating complete solutions with GenAI significantly improves task performance, especially for beginners, but does not consistently result in knowledge gains. Importantly, usage strategies differ by experience: beginners tend to rely heavily on GenAI toward task completion often without knowledge gain in the process, while intermediates adopt more selective approaches. We find that both over-reliance and minimal use result in weaker knowledge gains overall. Based on our results, we call on students and educators to adopt GenAI as a learning rather than a problem solving tool. Our study highlights the urgent need for guidance when integrating GenAI into programming education to foster deeper understanding.",
        "url": "http://arxiv.org/abs/2511.13271v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13271v1",
        "arxiv_id": "2511.13271v1",
        "authors": [
            "Rufeng Chen",
            "Shuaishuai Jiang",
            "Jiyun Shen",
            "AJung Moon",
            "Lili Wei"
        ],
        "submitted": "2025-11-17 11:42:24",
        "source": "arxiv",
        "comment": "9 pages, 4 figures, accepted at AIWARE 2025"
    },
    {
        "title": "Souper-Model: How Simple Arithmetic Unlocks State-of-the-Art LLM Performance",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, but their training remains resource- and time-intensive, requiring massive compute power and careful orchestration of training procedures. Model souping-the practice of averaging weights from multiple models of the same architecture-has emerged as a promising pre- and post-training technique that can enhance performance without expensive retraining. In this paper, we introduce Soup Of Category Experts (SoCE), a principled approach for model souping that utilizes benchmark composition to identify optimal model candidates and applies non-uniform weighted averaging to maximize performance. Contrary to previous uniform-averaging approaches, our method leverages the observation that benchmark categories often exhibit low inter-correlations in model performance. SoCE identifies \"expert\" models for each weakly-correlated category cluster and combines them using optimized weighted averaging rather than uniform weights. We demonstrate that the proposed method improves performance and robustness across multiple domains, including multilingual capabilities, tool calling, and math and achieves state-of-the-art results on the Berkeley Function Calling Leaderboard.",
        "url": "http://arxiv.org/abs/2511.13254v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13254v1",
        "arxiv_id": "2511.13254v1",
        "authors": [
            "Shalini Maiti",
            "Amar Budhiraja",
            "Bhavul Gauri",
            "Gaurav Chaurasia",
            "Anton Protopopov",
            "Alexis Audran-Reiss",
            "Michael Slater",
            "Despoina Magka",
            "Tatiana Shavrina",
            "Roberta Raileanu",
            "Yoram Bachrach"
        ],
        "submitted": "2025-11-17 11:13:34",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Computational Measurement of Political Positions: A Review of Text-Based Ideal Point Estimation Algorithms",
        "abstract": "This article presents the first systematic review of unsupervised and semi-supervised computational text-based ideal point estimation (CT-IPE) algorithms, methods designed to infer latent political positions from textual data. These algorithms are widely used in political science, communication, computational social science, and computer science to estimate ideological preferences from parliamentary speeches, party manifestos, and social media. Over the past two decades, their development has closely followed broader NLP trends -- beginning with word-frequency models and most recently turning to large language models (LLMs). While this trajectory has greatly expanded the methodological toolkit, it has also produced a fragmented field that lacks systematic comparison and clear guidance for applied use. To address this gap, we identified 25 CT-IPE algorithms through a systematic literature review and conducted a manual content analysis of their modeling assumptions and development contexts. To compare them meaningfully, we introduce a conceptual framework that distinguishes how algorithms generate, capture, and aggregate textual variance. On this basis, we identify four methodological families -- word-frequency, topic modeling, word embedding, and LLM-based approaches -- and critically assess their assumptions, interpretability, scalability, and limitations. Our review offers three contributions. First, it provides a structured synthesis of two decades of algorithm development, clarifying how diverse methods relate to one another. Second, it translates these insights into practical guidance for applied researchers, highlighting trade-offs in transparency, technical requirements, and validation strategies that shape algorithm choice. Third, it emphasizes that differences in estimation outcomes across algorithms are themselves informative, underscoring the need for systematic benchmarking.",
        "url": "http://arxiv.org/abs/2511.13238v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13238v1",
        "arxiv_id": "2511.13238v1",
        "authors": [
            "Patrick Parschan",
            "Charlott Jakob"
        ],
        "submitted": "2025-11-17 11:01:09",
        "source": "arxiv",
        "comment": "46 pages, 8 figures, 2 tables, accepted for publication in Quality & Quantity"
    },
    {
        "title": "Seeing isn't Hearing: Benchmarking Vision Language Models at Interpreting Spectrograms",
        "abstract": "With the rise of Large Language Models (LLMs) and their vision-enabled counterparts (VLMs), numerous works have investigated their capabilities in tasks that fuse the modalities of vision and language. In this work, we benchmark the extent to which VLMs are able to act as highly-trained phoneticians, interpreting spectrograms and waveforms of speech. To do this, we synthesise a novel dataset containing 4k+ English words spoken in isolation alongside stylistically consistent spectrogram and waveform figures. We test the ability of VLMs to understand these representations of speech through a multiple-choice task whereby models must predict the correct phonemic or graphemic transcription of a spoken word when presented amongst 3 distractor transcriptions that have been selected based on their phonemic edit distance to the ground truth. We observe that both zero-shot and finetuned models rarely perform above chance, demonstrating the requirement for specific parametric knowledge of how to interpret such figures, rather than paired samples alone.",
        "url": "http://arxiv.org/abs/2511.13225v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13225v1",
        "arxiv_id": "2511.13225v1",
        "authors": [
            "Tyler Loakman",
            "Joseph James",
            "Chenghua Lin"
        ],
        "submitted": "2025-11-17 10:41:07",
        "source": "arxiv",
        "comment": "Accepted to IJCNLP-AACL 2025"
    },
    {
        "title": "Cog-RAG: Cognitive-Inspired Dual-Hypergraph with Theme Alignment Retrieval-Augmented Generation",
        "abstract": "Retrieval-Augmented Generation (RAG) enhances the response quality and domain-specific performance of large language models (LLMs) by incorporating external knowledge to combat hallucinations. In recent research, graph structures have been integrated into RAG to enhance the capture of semantic relations between entities. However, it primarily focuses on low-order pairwise entity relations, limiting the high-order associations among multiple entities. Hypergraph-enhanced approaches address this limitation by modeling multi-entity interactions via hyperedges, but they are typically constrained to inter-chunk entity-level representations, overlooking the global thematic organization and alignment across chunks. Drawing inspiration from the top-down cognitive process of human reasoning, we propose a theme-aligned dual-hypergraph RAG framework (Cog-RAG) that uses a theme hypergraph to capture inter-chunk thematic structure and an entity hypergraph to model high-order semantic relations. Furthermore, we design a cognitive-inspired two-stage retrieval strategy that first activates query-relevant thematic content from the theme hypergraph, and then guides fine-grained recall and diffusion in the entity hypergraph, achieving semantic alignment and consistent generation from global themes to local details. Our extensive experiments demonstrate that Cog-RAG significantly outperforms existing state-of-the-art baseline approaches.",
        "url": "http://arxiv.org/abs/2511.13201v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13201v1",
        "arxiv_id": "2511.13201v1",
        "authors": [
            "Hao Hu",
            "Yifan Feng",
            "Ruoxue Li",
            "Rundong Xue",
            "Xingliang Hou",
            "Zhiqiang Tian",
            "Yue Gao",
            "Shaoyi Du"
        ],
        "submitted": "2025-11-17 10:10:33",
        "source": "arxiv",
        "comment": "Accepted by AAAI 2026 main conference"
    },
    {
        "title": "Rdgai: Classifying transcriptional changes using Large Language Models with a test case from an Arabic Gospel tradition",
        "abstract": "Application of phylogenetic methods to textual traditions has traditionally treated all changes as equivalent even though it is widely recognized that certain types of variants were more likely to be introduced than others. While it is possible to give weights to certain changes using a maximum parsimony evaluation criterion, it is difficult to state a priori what these weights should be. Probabilistic methods, such as Bayesian phylogenetics, allow users to create categories of changes, and the transition rates for each category can be estimated as part of the analysis. This classification of types of changes in readings also allows for inspecting the probability of these categories across each branch in the resulting trees. However, classification of readings is time-consuming, as it requires categorizing each reading against every other reading at each variation unit, presenting a significant barrier to entry for this kind of analysis. This paper presents Rdgai, a software package that automates this classification task using multi-lingual large language models (LLMs). The tool allows users to easily manually classify changes in readings and then it uses these annotations in the prompt for an LLM to automatically classify the remaining reading transitions. These classifications are stored in TEI XML and ready for downstream phylogenetic analysis. This paper demonstrates the application with data an Arabic translation of the Gospels.",
        "url": "http://arxiv.org/abs/2511.13801v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13801v1",
        "arxiv_id": "2511.13801v1",
        "authors": [
            "Robert Turnbull"
        ],
        "submitted": "2025-11-17 10:03:12",
        "source": "arxiv",
        "comment": "8 figures"
    },
    {
        "title": "Large Language Models Meet Extreme Multi-label Classification: Scaling and Multi-modal Framework",
        "abstract": "Foundation models have revolutionized artificial intelligence across numerous domains, yet their transformative potential remains largely untapped in Extreme Multi-label Classification (XMC). Queries in XMC are associated with relevant labels from extremely large label spaces, where it is critical to strike a balance between efficiency and performance. Therefore, many recent approaches efficiently pose XMC as a maximum inner product search between embeddings learned from small encoder-only transformer architectures. In this paper, we address two important aspects in XMC: how to effectively harness larger decoder-only models, and how to exploit visual information while maintaining computational efficiency. We demonstrate that both play a critical role in XMC separately and can be combined for improved performance. We show that a few billion-size decoder can deliver substantial improvements while keeping computational overhead manageable. Furthermore, our Vision-enhanced eXtreme Multi-label Learning framework (ViXML) efficiently integrates foundation vision models by pooling a single embedding per image. This limits computational growth while unlocking multi-modal capabilities. Remarkably, ViXML with small encoders outperforms text-only decoder in most cases, showing that an image is worth billions of parameters. Finally, we present an extension of existing text-only datasets to exploit visual metadata and make them available for future benchmarking. Comprehensive experiments across four public text-only datasets and their corresponding image enhanced versions validate our proposals' effectiveness, surpassing previous state-of-the-art by up to +8.21\\% in P@1 on the largest dataset. ViXML's code is available at https://github.com/DiegoOrtego/vixml.",
        "url": "http://arxiv.org/abs/2511.13189v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13189v1",
        "arxiv_id": "2511.13189v1",
        "authors": [
            "Diego Ortego",
            "Marlon Rodríguez",
            "Mario Almagro",
            "Kunal Dahiya",
            "David Jiménez",
            "Juan C. SanMiguel"
        ],
        "submitted": "2025-11-17 09:52:53",
        "source": "arxiv",
        "comment": "To appear at AAAI 2026"
    },
    {
        "title": "Evaluating Large Language Models for Diacritic Restoration in Romanian Texts: A Comparative Study",
        "abstract": "Automatic diacritic restoration is crucial for text processing in languages with rich diacritical marks, such as Romanian. This study evaluates the performance of several large language models (LLMs) in restoring diacritics in Romanian texts. Using a comprehensive corpus, we tested models including OpenAI's GPT-3.5, GPT-4, GPT-4o, Google's Gemini 1.0 Pro, Meta's Llama 2 and Llama 3, MistralAI's Mixtral 8x7B Instruct, airoboros 70B, and OpenLLM-Ro's RoLlama 2 7B, under multiple prompt templates ranging from zero-shot to complex multi-shot instructions. Results show that models such as GPT-4o achieve high diacritic restoration accuracy, consistently surpassing a neutral echo baseline, while others, including Meta's Llama family, exhibit wider variability. These findings highlight the impact of model architecture, training data, and prompt design on diacritic restoration performance and outline promising directions for improving NLP tools for diacritic-rich languages.",
        "url": "http://arxiv.org/abs/2511.13182v2",
        "pdf_url": "https://arxiv.org/pdf/2511.13182v2",
        "arxiv_id": "2511.13182v2",
        "authors": [
            "Mihai Dan Nadas",
            "Laura Diosan"
        ],
        "submitted": "2025-11-17 09:43:54",
        "source": "arxiv",
        "comment": "The original submission contained metadata errors and requires correction. A revised and complete version will be submitted as a replacement"
    },
    {
        "title": "Translation Entropy: A Statistical Framework for Evaluating Translation Systems",
        "abstract": "The translation of written language has been known since the 3rd century BC; however, its necessity has become increasingly common in the information age. Today, many translators exist, based on encoder-decoder deep architectures, nevertheless, no quantitative objective methods are available to assess their performance, likely because the entropy of even a single language remains unknown. This study presents a quantitative method for estimating translation entropy, with the following key finding. Given a translator, several sentences that differ by only one selected token of a given pivot sentence yield identical translations. Analyzing the statistics of this phenomenon across an ensemble of such sentences, consisting each of a pivot selected token, yields the probabilities of replacing this specific token with others while preserving the translation. These probabilities constitute the entropy of the selected token, and the average across all selected pivot tokens provides an estimate of the translator's overall translation entropy, which is enhanced along the decoder blocks. This entropic measure allows for the quantitative ranking of several publicly available translators and reveals whether mutual translation entropy is symmetric. Extending the proposed method to include the replacement of two tokens in a given pivot sentence demonstrates a multiplicative effect, where translation degeneracy is proportional to the product of the degeneracies of the two tokens. These findings establish translation entropy as a measurable property and objective benchmarking of artificial translators. Results are based on MarianMT, T5-Base and NLLB-200 translators.",
        "url": "http://arxiv.org/abs/2511.13180v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13180v1",
        "arxiv_id": "2511.13180v1",
        "authors": [
            "Ronit D. Gross",
            "Yanir Harel",
            "Ido Kanter"
        ],
        "submitted": "2025-11-17 09:42:15",
        "source": "arxiv",
        "comment": "23 pages, 6 figures and 8 tables"
    },
    {
        "title": "TCM-5CEval: Extended Deep Evaluation Benchmark for LLM's Comprehensive Clinical Research Competence in Traditional Chinese Medicine",
        "abstract": "Large language models (LLMs) have demonstrated exceptional capabilities in general domains, yet their application in highly specialized and culturally-rich fields like Traditional Chinese Medicine (TCM) requires rigorous and nuanced evaluation. Building upon prior foundational work such as TCM-3CEval, which highlighted systemic knowledge gaps and the importance of cultural-contextual alignment, we introduce TCM-5CEval, a more granular and comprehensive benchmark. TCM-5CEval is designed to assess LLMs across five critical dimensions: (1) Core Knowledge (TCM-Exam), (2) Classical Literacy (TCM-LitQA), (3) Clinical Decision-making (TCM-MRCD), (4) Chinese Materia Medica (TCM-CMM), and (5) Clinical Non-pharmacological Therapy (TCM-ClinNPT). We conducted a thorough evaluation of fifteen prominent LLMs, revealing significant performance disparities and identifying top-performing models like deepseek\\_r1 and gemini\\_2\\_5\\_pro. Our findings show that while models exhibit proficiency in recalling foundational knowledge, they struggle with the interpretative complexities of classical texts. Critically, permutation-based consistency testing reveals widespread fragilities in model inference. All evaluated models, including the highest-scoring ones, displayed a substantial performance degradation when faced with varied question option ordering, indicating a pervasive sensitivity to positional bias and a lack of robust understanding. TCM-5CEval not only provides a more detailed diagnostic tool for LLM capabilities in TCM but aldso exposes fundamental weaknesses in their reasoning stability. To promote further research and standardized comparison, TCM-5CEval has been uploaded to the Medbench platform, joining its predecessor in the \"In-depth Challenge for Comprehensive TCM Abilities\" special track.",
        "url": "http://arxiv.org/abs/2511.13169v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13169v1",
        "arxiv_id": "2511.13169v1",
        "authors": [
            "Tianai Huang",
            "Jiayuan Chen",
            "Lu Lu",
            "Pengcheng Chen",
            "Tianbin Li",
            "Bing Han",
            "Wenchao Tang",
            "Jie Xu",
            "Ming Li"
        ],
        "submitted": "2025-11-17 09:15:41",
        "source": "arxiv",
        "comment": "17 pages, 8 figures"
    },
    {
        "title": "Local Collaborative Filtering: A Collaborative Filtering Method that Utilizes Local Similarities among Users",
        "abstract": "To leverage user behavior data from the Internet more effectively in recommender systems, this paper proposes a novel collaborative filtering (CF) method called Local Collaborative Filtering (LCF). LCF utilizes local similarities among users and integrates their data using the law of large numbers (LLN), thereby improving the utilization of user behavior data. Experiments are conducted on the Steam game dataset, and the results of LCF align with real-world needs.",
        "url": "http://arxiv.org/abs/2511.13166v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13166v1",
        "arxiv_id": "2511.13166v1",
        "authors": [
            "Zhaoxin Shen",
            "Dan Wu"
        ],
        "submitted": "2025-11-17 09:10:37",
        "source": "arxiv",
        "comment": "4 pages, 2 figures"
    },
    {
        "title": "Distinguishing Repetition Disfluency from Morphological Reduplication in Bangla ASR Transcripts: A Novel Corpus and Benchmarking Analysis",
        "abstract": "Automatic Speech Recognition (ASR) transcripts, especially in low-resource languages like Bangla, contain a critical ambiguity: word-word repetitions can be either Repetition Disfluency (unintentional ASR error/hesitation) or Morphological Reduplication (a deliberate grammatical construct). Standard disfluency correction fails by erroneously deleting valid linguistic information. To solve this, we introduce the first publicly available, 20,000-row Bangla corpus, manually annotated to explicitly distinguish between these two phenomena in noisy ASR transcripts. We benchmark this novel resource using two paradigms: state-of-the-art multilingual Large Language Models (LLMs) and task-specific fine-tuning of encoder models. LLMs achieve competitive performance (up to 82.68\\% accuracy) with few-shot prompting. However, fine-tuning proves superior, with the language-specific BanglaBERT model achieving the highest accuracy of 84.78\\% and an F1 score of 0.677. This establishes a strong, linguistically-informed baseline and provides essential data for developing sophisticated, semantic-preserving text normalization systems for Bangla.",
        "url": "http://arxiv.org/abs/2511.13159v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13159v1",
        "arxiv_id": "2511.13159v1",
        "authors": [
            "Zaara Zabeen Arpa",
            "Sadnam Sakib Apurbo",
            "Nazia Karim Khan Oishee",
            "Ajwad Abrar"
        ],
        "submitted": "2025-11-17 09:06:01",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Zero-Shot Grammar Competency Estimation Using Large Language Model Generated Pseudo Labels",
        "abstract": "Grammar competency estimation is essential for assessing linguistic proficiency in both written and spoken language; however, the spoken modality presents additional challenges due to its spontaneous, unstructured, and disfluent nature. Developing accurate grammar scoring models further requires extensive expert annotation, making large-scale data creation impractical. To address these limitations, we propose a zero-shot grammar competency estimation framework that leverages unlabeled data and Large Language Models (LLMs) without relying on manual labels. During training, we employ LLM-generated predictions on unlabeled data by using grammar competency rubric-based prompts. These predictions, treated as pseudo labels, are utilized to train a transformer-based model through a novel training framework designed to handle label noise effectively. We show that the choice of LLM for pseudo-label generation critically affects model performance and that the ratio of clean-to-noisy samples during training strongly influences stability and accuracy. Finally, a qualitative analysis of error intensity and score prediction confirms the robustness and interpretability of our approach. Experimental results demonstrate the efficacy of our approach in estimating grammar competency scores with high accuracy, paving the way for scalable, low-resource grammar assessment systems.",
        "url": "http://arxiv.org/abs/2511.13152v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13152v1",
        "arxiv_id": "2511.13152v1",
        "authors": [
            "Sourya Dipta Das",
            "Shubham Kumar",
            "Kuldeep Yadav"
        ],
        "submitted": "2025-11-17 09:00:26",
        "source": "arxiv",
        "comment": "Accepted in AACL-IJCNLP 2025"
    },
    {
        "title": "A Comparative Analysis of Recurrent and Attention Architectures for Isolated Sign Language Recognition",
        "abstract": "This study presents a systematic comparative analysis of recurrent and attention-based neural architectures for isolated sign language recognition. We implement and evaluate two representative models-ConvLSTM and Vanilla Transformer-on the Azerbaijani Sign Language Dataset (AzSLD) and the Word-Level American Sign Language (WLASL) dataset. Our results demonstrate that the attention-based Vanilla Transformer consistently outperforms the recurrent ConvLSTM in both Top-1 and Top-5 accuracy across datasets, achieving up to 76.8% Top-1 accuracy on AzSLD and 88.3% on WLASL. The ConvLSTM, while more computationally efficient, lags in recognition accuracy, particularly on smaller datasets. These findings highlight the complementary strengths of each paradigm: the Transformer excels in overall accuracy and signer independence, whereas the ConvLSTM offers advantages in computational efficiency and temporal modeling. The study provides a nuanced analysis of these trade-offs, offering guidance for architecture selection in sign language recognition systems depending on application requirements and resource constraints.",
        "url": "http://arxiv.org/abs/2511.13126v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13126v1",
        "arxiv_id": "2511.13126v1",
        "authors": [
            "Nigar Alishzade",
            "Gulchin Abdullayeva"
        ],
        "submitted": "2025-11-17 08:28:35",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Region-Point Joint Representation for Effective Trajectory Similarity Learning",
        "abstract": "Recent learning-based methods have reduced the computational complexity of traditional trajectory similarity computation, but state-of-the-art (SOTA) methods still fail to leverage the comprehensive spectrum of trajectory information for similarity modeling. To tackle this problem, we propose \\textbf{RePo}, a novel method that jointly encodes \\textbf{Re}gion-wise and \\textbf{Po}int-wise features to capture both spatial context and fine-grained moving patterns. For region-wise representation, the GPS trajectories are first mapped to grid sequences, and spatial context are captured by structural features and semantic context enriched by visual features. For point-wise representation, three lightweight expert networks extract local, correlation, and continuous movement patterns from dense GPS sequences. Then, a router network adaptively fuses the learned point-wise features, which are subsequently combined with region-wise features using cross-attention to produce the final trajectory embedding. To train RePo, we adopt a contrastive loss with hard negative samples to provide similarity ranking supervision. Experiment results show that RePo achieves an average accuracy improvement of 22.2\\% over SOTA baselines across all evaluation metrics.",
        "url": "http://arxiv.org/abs/2511.13125v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13125v1",
        "arxiv_id": "2511.13125v1",
        "authors": [
            "Hao Long",
            "Silin Zhou",
            "Lisi Chen",
            "Shuo Shang"
        ],
        "submitted": "2025-11-17 08:28:18",
        "source": "arxiv",
        "comment": "This paper is accepted by AAAI2026"
    },
    {
        "title": "Extracting Events Like Code: A Multi-Agent Programming Framework for Zero-Shot Event Extraction",
        "abstract": "Zero-shot event extraction (ZSEE) remains a significant challenge for large language models (LLMs) due to the need for complex reasoning and domain-specific understanding. Direct prompting often yields incomplete or structurally invalid outputs--such as misclassified triggers, missing arguments, and schema violations. To address these limitations, we present Agent-Event-Coder (AEC), a novel multi-agent framework that treats event extraction like software engineering: as a structured, iterative code-generation process. AEC decomposes ZSEE into specialized subtasks--retrieval, planning, coding, and verification--each handled by a dedicated LLM agent. Event schemas are represented as executable class definitions, enabling deterministic validation and precise feedback via a verification agent. This programming-inspired approach allows for systematic disambiguation and schema enforcement through iterative refinement. By leveraging collaborative agent workflows, AEC enables LLMs to produce precise, complete, and schema-consistent extractions in zero-shot settings. Experiments across five diverse domains and six LLMs demonstrate that AEC consistently outperforms prior zero-shot baselines, showcasing the power of treating event extraction like code generation. The code and data are released on https://github.com/UESTC-GQJ/Agent-Event-Coder.",
        "url": "http://arxiv.org/abs/2511.13118v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13118v1",
        "arxiv_id": "2511.13118v1",
        "authors": [
            "Quanjiang Guo",
            "Sijie Wang",
            "Jinchuan Zhang",
            "Ben Zhang",
            "Zhao Kang",
            "Ling Tian",
            "Ke Yan"
        ],
        "submitted": "2025-11-17 08:17:15",
        "source": "arxiv",
        "comment": "11 pages, 5 figures, accepted by AAAI 2026 (Oral)"
    },
    {
        "title": "Evaluating the Ability of Large Language Models to Identify Adherence to CONSORT Reporting Guidelines in Randomized Controlled Trials: A Methodological Evaluation Study",
        "abstract": "The Consolidated Standards of Reporting Trials statement is the global benchmark for transparent and high-quality reporting of randomized controlled trials. Manual verification of CONSORT adherence is a laborious, time-intensive process that constitutes a significant bottleneck in peer review and evidence synthesis. This study aimed to systematically evaluate the accuracy and reliability of contemporary LLMs in identifying the adherence of published RCTs to the CONSORT 2010 statement under a zero-shot setting. We constructed a golden standard dataset of 150 published RCTs spanning diverse medical specialties. The primary outcome was the macro-averaged F1-score for the three-class classification task, supplemented by item-wise performance metrics and qualitative error analysis. Overall model performance was modest. The top-performing models, Gemini-2.5-Flash and DeepSeek-R1, achieved nearly identical macro F1 scores of 0.634 and Cohen's Kappa coefficients of 0.280 and 0.282, respectively, indicating only fair agreement with expert consensus. A striking performance disparity was observed across classes: while most models could identify compliant items with high accuracy (F1 score > 0.850), they struggled profoundly with identifying non-compliant and not applicable items, where F1 scores rarely exceeded 0.400. Notably, some high-profile models like GPT-4o underperformed, achieving a macro F1-score of only 0.521. LLMs show potential as preliminary screening assistants for CONSORT checks, capably identifying well-reported items. However, their current inability to reliably detect reporting omissions or methodological flaws makes them unsuitable for replacing human expertise in the critical appraisal of trial quality.",
        "url": "http://arxiv.org/abs/2511.13107v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13107v1",
        "arxiv_id": "2511.13107v1",
        "authors": [
            "Zhichao He",
            "Mouxiao Bian",
            "Jianhong Zhu",
            "Jiayuan Chen",
            "Yunqiu Wang",
            "Wenxia Zhao",
            "Tianbin Li",
            "Bing Han",
            "Jie Xu",
            "Junyan Wu"
        ],
        "submitted": "2025-11-17 08:05:15",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "BeDiscovER: The Benchmark of Discourse Understanding in the Era of Reasoning Language Models",
        "abstract": "We introduce BeDiscovER (Benchmark of Discourse Understanding in the Era of Reasoning Language Models), an up-to-date, comprehensive suite for evaluating the discourse-level knowledge of modern LLMs. BeDiscovER compiles 5 publicly available discourse tasks across discourse lexicon, (multi-)sentential, and documental levels, with in total 52 individual datasets. It covers both extensively studied tasks such as discourse parsing and temporal relation extraction, as well as some novel challenges such as discourse particle disambiguation (e.g., ``just''), and also aggregates a shared task on Discourse Relation Parsing and Treebanking for multilingual and multi-framework discourse relation classification. We evaluate open-source LLMs: Qwen3 series, DeepSeek-R1, and frontier model such as GPT-5-mini on BeDiscovER, and find that state-of-the-art models exhibit strong performance in arithmetic aspect of temporal reasoning, but they struggle with full document reasoning and some subtle semantic and discourse phenomena, such as rhetorical relation recognition.",
        "url": "http://arxiv.org/abs/2511.13095v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13095v1",
        "arxiv_id": "2511.13095v1",
        "authors": [
            "Chuyuan Li",
            "Giuseppe Carenini"
        ],
        "submitted": "2025-11-17 07:50:12",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "STEP: Success-Rate-Aware Trajectory-Efficient Policy Optimization",
        "abstract": "Multi-turn interaction remains challenging for online reinforcement learning. A common solution is trajectory-level optimization, which treats each trajectory as a single training sample. However, this approach can be inefficient and yield misleading learning signals: it applies uniform sampling across tasks regardless of difficulty, penalizes correct intermediate actions in failed trajectories, and incurs high sample-collection costs. To address these issues, we propose STEP (Success-rate-aware Trajectory-Efficient Policy optimization), a framework that dynamically allocates sampling based on per-task success rates and performs step-level optimization. STEP maintains a smoothed success-rate record to guide adaptive trajectory resampling, allocating more effort to harder tasks. It then computes success-rate-weighted advantages and decomposes trajectories into step-level samples. Finally, it applies a step-level GRPO augmentation to refine updates for low-success tasks. Experiments on OSWorld and AndroidWorld show that STEP substantially improves sample efficiency and training stability over trajectory-level GRPO, converging faster and generalizing better under the same sampling budget.",
        "url": "http://arxiv.org/abs/2511.13091v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13091v1",
        "arxiv_id": "2511.13091v1",
        "authors": [
            "Yuhan Chen",
            "Yuxuan Liu",
            "Long Zhang",
            "Pengzhi Gao",
            "Jian Luan",
            "Wei Liu"
        ],
        "submitted": "2025-11-17 07:43:15",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "FGNet: Leveraging Feature-Guided Attention to Refine SAM2 for 3D EM Neuron Segmentation",
        "abstract": "Accurate segmentation of neural structures in Electron Microscopy (EM) images is paramount for neuroscience. However, this task is challenged by intricate morphologies, low signal-to-noise ratios, and scarce annotations, limiting the accuracy and generalization of existing methods. To address these challenges, we seek to leverage the priors learned by visual foundation models on a vast amount of natural images to better tackle this task. Specifically, we propose a novel framework that can effectively transfer knowledge from Segment Anything 2 (SAM2), which is pre-trained on natural images, to the EM domain. We first use SAM2 to extract powerful, general-purpose features. To bridge the domain gap, we introduce a Feature-Guided Attention module that leverages semantic cues from SAM2 to guide a lightweight encoder, the Fine-Grained Encoder (FGE), in focusing on these challenging regions. Finally, a dual-affinity decoder generates both coarse and refined affinity maps. Experimental results demonstrate that our method achieves performance comparable to state-of-the-art (SOTA) approaches with the SAM2 weights frozen. Upon further fine-tuning on EM data, our method significantly outperforms existing SOTA methods. This study validates that transferring representations pre-trained on natural images, when combined with targeted domain-adaptive guidance, can effectively address the specific challenges in neuron segmentation.",
        "url": "http://arxiv.org/abs/2511.13063v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13063v1",
        "arxiv_id": "2511.13063v1",
        "authors": [
            "Zhenghua Li",
            "Hang Chen",
            "Zihao Sun",
            "Kai Li",
            "Xiaolin Hu"
        ],
        "submitted": "2025-11-17 07:11:07",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Dimension vs. Precision: A Comparative Analysis of Autoencoders and Quantization for Efficient Vector Retrieval on BEIR SciFact",
        "abstract": "Dense retrieval models have become a standard for state-of-the-art information retrieval. However, their high-dimensional, high-precision (float32) vector embeddings create significant storage and memory challenges for real-world deployment. To address this, we conduct a rigorous empirical study on the BEIR SciFact benchmark, evaluating the trade-offs between two primary compression strategies: (1) Dimensionality Reduction via deep Autoencoders (AE), reducing original 384-dim vectors to latent spaces from 384 down to 12, and (2) Precision Reduction via Quantization (float16, int8, and binary). We systematically compare each method by measuring the \"performance loss\" (or gain) relative to a float32 baseline across a full suite of retrieval metrics (NDCG, MAP, MRR, Recall, Precision) at various k cutoffs. Our results show that int8 scalar quantization provides the most effective \"sweet spot,\" achieving a 4x compression with a negligible [~1-2%] drop in nDCG@10. In contrast, Autoencoders show a graceful degradation but suffer a more significant performance loss at equivalent 4x compression ratios (AE-96). binary quantization was found to be unsuitable for this task due to catastrophic performance drops. This work provides a practical guide for deploying efficient, high-performance retrieval systems.",
        "url": "http://arxiv.org/abs/2511.13057v2",
        "pdf_url": "https://arxiv.org/pdf/2511.13057v2",
        "arxiv_id": "2511.13057v2",
        "authors": [
            "Satyanarayan Pati"
        ],
        "submitted": "2025-11-17 07:02:11",
        "source": "arxiv",
        "comment": "16 pages, 9 figures, 1 table"
    },
    {
        "title": "Spark-Prover-X1: Formal Theorem Proving Through Diverse Data Training",
        "abstract": "Large Language Models (LLMs) have shown significant promise in automated theorem proving, yet progress is often constrained by the scarcity of diverse and high-quality formal language data. To address this issue, we introduce Spark-Prover-X1, a 7B parameter model trained via an three-stage framework designed to unlock the reasoning potential of more accessible and moderately-sized LLMs. The first stage infuses deep knowledge through continuous pre-training on a broad mathematical corpus, enhanced by a suite of novel data tasks. Key innovation is a \"CoT-augmented state prediction\" task to achieve fine-grained reasoning. The second stage employs Supervised Fine-tuning (SFT) within an expert iteration loop to specialize both the Spark-Prover-X1-7B and Spark-Formalizer-X1-7B models. Finally, a targeted round of Group Relative Policy Optimization (GRPO) is applied to sharpen the prover's capabilities on the most challenging problems. To facilitate robust evaluation, particularly on problems from real-world examinations, we also introduce ExamFormal-Bench, a new benchmark dataset of 402 formal problems. Experimental results demonstrate that Spark-Prover achieves state-of-the-art performance among similarly-sized open-source models within the \"Whole-Proof Generation\" paradigm. It shows exceptional performance on difficult competition benchmarks, notably solving 27 problems on PutnamBench (pass@32) and achieving 24.0\\% on CombiBench (pass@32). Our work validates that this diverse training data and progressively refined training pipeline provides an effective path for enhancing the formal reasoning capabilities of lightweight LLMs. Both Spark-Prover-X1-7B and Spark-Formalizer-X1-7B, along with the ExamFormal-Bench dataset, are made publicly available at: https://www.modelscope.cn/organization/iflytek, https://gitcode.com/ifly_opensource.",
        "url": "http://arxiv.org/abs/2511.13043v2",
        "pdf_url": "https://arxiv.org/pdf/2511.13043v2",
        "arxiv_id": "2511.13043v2",
        "authors": [
            "Xinyuan Zhou",
            "Yi Lei",
            "Xiaoyu Zhou",
            "Jingyi Sun",
            "Yu Zhu",
            "Zhongyi Ye",
            "Weitai Zhang",
            "Quan Liu",
            "Si Wei",
            "Cong Liu"
        ],
        "submitted": "2025-11-17 06:44:02",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Mitigating Recommendation Biases via Group-Alignment and Global-Uniformity in Representation Learning",
        "abstract": "Collaborative Filtering~(CF) plays a crucial role in modern recommender systems, leveraging historical user-item interactions to provide personalized suggestions. However, CF-based methods often encounter biases due to imbalances in training data. This phenomenon makes CF-based methods tend to prioritize recommending popular items and performing unsatisfactorily on inactive users. Existing works address this issue by rebalancing training samples, reranking recommendation results, or making the modeling process robust to the bias. Despite their effectiveness, these approaches can compromise accuracy or be sensitive to weighting strategies, making them challenging to train. In this paper, we deeply analyze the causes and effects of the biases and propose a framework to alleviate biases in recommendation from the perspective of representation distribution, namely Group-Alignment and Global-Uniformity Enhanced Representation Learning for Debiasing Recommendation (AURL). Specifically, we identify two significant problems in the representation distribution of users and items, namely group-discrepancy and global-collapse. These two problems directly lead to biases in the recommendation results. To this end, we propose two simple but effective regularizers in the representation space, respectively named group-alignment and global-uniformity. The goal of group-alignment is to bring the representation distribution of long-tail entities closer to that of popular entities, while global-uniformity aims to preserve the information of entities as much as possible by evenly distributing representations. Our method directly optimizes both the group-alignment and global-uniformity regularization terms to mitigate recommendation biases. Extensive experiments on three real datasets and various recommendation backbones verify the superiority of our proposed framework.",
        "url": "http://arxiv.org/abs/2511.13041v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13041v1",
        "arxiv_id": "2511.13041v1",
        "authors": [
            "Miaomiao Cai",
            "Min Hou",
            "Lei Chen",
            "Le Wu",
            "Haoyue Bai",
            "Yong Li",
            "Meng Wang"
        ],
        "submitted": "2025-11-17 06:42:29",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "How Good is BLI as an Alignment Measure: A Study in Word Embedding Paradigm",
        "abstract": "Sans a dwindling number of monolingual embedding studies originating predominantly from the low-resource domains, it is evident that multilingual embedding has become the de facto choice due to its adaptability to the usage of code-mixed languages, granting the ability to process multilingual documents in a language-agnostic manner, as well as removing the difficult task of aligning monolingual embeddings. But is this victory complete? Are the multilingual models better than aligned monolingual models in every aspect? Can the higher computational cost of multilingual models always be justified? Or is there a compromise between the two extremes? Bilingual Lexicon Induction is one of the most widely used metrics in terms of evaluating the degree of alignment between two embedding spaces. In this study, we explore the strengths and limitations of BLI as a measure to evaluate the degree of alignment of two embedding spaces. Further, we evaluate how well traditional embedding alignment techniques, novel multilingual models, and combined alignment techniques perform BLI tasks in the contexts of both high-resource and low-resource languages. In addition to that, we investigate the impact of the language families to which the pairs of languages belong. We identify that BLI does not measure the true degree of alignment in some cases and we propose solutions for them. We propose a novel stem-based BLI approach to evaluate two aligned embedding spaces that take into account the inflected nature of languages as opposed to the prevalent word-based BLI techniques. Further, we introduce a vocabulary pruning technique that is more informative in showing the degree of the alignment, especially performing BLI on multilingual embedding models. Often, combined embedding alignment techniques perform better while in certain cases multilingual embeddings perform better (mainly low-resource language cases).",
        "url": "http://arxiv.org/abs/2511.13040v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13040v1",
        "arxiv_id": "2511.13040v1",
        "authors": [
            "Kasun Wickramasinghe",
            "Nisansa de Silva"
        ],
        "submitted": "2025-11-17 06:41:41",
        "source": "arxiv",
        "comment": "15 pages, 2 figures, 6 tables"
    },
    {
        "title": "AA-Omniscience: Evaluating Cross-Domain Knowledge Reliability in Large Language Models",
        "abstract": "Existing language model evaluations primarily measure general capabilities, yet reliable use of these models across a range of domains demands factual accuracy and recognition of knowledge gaps. We introduce AA-Omniscience, a benchmark designed to measure both factual recall and knowledge calibration across 6,000 questions. Questions are derived from authoritative academic and industry sources, and cover 42 economically relevant topics within six different domains. The evaluation measures a model's Omniscience Index, a bounded metric (-100 to 100) measuring factual recall that jointly penalizes hallucinations and rewards abstention when uncertain, with 0 equating to a model that answers questions correctly as much as it does incorrectly. Among evaluated models, Claude 4.1 Opus attains the highest score (4.8), making it one of only three models to score above zero. These results reveal persistent factuality and calibration weaknesses across frontier models. Performance also varies by domain, with the models from three different research labs leading across the six domains. This performance variability suggests models should be chosen according to the demands of the use case rather than general performance for tasks where knowledge is important.",
        "url": "http://arxiv.org/abs/2511.13029v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13029v1",
        "arxiv_id": "2511.13029v1",
        "authors": [
            "Declan Jackson",
            "William Keating",
            "George Cameron",
            "Micah Hill-Smith"
        ],
        "submitted": "2025-11-17 06:27:16",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "PragWorld: A Benchmark Evaluating LLMs' Local World Model under Minimal Linguistic Alterations and Conversational Dynamics",
        "abstract": "Real-world conversations are rich with pragmatic elements, such as entity mentions, references, and implicatures. Understanding such nuances is a requirement for successful natural communication, and often requires building a local world model which encodes such elements and captures the dynamics of their evolving states. However, it is not well-understood whether language models (LMs) construct or maintain a robust implicit representation of conversations. In this work, we evaluate the ability of LMs to encode and update their internal world model in dyadic conversations and test their malleability under linguistic alterations. To facilitate this, we apply seven minimal linguistic alterations to conversations sourced from popular datasets and construct two benchmarks comprising yes-no questions. We evaluate a wide range of open and closed source LMs and observe that they struggle to maintain robust accuracy. Our analysis unveils that LMs struggle to memorize crucial details, such as tracking entities under linguistic alterations to conversations. We then propose a dual-perspective interpretability framework which identifies transformer layers that are useful or harmful and highlights linguistic alterations most influenced by harmful layers, typically due to encoding spurious signals or relying on shortcuts. Inspired by these insights, we propose two layer-regularization based fine-tuning strategies that suppress the effect of the harmful layers.",
        "url": "http://arxiv.org/abs/2511.13021v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13021v1",
        "arxiv_id": "2511.13021v1",
        "authors": [
            "Sachin Vashistha",
            "Aryan Bibhuti",
            "Atharva Naik",
            "Martin Tutek",
            "Somak Aditya"
        ],
        "submitted": "2025-11-17 06:17:17",
        "source": "arxiv",
        "comment": "23 pages, 15 tables, 10 figures; AAAI 2026 Conference Main Track (oral)"
    },
    {
        "title": "WebCoach: Self-Evolving Web Agents with Cross-Session Memory Guidance",
        "abstract": "Multimodal LLM-powered agents have recently demonstrated impressive capabilities in web navigation, enabling agents to complete complex browsing tasks across diverse domains. However, current agents struggle with repetitive errors and lack the ability to learn from past experiences across sessions, limiting their long-term robustness and sample efficiency. We introduce WebCoach, a model-agnostic self-evolving framework that equips web browsing agents with persistent cross-session memory, enabling improved long-term planning, reflection, and continual learning without retraining. WebCoach consists of three key components: (1) a WebCondenser, which standardizes raw navigation logs into concise summaries; (2) an External Memory Store, which organizes complete trajectories as episodic experiences; and (3) a Coach, which retrieves relevant experiences based on similarity and recency, and decides whether to inject task-specific advice into the agent via runtime hooks. This design empowers web agents to access long-term memory beyond their native context window, improving robustness in complex browsing tasks. Moreover, WebCoach achieves self-evolution by continuously curating episodic memory from new navigation trajectories, enabling agents to improve over time without retraining. Evaluations on the WebVoyager benchmark demonstrate that WebCoach consistently improves the performance of browser-use agents across three different LLM backbones. With a 38B model, it increases task success rates from 47% to 61% while reducing or maintaining the average number of steps. Notably, smaller base models with WebCoach achieve performance comparable to the same web agent using GPT-4o.",
        "url": "http://arxiv.org/abs/2511.12997v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12997v1",
        "arxiv_id": "2511.12997v1",
        "authors": [
            "Genglin Liu",
            "Shijie Geng",
            "Sha Li",
            "Hejie Cui",
            "Sarah Zhang",
            "Xin Liu",
            "Tianyi Liu"
        ],
        "submitted": "2025-11-17 05:38:50",
        "source": "arxiv",
        "comment": "18 pages; work in progress"
    },
    {
        "title": "Fine-Tuned LLMs Know They Don't Know: A Parameter-Efficient Approach to Recovering Honesty",
        "abstract": "The honesty of Large Language Models (LLMs) is increasingly important for safe deployment in high-stakes domains. However, this crucial trait is severely undermined by supervised fine-tuning (SFT), a common technique for model specialization. Existing recovery methods rely on data-intensive global parameter adjustments, implicitly assuming that SFT deeply corrupts the models' ability to recognize their knowledge boundaries. However, we observe that fine-tuned LLMs still preserve this ability; what is damaged is their capacity to faithfully express that awareness. Building on this, we propose Honesty-Critical Neurons Restoration (HCNR) to surgically repair this suppressed capacity. HCNR identifies and restores key expression-governing neurons to their pre-trained state while harmonizing them with task-oriented neurons via Hessian-guided compensation. Experiments on four QA tasks and five LLM families demonstrate that HCNR effectively recovers 33.25% of the compromised honesty while achieving at least 2.23x speedup with over 10x less data compared to baseline methods, offering a practical solution for trustworthy LLM deployment.",
        "url": "http://arxiv.org/abs/2511.12991v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12991v1",
        "arxiv_id": "2511.12991v1",
        "authors": [
            "Zeyu Shi",
            "Ziming Wang",
            "Tianyu Chen",
            "Shiqi Gao",
            "Haoyi Zhou",
            "Qingyun Sun",
            "Jianxin Li"
        ],
        "submitted": "2025-11-17 05:30:48",
        "source": "arxiv",
        "comment": "Accepted by AAAI 2026 Main Track"
    },
    {
        "title": "Personalized Federated Recommendation With Knowledge Guidance",
        "abstract": "Federated Recommendation (FedRec) has emerged as a key paradigm for building privacy-preserving recommender systems. However, existing FedRec models face a critical dilemma: memory-efficient single-knowledge models suffer from a suboptimal knowledge replacement practice that discards valuable personalization, while high-performance dual-knowledge models are often too memory-intensive for practical on-device deployment. We propose Federated Recommendation with Knowledge Guidance (FedRKG), a model-agnostic framework that resolves this dilemma. The core principle, Knowledge Guidance, avoids full replacement and instead fuses global knowledge into preserved local embeddings, attaining the personalization benefits of dual-knowledge within a single-knowledge memory footprint. Furthermore, we introduce Adaptive Guidance, a fine-grained mechanism that dynamically modulates the intensity of this guidance for each user-item interaction, overcoming the limitations of static fusion methods. Extensive experiments on benchmark datasets demonstrate that FedRKG significantly outperforms state-of-the-art methods, validating the effectiveness of our approach. The code is available at https://github.com/Jaehyung-Lim/fedrkg.",
        "url": "http://arxiv.org/abs/2511.12959v2",
        "pdf_url": "https://arxiv.org/pdf/2511.12959v2",
        "arxiv_id": "2511.12959v2",
        "authors": [
            "Jaehyung Lim",
            "Wonbin Kweon",
            "Woojoo Kim",
            "Junyoung Kim",
            "Dongha Kim",
            "Hwanjo Yu"
        ],
        "submitted": "2025-11-17 04:35:53",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Can We Predict the Next Question? A Collaborative Filtering Approach to Modeling User Behavior",
        "abstract": "In recent years, large language models (LLMs) have excelled in language understanding and generation, powering advanced dialogue and recommendation systems. However, a significant limitation persists: these systems often model user preferences statically, failing to capture the dynamic and sequential nature of interactive behaviors. The sequence of a user's historical questions provides a rich, implicit signal of evolving interests and cognitive patterns, yet leveraging this temporal data for predictive tasks remains challenging due to the inherent disconnect between language modeling and behavioral sequence modeling.\n  To bridge this gap, we propose a Collaborative Filtering-enhanced Question Prediction (CFQP) framework. CFQP dynamically models evolving user-question interactions by integrating personalized memory modules with graph-based preference propagation. This dual mechanism allows the system to adaptively learn from user-specific histories while refining predictions through collaborative signals from similar users. Experimental results demonstrate that our approach effectively generates agents that mimic real-user questioning patterns, highlighting its potential for building proactive and adaptive dialogue systems.",
        "url": "http://arxiv.org/abs/2511.12949v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12949v1",
        "arxiv_id": "2511.12949v1",
        "authors": [
            "Bokang Fu",
            "Jiahao Wang",
            "Xiaojing Liu",
            "Yuli Liu"
        ],
        "submitted": "2025-11-17 04:01:20",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "A Plug-and-Play Spatially-Constrained Representation Enhancement Framework for Local-Life Recommendation",
        "abstract": "Local-life recommendation have witnessed rapid growth, providing users with convenient access to daily essentials. However, this domain faces two key challenges: (1) spatial constraints, driven by the requirements of the local-life scenario, where items are usually shown only to users within a limited geographic area, indirectly reducing their exposure probability; and (2) long-tail sparsity, where few popular items dominate user interactions, while many high-quality long-tail items are largely overlooked due to imbalanced interaction opportunities. Existing methods typically adopt a user-centric perspective, such as modeling spatial user preferences or enhancing long-tail representations with collaborative filtering signals. However, we argue that an item-centric perspective is more suitable for this domain, focusing on enhancing long-tail items representation that align with the spatially-constrained characteristics of local lifestyle services. To tackle this issue, we propose ReST, a Plug-And-Play Spatially-Constrained Representation Enhancement Framework for Long-Tail Local-Life Recommendation. Specifically, we first introduce a Meta ID Warm-up Network, which initializes fundamental ID representations by injecting their basic attribute-level semantic information. Subsequently, we propose a novel Spatially-Constrained ID Representation Enhancement Network (SIDENet) based on contrastive learning, which incorporates two efficient strategies: a spatially-constrained hard sampling strategy and a dynamic representation alignment strategy. This design adaptively identifies weak ID representations based on their attribute-level information during training. It additionally enhances them by capturing latent item relationships within the spatially-constrained characteristics of local lifestyle services, while preserving compatibility with popular items.",
        "url": "http://arxiv.org/abs/2511.12947v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12947v1",
        "arxiv_id": "2511.12947v1",
        "authors": [
            "Hao Jiang",
            "Guoquan Wang",
            "Sheng Yu",
            "Yang Zeng",
            "Wencong Zeng",
            "Guorui Zhou"
        ],
        "submitted": "2025-11-17 03:58:04",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "AIF: Asynchronous Inference Framework for Cost-Effective Pre-Ranking",
        "abstract": "In industrial recommendation systems, pre-ranking models based on deep neural networks (DNNs) commonly adopt a sequential execution framework: feature fetching and model forward computation are triggered only after receiving candidates from the upstream retrieval stage. This design introduces inherent bottlenecks, including redundant computations of identical users/items and increased latency due to strictly sequential operations, which jointly constrain the model's capacity and system efficiency. To address these limitations, we propose the Asynchronous Inference Framework (AIF), a cost-effective computational architecture that decouples interaction-independent components, those operating within a single user or item, from real-time prediction. AIF reorganizes the model inference process by performing user-side computations in parallel with the retrieval stage and conducting item-side computations in a nearline manner. This means that interaction-independent components are calculated just once and completed before the real-time prediction phase of the pre-ranking stage. As a result, AIF enhances computational efficiency and reduces latency, freeing up resources to significantly improve the feature set and model architecture of interaction-independent components. Moreover, we delve into model design within the AIF framework, employing approximated methods for interaction-dependent components in online real-time predictions. By co-designing both the framework and the model, our solution achieves notable performance gains without significantly increasing computational and latency costs. This has enabled the successful deployment of AIF in the Taobao display advertising system.",
        "url": "http://arxiv.org/abs/2511.12934v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12934v1",
        "arxiv_id": "2511.12934v1",
        "authors": [
            "Zhi Kou",
            "Xiang-Rong Sheng",
            "Shuguang Han",
            "Zhishan Zhao",
            "Yueyao Cheng",
            "Han Zhu",
            "Jian Xu",
            "Bo Zheng"
        ],
        "submitted": "2025-11-17 03:39:32",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Visual Room 2.0: Seeing is Not Understanding for MLLMs",
        "abstract": "Can multi-modal large language models (MLLMs) truly understand what they can see? Extending Searle's Chinese Room into the multi-modal domain, this paper proposes the Visual Room argument: MLLMs may describe every visual detail precisely yet fail to comprehend the underlying emotions and intentions, namely seeing is not understanding. Building on this, we introduce \\textit{Visual Room} 2.0, a hierarchical benchmark for evaluating perception-cognition alignment of MLLMs. We model human perceptive and cognitive processes across three levels: low, middle, and high, covering 17 representative tasks. The perception component ranges from attribute recognition to scene understanding, while the cognition component extends from textual entailment to causal and social reasoning. The dataset contains 350 multi-modal samples, each with six progressive questions (2,100 in total) spanning perception to cognition. Evaluating 10 state-of-the-art (SoTA) MLLMs, we highlight three key findings: (1) MLLMs exhibit stronger perceptual competence than cognitive ability (8.0\\%$\\uparrow$); (2) cognition appears not causally dependent on perception-based reasoning; and (3) cognition scales with model size, but perception does not consistently improve with larger variants. This work operationalizes Seeing $ e$ Understanding as a testable hypothesis, offering a new paradigm from perceptual processing to cognitive reasoning in MLLMs. Our dataset is available at https://huggingface.co/datasets/LHK2003/PCBench.",
        "url": "http://arxiv.org/abs/2511.12928v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12928v1",
        "arxiv_id": "2511.12928v1",
        "authors": [
            "Haokun Li",
            "Yazhou Zhang",
            "Jizhi Ding",
            "Qiuchi Li",
            "Peng Zhang"
        ],
        "submitted": "2025-11-17 03:34:52",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Tokenize Once, Recommend Anywhere: Unified Item Tokenization for Multi-domain LLM-based Recommendation",
        "abstract": "Large language model (LLM)-based recommender systems have achieved high-quality performance by bridging the discrepancy between the item space and the language space through item tokenization. However, existing item tokenization methods typically require training separate models for each item domain, limiting generalization. Moreover, the diverse distributions and semantics across item domains make it difficult to construct a unified tokenization that preserves domain-specific information. To address these challenges, we propose UniTok, a Unified item Tokenization framework that integrates our own mixture-of-experts (MoE) architecture with a series of codebooks to convert items into discrete tokens, enabling scalable tokenization while preserving semantic information across multiple item domains. Specifically, items from different domains are first projected into a unified latent space through a shared encoder. They are then routed to domain-specific experts to capture the unique semantics, while a shared expert, which is always active, encodes common knowledge transferable across domains. Additionally, to mitigate semantic imbalance across domains, we present a mutual information calibration mechanism, which guides the model towards retaining similar levels of semantic information for each domain. Comprehensive experiments on wide-ranging real-world datasets demonstrate that the proposed UniTok framework is (a) highly effective: achieving up to 51.89% improvements over strong benchmarks, (b) theoretically sound: showing the analytical validity of our architectural design and optimization; and (c) highly generalizable: demonstrating robust performance across diverse domains without requiring per-domain retraining, a capability not supported by existing baselines.",
        "url": "http://arxiv.org/abs/2511.12922v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12922v1",
        "arxiv_id": "2511.12922v1",
        "authors": [
            "Yu Hou",
            "Won-Yong Shin"
        ],
        "submitted": "2025-11-17 03:18:04",
        "source": "arxiv",
        "comment": "20 pages, 8 figures, 9 tables; Annual AAAI Conference on Artificial Intelligence (AAAI-26) (to appear) (Please cite our conference version.)"
    },
    {
        "title": "Auditing Google's AI Overviews and Featured Snippets: A Case Study on Baby Care and Pregnancy",
        "abstract": "Google Search increasingly surfaces AI-generated content through features like AI Overviews (AIO) and Featured Snippets (FS), which users frequently rely on despite having no control over their presentation. Through a systematic algorithm audit of 1,508 real baby care and pregnancy-related queries, we evaluate the quality and consistency of these information displays. Our robust evaluation framework assesses multiple quality dimensions, including answer consistency, relevance, presence of medical safeguards, source categories, and sentiment alignment. Our results reveal concerning gaps in information consistency, with information in AIO and FS displayed on the same search result page being inconsistent with each other in 33% of cases. Despite high relevance scores, both features critically lack medical safeguards (present in just 11% of AIO and 7% of FS responses). While health and wellness websites dominate source categories for both, AIO and FS, FS also often link to commercial sources. These findings have important implications for public health information access and demonstrate the need for stronger quality controls in AI-mediated health information. Our methodology provides a transferable framework for auditing AI systems across high-stakes domains where information quality directly impacts user well-being.",
        "url": "http://arxiv.org/abs/2511.12920v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12920v1",
        "arxiv_id": "2511.12920v1",
        "authors": [
            "Desheng Hu",
            "Joachim Baumann",
            "Aleksandra Urman",
            "Elsa Lichtenegger",
            "Robin Forsberg",
            "Aniko Hannak",
            "Christo Wilson"
        ],
        "submitted": "2025-11-17 03:16:36",
        "source": "arxiv",
        "comment": "18 pages, 10 figures; to appear in AAAI ICWSM 2026"
    },
    {
        "title": "Classification of Hope in Textual Data using Transformer-Based Models",
        "abstract": "This paper presents a transformer-based approach for classifying hope expressions in text. We developed and compared three architectures (BERT, GPT-2, and DeBERTa) for both binary classification (Hope vs. Not Hope) and multiclass categorization (five hope-related categories). Our initial BERT implementation achieved 83.65% binary and 74.87% multiclass accuracy. In the extended comparison, BERT demonstrated superior performance (84.49% binary, 72.03% multiclass accuracy) while requiring significantly fewer computational resources (443s vs. 704s training time) than newer architectures. GPT-2 showed lowest overall accuracy (79.34% binary, 71.29% multiclass), while DeBERTa achieved moderate results (80.70% binary, 71.56% multiclass) but at substantially higher computational cost (947s for multiclass training). Error analysis revealed architecture-specific strengths in detecting nuanced hope expressions, with GPT-2 excelling at sarcasm detection (92.46% recall). This study provides a framework for computational analysis of hope, with applications in mental health and social media analysis, while demonstrating that architectural suitability may outweigh model size for specialized emotion detection tasks.",
        "url": "http://arxiv.org/abs/2511.12874v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12874v1",
        "arxiv_id": "2511.12874v1",
        "authors": [
            "Chukwuebuka Fortunate Ijezue",
            "Tania-Amanda Fredrick Eneye",
            "Maaz Amjad"
        ],
        "submitted": "2025-11-17 02:07:24",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Rethinking the filter bubble? Developing a research agenda for the protective filter bubble",
        "abstract": "Filter bubbles and echo chambers have received global attention from scholars, media organizations, and the general public. Filter bubbles have primarily been regarded as intrinsically negative, and many studies have sought to minimize their influence. The detrimental influence of filter bubbles is well-studied. Filter bubbles may, for example, create information silos, amplify misinformation, and promote hatred and extremism. However, comparatively few studies have considered the other side of the filter bubble; its protective benefits, particularly to marginalized communities and those living in countries with low levels of press freedom. Through a review of the literature on digital safe spaces and protective filter bubbles, this commentary suggests that there may be a need to rethink the filter bubble, and it proposes several areas for future research.",
        "url": "http://arxiv.org/abs/2511.12873v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12873v1",
        "arxiv_id": "2511.12873v1",
        "authors": [
            "Jacob Erickson"
        ],
        "submitted": "2025-11-17 02:03:08",
        "source": "arxiv",
        "comment": "This work has been published in Big Data & Society. Please cite the journal version"
    },
    {
        "title": "From Perception to Reasoning: Deep Thinking Empowers Multimodal Large Language Models",
        "abstract": "With the remarkable success of Multimodal Large Language Models (MLLMs) in perception tasks, enhancing their complex reasoning capabilities has emerged as a critical research focus. Existing models still suffer from challenges such as opaque reasoning paths and insufficient generalization ability. Chain-of-Thought (CoT) reasoning, which has demonstrated significant efficacy in language models by enhancing reasoning transparency and output interpretability, holds promise for improving model reasoning capabilities when extended to the multimodal domain. This paper provides a systematic review centered on \"Multimodal Chain-of-Thought\" (MCoT). First, it analyzes the background and theoretical motivations for its inception from the perspectives of technical evolution and task demands. Then, it introduces mainstream MCoT methods from three aspects: CoT paradigms, the post-training stage, and the inference stage, while also analyzing their underlying mechanisms. Furthermore, the paper summarizes existing evaluation benchmarks and metrics, and discusses the application scenarios of MCoT. Finally, it analyzes the challenges currently facing MCoT and provides an outlook on its future research directions.",
        "url": "http://arxiv.org/abs/2511.12861v2",
        "pdf_url": "https://arxiv.org/pdf/2511.12861v2",
        "arxiv_id": "2511.12861v2",
        "authors": [
            "Wenxin Zhu",
            "Andong Chen",
            "Yuchen Song",
            "Kehai Chen",
            "Conghui Zhu",
            "Ziyan Chen",
            "Tiejun Zhao"
        ],
        "submitted": "2025-11-17 01:22:37",
        "source": "arxiv",
        "comment": "Survey; 7 figures, 3 tables, 44 pages"
    },
    {
        "title": "NeuroLex: A Lightweight Domain Language Model for EEG Report Understanding and Generation",
        "abstract": "Clinical electroencephalogram (EEG) reports encode domain-specific linguistic conventions that general-purpose language models (LMs) fail to capture. We introduce NeuroLex, a lightweight domain-adaptive language model trained purely on EEG report text from the Harvard Electroencephalography Database. Unlike existing biomedical LMs, NeuroLex is tailored to the linguistic and diagnostic characteristics of EEG reporting, enabling it to serve as both an independent textual model and a decoder backbone for multimodal EEG-language systems. Using span-corruption pretraining and instruction-style fine-tuning on report polishing, paragraph summarization, and terminology question answering, NeuroLex learns the syntax and reasoning patterns characteristic of EEG interpretation. Comprehensive evaluations show that it achieves lower perplexity, higher extraction and summarization accuracy, better label efficiency, and improved robustness to negation and factual hallucination compared with general models of the same scale. With an EEG-aware linguistic backbone, NeuroLex bridges biomedical text modeling and brain-computer interface applications, offering a foundation for interpretable and language-driven neural decoding.",
        "url": "http://arxiv.org/abs/2511.12851v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12851v1",
        "arxiv_id": "2511.12851v1",
        "authors": [
            "Kang Yin",
            "Hye-Bin Shin"
        ],
        "submitted": "2025-11-17 00:44:35",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Quantifying consistency and accuracy of Latent Dirichlet Allocation",
        "abstract": "Topic modelling in Natural Language Processing uncovers hidden topics in large, unlabelled text datasets. It is widely applied in fields such as information retrieval, content summarisation, and trend analysis across various disciplines. However, probabilistic topic models can produce different results when rerun due to their stochastic nature, leading to inconsistencies in latent topics. Factors like corpus shuffling, rare text removal, and document elimination contribute to these variations. This instability affects replicability, reliability, and interpretation, raising concerns about whether topic models capture meaningful topics or just noise. To address these problems, we defined a new stability measure that incorporates accuracy and consistency and uses the generative properties of LDA to generate a new corpus with ground truth. These generated corpora are run through LDA 50 times to determine the variability in the output. We show that LDA can correctly determine the underlying number of topics in the documents. We also find that LDA is more internally consistent, as the multiple reruns return similar topics; however, these topics are not the true topics.",
        "url": "http://arxiv.org/abs/2511.12850v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12850v1",
        "arxiv_id": "2511.12850v1",
        "authors": [
            "Saranzaya Magsarjav",
            "Melissa Humphries",
            "Jonathan Tuke",
            "Lewis Mitchell"
        ],
        "submitted": "2025-11-17 00:44:27",
        "source": "arxiv",
        "comment": "8 pages, 3 figures, to be submitted"
    },
    {
        "title": "From Passive to Persuasive: Steering Emotional Nuance in Human-AI Negotiation",
        "abstract": "Large Language Models (LLMs) demonstrate increasing conversational fluency, yet instilling them with nuanced, human-like emotional expression remains a significant challenge. Current alignment techniques often address surface-level output or require extensive fine-tuning. This paper demonstrates that targeted activation engineering can steer LLaMA 3.1-8B to exhibit more human-like emotional nuances. We first employ attribution patching to identify causally influential components, to find a key intervention locus by observing activation patterns during diagnostic conversational tasks. We then derive emotional expression vectors from the difference in the activations generated by contrastive text pairs (positive vs. negative examples of target emotions). Applying these vectors to new conversational prompts significantly enhances emotional characteristics: steered responses show increased positive sentiment (e.g., joy, trust) and more frequent first-person pronoun usage, indicative of greater personal engagement. Our findings offer a precise and interpretable framework and new directions for the study of conversational AI.",
        "url": "http://arxiv.org/abs/2511.12832v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12832v1",
        "arxiv_id": "2511.12832v1",
        "authors": [
            "Niranjan Chebrolu",
            "Gerard Christopher Yeo",
            "Kokil Jaidka"
        ],
        "submitted": "2025-11-16 23:33:06",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "BioMedJImpact: A Comprehensive Dataset and LLM Pipeline for AI Engagement and Scientific Impact Analysis of Biomedical Journals",
        "abstract": "Assessing journal impact is central to scholarly communication, yet existing open resources rarely capture how collaboration structures and artificial intelligence (AI) research jointly shape venue prestige in biomedicine. We present BioMedJImpact, a large-scale, biomedical-oriented dataset designed to advance journal-level analysis of scientific impact and AI engagement. Built from 1.74 million PubMed Central articles across 2,744 journals, BioMedJImpact integrates bibliometric indicators, collaboration features, and LLM-derived semantic indicators for AI engagement. Specifically, the AI engagement feature is extracted through a reproducible three-stage LLM pipeline that we propose. Using this dataset, we analyze how collaboration intensity and AI engagement jointly influence scientific impact across pre- and post-pandemic periods (2016-2019, 2020-2023). Two consistent trends emerge: journals with higher collaboration intensity, particularly those with larger and more diverse author teams, tend to achieve greater citation impact, and AI engagement has become an increasingly strong correlate of journal prestige, especially in quartile rankings. To further validate the three-stage LLM pipeline we proposed for deriving the AI engagement feature, we conduct human evaluation, confirming substantial agreement in AI relevance detection and consistent subfield classification. Together, these contributions demonstrate that BioMedJImpact serves as both a comprehensive dataset capturing the intersection of biomedicine and AI, and a validated methodological framework enabling scalable, content-aware scientometric analysis of scientific impact and innovation dynamics. Code is available at https://github.com/JonathanWry/BioMedJImpact.",
        "url": "http://arxiv.org/abs/2511.12821v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12821v1",
        "arxiv_id": "2511.12821v1",
        "authors": [
            "Ruiyu Wang",
            "Yuzhang Xie",
            "Xiao Hu",
            "Carl Yang",
            "Jiaying Lu"
        ],
        "submitted": "2025-11-16 23:03:15",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "Evaluating Autoformalization Robustness via Semantically Similar Paraphrasing",
        "abstract": "Large Language Models (LLMs) have recently emerged as powerful tools for autoformalization. Despite their impressive performance, these models can still struggle to produce grounded and verifiable formalizations. Recent work in text-to-SQL, has revealed that LLMs can be sensitive to paraphrased natural language (NL) inputs, even when high degrees of semantic fidelity are preserved (Safarzadeh, Oroojlooyjadid, and Roth 2025). In this paper, we investigate this claim in the autoformalization domain. Specifically, we evaluate the robustness of LLMs generating formal proofs with semantically similar paraphrased NL statements by measuring semantic and compilation validity. Using the formal benchmarks MiniF2F (Zheng, Han, and Polu 2021) and Lean 4 version of ProofNet (Xin et al. 2024), and two modern LLMs, we generate paraphrased natural language statements and cross-evaluate these statements across both models. The results of this paper reveal performance variability across paraphrased inputs, demonstrating that minor shifts in NL statements can significantly impact model outputs.",
        "url": "http://arxiv.org/abs/2511.12784v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12784v1",
        "arxiv_id": "2511.12784v1",
        "authors": [
            "Hayden Moore",
            "Asfahan Shah"
        ],
        "submitted": "2025-11-16 21:25:59",
        "source": "arxiv",
        "comment": null
    },
    {
        "title": "LLM Reinforcement in Context",
        "abstract": "Current Large Language Model alignment research mostly focuses on improving model robustness against adversarial attacks and misbehavior by training on examples and prompting. Research has shown that LLM jailbreak probability increases with the size of the user input or conversation length. There is a lack of appropriate research into means of strengthening alignment which also scale with user input length. We propose interruptions as a possible solution to this problem. Interruptions are control sentences added to the user input approximately every x tokens for some arbitrary x. We suggest that this can be generalized to the Chain-of-Thought process to prevent scheming.",
        "url": "http://arxiv.org/abs/2511.12782v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12782v1",
        "arxiv_id": "2511.12782v1",
        "authors": [
            "Thomas Rivasseau"
        ],
        "submitted": "2025-11-16 21:24:42",
        "source": "arxiv",
        "comment": "4 pages"
    },
    {
        "title": "Evidence of Phase Transitions in Small Transformer-Based Language Models",
        "abstract": "Phase transitions have been proposed as the origin of emergent abilities in large language models (LLMs), where new capabilities appear abruptly once models surpass critical thresholds of scale. Prior work, such as that of Wei et al., demonstrated these phenomena under model and data scaling, with transitions revealed after applying a log scale to training compute. In this work, we ask three complementary questions: (1) Are phase transitions unique to large models, or can they also be observed in small transformer-based language models? (2) Can such transitions be detected directly in linear training space, rather than only after log rescaling? and (3) Can these transitions emerge at early stages of training? To investigate, we train a small GPT-style transformer on a character-level corpus and analyze the evolution of vocabulary usage throughout training. We track the average word length, the number of correct versus incorrect words, and shifts in vocabulary diversity. Building on these measures, we apply Poisson and sub-Poisson statistics to quantify how words connect and reorganize. This combined analysis reveals a distinct transition point during training. Notably, these transitions are not apparent in standard loss or validation curves, but become visible through our vocabulary- and statistics-based probes. Our findings suggest that phase-transition reorganizations are a general feature of language model training, observable even in modest models, detectable directly in linear training space, and occurring surprisingly early as coherence emerges. This perspective provides new insight into the nonlinear dynamics of language model training and underscores the importance of tailored metrics for uncovering phase transition behaviors",
        "url": "http://arxiv.org/abs/2511.12768v1",
        "pdf_url": "https://arxiv.org/pdf/2511.12768v1",
        "arxiv_id": "2511.12768v1",
        "authors": [
            "Noah Hong",
            "Tao Hong"
        ],
        "submitted": "2025-11-16 20:37:12",
        "source": "arxiv",
        "comment": null
    }
]