# Daily Papers Report - 2026-02-22

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. Efficient Filtered-ANN via Learning-based Query Planning

- **LLM Score**: 8
- **Keyword Score**: 6
- **Authors**: Zhuocheng Gan, Yifan Wang
- **URL**: <http://arxiv.org/abs/2602.17914v1>
- **Submitted**: 2026-02-20 00:22:43
- **Topic Keywords**: query, retrieval, search
- **Reason**: This paper is highly relevant to Information Retrieval, specifically in the area of search technologies and query understanding. The focus on learning-based query planning and execution order optimization aligns with your interests in ranking models and real-time relevance optimization. However, the paper's emphasis on vector retrieval and ANN search is somewhat specific and may not be a central match to your broader interests in NLP and data mining.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Learning‚ÄëBased Query Planning for Filtered Approximate Nearest‚ÄëNeighbour Search
- **Aim**: Enable per‚Äëquery dynamic selection between pre‚Äëfiltering, post‚Äëfiltering, and ACORN‚Äë1 to maximize recall@k over execution time in filtered ANN workloads.
- **Rationale**: Static execution plans are brittle; optimal strategy depends on dataset size, dimensionality, predicate type, and selectivity. A lightweight planner can predict the best strategy without modifying the underlying ANN index.
- **Ground**: The paper presents a selectivity estimator (frequency tables, histograms, gradient‚Äëboosting for multi‚Äëlabel and numeric ranges) and a two‚Äëlayer MLP core planner trained on labeled queries. It evaluates on real (ArXiv, Wolt) and synthetic (GloVe‚Äë200, SIFT) datasets, comparing against pre‚Äëfiltering, post‚Äëfiltering, ACORN‚Äë1, and other state‚Äëof‚Äëthe‚Äëart methods.
- **Experiment**: Training data were generated by sampling filtered‚ÄëANN queries with 1‚Äì25‚ÄØ% selectivity; utilities were computed for pre‚Äë and post‚Äëfiltering to label optimal strategy. The planner was trained for up to 500 epochs with Adam. Evaluation used an Intel Core Ultra‚ÄØ9 CPU, 32‚ÄØGB RAM, single‚ÄëCPU inference (<1‚ÄØms). Results show recall@10 ‚âà 0.96‚Äì0.90, speedups up to 20√ó over ACORN‚Äë1, and construction time reductions up to 20√ó.
- **Takeaway**: A lightweight, index‚Äëagnostic learning‚Äëbased planner can dynamically choose the most efficient execution strategy for filtered ANN queries, achieving substantial latency reductions while maintaining high recall, making it suitable for production retrieval systems.

#### Abstract
> Filtered ANN search is an increasingly important problem in vector retrieval, yet systems face a difficult trade-off due to the execution order: Pre-filtering (filtering first, then ANN over the passing subset) requires expensive per-predicate index construction, while post-filtering (ANN first, then filtering candidates) may waste computation and lose recall under low selectivity due to insufficient candidates after filtering. We introduce a learning-based query planning framework that dynamically selects the most effective execution plan for each query, using lightweight predictions derived from dataset and query statistics (e.g., dimensionality, corpus size, distribution features, and predicate statistics). The framework supports diverse filter types, including categorical/keyword and range predicates, and is generic to use any backend ANN index. Experiments show that our method achieves up to 4x acceleration with >= 90% recall comparing to the strong baselines.

---

### 2. RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering

- **LLM Score**: 7
- **Keyword Score**: 14
- **Authors**: Deniz Qian, Hung-Ting Chen, Eunsol Choi
- **URL**: <http://arxiv.org/abs/2602.18425v1>
- **Submitted**: 2026-02-20 18:48:05
- **Comment**: 18 pages, 12 figures, 12 tables
- **Topic Keywords**: retriever, query, queries, rag, retrieval, search
- **Reason**: This paper introduces a multi-round retrieval framework (RVR) for comprehensive question answering, which aligns with the user's interest in Information Retrieval and query understanding. Although it focuses on question answering rather than general search, the use of a verifier and iterative approach to improve answer recall is relevant to the user's research themes. However, the specific application to question answering and the use of off-the-shelf retrievers may not be directly applicable to the user's primary focus on general search and ranking models.

#### Abstract
> Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario.

---

### 3. Click it or Leave it: Detecting and Spoiling Clickbait with Informativeness Measures and Large Language Models

- **LLM Score**: 7
- **Keyword Score**: 3
- **Authors**: Wojciech Michaluk, Tymoteusz Urban, Mateusz Kubita, Soveatin Kuntur, Anna Wroblewska
- **URL**: <http://arxiv.org/abs/2602.18171v1>
- **Submitted**: 2026-02-20 12:16:08
- **Topic Keywords**: click, search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, specifically in the area of click models and user behavior modeling. However, it focuses on clickbait detection rather than general click models, and its application is in the domain of natural language processing for text classification. While it shares some overlap with your interests, it is not a central match.

#### Abstract
> Clickbait headlines degrade the quality of online information and undermine user trust. We present a hybrid approach to clickbait detection that combines transformer-based text embeddings with linguistically motivated informativeness features. Using natural language processing techniques, we evaluate classical vectorizers, word embedding baselines, and large language model embeddings paired with tree-based classifiers. Our best-performing model, XGBoost over embeddings augmented with 15 explicit features, achieves an F1-score of 91\%, outperforming TF-IDF, Word2Vec, GloVe, LLM prompt based classification, and feature-only baselines. The proposed feature set enhances interpretability by highlighting salient linguistic cues such as second-person pronouns, superlatives, numerals, and attention-oriented punctuation, enabling transparent and well-calibrated clickbait predictions. We release code and trained models to support reproducible research.

---

### 4. Improving Neural Topic Modeling with Semantically-Grounded Soft Label Distributions

- **LLM Score**: 7
- **Keyword Score**: 2
- **Authors**: Raymond Li, Amirhossein Abaskohi, Chuyuan Li, Gabriel Murray, Giuseppe Carenini
- **URL**: <http://arxiv.org/abs/2602.17907v1>
- **Submitted**: 2026-02-20 00:12:04
- **Comment**: 20 pages, 5 figures
- **Topic Keywords**: retrieval
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the area of query understanding and ranking models. Although it focuses on neural topic modeling and language models, the proposed approach improves topic coherence and purity, which can be beneficial for search technologies. However, the primary focus on topic modeling and language models makes it less central to your core research themes.

#### Abstract
> Traditional neural topic models are typically optimized by reconstructing the document's Bag-of-Words (BoW) representations, overlooking contextual information and struggling with data sparsity. In this work, we propose a novel approach to construct semantically-grounded soft label targets using Language Models (LMs) by projecting the next token probabilities, conditioned on a specialized prompt, onto a pre-defined vocabulary to obtain contextually enriched supervision signals. By training the topic models to reconstruct the soft labels using the LM hidden states, our method produces higher-quality topics that are more closely aligned with the underlying thematic structure of the corpus. Experiments on three datasets show that our method achieves substantial improvements in topic coherence, purity over existing baselines. Additionally, we also introduce a retrieval-based metric, which shows that our approach significantly outperforms existing methods in identifying semantically similar documents, highlighting its effectiveness for retrieval-oriented applications.

---

### 5. Decomposing Retrieval Failures in RAG for Long-Document Financial Question Answering

- **LLM Score**: 4
- **Keyword Score**: 19
- **Authors**: Amine Kobeissi, Philippe Langlais
- **URL**: <http://arxiv.org/abs/2602.17981v1>
- **Submitted**: 2026-02-20 04:31:40
- **Topic Keywords**: query, ranking, rerank, relevance, rag, retrieval, rank, acl
- **Reason**: The paper is somewhat related to information retrieval, specifically focusing on retrieval strategies for question answering in the financial domain. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's focus on retrieval at multiple levels of granularity and the introduction of a domain fine-tuned page scorer are relevant to the broader field of IR, but not directly aligned with the user's primary research themes.

#### Abstract
> Retrieval-augmented generation is increasingly used for financial question answering over long regulatory filings, yet reliability depends on retrieving the exact context needed to justify answers in high stakes settings. We study a frequent failure mode in which the correct document is retrieved but the page or chunk that contains the answer is missed, leading the generator to extrapolate from incomplete context. Despite its practical significance, this within-document retrieval failure mode has received limited systematic attention in the Financial Question Answering (QA) literature. We evaluate retrieval at multiple levels of granularity, document, page, and chunk level, and introduce an oracle based analysis to provide empirical upper bounds on retrieval and generative performance. On a 150 question subset of FinanceBench, we reproduce and compare diverse retrieval strategies including dense, sparse, hybrid, and hierarchical methods with reranking and query reformulation. Across methods, gains in document discovery tend to translate into stronger page recall, yet oracle performance still suggests headroom for page and chunk level retrieval. To target this gap, we introduce a domain fine-tuned page scorer that treats pages as an intermediate retrieval unit between documents and chunks. Unlike prior passage-based hierarchical retrieval, we fine-tune a bi-encoder specifically for page-level relevance on financial filings, exploiting the semantic coherence of pages. Overall, our results demonstrate a significant improvement in page recall and chunk retrieval.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. SuiteEval: Simplifying Retrieval Benchmarks

- **LLM Score**: 4
- **Keyword Score**: 12
- **Authors**: Andrew Parry, Debasis Ganguly, Sean MacAvaney
- **URL**: <http://arxiv.org/abs/2602.18107v1>
- **Submitted**: 2026-02-20 09:54:16
- **Comment**: 5 pages, 3 figures, 2 tables, Accepted as a Demonstration to ECIR 2026
- **Topic Keywords**: information retrieval, ranking, rag, retrieval, rank, search
- **Reason**: The paper focuses on simplifying retrieval benchmarks, which is somewhat related to information retrieval and search technologies. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's emphasis on reproducibility and standardization is relevant to the broader field of IR, but it does not delve into the deep semantic understanding or real-time relevance optimization aspects that are central to the user's research.

#### Abstract
> Information retrieval evaluation often suffers from fragmented practices -- varying dataset subsets, aggregation methods, and pipeline configurations -- that undermine reproducibility and comparability, especially for foundation embedding models requiring robust out-of-domain performance. We introduce SuiteEval, a unified framework that offers automatic end-to-end evaluation, dynamic indexing that reuses on-disk indices to minimise disk usage, and built-in support for major benchmarks (BEIR, LoTTE, MS MARCO, NanoBEIR, and BRIGHT). Users only need to supply a pipeline generator. SuiteEval handles data loading, indexing, ranking, metric computation, and result aggregation. New benchmark suites can be added in a single line. SuiteEval reduces boilerplate and standardises evaluations to facilitate reproducible IR research, as a broader benchmark set is increasingly required.

### 7. VQPP: Video Query Performance Prediction Benchmark

- **LLM Score**: 4
- **Keyword Score**: 11
- **Authors**: Adrian Catalin Lutu, Eduard Poesina, Radu Tudor Ionescu
- **URL**: <http://arxiv.org/abs/2602.17814v1>
- **Submitted**: 2026-02-19 20:32:25
- **Topic Keywords**: information retrieval, query, queries, retrieval
- **Reason**: The paper VQPP: Video Query Performance Prediction Benchmark is somewhat related to the user's research interests in Information Retrieval (IR), particularly in the context of query performance prediction and retrieval system selection. However, the focus on video query performance prediction and content-based video retrieval is not a central match to the user's primary interests in text-based IR and query understanding. The paper's exploration of pre-retrieval and post-retrieval performance predictors is also somewhat relevant, but not a key area of focus for the user.

#### Abstract
> Query performance prediction (QPP) is an important and actively studied information retrieval task, having various applications, such as query reformulation, query expansion, and retrieval system selection, among many others. The task has been primarily studied in the context of text and image retrieval, whereas QPP for content-based video retrieval (CBVR) remains largely underexplored. To this end, we propose the first benchmark for video query performance prediction (VQPP), comprising two text-to-video retrieval datasets and two CBVR systems, respectively. VQPP contains a total of 56K text queries and 51K videos, and comes with official training, validation and test splits, fostering direct comparisons and reproducible results. We explore multiple pre-retrieval and post-retrieval performance predictors, creating a representative benchmark for future exploration of QPP in the video domain. Our results show that pre-retrieval predictors obtain competitive performance, enabling applications before performing the retrieval step. We also demonstrate the applicability of VQPP by employing the best performing pre-retrieval predictor as reward model for training a large language model (LLM) on the query reformulation task via direct preference optimization (DPO). We release our benchmark and code at https://github.com/AdrianLutu/VQPP.

### 8. HyTRec: A Hybrid Temporal-Aware Attention Architecture for Long Behavior Sequential Recommendation

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Lei Xin, Yuhao Zheng, Ke Cheng, Changjiang Jiang, Zifan Zhang, Fanhu Zeng
- **URL**: <http://arxiv.org/abs/2602.18283v1>
- **Submitted**: 2026-02-20 15:11:40
- **Comment**: Preprint
- **Topic Keywords**: ltr, user behavior, retrieval, recommend, trec
- **Reason**: While the paper explores a related topic of sequential recommendation, it primarily focuses on recommender systems rather than information retrieval. Although it involves modeling user behavior, the emphasis is on sequential recommendation rather than click models or query understanding. The paper's relevance to the user's core research themes is somewhat limited.

#### Abstract
> Modeling long sequences of user behaviors has emerged as a critical frontier in generative recommendation. However, existing solutions face a dilemma: linear attention mechanisms achieve efficiency at the cost of retrieval precision due to limited state capacity, while softmax attention suffers from prohibitive computational overhead. To address this challenge, we propose HyTRec, a model featuring a Hybrid Attention architecture that explicitly decouples long-term stable preferences from short-term intent spikes. By assigning massive historical sequences to a linear attention branch and reserving a specialized softmax attention branch for recent interactions, our approach restores precise retrieval capabilities within industrial-scale contexts involving ten thousand interactions. To mitigate the lag in capturing rapid interest drifts within the linear layers, we furthermore design Temporal-Aware Delta Network (TADN) to dynamically upweight fresh behavioral signals while effectively suppressing historical noise. Empirical results on industrial-scale datasets confirm the superiority that our model maintains linear inference speed and outperforms strong baselines, notably delivering over 8% improvement in Hit Rate for users with ultra-long sequences with great efficiency.

### 9. QueryPlot: Generating Geological Evidence Layers using Natural Language Queries for Mineral Exploration

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Meng Ye, Xiao Lin, Georgina Lukoczki, Graham W. Lederer, Yi Yao
- **URL**: <http://arxiv.org/abs/2602.17784v1>
- **Submitted**: 2026-02-19 19:31:37
- **Topic Keywords**: query, queries, retrieval, rank, search
- **Reason**: The paper explores a novel application of Natural Language Processing (NLP) and semantic retrieval in the geology domain, which is somewhat related to the user's interests in NLP and IR. However, the focus on geological evidence layers and mineral exploration is not directly aligned with the user's core research themes in e-commerce, query understanding, and ranking models.

#### Abstract
> Mineral prospectivity mapping requires synthesizing heterogeneous geological knowledge, including textual deposit models and geospatial datasets, to identify regions likely to host specific mineral deposit types. This process is traditionally manual and knowledge-intensive. We present QueryPlot, a semantic retrieval and mapping framework that integrates large-scale geological text corpora with geologic map data using modern Natural Language Processing techniques. We curate descriptive deposit models for over 120 deposit types and transform the State Geologic Map Compilation (SGMC) polygons into structured textual representations. Given a user-defined natural language query, the system encodes both queries and region descriptions using a pretrained embedding model and computes semantic similarity scores to rank and spatially visualize regions as continuous evidence layers. QueryPlot supports compositional querying over deposit characteristics, enabling aggregation of multiple similarity-derived layers for multi-criteria prospectivity analysis. In a case study on tungsten skarn deposits, we demonstrate that embedding-based retrieval achieves high recall of known occurrences and produces prospective regions that closely align with expert-defined permissive tracts. Furthermore, similarity scores can be incorporated as additional features in supervised learning pipelines, yielding measurable improvements in classification performance. QueryPlot is implemented as a web-based system supporting interactive querying, visualization, and export of GIS-compatible prospectivity layers.To support future research, we have made the source code and datasets used in this study publicly available.

### 10. Enhancing Scientific Literature Chatbots with Retrieval-Augmented Generation: A Performance Evaluation of Vector and Graph-Based Systems

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Hamideh Ghanadian, Amin Kamali, Mohammad Hossein Tekieh
- **URL**: <http://arxiv.org/abs/2602.17856v1>
- **Submitted**: 2026-02-19 21:42:02
- **Topic Keywords**: relevance, rag, retrieval, search
- **Reason**: This paper is somewhat relevant to your research interests in Information Retrieval, particularly in the context of retrieval-augmented generation and vector/graph-based systems. However, the focus on scientific literature chatbots and their application to scientific knowledge accessibility is not directly aligned with your primary interests in e-commerce, query understanding, and ranking models.

#### Abstract
> This paper investigates the enhancement of scientific literature chatbots through retrieval-augmented generation (RAG), with a focus on evaluating vector- and graph-based retrieval systems. The proposed chatbot leverages both structured (graph) and unstructured (vector) databases to access scientific articles and gray literature, enabling efficient triage of sources according to research objectives. To systematically assess performance, we examine two use-case scenarios: retrieval from a single uploaded document and retrieval from a large-scale corpus. Benchmark test sets were generated using a GPT model, with selected outputs annotated for evaluation. The comparative analysis emphasizes retrieval accuracy and response relevance, providing insight into the strengths and limitations of each approach. The findings demonstrate the potential of hybrid RAG systems to improve accessibility to scientific knowledge and to support evidence-based decision making.

### 11. Condition-Gated Reasoning for Context-Dependent Biomedical Question Answering

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Jash Rajesh Parekh, Wonbin Kweon, Joey Chan, Rezarta Islamaj, Robert Leaman, Pengcheng Jiang, Chih-Hsuan Wei, Zhizheng Wang, Zhiyong Lu, Jiawei Han
- **URL**: <http://arxiv.org/abs/2602.17911v1>
- **Submitted**: 2026-02-20 00:17:14
- **Topic Keywords**: query, retrieval
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of biomedical question answering and knowledge graph construction. However, the focus on biomedical QA and condition-gated reasoning is not directly aligned with your primary interests in e-commerce and deep semantic understanding. While the paper touches on query understanding and ranking models, it is not a central match for your research themes.

#### Abstract
> Current biomedical question answering (QA) systems often assume that medical knowledge applies uniformly, yet real-world clinical reasoning is inherently conditional: nearly every decision depends on patient-specific factors such as comorbidities and contraindications. Existing benchmarks do not evaluate such conditional reasoning, and retrieval-augmented or graph-based methods lack explicit mechanisms to ensure that retrieved knowledge is applicable to given context. To address this gap, we propose CondMedQA, the first benchmark for conditional biomedical QA, consisting of multi-hop questions whose answers vary with patient conditions. Furthermore, we propose Condition-Gated Reasoning (CGR), a novel framework that constructs condition-aware knowledge graphs and selectively activates or prunes reasoning paths based on query conditions. Our findings show that CGR more reliably selects condition-appropriate answers while matching or exceeding state-of-the-art performance on biomedical QA benchmarks, highlighting the importance of explicitly modeling conditionality for robust medical reasoning.

### 12. Dual-Tree LLM-Enhanced Negative Sampling for Implicit Collaborative Filtering

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Jiayi Wu, Zhengyu Wu, Xunkai Li, Rong-Hua Li, Guoren Wang
- **URL**: <http://arxiv.org/abs/2602.18249v1>
- **Submitted**: 2026-02-20 14:32:41
- **Topic Keywords**: rag, recommend, search
- **Reason**: This paper focuses on recommender systems, specifically implicit collaborative filtering, and proposes a novel negative sampling method. While it leverages large language models, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The paper's relevance to information retrieval and search technologies is limited, but it does explore deep semantic understanding and real-time relevance optimization in the context of recommender systems.

#### Abstract
> Negative sampling is a pivotal technique in implicit collaborative filtering (CF) recommendation, enabling efficient and effective training by contrasting observed interactions with sampled unobserved ones.
  Recently, large language models (LLMs) have shown promise in recommender systems; however, research on LLM-empowered negative sampling remains underexplored.
  Existing methods heavily rely on textual information and task-specific fine-tuning, limiting practical applicability.
  To address this limitation, we propose a text-free and fine-tuning-free Dual-Tree LLM-enhanced Negative Sampling method (DTL-NS).
  It consists of two modules: (i) an offline false negative identification module that leverages hierarchical index trees to transform collaborative structural and latent semantic information into structured item-ID encodings for LLM inference, enabling accurate identification of false negatives; and (ii) a multi-view hard negative sampling module that combines user-item preference scores with item-item hierarchical similarities from these encodings to mine high-quality hard negatives, thus improving models' discriminative ability.
  Extensive experiments demonstrate the effectiveness of DTL-NS. For example, on the Amazon-sports dataset, DTL-NS outperforms the strongest baseline by 10.64% and 19.12% in Recall@20 and NDCG@20, respectively.
  Moreover, DTL-NS can be integrated into various implicit CF models and negative sampling methods, consistently enhancing their performance.

### 13. CUICurate: A GraphRAG-based Framework for Automated Clinical Concept Curation for NLP applications

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Victoria Blake, Mathew Miller, Jamie Novak, Sze-yuan Ooi, Blanca Gallego
- **URL**: <http://arxiv.org/abs/2602.17949v1>
- **Submitted**: 2026-02-20 03:00:13
- **Comment**: 30 pages, 6 figures, 4 tables
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and Information Retrieval (IR), particularly in the context of clinical NLP applications. However, it focuses on clinical concept curation and does not directly address your core areas of interest in query understanding, ranking models, or user behavior modeling.

#### Abstract
> Background: Clinical named entity recognition tools commonly map free text to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs). For many downstream tasks, however, the clinically meaningful unit is not a single CUI but a concept set comprising related synonyms, subtypes, and supertypes. Constructing such concept sets is labour-intensive, inconsistently performed, and poorly supported by existing tools, particularly for NLP pipelines that operate directly on UMLS CUIs. Methods We present CUICurate, a Graph-based retrieval-augmented generation (GraphRAG) framework for automated UMLS concept set curation. A UMLS knowledge graph (KG) was constructed and embedded for semantic retrieval. For each target concept, candidate CUIs were retrieved from the KG, followed by large language model (LLM) filtering and classification steps comparing two LLMs (GPT-5 and GPT-5-mini). The framework was evaluated on five lexically heterogeneous clinical concepts against a manually curated benchmark and gold-standard concept sets. Results Across all concepts, CUICurate produced substantially larger and more complete concept sets than the manual benchmarks whilst matching human precision. Comparisons between the two LLMs found that GPT-5-mini achieved higher recall during filtering, while GPT-5 produced classifications that more closely aligned with clinician judgements. Outputs were stable across repeated runs and computationally inexpensive. Conclusions CUICurate offers a scalable and reproducible approach to support UMLS concept set curation that substantially reduces manual effort. By integrating graph-based retrieval with LLM reasoning, the framework produces focused candidate concept sets that can be adapted to clinical NLP pipelines for different phenotyping and analytic requirements.

### 14. Information-Theoretic Storage Cost in Sentence Comprehension

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Kohei Kajikawa, Shinnosuke Isono, Ethan Gotlieb Wilcox
- **URL**: <http://arxiv.org/abs/2602.18217v1>
- **Submitted**: 2026-02-20 13:55:56
- **Topic Keywords**: rag
- **Reason**: This paper explores sentence comprehension and processing storage cost using an information-theoretic formalization, which is related to query understanding and ranking models in Information Retrieval. However, the focus on psycholinguistic theories and neural language models is somewhat tangential to the user's core research themes in IR and Search technologies. The connection to NLP is relevant, but the paper's primary contribution is in the area of sentence comprehension rather than search or retrieval.

#### Abstract
> Real-time sentence comprehension imposes a significant load on working memory, as comprehenders must maintain contextual information to anticipate future input. While measures of such load have played an important role in psycholinguistic theories, they have been formalized, largely, using symbolic grammars, which assign discrete, uniform costs to syntactic predictions. This study proposes a measure of processing storage cost based on an information-theoretic formalization, as the amount of information previous words carry about future context, under uncertainty. Unlike previous discrete, grammar-based metrics, this measure is continuous, theory-neutral, and can be estimated from pre-trained neural language models. The validity of this approach is demonstrated through three analyses in English: our measure (i) recovers well-known processing asymmetries in center embeddings and relative clauses, (ii) correlates with a grammar-based storage cost in a syntactically-annotated corpus, and (iii) predicts reading-time variance in two large-scale naturalistic datasets over and above baseline models with traditional information-based predictors.

### 15. The Statistical Signature of LLMs

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Ortal Hadad, Edoardo Loru, Jacopo Nudo, Niccol√≤ Di Marco, Matteo Cinelli, Walter Quattrociocchi
- **URL**: <http://arxiv.org/abs/2602.18152v1>
- **Submitted**: 2026-02-20 11:33:37
- **Topic Keywords**: rag
- **Reason**: The paper explores the statistical properties of Large Language Models (LLMs), which is somewhat related to information retrieval, particularly in the context of query understanding and ranking models. However, the focus on statistical signatures and compression behavior is not directly aligned with the user's primary research interests in IR, NLP, and user behavior modeling. While the paper touches on the generation of text, it does not explicitly address query understanding, ranking models, or user behavior modeling.

#### Abstract
> Large language models generate text through probabilistic sampling from high-dimensional distributions, yet how this process reshapes the structural statistical organization of language remains incompletely characterized. Here we show that lossless compression provides a simple, model-agnostic measure of statistical regularity that differentiates generative regimes directly from surface text. We analyze compression behavior across three progressively more complex information ecosystems: controlled human-LLM continuations, generative mediation of a knowledge infrastructure (Wikipedia vs. Grokipedia), and fully synthetic social interaction environments (Moltbook vs. Reddit). Across settings, compression reveals a persistent structural signature of probabilistic generation. In controlled and mediated contexts, LLM-produced language exhibits higher structural regularity and compressibility than human-written text, consistent with a concentration of output within highly recurrent statistical patterns. However, this signature shows scale dependence: in fragmented interaction environments the separation attenuates, suggesting a fundamental limit to surface-level distinguishability at small scales. This compressibility-based separation emerges consistently across models, tasks, and domains and can be observed directly from surface text without relying on model internals or semantic evaluation. Overall, our findings introduce a simple and robust framework for quantifying how generative systems reshape textual production, offering a structural perspective on the evolving complexity of communication.

### 16. Detecting Contextual Hallucinations in LLMs with Frequency-Aware Attention

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Siya Qi, Yudong Chen, Runcong Zhao, Qinglin Zhu, Zhanghao Hu, Wei Liu, Yulan He, Zheng Yuan, Lin Gui
- **URL**: <http://arxiv.org/abs/2602.18145v1>
- **Submitted**: 2026-02-20 11:18:45
- **Comment**: 25 pages, 10 figures
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to your research interests in Natural Language Processing (NLP) and deep semantic understanding, but it does not directly focus on Information Retrieval (IR) or Search technologies. The paper's emphasis on detecting contextual hallucinations in Large Language Models (LLMs) is relevant to your broader interests in NLP, but it does not align with your primary focus on IR and query understanding.

#### Abstract
> Hallucination detection is critical for ensuring the reliability of large language models (LLMs) in context-based generation. Prior work has explored intrinsic signals available during generation, among which attention offers a direct view of grounding behavior. However, existing approaches typically rely on coarse summaries that fail to capture fine-grained instabilities in attention. Inspired by signal processing, we introduce a frequency-aware perspective on attention by analyzing its variation during generation. We model attention distributions as discrete signals and extract high-frequency components that reflect rapid local changes in attention. Our analysis reveals that hallucinated tokens are associated with high-frequency attention energy, reflecting fragmented and unstable grounding behavior. Based on this insight, we develop a lightweight hallucination detector using high-frequency attention features. Experiments on the RAGTruth and HalluRAG benchmarks show that our approach achieves performance gains over verification-based, internal-representation-based, and attention-based methods across models and tasks.

### 17. Agentic Adversarial QA for Improving Domain-Specific LLMs

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Vincent Grari, Ciprian Tomoiaga, Sylvain Lamprier, Tatsunori Hashimoto, Marcin Detyniecki
- **URL**: <http://arxiv.org/abs/2602.18137v1>
- **Submitted**: 2026-02-20 10:53:09
- **Comment**: 9 pages, 1 Figure
- **Topic Keywords**: rag
- **Reason**: The paper focuses on improving Large Language Models (LLMs) for domain-specific tasks, which is somewhat related to information retrieval and query understanding. However, the primary focus is on fine-tuning LLMs for specialized domains, which is not directly aligned with the user's core research themes in IR and search technologies. The paper's emphasis on synthetic data generation and adversarial question-generation is more relevant to NLP and data mining.

#### Abstract
> Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited coverage of high-quality, task-relevant data. To address this, synthetic data generation methods such as paraphrasing or knowledge extraction are commonly applied. Although these approaches excel at factual recall and conceptual knowledge, they suffer from two critical shortcomings: (i) they provide minimal support for interpretive reasoning capabilities in these specialized domains, and (ii) they often produce synthetic corpora that are excessively large and redundant, resulting in poor sample efficiency. To overcome these gaps, we propose an adversarial question-generation framework that produces a compact set of semantically challenging questions. These questions are constructed by comparing the outputs of the model to be adapted and a robust expert model grounded in reference documents, using an iterative, feedback-driven process designed to reveal and address comprehension gaps. Evaluation on specialized subsets of the LegalBench corpus demonstrates that our method achieves greater accuracy with substantially fewer synthetic samples.

### 18. Analyzing LLM Instruction Optimization for Tabular Fact Verification

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Xiaotang Du, Giwon Hong, Wai-Chung Kwan, Rohit Saxena, Ivan Titov, Pasquale Minervini, Emily Allaway
- **URL**: <http://arxiv.org/abs/2602.17937v1>
- **Submitted**: 2026-02-20 01:56:27
- **Topic Keywords**: rag
- **Reason**: This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and related topics, specifically in the context of large language models (LLMs) and instruction optimization. However, it does not directly align with the user's core research themes in Information Retrieval (IR), query understanding, ranking models, or user behavior modeling. The paper's focus on tabular fact verification and LLM instruction optimization is not a central match for the user's research interests.

#### Abstract
> Instruction optimization provides a lightweight, model-agnostic approach to enhancing the reasoning performance of large language models (LLMs). This paper presents the first systematic comparison of instruction optimization, based on the DSPy optimization framework, for tabular fact verification. We evaluate four out-of-the-box prompting techniques that cover both text-only prompting and code use: direct prediction, Chain-of-Thought (CoT), ReAct with SQL tools, and CodeAct with Python execution. We study three optimizers from the DSPy framework -- COPRO, MiPROv2, and SIMBA -- across four benchmarks and three model families. We find that instruction optimization consistently improves verification accuracy, with MiPROv2 yielding the most stable gains for CoT, and SIMBA providing the largest benefits for ReAct agents, particularly at larger model scales. Behavioral analyses reveal that SIMBA encourages more direct reasoning paths by applying heuristics, thereby improving numerical comparison abilities in CoT reasoning and helping avoid unnecessary tool calls in ReAct agents. Across different prompting techniques, CoT remains effective for tabular fact checking, especially with smaller models. Although ReAct agents built with larger models can achieve competitive performance, they require careful instruction optimization.

### 19. Understanding Unreliability of Steering Vectors in Language Models: Geometric Predictors and the Limits of Linear Approximations

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Joschka Braun
- **URL**: <http://arxiv.org/abs/2602.17881v1>
- **Submitted**: 2026-02-19 22:37:05
- **Comment**: Master's Thesis, University of T√ºbingen. 89 pages, 34 figures. Portions of this work were published at the ICLR 2025 Workshop on Foundation Models in the Wild (see arXiv:2505.22637)
- **Topic Keywords**: rag
- **Reason**: This paper explores the limitations of steering vectors in language models, which is related to query understanding and ranking models in Information Retrieval. However, the focus on language model behavior and reliability does not directly align with the user's primary research themes of real-time relevance optimization and deep semantic understanding in IR. The connection to NLP is relevant, but the paper's scope is more specific to language model control rather than the broader topics of IR and search technologies.

#### Abstract
> Steering vectors are a lightweight method for controlling language model behavior by adding a learned bias to the activations at inference time. Although effective on average, steering effect sizes vary across samples and are unreliable for many target behaviors. In my thesis, I investigate why steering reliability differs across behaviors and how it is impacted by steering vector training data. First, I find that higher cosine similarity between training activation differences predicts more reliable steering. Second, I observe that behavior datasets where positive and negative activations are better separated along the steering direction are more reliably steerable. Finally, steering vectors trained on different prompt variations are directionally distinct, yet perform similarly well and exhibit correlated efficacy across datasets. My findings suggest that steering vectors are unreliable when the latent target behavior representation is not effectively approximated by the linear steering direction. Taken together, these insights offer a practical diagnostic for steering unreliability and motivate the development of more robust steering methods that explicitly account for non-linear latent behavior representations.

### 20. Validating Political Position Predictions of Arguments

- **LLM Score**: 2
- **Keyword Score**: 12
- **Authors**: Jordan Robinson, Angus R. Williams, Katie Atkinson, Anthony G. Cohn
- **URL**: <http://arxiv.org/abs/2602.18351v1>
- **Submitted**: 2026-02-20 17:03:44
- **Comment**: 13 pages, 6 figures, 6 tables. Under review
- **Topic Keywords**: ranking, pointwise, pairwise, retrieval, rank
- **Reason**: This paper focuses on validating political position predictions in argumentative discourse, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves language models and knowledge representation, the context and application are quite different from the user's interests.

#### Abstract
> Real-world knowledge representation often requires capturing subjective, continuous attributes -- such as political positions -- that conflict with pairwise validation, the widely accepted gold standard for human evaluation. We address this challenge through a dual-scale validation framework applied to political stance prediction in argumentative discourse, combining pointwise and pairwise human annotation. Using 22 language models, we construct a large-scale knowledge base of political position predictions for 23,228 arguments drawn from 30 debates that appeared on the UK politicial television programme \textit{Question Time}. Pointwise evaluation shows moderate human-model agreement (Krippendorff's $Œ±=0.578$), reflecting intrinsic subjectivity, while pairwise validation reveals substantially stronger alignment between human- and model-derived rankings ($Œ±=0.86$ for the best model). This work contributes: (i) a practical validation methodology for subjective continuous knowledge that balances scalability with reliability; (ii) a validated structured argumentation knowledge base enabling graph-based reasoning and retrieval-augmented generation in political domains; and (iii) evidence that ordinal structure can be extracted from pointwise language models predictions from inherently subjective real-world discourse, advancing knowledge representation capabilities for domains where traditional symbolic or categorical approaches are insufficient.

### 21. A Topology-Aware Positive Sample Set Construction and Feature Optimization Method in Implicit Collaborative Filtering

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Jiayi Wu, Zhengyu Wu, Xunkai Li, Rong-Hua Li, Guoren Wang
- **URL**: <http://arxiv.org/abs/2602.18288v1>
- **Submitted**: 2026-02-20 15:35:48
- **Topic Keywords**: ltr, rag
- **Reason**: This paper focuses on implicit collaborative filtering, which is a recommender system technique. While it touches on data mining and related topics, it doesn't align with the user's primary research interests in Information Retrieval, particularly query understanding, ranking models, and user behavior modeling.

#### Abstract
> Negative sampling strategies are widely used in implicit collaborative filtering to address issues like data sparsity and class imbalance. However, these methods often introduce false negatives, hindering the model's ability to accurately learn users' latent preferences. To mitigate this problem, existing methods adjust the negative sampling distribution based on statistical features from model training or the hardness of negative samples. Nevertheless, these methods face two key limitations: (1) over-reliance on the model's current representation capabilities; (2) failure to leverage the potential of false negatives as latent positive samples to guide model learning of user preferences more accurately. To address the above issues, we propose a Topology-aware Positive Sample Set Construction and Feature Optimization method (TPSC-FO). First, we design a simple topological community-aware false negative identification (FNI) method and observe that topological community structures in interaction networks can effectively identify false negatives. Motivated by this, we develop a topology-aware positive sample set construction module. This module employs a differential community detection strategy to capture topological community structures in implicit feedback, coupled with personalized noise filtration to reliably identify false negatives and convert them into positive samples. Additionally, we introduce a neighborhood-guided feature optimization module that refines positive sample features by incorporating neighborhood features in the embedding space, effectively mitigating noise in the positive samples. Extensive experiments on five real-world datasets and two synthetic datasets validate the effectiveness of TPSC-FO.

### 22. A Simple yet Effective Negative Sampling Plugin for Constructing Positive Sample Pairs in Implicit Collaborative Filtering

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Jiayi Wu, Zhengyu Wu, Xunkai Li, Ronghua Li, Guoren Wang
- **URL**: <http://arxiv.org/abs/2602.18206v1>
- **Submitted**: 2026-02-20 13:34:43
- **Topic Keywords**: ranking, recommend, rank
- **Reason**: This paper focuses on implicit collaborative filtering and negative sampling, which is somewhat related to information retrieval, but it does not directly address query understanding, ranking models, or user behavior modeling. The paper's emphasis on recommender systems and collaborative filtering is not a central match for your primary research interests in information retrieval and deep semantic understanding.

#### Abstract
> Most implicit collaborative filtering (CF) models are trained with negative sampling, where existing work designs sophisticated strategies for high-quality negatives while largely overlooking the exploration of positive samples. Although some denoising recommendation methods can be applied to implicit CF for denoising positive samples, they often sparsify positive supervision. Moreover, these approaches generally overlook user activity bias during training, leading to insufficient learning for inactive users. To address these issues, we propose a simple yet effective negative sampling plugin, PSP-NS, from the perspective of enhancing positive supervision signals. It builds a user-item bipartite graph with edge weights indicating interaction confidence inferred from global and local patterns, generates positive sample pairs via replication-based reweighting to strengthen positive signals, and adopts an activity-aware weighting scheme to effectively learn inactive users' preferences. We provide theoretical insights from a margin-improvement perspective, explaining why PSP-NS tends to improve ranking quality (e.g., Precision@k/Recall@k), and conduct extensive experiments on four real-world datasets to demonstrate its superiority. For instance, PSP-NS boosts Recall@30 and Precision@30 by 32.11% and 22.90% on Yelp over the strongest baselines. PSP-NS can be integrated with various implicit CF recommenders or negative sampling methods to enhance their performance.

### 23. PsihoRo: Depression and Anxiety Romanian Text Corpus

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Alexandra Ciobotaru, Ana-Maria Bucur, Liviu P. Dinu
- **URL**: <http://arxiv.org/abs/2602.18324v1>
- **Submitted**: 2026-02-20 16:24:23
- **Comment**: This article was accepted at LREC 2026
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your research interests as it focuses on creating a mental health corpus for Romanian, which is outside your primary area of Information Retrieval and Search technologies. Although it involves Natural Language Processing, it does not align with your interests in query understanding, ranking models, or user behavior modeling.

#### Abstract
> Psychological corpora in NLP are collections of texts used to analyze human psychology, emotions, and mental health. These texts allow researchers to study psychological constructs, detect mental health issues and analyze emotional language. However, mental health data can be difficult to collect correctly from social media, due to suppositions made by the collectors. A more pragmatic strategy involves gathering data through open-ended questions and then assessing this information with self-report screening surveys. This method was employed successfully for English, a language with a lot of psychological NLP resources. However, this cannot be stated for Romanian, which currently has no open-source mental health corpus. To address this gap, we have created the first corpus for depression and anxiety in Romanian, by utilizing a form with 6 open-ended questions along with the standardized PHQ-9 and GAD-7 screening questionnaires. Consisting of the texts of 205 respondents and although it may seem small, PsihoRo is a first step towards understanding and analyzing texts regarding the mental health of the Romanian population. We employ statistical analysis, text analysis using Romanian LIWC, emotion detection and topic modeling to show what are the most important features of this newly introduced resource to the NLP community.

### 24. TFL: Targeted Bit-Flip Attack on Large Language Model

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jingkai Guo, Chaitali Chakrabarti, Deliang Fan
- **URL**: <http://arxiv.org/abs/2602.17837v1>
- **Submitted**: 2026-02-19 20:59:47
- **Comment**: 13 pages, 11 figures. Preprint
- **Topic Keywords**: queries
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. It focuses on targeted attacks on Large Language Models, which is a security-related topic and does not align with your core research themes.

#### Abstract
> Large language models (LLMs) are increasingly deployed in safety and security critical applications, raising concerns about their robustness to model parameter fault injection attacks. Recent studies have shown that bit-flip attacks (BFAs), which exploit computer main memory (i.e., DRAM) vulnerabilities to flip a small number of bits in model weights, can severely disrupt LLM behavior. However, existing BFA on LLM largely induce un-targeted failure or general performance degradation, offering limited control over manipulating specific or targeted outputs. In this paper, we present TFL, a novel targeted bit-flip attack framework that enables precise manipulation of LLM outputs for selected prompts while maintaining almost no or minor degradation on unrelated inputs. Within our TFL framework, we propose a novel keyword-focused attack loss to promote attacker-specified target tokens in generative outputs, together with an auxiliary utility score that balances attack effectiveness against collateral performance impact on benign data. We evaluate TFL on multiple LLMs (Qwen, DeepSeek, Llama) and benchmarks (DROP, GSM8K, and TriviaQA). The experiments show that TFL achieves successful targeted LLM output manipulations with less than 50 bit flips and significantly reduced effect on unrelated queries compared to prior BFA approaches. This demonstrates the effectiveness of TFL and positions it as a new class of stealthy and targeted LLM model attack.

### 25. VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Harshul Raj Surana, Arijit Maji, Aryan Vats, Akash Ghosh, Sriparna Saha, Amit Sheth
- **URL**: <http://arxiv.org/abs/2602.18429v1>
- **Submitted**: 2026-02-20 18:53:07
- **Topic Keywords**: rag
- **Reason**: This paper focuses on developing a dataset and framework for culturally aware reasoning models, which is somewhat related to information retrieval and NLP. However, the specific domain (Indian culture) and task (question-answering) are not directly aligned with the user's research interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models.

### 26. Analyzing and Improving Chain-of-Thought Monitorability Through Information Theory

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Usman Anwar, Tim Bakker, Dana Kianfar, Cristina Pinneri, Christos Louizos
- **URL**: <http://arxiv.org/abs/2602.18297v1>
- **Submitted**: 2026-02-20 15:50:30
- **Comment**: First two authors contributed equally
- **Topic Keywords**: acl
- **Reason**: This paper focuses on analyzing and improving Chain-of-Thought monitors, which is a topic in Natural Language Processing (NLP) and Large Language Model (LLM) research. While it touches on information theory and mutual information, it doesn't directly relate to Information Retrieval (IR), Search technologies, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Chain-of-thought (CoT) monitors are LLM-based systems that analyze reasoning traces to detect when outputs may exhibit attributes of interest, such as test-hacking behavior during code generation. In this paper, we use information-theoretic analysis to show that non-zero mutual information between CoT and output is a necessary but not sufficient condition for CoT monitorability. We identify two sources of approximation error that may undermine the performance of CoT monitors in practice: information gap, which measures the extent to which the monitor can extract the information available in CoT, and elicitation error, which measures the extent to which the monitor approximates the optimal monitoring function. We further demonstrate that CoT monitorability can be systematically improved through targeted training objectives. To this end, we propose two complementary approaches: (a) an oracle-based method that directly rewards the monitored model for producing CoTs that maximize monitor accuracy, and (b) a more practical, label-free approach that maximizes conditional mutual information between outputs and CoTs. Across multiple different environments, we show both methods significantly improve monitor accuracy while preventing CoT degeneration even when training against a monitor, thereby mitigating reward hacking when the task reward is imperfectly specified.

### 27. Improving Sampling for Masked Diffusion Models via Information Gain

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Kaisen Yang, Jayden Teoh, Kaicheng Yang, Yitong Zhang, Alex Lamb
- **URL**: <http://arxiv.org/abs/2602.18176v1>
- **Submitted**: 2026-02-20 12:26:03
- **Comment**: https://github.com/yks23/Information-Gain-Sampler
- **Topic Keywords**: rag
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves information gain, it's in the context of masked diffusion models for tasks like reasoning, coding, and creative writing, which is not a central focus of your research.

#### Abstract
> Masked Diffusion Models (MDMs) offer greater flexibility in decoding order than autoregressive models but require careful planning to achieve high-quality generation. Existing samplers typically adopt greedy heuristics, prioritizing positions with the highest local certainty to decode at each step. Through failure case analysis, we identify a fundamental limitation of this approach: it neglects the downstream impact of current decoding choices on subsequent steps and fails to minimize cumulative uncertainty. In particular, these methods do not fully exploit the non-causal nature of MDMs, which enables evaluating how a decoding decision reshapes token probabilities/uncertainty across all remaining masked positions. To bridge this gap, we propose the Info-Gain Sampler, a principled decoding framework that balances immediate uncertainty with information gain over future masked tokens. Extensive evaluations across diverse architectures and tasks (reasoning, coding, creative writing, and image generation) demonstrate that Info-Gain Sampler consistently outperforms existing samplers for MDMs. For instance, it achieves a 3.6% improvement in average accuracy on reasoning tasks and a 63.1% win-rate in creative writing. Notably, on reasoning tasks it reduces cumulative uncertainty from 78.4 to 48.6, outperforming the best baseline by a large margin. The code will be available at https://github.com/yks23/Information-Gain-Sampler.

### 28. SPQ: An Ensemble Technique for Large Language Model Compression

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jiamin Yao, Eren Gultepe
- **URL**: <http://arxiv.org/abs/2602.18420v1>
- **Submitted**: 2026-02-20 18:44:16
- **Comment**: Accepted to LREC 2026 Main Conference
- **Topic Keywords**: rank
- **Reason**: This paper focuses on large language model compression techniques, which is not directly related to your primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on NLP, the specific topic of model compression is not a central match for your research themes.

#### Abstract
> This study presents an ensemble technique, SPQ (SVD-Pruning-Quantization), for large language model (LLM) compression that combines variance-retained singular value decomposition (SVD), activation-based pruning, and post-training linear quantization. Each component targets a different source of inefficiency: i) pruning removes redundant neurons in MLP layers, ii) SVD reduces attention projections into compact low-rank factors, iii) and 8-bit quantization uniformly compresses all linear layers. At matched compression ratios, SPQ outperforms individual methods (SVD-only, pruning-only, or quantization-only) in perplexity, demonstrating the benefit of combining complementary techniques. Applied to LLaMA-2-7B, SPQ achieves up to 75% memory reduction while maintaining or improving perplexity (e.g., WikiText-2 5.47 to 4.91) and preserving accuracy on downstream benchmarks such as C4, TruthfulQA, and GSM8K. Compared to strong baselines like GPTQ and SparseGPT, SPQ offers competitive perplexity and accuracy while using less memory (6.86 GB vs. 7.16 GB for GPTQ). Moreover, SPQ improves inference throughput over GPTQ, achieving up to a 1.9x speedup, which further enhances its practicality for real-world deployment. The effectiveness of SPQ's robust compression through layer-aware and complementary compression techniques may provide practical deployment of LLMs in memory-constrained environments. Code is available at: https://github.com/JiaminYao/SPQ_LLM_Compression/

### 29. ADAPT: Hybrid Prompt Optimization for LLM Feature Visualization

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Jo√£o N. Cardoso, Arlindo L. Oliveira, Bruno Martins
- **URL**: <http://arxiv.org/abs/2602.17867v1>
- **Submitted**: 2026-02-19 22:03:25
- **Topic Keywords**: search
- **Reason**: This paper focuses on feature visualization for Large Language Models (LLMs), which is not directly related to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves LLMs, the paper's primary goal is to optimize feature visualization, which is not a central concern in your research interests.

#### Abstract
> Understanding what features are encoded by learned directions in LLM activation space requires identifying inputs that strongly activate them. Feature visualization, which optimizes inputs to maximally activate a target direction, offers an alternative to costly dataset search approaches, but remains underexplored for LLMs due to the discrete nature of text. Furthermore, existing prompt optimization techniques are poorly suited to this domain, which is highly prone to local minima. To overcome these limitations, we introduce ADAPT, a hybrid method combining beam search initialization with adaptive gradient-guided mutation, designed around these failure modes. We evaluate on Sparse Autoencoder latents from Gemma 2 2B, proposing metrics grounded in dataset activation statistics to enable rigorous comparison, and show that ADAPT consistently outperforms prior methods across layers and latent types. Our results establish that feature visualization for LLMs is tractable, but requires design assumptions tailored to the domain.

### 30. Mind the Style: Impact of Communication Style on Human-Chatbot Interaction

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Erik Derner, Dalibor Kuƒçera, Aditya Gulati, Ayoub Bagheri, Nuria Oliver
- **URL**: <http://arxiv.org/abs/2602.17850v1>
- **Submitted**: 2026-02-19 21:32:41
- **Topic Keywords**: personalization
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it touches on conversational agents and user interaction, its focus on communication style and user experience is more aligned with Human-Computer Interaction and User Experience Design.

#### Abstract
> Conversational agents increasingly mediate everyday digital interactions, yet the effects of their communication style on user experience and task success remain unclear. Addressing this gap, we describe the results of a between-subject user study where participants interact with one of two versions of a chatbot called NAVI which assists users in an interactive map-based 2D navigation task. The two chatbot versions differ only in communication style: one is friendly and supportive, while the other is direct and task-focused. Our results show that the friendly style increases subjective satisfaction and significantly improves task completion rates among female participants only, while no baseline differences between female and male participants were observed in a control condition without the chatbot. Furthermore, we find little evidence of users mimicking the chatbot's style, suggesting limited linguistic accommodation. These findings highlight the importance of user- and task-sensitive conversational agents and support that communication style personalization can meaningfully enhance interaction quality and performance.

### 31. FENCE: A Financial and Multimodal Jailbreak Detection Dataset

- **LLM Score**: 0
- **Keyword Score**: 4
- **Authors**: Mirae Kim, Seonghun Jeong, Youngjun Kwak
- **URL**: <http://arxiv.org/abs/2602.18154v1>
- **Submitted**: 2026-02-20 11:40:41
- **Comment**: lrec 2026 accepted paper
- **Topic Keywords**: queries, korea
- **Reason**: This paper is not relevant to your research interests as it focuses on multimodal jailbreak detection in finance, which is outside your primary area of interest in Information Retrieval and Search technologies, particularly query understanding, ranking models, and user behavior modeling.

#### Abstract
> Jailbreaking poses a significant risk to the deployment of Large Language Models (LLMs) and Vision Language Models (VLMs). VLMs are particularly vulnerable because they process both text and images, creating broader attack surfaces. However, available resources for jailbreak detection are scarce, particularly in finance. To address this gap, we present FENCE, a bilingual (Korean-English) multimodal dataset for training and evaluating jailbreak detectors in financial applications. FENCE emphasizes domain realism through finance-relevant queries paired with image-grounded threats. Experiments with commercial and open-source VLMs reveal consistent vulnerabilities, with GPT-4o showing measurable attack success rates and open-source models displaying greater exposure. A baseline detector trained on FENCE achieves 99 percent in-distribution accuracy and maintains strong performance on external benchmarks, underscoring the dataset's robustness for training reliable detection models. FENCE provides a focused resource for advancing multimodal jailbreak detection in finance and for supporting safer, more reliable AI systems in sensitive domains. Warning: This paper includes example data that may be offensive.

### 32. The Economical-Ecological Benefits of Matching Non-matching Socks

- **LLM Score**: 0
- **Keyword Score**: 2
- **Authors**: Teddy Lazebnik
- **URL**: <http://arxiv.org/abs/2602.18221v1>
- **Submitted**: 2026-02-20 14:00:20
- **Topic Keywords**: rag
- **Reason**: This paper is completely unrelated to Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. It appears to be a study on the economic and ecological benefits of pairing non-matching socks, which is outside the scope of your research interests.

#### Abstract
> Socks are produced and replaced at a massive scale, yet their paired use makes them unusually vulnerable to waste, as the loss of a single sock can strand usable wear-capacity and trigger premature replacement. In this study, we quantify the economic and ecological value of pairing non-matching \say{orphan} socks, and the social cost that discourages this behaviour. We formalize sock ownership as a sequential decision problem under uncertainty in which socks wear out and disappear stochastically during laundering, while public exposure induces a person-specific mismatch penalty. We conducted an in-person study to estimate mismatch sensitivity and diversity preference, linking behavioural heterogeneity to optimal mixing strategies. Using these results and a computer simulation-based evaluation of interpretable pairing policies, we show that strict matching can appear resource-frugal largely because it generates many sockless days, whereas controlled tolerance for mismatch sustains service and reduces stranded capacity across loss regimes. This study establishes the feasibility of matching non-matching socks while outlining its limitations and challenges.

---

