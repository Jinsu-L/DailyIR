[
    {
        "title": "Performance of the SafeTerm AI-Based MedDRA Query System Against Standardised MedDRA Queries",
        "abstract": "In pre-market drug safety review, grouping related adverse event terms into SMQs or OCMQs is critical for signal detection. We assess the performance of SafeTerm Automated Medical Query (AMQ) on MedDRA SMQs. The AMQ is a novel quantitative artificial intelligence system that understands and processes medical terminology and automatically retrieves relevant MedDRA Preferred Terms (PTs) for a given input query, ranking them by a relevance score (0-1) using multi-criteria statistical methods. The system (SafeTerm) embeds medical query terms and MedDRA PTs in a multidimensional vector space, then applies cosine similarity, and extreme-value clustering to generate a ranked list of PTs. Validation was conducted against tier-1 SMQs (110 queries, v28.1). Precision, recall and F1 were computed at multiple similarity-thresholds, defined either manually or using an automated method. High recall (94%)) is achieved at moderate similarity thresholds, indicative of good retrieval sensitivity. Higher thresholds filter out more terms, resulting in improved precision (up to 89%). The optimal threshold (0.70)) yielded an overall recall of (48%) and precision of (45%) across all 110 queries. Restricting to narrow-term PTs achieved slightly better performance at an increased (+0.05) similarity threshold, confirming increased relatedness of narrow versus broad terms. The automatic threshold (0.66) selection prioritizes recall (0.58) to precision (0.29). SafeTerm AMQ achieves comparable, satisfactory performance on SMQs and sanitized OCMQs. It is therefore a viable supplementary method for automated MedDRA query generation, balancing recall and precision. We recommend using suitable MedDRA PT terminology in query formulation and applying the automated threshold method to optimise recall. Increasing similarity scores allows refined, narrow terms selection.",
        "url": "http://arxiv.org/abs/2512.07552v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07552v1",
        "arxiv_id": "2512.07552v1",
        "authors": [
            "Francois Vandenhende",
            "Anna Georgiou",
            "Michalis Georgiou",
            "Theodoros Psaras",
            "Ellie Karekla",
            "Elena Hadjicosta"
        ],
        "submitted": "2025-12-08 13:32:20",
        "source": "arxiv",
        "comment": "8 pages, 3 figures",
        "score": 16,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper discusses an AI‑based retrieval system that embeds medical terms and ranks them using similarity metrics, aligning with query understanding and ranking models in IR. However, it focuses on a narrow medical domain and lacks broader IR topics such as user behavior modeling or real‑time relevance optimization, making it a somewhat related but not central match."
    },
    {
        "title": "Reformulate, Retrieve, Localize: Agents for Repository-Level Bug Localization",
        "abstract": "Bug localization remains a critical yet time-consuming challenge in large-scale software repositories. Traditional information retrieval-based bug localization (IRBL) methods rely on unchanged bug descriptions, which often contain noisy information, leading to poor retrieval accuracy. Recent advances in large language models (LLMs) have improved bug localization through query reformulation, yet the effect on agent performance remains unexplored. In this study, we investigate how an LLM-powered agent can improve file-level bug localization via lightweight query reformulation and summarization. We first employ an open-source, non-fine-tuned LLM to extract key information from bug reports, such as identifiers and code snippets, and reformulate queries pre-retrieval. Our agent then orchestrates BM25 retrieval using these preprocessed queries, automating localization workflow at scale. Using the best-performing query reformulation technique, our agent achieves 35% better ranking in first-file retrieval than our BM25 baseline and up to +22% file retrieval performance over SWE-agent.",
        "url": "http://arxiv.org/abs/2512.07022v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07022v1",
        "arxiv_id": "2512.07022v1",
        "authors": [
            "Genevieve Caumartin",
            "Glaucia Melo"
        ],
        "submitted": "2025-12-07 22:25:11",
        "source": "arxiv",
        "comment": "Accepted at BoatSE 2026",
        "score": 15,
        "keyword_reasons": [
            "Found 'information retrieval' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on bug localization in software repositories, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it does involve query reformulation and retrieval, the context is specific to software engineering and not aligned with the user's interests in e-commerce or general information retrieval."
    },
    {
        "title": "Automated Generation of Custom MedDRA Queries Using SafeTerm Medical Map",
        "abstract": "In pre-market drug safety review, grouping related adverse event terms into standardised MedDRA queries or the FDA Office of New Drugs Custom Medical Queries (OCMQs) is critical for signal detection. We present a novel quantitative artificial intelligence system that understands and processes medical terminology and automatically retrieves relevant MedDRA Preferred Terms (PTs) for a given input query, ranking them by a relevance score using multi-criteria statistical methods. The system (SafeTerm) embeds medical query terms and MedDRA PTs in a multidimensional vector space, then applies cosine similarity and extreme-value clustering to generate a ranked list of PTs. Validation was conducted against the FDA OCMQ v3.0 (104 queries), restricted to valid MedDRA PTs. Precision, recall and F1 were computed across similarity-thresholds. High recall (>95%) is achieved at moderate thresholds. Higher thresholds improve precision (up to 86%). The optimal threshold (~0.70 - 0.75) yielded recall ~50% and precision ~33%. Narrow-term PT subsets performed similarly but required slightly higher similarity thresholds. The SafeTerm AI-driven system provides a viable supplementary method for automated MedDRA query generation. A similarity threshold of ~0.60 is recommended initially, with increased thresholds for refined term selection.",
        "url": "http://arxiv.org/abs/2512.07694v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07694v1",
        "arxiv_id": "2512.07694v1",
        "authors": [
            "Francois Vandenhende",
            "Anna Georgiou",
            "Michalis Georgiou",
            "Theodoros Psaras",
            "Ellie Karekla",
            "Elena Hadjicosta"
        ],
        "submitted": "2025-12-08 16:33:03",
        "source": "arxiv",
        "comment": "12 pages, 4 figures",
        "score": 14,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'ranking' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves ranking models and vector space embeddings, the context is specific to medical terminology and drug safety review, which is not a central focus of your research."
    },
    {
        "title": "FVA-RAG: Falsification-Verification Alignment for Mitigating Sycophantic Hallucinations",
        "abstract": "Retrieval-Augmented Generation (RAG) systems have significantly reduced hallucinations in Large Language Models (LLMs) by grounding responses in external context. However, standard RAG architectures suffer from a critical vulnerability: Retrieval Sycophancy. When presented with a query based on a false premise or a common misconception, vector-based retrievers tend to fetch documents that align with the user's bias rather than objective truth, leading the model to \"hallucinate with citations.\"\n  In this work, we introduce Falsification-Verification Alignment RAG (FVA-RAG), a framework that shifts the retrieval paradigm from Inductive Verification (seeking support) to Deductive Falsification (seeking disproof). Unlike existing \"Self-Correction\" methods that rely on internal consistency, FVA-RAG deploys a distinct Adversarial Retrieval Policy that actively generates \"Kill Queries\"-targeted search terms designed to surface contradictory evidence. We introduce a dual-verification mechanism that explicitly weighs the draft answer against this \"Anti-Context.\" Preliminary experiments on a dataset of common misconceptions demonstrate that FVA-RAG significantly improves robustness against sycophantic hallucinations compared to standard RAG baselines, effectively acting as an inference-time \"Red Team\" for factual generation.",
        "url": "http://arxiv.org/abs/2512.07015v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07015v1",
        "arxiv_id": "2512.07015v1",
        "authors": [
            "Mayank Ravishankara"
        ],
        "submitted": "2025-12-07 21:28:42",
        "source": "arxiv",
        "comment": null,
        "score": 14,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper introduces a framework for mitigating hallucinations in Retrieval-Augmented Generation systems, which is related to query understanding and ranking models. However, the focus on falsification and verification is not directly aligned with the user's core research themes in Information Retrieval and Search technologies, particularly in the e-commerce domain. The connection to Natural Language Processing is more relevant, but still not a central match."
    },
    {
        "title": "MUSE: A Simple Yet Effective Multimodal Search-Based Framework for Lifelong User Interest Modeling",
        "abstract": "Lifelong user interest modeling is crucial for industrial recommender systems, yet existing approaches rely predominantly on ID-based features, suffering from poor generalization on long-tail items and limited semantic expressiveness. While recent work explores multimodal representations for behavior retrieval in the General Search Unit (GSU), they often neglect multimodal integration in the fine-grained modeling stage -- the Exact Search Unit (ESU). In this work, we present a systematic analysis of how to effectively leverage multimodal signals across both stages of the two-stage lifelong modeling framework. Our key insight is that simplicity suffices in the GSU: lightweight cosine similarity with high-quality multimodal embeddings outperforms complex retrieval mechanisms. In contrast, the ESU demands richer multimodal sequence modeling and effective ID-multimodal fusion to unlock its full potential. Guided by these principles, we propose MUSE, a simple yet effective multimodal search-based framework. MUSE has been deployed in Taobao display advertising system, enabling 100K-length user behavior sequence modeling and delivering significant gains in top-line metrics with negligible online latency overhead. To foster community research, we share industrial deployment practices and open-source the first large-scale dataset featuring ultra-long behavior sequences paired with high-quality multimodal embeddings. Our code and data is available at https://taobao-mm.github.io.",
        "url": "http://arxiv.org/abs/2512.07216v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07216v1",
        "arxiv_id": "2512.07216v1",
        "authors": [
            "Bin Wu",
            "Feifan Yang",
            "Zhangming Chan",
            "Yu-Ran Gu",
            "Jiawei Feng",
            "Chao Yi",
            "Xiang-Rong Sheng",
            "Han Zhu",
            "Jian Xu",
            "Mang Ye",
            "Bo Zheng"
        ],
        "submitted": "2025-12-08 06:55:13",
        "source": "arxiv",
        "comment": null,
        "score": 11,
        "keyword_reasons": [
            "Found 'ltr' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'user behavior' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of lifelong user interest modeling and multimodal search-based frameworks. However, it focuses more on recommender systems and industrial deployment practices, which is a secondary area of interest for you. The paper's emphasis on deep semantic understanding and real-time relevance optimization aligns with your primary focus, but to a lesser extent."
    },
    {
        "title": "SPAD: Seven-Source Token Probability Attribution with Syntactic Aggregation for Detecting Hallucinations in RAG",
        "abstract": "Detecting hallucinations in Retrieval-Augmented Generation (RAG) remains a challenge. Prior approaches attribute hallucinations to a binary conflict between internal knowledge (stored in FFNs) and retrieved context. However, this perspective is incomplete, failing to account for the impact of other components in the generative process, such as the user query, previously generated tokens, the current token itself, and the final LayerNorm adjustment. To address this, we introduce SPAD. First, we mathematically attribute each token's probability into seven distinct sources: Query, RAG, Past, Current Token, FFN, Final LayerNorm, and Initial Embedding. This attribution quantifies how each source contributes to the generation of the current token. Then, we aggregate these scores by POS tags to quantify how different components drive specific linguistic categories. By identifying anomalies, such as Nouns relying on Final LayerNorm, SPAD effectively detects hallucinations. Extensive experiments demonstrate that SPAD achieves state-of-the-art performance",
        "url": "http://arxiv.org/abs/2512.07515v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07515v1",
        "arxiv_id": "2512.07515v1",
        "authors": [
            "Pengqian Lu",
            "Jie Lu",
            "Anjin Liu",
            "Guangquan Zhang"
        ],
        "submitted": "2025-12-08 12:50:41",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 6,
        "llm_reason": "This paper is somewhat related to your research interests in Information Retrieval, particularly in the context of Retrieval-Augmented Generation (RAG) and detecting hallucinations. However, the focus is more on NLP and deep semantic understanding, which aligns with your interests, but the specific application and methodology differ from your core research themes."
    },
    {
        "title": "Beyond Real: Imaginary Extension of Rotary Position Embeddings for Long-Context LLMs",
        "abstract": "Rotary Position Embeddings (RoPE) have become a standard for encoding sequence order in Large Language Models (LLMs) by applying rotations to query and key vectors in the complex plane. Standard implementations, however, utilize only the real component of the complex-valued dot product for attention score calculation. This simplification discards the imaginary component, which contains valuable phase information, leading to a potential loss of relational details crucial for modeling long-context dependencies. In this paper, we propose an extension that re-incorporates this discarded imaginary component. Our method leverages the full complex-valued representation to create a dual-component attention score. We theoretically and empirically demonstrate that this approach enhances the modeling of long-context dependencies by preserving more positional information. Furthermore, evaluations on a suite of long-context language modeling benchmarks show that our method consistently improves performance over the standard RoPE, with the benefits becoming more significant as context length increases. The code is available at https://github.com/OpenMOSS/rope_pp.",
        "url": "http://arxiv.org/abs/2512.07525v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07525v1",
        "arxiv_id": "2512.07525v1",
        "authors": [
            "Xiaoran Liu",
            "Yuerong Song",
            "Zhigeng Liu",
            "Zengfeng Huang",
            "Qipeng Guo",
            "Zhaoxiang Liu",
            "Shiguo Lian",
            "Ziwei He",
            "Xipeng Qiu"
        ],
        "submitted": "2025-12-08 12:59:54",
        "source": "arxiv",
        "comment": "20 pages, 6 figures, under review",
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper focuses on improving Large Language Models (LLMs) by leveraging the full complex-valued representation of Rotary Position Embeddings, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. The paper's emphasis on long-context language modeling and its application to LLMs does not align with the user's core research themes."
    },
    {
        "title": "OnePiece: The Great Route to Generative Recommendation -- A Case Study from Tencent Algorithm Competition",
        "abstract": "In past years, the OpenAI's Scaling-Laws shows the amazing intelligence with the next-token prediction paradigm in neural language modeling, which pointing out a free-lunch way to enhance the model performance by scaling the model parameters. In RecSys, the retrieval stage is also follows a 'next-token prediction' paradigm, to recall the hunderds of items from the global item set, thus the generative recommendation usually refers specifically to the retrieval stage (without Tree-based methods). This raises a philosophical question: without a ground-truth next item, does the generative recommendation also holds a potential scaling law? In retrospect, the generative recommendation has two different technique paradigms: (1) ANN-based framework, utilizing the compressed user embedding to retrieve nearest other items in embedding space, e.g, Kuaiformer. (2) Auto-regressive-based framework, employing the beam search to decode the item from whole space, e.g, OneRec. In this paper, we devise a unified encoder-decoder framework to validate their scaling-laws at same time. Our empirical finding is that both of their losses strictly adhere to power-law Scaling Laws ($R^2$>0.9) within our unified architecture.",
        "url": "http://arxiv.org/abs/2512.07424v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07424v1",
        "arxiv_id": "2512.07424v1",
        "authors": [
            "Jiangxia Cao",
            "Shuo Yang",
            "Zijun Wang",
            "Qinghai Tan"
        ],
        "submitted": "2025-12-08 10:56:56",
        "source": "arxiv",
        "comment": "Work in progress",
        "score": 5,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)",
            "Found 'recsys' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores generative recommendation techniques in the context of recommender systems, which is somewhat related to the user's interests in Information Retrieval and Search technologies. However, the focus on neural language modeling and scaling laws in recommender systems is not a central match to the user's primary research themes, such as query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Efficient ASR for Low-Resource Languages: Leveraging Cross-Lingual Unlabeled Data",
        "abstract": "Automatic speech recognition for low-resource languages remains fundamentally constrained by the scarcity of labeled data and computational resources required by state-of-the-art models. We present a systematic investigation into cross-lingual continuous pretraining for low-resource languages, using Perso-Arabic languages (Persian, Arabic, and Urdu) as our primary case study. Our approach demonstrates that strategic utilization of unlabeled speech data can effectively bridge the resource gap without sacrificing recognition accuracy. We construct a 3,000-hour multilingual corpus through a scalable unlabeled data collection pipeline and employ targeted continual pretraining combined with morphologically-aware tokenization to develop a 300M parameter model that achieves performance comparable to systems 5 times larger. Our model outperforms Whisper Large v3 (1.5B parameters) on Persian and achieves competitive results on Arabic and Urdu despite using significantly fewer parameters and substantially less labeled data. These findings challenge the prevailing assumption that ASR quality scales primarily with model size, revealing instead that data relevance and strategic pretraining are more critical factors for low-resource scenarios. This work provides a practical pathway toward inclusive speech technology, enabling effective ASR for underrepresented languages without dependence on massive computational infrastructure or proprietary datasets.",
        "url": "http://arxiv.org/abs/2512.07277v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07277v1",
        "arxiv_id": "2512.07277v1",
        "authors": [
            "Srihari Bandarupalli",
            "Bhavana Akkiraju",
            "Charan Devarakonda",
            "Vamsiraghusimha Narsinga",
            "Anil Kumar Vuppala"
        ],
        "submitted": "2025-12-08 08:16:34",
        "source": "arxiv",
        "comment": "Accepted in AACL IJCNLP 2025",
        "score": 5,
        "keyword_reasons": [
            "Found 'relevance' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Automatic Speech Recognition (ASR) for low-resource languages, leveraging cross-lingual unlabeled data. While it touches on the concept of 'relevance optimization', it's primarily concerned with ASR and not directly related to Information Retrieval, Search technologies, or query understanding, which are core areas of your research interests."
    },
    {
        "title": "Ensembling LLM-Induced Decision Trees for Explainable and Robust Error Detection",
        "abstract": "Error detection (ED), which aims to identify incorrect or inconsistent cell values in tabular data, is important for ensuring data quality. Recent state-of-the-art ED methods leverage the pre-trained knowledge and semantic capability embedded in large language models (LLMs) to directly label whether a cell is erroneous. However, this LLM-as-a-labeler pipeline (1) relies on the black box, implicit decision process, thus failing to provide explainability for the detection results, and (2) is highly sensitive to prompts, yielding inconsistent outputs due to inherent model stochasticity, therefore lacking robustness. To address these limitations, we propose an LLM-as-an-inducer framework that adopts LLM to induce the decision tree for ED (termed TreeED) and further ensembles multiple such trees for consensus detection (termed ForestED), thereby improving explainability and robustness. Specifically, based on prompts derived from data context, decision tree specifications and output requirements, TreeED queries the LLM to induce the decision tree skeleton, whose root-to-leaf decision paths specify the stepwise procedure for evaluating a given sample. Each tree contains three types of nodes: (1) rule nodes that perform simple validation checks (e.g., format or range), (2) Graph Neural Network (GNN) nodes that capture complex patterns (e.g., functional dependencies), and (3) leaf nodes that output the final decision types (error or clean). Furthermore, ForestED employs uncertainty-based sampling to obtain multiple row subsets, constructing a decision tree for each subset using TreeED. It then leverages an Expectation-Maximization-based algorithm that jointly estimates tree reliability and optimizes the consensus ED prediction. Extensive xperiments demonstrate that our methods are accurate, explainable and robust, achieving an average F1-score improvement of 16.1% over the best baseline.",
        "url": "http://arxiv.org/abs/2512.07246v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07246v1",
        "arxiv_id": "2512.07246v1",
        "authors": [
            "Mengqi Wang",
            "Jianwei Wang",
            "Qing Liu",
            "Xiwei Xu",
            "Zhenchang Xing",
            "Liming Zhu",
            "Wenjie Zhang"
        ],
        "submitted": "2025-12-08 07:40:48",
        "source": "arxiv",
        "comment": "14 pages, 8 figures",
        "score": 5,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 3,
        "llm_reason": "This paper is loosely relevant to your research interests in Information Retrieval and Natural Language Processing, as it involves leveraging large language models (LLMs) for decision-making. However, the focus on error detection in tabular data and the use of decision trees and graph neural networks is not directly aligned with your core research themes of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Replicating TEMPEST at Scale: Multi-Turn Adversarial Attacks Against Trillion-Parameter Frontier Models",
        "abstract": "Despite substantial investment in safety alignment, the vulnerability of large language models to sophisticated multi-turn adversarial attacks remains poorly characterized, and whether model scale or inference mode affects robustness is unknown. This study employed the TEMPEST multi-turn attack framework to evaluate ten frontier models from eight vendors across 1,000 harmful behaviors, generating over 97,000 API queries across adversarial conversations with automated evaluation by independent safety classifiers. Results demonstrated a spectrum of vulnerability: six models achieved 96% to 100% attack success rate (ASR), while four showed meaningful resistance, with ASR ranging from 42% to 78%; enabling extended reasoning on identical architecture reduced ASR from 97% to 42%. These findings indicate that safety alignment quality varies substantially across vendors, that model scale does not predict adversarial robustness, and that thinking mode provides a deployable safety enhancement. Collectively, this work establishes that current alignment techniques remain fundamentally vulnerable to adaptive multi-turn attacks regardless of model scale, while identifying deliberative inference as a promising defense direction.",
        "url": "http://arxiv.org/abs/2512.07059v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07059v1",
        "arxiv_id": "2512.07059v1",
        "authors": [
            "Richard Young"
        ],
        "submitted": "2025-12-08 00:30:40",
        "source": "arxiv",
        "comment": "30 pages, 11 figures, 5 tables. Code and data: https://github.com/ricyoung/tempest-replication",
        "score": 5,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on adversarial attacks against large language models, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on model robustness, it does not address query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's interests."
    },
    {
        "title": "Block Sparse Flash Attention",
        "abstract": "Modern large language models increasingly require long contexts for reasoning and multi-document tasks, but attention's quadratic complexity creates a severe computational bottleneck. We present Block-Sparse FlashAttention (BSFA), a drop-in replacement that accelerates long-context inference while preserving model quality. Unlike methods that predict importance before computing scores, BSFA computes exact query-key similarities to select the top-k most important value blocks for each query. By comparing per-block maximum scores against calibrated thresholds, we skip approximately 50% of the computation and memory transfers for pruned blocks. Our training-free approach requires only a one-time threshold calibration on a small dataset to learn the per-layer and per-head attention score distributions. We provide a CUDA kernel implementation that can be used as a drop-in replacement for FlashAttention. On Llama-3.1-8B, BSFA achieves up to 1.10x speedup on real-world reasoning benchmarks and up to 1.24x for needle-in-a-haystack retrieval tasks while maintaining above 99% baseline accuracy, with certain configurations even improving accuracy by focusing on the most relevant content, substantially outperforming existing sparse attention methods. The implementation is available at https://github.com/Danielohayon/Block-Sparse-Flash-Attention",
        "url": "http://arxiv.org/abs/2512.07011v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07011v1",
        "arxiv_id": "2512.07011v1",
        "authors": [
            "Daniel Ohayon",
            "Itay Lamprecht",
            "Itay Hubara",
            "Israel Cohen",
            "Daniel Soudry",
            "Noam Elata"
        ],
        "submitted": "2025-12-07 21:20:12",
        "source": "arxiv",
        "comment": "10 pages, 5 figures. Code: https://github.com/Danielohayon/Block-Sparse-Flash-Attention",
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper presents a novel attention mechanism, Block-Sparse FlashAttention, which accelerates long-context inference in large language models. While it is related to my interests in Natural Language Processing (NLP) and attention mechanisms, it does not directly align with my core research themes in Information Retrieval (IR), query understanding, and ranking models. The paper's focus on sparse attention and speedup in large language models is somewhat relevant to my interests, but it is not a central match."
    },
    {
        "title": "Pay Less Attention to Function Words for Free Robustness of Vision-Language Models",
        "abstract": "To address the trade-off between robustness and performance for robust VLM, we observe that function words could incur vulnerability of VLMs against cross-modal adversarial attacks, and propose Function-word De-Attention (FDA) accordingly to mitigate the impact of function words. Similar to differential amplifiers, our FDA calculates the original and the function-word cross-attention within attention heads, and differentially subtracts the latter from the former for more aligned and robust VLMs. Comprehensive experiments include 2 SOTA baselines under 6 different attacks on 2 downstream tasks, 3 datasets, and 3 models. Overall, our FDA yields an average 18/13/53% ASR drop with only 0.2/0.3/0.6% performance drops on the 3 tested models on retrieval, and a 90% ASR drop with a 0.3% performance gain on visual grounding. We demonstrate the scalability, generalization, and zero-shot performance of FDA experimentally, as well as in-depth ablation studies and analysis. Code will be made publicly at https://github.com/michaeltian108/FDA.",
        "url": "http://arxiv.org/abs/2512.07222v2",
        "pdf_url": "https://arxiv.org/pdf/2512.07222v2",
        "arxiv_id": "2512.07222v2",
        "authors": [
            "Qiwei Tian",
            "Chenhao Lin",
            "Zhengyu Zhao",
            "Chao Shen"
        ],
        "submitted": "2025-12-08 07:05:18",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it involves attention mechanisms, the focus is on Vision-Language Models and robustness against adversarial attacks, which is not a primary area of interest for the user."
    },
    {
        "title": "Group Representational Position Encoding",
        "abstract": "We present GRAPE (Group RepresentAtional Position Encoding), a unified framework for positional encoding based on group actions. GRAPE brings together two families of mechanisms: (i) multiplicative rotations (Multiplicative GRAPE) in $\\mathrm{SO}(d)$ and (ii) additive logit biases (Additive GRAPE) arising from unipotent actions in the general linear group $\\mathrm{GL}$. In Multiplicative GRAPE, a position $n \\in \\mathbb{Z}$ (or $t \\in \\mathbb{R}$) acts as $\\mathbf{G}(n)=\\exp(n\\,ω\\,\\mathbf{L})$ with a rank-2 skew generator $\\mathbf{L} \\in \\mathbb{R}^{d \\times d}$, yielding a relative, compositional, norm-preserving map with a closed-form matrix exponential. RoPE is recovered exactly when the $d/2$ planes are the canonical coordinate pairs with log-uniform spectrum. Learned commuting subspaces and compact non-commuting mixtures strictly extend this geometry to capture cross-subspace feature coupling at $O(d)$ and $O(r d)$ cost per head, respectively. In Additive GRAPE, additive logits arise as rank-1 (or low-rank) unipotent actions, recovering ALiBi and the Forgetting Transformer (FoX) as exact special cases while preserving an exact relative law and streaming cacheability. Altogether, GRAPE supplies a principled design space for positional geometry in long-context models, subsuming RoPE and ALiBi as special cases. Project Page: https://github.com/model-architectures/GRAPE.",
        "url": "http://arxiv.org/abs/2512.07805v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07805v1",
        "arxiv_id": "2512.07805v1",
        "authors": [
            "Yifan Zhang",
            "Zixiang Chen",
            "Yifeng Liu",
            "Zhen Qin",
            "Huizhuo Yuan",
            "Kangping Xu",
            "Yang Yuan",
            "Quanquan Gu",
            "Andrew Chi-Chih Yao"
        ],
        "submitted": "2025-12-08 18:39:13",
        "source": "arxiv",
        "comment": "Project Page: https://github.com/model-architectures/GRAPE",
        "score": 3,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on positional encoding in deep learning models, which is a topic in Natural Language Processing (NLP). However, it does not appear to be directly related to Information Retrieval (IR), query understanding, ranking models, or user behavior modeling, which are the primary areas of interest for the user."
    },
    {
        "title": "LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples",
        "abstract": "Large language models (LLMs) possess vast knowledge acquired from extensive training corpora, but they often cannot remove specific pieces of information when needed, which makes it hard to handle privacy, bias mitigation, and knowledge correction. Traditional model unlearning approaches require computationally expensive fine-tuning or direct weight editing, making them impractical for real-world deployment. In this work, we introduce LoRA-based Unlearning with Negative Examples (LUNE), a lightweight framework that performs negative-only unlearning by updating only low-rank adapters while freezing the backbone, thereby localizing edits and avoiding disruptive global changes. Leveraging Low-Rank Adaptation (LoRA), LUNE targets intermediate representations to suppress (or replace) requested knowledge with an order-of-magnitude lower compute and memory than full fine-tuning or direct weight editing. Extensive experiments on multiple factual unlearning tasks show that LUNE: (I) achieves effectiveness comparable to full fine-tuning and memory-editing methods, and (II) reduces computational cost by about an order of magnitude.",
        "url": "http://arxiv.org/abs/2512.07375v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07375v1",
        "arxiv_id": "2512.07375v1",
        "authors": [
            "Yezi Liu",
            "Hanning Chen",
            "Wenjun Huang",
            "Yang Ni",
            "Mohsen Imani"
        ],
        "submitted": "2025-12-08 10:10:29",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on unlearning in large language models, which is not a primary area of interest for information retrieval and search technologies. While it touches on deep semantic understanding, the context is not aligned with the user's core research themes."
    },
    {
        "title": "Benchmarking Deep Neural Networks for Modern Recommendation Systems",
        "abstract": "This paper examines the deployment of seven different neural network architectures CNN, RNN, GNN, Autoencoder, Transformer, NCF, and Siamese Networks on three distinct datasets: Retail E-commerce, Amazon Products, and Netflix Prize. It evaluates their effectiveness through metrics such as accuracy, recall, F1-score, and diversity in recommendations. The results demonstrate that GNNs are particularly adept at managing complex item relationships in e-commerce environments, whereas RNNs are effective in capturing the temporal dynamics that are essential for platforms such as Netflix.. Siamese Networks are emphasized for their contribution to the diversification of recommendations, particularly in retail settings. Despite their benefits, issues like computational demands, reliance on extensive data, and the challenge of balancing accurate and diverse recommendations are addressed. The study seeks to inform the advancement of recommendation systems by suggesting hybrid methods that merge the strengths of various models to better satisfy user preferences and accommodate the evolving demands of contemporary digital platforms.",
        "url": "http://arxiv.org/abs/2512.07000v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07000v1",
        "arxiv_id": "2512.07000v1",
        "authors": [
            "Abderaouf Bahi",
            "Ibtissem Gasmi"
        ],
        "submitted": "2025-12-07 21:06:24",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat relevant to your research interests in Information Retrieval and Search technologies, but it focuses more on recommender systems, which is a related but secondary area of interest. The paper's emphasis on deep neural networks and their applications in e-commerce environments is somewhat aligned with your background in the e-commerce domain, but it does not directly address query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "ReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning",
        "abstract": "Large language models (LLMs) are increasingly deployed in settings where reasoning, such as multi-step problem solving and chain-of-thought, is essential. Yet, current evaluation practices overwhelmingly report single-run accuracy while ignoring the intrinsic uncertainty that naturally arises from stochastic decoding. This omission creates a blind spot because practitioners cannot reliably assess whether a method's reported performance is stable, reproducible, or cost-consistent. We introduce ReasonBENCH, the first benchmark designed to quantify the underlying instability in LLM reasoning. ReasonBENCH provides (i) a modular evaluation library that standardizes reasoning frameworks, models, and tasks, (ii) a multi-run protocol that reports statistically reliable metrics for both quality and cost, and (iii) a public leaderboard to encourage variance-aware reporting. Across tasks from different domains, we find that the vast majority of reasoning strategies and models exhibit high instability. Notably, even strategies with similar average performance can display confidence intervals up to four times wider, and the top-performing methods often incur higher and less stable costs. Such instability compromises reproducibility across runs and, consequently, the reliability of reported performance. To better understand these dynamics, we further analyze the impact of prompts, model families, and scale on the trade-off between solve rate and stability. Our results highlight reproducibility as a critical dimension for reliable LLM reasoning and provide a foundation for future reasoning methods and uncertainty quantification techniques. ReasonBENCH is publicly available at https://github.com/au-clan/ReasonBench .",
        "url": "http://arxiv.org/abs/2512.07795v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07795v1",
        "arxiv_id": "2512.07795v1",
        "authors": [
            "Nearchos Potamitis",
            "Lars Klein",
            "Akhil Arora"
        ],
        "submitted": "2025-12-08 18:26:58",
        "source": "arxiv",
        "comment": "11 pages, 3 tables, 4 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and Large Language Models (LLMs), but it does not directly address query understanding, ranking models, or user behavior modeling in the context of Information Retrieval. The focus on LLM reasoning and instability is tangentially relevant to the user's interests in deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Mary, the Cheeseburger-Eating Vegetarian: Do LLMs Recognize Incoherence in Narratives?",
        "abstract": "Leveraging a dataset of paired narratives, we investigate the extent to which large language models (LLMs) can reliably separate incoherent and coherent stories. A probing study finds that LLMs' internal representations can reliably identify incoherent narratives. However, LLMs generate responses to rating questions that fail to satisfactorily separate the coherent and incoherent narratives across several prompt variations, hinting at a gap in LLM's understanding of storytelling. The reasoning LLMs tested do not eliminate these deficits, indicating that thought strings may not be able to fully address the discrepancy between model internal state and behavior. Additionally, we find that LLMs appear to be more sensitive to incoherence resulting from an event that violates the setting (e.g., a rainy day in the desert) than to incoherence arising from a character violating an established trait (e.g., Mary, a vegetarian, later orders a cheeseburger), suggesting that LLMs may rely more on prototypical world knowledge than building meaning-based narrative coherence. The consistent asymmetry found in our results suggests that LLMs do not have a complete grasp on narrative coherence.",
        "url": "http://arxiv.org/abs/2512.07777v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07777v1",
        "arxiv_id": "2512.07777v1",
        "authors": [
            "Karin de Langis",
            "Püren Öncel",
            "Ryan Peters",
            "Andrew Elfenbein",
            "Laura Kristen Allen",
            "Andreas Schramm",
            "Dongyeop Kang"
        ],
        "submitted": "2025-12-08 17:58:43",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the ability of Large Language Models (LLMs) to recognize incoherence in narratives, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on narrative coherence and LLMs' internal representations is not directly aligned with the user's core research themes in IR and Search technologies. The connection to NLP is relevant, but the paper's scope is more focused on language understanding and model evaluation rather than search or retrieval."
    },
    {
        "title": "PCMind-2.1-Kaiyuan-2B Technical Report",
        "abstract": "The rapid advancement of Large Language Models (LLMs) has resulted in a significant knowledge gap between the open-source community and industry, primarily because the latter relies on closed-source, high-quality data and training recipes. To address this, we introduce PCMind-2.1-Kaiyuan-2B, a fully open-source 2-billion-parameter model focused on improving training efficiency and effectiveness under resource constraints. Our methodology includes three key innovations: a Quantile Data Benchmarking method for systematically comparing heterogeneous open-source datasets and providing insights on data mixing strategies; a Strategic Selective Repetition scheme within a multi-phase paradigm to effectively leverage sparse, high-quality data; and a Multi-Domain Curriculum Training policy that orders samples by quality. Supported by a highly optimized data preprocessing pipeline and architectural modifications for FP16 stability, Kaiyuan-2B achieves performance competitive with state-of-the-art fully open-source models, demonstrating practical and scalable solutions for resource-limited pretraining. We release all assets (including model weights, data, and code) under Apache 2.0 license at https://huggingface.co/thu-pacman/PCMind-2.1-Kaiyuan-2B.",
        "url": "http://arxiv.org/abs/2512.07612v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07612v1",
        "arxiv_id": "2512.07612v1",
        "authors": [
            "Kairong Luo",
            "Zhenbo Sun",
            "Xinyu Shi",
            "Shengqi Chen",
            "Bowen Yu",
            "Yunyi Chen",
            "Chenyi Dang",
            "Hengtao Tao",
            "Hui Wang",
            "Fangming Liu",
            "Kaifeng Lyu",
            "Wenguang Chen"
        ],
        "submitted": "2025-12-08 15:00:10",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Large Language Models (LLMs) and their training efficiency, which is not directly related to Information Retrieval (IR) or Search technologies. While it touches on data preprocessing, the context is not aligned with the user's core research themes."
    },
    {
        "title": "A Simple Method to Enhance Pre-trained Language Models with Speech Tokens for Classification",
        "abstract": "This paper presents a simple method that allows to easily enhance textual pre-trained large language models with speech information, when fine-tuned for a specific classification task. A classical issue with the fusion of many embeddings from audio with text is the large length of the audio sequence compared to the text one. Our method benefits from an existing speech tokenizer trained for Audio Speech Recognition that output long sequences of tokens from a large vocabulary, making it difficult to integrate it at low cost in a large language model. By applying a simple lasso-based feature selection on multimodal Bag-of-Words representation, we retain only the most important audio tokens for the task, and adapt the language model to them with a self-supervised language modeling objective, before fine-tuning it on the downstream task. We show this helps to improve the performances compared to an unimodal model, to a bigger SpeechLM or to integrating audio via a learned representation. We show the effectiveness of our method on two recent Argumentative Fallacy Detection and Classification tasks where the use of audio was believed counterproductive, reaching state-of-the-art results. We also provide an in-depth analysis of the method, showing that even a random audio token selection helps enhancing the unimodal model. Our code is available [online](https://github.com/salocinc/EACL26SpeechTokFallacy/).",
        "url": "http://arxiv.org/abs/2512.07571v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07571v1",
        "arxiv_id": "2512.07571v1",
        "authors": [
            "Nicolas Calbucura",
            "Valentin Barriere"
        ],
        "submitted": "2025-12-08 14:05:40",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the integration of speech information with pre-trained language models for classification tasks. While it touches on multimodal learning, which is related to query understanding and ranking models, the focus is on NLP and classification, rather than search technologies or user behavior modeling. The paper's emphasis on speech tokens and audio information is not directly relevant to the user's core research themes."
    },
    {
        "title": "MoCoRP: Modeling Consistent Relations between Persona and Response for Persona-based Dialogue",
        "abstract": "As dialogue systems become increasingly important across various domains, a key challenge in persona-based dialogue is generating engaging and context-specific interactions while ensuring the model acts with a coherent personality. However, existing persona-based dialogue datasets lack explicit relations between persona sentences and responses, which makes it difficult for models to effectively capture persona information. To address these issues, we propose MoCoRP (Modeling Consistent Relations between Persona and Response), a framework that incorporates explicit relations into language models. MoCoRP leverages an NLI expert to explicitly extract the NLI relations between persona sentences and responses, enabling the model to effectively incorporate appropriate persona information from the context into its responses. We applied this framework to pre-trained models like BART and further extended it to modern large language models (LLMs) through alignment tuning. Experimental results on the public datasets ConvAI2 and MPChat demonstrate that MoCoRP outperforms existing baselines, achieving superior persona consistency and engaging, context-aware dialogue generation. Furthermore, our model not only excels in quantitative metrics but also shows significant improvements in qualitative aspects. These results highlight the effectiveness of explicitly modeling persona-response relations in persona-based dialogue. The source codes of MoCoRP are available at https://github.com/DMCB-GIST/MoCoRP.",
        "url": "http://arxiv.org/abs/2512.07544v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07544v1",
        "arxiv_id": "2512.07544v1",
        "authors": [
            "Kyungro Lee",
            "Dongha Choi",
            "Hyunju Lee"
        ],
        "submitted": "2025-12-08 13:25:00",
        "source": "arxiv",
        "comment": "18 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on persona-based dialogue systems, which is outside the user's primary research interests in Information Retrieval and Search technologies. While it involves Natural Language Processing, the specific application and goals of the paper do not align closely with the user's core themes."
    },
    {
        "title": "Enhancing Agentic RL with Progressive Reward Shaping and Value-based Sampling Policy Optimization",
        "abstract": "Large Language Models (LLMs) empowered with Tool-Integrated Reasoning (TIR) can iteratively plan, call external tools, and integrate returned information to solve complex, long-horizon reasoning tasks. Agentic Reinforcement Learning (Agentic RL) optimizes such models over full tool-interaction trajectories, but two key challenges hinder effectiveness: (1) Sparse, non-instructive rewards, such as binary 0-1 verifiable signals, provide limited guidance for intermediate steps and slow convergence; (2) Gradient degradation in Group Relative Policy Optimization (GRPO), where identical rewards within a rollout group yield zero advantage, reducing sample efficiency and destabilizing training. To address these challenges, we propose two complementary techniques: Progressive Reward Shaping (PRS) and Value-based Sampling Policy Optimization (VSPO). PRS is a curriculum-inspired reward design that introduces dense, stage-wise feedback - encouraging models to first master parseable and properly formatted tool calls, then optimize for factual correctness and answer quality. We instantiate PRS for short-form QA (with a length-aware BLEU to fairly score concise answers) and long-form QA (with LLM-as-a-Judge scoring to prevent reward hacking). VSPO is an enhanced GRPO variant that replaces low-value samples with prompts selected by a task-value metric balancing difficulty and uncertainty, and applies value-smoothing clipping to stabilize gradient updates. Experiments on multiple short-form and long-form QA benchmarks show that PRS consistently outperforms traditional binary rewards, and VSPO achieves superior stability, faster convergence, and higher final performance compared to PPO, GRPO, CISPO, and SFT-only baselines. Together, PRS and VSPO yield LLM-based TIR agents that generalize better across domains.",
        "url": "http://arxiv.org/abs/2512.07478v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07478v1",
        "arxiv_id": "2512.07478v1",
        "authors": [
            "Zhuoran Zhuang",
            "Ye Chen",
            "Jianghao Su",
            "Chao Luo",
            "Luhui Liu",
            "Xia Zeng"
        ],
        "submitted": "2025-12-08 11:59:25",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Large Language Models (LLMs) and Tool-Integrated Reasoning (TIR), which is not directly related to Information Retrieval (IR) or Search technologies. While it involves optimization techniques, the context is more aligned with NLP and deep learning, but the specific challenges and solutions presented do not seem to be relevant to the user's core research themes."
    },
    {
        "title": "Living the Novel: A System for Generating Self-Training Timeline-Aware Conversational Agents from Novels",
        "abstract": "We present the Living Novel, an end-to-end system that transforms any literary work into an immersive, multi-character conversational experience. This system is designed to solve two fundamental challenges for LLM-driven characters. Firstly, generic LLMs suffer from persona drift, often failing to stay in character. Secondly, agents often exhibit abilities that extend beyond the constraints of the story's world and logic, leading to both narrative incoherence (spoiler leakage) and robustness failures (frame-breaking). To address these challenges, we introduce a novel two-stage training pipeline. Our Deep Persona Alignment (DPA) stage uses data-free reinforcement finetuning to instill deep character fidelity. Our Coherence and Robustness Enhancing (CRE) stage then employs a story-time-aware knowledge graph and a second retrieval-grounded training pass to architecturally enforce these narrative constraints. We validate our system through a multi-phase evaluation using Jules Verne's Twenty Thousand Leagues Under the Sea. A lab study with a detailed ablation of system components is followed by a 5-day in-the-wild diary study. Our DPA pipeline helps our specialized model outperform GPT-4o on persona-specific metrics, and our CRE stage achieves near-perfect performance in coherence and robustness measures. Our study surfaces practical design guidelines for AI-driven narrative systems: we find that character-first self-training is foundational for believability, while explicit story-time constraints are crucial for sustaining coherent, interruption-resilient mobile-web experiences.",
        "url": "http://arxiv.org/abs/2512.07474v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07474v1",
        "arxiv_id": "2512.07474v1",
        "authors": [
            "Yifei Huang",
            "Tianyu Yan",
            "Sitong Gong",
            "Xiwei Gao",
            "Caixin Kang",
            "Ruicong Liu",
            "Huchuan Lu",
            "Bo Zheng"
        ],
        "submitted": "2025-12-08 11:57:46",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on conversational agents and narrative systems, which do not align with your core areas of Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the context is more related to storytelling and character development rather than query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Generating Storytelling Images with Rich Chains-of-Reasoning",
        "abstract": "An image can convey a compelling story by presenting rich, logically connected visual clues. These connections form Chains-of-Reasoning (CoRs) within the image, enabling viewers to infer events, causal relationships, and other information, thereby understanding the underlying story. In this paper, we focus on these semantically rich images and define them as Storytelling Images. Such images have diverse applications beyond illustration creation and cognitive screening, leveraging their ability to convey multi-layered information visually and inspire active interpretation. However, due to their complex semantic nature, Storytelling Images are inherently challenging to create, and thus remain relatively scarce. To address this challenge, we introduce the Storytelling Image Generation task, which explores how generative AI models can be leveraged to create such images. Specifically, we propose a two-stage pipeline, StorytellingPainter, which combines the creative reasoning abilities of Large Language Models (LLMs) with the visual synthesis capabilities of Text-to-Image (T2I) models to generate Storytelling Images. Alongside this pipeline, we develop a dedicated evaluation framework comprising three main evaluators: a Semantic Complexity Evaluator, a KNN-based Diversity Evaluator and a Story-Image Alignment Evaluator. Given the critical role of story generation in the Storytelling Image Generation task and the performance disparity between open-source and proprietary LLMs, we further explore tailored training strategies to reduce this gap, resulting in a series of lightweight yet effective models named Mini-Storytellers. Experimental results demonstrate the feasibility and effectiveness of our approaches. The code is available at https://github.com/xiujiesong/StorytellingImageGeneration.",
        "url": "http://arxiv.org/abs/2512.07198v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07198v1",
        "arxiv_id": "2512.07198v1",
        "authors": [
            "Xiujie Song",
            "Qi Jia",
            "Shota Watanabe",
            "Xiaoyi Pang",
            "Ruijie Chen",
            "Mengyue Wu",
            "Kenny Q. Zhu"
        ],
        "submitted": "2025-12-08 06:18:44",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on generating storytelling images using AI models, which is outside the scope of information retrieval and search technologies. While it involves some NLP aspects, the primary focus is on image generation and storytelling, making it less relevant to your research interests."
    },
    {
        "title": "MASim: Multilingual Agent-Based Simulation for Social Science",
        "abstract": "Multi-agent role-playing has recently shown promise for studying social behavior with language agents, but existing simulations are mostly monolingual and fail to model cross-lingual interaction, an essential property of real societies. We introduce MASim, the first multilingual agent-based simulation framework that supports multi-turn interaction among generative agents with diverse sociolinguistic profiles. MASim offers two key analyses: (i) global public opinion modeling, by simulating how attitudes toward open-domain hypotheses evolve across languages and cultures, and (ii) media influence and information diffusion, via autonomous news agents that dynamically generate content and shape user behavior. To instantiate simulations, we construct the MAPS benchmark, which combines survey questions and demographic personas drawn from global population distributions. Experiments on calibration, sensitivity, consistency, and cultural case studies show that MASim reproduces sociocultural phenomena and highlights the importance of multilingual simulation for scalable, controlled computational social science.",
        "url": "http://arxiv.org/abs/2512.07195v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07195v1",
        "arxiv_id": "2512.07195v1",
        "authors": [
            "Xuan Zhang",
            "Wenxuan Zhang",
            "Anxu Wang",
            "See-Kiong Ng",
            "Yang Deng"
        ],
        "submitted": "2025-12-08 06:12:48",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'user behavior' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval, Search technologies, or query understanding, which are core areas of your research interests. While it involves natural language processing and user behavior modeling, the focus is on social science and multilingual agent-based simulation, making it only loosely relevant to your work."
    },
    {
        "title": "Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models",
        "abstract": "As multimodal reasoning improves the overall capabilities of Large Vision Language Models (LVLMs), recent studies have begun to explore safety-oriented reasoning, aiming to enhance safety awareness by analyzing potential safety risks during the reasoning process before generating the final response. Although such approaches improve safety awareness and interpretability, this single-pass think-then-answer paradigm remains vulnerable to contextual or visual jailbreak attacks. This reveals a critical flaw: single-pass reasoning may overlook explicit harmful content in its own output. Our key insight is to exploit this wasted signal through reflection, which can effectively leverage the malicious content revealed in the first-pass reasoning to enable genuine self-correction and prevent unsafe generations. Motivated by this, we propose Think-Reflect-Revise (TRR), a three-stage training framework designed to enhance the safety alignment of LVLMs through policy-guided self-reflection. We first build a Reflective Safety Reasoning (ReSafe) dataset with 5,000 examples that follow a think-reflect-revise process. We then fine-tune the target model using the ReSafe dataset to initialize reflective behavior, and finally reinforce policy-guided reflection through reinforcement learning. Experimental results show that TRR substantially improves the safety performance of LVLMs across both safety-awareness benchmarks and jailbreak attack evaluations, increasing the overall safe response rate from 42.8% to 87.7% on Qwen2.5-VL-7B, while preserving stable performance on general benchmarks such as MMMU and MMStar. The project page is available at https://think-reflect-revise.github.io/.",
        "url": "http://arxiv.org/abs/2512.07141v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07141v1",
        "arxiv_id": "2512.07141v1",
        "authors": [
            "Fenghua Weng",
            "Chaochao Lu",
            "Xia Hu",
            "Wenqi Shao",
            "Wenjie Wang"
        ],
        "submitted": "2025-12-08 03:46:03",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on safety alignment in Large Vision Language Models, which is not directly related to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on multimodal reasoning, it is more aligned with AI safety and model interpretability, which is not a central match for your interests."
    },
    {
        "title": "GUMBridge: a Corpus for Varieties of Bridging Anaphora",
        "abstract": "Bridging is an anaphoric phenomenon where the referent of an entity in a discourse is dependent on a previous, non-identical entity for interpretation, such as in \"There is 'a house'. 'The door' is red,\" where the door is specifically understood to be the door of the aforementioned house. While there are several existing resources in English for bridging anaphora, most are small, provide limited coverage of the phenomenon, and/or provide limited genre coverage. In this paper, we introduce GUMBridge, a new resource for bridging, which includes 16 diverse genres of English, providing both broad coverage for the phenomenon and granular annotations for the subtype categorization of bridging varieties. We also present an evaluation of annotation quality and report on baseline performance using open and closed source contemporary LLMs on three tasks underlying our data, showing that bridging resolution and subtype classification remain difficult NLP tasks in the age of LLMs.",
        "url": "http://arxiv.org/abs/2512.07134v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07134v1",
        "arxiv_id": "2512.07134v1",
        "authors": [
            "Lauren Levine",
            "Amir Zeldes"
        ],
        "submitted": "2025-12-08 03:39:45",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to your research interests in Information Retrieval, Search technologies, or query understanding. While it involves Natural Language Processing (NLP), it focuses on a specific anaphoric phenomenon and corpus development, which is not a central match to your primary research themes."
    },
    {
        "title": "DART: Leveraging Multi-Agent Disagreement for Tool Recruitment in Multimodal Reasoning",
        "abstract": "Specialized visual tools can augment large language models or vision language models with expert knowledge (e.g., grounding, spatial reasoning, medical knowledge, etc.), but knowing which tools to call (and when to call them) can be challenging. We introduce DART, a multi-agent framework that uses disagreements between multiple debating visual agents to identify useful visual tools (e.g., object detection, OCR, spatial reasoning, etc.) that can resolve inter-agent disagreement. These tools allow for fruitful multi-agent discussion by introducing new information, and by providing tool-aligned agreement scores that highlight agents in agreement with expert tools, thereby facilitating discussion. We utilize an aggregator agent to select the best answer by providing the agent outputs and tool information. We test DART on four diverse benchmarks and show that our approach improves over multi-agent debate as well as over single agent tool-calling frameworks, beating the next-strongest baseline (multi-agent debate with a judge model) by 3.4% and 2.4% on A-OKVQA and MMMU respectively. We also find that DART adapts well to new tools in applied domains, with a 1.3% improvement on the M3D medical dataset over other strong tool-calling, single agent, and multi-agent baselines. Additionally, we measure text overlap across rounds to highlight the rich discussion in DART compared to existing multi-agent methods. Finally, we study the tool call distribution, finding that diverse tools are reliably used to help resolve disagreement.",
        "url": "http://arxiv.org/abs/2512.07132v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07132v1",
        "arxiv_id": "2512.07132v1",
        "authors": [
            "Nithin Sivakumaran",
            "Justin Chih-Yao Chen",
            "David Wan",
            "Yue Zhang",
            "Jaehong Yoon",
            "Elias Stengel-Eskin",
            "Mohit Bansal"
        ],
        "submitted": "2025-12-08 03:33:38",
        "source": "arxiv",
        "comment": "Code: https://github.com/nsivaku/dart",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multimodal reasoning and tool recruitment using multi-agent disagreement, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some aspects of query understanding and ranking models, the context is more aligned with multimodal reasoning and tool recruitment, making it somewhat tangential to the user's primary interests."
    },
    {
        "title": "Leveraging KV Similarity for Online Structured Pruning in LLMs",
        "abstract": "Pruning has emerged as a promising direction for accelerating large language model (LLM) inference, yet existing approaches often suffer from instability because they rely on offline calibration data that may not generalize across inputs. In this work, we introduce Token Filtering, a lightweight online structured pruning technique that makes pruning decisions directly during inference without any calibration data. The key idea is to measure token redundancy via joint key-value similarity and skip redundant attention computations, thereby reducing inference cost while preserving critical information. To further enhance stability, we design a variance-aware fusion strategy that adaptively weights key and value similarity across heads, ensuring that informative tokens are retained even under high pruning ratios. This design introduces no additional memory overhead and provides a more reliable criterion for token importance. Extensive experiments on LLaMA-2 (7B/13B), LLaMA-3 (8B), and Mistral (7B) demonstrate that Token Filtering consistently outperforms prior structured pruning methods, preserving accuracy on commonsense reasoning benchmarks and maintaining strong performance on challenging tasks such as MMLU, even with 50% pruning.",
        "url": "http://arxiv.org/abs/2512.07090v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07090v1",
        "arxiv_id": "2512.07090v1",
        "authors": [
            "Jungmin Lee",
            "Gwangeun Byeon",
            "Yulhwa Kim",
            "Seokin Hong"
        ],
        "submitted": "2025-12-08 01:56:27",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on pruning large language models, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific topic of model pruning and its optimization is not a central match for your research themes."
    },
    {
        "title": "SETUP: Sentence-level English-To-Uniform Meaning Representation Parser",
        "abstract": "Uniform Meaning Representation (UMR) is a novel graph-based semantic representation which captures the core meaning of a text, with flexibility incorporated into the annotation schema such that the breadth of the world's languages can be annotated (including low-resource languages). While UMR shows promise in enabling language documentation, improving low-resource language technologies, and adding interpretability, the downstream applications of UMR can only be fully explored when text-to-UMR parsers enable the automatic large-scale production of accurate UMR graphs at test time. Prior work on text-to-UMR parsing is limited to date. In this paper, we introduce two methods for English text-to-UMR parsing, one of which fine-tunes existing parsers for Abstract Meaning Representation and the other, which leverages a converter from Universal Dependencies, using prior work as a baseline. Our best-performing model, which we call SETUP, achieves an AnCast score of 84 and a SMATCH++ score of 91, indicating substantial gains towards automatic UMR parsing.",
        "url": "http://arxiv.org/abs/2512.07068v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07068v1",
        "arxiv_id": "2512.07068v1",
        "authors": [
            "Emma Markle",
            "Javier Gutierrez Bach",
            "Shira Wein"
        ],
        "submitted": "2025-12-08 00:56:00",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper introduces a novel method for text-to-UMR parsing, which is related to query understanding and semantic understanding in Information Retrieval. However, the focus on language representation and parsing is somewhat tangential to the user's core research themes in IR and Search technologies. While the paper's results on automatic UMR parsing are promising, they do not directly address the user's interests in ranking models, user behavior modeling, or recommender systems."
    },
    {
        "title": "Collaborative Causal Sensemaking: Closing the Complementarity Gap in Human-AI Decision Support",
        "abstract": "LLM-based agents are increasingly deployed for expert decision support, yet human-AI teams in high-stakes settings do not yet reliably outperform the best individual. We argue this complementarity gap reflects a fundamental mismatch: current agents are trained as answer engines, not as partners in the collaborative sensemaking through which experts actually make decisions. Sensemaking (the ability to co-construct causal explanations, surface uncertainties, and adapt goals) is the key capability that current training pipelines do not explicitly develop or evaluate. We propose Collaborative Causal Sensemaking (CCS) as a research agenda to develop this capability from the ground up, spanning new training environments that reward collaborative thinking, representations for shared human-AI mental models, and evaluation centred on trust and complementarity. These directions can advance MAS research toward agents that think with their human partners rather than for them.",
        "url": "http://arxiv.org/abs/2512.07801v2",
        "pdf_url": "https://arxiv.org/pdf/2512.07801v2",
        "arxiv_id": "2512.07801v2",
        "authors": [
            "Raunak Jain",
            "Mudita Khurana"
        ],
        "submitted": "2025-12-08 18:30:41",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be focused on human-AI collaboration and decision support, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on the idea of 'sensemaking', it does not seem to involve query understanding, ranking models, or user behavior modeling, making it only loosely relevant to the user's research."
    },
    {
        "title": "When Large Language Models Do Not Work: Online Incivility Prediction through Graph Neural Networks",
        "abstract": "Online incivility has emerged as a widespread and persistent problem in digital communities, imposing substantial social and psychological burdens on users. Although many platforms attempt to curb incivility through moderation and automated detection, the performance of existing approaches often remains limited in both accuracy and efficiency. To address this challenge, we propose a Graph Neural Network (GNN) framework for detecting three types of uncivil behavior (i.e., toxicity, aggression, and personal attacks) within the English Wikipedia community. Our model represents each user comment as a node, with textual similarity between comments defining the edges, allowing the network to jointly learn from both linguistic content and relational structures among comments. We also introduce a dynamically adjusted attention mechanism that adaptively balances nodal and topological features during information aggregation. Empirical evaluations demonstrate that our proposed architecture outperforms 12 state-of-the-art Large Language Models (LLMs) across multiple metrics while requiring significantly lower inference cost. These findings highlight the crucial role of structural context in detecting online incivility and address the limitations of text-only LLM paradigms in behavioral prediction. All datasets and comparative outputs will be publicly available in our repository to support further research and reproducibility.",
        "url": "http://arxiv.org/abs/2512.07684v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07684v1",
        "arxiv_id": "2512.07684v1",
        "authors": [
            "Zihan Chen",
            "Lanyu Yu"
        ],
        "submitted": "2025-12-08 16:22:40",
        "source": "arxiv",
        "comment": "10 pages",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on online incivility prediction using Graph Neural Networks, which is unrelated to the user's core research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it involves text analysis, the context is not relevant to the user's areas of focus, such as query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Exploring Test-time Scaling via Prediction Merging on Large-Scale Recommendation",
        "abstract": "Inspired by the success of language models (LM), scaling up deep learning recommendation systems (DLRS) has become a recent trend in the community. All previous methods tend to scale up the model parameters during training time. However, how to efficiently utilize and scale up computational resources during test time remains underexplored, which can prove to be a scaling-efficient approach and bring orthogonal improvements in LM domains. The key point in applying test-time scaling to DLRS lies in effectively generating diverse yet meaningful outputs for the same instance. We propose two ways: One is to explore the heterogeneity of different model architectures. The other is to utilize the randomness of model initialization under a homogeneous architecture. The evaluation is conducted across eight models, including both classic and SOTA models, on three benchmarks. Sufficient evidence proves the effectiveness of both solutions. We further prove that under the same inference budget, test-time scaling can outperform parameter scaling. Our test-time scaling can also be seamlessly accelerated with the increase in parallel servers when deployed online, without affecting the inference time on the user side. Code is available.",
        "url": "http://arxiv.org/abs/2512.07650v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07650v1",
        "arxiv_id": "2512.07650v1",
        "authors": [
            "Fuyuan Lyu",
            "Zhentai Chen",
            "Jingyan Jiang",
            "Lingjie Li",
            "Xing Tang",
            "Xiuqiang He",
            "Xue Liu"
        ],
        "submitted": "2025-12-08 15:41:10",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores test-time scaling for deep learning recommendation systems, leveraging ideas from language models. While it touches on scaling and optimization, which are related to IR and NLP, its primary focus is on recommender systems, which is a secondary interest of yours. The paper's emphasis on test-time scaling and model diversity is somewhat relevant to your interests in real-time relevance optimization, but it's not a central match."
    },
    {
        "title": "Complementary Learning Approach for Text Classification using Large Language Models",
        "abstract": "In this study, we propose a structured methodology that utilizes large language models (LLMs) in a cost-efficient and parsimonious manner, integrating the strengths of scholars and machines while offsetting their respective weaknesses. Our methodology, facilitated through a chain of thought and few-shot learning prompting from computer science, extends best practices for co-author teams in qualitative research to human-machine teams in quantitative research. This allows humans to utilize abductive reasoning and natural language to interrogate not just what the machine has done but also what the human has done. Our method highlights how scholars can manage inherent weaknesses OF LLMs using careful, low-cost techniques. We demonstrate how to use the methodology to interrogate human-machine rating discrepancies for a sample of 1,934 press releases announcing pharmaceutical alliances (1990-2017).",
        "url": "http://arxiv.org/abs/2512.07583v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07583v1",
        "arxiv_id": "2512.07583v1",
        "authors": [
            "Navid Asgari",
            "Benjamin M. Cole"
        ],
        "submitted": "2025-12-08 14:26:31",
        "source": "arxiv",
        "comment": "67 pages",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the use of large language models in text classification, which is somewhat related to your interests in Natural Language Processing (NLP). However, the focus on text classification and human-machine collaboration is not directly aligned with your primary focus on information retrieval, especially in areas requiring deep semantic understanding and real-time relevance optimization."
    },
    {
        "title": "Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models",
        "abstract": "Vision-language models (VLMs) frequently generate hallucinated content plausible but incorrect claims about image content. We propose a training-free self-correction framework enabling VLMs to iteratively refine responses through uncertainty-guided visual re-attention. Our method combines multidimensional uncertainty quantification (token entropy, attention dispersion, semantic consistency, claim confidence) with attention-guided cropping of under-explored regions. Operating entirely with frozen, pretrained VLMs, our framework requires no gradient updates. We validate our approach on the POPE and MMHAL BENCH benchmarks using the Qwen2.5-VL-7B [23] architecture. Experimental results demonstrate that our method reduces hallucination rates by 9.8 percentage points compared to the baseline, while improving object existence accuracy by 4.7 points on adversarial splits. Furthermore, qualitative analysis confirms that uncertainty-guided re-attention successfully grounds corrections in visual evidence where standard decoding fails. We validate our approach on Qwen2.5-VL-7B [23], with plans to extend validation across diverse architectures in future versions. We release our code and methodology to facilitate future research in trustworthy multimodal systems.",
        "url": "http://arxiv.org/abs/2512.07564v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07564v1",
        "arxiv_id": "2512.07564v1",
        "authors": [
            "Kassoum Sanogo",
            "Renzo Ardiccioni"
        ],
        "submitted": "2025-12-08 13:58:46",
        "source": "arxiv",
        "comment": "24 pages, 3 figures, 2 tables. Training-free self-correction framework for vision-language models. Code and implementation details will be released at: https://github.com/kassoumsanogo1/self-correcting-vlm-re-Attention.git",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to your research interests in Natural Language Processing (NLP) and multimodal systems, but it primarily focuses on reducing hallucinations in vision-language models, which is not directly related to your core areas of interest in Information Retrieval (IR) and Search technologies. While the paper's use of uncertainty-guided re-attention is an interesting technique, it is not directly applicable to your research areas."
    },
    {
        "title": "On the Impact of Graph Neural Networks in Recommender Systems: A Topological Perspective",
        "abstract": "In recommender systems, user-item interactions can be modeled as a bipartite graph, where user and item nodes are connected by undirected edges. This graph-based view has motivated the rapid adoption of graph neural networks (GNNs), which often outperform collaborative filtering (CF) methods such as latent factor models, deep neural networks, and generative strategies. Yet, despite their empirical success, the reasons why GNNs offer systematic advantages over other CF approaches remain only partially understood. This monograph advances a topology-centered perspective on GNN-based recommendation. We argue that a comprehensive understanding of these models' performance should consider the structural properties of user-item graphs and their interaction with GNN architectural design. To support this view, we introduce a formal taxonomy that distills common modeling patterns across eleven representative GNN-based recommendation approaches and consolidates them into a unified conceptual pipeline. We further formalize thirteen classical and topological characteristics of recommendation datasets and reinterpret them through the lens of graph machine learning. Using these definitions, we analyze the considered GNN-based recommender architectures to assess how and to what extent they encode such properties. Building on this analysis, we derive an explanatory framework that links measurable dataset characteristics to model behavior and performance. Taken together, this monograph re-frames GNN-based recommendation through its topological underpinnings and outlines open theoretical, data-centric, and evaluation challenges for the next generation of topology-aware recommender systems.",
        "url": "http://arxiv.org/abs/2512.07384v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07384v1",
        "arxiv_id": "2512.07384v1",
        "authors": [
            "Daniele Malitesta",
            "Claudio Pomo",
            "Vito Walter Anelli",
            "Alberto Carlo Maria Mancino",
            "Alejandro Bellogín",
            "Tommaso Di Noia"
        ],
        "submitted": "2025-12-08 10:19:43",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to the user's research interests in recommender systems, but it focuses on graph neural networks and their application in this domain, which is not the user's primary focus. The paper's emphasis on topology and graph machine learning is also somewhat tangential to the user's interests in information retrieval and search technologies."
    },
    {
        "title": "Recover-to-Forget: Gradient Reconstruction from LoRA for Efficient LLM Unlearning",
        "abstract": "Unlearning in large foundation models (e.g., LLMs) is essential for enabling dynamic knowledge updates, enforcing data deletion rights, and correcting model behavior. However, existing unlearning methods often require full-model fine-tuning or access to the original training data, which limits their scalability and practicality. In this work, we introduce Recover-to-Forget (R2F), a novel framework for efficient unlearning in LLMs based on reconstructing full-model gradient directions from low-rank LoRA adapter updates. Rather than performing backpropagation through the full model, we compute gradients with respect to LoRA parameters using multiple paraphrased prompts and train a gradient decoder to approximate the corresponding full-model gradients. To ensure applicability to larger or black-box models, the decoder is trained on a proxy model and transferred to target models. We provide a theoretical analysis of cross-model generalization and demonstrate that our method achieves effective unlearning while preserving general model performance. Experimental results demonstrate that R2F offers a scalable and lightweight alternative for unlearning in pretrained LLMs without requiring full retraining or access to internal parameters.",
        "url": "http://arxiv.org/abs/2512.07374v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07374v1",
        "arxiv_id": "2512.07374v1",
        "authors": [
            "Yezi Liu",
            "Hanning Chen",
            "Wenjun Huang",
            "Yang Ni",
            "Mohsen Imani"
        ],
        "submitted": "2025-12-08 10:10:12",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on unlearning in large language models, which is a topic related to NLP, but does not directly align with the user's primary research interests in Information Retrieval, query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Investigating Training and Generalization in Faithful Self-Explanations of Large Language Models",
        "abstract": "Large language models have the potential to generate explanations for their own predictions in a variety of styles based on user instructions. Recent research has examined whether these self-explanations faithfully reflect the models' actual behavior and has found that they often lack faithfulness. However, the question of how to improve faithfulness remains underexplored. Moreover, because different explanation styles have superficially distinct characteristics, it is unclear whether improvements observed in one style also arise when using other styles. This study analyzes the effects of training for faithful self-explanations and the extent to which these effects generalize, using three classification tasks and three explanation styles. We construct one-word constrained explanations that are likely to be faithful using a feature attribution method, and use these pseudo-faithful self-explanations for continual learning on instruction-tuned models. Our experiments demonstrate that training can improve self-explanation faithfulness across all classification tasks and explanation styles, and that these improvements also show signs of generalization to the multi-word settings and to unseen tasks. Furthermore, we find consistent cross-style generalization among three styles, suggesting that training may contribute to a broader improvement in faithful self-explanation ability.",
        "url": "http://arxiv.org/abs/2512.07288v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07288v1",
        "arxiv_id": "2512.07288v1",
        "authors": [
            "Tomoki Doi",
            "Masaru Isonuma",
            "Hitomi Yanaka"
        ],
        "submitted": "2025-12-08 08:28:10",
        "source": "arxiv",
        "comment": "To appear in the Proceedings of the Asia-Pacific Chapter of the Association for Computational Linguistics: Student Research Workshop (AACL-SRW 2025)",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and Large Language Models, but it does not directly address information retrieval, query understanding, or ranking models. The focus on self-explanations and faithful explanations in language models is tangentially related to the user's interests in deep semantic understanding, but it is not a central match."
    },
    {
        "title": "TeluguST-46: A Benchmark Corpus and Comprehensive Evaluation for Telugu-English Speech Translation",
        "abstract": "Despite Telugu being spoken by over 80 million people, speech translation research for this morphologically rich language remains severely underexplored. We address this gap by developing a high-quality Telugu--English speech translation benchmark from 46 hours of manually verified CSTD corpus data (30h/8h/8h train/dev/test split). Our systematic comparison of cascaded versus end-to-end architectures shows that while IndicWhisper + IndicMT achieves the highest performance due to extensive Telugu-specific training data, finetuned SeamlessM4T models demonstrate remarkable competitiveness despite using significantly less Telugu-specific training data. This finding suggests that with careful hyperparameter tuning and sufficient parallel data (potentially less than 100 hours), end-to-end systems can achieve performance comparable to cascaded approaches in low-resource settings. Our metric reliability study evaluating BLEU, METEOR, ChrF++, ROUGE-L, TER, and BERTScore against human judgments reveals that traditional metrics provide better quality discrimination than BERTScore for Telugu--English translation. The work delivers three key contributions: a reproducible Telugu--English benchmark, empirical evidence of competitive end-to-end performance potential in low-resource scenarios, and practical guidance for automatic evaluation in morphologically complex language pairs.",
        "url": "http://arxiv.org/abs/2512.07265v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07265v1",
        "arxiv_id": "2512.07265v1",
        "authors": [
            "Bhavana Akkiraju",
            "Srihari Bandarupalli",
            "Swathi Sambangi",
            "Vasavi Ravuri",
            "R Vijaya Saraswathi",
            "Anil Kumar Vuppala"
        ],
        "submitted": "2025-12-08 08:06:11",
        "source": "arxiv",
        "comment": "Submitted to AACL IJCNLP 2025",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing. The focus is on speech translation and benchmarking for the Telugu language, which does not align with your areas of expertise."
    },
    {
        "title": "PICKT: Practical Interlinked Concept Knowledge Tracing for Personalized Learning using Knowledge Map Concept Relations",
        "abstract": "With the recent surge in personalized learning, Intelligent Tutoring Systems (ITS) that can accurately track students' individual knowledge states and provide tailored learning paths based on this information are in demand as an essential task. This paper focuses on the core technology of Knowledge Tracing (KT) models that analyze students' sequences of interactions to predict their knowledge acquisition levels. However, existing KT models suffer from limitations such as restricted input data formats, cold start problems arising with new student enrollment or new question addition, and insufficient stability in real-world service environments. To overcome these limitations, a Practical Interlinked Concept Knowledge Tracing (PICKT) model that can effectively process multiple types of input data is proposed. Specifically, a knowledge map structures the relationships among concepts considering the question and concept text information, thereby enabling effective knowledge tracing even in cold start situations. Experiments reflecting real operational environments demonstrated the model's excellent performance and practicality. The main contributions of this research are as follows. First, a model architecture that effectively utilizes diverse data formats is presented. Second, significant performance improvements are achieved over existing models for two core cold start challenges: new student enrollment and new question addition. Third, the model's stability and practicality are validated through delicate experimental design, enhancing its applicability in real-world product environments. This provides a crucial theoretical and technical foundation for the practical implementation of next-generation ITS.",
        "url": "http://arxiv.org/abs/2512.07179v1",
        "pdf_url": "https://arxiv.org/pdf/2512.07179v1",
        "arxiv_id": "2512.07179v1",
        "authors": [
            "Wonbeen Lee",
            "Channyoung Lee",
            "Junho Sohn",
            "Hansam Cho"
        ],
        "submitted": "2025-12-08 05:24:17",
        "source": "arxiv",
        "comment": "15 pages, 5 figures, 17 tables. Preparing submission for EDM 2026 conference",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Knowledge Tracing models for personalized learning, which is outside the user's primary research interests in Information Retrieval and Search technologies. While it involves data analysis and modeling, the context and application are not directly related to the user's areas of expertise."
    },
    {
        "title": "Prompting-in-a-Series: Psychology-Informed Contents and Embeddings for Personality Recognition With Decoder-Only Models",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various natural language processing tasks. This research introduces a novel \"Prompting-in-a-Series\" algorithm, termed PICEPR (Psychology-Informed Contents Embeddings for Personality Recognition), featuring two pipelines: (a) Contents and (b) Embeddings. The approach demonstrates how a modularised decoder-only LLM can summarize or generate content, which can aid in classifying or enhancing personality recognition functions as a personality feature extractor and a generator for personality-rich content. We conducted various experiments to provide evidence to justify the rationale behind the PICEPR algorithm. Meanwhile, we also explored closed-source models such as \\textit{gpt4o} from OpenAI and \\textit{gemini} from Google, along with open-source models like \\textit{mistral} from Mistral AI, to compare the quality of the generated content. The PICEPR algorithm has achieved a new state-of-the-art performance for personality recognition by 5-15\\% improvement. The work repository and models' weight can be found at https://research.jingjietan.com/?q=PICEPR.",
        "url": "http://arxiv.org/abs/2512.06991v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06991v1",
        "arxiv_id": "2512.06991v1",
        "authors": [
            "Jing Jie Tan",
            "Ban-Hoe Kwan",
            "Danny Wee-Kiat Ng",
            "Yan-Chai Hum",
            "Anissa Mokraoui",
            "Shih-Yu Lo"
        ],
        "submitted": "2025-12-07 20:52:00",
        "source": "arxiv",
        "comment": "16 pages",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on personality recognition using large language models, which is outside your primary area of interest in Information Retrieval and Search technologies. Although it involves NLP, the specific application and techniques used are not aligned with your core research themes."
    },
    {
        "title": "Space efficient implementation of hypergraph dualization in the D-basis algorithm",
        "abstract": "We present a new implementation of the $D$-basis algorithm called the Small Space which considerably reduces the algorithm's memory usage for data analysis applications. The previous implementation delivers the complete set of implications that hold on the set of attributes of an input binary table. In the new version, the only output is the frequencies of attributes that appear in the antecedents of implications from the $D$-basis, with a fixed consequent attribute. Such frequencies, rather than the implications themselves, became the primary focus in analysis of datasets where the $D$-basis has been applied over the last decade. The $D$-basis employs a hypergraph dualization algorithm, and a dualization implementation known as Reverse Search allows for the gradual computation of frequencies without the need for storing all discovered implications. We demonstrate the effectiveness of the Small Space implementation by comparing the runtimes and maximum memory usage of this new version with the current implementation.",
        "url": "http://arxiv.org/abs/2512.06988v1",
        "pdf_url": "https://arxiv.org/pdf/2512.06988v1",
        "arxiv_id": "2512.06988v1",
        "authors": [
            "Skylar Homan",
            "Anoop Krishnadas",
            "Kira Adaricheva"
        ],
        "submitted": "2025-12-07 20:47:36",
        "source": "arxiv",
        "comment": "21 pages, 3 figures, 10 tables. Submitted to Discrete Applied Mathematics. Results were presented at the AMS 2025 Fall Western Sectional Meeting at the University of Denver",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 0,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, Natural Language Processing, or data mining. The paper focuses on a space-efficient implementation of a hypergraph dualization algorithm, which is unrelated to your areas of interest."
    }
]