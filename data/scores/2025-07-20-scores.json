[
    {
        "title": "PARK: Personalized academic retrieval with knowledge-graphs",
        "abstract": "Academic Search is a search task aimed to manage and retrieve scientific\ndocuments like journal articles and conference papers. Personalization in this\ncontext meets individual researchers' needs by leveraging, through user\nprofiles, the user related information (e.g. documents authored by a\nresearcher), to improve search effectiveness and to reduce the information\noverload. While citation graphs are a valuable means to support the outcome of\nrecommender systems, their use in personalized academic search (with, e.g.\nnodes as papers and edges as citations) is still under-explored.\n  Existing personalized models for academic search often struggle to fully\ncapture users' academic interests. To address this, we propose a two-step\napproach: first, training a neural language model for retrieval, then\nconverting the academic graph into a knowledge graph and embedding it into a\nshared semantic space with the language model using translational embedding\ntechniques. This allows user models to capture both explicit relationships and\nhidden structures in citation graphs and paper content. We evaluate our\napproach in four academic search domains, outperforming traditional graph-based\nand personalized models in three out of four, with up to a 10\\% improvement in\nMAP@100 over the second-best model. This highlights the potential of knowledge\ngraph-based user models to enhance retrieval effectiveness.",
        "url": "http://arxiv.org/abs/2507.13910v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13910v1",
        "arxiv_id": "2507.13910v1",
        "authors": [
            "Pranav Kasela",
            "Gabriella Pasi",
            "Raffaele Perego"
        ],
        "submitted": "2025-07-18 13:41:01",
        "source": "arxiv",
        "comment": "Accepted in Information Systems. [17 May 2025]\n  https://doi.org/10.1016/j.is.2025.102574",
        "score": 7,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'personalization' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 7,
        "llm_reason": "The paper explores personalized academic retrieval with knowledge-graphs, which is related to information retrieval and search technologies. The use of neural language models and translational embedding techniques is also relevant to query understanding and ranking models. However, the focus on academic search and citation graphs is somewhat specific and may not directly align with the user's interests in e-commerce and real-time relevance optimization."
    },
    {
        "title": "Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models",
        "abstract": "When deciding to read an article or incorporate it into their research,\nscholars often seek to quickly identify and understand its main ideas. In this\npaper, we aim to extract these key concepts and contributions from scientific\narticles in the form of Question and Answer (QA) pairs. We propose two distinct\napproaches for generating QAs. The first approach involves selecting salient\nparagraphs, using a Large Language Model (LLM) to generate questions, ranking\nthese questions by the likelihood of obtaining meaningful answers, and\nsubsequently generating answers. This method relies exclusively on the content\nof the articles. However, assessing an article's novelty typically requires\ncomparison with the existing literature. Therefore, our second approach\nleverages a Knowledge Graph (KG) for QA generation. We construct a KG by\nfine-tuning an Entity Relationship (ER) extraction model on scientific articles\nand using it to build the graph. We then employ a salient triplet extraction\nmethod to select the most pertinent ERs per article, utilizing metrics such as\nthe centrality of entities based on a triplet TF-IDF-like measure. This measure\nassesses the saliency of a triplet based on its importance within the article\ncompared to its prevalence in the literature. For evaluation, we generate QAs\nusing both approaches and have them assessed by Subject Matter Experts (SMEs)\nthrough a set of predefined metrics to evaluate the quality of both questions\nand answers. Our evaluations demonstrate that the KG-based approach effectively\ncaptures the main ideas discussed in the articles. Furthermore, our findings\nindicate that fine-tuning the ER extraction model on our scientific corpus is\ncrucial for extracting high-quality triplets from such documents.",
        "url": "http://arxiv.org/abs/2507.13827v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13827v1",
        "arxiv_id": "2507.13827v1",
        "authors": [
            "Hosein Azarbonyad",
            "Zi Long Zhu",
            "Georgios Cheirmpos",
            "Zubair Afzal",
            "Vikrant Yadav",
            "Georgios Tsatsaronis"
        ],
        "submitted": "2025-07-18 11:31:52",
        "source": "arxiv",
        "comment": "SIGIR 2025",
        "score": 7,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores question-answer extraction from scientific articles using knowledge graphs and large language models, which is somewhat related to my interests in information retrieval and natural language processing. However, the focus on scientific articles and knowledge graphs is not directly aligned with my primary focus on query understanding, ranking models, and user behavior modeling in the e-commerce domain."
    },
    {
        "title": "DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits",
        "abstract": "Progress notes are among the most clinically meaningful artifacts in an\nElectronic Health Record (EHR), offering temporally grounded insights into a\npatient's evolving condition, treatments, and care decisions. Despite their\nimportance, they are severely underrepresented in large-scale EHR datasets. For\ninstance, in the widely used Medical Information Mart for Intensive Care III\n(MIMIC-III) dataset, only about $8.56\\%$ of hospital visits include progress\nnotes, leaving gaps in longitudinal patient narratives. In contrast, the\ndataset contains a diverse array of other note types, each capturing different\naspects of care.\n  We present DENSE (Documenting Evolving Progress Notes from Scattered\nEvidence), a system designed to align with clinical documentation workflows by\nsimulating how physicians reference past encounters while drafting progress\nnotes. The system introduces a fine-grained note categorization and a temporal\nalignment mechanism that organizes heterogeneous notes across visits into\nstructured, chronological inputs. At its core, DENSE leverages a clinically\ninformed retrieval strategy to identify temporally and semantically relevant\ncontent from both current and prior visits. This retrieved evidence is used to\nprompt a large language model (LLM) to generate clinically coherent and\ntemporally aware progress notes.\n  We evaluate DENSE on a curated cohort of patients with multiple visits and\ncomplete progress note documentation. The generated notes demonstrate strong\nlongitudinal fidelity, achieving a temporal alignment ratio of $1.089$,\nsurpassing the continuity observed in original notes. By restoring narrative\ncoherence across fragmented documentation, our system supports improved\ndownstream tasks such as summarization, predictive modeling, and clinical\ndecision support, offering a scalable solution for LLM-driven note synthesis in\nreal-world healthcare settings.",
        "url": "http://arxiv.org/abs/2507.14079v1",
        "pdf_url": "http://arxiv.org/pdf/2507.14079v1",
        "arxiv_id": "2507.14079v1",
        "authors": [
            "Garapati Keerthana",
            "Manik Gupta"
        ],
        "submitted": "2025-07-18 17:00:27",
        "source": "arxiv",
        "comment": null,
        "score": 6,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'ctr' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on generating progress notes in the healthcare domain using a system called DENSE, which leverages a clinically informed retrieval strategy and a large language model. While it involves information retrieval and natural language processing, the context is quite different from the user's interests in search technologies, query understanding, and user behavior modeling, and does not seem to require deep semantic understanding or real-time relevance optimization."
    },
    {
        "title": "Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track",
        "abstract": "Objective: Recent advances in language models have shown potential to adapt\nprofessional-facing biomedical literature to plain language, making it\naccessible to patients and caregivers. However, their unpredictability,\ncombined with the high potential for harm in this domain, means rigorous\nevaluation is necessary. Our goals with this track were to stimulate research\nand to provide high-quality evaluation of the most promising systems.\n  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts\n(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included\ncomplete, sentence-level, rewriting of abstracts (Task 1) as well as\nidentifying and replacing difficult terms (Task 2). For automatic evaluation of\nTask 1, we developed a four-fold set of professionally-written references.\nSubmissions for both Tasks 1 and 2 were provided extensive manual evaluation\nfrom biomedical experts.\n  Results: Twelve teams spanning twelve countries participated in the track,\nwith models from multilayer perceptrons to large pretrained transformers. In\nmanual judgments of Task 1, top-performing models rivaled human levels of\nfactual accuracy and completeness, but not simplicity or brevity. Automatic,\nreference-based metrics generally did not correlate well with manual judgments.\nIn Task 2, systems struggled with identifying difficult terms and classifying\nhow to replace them. When generating replacements, however, LLM-based systems\ndid well in manually judged accuracy, completeness, and simplicity, though not\nin brevity.\n  Conclusion: The PLABA track showed promise for using Large Language Models to\nadapt biomedical literature for the general public, while also highlighting\ntheir deficiencies and the need for improved automatic benchmarking tools.",
        "url": "http://arxiv.org/abs/2507.14096v1",
        "pdf_url": "http://arxiv.org/pdf/2507.14096v1",
        "arxiv_id": "2507.14096v1",
        "authors": [
            "Brian Ondov",
            "William Xia",
            "Kush Attal",
            "Ishita Unde",
            "Jerry He",
            "Hoa Dang",
            "Ian Soboroff",
            "Dina Demner-Fushman"
        ],
        "submitted": "2025-07-18 17:23:52",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)",
            "Found 'trec' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to information retrieval, specifically in the context of adapting biomedical literature for the general public. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The focus on language models and biomedical literature is not directly applicable to the user's research themes."
    },
    {
        "title": "Exploiting Primacy Effect To Improve Large Language Models",
        "abstract": "Large Language Models (LLMs) have become essential in many Natural Language\nProcessing (NLP) tasks, leveraging extensive pre-training and fine-tuning to\nachieve high accuracy. However, like humans, LLMs exhibit biases, particularly\npositional biases such as primacy and recency effects, which can influence the\naccuracy of the answers. The primacy effect-where items presented first are\nmore likely to be remembered or selected-plays a key role in Multiple Choice\nQuestion Answering (MCQA), where the order of answer options can affect\nprediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We\nfirst show that fine-tuning amplifies this bias, probably due to exposure to\nhuman-like patterns. Hence, we strategically leverage this effect by reordering\nresponse options based on semantic similarity to the query, without requiring\nknowledge of the correct answer. Our experimental results show that this\napproach significantly improves performance in MCQA. More generally, our\nfindings underscore the dual nature of biases as both challenges and\nopportunities, offering insights for bias-aware model design and NLP\napplications.",
        "url": "http://arxiv.org/abs/2507.13949v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13949v1",
        "arxiv_id": "2507.13949v1",
        "authors": [
            "Bianca Raimondi",
            "Maurizio Gabbrielli"
        ],
        "submitted": "2025-07-18 14:18:18",
        "source": "arxiv",
        "comment": "Accepted by RANLP 2025",
        "score": 5,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the primacy effect in Large Language Models, which is a topic in NLP, but it does not directly relate to Information Retrieval, query understanding, ranking models, or user behavior modeling, which are the user's primary research interests. While the paper touches on bias-aware model design, it does not specifically address real-time relevance optimization or deep semantic understanding, which are key aspects of the user's research focus."
    },
    {
        "title": "Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support",
        "abstract": "We present Marcel, a lightweight and open-source conversational agent\ndesigned to support prospective students with admission-related inquiries. The\nsystem aims to provide fast and personalized responses, while reducing workload\nof university staff. We employ retrieval-augmented generation to ground answers\nin university resources and to provide users with verifiable, contextually\nrelevant information. To improve retrieval quality, we introduce an FAQ\nretriever that maps user questions to knowledge-base entries, allowing\nadministrators to steer retrieval, and improving over standard dense/hybrid\nretrieval strategies. The system is engineered for easy deployment in\nresource-constrained academic settings. We detail the system architecture,\nprovide a technical evaluation of its components, and report insights from a\nreal-world deployment.",
        "url": "http://arxiv.org/abs/2507.13937v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13937v1",
        "arxiv_id": "2507.13937v1",
        "authors": [
            "Jan Trienes",
            "Anastasiia Derzhanskaia",
            "Roland Schwarzkopf",
            "Markus Mühling",
            "Jörg Schlötterer",
            "Christin Seifert"
        ],
        "submitted": "2025-07-18 14:09:45",
        "source": "arxiv",
        "comment": null,
        "score": 5,
        "keyword_reasons": [
            "Found 'retriever' (score: +3)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on a conversational agent for university student support, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions retrieval-augmented generation and an FAQ retriever, the context is specific to university admissions and does not align with the user's broader interests."
    },
    {
        "title": "Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment",
        "abstract": "Bridge maintenance and safety are essential for transportation authorities,\nand Non-Destructive Evaluation (NDE) techniques are critical to assessing\nstructural integrity. However, interpreting NDE data can be time-consuming and\nrequires expertise, potentially delaying decision-making. Recent advancements\nin Large Language Models (LLMs) offer new ways to automate and improve this\nanalysis. This pilot study introduces a holistic assessment of LLM capabilities\nfor interpreting NDE contour maps and demonstrates the effectiveness of LLMs in\nproviding detailed bridge condition analyses. It establishes a framework for\nintegrating LLMs into bridge inspection workflows, indicating that LLM-assisted\nanalysis can enhance efficiency without compromising accuracy. In this study,\nseveral LLMs are explored with prompts specifically designed to enhance the\nquality of image descriptions, which are applied to interpret five different\nNDE contour maps obtained through technologies for assessing bridge conditions.\nEach LLM model is evaluated based on its ability to produce detailed\ndescriptions, identify defects, provide actionable recommendations, and\ndemonstrate overall accuracy. The research indicates that four of the nine\nmodels provide better image descriptions, effectively covering a wide range of\ntopics related to the bridge's condition. The outputs from these four models\nare summarized using five different LLMs to form a comprehensive overview of\nthe bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more\neffective summaries. The findings suggest that LLMs have the potential to\nsignificantly improve efficiency and accuracy. This pilot study presents an\ninnovative approach that leverages LLMs for image captioning in parallel and\nsummarization, enabling faster decision-making in bridge maintenance and\nenhancing infrastructure management and safety assessments.",
        "url": "http://arxiv.org/abs/2507.14107v1",
        "pdf_url": "http://arxiv.org/pdf/2507.14107v1",
        "arxiv_id": "2507.14107v1",
        "authors": [
            "Viraj Nishesh Darji",
            "Callie C. Liao",
            "Duoduo Liao"
        ],
        "submitted": "2025-07-18 17:39:03",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The topic of bridge condition assessment using Large Language Models is outside the user's primary focus and expertise."
    },
    {
        "title": "DUALRec: A Hybrid Sequential and Language Model Framework for Context-Aware Movie Recommendation",
        "abstract": "The modern recommender systems are facing an increasing challenge of\nmodelling and predicting the dynamic and context-rich user preferences.\nTraditional collaborative filtering and content-based methods often struggle to\ncapture the temporal patternings and evolving user intentions. While Large\nLanguage Models (LLMs) have gained gradual attention in recent years, by their\nstrong semantic understanding and reasoning abilities, they are not inherently\ndesigned to model chronologically evolving user preference and intentions. On\nthe other hand, for sequential models like LSTM (Long-Short-Term-Memory) which\nis good at capturing the temporal dynamics of user behaviour and evolving user\npreference over time, but still lacks a rich semantic understanding for\ncomprehensive recommendation generation. In this study, we propose DUALRec\n(Dynamic User-Aware Language-based Recommender), a novel recommender that\nleverages the complementary strength of both models, which combines the\ntemporal modelling abilities of LSTM networks with semantic reasoning power of\nthe fine-tuned Large Language Models. The LSTM component will capture users\nevolving preference through their viewing history, while the fine-tuned LLM\nvariants will leverage these temporal user insights to generate next movies\nthat users might enjoy. Experimental results on MovieLens-1M dataset shows that\nthe DUALRec model outperforms a wide range of baseline models, with\ncomprehensive evaluation matrices of Hit Rate (HR@k), Normalized Discounted\nCumulative Gain (NDCG@k), and genre similarity metrics. This research proposes\na novel architecture that bridges the gap between temporal sequence modeling\nand semantic reasoning, and offers a promising direction for developing more\nintelligent and context-aware recommenders.",
        "url": "http://arxiv.org/abs/2507.13957v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13957v1",
        "arxiv_id": "2507.13957v1",
        "authors": [
            "Yitong Li",
            "Raoul Grasman"
        ],
        "submitted": "2025-07-18 14:22:05",
        "source": "arxiv",
        "comment": "10 pages, 5 figures",
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a hybrid recommender system that combines sequential and language models, which is somewhat related to my interests in Information Retrieval and Search technologies. However, the focus on movie recommendation and user behavior modeling in the e-commerce domain is not directly aligned with my primary research themes, which are query understanding, ranking models, and user behavior modeling in a broader context."
    },
    {
        "title": "SPARQL Query Generation with LLMs: Measuring the Impact of Training Data Memorization and Knowledge Injection",
        "abstract": "Nowadays, the importance of software with natural-language user interfaces\ncannot be underestimated. In particular, in Question Answering (QA) systems,\ngenerating a SPARQL query for a given natural-language question (often named\nQuery Building) from the information retrieved from the same question is the\ncentral task of QA systems working over Knowledge Graphs (KGQA). Due to the\nrise of Large Language Models (LLMs), they are considered a well-suited method\nto increase the quality of the question-answering functionality, as there is\nstill a lot of room for improvement, aiming for enhanced quality and\ntrustworthiness. However, LLMs are trained on web data, where researchers have\nno control over whether the benchmark or the knowledge graph was already\nincluded in the training data. In this paper, we introduce a novel method that\nevaluates the quality of LLMs by generating a SPARQL query from a\nnatural-language question under various conditions: (1) zero-shot SPARQL\ngeneration, (2) with knowledge injection, and (3) with \"anonymized\" knowledge\ninjection. This enables us, for the first time, to estimate the influence of\nthe training data on the QA quality improved by LLMs. Ultimately, this will\nhelp to identify how portable a method is or whether good results might mostly\nbe achieved because a benchmark was already included in the training data (cf.\nLLM memorization). The developed method is portable, robust, and supports any\nknowledge graph; therefore, it could be easily applied to any KGQA or LLM,\ns.t., generating consistent insights into the actual LLM capabilities is\npossible.",
        "url": "http://arxiv.org/abs/2507.13859v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13859v1",
        "arxiv_id": "2507.13859v1",
        "authors": [
            "Aleksandr Gashkov",
            "Aleksandr Perevalov",
            "Maria Eltsova",
            "Andreas Both"
        ],
        "submitted": "2025-07-18 12:28:08",
        "source": "arxiv",
        "comment": "Winner of Best Paper Award at the 25th International Conference on\n  Web Engineering (ICWE 2025)",
        "score": 4,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of Large Language Models (LLMs) in Query Answering systems, focusing on SPARQL query generation. While it touches on the topic of query understanding, it does not specifically address ranking models or user behavior modeling, which are key areas of interest for you. The paper's focus on LLMs and knowledge graphs is somewhat related to your research in NLP and data mining, but it does not align with your primary focus on information retrieval and real-time relevance optimization."
    },
    {
        "title": "RAG-based Architectures for Drug Side Effect Retrieval in LLMs",
        "abstract": "Drug side effects are a major global health concern, necessitating advanced\nmethods for their accurate detection and analysis. While Large Language Models\n(LLMs) offer promising conversational interfaces, their inherent limitations,\nincluding reliance on black-box training data, susceptibility to\nhallucinations, and lack of domain-specific knowledge, hinder their reliability\nin specialized fields like pharmacovigilance. To address this gap, we propose\ntwo architectures: Retrieval-Augmented Generation (RAG) and GraphRAG, which\nintegrate comprehensive drug side effect knowledge into a Llama 3 8B language\nmodel. Through extensive evaluations on 19,520 drug side effect associations\n(covering 976 drugs and 3,851 side effect terms), our results demonstrate that\nGraphRAG achieves near-perfect accuracy in drug side effect retrieval. This\nframework offers a highly accurate and scalable solution, signifying a\nsignificant advancement in leveraging LLMs for critical pharmacovigilance\napplications.",
        "url": "http://arxiv.org/abs/2507.13822v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13822v1",
        "arxiv_id": "2507.13822v1",
        "authors": [
            "Shad Nygren",
            "Pinar Avci",
            "Andre Daniels",
            "Reza Rassol",
            "Afshin Beheshti",
            "Diego Galeano"
        ],
        "submitted": "2025-07-18 11:20:52",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on drug side effect retrieval in Large Language Models, which is outside your primary area of interest."
    },
    {
        "title": "Point of Interest Recommendation: Pitfalls and Viable Solutions",
        "abstract": "Point of interest (POI) recommendation can play a pivotal role in enriching\ntourists' experiences by suggesting context-dependent and preference-matching\nlocations and activities, such as restaurants, landmarks, itineraries, and\ncultural attractions. Unlike some more common recommendation domains (e.g.,\nmusic and video), POI recommendation is inherently high-stakes: users invest\nsignificant time, money, and effort to search, choose, and consume these\nsuggested POIs. Despite the numerous research works in the area, several\nfundamental issues remain unresolved, hindering the real-world applicability of\nthe proposed approaches. In this paper, we discuss the current status of the\nPOI recommendation problem and the main challenges we have identified. The\nfirst contribution of this paper is a critical assessment of the current state\nof POI recommendation research and the identification of key shortcomings\nacross three main dimensions: datasets, algorithms, and evaluation\nmethodologies. We highlight persistent issues such as the lack of standardized\nbenchmark datasets, flawed assumptions in the problem definition and model\ndesign, and inadequate treatment of biases in the user behavior and system\nperformance. The second contribution is a structured research agenda that,\nstarting from the identified issues, introduces important directions for future\nwork related to multistakeholder design, context awareness, data collection,\ntrustworthiness, novel interactions, and real-world evaluation.",
        "url": "http://arxiv.org/abs/2507.13725v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13725v1",
        "arxiv_id": "2507.13725v1",
        "authors": [
            "Alejandro Bellogín",
            "Linus W. Dietz",
            "Francesco Ricci",
            "Pablo Sánchez"
        ],
        "submitted": "2025-07-18 08:10:09",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'user behavior' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Point of Interest (POI) recommendation, which is a topic in recommender systems, but it does not directly relate to the user's primary interests in Information Retrieval (IR), query understanding, ranking models, and user behavior modeling. While the paper discusses challenges and future directions, it does not seem to address the user's core research themes."
    },
    {
        "title": "Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers",
        "abstract": "The safety of large language models (LLMs) has garnered significant research\nattention. In this paper, we argue that previous empirical studies demonstrate\nLLMs exhibit a propensity to trust information from authoritative sources, such\nas academic papers, implying new possible vulnerabilities. To verify this\npossibility, a preliminary analysis is designed to illustrate our two findings.\nBased on this insight, a novel jailbreaking method, Paper Summary Attack\n(\\llmname{PSA}), is proposed. It systematically synthesizes content from either\nattack-focused or defense-focused LLM safety paper to construct an adversarial\nprompt template, while strategically infilling harmful query as adversarial\npayloads within predefined subsections. Extensive experiments show significant\nvulnerabilities not only in base LLMs, but also in state-of-the-art reasoning\nmodel like Deepseek-R1. PSA achieves a 97\\% attack success rate (ASR) on\nwell-aligned models like Claude3.5-Sonnet and an even higher 98\\% ASR on\nDeepseek-R1. More intriguingly, our work has further revealed diametrically\nopposed vulnerability bias across different base models, and even between\ndifferent versions of the same model, when exposed to either attack-focused or\ndefense-focused papers. This phenomenon potentially indicates future research\nclues for both adversarial methodologies and safety alignment.Code is available\nat https://github.com/233liang/Paper-Summary-Attack",
        "url": "http://arxiv.org/abs/2507.13474v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13474v1",
        "arxiv_id": "2507.13474v1",
        "authors": [
            "Liang Lin",
            "Zhihao Xu",
            "Xuehai Tang",
            "Shi Liu",
            "Biyu Zhou",
            "Fuqing Zhu",
            "Jizhong Han",
            "Songlin Hu"
        ],
        "submitted": "2025-07-17 18:33:50",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on the safety of large language models and proposes a novel attack method, which is not related to your areas of interest."
    },
    {
        "title": "EdgeVLA: Efficient Vision-Language-Action Models",
        "abstract": "Vision-Language Models (VLMs) have emerged as a promising approach to address\nthe data scarcity challenge in robotics, enabling the development of\ngeneralizable visuomotor control policies. While models like OpenVLA showcase\nthe potential of this paradigm, deploying large-scale VLMs on\nresource-constrained mobile manipulation systems remains a significant hurdle.\nThis paper introduces Edge VLA (EVLA), a novel approach designed to\nsignificantly enhance the inference speed of Vision-Language-Action (VLA)\nmodels. EVLA maintains the representational power of these models while\nenabling real-time performance on edge devices. We achieve this through two key\ninnovations: 1) Eliminating the autoregressive requirement for end-effector\nposition prediction, leading to a 7x speedup in inference, and 2) Leveraging\nthe efficiency of Small Language Models (SLMs), demonstrating comparable\ntraining performance to larger models with significantly reduced computational\ndemands. Our early results demonstrate that EVLA achieves comparable training\ncharacteristics to OpenVLA while offering substantial gains in inference speed\nand memory efficiency. We release our model checkpoints and training\n\\href{https://github.com/kscalelabs/evla }{codebase} to foster further\nresearch.",
        "url": "http://arxiv.org/abs/2507.14049v1",
        "pdf_url": "http://arxiv.org/pdf/2507.14049v1",
        "arxiv_id": "2507.14049v1",
        "authors": [
            "Paweł Budzianowski",
            "Wesley Maa",
            "Matthew Freed",
            "Jingxiang Mo",
            "Winston Hsiao",
            "Aaron Xie",
            "Tomasz Młoduchowski",
            "Viraj Tipnis",
            "Benjamin Bolte"
        ],
        "submitted": "2025-07-18 16:15:09",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on Vision-Language-Action models for robotics, which is not directly related to Information Retrieval, Search technologies, or Natural Language Processing. While it mentions small language models, the context is different from the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis",
        "abstract": "This study proposes the Cognitive Pairwise Comparison Classification Model\nSelection (CPC-CMS) framework for document-level sentiment analysis. The CPC,\nbased on expert knowledge judgment, is used to calculate the weights of\nevaluation criteria, including accuracy, precision, recall, F1-score,\nspecificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and\nefficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random\nForest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long\nShort-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from\nTransformers (ALBERT) are chosen as classification baseline models. A weighted\ndecision matrix consisting of classification evaluation scores with respect to\ncriteria weights, is formed to select the best classification model for a\nclassification problem. Three open datasets of social media are used to\ndemonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,\nfor evaluation results excluding the time factor, ALBERT is the best for the\nthree datasets; if time consumption is included, no single model always\nperforms better than the other models. The CPC-CMS can be applied to the other\nclassification applications in different areas.",
        "url": "http://arxiv.org/abs/2507.14022v1",
        "pdf_url": "http://arxiv.org/pdf/2507.14022v1",
        "arxiv_id": "2507.14022v1",
        "authors": [
            "Jianfei Li",
            "Kevin Kam Fung Yuen"
        ],
        "submitted": "2025-07-18 15:41:53",
        "source": "arxiv",
        "comment": "35 pages, 33 tables, 6 Figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on document-level sentiment analysis, using a framework for selecting the best classification model. While it involves classification and evaluation metrics, it is not directly related to information retrieval, search technologies, or query understanding, which are the user's primary research interests."
    },
    {
        "title": "Label Unification for Cross-Dataset Generalization in Cybersecurity NER",
        "abstract": "The field of cybersecurity NER lacks standardized labels, making it\nchallenging to combine datasets. We investigate label unification across four\ncybersecurity datasets to increase data resource usability. We perform a\ncoarse-grained label unification and conduct pairwise cross-dataset evaluations\nusing BiLSTM models. Qualitative analysis of predictions reveals errors,\nlimitations, and dataset differences. To address unification limitations, we\npropose alternative architectures including a multihead model and a graph-based\ntransfer model. Results show that models trained on unified datasets generalize\npoorly across datasets. The multihead model with weight sharing provides only\nmarginal improvements over unified training, while our graph-based transfer\nmodel built on BERT-base-NER shows no significant performance gains compared\nBERT-base-NER.",
        "url": "http://arxiv.org/abs/2507.13870v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13870v1",
        "arxiv_id": "2507.13870v1",
        "authors": [
            "Maciej Jalocha",
            "Johan Hausted Schmidt",
            "William Michelseen"
        ],
        "submitted": "2025-07-18 12:47:20",
        "source": "arxiv",
        "comment": "5 pages, 5 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'pairwise' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on cybersecurity Named Entity Recognition (NER) and label unification, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's abstract does not mention query understanding, ranking models, or user behavior modeling, making it irrelevant to the user's core research themes."
    },
    {
        "title": "DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs",
        "abstract": "Rich and context-aware activity logs facilitate user behavior analysis and\nhealth monitoring, making them a key research focus in ubiquitous computing.\nThe remarkable semantic understanding and generation capabilities of Large\nLanguage Models (LLMs) have recently created new opportunities for activity log\ngeneration. However, existing methods continue to exhibit notable limitations\nin terms of accuracy, efficiency, and semantic richness. To address these\nchallenges, we propose DailyLLM. To the best of our knowledge, this is the\nfirst log generation and summarization system that comprehensively integrates\ncontextual activity information across four dimensions: location, motion,\nenvironment, and physiology, using only sensors commonly available on\nsmartphones and smartwatches. To achieve this, DailyLLM introduces a\nlightweight LLM-based framework that integrates structured prompting with\nefficient feature extraction to enable high-level activity understanding.\nExtensive experiments demonstrate that DailyLLM outperforms state-of-the-art\n(SOTA) log generation methods and can be efficiently deployed on personal\ncomputers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM\nachieves a 17% improvement in log generation BERTScore precision compared to\nthe 70B-parameter SOTA baseline, while delivering nearly 10x faster inference\nspeed.",
        "url": "http://arxiv.org/abs/2507.13737v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13737v1",
        "arxiv_id": "2507.13737v1",
        "authors": [
            "Ye Tian",
            "Xiaoyuan Ren",
            "Zihao Wang",
            "Onat Gungor",
            "Xiaofan Yu",
            "Tajana Rosing"
        ],
        "submitted": "2025-07-18 08:33:30",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'user behavior' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on activity log generation using multi-modal sensors and LLMs, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on semantic understanding, it is primarily concerned with activity log generation and summarization, which is outside the scope of the user's research interests."
    },
    {
        "title": "Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations",
        "abstract": "Large Language Models (LLMs) are increasingly being implemented as joint\ndecision-makers and explanation generators for Group Recommender Systems (GRS).\nIn this paper, we evaluate these recommendations and explanations by comparing\nthem to social choice-based aggregation strategies. Our results indicate that\nLLM-generated recommendations often resembled those produced by Additive\nUtilitarian (ADD) aggregation. However, the explanations typically referred to\naveraging ratings (resembling but not identical to ADD aggregation). Group\nstructure, uniform or divergent, did not impact the recommendations.\nFurthermore, LLMs regularly claimed additional criteria such as user or item\nsimilarity, diversity, or used undefined popularity metrics or thresholds. Our\nfindings have important implications for LLMs in the GRS pipeline as well as\nstandard aggregation strategies. Additional criteria in explanations were\ndependent on the number of ratings in the group scenario, indicating potential\ninefficiency of standard aggregation methods at larger item set sizes.\nAdditionally, inconsistent and ambiguous explanations undermine transparency\nand explainability, which are key motivations behind the use of LLMs for GRS.",
        "url": "http://arxiv.org/abs/2507.13705v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13705v1",
        "arxiv_id": "2507.13705v1",
        "authors": [
            "Cedric Waterschoot",
            "Nava Tintarev",
            "Francesco Barile"
        ],
        "submitted": "2025-07-18 07:20:52",
        "source": "arxiv",
        "comment": "Short paper accepted at the Nineteenth ACM Conference on Recommender\n  Systems (RecSys '25). Cedric Waterschoot, Nava Tintarev, and Francesco\n  Barile. 2025. Consistent Explainers or Unreliable Narrators? Understanding\n  LLM-generated Group Recommendations. Proceedings of the Nineteenth ACM\n  Conference on Recommender Systems (RecSys '25), Prague, Czech Republic. doi:\n  10.1145/3705328.3748015",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the use of Large Language Models (LLMs) in Group Recommender Systems (GRS), which is related to search technologies and query understanding. However, the focus on LLM-generated group recommendations and explanations is not directly aligned with my primary research interests in information retrieval, ranking models, and user behavior modeling. While the paper touches on some relevant topics, such as aggregation strategies and explanation generation, it does not deeply engage with the core themes of my research."
    },
    {
        "title": "LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues",
        "abstract": "Multi-turn dialogues are essential in many real-world applications of large\nlanguage models, such as chatbots and virtual assistants. As conversation\nhistories become longer, existing large language models face increasing\ncomputational and memory challenges, which hinder their ability to provide\nefficient and responsive interactions. Most current acceleration methods either\ncompress the context or optimize key value caching, but they often rely on\nfixed or position-based heuristics that do not adapt well to the dynamic and\nunpredictable patterns found in actual multi-turn conversations. In this paper,\nwe present LoopServe, an adaptive dual-phase inference acceleration framework\nfor large language models in multi-turn dialogues. LoopServe introduces two\nmain innovations. First, it performs online sparsification during the\nprefilling phase by dynamically selecting the most important parts of the\nattention matrix for each new input. Second, it uses progressive key value\ncompression during decoding by adaptively maintaining a relevant and efficient\ncache based on the most recently generated output tokens. We also propose a\n\\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new\nbenchmark} with eleven multi-turn datasets that reflect realistic query\npositions and conversational dependencies. Extensive experiments demonstrate\nthat LoopServe consistently achieves superior effectiveness compared to\nexisting baselines and significantly accelerates LLM inference across a wide\nrange of long-context dialogue tasks.",
        "url": "http://arxiv.org/abs/2507.13681v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13681v1",
        "arxiv_id": "2507.13681v1",
        "authors": [
            "Haoyang Li",
            "Zhanchao Xu",
            "Yiming Li",
            "Xuejia Chen",
            "Darian Li",
            "Anxin Tian",
            "Qingfa Xiao",
            "Cheng Deng",
            "Jun Wang",
            "Qing Li",
            "Lei Chen",
            "Mingxuan Yuan"
        ],
        "submitted": "2025-07-18 06:12:08",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'query' (score: +3)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on large language models and multi-turn dialogues, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions query positions, the context is different from the user's focus on query understanding and ranking models."
    },
    {
        "title": "IP2: Entity-Guided Interest Probing for Personalized News Recommendation",
        "abstract": "News recommender systems aim to provide personalized news reading experiences\nfor users based on their reading history. Behavioral science studies suggest\nthat screen-based news reading contains three successive steps: scanning, title\nreading, and then clicking. Adhering to these steps, we find that intra-news\nentity interest dominates the scanning stage, while the inter-news entity\ninterest guides title reading and influences click decisions. Unfortunately,\ncurrent methods overlook the unique utility of entities in news recommendation.\nTo this end, we propose a novel method called IP2 to probe entity-guided\nreading interest at both intra- and inter-news levels. At the intra-news level,\na Transformer-based entity encoder is devised to aggregate mentioned entities\nin the news title into one signature entity. Then, a signature entity-title\ncontrastive pre-training is adopted to initialize entities with proper meanings\nusing the news story context, which in the meantime facilitates us to probe for\nintra-news entity interest. As for the inter-news level, a dual tower user\nencoder is presented to capture inter-news reading interest from both the title\nmeaning and entity sides. In addition to highlighting the contribution of\ninter-news entity guidance, a cross-tower attention link is adopted to\ncalibrate title reading interest using inter-news entity interest, thus further\naligning with real-world behavior. Extensive experiments on two real-world\ndatasets demonstrate that our IP2 achieves state-of-the-art performance in news\nrecommendation.",
        "url": "http://arxiv.org/abs/2507.13622v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13622v1",
        "arxiv_id": "2507.13622v1",
        "authors": [
            "Youlin Wu",
            "Yuanyuan Sun",
            "Xiaokun Zhang",
            "Haoxi Zhan",
            "Bo Xu",
            "Liang Yang",
            "Hongfei Lin"
        ],
        "submitted": "2025-07-18 03:35:58",
        "source": "arxiv",
        "comment": "Accepted in RecSys 2025",
        "score": 3,
        "keyword_reasons": [
            "Found 'click' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on news recommendation, which is a specific application of information retrieval. While it involves entity-guided interest probing, the approach is not directly related to query understanding, ranking models, or user behavior modeling, which are core areas of interest in my research. The paper's emphasis on news recommendation and entity-based methods makes it somewhat relevant, but not a central match for my research themes."
    },
    {
        "title": "Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based Personalized Recommendation",
        "abstract": "Large language models (LLMs) can perform recommendation tasks by taking\nprompts written in natural language as input. Compared to traditional methods\nsuch as collaborative filtering, LLM-based recommendation offers advantages in\nhandling cold-start, cross-domain, and zero-shot scenarios, as well as\nsupporting flexible input formats and generating explanations of user behavior.\nIn this paper, we focus on a single-user setting, where no information from\nother users is used. This setting is practical for privacy-sensitive or\ndata-limited applications. In such cases, prompt engineering becomes especially\nimportant for controlling the output generated by the LLM. We conduct a\nlarge-scale comparison of 23 prompt types across 8 public datasets and 12 LLMs.\nWe use statistical tests and linear mixed-effects models to evaluate both\naccuracy and inference cost. Our results show that for cost-efficient LLMs,\nthree types of prompts are especially effective: those that rephrase\ninstructions, consider background knowledge, and make the reasoning process\neasier to follow. For high-performance LLMs, simple prompts often outperform\nmore complex ones while reducing cost. In contrast, commonly used prompting\nstyles in natural language processing, such as step-by-step reasoning, or the\nuse of reasoning models often lead to lower accuracy. Based on these findings,\nwe provide practical suggestions for selecting prompts and LLMs depending on\nthe required balance between accuracy and cost.",
        "url": "http://arxiv.org/abs/2507.13525v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13525v1",
        "arxiv_id": "2507.13525v1",
        "authors": [
            "Genki Kusano",
            "Kosuke Akimoto",
            "Kunihiro Takeoka"
        ],
        "submitted": "2025-07-17 20:26:00",
        "source": "arxiv",
        "comment": "Accepted to ACM RecSys2025 reproducibility",
        "score": 3,
        "keyword_reasons": [
            "Found 'user behavior' (score: +2)",
            "Found 'recommend' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on prompt engineering for LLM-based personalized recommendation, which is related to information retrieval and search technologies. However, the primary focus is on recommendation systems rather than information retrieval, and the paper does not explicitly address query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user."
    },
    {
        "title": "Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog",
        "abstract": "As AI systems take on collaborative roles, they must reason about shared\ngoals and beliefs-not just generate fluent language. The Rational Speech Act\n(RSA) framework offers a principled approach to pragmatic reasoning, but\nexisting extensions face challenges in scaling to multi-turn, collaborative\nscenarios. In this paper, we introduce Collaborative Rational Speech Act\n(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn\ndialog by optimizing a gain function adapted from rate-distortion theory. This\ngain is an extension of the gain model that is maximized in the original RSA\nmodel but takes into account the scenario in which both agents in a\nconversation have private information and produce utterances conditioned on the\ndialog. We demonstrate the effectiveness of CRSA on referential games and\ntemplate-based doctor-patient dialogs in the medical domain. Empirical results\nshow that CRSA yields more consistent, interpretable, and collaborative\nbehavior than existing baselines-paving the way for more pragmatic and socially\naware language agents.",
        "url": "http://arxiv.org/abs/2507.14063v1",
        "pdf_url": "http://arxiv.org/pdf/2507.14063v1",
        "arxiv_id": "2507.14063v1",
        "authors": [
            "Lautaro Estienne",
            "Gabriel Ben Zenou",
            "Nona Naderi",
            "Jackie Cheung",
            "Pablo Piantanida"
        ],
        "submitted": "2025-07-18 16:42:22",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores a novel approach to pragmatic reasoning in multi-turn dialog, which is related to query understanding and user behavior modeling in information retrieval. However, the focus on dialog systems and language generation is not directly aligned with the user's primary interest in information retrieval and search technologies."
    },
    {
        "title": "Efficient Temporal Tokenization for Mobility Prediction with Large Language Models",
        "abstract": "We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for\nHuman Mobility), a framework that leverages large language models (LLMs) as\nspatio-temporal predictors and trajectory reasoners. RHYTHM partitions\ntrajectories into daily segments encoded as discrete tokens with hierarchical\nattention, capturing both daily and weekly dependencies while substantially\nreducing the sequence length. Token representations are enriched with\npre-computed prompt embeddings via a frozen LLM, enhancing the model's ability\nto capture interdependencies without extensive computational overhead. By\nfreezing the LLM backbone, RHYTHM achieves significant computational\nefficiency. Evaluation on three real-world datasets demonstrates a 2.4%\nimprovement in accuracy, 5.0% increase on weekends, and 24.6% reduction in\ntraining time compared to state-of-the-art methods.",
        "url": "http://arxiv.org/abs/2507.14017v1",
        "pdf_url": "http://arxiv.org/pdf/2507.14017v1",
        "arxiv_id": "2507.14017v1",
        "authors": [
            "Haoyu He",
            "Haozheng Luo",
            "Yan Chen",
            "Qi R. Wang"
        ],
        "submitted": "2025-07-18 15:31:16",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on mobility prediction using large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it leverages language models, the application is in a different domain and does not involve ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest for your research."
    },
    {
        "title": "Preprint: Did I Just Browse A Website Written by LLMs?",
        "abstract": "Increasingly, web content is automatically generated by large language models\n(LLMs) with little human input. We call this \"LLM-dominant\" content. Since LLMs\nplagiarize and hallucinate, LLM-dominant content can be unreliable and\nunethical. Yet, websites rarely disclose such content, and human readers\nstruggle to distinguish it. Thus, we must develop reliable detectors for\nLLM-dominant content. However, state-of-the-art LLM detectors are insufficient,\nbecause they perform well mainly on clean, prose-like text, while web content\nhas complex markup and diverse genres.\n  We propose a highly reliable, scalable pipeline that classifies entire\nwebsites. Instead of naively classifying text extracted from each page, we\nclassify each site based on an LLM text detector's outputs of multiple\nprose-like pages. We train and evaluate our detector by collecting 2 distinct\nground truth datasets totaling 120 sites, and obtain 100% accuracies testing\nacross them. In the wild, we detect a sizable portion of sites as LLM-dominant\namong 10k sites in search engine results and 10k in Common Crawl archives. We\nfind LLM-dominant sites are growing in prevalence and rank highly in search\nresults, raising questions about their impact on end users and the overall Web\necosystem.",
        "url": "http://arxiv.org/abs/2507.13933v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13933v1",
        "arxiv_id": "2507.13933v1",
        "authors": [
            "Sichang \"Steven\" He",
            "Ramesh Govindan",
            "Harsha V. Madhyastha"
        ],
        "submitted": "2025-07-18 14:09:04",
        "source": "arxiv",
        "comment": "In submission. 2 pages. 3 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper's focus on detecting automatically generated web content using large language models (LLMs) is somewhat related to information retrieval and search technologies. However, the specific problem domain and methodology are not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies",
        "abstract": "Code-switching (CS), the alternating use of two or more languages, challenges\nautomatic speech recognition (ASR) due to scarce training data and linguistic\nsimilarities. The lack of dedicated CS datasets limits ASR performance, as most\nmodels rely on monolingual or mixed-language corpora that fail to reflect\nreal-world CS patterns. This issue is critical in multilingual societies where\nCS occurs in informal and formal settings. A key example is Catalan-Spanish CS,\nwidely used in media and parliamentary speeches. In this work, we improve ASR\nfor Catalan-Spanish CS by exploring three strategies: (1) generating synthetic\nCS data, (2) concatenating monolingual audio, and (3) leveraging real CS data\nwith language tokens. We extract CS data from Catalan speech corpora and\nfine-tune OpenAI's Whisper models, making them available on Hugging Face.\nResults show that combining a modest amount of synthetic CS data with the\ndominant language token yields the best transcription performance.",
        "url": "http://arxiv.org/abs/2507.13875v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13875v1",
        "arxiv_id": "2507.13875v1",
        "authors": [
            "Carlos Mena",
            "Pol Serra",
            "Jacobo Romero",
            "Abir Messaoudi",
            "Jose Giraldo",
            "Carme Armentano-Oller",
            "Rodolfo Zevallos",
            "Ivan Meza",
            "Javier Hernando"
        ],
        "submitted": "2025-07-18 12:54:41",
        "source": "arxiv",
        "comment": "Accepted at Interspeech 2025",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on optimizing Automatic Speech Recognition (ASR) for code-switching in Catalan-Spanish, which is not directly related to Information Retrieval, Search technologies, or query understanding. The paper's emphasis on ASR and language processing is more relevant to Natural Language Processing (NLP) and speech recognition, but it does not align with the user's primary focus on IR, ranking models, and user behavior modeling."
    },
    {
        "title": "KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs",
        "abstract": "Large language models (LLMs) have demonstrated state-of-the-art performance\nacross a wide range of natural language processing tasks. However,\nhigh-performing models are typically accessible only via APIs, incurring\nsubstantial inference costs. Cascade methods address this by initially\nemploying a cheaper model and escalating to a stronger one only when necessary.\nNevertheless, existing cascade approaches struggle to select a reliable\nrepresentative response and assess the overall reliability of free-form\noutputs, as they rely on exact text matching. To overcome these limitations, we\npropose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient\nfree-form text generation. KiC identifies the most representative answer among\nmultiple outputs from a weaker model and evaluates the semantic alignment of\nother responses with it. Based on the degree of alignment, KiC determines\nwhether to accept the weaker model's output or escalate to a stronger model.\nExperiments on three free-form text generation benchmarks show that KiC\nachieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81\npercent on average, and even outperforms GPT-4 in a specific benchmark.",
        "url": "http://arxiv.org/abs/2507.13666v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13666v1",
        "arxiv_id": "2507.13666v1",
        "authors": [
            "Woo-Chan Kim",
            "Ji-Hoon Park",
            "Seong-Whan Lee"
        ],
        "submitted": "2025-07-18 05:34:36",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper proposes a novel framework for cost-efficient free-form text generation, using a cascade approach with keyword-inspired selection. While it touches on natural language processing and language models, the focus is on text generation rather than information retrieval or search technologies. The relevance to the user's interests is limited, as it does not directly address query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer",
        "abstract": "Integrating large language models into specialized domains like healthcare\npresents unique challenges, including domain adaptation and limited labeled\ndata. We introduce CU-ICU, a method for customizing unsupervised\ninstruction-finetuned language models for ICU datasets by leveraging the\nText-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse\nfine-tuning approach that combines few-shot prompting with selective parameter\nupdates, enabling efficient adaptation with minimal supervision. Our evaluation\nacross critical ICU tasks--early sepsis detection, mortality prediction, and\nclinical note generation--demonstrates that CU-ICU consistently improves\npredictive accuracy and interpretability over standard fine-tuning methods.\nNotably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and\na 20% enhancement in generating clinically relevant explanations while updating\nfewer than 1% of model parameters in its most efficient configuration. These\nresults establish CU-ICU as a scalable, low-overhead solution for delivering\naccurate and interpretable clinical decision support in real-world ICU\nenvironments.",
        "url": "http://arxiv.org/abs/2507.13655v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13655v1",
        "arxiv_id": "2507.13655v1",
        "authors": [
            "Teerapong Panboonyuen"
        ],
        "submitted": "2025-07-18 04:49:41",
        "source": "arxiv",
        "comment": "12 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on customizing language models for healthcare datasets, specifically ICU datasets, using the Text-to-Text Transfer Transformer architecture. While it involves fine-tuning language models, which is related to query understanding and ranking models, the paper's primary focus is on domain adaptation and clinical decision support, which is not directly aligned with the user's research interests in Information Retrieval and Search technologies."
    },
    {
        "title": "CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks",
        "abstract": "Despite recent progress in video large language models (VideoLLMs), a key\nopen challenge remains: how to equip models with chain-of-thought (CoT)\nreasoning abilities grounded in fine-grained object-level video understanding.\nExisting instruction-tuned models, such as the Qwen and LLaVA series, are\ntrained on high-level video-text pairs, often lacking structured annotations\nnecessary for compositional, step-by-step reasoning. We propose CoTasks:\nChain-of-Thought based Video Instruction Tuning Tasks, a new framework that\ndecomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)\ninto four entity-level foundational tasks: frame localization, entity tracking,\nspatial and temporal relation extraction. By embedding these intermediate\nCoT-style reasoning steps into the input, CoTasks enables models to explicitly\nperform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA\nbenchmark show that CoTasks significantly enhance inference performance:\nLLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and\nQwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal\n(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the\neffectiveness of CoTasks as a structured CoT-style supervision framework for\nimproving compositional video reasoning.",
        "url": "http://arxiv.org/abs/2507.13609v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13609v1",
        "arxiv_id": "2507.13609v1",
        "authors": [
            "Yanan Wang",
            "Julio Vizcarra",
            "Zhi Li",
            "Hao Niu",
            "Mori Kurokawa"
        ],
        "submitted": "2025-07-18 02:29:19",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on video instruction tuning tasks, chain-of-thought reasoning, and video understanding, which are not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on video understanding and object-level video analysis is not aligned with the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Off-Policy Evaluation and Learning for Matching Markets",
        "abstract": "Matching users based on mutual preferences is a fundamental aspect of\nservices driven by reciprocal recommendations, such as job search and dating\napplications. Although A/B tests remain the gold standard for evaluating new\npolicies in recommender systems for matching markets, it is costly and\nimpractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays\na crucial role by enabling the evaluation of recommendation policies using only\noffline logged data naturally collected on the platform. However, unlike\nconventional recommendation settings, the large scale and bidirectional nature\nof user interactions in matching platforms introduce variance issues and\nexacerbate reward sparsity, making standard OPE methods unreliable. To address\nthese challenges and facilitate effective offline evaluation, we propose novel\nOPE estimators, \\textit{DiPS} and \\textit{DPR}, specifically designed for\nmatching markets. Our methods combine elements of the Direct Method (DM),\nInverse Propensity Score (IPS), and Doubly Robust (DR) estimators while\nincorporating intermediate labels, such as initial engagement signals, to\nachieve better bias-variance control in matching markets. Theoretically, we\nderive the bias and variance of the proposed estimators and demonstrate their\nadvantages over conventional methods. Furthermore, we show that these\nestimators can be seamlessly extended to offline policy learning methods for\nimproving recommendation policies for making more matches. We empirically\nevaluate our methods through experiments on both synthetic data and A/B testing\nlogs from a real job-matching platform. The empirical results highlight the\nsuperiority of our approach over existing methods in off-policy evaluation and\nlearning tasks for a variety of configurations.",
        "url": "http://arxiv.org/abs/2507.13608v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13608v1",
        "arxiv_id": "2507.13608v1",
        "authors": [
            "Yudai Hayashi",
            "Shuhei Goda",
            "Yuta Saito"
        ],
        "submitted": "2025-07-18 02:23:37",
        "source": "arxiv",
        "comment": "RecSys'25",
        "score": 2,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on off-policy evaluation and learning for matching markets, which is a specific application of recommender systems. While it touches on some relevant topics like user behavior modeling and ranking models, the primary focus is on a different domain (matching markets) and does not directly address query understanding, ranking models, or user behavior modeling in the context of information retrieval."
    },
    {
        "title": "Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder",
        "abstract": "Formal thought disorder (FTD), a hallmark of schizophrenia spectrum\ndisorders, manifests as incoherent speech and poses challenges for clinical\nassessment. Traditional clinical rating scales, though validated, are\nresource-intensive and lack scalability. Automated speech analysis with\nautomatic speech recognition (ASR) allows for objective quantification of\nlinguistic and temporal features of speech, offering scalable alternatives. The\nuse of utterance timestamps in ASR captures pause dynamics, which are thought\nto reflect the cognitive processes underlying speech production. However, the\nutility of integrating these ASR-derived features for assessing FTD severity\nrequires further evaluation. This study integrates pause features with semantic\ncoherence metrics across three datasets: naturalistic self-recorded diaries\n(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream\nnarratives (PsyCL, n = 43). We evaluated pause related features alongside\nestablished coherence measures, using support vector regression (SVR) to\npredict clinical FTD scores. Key findings demonstrate that pause features alone\nrobustly predict the severity of FTD. Integrating pause features with semantic\ncoherence metrics enhanced predictive performance compared to semantic-only\nmodels, with integration of independent models achieving correlations up to\n\\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best\n\\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance\ngains from semantic and pause features integration held consistently across all\ncontexts, though the nature of pause patterns was dataset-dependent. These\nfindings suggest that frameworks combining temporal and semantic analyses\nprovide a roadmap for refining the assessment of disorganized speech and\nadvance automated speech analysis in psychosis.",
        "url": "http://arxiv.org/abs/2507.13551v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13551v1",
        "arxiv_id": "2507.13551v1",
        "authors": [
            "Feng Chen",
            "Weizhe Xu",
            "Changye Li",
            "Serguei Pakhomov",
            "Alex Cohen",
            "Simran Bhola",
            "Sandy Yin",
            "Sunny X Tang",
            "Michael Mackinley",
            "Lena Palaniyappan",
            "Dror Ben-Zeev",
            "Trevor Cohen"
        ],
        "submitted": "2025-07-17 22:00:16",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper is not relevant to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on speech analysis and assessment of thought disorder in schizophrenia spectrum disorders, which is outside the user's area of expertise."
    },
    {
        "title": "A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows",
        "abstract": "The analysis of conversational dynamics has gained increasing importance with\nthe rise of large language model-based systems, which interact with users\nacross diverse contexts. In this work, we propose a novel computational\nframework for constructing conversational graphs that capture the flow and\nstructure of loosely organized dialogues, referred to as quasi-patterned\nconversations. We introduce the Filter & Reconnect method, a novel graph\nsimplification technique that minimizes noise while preserving semantic\ncoherence and structural integrity of conversational graphs. Through\ncomparative analysis, we demonstrate that the use of large language models\ncombined with our graph simplification technique has resulted in semantic\nmetric S increasing by a factor of 2.06 compared to previous approaches while\nsimultaneously enforcing a tree-like structure with 0 {\\delta}-hyperbolicity,\nensuring optimal clarity in conversation modeling. This work provides a\ncomputational method for analyzing large-scale dialogue datasets, with\npractical applications related to monitoring automated systems such as\nchatbots, dialogue management tools, and user behavior analytics.",
        "url": "http://arxiv.org/abs/2507.13544v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13544v1",
        "arxiv_id": "2507.13544v1",
        "authors": [
            "Mohamed Achref Ben Ammar",
            "Mohamed Taha Bennani"
        ],
        "submitted": "2025-07-17 21:34:13",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'user behavior' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on conversational systems and dialogue analysis, which is not directly related to the user's primary research interests in Information Retrieval and Search technologies. While the paper mentions large language models, it does not specifically address query understanding, ranking models, or user behavior modeling. The connection to the user's background in e-commerce is also tenuous."
    },
    {
        "title": "NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining",
        "abstract": "Recent advances in generative modeling enable image editing assistants that\nfollow natural language instructions without additional user input. Their\nsupervised training requires millions of triplets: original image, instruction,\nedited image. Yet mining pixel-accurate examples is hard. Each edit must affect\nonly prompt-specified regions, preserve stylistic coherence, respect physical\nplausibility, and retain visual appeal. The lack of robust automated\nedit-quality metrics hinders reliable automation at scale. We present an\nautomated, modular pipeline that mines high-fidelity triplets across domains,\nresolutions, instruction complexities, and styles. Built on public generative\nmodels and running without human intervention, our system uses a task-tuned\nGemini validator to score instruction adherence and aesthetics directly,\nremoving any need for segmentation or grounding models. Inversion and\ncompositional bootstrapping enlarge the mined set by approximately 2.2x,\nenabling large-scale high-fidelity training data. By automating the most\nrepetitive annotation steps, the approach allows a new scale of training\nwithout human labeling effort. To democratize research in this\nresource-intensive area, we release NHR-Edit: an open dataset of 358k\nhigh-quality triplets. In the largest cross-dataset evaluation, it surpasses\nall public alternatives. We also release Bagel-NHR-Edit, an open-source\nfine-tuned Bagel model, which achieves state-of-the-art metrics in our\nexperiments.",
        "url": "http://arxiv.org/abs/2507.14119v1",
        "pdf_url": "http://arxiv.org/pdf/2507.14119v1",
        "arxiv_id": "2507.14119v1",
        "authors": [
            "Maksim Kuprashevich",
            "Grigorii Alekseenko",
            "Irina Tolstykh",
            "Georgii Fedorov",
            "Bulat Suleimanov",
            "Vladimir Dokholyan",
            "Aleksandr Gordeev"
        ],
        "submitted": "2025-07-18 17:50:00",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on image editing and triplet mining, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language instructions, the context is image editing rather than search or retrieval. The paper's emphasis on generative models and automated validation is also not aligned with the user's interests in ranking models and user behavior modeling."
    },
    {
        "title": "The Levers of Political Persuasion with Conversational AI",
        "abstract": "There are widespread fears that conversational AI could soon exert\nunprecedented influence over human beliefs. Here, in three large-scale\nexperiments (N=76,977), we deployed 19 LLMs-including some post-trained\nexplicitly for persuasion-to evaluate their persuasiveness on 707 political\nissues. We then checked the factual accuracy of 466,769 resulting LLM claims.\nContrary to popular concerns, we show that the persuasive power of current and\nnear-future AI is likely to stem more from post-training and prompting\nmethods-which boosted persuasiveness by as much as 51% and 27%\nrespectively-than from personalization or increasing model scale. We further\nshow that these methods increased persuasion by exploiting LLMs' unique ability\nto rapidly access and strategically deploy information and that, strikingly,\nwhere they increased AI persuasiveness they also systematically decreased\nfactual accuracy.",
        "url": "http://arxiv.org/abs/2507.13919v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13919v1",
        "arxiv_id": "2507.13919v1",
        "authors": [
            "Kobi Hackenburg",
            "Ben M. Tappin",
            "Luke Hewitt",
            "Ed Saunders",
            "Sid Black",
            "Hause Lin",
            "Catherine Fist",
            "Helen Margetts",
            "David G. Rand",
            "Christopher Summerfield"
        ],
        "submitted": "2025-07-18 13:50:09",
        "source": "arxiv",
        "comment": "19 pages, 4 figures. Our supplementary materials file can be found at\n  https://github.com/kobihackenburg/scaling-conversational-AI",
        "score": 1,
        "keyword_reasons": [
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on conversational AI and persuasion in a political context is outside the scope of your expertise and interests."
    },
    {
        "title": "InTraVisTo: Inside Transformer Visualisation Tool",
        "abstract": "The reasoning capabilities of Large Language Models (LLMs) have increased\ngreatly over the last few years, as have their size and complexity.\nNonetheless, the use of LLMs in production remains challenging due to their\nunpredictable nature and discrepancies that can exist between their desired\nbehavior and their actual model output. In this paper, we introduce a new tool,\nInTraVisTo (Inside Transformer Visualisation Tool), designed to enable\nresearchers to investigate and trace the computational process that generates\neach token in a Transformer-based LLM. InTraVisTo provides a visualization of\nboth the internal state of the Transformer model (by decoding token embeddings\nat each layer of the model) and the information flow between the various\ncomponents across the different layers of the model (using a Sankey diagram).\nWith InTraVisTo, we aim to help researchers and practitioners better understand\nthe computations being performed within the Transformer model and thus to shed\nsome light on internal patterns and reasoning processes employed by LLMs.",
        "url": "http://arxiv.org/abs/2507.13858v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13858v1",
        "arxiv_id": "2507.13858v1",
        "authors": [
            "Nicolò Brunello",
            "Davide Rigamonti",
            "Andrea Sassella",
            "Vincenzo Scotti",
            "Mark James Carman"
        ],
        "submitted": "2025-07-18 12:23:47",
        "source": "arxiv",
        "comment": "8 pages",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on visualizing the internal workings of Large Language Models, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it may have some tangential relevance to NLP, the paper's scope and methodology are not aligned with the user's primary research interests."
    },
    {
        "title": "Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions",
        "abstract": "In visual question answering (VQA) context, users often pose ambiguous\nquestions to visual language models (VLMs) due to varying expression habits.\nExisting research addresses such ambiguities primarily by rephrasing questions.\nThese approaches neglect the inherently interactive nature of user interactions\nwith VLMs, where ambiguities can be clarified through user feedback. However,\nresearch on interactive clarification faces two major challenges: (1)\nBenchmarks are absent to assess VLMs' capacity for resolving ambiguities\nthrough interaction; (2) VLMs are trained to prefer answering rather than\nasking, preventing them from seeking clarification. To overcome these\nchallenges, we introduce \\textbf{ClearVQA} benchmark, which targets three\ncommon categories of ambiguity in VQA context, and encompasses various VQA\nscenarios.",
        "url": "http://arxiv.org/abs/2507.13773v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13773v1",
        "arxiv_id": "2507.13773v1",
        "authors": [
            "Pu Jian",
            "Donglei Yu",
            "Wen Yang",
            "Shuo Ren",
            "Jiajun Zhang"
        ],
        "submitted": "2025-07-18 09:31:43",
        "source": "arxiv",
        "comment": "ACL2025 Main",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on visual question answering, which is not directly related to my primary research interests in Information Retrieval and Search technologies. While it touches on query understanding and ambiguity resolution, the context is specific to visual language models and does not address ranking models or user behavior modeling, which are key areas of interest for me."
    },
    {
        "title": "PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs",
        "abstract": "Large Language Models (LLMs) frequently reproduce the gender- and\nsexual-identity prejudices embedded in their training corpora, leading to\noutputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of\ngreat importance. To achieve this, we evaluate two parameter-efficient\nfine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt\ntuning - as lightweight alternatives to full-model fine-tuning for mitigating\nsuch biases. Using the WinoQueer benchmark, we quantify bias in three\nopen-source LLMs and observe baseline bias scores reaching up to 98 (out of\n100) across a range of queer identities defined by gender and/or sexual\norientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%\nadditional parameters) on a curated QueerNews corpus reduces those scores by up\nto 50 points and raises neutrality from virtually 0% to as much as 36%.\nSoft-prompt tuning (10 virtual tokens) delivers only marginal improvements.\nThese findings show that LoRA can deliver meaningful fairness gains with\nminimal computation. We advocate broader adoption of community-informed PEFT,\nthe creation of larger queer-authored corpora, and richer evaluation suites\nbeyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.",
        "url": "http://arxiv.org/abs/2507.13743v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13743v1",
        "arxiv_id": "2507.13743v1",
        "authors": [
            "Maluna Menke",
            "Thilo Hagendorff"
        ],
        "submitted": "2025-07-18 08:44:27",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on reducing biases in Large Language Models (LLMs) and fine-tuning techniques, which is not directly related to Information Retrieval (IR) or Search technologies. Although it mentions 'evaluation' and 'benchmarks', the context is not relevant to the user's interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters",
        "abstract": "Multilingual translation stands as a challenging task for large language\nmodels (LLMs) to handle intricate language patterns and stilted translations\nthat arise in automated translations. In this paper, we introduce Seed-X, a\nfamily of open-source LLMs comprising instruct and reasoning models, pushing\nthe limits of translation capability with 7B parameter size. The base model is\npre-trained on a diverse, high-quality dataset encompassing both monolingual\nand bilingual content across 28 languages, harnessing the full potential of\nmultilingual data. The instruct model is then finetuned to translate by\nChain-of-Thought (CoT) reasoning and further enhanced through reinforcement\nlearning (RL) to achieve better generalization across diverse language pairs.\nSeed-X achieves performance comparable to leading closed-source models,\nincluding Gemini-2.5 and GPT-4o, across 28 languages, and significantly\noutperforms larger open-source models in both automatic metrics and human\nevaluations. We share the best practices through our optimization process, and\nmake the parameter public available for advancing translation research and\napplications.",
        "url": "http://arxiv.org/abs/2507.13618v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13618v1",
        "arxiv_id": "2507.13618v1",
        "authors": [
            "Shanbo Cheng",
            "Yu Bao",
            "Qian Cao",
            "Luyang Huang",
            "Liyan Kang",
            "Zhicheng Liu",
            "Yu Lu",
            "Wenhao Zhu",
            "Zhichao Huang",
            "Tao Li",
            "Sitong Liu",
            "Ningxin Peng",
            "Shuaijie She",
            "Lu Xu",
            "Nuo Xu",
            "Sen Yang",
            "Runsheng Yu",
            "Yiming Yu",
            "Liehao Zou",
            "Hang Li",
            "Lu Lu",
            "Yuxuan Wang",
            "Yonghui Wu"
        ],
        "submitted": "2025-07-18 03:19:43",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on building a multilingual translation model, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions large language models, it does not explore query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user."
    },
    {
        "title": "Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models",
        "abstract": "The rapid advancements in large language models (LLMs) have significantly\nimproved their ability to generate natural language, making texts generated by\nLLMs increasingly indistinguishable from human-written texts. While recent\nresearch has primarily focused on using LLMs to classify text as either\nhuman-written and machine-generated texts, our study focus on characterizing\nthese texts using a set of linguistic features across different linguistic\nlevels such as morphology, syntax, and semantics. We select a dataset of\nhuman-written and machine-generated texts spanning 8 domains and produced by 11\ndifferent LLMs. We calculate different linguistic features such as dependency\nlength and emotionality and we use them for characterizing human-written and\nmachine-generated texts along with different sampling strategies, repetition\ncontrols and model release date. Our statistical analysis reveals that\nhuman-written texts tend to exhibit simpler syntactic structures and more\ndiverse semantic content. Furthermore, we calculate the variability of our set\nof features across models and domains. Both human and machine texts show\nstylistic diversity across domains, with humans displaying greater variation in\nour features. Finally, we apply style embeddings to further test variability\namong human-written and machine-generated texts. Notably, newer models output\ntext that is similarly variable, pointing to an homogenization of\nmachine-generated texts.",
        "url": "http://arxiv.org/abs/2507.13614v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13614v1",
        "arxiv_id": "2507.13614v1",
        "authors": [
            "Sergio E. Zanotto",
            "Segun Aroyehun"
        ],
        "submitted": "2025-07-18 02:46:55",
        "source": "arxiv",
        "comment": "arXiv admin note: text overlap with arXiv:2412.03025",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper explores the linguistic characteristics of texts generated by humans and large language models, which is related to query understanding and ranking models in Information Retrieval. However, the focus on linguistic features and text classification is not directly aligned with my primary research interests in real-time relevance optimization and deep semantic understanding."
    },
    {
        "title": "Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?",
        "abstract": "There has been extensive research on assessing the value orientation of Large\nLanguage Models (LLMs) as it can shape user experiences across demographic\ngroups. However, several challenges remain. First, while the Multiple Choice\nQuestion (MCQ) setting has been shown to be vulnerable to perturbations, there\nis no systematic comparison of probing methods for value probing. Second, it is\nunclear to what extent the probed values capture in-context information and\nreflect models' preferences for real-world actions. In this paper, we evaluate\nthe robustness and expressiveness of value representations across three widely\nused probing strategies. We use variations in prompts and options, showing that\nall methods exhibit large variances under input perturbations. We also\nintroduce two tasks studying whether the values are responsive to demographic\ncontext, and how well they align with the models' behaviors in value-related\nscenarios. We show that the demographic context has little effect on the\nfree-text generation, and the models' values only weakly correlate with their\npreference for value-based actions. Our work highlights the need for a more\ncareful examination of LLM value probing and awareness of its limitations.",
        "url": "http://arxiv.org/abs/2507.13490v1",
        "pdf_url": "http://arxiv.org/pdf/2507.13490v1",
        "arxiv_id": "2507.13490v1",
        "authors": [
            "Siqi Shen",
            "Mehar Singh",
            "Lajanugen Logeswaran",
            "Moontae Lee",
            "Honglak Lee",
            "Rada Mihalcea"
        ],
        "submitted": "2025-07-17 18:56:41",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "The paper focuses on Large Language Models (LLMs) and value probing strategies, which is not directly related to Information Retrieval, Search technologies, or query understanding. The topics of NLP, data mining, and recommender systems are also not addressed in this paper."
    }
]