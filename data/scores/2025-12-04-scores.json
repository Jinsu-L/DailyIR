[
    {
        "title": "Learning to Comparison-Shop",
        "abstract": "In online marketplaces like Airbnb, users frequently engage in comparison shopping before making purchase decisions. Despite the prevalence of this behavior, a significant disconnect persists between mainstream e-commerce search engines and users' comparison needs. Traditional ranking models often evaluate items in isolation, disregarding the context in which users compare multiple items on a search results page. While recent advances in deep learning have sought to improve ranking accuracy, diversity, and fairness by encoding listwise context, the challenge of aligning search rankings with user comparison shopping behavior remains inadequately addressed. In this paper, we propose a novel ranking architecture - Learning-to-Comparison-Shop (LTCS) System - that explicitly models and learns users' comparison shopping behaviors. Through extensive offline and online experiments, we demonstrate that our approach yields statistically significant gains in key business metrics - improving NDCG by 1.7% and boosting booking conversion rate by 0.6% in A/B testing - while also enhancing user experience. We also compare our model against state-of-the-art approaches and demonstrate that LTCS significantly outperforms them.",
        "url": "http://arxiv.org/abs/2512.04009v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04009v1",
        "arxiv_id": "2512.04009v1",
        "authors": [
            "Jie Tang",
            "Daochen Zha",
            "Xin Liu",
            "Huiji Gao",
            "Liwei He",
            "Stephanie Moyerman",
            "Sanjeev Katariya"
        ],
        "submitted": "2025-12-03 17:46:18",
        "source": "arxiv",
        "comment": null,
        "score": 13,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'listwise' (score: +3)",
            "Found 'conversion rate' (score: +2)",
            "Found 'shopping' (score: +1)",
            "Found 'commerce' (score: +1)",
            "Found 'e-commerce' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 9,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding and ranking models. The proposed Learning-to-Comparison-Shop (LTCS) System addresses a significant challenge in e-commerce search engines, aligning with your focus on deep semantic understanding and real-time relevance optimization. The paper's emphasis on modeling user comparison shopping behavior also resonates with your interest in user behavior modeling."
    },
    {
        "title": "BookRAG: A Hierarchical Structure-aware Index-based Approach for Retrieval-Augmented Generation on Complex Documents",
        "abstract": "As an effective method to boost the performance of Large Language Models (LLMs) on the question answering (QA) task, Retrieval-Augmented Generation (RAG), which queries highly relevant information from external complex documents, has attracted tremendous attention from both industry and academia. Existing RAG approaches often focus on general documents, and they overlook the fact that many real-world documents (such as books, booklets, handbooks, etc.) have a hierarchical structure, which organizes their content from different granularity levels, leading to poor performance for the QA task. To address these limitations, we introduce BookRAG, a novel RAG approach targeted for documents with a hierarchical structure, which exploits logical hierarchies and traces entity relations to query the highly relevant information. Specifically, we build a novel index structure, called BookIndex, by extracting a hierarchical tree from the document, which serves as the role of its table of contents, using a graph to capture the intricate relationships between entities, and mapping entities to tree nodes. Leveraging the BookIndex, we then propose an agent-based query method inspired by the Information Foraging Theory, which dynamically classifies queries and employs a tailored retrieval workflow. Extensive experiments on three widely adopted benchmarks demonstrate that BookRAG achieves state-of-the-art performance, significantly outperforming baselines in both retrieval recall and QA accuracy while maintaining competitive efficiency.",
        "url": "http://arxiv.org/abs/2512.03413v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03413v1",
        "arxiv_id": "2512.03413v1",
        "authors": [
            "Shu Wang",
            "Yingli Zhou",
            "Yixiang Fang"
        ],
        "submitted": "2025-12-03 03:40:49",
        "source": "arxiv",
        "comment": null,
        "score": 10,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper focuses on Retrieval-Augmented Generation (RAG) for question answering, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the specific application to complex documents with hierarchical structures and the use of graph-based indexing and agent-based query methods are not directly aligned with the user's core research themes."
    },
    {
        "title": "AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation",
        "abstract": "Accurate and reliable search on online healthcare platforms is critical for user safety and service efficacy. Traditional methods, however, often fail to comprehend complex and nuanced user queries, limiting their effectiveness. Large language models (LLMs) present a promising solution, offering powerful semantic understanding to bridge this gap. Despite their potential, deploying LLMs in this high-stakes domain is fraught with challenges, including factual hallucinations, specialized knowledge gaps, and high operational costs. To overcome these barriers, we introduce \\textbf{AR-Med}, a novel framework for \\textbf{A}utomated \\textbf{R}elevance assessment for \\textbf{Med}ical search that has been successfully deployed at scale on the Online Medical Delivery Platforms. AR-Med grounds LLM reasoning in verified medical knowledge through a retrieval-augmented approach, ensuring high accuracy and reliability. To enable efficient online service, we design a practical knowledge distillation scheme that compresses large teacher models into compact yet powerful student models. We also introduce LocalQSMed, a multi-expert annotated benchmark developed to guide model iteration and ensure strong alignment between offline and online performance. Extensive experiments show AR-Med achieves an offline accuracy of over 93\\%, a 24\\% absolute improvement over the original online system, and delivers significant gains in online relevance and user satisfaction. Our work presents a practical and scalable blueprint for developing trustworthy, LLM-powered systems in real-world healthcare applications.",
        "url": "http://arxiv.org/abs/2512.03737v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03737v1",
        "arxiv_id": "2512.03737v1",
        "authors": [
            "Chuyue Wang",
            "Jie Feng",
            "Yuxi Wu",
            "Hang Zhang",
            "Zhiguo Fan",
            "Bing Cheng",
            "Wei Lin"
        ],
        "submitted": "2025-12-03 12:34:47",
        "source": "arxiv",
        "comment": null,
        "score": 9,
        "keyword_reasons": [
            "Found 'queries' (score: +3)",
            "Found 'relevance' (score: +3)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 9,
        "llm_reason": "This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of query understanding, ranking models, and user behavior modeling. The focus on leveraging Large Language Models (LLMs) for semantic understanding and real-time relevance optimization aligns well with your expertise in e-commerce and NLP. The application of AR-Med in the medical domain is a specific area of interest, but the underlying concepts and techniques are broadly applicable to your research themes."
    },
    {
        "title": "M3DR: Towards Universal Multilingual Multimodal Document Retrieval",
        "abstract": "Multimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we present M3DR (Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts. M3DR leverages synthetic multilingual document data and generalizes across different vision-language architectures and model sizes, enabling robust cross-lingual and cross-modal alignment. Using contrastive training, our models learn unified representations for text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings. M3DR generalizes across both single dense vector and ColBERT-style token-level multi-vector retrieval paradigms. Our models, NetraEmbed and ColNetraEmbed achieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval.",
        "url": "http://arxiv.org/abs/2512.03514v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03514v1",
        "arxiv_id": "2512.03514v1",
        "authors": [
            "Adithya S Kolavi",
            "Vyoman Jain"
        ],
        "submitted": "2025-12-03 07:17:59",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'semantic search' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'retrieval' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 6,
        "llm_reason": "The paper M3DR: Towards Universal Multilingual Multimodal Document Retrieval is somewhat related to the user's interests in Information Retrieval, particularly in the area of multimodal document retrieval. However, the focus on multilingual and multimodal aspects, while interesting, does not directly align with the user's primary focus on query understanding, ranking models, and user behavior modeling. The paper's emphasis on deep semantic understanding and real-time relevance optimization is also relevant, but not a central match."
    },
    {
        "title": "LLM as Explainable Re-Ranker for Recommendation System",
        "abstract": "The application of large language models (LLMs) in recommendation systems has recently gained traction. Traditional recommendation systems often lack explainability and suffer from issues such as popularity bias. Previous research has also indicated that LLMs, when used as standalone predictors, fail to achieve accuracy comparable to traditional models. To address these challenges, we propose to use LLM as an explainable re-ranker, a hybrid approach that combines traditional recommendation models with LLMs to enhance both accuracy and interpretability. We constructed a dataset to train the re-ranker LLM and evaluated the alignment between the generated dataset and human expectations. Leveraging a two-stage training process, our model significantly improved NDCG, a key ranking metric. Moreover, the re-ranker outperformed a zero-shot baseline in ranking accuracy and interpretability. These results highlight the potential of integrating traditional recommendation models with LLMs to address limitations in existing systems and pave the way for more explainable and fair recommendation frameworks.",
        "url": "http://arxiv.org/abs/2512.03439v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03439v1",
        "arxiv_id": "2512.03439v1",
        "authors": [
            "Yaqi Wang",
            "Haojia Sun",
            "Shuting Zhang"
        ],
        "submitted": "2025-12-03 04:42:58",
        "source": "arxiv",
        "comment": null,
        "score": 8,
        "keyword_reasons": [
            "Found 'ranking' (score: +3)",
            "Found 'rag' (score: +2)",
            "Found 'recommend' (score: +1)",
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of large language models in recommendation systems, which is somewhat related to your interests in Information Retrieval and Search technologies. However, the focus on recommender systems and explainability is not a central match for your primary research themes, which include query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Nexus: Higher-Order Attention Mechanisms in Transformers",
        "abstract": "Transformers have achieved significant success across various domains, relying on self-attention to capture dependencies. However, the standard first-order attention mechanism is often limited by a low-rank bottleneck, struggling to capture intricate, multi-hop relationships within a single layer. In this paper, we propose the Nexus, a novel architecture designed to enhance representational power through a recursive framework. Unlike standard approaches that use static linear projections for Queries and Keys, Nexus dynamically refines these representations via nested self-attention mechanisms. Specifically, the Query and Key vectors are themselves outputs of inner attention loops, allowing tokens to aggregate global context and model high-order correlations \\textit{prior} to the final attention computation. We enforce a parameter-efficient weight-sharing strategy across recursive steps, ensuring that this enhanced expressivity incurs $\\mathcal{O}(1)$ additional parameters. We provide theoretical analysis demonstrating that our method breaks the linear bottleneck of standard attention. Empirically, Nexus outperforms standard Transformers on multiple benchmarks.",
        "url": "http://arxiv.org/abs/2512.03377v2",
        "pdf_url": "https://arxiv.org/pdf/2512.03377v2",
        "arxiv_id": "2512.03377v2",
        "authors": [
            "Hanting Chen",
            "Chong Zhu",
            "Kai Han",
            "Yuchuan Tian",
            "Yuchen Liang",
            "Tianyu Guo",
            "Xinghao Chen",
            "Dacheng Tao",
            "Yunhe Wang"
        ],
        "submitted": "2025-12-03 02:25:38",
        "source": "arxiv",
        "comment": null,
        "score": 7,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'queries' (score: +3)",
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper proposes a novel architecture, Nexus, which enhances representational power in Transformers through recursive self-attention mechanisms. While it contributes to the advancement of deep learning models, its focus is on improving the Transformer architecture rather than information retrieval or query understanding. The paper's relevance to your research interests is somewhat limited, but it may be of interest due to its connection to NLP and deep learning."
    },
    {
        "title": "A Preliminary Study on the Promises and Challenges of Native Top-$k$ Sparse Attention",
        "abstract": "Large Language Models (LLMs) are increasingly prevalent in the field of long-context modeling, however, their inference computational costs have become a critical bottleneck hindering the advancement of tasks such as agents and multimodal applications. This report conducts a preliminary investigation into the effectiveness and theoretical mechanisms of the Top-$k$ Attention mechanism during both the decoding and training phases. First, we validate the effectiveness of exact Top-$k$ Decoding through extensive experimentation. Experiments demonstrate that retaining only the pivotal Keys with the highest similarity to the Query as the context window during the decoding stage achieves performance comparable to, or even surpassing, full attention on downstream tasks such as HELMET and LongBench v2. Second, we further explore the native Top-$k$ Attention training strategy. Experiments confirm that ensuring the consistency between training and inference regarding Top-$k$ Attention operations facilitates the further unlocking of Top-$k$ Decoding's potential, thereby significantly enhancing model performance. Furthermore, considering the high computational complexity of exact Top-$k$ Attention, we investigate the impact of approximate Top-$k$ algorithm precision on downstream tasks. Our research confirms a positive correlation between downstream task performance and approximation fidelity, and we provide statistical evaluations of the Lightning Indexer's precision within the DeepSeek-V3.2-Exp model. Finally, this report provides a theoretical interpretation from the perspective of Entropy. Experimental observations indicate that models subjected to Top-$k$ Attention SFT exhibit a distinct phenomenon of entropy reduction in downstream tasks, which validates the hypothesis that low-entropy states are better adapted to Top-$k$ Decoding.",
        "url": "http://arxiv.org/abs/2512.03494v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03494v1",
        "arxiv_id": "2512.03494v1",
        "authors": [
            "Di Xiu",
            "Hongyin Tang",
            "Bolin Rong",
            "Lizhi Yan",
            "Jingang Wang",
            "Yifan Lu",
            "Xunliang Cai"
        ],
        "submitted": "2025-12-03 06:44:02",
        "source": "arxiv",
        "comment": null,
        "score": 4,
        "keyword_reasons": [
            "Found 'query' (score: +3)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the Top-$k$ Attention mechanism, which is related to ranking models and query understanding in Information Retrieval. However, the focus is on the computational efficiency of Large Language Models, which is not a central theme in your research interests. The paper's connection to entropy reduction and its theoretical interpretation from that perspective also seems somewhat tangential to your core research themes."
    },
    {
        "title": "Thinking with Programming Vision: Towards a Unified View for Thinking with Images",
        "abstract": "Multimodal large language models (MLLMs) that think with images can interactively use tools to reason about visual inputs, but current approaches often rely on a narrow set of tools with limited real-world necessity and scalability. In this work, we first reveal a critical and previously overlooked weakness: even state-of-the-art MLLMs are surprisingly brittle, showing significant performance degradation on images with simple orientation changes or natural corruptions, underscoring the need for more robust tool-based reasoning. To address this, we propose CodeVision, a flexible and scalable code-as-tool framework where the model generates code as a universal interface to invoke any image operation, moving beyond fixed tool registries. We train our model using a two-stage methodology, beginning with Supervised Fine-Tuning (SFT) on a high-quality dataset curated for complex, multi-turn tool composition and error recovery, followed by Reinforcement Learning (RL) with a novel and dense process reward function to encourage strategic and efficient tool use. To facilitate this research, we construct new SFT and RL datasets and introduce a challenging new benchmark suite designed to rigorously evaluate robustness to orientation changes and multi-tool reasoning. Experiments on Qwen2.5-VL and Qwen3-VL series show that our approach significantly improves model performance and fosters emergent capabilities such as flexible tool composition, efficient chained execution, and robust error recovery from runtime feedback. Code is available at https://github.com/ByteDance-BandAI/CodeVision.",
        "url": "http://arxiv.org/abs/2512.03746v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03746v1",
        "arxiv_id": "2512.03746v1",
        "authors": [
            "Zirun Guo",
            "Minjie Hong",
            "Feng Zhang",
            "Kai Jia",
            "Tao Jin"
        ],
        "submitted": "2025-12-03 12:44:15",
        "source": "arxiv",
        "comment": null,
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on multimodal large language models and their ability to reason about visual inputs using code-as-tool frameworks. While it touches on the idea of using tools to interact with visual inputs, it does not directly relate to information retrieval, search technologies, or query understanding, which are the core areas of your research interests."
    },
    {
        "title": "Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaraní",
        "abstract": "This study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaraní. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaraní dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaraní and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.",
        "url": "http://arxiv.org/abs/2512.03334v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03334v1",
        "arxiv_id": "2512.03334v1",
        "authors": [
            "Nemika Tyagi",
            "Nelvin Licona Guevara",
            "Olga Kellert"
        ],
        "submitted": "2025-12-03 00:56:27",
        "source": "arxiv",
        "comment": "10 pages, 4 figures",
        "score": 3,
        "keyword_reasons": [
            "Found 'rag' (score: +2)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests as it focuses on sociolinguistic analysis of code-switched discourse, using large language models for annotation, which is outside your core areas of Information Retrieval, Search technologies, and Natural Language Processing."
    },
    {
        "title": "SkillFactory: Self-Distillation For Learning Cognitive Behaviors",
        "abstract": "Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These \"silver\" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.",
        "url": "http://arxiv.org/abs/2512.04072v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04072v1",
        "arxiv_id": "2512.04072v1",
        "authors": [
            "Zayne Sprague",
            "Jack Lu",
            "Manya Wadhwa",
            "Sedrick Keh",
            "Mengye Ren",
            "Greg Durrett"
        ],
        "submitted": "2025-12-03 18:54:53",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on cognitive skills and reasoning models in NLP, but it does not directly relate to Information Retrieval, Search technologies, or query understanding, which are the core areas of your research interests."
    },
    {
        "title": "BERnaT: Basque Encoders for Representing Natural Textual Diversity",
        "abstract": "Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.",
        "url": "http://arxiv.org/abs/2512.03903v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03903v1",
        "arxiv_id": "2512.03903v1",
        "authors": [
            "Ekhi Azurmendi",
            "Joseba Fernandez de Landa",
            "Jaione Bengoetxea",
            "Maite Heredia",
            "Julen Etxaniz",
            "Mikel Zubillaga",
            "Ander Soraluze",
            "Aitor Soroa"
        ],
        "submitted": "2025-12-03 15:50:42",
        "source": "arxiv",
        "comment": "Submitted to LREC 2026",
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores language model robustness and representational biases by incorporating linguistic diversity, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on language model pre-training and evaluation is not directly aligned with the user's primary interests in search technologies and user behavior modeling."
    },
    {
        "title": "Training and Evaluation of Guideline-Based Medical Reasoning in LLMs",
        "abstract": "Machine learning for early prediction in medicine has recently shown breakthrough performance, however, the focus on improving prediction accuracy has led to a neglect of faithful explanations that are required to gain the trust of medical practitioners. The goal of this paper is to teach LLMs to follow medical consensus guidelines step-by-step in their reasoning and prediction process. Since consensus guidelines are ubiquitous in medicine, instantiations of verbalized medical inference rules to electronic health records provide data for fine-tuning LLMs to learn consensus rules and possible exceptions thereof for many medical areas. Consensus rules also enable an automatic evaluation of the model's inference process regarding its derivation correctness (evaluating correct and faithful deduction of a conclusion from given premises) and value correctness (comparing predicted values against real-world measurements). We exemplify our work using the complex Sepsis-3 consensus definition. Our experiments show that small fine-tuned models outperform one-shot learning of considerably larger LLMs that are prompted with the explicit definition and models that are trained on medical texts including consensus definitions. Since fine-tuning on verbalized rule instantiations of a specific medical area yields nearly perfect derivation correctness for rules (and exceptions) on unseen patient data in that area, the bottleneck for early prediction is not out-of-distribution generalization, but the orthogonal problem of generalization into the future by forecasting sparsely and irregularly sampled clinical variables. We show that the latter results can be improved by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.",
        "url": "http://arxiv.org/abs/2512.03838v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03838v1",
        "arxiv_id": "2512.03838v1",
        "authors": [
            "Michael Staniek",
            "Artem Sokolov",
            "Stefan Riezler"
        ],
        "submitted": "2025-12-03 14:39:02",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'ctr' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on teaching Large Language Models (LLMs) to follow medical consensus guidelines, which is not directly related to Information Retrieval, Search technologies, or user behavior modeling. While it involves deep semantic understanding, it is primarily concerned with medical reasoning and prediction, which is outside the user's core research themes."
    },
    {
        "title": "Improving Alignment Between Human and Machine Codes: An Empirical Assessment of Prompt Engineering for Construct Identification in Psychology",
        "abstract": "Due to their architecture and vast pre-training data, large language models (LLMs) demonstrate strong text classification performance. However, LLM output - here, the category assigned to a text - depends heavily on the wording of the prompt. While literature on prompt engineering is expanding, few studies focus on classification tasks, and even fewer address domains like psychology, where constructs have precise, theory-driven definitions that may not be well represented in pre-training data. We present an empirical framework for optimizing LLM performance for identifying constructs in texts via prompt engineering. We experimentally evaluate five prompting strategies --codebook-guided empirical prompt selection, automatic prompt engineering, persona prompting, chain-of-thought reasoning, and explanatory prompting - with zero-shot and few-shot classification. We find that persona, chain-of-thought, and explanations do not fully address performance loss accompanying a badly worded prompt. Instead, the most influential features of a prompt are the construct definition, task framing, and, to a lesser extent, the examples provided. Across three constructs and two models, the classifications most aligned with expert judgments resulted from a few-shot prompt combining codebook-guided empirical prompt selection with automatic prompt engineering. Based on our findings, we recommend that researchers generate and evaluate as many prompt variants as feasible, whether human-crafted, automatically generated, or ideally both, and select prompts and examples based on empirical performance in a training dataset, validating the final approach in a holdout set. This procedure offers a practical, systematic, and theory-driven method for optimizing LLM prompts in settings where alignment with expert judgment is critical.",
        "url": "http://arxiv.org/abs/2512.03818v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03818v1",
        "arxiv_id": "2512.03818v1",
        "authors": [
            "Kylie L. Anglin",
            "Stephanie Milan",
            "Brittney Hernandez",
            "Claudia Ventura"
        ],
        "submitted": "2025-12-03 14:07:42",
        "source": "arxiv",
        "comment": "22 pages, 2 figures",
        "score": 2,
        "keyword_reasons": [
            "Found 'recommend' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores prompt engineering for large language models in the psychology domain, which is somewhat related to information retrieval and NLP. However, the focus on classification tasks and domain-specific constructs does not directly align with the user's primary interests in query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics",
        "abstract": "Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.",
        "url": "http://arxiv.org/abs/2512.03807v2",
        "pdf_url": "https://arxiv.org/pdf/2512.03807v2",
        "arxiv_id": "2512.03807v2",
        "authors": [
            "Christos Kolomvakis",
            "Thomas Bobille",
            "Arnaud Vandaele",
            "Nicolas Gillis"
        ],
        "submitted": "2025-12-03 13:55:54",
        "source": "arxiv",
        "comment": "24 pages, 12 tables, 3 figures, 2 typos corrected in v2, code and data available from https://gitlab.com/ckolomvakis/boolean-matrix-factorization-ip-and-heuristics",
        "score": 2,
        "keyword_reasons": [
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Boolean matrix factorization, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, or Natural Language Processing. While it touches on scalability and optimization, the context is more aligned with data mining and computer vision, but lacks the deep semantic understanding and real-time relevance optimization aspects that are central to the user's interests."
    },
    {
        "title": "AITutor-EvalKit: Exploring the Capabilities of AI Tutors",
        "abstract": "We present AITutor-EvalKit, an application that uses language technology to evaluate the pedagogical quality of AI tutors, provides software for demonstration and evaluation, as well as model inspection and data visualization. This tool is aimed at education stakeholders as well as *ACL community at large, as it supports learning and can also be used to collect user feedback and annotations.",
        "url": "http://arxiv.org/abs/2512.03688v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03688v1",
        "arxiv_id": "2512.03688v1",
        "authors": [
            "Numaan Naeem",
            "Kaushal Kumar Maurya",
            "Kseniia Petukhova",
            "Ekaterina Kochmar"
        ],
        "submitted": "2025-12-03 11:27:50",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'acl' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper appears to be unrelated to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on AI tutors and education seems to be outside your primary areas of focus."
    },
    {
        "title": "Fine-grained Narrative Classification in Biased News Articles",
        "abstract": "Narratives are the cognitive and emotional scaffolds of propaganda. They organize isolated persuasive techniques into coherent stories that justify actions, attribute blame, and evoke identification with ideological camps. In this paper, we propose a novel fine-grained narrative classification in biased news articles. We also explore article-bias classification as the precursor task to narrative classification and fine-grained persuasive technique identification. We develop INDI-PROP, the first ideologically grounded fine-grained narrative dataset with multi-level annotation for analyzing propaganda in Indian news media. Our dataset INDI-PROP comprises 1,266 articles focusing on two polarizing socio-political events in recent times: CAA and the Farmers' protest. Each article is annotated at three hierarchical levels: (i) ideological article-bias (pro-government, pro-opposition, neutral), (ii) event-specific fine-grained narrative frames anchored in ideological polarity and communicative intent, and (iii) persuasive techniques. We propose FANTA and TPTC, two GPT-4o-mini guided multi-hop prompt-based reasoning frameworks for the bias, narrative, and persuasive technique classification. FANTA leverages multi-layered communicative phenomena by integrating information extraction and contextual framing for hierarchical reasoning. On the other hand, TPTC adopts systematic decomposition of persuasive cues via a two-stage approach. Our evaluation suggests substantial improvement over underlying baselines in each case.",
        "url": "http://arxiv.org/abs/2512.03582v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03582v1",
        "arxiv_id": "2512.03582v1",
        "authors": [
            "Zeba Afroz",
            "Harsh Vardhan",
            "Pawan Bhakuni",
            "Aanchal Punia",
            "Rajdeep Kumar",
            "Md. Shad Akhtar"
        ],
        "submitted": "2025-12-03 09:07:52",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on narrative classification and persuasive technique identification in biased news articles, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP tasks, the context and application are quite different from your areas of focus."
    },
    {
        "title": "CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding",
        "abstract": "The rise of Visual-Language Models (LVLMs) has unlocked new possibilities for seamlessly integrating visual and textual information. However, their ability to interpret cartographic maps remains largely unexplored. In this paper, we introduce CartoMapQA, a benchmark specifically designed to evaluate LVLMs' understanding of cartographic maps through question-answering tasks. The dataset includes over 2000 samples, each composed of a cartographic map, a question (with open-ended or multiple-choice answers), and a ground-truth answer. These tasks span key low-, mid- and high-level map interpretation skills, including symbol recognition, embedded information extraction, scale interpretation, and route-based reasoning. Our evaluation of both open-source and proprietary LVLMs reveals persistent challenges: models frequently struggle with map-specific semantics, exhibit limited geospatial reasoning, and are prone to Optical Character Recognition (OCR)-related errors. By isolating these weaknesses, CartoMapQA offers a valuable tool for guiding future improvements in LVLM architectures. Ultimately, it supports the development of models better equipped for real-world applications that depend on robust and reliable map understanding, such as navigation, geographic search, and urban planning. Our source code and data are openly available to the research community at: https://github.com/ungquanghuy-kddi/CartoMapQA.git",
        "url": "http://arxiv.org/abs/2512.03558v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03558v1",
        "arxiv_id": "2512.03558v1",
        "authors": [
            "Huy Quang Ung",
            "Guillaume Habault",
            "Yasutaka Nishimura",
            "Hao Niu",
            "Roberto Legaspi",
            "Tomoki Oya",
            "Ryoichi Kojima",
            "Masato Taya",
            "Chihiro Ono",
            "Atsunori Minamikawa",
            "Yan Liu"
        ],
        "submitted": "2025-12-03 08:25:22",
        "source": "arxiv",
        "comment": "Accepted at SIGSPATIAL 2025 (Best paper candidates), 15 pages",
        "score": 2,
        "keyword_reasons": [
            "Found 'search' (score: +1)",
            "Found 'kdd' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper explores the application of Visual-Language Models (LVLMs) in cartographic map understanding, which is somewhat related to information retrieval and search technologies. However, the focus on map understanding and question-answering tasks is not directly aligned with the user's core research themes in query understanding, ranking models, and user behavior modeling. The connection to geographic search is a weak link to the user's interests."
    },
    {
        "title": "NAS-LoRA: Empowering Parameter-Efficient Fine-Tuning for Visual Foundation Models with Searchable Adaptation",
        "abstract": "The Segment Anything Model (SAM) has emerged as a powerful visual foundation model for image segmentation. However, adapting SAM to specific downstream tasks, such as medical and agricultural imaging, remains a significant challenge. To address this, Low-Rank Adaptation (LoRA) and its variants have been widely employed to enhancing SAM's adaptation performance on diverse domains. Despite advancements, a critical question arises: can we integrate inductive bias into the model? This is particularly relevant since the Transformer encoder in SAM inherently lacks spatial priors within image patches, potentially hindering the acquisition of high-level semantic information. In this paper, we propose NAS-LoRA, a new Parameter-Efficient Fine-Tuning (PEFT) method designed to bridge the semantic gap between pre-trained SAM and specialized domains. Specifically, NAS-LoRA incorporates a lightweight Neural Architecture Search (NAS) block between the encoder and decoder components of LoRA to dynamically optimize the prior knowledge integrated into weight updates. Furthermore, we propose a stage-wise optimization strategy to help the ViT encoder balance weight updates and architectural adjustments, facilitating the gradual learning of high-level semantic information. Various Experiments demonstrate our NAS-LoRA improves existing PEFT methods, while reducing training cost by 24.14% without increasing inference cost, highlighting the potential of NAS in enhancing PEFT for visual foundation models.",
        "url": "http://arxiv.org/abs/2512.03499v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03499v1",
        "arxiv_id": "2512.03499v1",
        "authors": [
            "Renqi Chen",
            "Haoyang Su",
            "Shixiang Tang"
        ],
        "submitted": "2025-12-03 06:47:56",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rank' (score: +1)",
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on visual foundation models and their adaptation to specific domains using NAS and LoRA, which is outside the scope of information retrieval and search technologies. While it involves optimization and fine-tuning, the context is image segmentation and visual tasks, not query understanding or ranking models."
    },
    {
        "title": "Tuning for TraceTarnish: Techniques, Trends, and Testing Tangible Traits",
        "abstract": "In this study, we more rigorously evaluated our attack script $\\textit{TraceTarnish}$, which leverages adversarial stylometry principles to anonymize the authorship of text-based messages. To ensure the efficacy and utility of our attack, we sourced, processed, and analyzed Reddit comments--comments that were later alchemized into $\\textit{TraceTarnish}$ data--to gain valuable insights. The transformed $\\textit{TraceTarnish}$ data was then further augmented by $\\textit{StyloMetrix}$ to manufacture stylometric features--features that were culled using the Information Gain criterion, leaving only the most informative, predictive, and discriminative ones. Our results found that function words and function word types ($L\\_FUNC\\_A$ $\\&$ $L\\_FUNC\\_T$); content words and content word types ($L\\_CONT\\_A$ $\\&$ $L\\_CONT\\_T$); and the Type-Token Ratio ($ST\\_TYPE\\_TOKEN\\_RATIO\\_LEMMAS$) yielded significant Information-Gain readings. The identified stylometric cues--function-word frequencies, content-word distributions, and the Type-Token Ratio--serve as reliable indicators of compromise (IoCs), revealing when a text has been deliberately altered to mask its true author. Similarly, these features could function as forensic beacons, alerting defenders to the presence of an adversarial stylometry attack; granted, in the absence of the original message, this signal may go largely unnoticed, as it appears to depend on a pre- and post-transformation comparison. \"In trying to erase a trace, you often imprint a larger one.\" Armed with this understanding, we framed $\\textit{TraceTarnish}$'s operations and outputs around these five isolated features, using them to conceptualize and implement enhancements that further strengthen the attack.",
        "url": "http://arxiv.org/abs/2512.03465v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03465v1",
        "arxiv_id": "2512.03465v1",
        "authors": [
            "Robert Dilworth"
        ],
        "submitted": "2025-12-03 05:39:40",
        "source": "arxiv",
        "comment": "20 pages, 8 figures, 2 tables",
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on adversarial stylometry and text anonymization, which is outside your core research themes."
    },
    {
        "title": "PretrainZero: Reinforcement Active Pretraining",
        "abstract": "Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.",
        "url": "http://arxiv.org/abs/2512.03442v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03442v1",
        "arxiv_id": "2512.03442v1",
        "authors": [
            "Xingrun Xing",
            "Zhiyuan Fan",
            "Jie Lou",
            "Guoqi Li",
            "Jiajun Zhang",
            "Debing Zhang"
        ],
        "submitted": "2025-12-03 04:51:32",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not directly related to Information Retrieval or Search technologies, but rather focuses on Reinforcement Learning and Artificial General Intelligence. While it mentions pretraining and reasoning, the context is different from query understanding, ranking models, and user behavior modeling, which are core areas of interest."
    },
    {
        "title": "SPARK: Stepwise Process-Aware Rewards for Reference-Free Reinforcement Learning",
        "abstract": "Process reward models (PRMs) that provide dense, step-level feedback have shown promise for reinforcement learning, yet their adoption remains limited by the need for expensive step-level annotations or ground truth references. We propose SPARK: a three-stage framework where in the first stage a generator model produces diverse solutions and a verifier model evaluates them using parallel scaling (self-consistency) and sequential scaling (meta-critique). In the second stage, we use these verification outputs as synthetic training data to fine-tune generative process reward models, which subsequently serve as reward signals during training. We show that aggregating multiple independent verifications at the step level produces training data for process reward models that surpass ground-truth outcome supervision, achieving 67.5 F1 on ProcessBench (a benchmark for identifying erroneous steps in mathematical reasoning) compared to 66.4 for reference-guided training and 61.9 for GPT-4o. In the final stage, we apply our generative PRM with chain-of-thought verification (PRM-CoT) as the reward model in RL experiments on mathematical reasoning, and introduce format constraints to prevent reward hacking. Using Qwen2.5-Math-7B, we achieve 47.4% average accuracy across six mathematical reasoning benchmarks, outperforming ground-truth-based RLVR (43.9%). Our work enables reference-free RL training that exceeds ground-truth methods, opening new possibilities for domains lacking verifiable answers or accessible ground truth.",
        "url": "http://arxiv.org/abs/2512.03244v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03244v1",
        "arxiv_id": "2512.03244v1",
        "authors": [
            "Salman Rahman",
            "Sruthi Gorantla",
            "Arpit Gupta",
            "Swastik Roy",
            "Nanyun Peng",
            "Yang Liu"
        ],
        "submitted": "2025-12-02 21:30:47",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on reinforcement learning and process reward models, which is somewhat related to information retrieval and search technologies. However, the topic is not directly aligned with the user's core research themes, such as query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "Identifying attributions of causality in political text",
        "abstract": "Explanations are a fundamental element of how people make sense of the political world. Citizens routinely ask and answer questions about why events happen, who is responsible, and what could or should be done differently. Yet despite their importance, explanations remain an underdeveloped object of systematic analysis in political science, and existing approaches are fragmented and often issue-specific. I introduce a framework for detecting and parsing explanations in political text. To do this, I train a lightweight causal language model that returns a structured data set of causal claims in the form of cause-effect pairs for downstream analysis. I demonstrate how causal explanations can be studied at scale, and show the method's modest annotation requirements, generalizability, and accuracy relative to human coding.",
        "url": "http://arxiv.org/abs/2512.03214v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03214v1",
        "arxiv_id": "2512.03214v1",
        "authors": [
            "Paulina Garcia-Corral"
        ],
        "submitted": "2025-12-02 20:37:07",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on political text analysis and causal explanation detection, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing, particularly in the areas of query understanding, ranking models, and user behavior modeling."
    },
    {
        "title": "InvertiTune: High-Quality Data Synthesis for Cost-Effective Single-Shot Text-to-Knowledge Graph Generation",
        "abstract": "Large Language Models (LLMs) have revolutionized the ability to understand and generate text, enabling significant progress in automatic knowledge graph construction from text (Text2KG). Many Text2KG methods, however, rely on iterative LLM prompting, making them computationally expensive and prone to overlooking complex relations distributed throughout the text. To address these limitations, we propose InvertiTune, a framework that combines a controlled data generation pipeline with supervised fine-tuning (SFT). Within this framework, the data-generation pipeline systematically extracts subgraphs from large knowledge bases, applies noise filtering, and leverages LLMs to generate corresponding natural text descriptions, a task more aligned with LLM capabilities than direct KG generation from text. This pipeline enables generating datasets composed of longer texts paired with larger KGs that better reflect real-world scenarios compared to existing benchmarks, thus supporting effective SFT of lightweight models for single-shot KG construction. Experimental results on CE12k, a dataset generated using the introduced pipeline, show that InvertiTune outperforms larger non-fine-tuned LLMs as well as state-of-the-art Text2KG approaches, while also demonstrating stronger cross-dataset generalization on CrossEval-1200, a test set created from three established benchmark datasets and CE12k. These findings highlight the importance of realistic, high-quality training data for advancing efficient and high-performing Text2KG systems.",
        "url": "http://arxiv.org/abs/2512.03197v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03197v1",
        "arxiv_id": "2512.03197v1",
        "authors": [
            "Faezeh Faez",
            "Marzieh S. Tahaei",
            "Yaochen Hu",
            "Ali Pourranjbar",
            "Mahdi Biparva",
            "Mark Coates",
            "Yingxue Zhang"
        ],
        "submitted": "2025-12-02 19:51:28",
        "source": "arxiv",
        "comment": null,
        "score": 2,
        "keyword_reasons": [
            "Found 'rag' (score: +2)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on text-to-knowledge graph generation, which is not a core area of your research interests. While it involves large language models and data generation, the primary application is in knowledge graph construction, which is not directly related to your expertise in information retrieval and search technologies."
    },
    {
        "title": "Evaluating Hydro-Science and Engineering Knowledge of Large Language Models",
        "abstract": "Hydro-Science and Engineering (Hydro-SE) is a critical and irreplaceable domain that secures human water supply, generates clean hydropower energy, and mitigates flood and drought disasters. Featuring multiple engineering objectives, Hydro-SE is an inherently interdisciplinary domain that integrates scientific knowledge with engineering expertise. This integration necessitates extensive expert collaboration in decision-making, which poses difficulties for intelligence. With the rapid advancement of large language models (LLMs), their potential application in the Hydro-SE domain is being increasingly explored. However, the knowledge and application abilities of LLMs in Hydro-SE have not been sufficiently evaluated. To address this issue, we propose the Hydro-SE LLM evaluation benchmark (Hydro-SE Bench), which contains 4,000 multiple-choice questions. Hydro-SE Bench covers nine subfields and enables evaluation of LLMs in aspects of basic conceptual knowledge, engineering application ability, and reasoning and calculation ability. The evaluation results on Hydro-SE Bench show that the accuracy values vary among 0.74 to 0.80 for commercial LLMs, and among 0.41 to 0.68 for small-parameter LLMs. While LLMs perform well in subfields closely related to natural and physical sciences, they struggle with domain-specific knowledge such as industry standards and hydraulic structures. Model scaling mainly improves reasoning and calculation abilities, but there is still great potential for LLMs to better handle problems in practical engineering application. This study highlights the strengths and weaknesses of LLMs for Hydro-SE tasks, providing model developers with clear training targets and Hydro-SE researchers with practical guidance for applying LLMs.",
        "url": "http://arxiv.org/abs/2512.03672v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03672v1",
        "arxiv_id": "2512.03672v1",
        "authors": [
            "Shiruo Hu",
            "Wenbo Shan",
            "Yingjia Li",
            "Zhiqi Wan",
            "Xinpeng Yu",
            "Yunjia Qi",
            "Haotian Xia",
            "Yang Xiao",
            "Dingxiao Liu",
            "Jiaru Wang",
            "Chenxu Gong",
            "Ruixi Zhang",
            "Shuyue Wu",
            "Shibo Cui",
            "Chee Hui Lai",
            "Wei Luo",
            "Yubin He",
            "Bin Xu",
            "Jianshi Zhao"
        ],
        "submitted": "2025-12-03 11:01:40",
        "source": "arxiv",
        "comment": "Hydro-SE Bench sets a new benchmark for the evaluation of LLMs in the Hydro-Science and Engineering domain, with its code and data available at \\url{https://github.com/sheishijun/Hydro-SE-Bench}",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on evaluating the knowledge of large language models in the Hydro-Science and Engineering domain, which is outside your areas of expertise."
    },
    {
        "title": "AlignCheck: a Semantic Open-Domain Metric for Factual Consistency Assessment",
        "abstract": "Large Language Models have significantly advanced natural language processing tasks, but remain prone to generating incorrect or misleading but plausible arguments. This issue, known as hallucination, is particularly concerning in high-stakes domains like clinical applications, where factual inaccuracies can have severe consequences. Existing evaluation metrics fail to adequately assess factual consistency and lack interpretability, making diagnosing and mitigating errors difficult. We propose an interpretable framework for factual consistency assessment for in-domain and open-domain texts to address these limitations. Our approach decomposes text into atomic facts and introduces a flexible, schema-free methodology. Unlike previous methods with an absolute metric, we incorporate a weighted metric to enhance factual evaluation. Additionally, we propose a mechanism to control assessment complexity in intricate domains. We benchmark our approach on popular general and clinical datasets and release our code to support fact-aware model training in future research.",
        "url": "http://arxiv.org/abs/2512.03634v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03634v1",
        "arxiv_id": "2512.03634v1",
        "authors": [
            "Ahmad Aghaebrahimian"
        ],
        "submitted": "2025-12-03 10:14:31",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper focuses on evaluating the factual consistency of text generated by large language models, which is related to query understanding and deep semantic understanding in Information Retrieval. However, it does not directly address ranking models, user behavior modeling, or search technologies, making it somewhat relevant but not a central match to your research interests."
    },
    {
        "title": "SELF: A Robust Singular Value and Eigenvalue Approach for LLM Fingerprinting",
        "abstract": "The protection of Intellectual Property (IP) in Large Language Models (LLMs) represents a critical challenge in contemporary AI research. While fingerprinting techniques have emerged as a fundamental mechanism for detecting unauthorized model usage, existing methods -- whether behavior-based or structural -- suffer from vulnerabilities such as false claim attacks or susceptible to weight manipulations. To overcome these limitations, we propose SELF, a novel intrinsic weight-based fingerprinting scheme that eliminates dependency on input and inherently resists false claims. SELF achieves robust IP protection through two key innovations: 1) unique, scalable and transformation-invariant fingerprint extraction via singular value and eigenvalue decomposition of LLM attention weights, and 2) effective neural network-based fingerprint similarity comparison based on few-shot learning and data augmentation. Experimental results demonstrate SELF maintains high IP infringement detection accuracy while showing strong robustness against various downstream modifications, including quantization, pruning, and fine-tuning attacks. Our code is available at https://github.com/HanxiuZhang/SELF_v2.",
        "url": "http://arxiv.org/abs/2512.03620v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03620v1",
        "arxiv_id": "2512.03620v1",
        "authors": [
            "Hanxiu Zhang",
            "Yue Zheng"
        ],
        "submitted": "2025-12-03 09:53:47",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on Large Language Model (LLM) fingerprinting, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on neural networks, the context is specific to LLM protection and not relevant to the user's core themes of query understanding, ranking models, or user behavior modeling."
    },
    {
        "title": "Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates",
        "abstract": "Low-rank adaptation (LoRA) is one of the most popular methods among parameter-efficient fine-tuning (PEFT) methods to adapt pre-trained large language models (LLMs) to specific downstream tasks. However, the model trained based on LoRA often has an unsatisfactory performance due to its low-rank assumption. In this paper, we propose a novel method called Dual LoRA to improve the performance by incorporating an inductive bias into the original LoRA. Specifically, we separate low-rank matrices into two groups: the magnitude group to control whether or not and how far we should update a parameter and the direction group to decide whether this parameter should move forward or backward, to better simulate the parameter updating process of the full fine-tuning based on gradient-based optimization algorithms. We show that this can be simply achieved by adding a ReLU function to the magnitude group and a sign function to the direction group. We conduct several experiments over a wide range of NLP tasks, including natural language generation (NLG), understanding (NLU), and commonsense reasoning datasets on GPT-2, RoBERTa, DeBERTa, and LLaMA-1/2/3 as baseline models. The results show that we consistently outperform LoRA and its state-of-the-art variants with the same number of trainable parameters.",
        "url": "http://arxiv.org/abs/2512.03402v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03402v1",
        "arxiv_id": "2512.03402v1",
        "authors": [
            "Yixing Xu",
            "Chao Li",
            "Xuanwu Yin",
            "Spandan Tiwari",
            "Dong Li",
            "Ashish Sirasao",
            "Emad Barsoum"
        ],
        "submitted": "2025-12-03 03:14:09",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'rank' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on parameter-efficient fine-tuning of pre-trained language models, which is a topic related to NLP, but it does not directly address information retrieval, query understanding, or ranking models, making it less relevant to your core research interests."
    },
    {
        "title": "LLM-Generated Ads: From Personalization Parity to Persuasion Superiority",
        "abstract": "As large language models (LLMs) become increasingly capable of generating persuasive content, understanding their effectiveness across different advertising strategies becomes critical. This paper presents a two-part investigation examining LLM-generated advertising through complementary lenses: (1) personality-based and (2) psychological persuasion principles.\n  In our first study (n=400), we tested whether LLMs could generate personalized advertisements tailored to specific personality traits (openness and neuroticism) and how their performance compared to human experts. Results showed that LLM-generated ads achieved statistical parity with human-written ads (51.1% vs. 48.9%, p > 0.05), with no significant performance differences for matched personalities.\n  Building on these insights, our second study (n=800) shifted focus from individual personalization to universal persuasion, testing LLM performance across four foundational psychological principles: authority, consensus, cognition, and scarcity. AI-generated ads significantly outperformed human-created content, achieving a 59.1% preference rate (vs. 40.9%, p < 0.001), with the strongest performance in authority (63.0%) and consensus (62.5%) appeals. Qualitative analysis revealed AI's advantage stems from crafting more sophisticated, aspirational messages and achieving superior visual-narrative coherence. Critically, this quality advantage proved robust: even after applying a 21.2 percentage point detection penalty when participants correctly identified AI-origin, AI ads still outperformed human ads, and 29.4% of participants chose AI content despite knowing its origin. These findings demonstrate LLMs' evolution from parity in personalization to superiority in persuasive storytelling, with significant implications for advertising practice given LLMs' near-zero marginal cost and time requirements compared to human experts.",
        "url": "http://arxiv.org/abs/2512.03373v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03373v1",
        "arxiv_id": "2512.03373v1",
        "authors": [
            "Elyas Meguellati",
            "Stefano Civelli",
            "Lei Han",
            "Abraham Bernstein",
            "Shazia Sadiq",
            "Gianluca Demartini"
        ],
        "submitted": "2025-12-03 02:13:38",
        "source": "arxiv",
        "comment": null,
        "score": 1,
        "keyword_reasons": [
            "Found 'personalization' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "This paper explores the effectiveness of large language models (LLMs) in generating persuasive content for advertising. While it touches on personalization and user behavior modeling, its primary focus is on the persuasive capabilities of LLMs, which is somewhat related to the user's interests in information retrieval and query understanding. However, the paper's emphasis on advertising and persuasion is not a central match for the user's research themes."
    },
    {
        "title": "Idea-Gated Transformers: Enforcing Semantic Coherence via Differentiable Vocabulary Pruning",
        "abstract": "Autoregressive Language Models (LLMs) trained on Next-Token Prediction (NTP) often suffer from ``Topic Drift'' where the generation wanders away from the initial prompt due to a reliance on local associations rather than global planning \\citep{holtzman2019curious}. While scaling model size mitigates this \\citep{brown2020language}, the fundamental myopia of the NTP objective remains. In this work, we introduce the Idea-Gated Transformer, a novel architecture that separates semantic planning from syntactic generation. We introduce an auxiliary ``Idea Head'' trained to predict the bag-of-words distribution for a future context window, creating a latent ``Concept Vector'' that actively gates the main vocabulary during generation. We propose a differentiable gating mechanism that suppresses semantically irrelevant tokens, effectively pruning the search space in real-time. Experiments on WikiText-103 demonstrate that while the Idea-Gated model achieves comparable validation perplexity to a standard GPT-2 baseline, it exhibits significantly superior Domain Retention. Qualitative and quantitative analysis reveals that the gating mechanism successfully locks generation into specific semantic clusters (e.g., Finance, Science) and resists associative drift, offering a parameter-efficient path toward more controllable language modeling.",
        "url": "http://arxiv.org/abs/2512.03343v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03343v1",
        "arxiv_id": "2512.03343v1",
        "authors": [
            "Darshan Fofadiya"
        ],
        "submitted": "2025-12-03 01:17:07",
        "source": "arxiv",
        "comment": "Code available at https://github.com/DarshanFofadiya/idea-gated-transformers/tree/main",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 8,
        "llm_reason": "This paper introduces a novel architecture for language modeling that addresses the issue of 'Topic Drift' by separating semantic planning from syntactic generation. Although not directly related to information retrieval, the work on semantic coherence and vocabulary pruning is relevant to the broader field of natural language processing, which is of interest to you. The paper's focus on controllable language modeling and real-time relevance optimization also aligns with your research goals."
    },
    {
        "title": "PERCS: Persona-Guided Controllable Biomedical Summarization Dataset",
        "abstract": "Automatic medical text simplification plays a key role in improving health literacy by making complex biomedical research accessible to diverse readers. However, most existing resources assume a single generic audience, overlooking the wide variation in medical literacy and information needs across user groups. To address this limitation, we introduce PERCS (Persona-guided Controllable Summarization), a dataset of biomedical abstracts paired with summaries tailored to four personas: Laypersons, Premedical Students, Non-medical Researchers, and Medical Experts. These personas represent different levels of medical literacy and information needs, emphasizing the need for targeted, audience-specific summarization. Each summary in PERCS was reviewed by physicians for factual accuracy and persona alignment using a detailed error taxonomy. Technical validation shows clear differences in readability, vocabulary, and content depth across personas. Along with describing the dataset, we benchmark four large language models on PERCS using automatic evaluation metrics that assess comprehensiveness, readability, and faithfulness, establishing baseline results for future research. The dataset, annotation guidelines, and evaluation materials are publicly available to support research on persona-specific communication and controllable biomedical summarization.",
        "url": "http://arxiv.org/abs/2512.03340v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03340v1",
        "arxiv_id": "2512.03340v1",
        "authors": [
            "Rohan Charudatt Salvi",
            "Chirag Chawla",
            "Dhruv Jain",
            "Swapnil Panigrahi",
            "Md Shad Akhtar",
            "Shweta Yadav"
        ],
        "submitted": "2025-12-03 01:13:56",
        "source": "arxiv",
        "comment": "9 pages, 4 figures, 6 tables",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 4,
        "llm_reason": "The paper is somewhat related to the user's interests in Information Retrieval and Natural Language Processing, particularly in the context of biomedical text summarization and persona-guided summarization. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest for the user."
    },
    {
        "title": "Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies",
        "abstract": "This study investigates the potential of language models to improve the classification of labor market information by linking job vacancy texts to two major European frameworks: the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy and the European Qualifications Framework (EQF). We examine and compare two prominent methodologies from the literature: Sentence Linking and Entity Linking. In support of ongoing research, we release an open-source tool, incorporating these two methodologies, designed to facilitate further work on labor classification and employment discourse. To move beyond surface-level skill extraction, we introduce two annotated datasets specifically aimed at evaluating how occupations and qualifications are represented within job vacancy texts. Additionally, we examine different ways to utilize generative large language models for this task. Our findings contribute to advancing the state of the art in job entity extraction and offer computational infrastructure for examining work, skills, and labor market narratives in a digitally mediated economy. Our code is made publicly available: https://github.com/tabiya-tech/tabiya-livelihoods-classifier",
        "url": "http://arxiv.org/abs/2512.03195v1",
        "pdf_url": "https://arxiv.org/pdf/2512.03195v1",
        "arxiv_id": "2512.03195v1",
        "authors": [
            "Stylianos Saroglou",
            "Konstantinos Diamantaras",
            "Francesco Preta",
            "Marina Delianidi",
            "Apostolos Benisis",
            "Christian Johannes Meyer"
        ],
        "submitted": "2025-12-02 19:49:43",
        "source": "arxiv",
        "comment": "14 pages, 1 figure, Preprint",
        "score": 1,
        "keyword_reasons": [
            "Found 'search' (score: +1)"
        ],
        "llm_score": 2,
        "llm_reason": "This paper focuses on labor market information classification using language models, which is not directly related to the user's core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the specific application and methodologies (e.g., ESCO and EQF taxonomies) are not aligned with the user's interests in query understanding, ranking models, and user behavior modeling."
    }
]