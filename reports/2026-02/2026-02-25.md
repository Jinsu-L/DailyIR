# Daily Papers Report - 2026-02-25

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. PRECTR-V2:Unified Relevance-CTR Framework with Cross-User Preference Mining, Exposure Bias Correction, and LLM-Distilled Encoder Optimization

- **LLM Score**: 9
- **Keyword Score**: 20
- **Authors**: Shuzhi Cao, Rong Chen, Ailong He, Shuguang Han, Jufeng Chen
- **URL**: <http://arxiv.org/abs/2602.20676v1>
- **Submitted**: 2026-02-24 08:26:17
- **Comment**: arXiv admin note: text overlap with arXiv:2503.18395
- **Topic Keywords**: query, ranking, pairwise, relevance, click, ctr, click-through rate, rank, search
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in query understanding, ranking models, and user behavior modeling. The paper proposes a unified framework for search relevance matching and click-through rate prediction, addressing challenges such as low-active users, exposure bias, and model optimization, which are all key areas of interest in your research.

#### Abstract
> In search systems, effectively coordinating the two core objectives of search relevance matching and click-through rate (CTR) prediction is crucial for discovering users' interests and enhancing platform revenue. In our prior work PRECTR, we proposed a unified framework to integrate these two subtasks,thereby eliminating their inconsistency and leading to mutual benefit.However, our previous work still faces three main challenges. First, low-active users and new users have limited search behavioral data, making it difficult to achieve effective personalized relevance preference modeling. Second, training data for ranking models predominantly come from high-relevance exposures, creating a distribution mismatch with the broader candidate space in coarse-ranking, leading to generalization bias. Third, due to the latency constraint, the original model employs an Emb+MLP architecture with a frozen BERT encoder, which prevents joint optimization and creates misalignment between representation learning and CTR fine-tuning. To solve these issues, we further reinforce our method and propose PRECTR-V2. Specifically, we mitigate the low-activity users' sparse behavior problem by mining global relevance preferences under the specific query, which facilitates effective personalized relevance modeling for cold-start scenarios. Subsequently, we construct hard negative samples through embedding noise injection and relevance label reconstruction, and optimize their relative ranking against positive samples via pairwise loss, thereby correcting exposure bias. Finally, we pretrain a lightweight transformer-based encoder via knowledge distillation from LLM and SFT on the text relevance classification task. This encoder replaces the frozen BERT module, enabling better adaptation to CTR fine-tuning and advancing beyond the traditional Emb+MLP paradigm.

---

### 2. Naver Labs Europe @ WSDM CUP | Multilingual Retrieval

- **LLM Score**: 8
- **Keyword Score**: 19
- **Authors**: Thibault Formal, Maxime Louis, Herv√© D√©jean, St√©phane Clinchant
- **URL**: <http://arxiv.org/abs/2602.20986v1>
- **Submitted**: 2026-02-24 15:09:01
- **Comment**: Report paper of our submission to the WSDM Cup 2026
- **Topic Keywords**: sparse retrieval, queries, ranking, rerank, relevance, retrieval, rank, wsdm
- **Reason**: The paper is highly relevant to Information Retrieval, specifically focusing on multilingual retrieval and learned sparse retrieval models, which aligns with your interests in query understanding and ranking models. The use of SPLARE, a learned sparse retrieval model, is particularly noteworthy, as it demonstrates advancements in deep semantic understanding and real-time relevance optimization. However, the paper's focus on multilingual retrieval may not be directly applicable to your e-commerce background.

#### Abstract
> This report presents our participation to the WSDM Cup 2026 shared task on multilingual document retrieval from English queries. The task provides a challenging benchmark for cross-lingual generalization. It also provides a natural testbed for evaluating SPLARE, our recently proposed learned sparse retrieval model, which produces generalizable sparse latent representations and is particularly well suited to multilingual retrieval settings.
  We evaluate five progressively enhanced runs, starting from a SPLARE-7B model and incorporating lightweight improvements, including reranking with Qwen3-Reranker-4B and simple score fusion strategies. Our results demonstrate the strength of SPLARE compared to state-of-the-art dense baselines such as Qwen3-8B-Embed. More broadly, our submission highlights the continued relevance and competitiveness of learned sparse retrieval models beyond English-centric scenarios.

---

### 3. Mitigating Preference Leakage via Strict Estimator Separation for Normative Generative Ranking

- **LLM Score**: 8
- **Keyword Score**: 15
- **Authors**: Dalia Nahhas, Xiaohao Cai, Imran Razzak, Shoaib Jameel
- **URL**: <http://arxiv.org/abs/2602.20800v2>
- **Submitted**: 2026-02-24 11:38:36
- **Topic Keywords**: information retrieval, query, ranking, relevance, retrieval, rank
- **Reason**: This paper is highly relevant to your research interests in Information Retrieval, particularly in the context of Generative Information Retrieval (GenIR) and ranking models. The paper's focus on mitigating preference leakage and introducing a leakage-free two-judge framework aligns with your interests in query understanding and ranking models. However, the paper's specific application to cultural relevance and normative criteria is somewhat niche, preventing a perfect match with your broader interests.

#### Abstract
> In Generative Information Retrieval (GenIR), the bottleneck has shifted from generation to the selection of candidates, particularly for normative criteria such as cultural relevance. Current LLM-as-a-Judge evaluations often suffer from circularity and preference leakage, where overlapping supervision and evaluation models inflate performance. We address this by formalising cultural relevance as a within-query ranking task and introducing a leakage-free two-judge framework that strictly separates supervision (Judge B) from evaluation (Judge A). On a new benchmark of 33,052 (NGR-33k) culturally grounded stories, we find that while classical baselines yield only modest gains, a dense bi-encoder distilled from a Judge-B-supervised Cross-Encoder is highly effective. Although the Cross-Encoder provides a strong supervision signal for distillation, the distilled BGE-M3 model substantially outperforms it under leakage-free Judge~A evaluation. We validate our framework on the human-curated Moral Stories dataset, showing strong alignment with human norms. Our results demonstrate that rigorous evaluator separation is a prerequisite for credible GenIR evaluation, proving that subtle cultural preferences can be distilled into efficient rankers without leakage.

---

### 4. Indaleko: The Unified Personal Index

- **LLM Score**: 8
- **Keyword Score**: 14
- **Authors**: William Anthony Mason
- **URL**: <http://arxiv.org/abs/2602.20507v1>
- **Submitted**: 2026-02-24 03:17:36
- **Comment**: PhD dissertation, University of British Columbia, August 2025. 287 pages
- **Topic Keywords**: information retrieval, query, queries, rag, retrieval, search
- **Reason**: This paper presents a novel approach to personal information retrieval, focusing on memory-aligned architecture and natural language queries. While not directly related to query understanding or ranking models, it explores a deep semantic understanding of user behavior and context, aligning with your broader interests in Information Retrieval and NLP. The paper's emphasis on real-time relevance optimization and its evaluation against commercial systems also resonates with your research themes.

#### Abstract
> Personal information retrieval fails when systems ignore how human memory works. While existing platforms force keyword searches across isolated silos, humans naturally recall through episodic cues like when, where, and in what context information was encountered. This dissertation presents the Unified Personal Index (UPI), a memory-aligned architecture that bridges this fundamental gap. The Indaleko prototype demonstrates the UPI's feasibility on a 31-million file dataset spanning 160TB across eight storage platforms. By integrating temporal, spatial, and activity metadata into a unified graph database, Indaleko enables natural language queries like "photos near the conference venue last spring" that existing systems cannot process. The implementation achieves sub-second query responses through memory anchor indexing, eliminates cross-platform search fragmentation, and maintains perfect precision for well-specified memory patterns. Evaluation against commercial systems (Google Drive, OneDrive, Dropbox, Windows Search) reveals that all fail on memory-based queries, returning overwhelming result sets without contextual filtering. In contrast, Indaleko successfully processes multi-dimensional queries combining time, location, and activity patterns. The extensible architecture supports rapid integration of new data sources (10 minutes to 10 hours per provider) while preserving privacy through UUID-based semantic decoupling. The UPI's architectural synthesis bridges cognitive theory with distributed systems design, as demonstrated through the Indaleko prototype and rigorous evaluation. This work transforms personal information retrieval from keyword matching to memory-aligned finding, providing immediate benefits for existing data while establishing foundations for future context-aware systems.

---

### 5. Generative Pseudo-Labeling for Pre-Ranking with LLMs

- **LLM Score**: 8
- **Keyword Score**: 11
- **Authors**: Junyu Bi, Xinting Niu, Daixuan Cheng, Kun Yuan, Tao Wang, Binbin Cao, Jian Wu, Yuning Jiang
- **URL**: <http://arxiv.org/abs/2602.20995v1>
- **Submitted**: 2026-02-24 15:14:49
- **Topic Keywords**: ranking, rag, click, click-through rate, recommend, rank
- **Reason**: This paper is highly relevant to Information Retrieval, particularly in the context of pre-ranking and recommendation systems. The use of large language models (LLMs) to generate unbiased pseudo-labels for unexposed items aligns with the user's interests in query understanding and ranking models. However, the focus on recommender systems and e-commerce domain is not the primary area of interest for the user.

#### Abstract
> Pre-ranking is a critical stage in industrial recommendation systems, tasked with efficiently scoring thousands of recalled items for downstream ranking. A key challenge is the train-serving discrepancy: pre-ranking models are trained only on exposed interactions, yet must score all recalled candidates -- including unexposed items -- during online serving. This mismatch not only induces severe sample selection bias but also degrades generalization, especially for long-tail content. Existing debiasing approaches typically rely on heuristics (e.g., negative sampling) or distillation from biased rankers, which either mislabel plausible unexposed items as negatives or propagate exposure bias into pseudo-labels. In this work, we propose Generative Pseudo-Labeling (GPL), a framework that leverages large language models (LLMs) to generate unbiased, content-aware pseudo-labels for unexposed items, explicitly aligning the training distribution with the online serving space. By offline generating user-specific interest anchors and matching them with candidates in a frozen semantic space, GPL provides high-quality supervision without adding online latency. Deployed in a large-scale production system, GPL improves click-through rate by 3.07%, while significantly enhancing recommendation diversity and long-tail item discovery.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. What Makes a Good Query? Measuring the Impact of Human-Confusing Linguistic Features on LLM Performance

- **LLM Score**: 8
- **Keyword Score**: 6
- **Authors**: William Watson, Nicole Cho, Sumitra Ganesh, Manuela Veloso
- **URL**: <http://arxiv.org/abs/2602.20300v1>
- **Submitted**: 2026-02-23 19:30:08
- **Comment**: EACL 2026 Findings
- **Topic Keywords**: query, queries
- **Reason**: This paper explores the impact of query features on Large Language Model (LLM) performance, specifically hallucinations. While the focus is on LLMs, the query understanding and ranking aspects are relevant to Information Retrieval. The study's emphasis on query features and their effects on model performance aligns with my research interests in query understanding and ranking models.

#### Abstract
> Large Language Model (LLM) hallucinations are usually treated as defects of the model or its decoding strategy. Drawing on classical linguistics, we argue that a query's form can also shape a listener's (and model's) response. We operationalize this insight by constructing a 22-dimension query feature vector covering clause complexity, lexical rarity, and anaphora, negation, answerability, and intention grounding, all known to affect human comprehension. Using 369,837 real-world queries, we ask: Are there certain types of queries that make hallucination more likely? A large-scale analysis reveals a consistent "risk landscape": certain features such as deep clause nesting and underspecification align with higher hallucination propensity. In contrast, clear intention grounding and answerability align with lower hallucination rates. Others, including domain specificity, show mixed, dataset- and model-dependent effects. Thus, these findings establish an empirically observable query-feature representation correlated with hallucination risk, paving the way for guided query rewriting and future intervention studies.

### 7. Case-Aware LLM-as-a-Judge Evaluation for Enterprise-Scale RAG Systems

- **LLM Score**: 8
- **Keyword Score**: 4
- **Authors**: Mukul Chhabra, Luigi Medrano, Arush Verma
- **URL**: <http://arxiv.org/abs/2602.20379v1>
- **Submitted**: 2026-02-23 21:37:06
- **Comment**: 12 pages including appendix, 6 figures
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper is highly relevant to Information Retrieval, particularly in the context of Retrieval-Augmented Generation (RAG) systems, which is a subfield of IR. The focus on multi-turn workflows, case-aware evaluation, and operational constraints aligns with the user's interests in query understanding and ranking models. However, the specific domain of enterprise-scale RAG systems is somewhat niche, but still falls within the broader scope of IR.

#### Abstract
> Enterprise Retrieval-Augmented Generation (RAG) assistants operate in multi-turn, case-based workflows such as technical support and IT operations, where evaluation must reflect operational constraints, structured identifiers (e.g., error codes, versions), and resolution workflows. Existing RAG evaluation frameworks are primarily designed for benchmark-style or single-turn settings and often fail to capture enterprise-specific failure modes such as case misidentification, workflow misalignment, and partial resolution across turns.
  We present a case-aware LLM-as-a-Judge evaluation framework for enterprise multi-turn RAG systems. The framework evaluates each turn using eight operationally grounded metrics that separate retrieval quality, grounding fidelity, answer utility, precision integrity, and case/workflow alignment. A severity-aware scoring protocol reduces score inflation and improves diagnostic clarity across heterogeneous enterprise cases. The system uses deterministic prompting with strict JSON outputs, enabling scalable batch evaluation, regression testing, and production monitoring.
  Through a comparative study of two instruction-tuned models across short and long workflows, we show that generic proxy metrics provide ambiguous signals, while the proposed framework exposes enterprise-critical tradeoffs that are actionable for system improvement.

### 8. Turning Semantics into Topology: LLM-Driven Attribute Augmentation for Collaborative Filtering

- **LLM Score**: 7
- **Keyword Score**: 3
- **Authors**: Junjie Meng, Ranxu zhang, Wei Wu, Rui Zhang, Chuan Qin, Qi Zhang, Qi Liu, Hui Xiong, Chao Wang
- **URL**: <http://arxiv.org/abs/2602.21099v1>
- **Submitted**: 2026-02-24 17:01:47
- **Topic Keywords**: retrieval, recommend
- **Reason**: This paper explores the application of Large Language Models (LLMs) in recommender systems, which is somewhat related to your research interests in Information Retrieval and Search technologies. Although the focus is on collaborative filtering, the use of LLMs for semantic understanding and real-time relevance optimization aligns with your interests. However, the paper's primary focus on recommender systems and collaborative filtering is not a central match for your core research themes.

#### Abstract
> Large Language Models (LLMs) have shown great potential for enhancing recommender systems through their extensive world knowledge and reasoning capabilities. However, effectively translating these semantic signals into traditional collaborative embeddings remains an open challenge. Existing approaches typically fall into two extremes: direct inference methods are computationally prohibitive for large-scale retrieval, while embedding-based methods primarily focus on unilateral feature augmentation rather than holistic collaborative signal enhancement. To bridge this gap, we propose Topology-Augmented Graph Collaborative Filtering (TAGCF), a novel framework that transforms semantic knowledge into topological connectivity. Unlike existing approaches that depend on textual features or direct interaction synthesis, TAGCF employs LLMs to infer interaction intents and underlying causal relationships from user-item pairs, representing these insights as intermediate attribute nodes within an enriched User-Attribute-Item (U-A-I) graph. Furthermore, to effectively model the heterogeneous relations in this augmented structure, we propose Adaptive Relation-weighted Graph Convolution (ARGC), which employs relation-specific prediction networks to dynamically estimate the importance of each relation type. Extensive experiments across multiple benchmark datasets and CF backbones demonstrate consistent improvements, with comprehensive evaluations including cold-start scenarios validating the effectiveness and robustness of our framework. All code will be made publicly available. For anonymous review, our code is available at the following anonymous link: https://anonymous.4open.science/r/AGCF-2441353190/.

### 9. RMIT-ADM+S at the MMU-RAG NeurIPS 2025 Competition

- **LLM Score**: 6
- **Keyword Score**: 11
- **Authors**: Kun Ran, Marwah Alaofi, Danula Hettiachchi, Chenglong Ma, Khoi Nguyen Dinh Anh, Khoi Vo Nguyen, Sachin Pathiyan Cherumanal, Lida Rashidi, Falk Scholer, Damiano Spina, Shuoqi Sun, Oleg Zendel
- **URL**: <http://arxiv.org/abs/2602.20735v1>
- **Submitted**: 2026-02-24 09:58:25
- **Comment**: MMU-RAG NeurIPS 2025 winning system
- **Topic Keywords**: query, rag, retrieval, search, sigir, neurips
- **Reason**: The paper presents a retrieval-augmented generation architecture for text-to-text tasks, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on a specific competition and the use of lightweight components for efficient operation on a single GPU does not directly align with the user's interests in deep semantic understanding and real-time relevance optimization.

#### Abstract
> This paper presents the award-winning RMIT-ADM+S system for the Text-to-Text
  track of the NeurIPS~2025 MMU-RAG Competition. We introduce Routing-to-RAG
  (R2RAG), a research-focused retrieval-augmented generation (RAG)
  architecture composed of lightweight components that dynamically adapt the
  retrieval strategy based on inferred query complexity and evidence
  sufficiency. The system uses smaller LLMs, enabling operation on a single
  consumer-grade GPU while supporting complex research tasks. It builds on the
  G-RAG system, winner of the ACM~SIGIR~2025 LiveRAG Challenge, and extends it
  with modules informed by qualitative review of outputs. R2RAG won the Best
  Dynamic Evaluation award in the Open Source category, demonstrating high
  effectiveness with careful design and efficient use of resources.

### 10. A Benchmark for Deep Information Synthesis

- **LLM Score**: 6
- **Keyword Score**: 3
- **Authors**: Debjit Paul, Daniel Murphy, Milan Gritta, Ronald Cardenas, Victor Prokhorov, Lena Sophia Bolliger, Aysim Toker, Roy Miles, Andreea-Maria Oncescu, Jasivan Alex Sivakumar, Philipp Borchert, Ismail Elezi, Meiru Zhang, Ka Yiu Lee, Guchun Zhang, Jun Wang, Gerasimos Lampouras
- **URL**: <http://arxiv.org/abs/2602.21143v1>
- **Submitted**: 2026-02-24 17:43:32
- **Comment**: Accepted at ICLR 2026
- **Topic Keywords**: retrieval, search
- **Reason**: The paper introduces a benchmark for deep information synthesis, which is somewhat related to information retrieval, particularly in the context of query understanding and real-time relevance optimization. However, the focus is on evaluating large language models rather than ranking models or user behavior modeling, making it less central to your core research themes.

#### Abstract
> Large language model (LLM)-based agents are increasingly used to solve complex tasks involving tool use, such as web browsing, code execution, and data analysis. However, current evaluation benchmarks do not adequately assess their ability to solve real-world tasks that require synthesizing information from multiple sources and inferring insights beyond simple fact retrieval. To address this, we introduce DEEPSYNTH, a novel benchmark designed to evaluate agents on realistic, time-consuming problems that combine information gathering, synthesis, and structured reasoning to produce insights. DEEPSYNTH contains 120 tasks collected across 7 domains and data sources covering 67 countries. DEEPSYNTH is constructed using a multi-stage data collection pipeline that requires annotators to collect official data sources, create hypotheses, perform manual analysis, and design tasks with verifiable answers. When evaluated on DEEPSYNTH, 11 state-of-the-art LLMs and deep research agents achieve a maximum F1 score of 8.97 and 17.5 on the LLM-judge metric, underscoring the difficulty of the benchmark. Our analysis reveals that current agents struggle with hallucinations and reasoning over large information spaces, highlighting DEEPSYNTH as a crucial benchmark for guiding future research.

### 11. Natural Language Processing Models for Robust Document Categorization

- **LLM Score**: 6
- **Keyword Score**: 2
- **Authors**: Radoslaw Roszczyk, Pawel Tecza, Maciej Stodolski, Krzysztof Siwek
- **URL**: <http://arxiv.org/abs/2602.20336v1>
- **Submitted**: 2026-02-23 20:33:22
- **Comment**: 13 pages, 1 fiure, 5 tables
- **Topic Keywords**: rag
- **Reason**: The paper explores Natural Language Processing (NLP) models for document categorization, which is somewhat related to your interests in Information Retrieval and NLP. However, the focus on document categorization and classification accuracy is not directly aligned with your primary focus on query understanding, ranking models, and user behavior modeling. The paper's emphasis on computational efficiency and real-world automation pipelines also doesn't directly intersect with your research themes.

#### Abstract
> This article presents an evaluation of several machine learning methods applied to automated text classification, alongside the design of a demonstrative system for unbalanced document categorization and distribution. The study focuses on balancing classification accuracy with computational efficiency, a key consideration when integrating AI into real world automation pipelines. Three models of varying complexity were examined: a Naive Bayes classifier, a bidirectional LSTM network, and a fine tuned transformer based BERT model.
  The experiments reveal substantial differences in performance. BERT achieved the highest accuracy, consistently exceeding 99\%, but required significantly longer training times and greater computational resources. The BiLSTM model provided a strong compromise, reaching approximately 98.56\% accuracy while maintaining moderate training costs and offering robust contextual understanding. Naive Bayes proved to be the fastest to train, on the order of milliseconds, yet delivered the lowest accuracy, averaging around 94.5\%. Class imbalance influenced all methods, particularly in the recognition of minority categories.
  A fully functional demonstrative system was implemented to validate practical applicability, enabling automated routing of technical requests with throughput unattainable through manual processing. The study concludes that BiLSTM offers the most balanced solution for the examined scenario, while also outlining opportunities for future improvements and further exploration of transformer architectures.

### 12. Beyond the Star Rating: A Scalable Framework for Aspect-Based Sentiment Analysis Using LLMs and Text Classification

- **LLM Score**: 6
- **Keyword Score**: 1
- **Authors**: Vishal Patil, Shree Vaishnavi Bacha, Revanth Yamani, Yidan Sun, Mayank Kejriwal
- **URL**: <http://arxiv.org/abs/2602.21082v1>
- **Submitted**: 2026-02-24 16:45:17
- **Topic Keywords**: search
- **Reason**: This paper is somewhat related to the user's interests in Natural Language Processing (NLP) and data mining, as it involves aspect-based sentiment analysis and the application of large language models (LLMs). However, it does not directly align with the user's primary focus on Information Retrieval, especially in areas requiring deep semantic understanding and real-time relevance optimization. The paper's focus on the hospitality industry also limits its broader applicability to the user's interests.

#### Abstract
> Customer-provided reviews have become an important source of information for business owners and other customers alike. However, effectively analyzing millions of unstructured reviews remains challenging. While large language models (LLMs) show promise for natural language understanding, their application to large-scale review analysis has been limited by computational costs and scalability concerns. This study proposes a hybrid approach that uses LLMs for aspect identification while employing classic machine-learning methods for sentiment classification at scale. Using ChatGPT to analyze sampled restaurant reviews, we identified key aspects of dining experiences and developed sentiment classifiers using human-labeled reviews, which we subsequently applied to 4.7 million reviews collected over 17 years from a major online platform. Regression analysis reveals that our machine-labeled aspects significantly explain variance in overall restaurant ratings across different aspects of dining experiences, cuisines, and geographical regions. Our findings demonstrate that combining LLMs with traditional machine learning approaches can effectively automate aspect-based sentiment analysis of large-scale customer feedback, suggesting a practical framework for both researchers and practitioners in the hospitality industry and potentially, other service sectors.

### 13. From Logs to Language: Learning Optimal Verbalization for LLM-Based Recommendation in Production

- **LLM Score**: 6
- **Keyword Score**: 1
- **Authors**: Yucheng Shi, Ying Li, Yu Wang, Yesu Feng, Arjun Rao, Rein Houthooft, Shradha Sehgal, Jin Wang, Hao Zhen, Ninghao Liu, Linas Baltrunas
- **URL**: <http://arxiv.org/abs/2602.20558v1>
- **Submitted**: 2026-02-24 05:15:24
- **Comment**: Work in progress
- **Topic Keywords**: recommend
- **Reason**: The paper explores verbalization for LLM-based recommendation, which is somewhat related to information retrieval and ranking models. However, the focus on natural language processing and recommender systems is not a central match to the user's primary research interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large language models (LLMs) are promising backbones for generative recommender systems, yet a key challenge remains underexplored: verbalization, i.e., converting structured user interaction logs into effective natural language inputs. Existing methods rely on rigid templates that simply concatenate fields, yielding suboptimal representations for recommendation. We propose a data-centric framework that learns verbalization for LLM-based recommendation. Using reinforcement learning, a verbalization agent transforms raw interaction histories into optimized textual contexts, with recommendation accuracy as the training signal. This agent learns to filter noise, incorporate relevant metadata, and reorganize information to improve downstream predictions. Experiments on a large-scale industrial streaming dataset show that learned verbalization delivers up to 93% relative improvement in discovery item recommendation accuracy over template-based baselines. Further analysis reveals emergent strategies such as user interest summarization, noise removal, and syntax normalization, offering insights into effective context construction for LLM-based recommender systems.

### 14. Multi-Vector Index Compression in Any Modality

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Hanxiang Qin, Alexander Martin, Rohan Jha, Chunsheng Zuo, Reno Kriz, Benjamin Van Durme
- **URL**: <http://arxiv.org/abs/2602.21202v1>
- **Submitted**: 2026-02-24 18:57:33
- **Comment**: 12 pages, 4 figures
- **Topic Keywords**: information retrieval, query, rag, retrieval
- **Reason**: This paper is somewhat related to information retrieval, but its focus on multi-vector retrieval and index compression in various modalities does not directly align with your core research themes of query understanding, ranking models, and user behavior modeling. While it touches on semantic understanding, the context is more about efficient retrieval and storage rather than real-time relevance optimization.

#### Abstract
> We study efficient multi-vector retrieval for late interaction in any modality. Late interaction has emerged as a dominant paradigm for information retrieval in text, images, visual documents, and videos, but its computation and storage costs grow linearly with document length, making it costly for image-, video-, and audio-rich corpora. To address this limitation, we explore query-agnostic methods for compressing multi-vector document representations under a constant vector budget. We introduce four approaches for index compression: sequence resizing, memory tokens, hierarchical pooling, and a novel attention-guided clustering (AGC). AGC uses an attention-guided mechanism to identify the most semantically salient regions of a document as cluster centroids and to weight token aggregation. Evaluating these methods on retrieval tasks spanning text (BEIR), visual-document (ViDoRe), and video (MSR-VTT, MultiVENT 2.0), we show that attention-guided clustering consistently outperforms other parameterized compression methods (sequence resizing and memory tokens), provides greater flexibility in index size than non-parametric hierarchical clustering, and achieves competitive or improved performance compared to a full, uncompressed index. The source code is available at: github.com/hanxiangqin/omni-col-press.

### 15. HiSAC: Hierarchical Sparse Activation Compression for Ultra-long Sequence Modeling in Recommenders

- **LLM Score**: 4
- **Keyword Score**: 10
- **Authors**: Kun Yuan, Junyu Bi, Daixuan Cheng, Changfa Wu, Shuwen Xiao, Binbin Cao, Jian Wu, Yuning Jiang
- **URL**: <http://arxiv.org/abs/2602.21009v1>
- **Submitted**: 2026-02-24 15:28:58
- **Topic Keywords**: ltr, rag, user behavior, ctr, recommend
- **Reason**: The paper discusses recommender systems and ultra-long sequence modeling, which is somewhat related to the user's interests in Information Retrieval and Search technologies. However, the focus on recommender systems and the specific application to e-commerce (Taobao) limits its relevance to the user's broader interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Modern recommender systems leverage ultra-long user behavior sequences to capture dynamic preferences, but end-to-end modeling is infeasible in production due to latency and memory constraints. While summarizing history via interest centers offers a practical alternative, existing methods struggle to (1) identify user-specific centers at appropriate granularity and (2) accurately assign behaviors, leading to quantization errors and loss of long-tail preferences. To alleviate these issues, we propose Hierarchical Sparse Activation Compression (HiSAC), an efficient framework for personalized sequence modeling. HiSAC encodes interactions into multi-level semantic IDs and constructs a global hierarchical codebook. A hierarchical voting mechanism sparsely activates personalized interest-agents as fine-grained preference centers. Guided by these agents, Soft-Routing Attention aggregates historical signals in semantic space, weighting by similarity to minimize quantization error and retain long-tail behaviors. Deployed on Taobao's "Guess What You Like" homepage, HiSAC achieves significant compression and cost reduction, with online A/B tests showing a consistent 1.65% CTR uplift -- demonstrating its scalability and real-world effectiveness.

### 16. E-MMKGR: A Unified Multimodal Knowledge Graph Framework for E-commerce Applications

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Jiwoo Kang, Yeon-Chang Lee
- **URL**: <http://arxiv.org/abs/2602.20877v1>
- **Submitted**: 2026-02-24 13:19:42
- **Topic Keywords**: rag, retrieval, recommend, commerce, e-commerce, search
- **Reason**: The paper proposes a multimodal knowledge graph framework for e-commerce applications, which is somewhat related to information retrieval and search technologies, but its focus on recommender systems and knowledge graph construction does not align with the user's primary interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Multimodal recommender systems (MMRSs) enhance collaborative filtering by leveraging item-side modalities, but their reliance on a fixed set of modalities and task-specific objectives limits both modality extensibility and task generalization. We propose E-MMKGR, a framework that constructs an e-commerce-specific Multimodal Knowledge Graph E-MMKG and learns unified item representations through GNN-based propagation and KG-oriented optimization. These representations provide a shared semantic foundation applicable to diverse tasks. Experiments on real-world Amazon datasets show improvements of up to 10.18% in Recall@10 for recommendation and up to 21.72% over vector-based retrieval for product search, demonstrating the effectiveness and extensibility of our approach.

### 17. No One Size Fits All: QueryBandits for Hallucination Mitigation

- **LLM Score**: 4
- **Keyword Score**: 8
- **Authors**: Nicole Cho, William Watson, Alec Koppel, Sumitra Ganesh, Manuela Veloso
- **URL**: <http://arxiv.org/abs/2602.20332v1>
- **Submitted**: 2026-02-23 20:28:48
- **Topic Keywords**: query, queries, rag
- **Reason**: The paper explores query rewriting and hallucination mitigation in Large Language Models, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on closed-source models and contextual bandit frameworks is not directly aligned with the user's primary research interests in IR and NLP.

#### Abstract
> Advanced reasoning capabilities in Large Language Models (LLMs) have led to more frequent hallucinations; yet most mitigation work focuses on open-source models for post-hoc detection and parameter editing. The dearth of studies focusing on hallucinations in closed-source models is especially concerning, as they constitute the vast majority of models in institutional deployments. We introduce QueryBandits, a model-agnostic contextual bandit framework that adaptively learns online to select the optimal query-rewrite strategy by leveraging an empirically validated and calibrated reward function. Across 16 QA scenarios, our top QueryBandit (Thompson Sampling) achieves an 87.5% win rate over a No-Rewrite baseline and outperforms zero-shot static policies (e.g., Paraphrase or Expand) by 42.6% and 60.3%, respectively. Moreover, all contextual bandits outperform vanilla bandits across all datasets, with higher feature variance coinciding with greater variance in arm selection. This substantiates our finding that there is no single rewrite policy optimal for all queries. We also discover that certain static policies incur higher cumulative regret than No-Rewrite, indicating that an inflexible query-rewriting policy can worsen hallucinations. Thus, learning an online policy over semantic features with QueryBandits can shift model behavior purely through forward-pass mechanisms, enabling its use with closed-source models and bypassing the need for retraining or gradient-based adaptation.

### 18. IntRR: A Framework for Integrating SID Redistribution and Length Reduction

- **LLM Score**: 4
- **Keyword Score**: 7
- **Authors**: Zesheng Wang, Longfei Xu, Weidong Deng, Huimin Yan, Kaikui Liu, Xiangxiang Chu
- **URL**: <http://arxiv.org/abs/2602.20704v1>
- **Submitted**: 2026-02-24 09:09:40
- **Topic Keywords**: ranking, rag, recommend, rank
- **Reason**: The paper discusses a framework for improving generative recommendation systems by redistributing semantic IDs and reducing sequence length. While it touches on aspects of information retrieval and ranking models, its primary focus is on recommender systems, which is a related but secondary interest of yours. The paper's emphasis on semantic understanding and optimization is relevant, but not central to your core research themes.

#### Abstract
> Generative Recommendation (GR) has emerged as a transformative paradigm that reformulates the traditional cascade ranking system into a sequence-to-item generation task, facilitated by the use of discrete Semantic IDs (SIDs). However, current SIDs are suboptimal as the indexing objectives (Stage 1) are misaligned with the actual recommendation goals (Stage 2). Since these identifiers remain static (Stage 2), the backbone model lacks the flexibility to adapt them to the evolving complexities of user interactions. Furthermore, the prevailing strategy of flattening hierarchical SIDs into token sequences leads to sequence length inflation, resulting in prohibitive computational overhead and inference latency. To address these challenges, we propose IntRR, a novel framework that integrates objective-aligned SID Redistribution and structural Length Reduction. By leveraging item-specific Unique IDs (UIDs) as collaborative anchors, this approach dynamically redistributes semantic weights across hierarchical codebook layers. Concurrently, IntRR handles the SID hierarchy recursively, eliminating the need to flatten sequences. This ensures a fixed cost of one token per item. Extensive experiments on benchmark datasets demonstrate that IntRR yields substantial improvements over representative generative baselines, achieving superior performance in both recommendation accuracy and efficiency.

### 19. PreScience: A Benchmark for Forecasting Scientific Contributions

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Anirudh Ajith, Amanpreet Singh, Jay DeYoung, Nadav Kunievsky, Austin C. Kozlowski, Oyvind Tafjord, James Evans, Daniel S. Weld, Tom Hope, Doug Downey
- **URL**: <http://arxiv.org/abs/2602.20459v1>
- **Submitted**: 2026-02-24 01:37:53
- **Comment**: 10 pages (53 with bibliography and appendix), 4 figures (13 with appendix), 4 tables (10 with appendix), 1 algorithm
- **Topic Keywords**: rag, search
- **Reason**: This paper introduces a benchmark for forecasting scientific contributions, which is somewhat related to information retrieval, particularly in the context of query understanding and ranking models. However, the focus on scientific forecasting and collaboration prediction is not directly aligned with the user's core research themes. The use of LLMs and evaluation metrics is relevant to the user's interests in NLP and data mining.

#### Abstract
> Can AI systems trained on the scientific record up to a fixed point in time forecast the scientific advances that follow? Such a capability could help researchers identify collaborators and impactful research directions, and anticipate which problems and methods will become central next. We introduce PreScience -- a scientific forecasting benchmark that decomposes the research process into four interdependent generative tasks: collaborator prediction, prior work selection, contribution generation, and impact prediction. PreScience is a carefully curated dataset of 98K recent AI-related research papers, featuring disambiguated author identities, temporally aligned scholarly metadata, and a structured graph of companion author publication histories and citations spanning 502K total papers. We develop baselines and evaluations for each task, including LACERScore, a novel LLM-based measure of contribution similarity that outperforms previous metrics and approximates inter-annotator agreement. We find substantial headroom remains in each task -- e.g. in contribution generation, frontier LLMs achieve only moderate similarity to the ground-truth (GPT-5, averages 5.6 on a 1-10 scale). When composed into a 12-month end-to-end simulation of scientific production, the resulting synthetic corpus is systematically less diverse and less novel than human-authored research from the same period.

### 20. The Art of Efficient Reasoning: Data, Reward, and Optimization

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Taiqiang Wu, Zenan Xu, Bo Zhou, Ngai Wong
- **URL**: <http://arxiv.org/abs/2602.20945v2>
- **Submitted**: 2026-02-24 14:28:16
- **Comment**: Tech Report, Insights on Efficient Reasoning via Reward Shaping
- **Topic Keywords**: ctr
- **Reason**: The paper explores efficient reasoning in Large Language Models (LLMs) using Reinforcement Learning (RL) and reward shaping. While it touches on optimization strategies, it doesn't directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> Large Language Models (LLMs) consistently benefit from scaled Chain-of-Thought (CoT) reasoning, but also suffer from heavy computational overhead. To address this issue, efficient reasoning aims to incentivize short yet accurate thinking trajectories, typically through reward shaping with Reinforcement Learning (RL). In this paper, we systematically investigate the mechanics of efficient reasoning for LLMs. For comprehensive evaluation, we advocate for more fine-grained metrics, including length distribution conditioned on correctness and performance across a wide spectrum of token budgets ranging from 2k to 32k. First, we reveal that the training process follows a two-stage paradigm: length adaptation and reasoning refinement. After that, we conduct extensive experiments (about 0.2 million GPU hours) in a unified protocol, deconstructing training prompts and rollouts, reward shaping, and optimization strategies. In particular, a key finding is to train on relatively easier prompts, ensuring the density of positive reward signals and thus avoiding the length collapse. Meanwhile, the learned length bias can be generalized across domains. We distill all findings into valuable insights and practical guidelines, and further validate them across the Qwen3 series, ranging from 0.6B to 30B, demonstrating the robustness and generalization.

### 21. Semantic Novelty at Scale: Narrative Shape Taxonomy and Readership Prediction in 28,606 Books

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: W. Frederick Zimmerman
- **URL**: <http://arxiv.org/abs/2602.20647v1>
- **Submitted**: 2026-02-24 07:52:35
- **Comment**: six figures. dataset available at Hugging Face
- **Topic Keywords**: rag
- **Reason**: This paper explores narrative structure and reader engagement through semantic novelty measures, which is somewhat related to information retrieval and deep semantic understanding. However, the focus is on narrative shape and readership prediction, rather than search technologies or query understanding, limiting its relevance to your core research themes.

#### Abstract
> I introduce semantic novelty--cosine distance between each paragraph's sentence embedding and the running centroid of all preceding paragraphs--as an information-theoretic measure of narrative structure at corpus scale. Applying it to 28,606 books in PG19 (pre-1920 English literature), I compute paragraph-level novelty curves using 768-dimensional SBERT embeddings, then reduce each to a 16-segment Piecewise Aggregate Approximation (PAA). Ward-linkage clustering on PAA vectors reveals eight canonical narrative shape archetypes, from Steep Descent (rapid convergence) to Steep Ascent (escalating unpredictability). Volume--variance of the novelty trajectory--is the strongest length-independent predictor of readership (partial rho = 0.32), followed by speed (rho = 0.19) and Terminal/Initial ratio (rho = 0.19). Circuitousness shows strong raw correlation (rho = 0.41) but is 93 percent correlated with length; after control, partial rho drops to 0.11--demonstrating that naive correlations in corpus studies can be dominated by length confounds. Genre strongly constrains narrative shape (chi squared = 2121.6, p < 10 to the power negative 242), with fiction maintaining plateau profiles while nonfiction front-loads information. Historical analysis shows books became progressively more predictable between 1840 and 1910 (T/I ratio trend r = negative 0.74, p = 0.037). SAX analysis reveals 85 percent signature uniqueness, suggesting each book traces a nearly unique path through semantic space. These findings demonstrate that information-density dynamics, distinct from sentiment or topic, constitute a fundamental dimension of narrative structure with measurable consequences for reader engagement. Dataset: https://huggingface.co/datasets/wfzimmerman/pg19-semantic-novelty

### 22. GATES: Self-Distillation under Privileged Context with Consensus Gating

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Alex Stein, Furong Huang, Tom Goldstein
- **URL**: <http://arxiv.org/abs/2602.20574v1>
- **Submitted**: 2026-02-24 05:56:20
- **Comment**: 10 Pages of main text with an additional 7 pages of supplementary material
- **Topic Keywords**: rag
- **Reason**: The paper explores self-distillation in question answering, which is somewhat related to query understanding and ranking models in Information Retrieval. However, the focus on document-grounded question answering and consensus gating is not directly aligned with the user's primary research interests in IR and NLP. While the paper touches on aspects of deep semantic understanding, its primary contribution is in the context of question answering rather than search technologies.

#### Abstract
> We study self-distillation in settings where supervision is unreliable: there are no ground truth labels, verifiable rewards, or external graders to evaluate answers. We focus on document-grounded question answering with asymmetric context, where a single model serves as both tutor (with access to a relevant source document during training) and student (answering from the question alone at test time). Rather than assuming tutor correctness, we derive supervision online from tutor consensus by sampling multiple document-grounded reasoning traces and using agreement to gate learning. Conditioned on this reliability signal, we distill knowledge through full tutor reasoning trajectories (not just final answers), providing a dense and stable learning signal. Empirically, this consensus-gated trajectory distillation substantially improves transfer to the document-free student. Held-out in-domain accuracy under asymmetric evaluation improves from 46.0\% to 62.0\%, and average (maj@8) accuracy on public document-free math benchmarks improves from 20.2\% to 35.4\%.

### 23. PVminer: A Domain-Specific Tool to Detect the Patient Voice in Patient Generated Data

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Samah Fodeh, Linhai Ma, Yan Wang, Srivani Talakokkul, Ganesh Puthiaraju, Afshan Khan, Ashley Hagaman, Sarah Lowe, Aimee Roundtree
- **URL**: <http://arxiv.org/abs/2602.21165v1>
- **Submitted**: 2026-02-24 18:10:00
- **Topic Keywords**: search
- **Reason**: The paper PVminer is somewhat related to your research interests in Natural Language Processing (NLP) and information retrieval, particularly in the context of patient-generated data and secure patient-provider communication. However, it focuses on a specific domain (healthcare) and task (patient voice detection), which is not a central match with your broader interests in e-commerce, query understanding, and ranking models.

#### Abstract
> Patient-generated text such as secure messages, surveys, and interviews contains rich expressions of the patient voice (PV), reflecting communicative behaviors and social determinants of health (SDoH). Traditional qualitative coding frameworks are labor intensive and do not scale to large volumes of patient-authored messages across health systems. Existing machine learning (ML) and natural language processing (NLP) approaches provide partial solutions but often treat patient-centered communication (PCC) and SDoH as separate tasks or rely on models not well suited to patient-facing language. We introduce PVminer, a domain-adapted NLP framework for structuring patient voice in secure patient-provider communication. PVminer formulates PV detection as a multi-label, multi-class prediction task integrating patient-specific BERT encoders (PV-BERT-base and PV-BERT-large), unsupervised topic modeling for thematic augmentation (PV-Topic-BERT), and fine-tuned classifiers for Code, Subcode, and Combo-level labels. Topic representations are incorporated during fine-tuning and inference to enrich semantic inputs. PVminer achieves strong performance across hierarchical tasks and outperforms biomedical and clinical pre-trained baselines, achieving F1 scores of 82.25% (Code), 80.14% (Subcode), and up to 77.87% (Combo). An ablation study further shows that author identity and topic-based augmentation each contribute meaningful gains. Pre-trained models, source code, and documentation will be publicly released, with annotated datasets available upon request for research use.

### 24. An Expert Schema for Evaluating Large Language Model Errors in Scholarly Question-Answering Systems

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Anna Martin-Boyle, William Humphreys, Martha Brown, Cara Leckey, Harmanpreet Kaur
- **URL**: <http://arxiv.org/abs/2602.21059v1>
- **Submitted**: 2026-02-24 16:16:44
- **Comment**: 24 pages, 2 figures. Accepted at ACM CHI conference on Human Factors in Computing Systems, 2026
- **Topic Keywords**: search
- **Reason**: This paper is somewhat related to your research interests in Information Retrieval and Natural Language Processing, particularly in the context of Large Language Models and evaluation metrics. However, the focus on scholarly question-answering systems and expert schema for evaluating LLM errors is not directly aligned with your primary interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large Language Models (LLMs) are transforming scholarly tasks like search and summarization, but their reliability remains uncertain. Current evaluation metrics for testing LLM reliability are primarily automated approaches that prioritize efficiency and scalability, but lack contextual nuance and fail to reflect how scientific domain experts assess LLM outputs in practice. We developed and validated a schema for evaluating LLM errors in scholarly question-answering systems that reflects the assessment strategies of practicing scientists. In collaboration with domain experts, we identified 20 error patterns across seven categories through thematic analysis of 68 question-answer pairs. We validated this schema through contextual inquiries with 10 additional scientists, which showed not only which errors experts naturally identify but also how structured evaluation schemas can help them detect previously overlooked issues. Domain experts use systematic assessment strategies, including technical precision testing, value-based evaluation, and meta-evaluation of their own practices. We discuss implications for supporting expert evaluation of LLM outputs, including opportunities for personalized, schema-driven tools that adapt to individual evaluation patterns and expertise levels.

### 25. Position-Aware Sequential Attention for Accurate Next Item Recommendations

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Timur Nabiev, Evgeny Frolov
- **URL**: <http://arxiv.org/abs/2602.21052v1>
- **Submitted**: 2026-02-24 16:09:47
- **Topic Keywords**: recommend
- **Reason**: This paper focuses on recommender systems, specifically introducing a new attention mechanism for sequential modeling. While it touches on sequential patterns, it does not directly relate to information retrieval, query understanding, or ranking models, which are core areas of interest. The paper's emphasis on recommender systems and next-item prediction makes it somewhat relevant but not a central match for your research interests.

#### Abstract
> Sequential self-attention models usually rely on additive positional embeddings, which inject positional information into item representations at the input. In the absence of positional signals, the attention block is permutation-equivariant over sequence positions and thus has no intrinsic notion of temporal order beyond causal masking. We argue that additive positional embeddings make the attention mechanism only superficially sensitive to sequence order: positional information is entangled with item embedding semantics, propagates weakly in deep architectures, and limits the ability to capture rich sequential patterns. To address these limitations, we introduce a kernelized self-attention mechanism, where a learnable positional kernel operates purely in the position space, disentangled from semantic similarity, and directly modulates attention weights. When applied per attention block, this kernel enables adaptive multi-scale sequential modeling. Experiments on standard next-item prediction benchmarks show that our positional kernel attention consistently improves over strong competing baselines.

### 26. PaperTrail: A Claim-Evidence Interface for Grounding Provenance in LLM-based Scholarly Q&A

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Anna Martin-Boyle, Cara A. C. Leckey, Martha C. Brown, Harmanpreet Kaur
- **URL**: <http://arxiv.org/abs/2602.21045v1>
- **Submitted**: 2026-02-24 16:04:50
- **Comment**: 25 pages, 3 figures. Accepted at the ACM CHI conference on Human Factors in Computing Systems 2026
- **Topic Keywords**: search
- **Reason**: The paper explores the use of large language models in scholarly question-answering systems, which is somewhat related to information retrieval and search technologies. However, the focus on claim-evidence matching and provenance in scholarly settings is not directly aligned with the user's core research themes of query understanding, ranking models, and user behavior modeling. While it touches on NLP, the connection is not strong enough to warrant a higher score.

#### Abstract
> Large language models (LLMs) are increasingly used in scholarly question-answering (QA) systems to help researchers synthesize vast amounts of literature. However, these systems often produce subtle errors (e.g., unsupported claims, errors of omission), and current provenance mechanisms like source citations are not granular enough for the rigorous verification that scholarly domain requires. To address this, we introduce PaperTrail, a novel interface that decomposes both LLM answers and source documents into discrete claims and evidence, mapping them to reveal supported assertions, unsupported claims, and information omitted from the source texts. We evaluated PaperTrail in a within-subjects study with 26 researchers who performed two scholarly editing tasks using PaperTrail and a baseline interface. Our results show that PaperTrail significantly lowered participants' trust compared to the baseline. However, this increased caution did not translate to behavioral changes, as people continued to rely on LLM-generated scholarly edits to avoid a cognitively burdensome task. We discuss the value of claim-evidence matching for understanding LLM trustworthiness in scholarly settings, and present design implications for cognition-friendly communication of provenance information.

### 27. Overton Pluralistic Reinforcement Learning for Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Yu Fu, Seongho Son, Ilija Bogunovic
- **URL**: <http://arxiv.org/abs/2602.20759v1>
- **Submitted**: 2026-02-24 10:39:27
- **Comment**: 28 pages, 8 figures
- **Topic Keywords**: query, rag
- **Reason**: This paper focuses on large language models and pluralistic reinforcement learning, which is somewhat related to the user's interests in NLP and deep semantic understanding. However, the paper's primary focus on large language models and pluralistic responses does not directly align with the user's core research themes in Information Retrieval, query understanding, and ranking models.

#### Abstract
> Existing alignment paradigms remain limited in capturing the pluralistic nature of human values. Overton Pluralism addresses this gap by generating responses with diverse perspectives from a single query. This paper introduces OP-GRPO (Overton Pluralistic Group Relative Policy Optimization), a reinforcement learning framework for implicit Overton Pluralism that enables a single large language model to produce pluralistic responses without explicit prompting or modular orchestration. Our workflow consists of two main steps. First, similarity estimator training fine-tunes a Sentence Transformer for Overton Pluralism tasks to provide more accurate coverage evaluation of generated responses. Second, OP-GRPO training incorporates this similarity estimator into a dual-reward system designed to ensure both broad coverage of genuine human perspectives and the uniqueness of each perspective, thereby promoting diversity. Empirical results demonstrate a "small models, big perspective coverage" effect. The trained Qwen2.5-3B-Instruct model surpasses a 20B GPT-OSS baseline with a 37.4 percent relative accuracy gain on a Natural Language Inference benchmark, and also outperforms a modular architecture baseline with a 19.1 percent relative improvement. Additional evaluations using GPT-4.1 as a large language model judge further confirm the robustness of the approach.

### 28. InterviewSim: A Scalable Framework for Interview-Grounded Personality Simulation

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Yu Li, Pranav Narayanan Venkit, Yada Pruksachatkun, Chien-Sheng Wu
- **URL**: <http://arxiv.org/abs/2602.20294v1>
- **Submitted**: 2026-02-23 19:21:10
- **Topic Keywords**: rag, retrieval, search
- **Reason**: This paper is not directly related to Information Retrieval, Search technologies, or query understanding, ranking models, or user behavior modeling. While it involves Natural Language Processing and data mining, its focus on personality simulation and interview-grounded evaluation is not a central match to your research interests.

#### Abstract
> Simulating real personalities with large language models requires grounding generation in authentic personal data. Existing evaluation approaches rely on demographic surveys, personality questionnaires, or short AI-led interviews as proxies, but lack direct assessment against what individuals actually said. We address this gap with an interview-grounded evaluation framework for personality simulation at a large scale. We extract over 671,000 question-answer pairs from 23,000 verified interview transcripts across 1,000 public personalities, each with an average of 11.5 hours of interview content. We propose a multi-dimensional evaluation framework with four complementary metrics measuring content similarity, factual consistency, personality alignment, and factual knowledge retention. Through systematic comparison, we demonstrate that methods grounded in real interview data substantially outperform those relying solely on biographical profiles or the model's parametric knowledge. We further reveal a trade-off in how interview data is best utilized: retrieval-augmented methods excel at capturing personality style and response quality, while chronological-based methods better preserve factual consistency and knowledge retention. Our evaluation framework enables principled method selection based on application requirements, and our empirical findings provide actionable insights for advancing personality simulation research.

### 29. An artificial intelligence framework for end-to-end rare disease phenotyping from clinical notes using large language models

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Cathy Shyr, Yan Hu, Rory J. Tinker, Thomas A. Cassini, Kevin W. Byram, Rizwan Hamid, Daniel V. Fabbri, Adam Wright, Josh F. Peterson, Lisa Bastarache, Hua Xu
- **URL**: <http://arxiv.org/abs/2602.20324v1>
- **Submitted**: 2026-02-23 20:20:23
- **Topic Keywords**: ranking, rank
- **Reason**: This paper focuses on rare disease phenotyping from clinical notes using large language models, which is not directly related to your core research themes in Information Retrieval, Search technologies, and Natural Language Processing. While it involves NLP, the application domain is quite different from your e-commerce background and interests in real-time relevance optimization.

#### Abstract
> Phenotyping is fundamental to rare disease diagnosis, but manual curation of structured phenotypes from clinical notes is labor-intensive and difficult to scale. Existing artificial intelligence approaches typically optimize individual components of phenotyping but do not operationalize the full clinical workflow of extracting features from clinical text, standardizing them to Human Phenotype Ontology (HPO) terms, and prioritizing diagnostically informative HPO terms. We developed RARE-PHENIX, an end-to-end AI framework for rare disease phenotyping that integrates large language model-based phenotype extraction, ontology-grounded standardization to HPO terms, and supervised ranking of diagnostically informative phenotypes. We trained RARE-PHENIX using data from 2,671 patients across 11 Undiagnosed Diseases Network clinical sites, and externally validated it on 16,357 real-world clinical notes from Vanderbilt University Medical Center. Using clinician-curated HPO terms as the gold standard, RARE-PHENIX consistently outperformed a state-of-the-art deep learning baseline (PhenoBERT) across ontology-based similarity and precision-recall-F1 metrics in end-to-end evaluation (i.e., ontology-based similarity of 0.70 vs. 0.58). Ablation analyses demonstrated performance improvements with the addition of each module in RARE-PHENIX (extraction, standardization, and prioritization), supporting the value of modeling the full clinical phenotyping workflow. By modeling phenotyping as a clinically aligned workflow rather than a single extraction task, RARE-PHENIX provides structured, ranked phenotypes that are more concordant with clinician curation and has the potential to support human-in-the-loop rare disease diagnosis in real-world settings.

### 30. Evaluating Proactive Risk Awareness of Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Xuan Luo, Yubin Chen, Zhiyu Hou, Linpu Yu, Geng Tu, Jing Li, Ruifeng Xu
- **URL**: <http://arxiv.org/abs/2602.20976v1>
- **Submitted**: 2026-02-24 15:00:00
- **Topic Keywords**: queries
- **Reason**: This paper focuses on the safety and responsibility of large language models, particularly in the environmental and ecological domain. While it touches on the broader theme of AI decision-making, it does not directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of interest. The paper's emphasis on proactive risk awareness and safety alignment is not a central match for the user's research themes.

#### Abstract
> As large language models (LLMs) are increasingly embedded in everyday decision-making, their safety responsibilities extend beyond reacting to explicit harmful intent toward anticipating unintended but consequential risks. In this work, we introduce a proactive risk awareness evaluation framework that measures whether LLMs can anticipate potential harms and provide warnings before damage occurs. We construct the Butterfly dataset to instantiate this framework in the environmental and ecological domain. It contains 1,094 queries that simulate ordinary solution-seeking activities whose responses may induce latent ecological impact. Through experiments across five widely used LLMs, we analyze the effects of response length, languages, and modality. Experimental results reveal consistent, significant declines in proactive awareness under length-restricted responses, cross-lingual similarities, and persistent blind spots in (multimodal) species protection. These findings highlight a critical gap between current safety alignment and the requirements of real-world ecological responsibility, underscoring the need for proactive safeguards in LLM deployment.

### 31. Linear Reasoning vs. Proof by Cases: Obstacles for Large Language Models in FOL Problem Solving

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Yuliang Ji, Fuchen Shen, Jian Wu, Qiujie Xie, Yue Zhang
- **URL**: <http://arxiv.org/abs/2602.20973v1>
- **Submitted**: 2026-02-24 14:53:34
- **Topic Keywords**: search, acl
- **Reason**: This paper focuses on the evaluation of Large Language Models' mathematical reasoning capabilities using first-order logic and case-based reasoning problems. While it touches on natural language processing, it is primarily concerned with mathematical reasoning and proof generation, which is not a central match for your research interests in Information Retrieval and Search technologies.

#### Abstract
> To comprehensively evaluate the mathematical reasoning capabilities of Large Language Models (LLMs), researchers have introduced abundant mathematical reasoning datasets. However, most existing datasets primarily focus on linear reasoning, neglecting other parts such as proof by contradiction and proof by cases, which are crucial for investigating LLMs' reasoning abilities. To address this limitation, we first introduce a novel first-order logic (FOL) dataset named PC-FOL, annotated by professional mathematicians, focusing on case-based reasoning problems. All instances in this dataset are equipped with a manually written natural language proof, clearly distinguishing it from conventional linear reasoning datasets. Our experimental results over leading LLMs demonstrate a substantial performance gap between linear reasoning and case-based reasoning problems. To further investigate this phenomenon, we provide a theoretical analysis grounded in graphical model, which provides an explanation for the observed disparity between the two types of reasoning problems. We hope this work can reveal the core challenges in the field of automated natural language mathematical proof generation, paving the way for future research.

### 32. Protein Language Models Diverge from Natural Language: Comparative Analysis and Improved Inference

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Anna Hart, Chi Han, Jeonghwan Kim, Huimin Zhao, Heng Ji
- **URL**: <http://arxiv.org/abs/2602.20449v1>
- **Submitted**: 2026-02-24 01:18:30
- **Topic Keywords**: rag, search
- **Reason**: This paper is not relevant to your research interests as it focuses on protein language models and their application in the biological domain, which is outside your primary areas of interest in Information Retrieval, Search technologies, and Natural Language Processing.

#### Abstract
> Modern Protein Language Models (PLMs) apply transformer-based model architectures from natural language processing to biological sequences, predicting a variety of protein functions and properties. However, protein language has key differences from natural language, such as a rich functional space despite a vocabulary of only 20 amino acids. These differences motivate research into how transformer-based architectures operate differently in the protein domain and how we can better leverage PLMs to solve protein-related tasks. In this work, we begin by directly comparing how the distribution of information stored across layers of attention heads differs between the protein and natural language domain. Furthermore, we adapt a simple early-exit technique-originally used in the natural language domain to improve efficiency at the cost of performance-to achieve both increased accuracy and substantial efficiency gains in protein non-structural property prediction by allowing the model to automatically select protein representations from the intermediate layers of the PLMs for the specific task and protein at hand. We achieve performance gains ranging from 0.4 to 7.01 percentage points while simultaneously improving efficiency by over 10 percent across models and non-structural prediction tasks. Our work opens up an area of research directly comparing how language models change behavior when moved into the protein domain and advances language modeling in biological domains.

### 33. Counterfactual Simulation Training for Chain-of-Thought Faithfulness

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Peter Hase, Christopher Potts
- **URL**: <http://arxiv.org/abs/2602.20710v1>
- **Submitted**: 2026-02-24 09:15:30
- **Topic Keywords**: rag
- **Reason**: This paper focuses on improving the faithfulness of Chain-of-Thought (CoT) reasoning in Large Language Models (LLMs), which is not directly related to Information Retrieval or Search technologies. While it touches on aspects of model behavior, it does not align with the user's core research themes.

#### Abstract
> Inspecting Chain-of-Thought reasoning is among the most common means of understanding why an LLM produced its output. But well-known problems with CoT faithfulness severely limit what insights can be gained from this practice. In this paper, we introduce a training method called Counterfactual Simulation Training (CST), which aims to improve CoT faithfulness by rewarding CoTs that enable a simulator to accurately predict a model's outputs over counterfactual inputs. We apply CST in two settings: (1) CoT monitoring with cue-based counterfactuals, to detect when models rely on spurious features, reward hack, or are sycophantic, and (2) counterfactual simulation over generic model-based counterfactuals, to encourage models to produce more faithful, generalizable reasoning in the CoT. Experiments with models up to 235B parameters show that CST can substantially improve monitor accuracy on cue-based counterfactuals (by 35 accuracy points) as well as simulatability over generic counterfactuals (by 2 points). We further show that: (1) CST outperforms prompting baselines, (2) rewriting unfaithful CoTs with an LLM is 5x more efficient than RL alone, (3) faithfulness improvements do not generalize to dissuading cues (as opposed to persuading cues), and (4) larger models do not show more faithful CoT out of the box, but they do benefit more from CST. These results suggest that CST can improve CoT faithfulness in general, with promising applications for CoT monitoring. Code for experiments in this paper is available at https://github.com/peterbhase/counterfactual-simulation-training

### 34. CAMEL: Confidence-Gated Reflection for Reward Modeling

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Zirui Zhu, Hailun Xu, Yang Luo, Yong Liu, Kanchan Sarkar, Kun Xu, Yang You
- **URL**: <http://arxiv.org/abs/2602.20670v1>
- **Submitted**: 2026-02-24 08:20:08
- **Comment**: Preprint. 13 pages
- **Topic Keywords**: rag
- **Reason**: This paper focuses on reward modeling for large language models, which is a topic related to NLP, but it does not directly align with your core research interests in Information Retrieval, Search technologies, and query understanding. While it involves some form of modeling, the context is not about search or e-commerce, and the techniques described are not directly applicable to your areas of focus.

#### Abstract
> Reward models play a fundamental role in aligning large language models with human preferences. Existing methods predominantly follow two paradigms: scalar discriminative preference models, which are efficient but lack interpretability, and generative judging models, which offer richer reasoning at the cost of higher computational overhead. We observe that the log-probability margin between verdict tokens strongly correlates with prediction correctness, providing a reliable proxy for instance difficulty without additional inference cost. Building on this insight, we propose CAMEL, a confidence-gated reflection framework that performs a lightweight single-token preference decision first and selectively invokes reflection only for low-confidence instances. To induce effective self-correction, we train the model via reinforcement learning with counterfactual prefix augmentation, which exposes the model to diverse initial verdicts and encourages genuine revision. Empirically, CAMEL achieves state-of-the-art performance on three widely used reward-model benchmarks with 82.9% average accuracy, surpassing the best prior model by 3.2% and outperforming 70B-parameter models using only 14B parameters, while establishing a strictly better accuracy-efficiency Pareto frontier.

### 35. Disentangling Geometry, Performance, and Training in Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Atharva Kulkarni, Jacob Mitchell Springer, Arjun Subramonian, Swabha Swayamdipta
- **URL**: <http://arxiv.org/abs/2602.20433v1>
- **Submitted**: 2026-02-24 00:31:04
- **Topic Keywords**: rank, search
- **Reason**: This paper focuses on language model interpretability and the geometric properties of Transformer weights, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it touches on NLP, the specific topics and methods explored are not aligned with your areas of focus.

#### Abstract
> Geometric properties of Transformer weights, particularly the unembedding matrix, have been widely useful in language model interpretability research. Yet, their utility for estimating downstream performance remains unclear. In this work, we systematically investigate the relationship between model performance and the unembedding matrix geometry, particularly its effective rank. Our experiments, involving a suite of 108 OLMo-style language models trained under controlled variation, reveal several key findings. While the best-performing models often exhibit a high effective rank, this trend is not universal across tasks and training setups. Contrary to prior work, we find that low effective rank does not cause late-stage performance degradation in small models, but instead co-occurs with it; we find adversarial cases where low-rank models do not exhibit saturation. Moreover, we show that effective rank is strongly influenced by pre-training hyperparameters, such as batch size and weight decay, which in-turn affect the model's performance. Lastly, extending our analysis to other geometric metrics and final-layer representation, we find that these metrics are largely aligned, but none can reliably predict downstream performance. Overall, our findings suggest that the model's geometry, as captured by existing metrics, primarily reflects training choices rather than performance.

### 36. MedCLIPSeg: Probabilistic Vision-Language Adaptation for Data-Efficient and Generalizable Medical Image Segmentation

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Taha Koleilat, Hojat Asgariandehkordi, Omid Nejati Manzari, Berardino Barile, Yiming Xiao, Hassan Rivaz
- **URL**: <http://arxiv.org/abs/2602.20423v1>
- **Submitted**: 2026-02-23 23:46:05
- **Comment**: CVPR 2026; Project Page: https://tahakoleilat.github.io/MedCLIPSeg
- **Topic Keywords**: rag
- **Reason**: This paper is not relevant to your research interests as it primarily focuses on medical image segmentation using vision-language models, which is outside your core areas of Information Retrieval, Search technologies, and Natural Language Processing. While it does involve text-guided processing, the application domain and methodology are not aligned with your research themes.

#### Abstract
> Medical image segmentation remains challenging due to limited annotations for training, ambiguous anatomical features, and domain shifts. While vision-language models such as CLIP offer strong cross-modal representations, their potential for dense, text-guided medical image segmentation remains underexplored. We present MedCLIPSeg, a novel framework that adapts CLIP for robust, data-efficient, and uncertainty-aware medical image segmentation. Our approach leverages patch-level CLIP embeddings through probabilistic cross-modal attention, enabling bidirectional interaction between image and text tokens and explicit modeling of predictive uncertainty. Together with a soft patch-level contrastive loss that encourages more nuanced semantic learning across diverse textual prompts, MedCLIPSeg effectively improves data efficiency and domain generalizability. Extensive experiments across 16 datasets spanning five imaging modalities and six organs demonstrate that MedCLIPSeg outperforms prior methods in accuracy, efficiency, and robustness, while providing interpretable uncertainty maps that highlight local reliability of segmentation results. This work demonstrates the potential of probabilistic vision-language modeling for text-driven medical image segmentation.

### 37. On Data Engineering for Scaling LLM Terminal Capabilities

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Renjie Pi, Grace Lam, Mohammad Shoeybi, Pooya Jannaty, Bryan Catanzaro, Wei Ping
- **URL**: <http://arxiv.org/abs/2602.21193v1>
- **Submitted**: 2026-02-24 18:51:04
- **Topic Keywords**: search
- **Reason**: This paper focuses on data engineering for scaling large language models (LLMs), which is not directly related to information retrieval, search technologies, or query understanding. While it involves NLP, the context is more about model training and optimization rather than real-time relevance optimization or deep semantic understanding.

#### Abstract
> Despite rapid recent progress in the terminal capabilities of large language models, the training data strategies behind state-of-the-art terminal agents remain largely undisclosed. We address this gap through a systematic study of data engineering practices for terminal agents, making two key contributions: (1) Terminal-Task-Gen, a lightweight synthetic task generation pipeline that supports seed-based and skill-based task construction, and (2) a comprehensive analysis of data and training strategies, including filtering, curriculum learning, long context training, and scaling behavior. Our pipeline yields Terminal-Corpus, a large-scale open-source dataset for terminal tasks. Using this dataset, we train Nemotron-Terminal, a family of models initialized from Qwen3(8B, 14B, 32B) that achieve substantial gains on Terminal-Bench 2.0: Nemotron-Terminal-8B improves from 2.5% to 13.0% Nemotron-Terminal-14B improves from 4.0% to 20.2%, and Nemotron-Terminal-32B improves from 3.4% to 27.4%, matching the performance of significantly larger models. To accelerate research in this domain, we open-source our model checkpoints and most of our synthetic datasets at https://huggingface.co/collections/nvidia/nemotron-terminal.

### 38. ID-LoRA: Efficient Low-Rank Adaptation Inspired by Matrix Interpolative Decomposition

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Xindian Ma, Rundong Kong, Peng Zhang, Ruoxiang Huang, Yongyu Jiang
- **URL**: <http://arxiv.org/abs/2602.20727v1>
- **Submitted**: 2026-02-24 09:45:10
- **Topic Keywords**: rank
- **Reason**: This paper focuses on Parameter-Efficient Fine-Tuning (PEFT) techniques for Large Language Models (LLMs), specifically proposing a novel framework called ID-LoRA. While it touches on model adaptation and parameter efficiency, it doesn't directly relate to information retrieval, search technologies, or user behavior modeling, which are core areas of your research interests.

#### Abstract
> LoRA has become a universal Parameter-Efficient Fine-Tuning (PEFT) technique that equips Large Language Models (LLMs) to adapt quickly to new tasks. However, when these models are scaled up, even the latest LoRA variants still introduce considerable overhead in trainable parameters. Conversely, aggressively lowering the rank to curb this overhead markedly degrades performance in complex multi-task settings. We propose ID-LoRA, a novel PEFT framework that breaks the trade-off. Its core innovation lies in extracting and reusing clustered parameter groups from the pretrained weight matrix. These groups are then used to form multiple low-rank components, all of which share only a single initialized trainable low-rank matrix. This approach cuts the number of trainable parameters while keeping the model's capacity intact. We evaluate ID-LoRA on five diverse benchmarks: Mathematical Reasoning, Code Generation, MMLU, CommonsenseQA, and Safety Alignment. ID-LoRA outperforms both full fine-tuning and existing PEFT baselines (e.g., LoRA, DoRA, HydraLoRA) while using up to 46% fewer trainable parameters than the standard LoRA. In multi-task scenarios, it surpasses LoRA and its recent variants (e.g., DoRA and HydraLoRA) on both Code and MMLU tasks, yet requires only 54% of the trainable parameters demanded by the conventional LoRA.

### 39. Personal Information Parroting in Language Models

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Nishant Subramani, Kshitish Ghate, Mona Diab
- **URL**: <http://arxiv.org/abs/2602.20580v1>
- **Submitted**: 2026-02-24 06:02:03
- **Comment**: EACL Findings 2026
- **Topic Keywords**: recommend
- **Reason**: This paper is not directly related to your research interests in Information Retrieval, Search technologies, or Natural Language Processing. While it involves language models, the focus is on detecting and minimizing personal information memorization, which is not a central theme in your research.

#### Abstract
> Modern language models (LM) are trained on large scrapes of the Web, containing millions of personal information (PI) instances, many of which LMs memorize, increasing privacy risks. In this work, we develop the regexes and rules (R&R) detector suite to detect email addresses, phone numbers, and IP addresses, which outperforms the best regex-based PI detectors. On a manually curated set of 483 instances of PI, we measure memorization: finding that 13.6% are parroted verbatim by the Pythia-6.9b model, i.e., when the model is prompted with the tokens that precede the PI in the original document, greedy decoding generates the entire PI span exactly. We expand this analysis to study models of varying sizes (160M-6.9B) and pretraining time steps (70k-143k iterations) in the Pythia model suite and find that both model size and amount of pretraining are positively correlated with memorization. Even the smallest model, Pythia-160m, parrots 2.7% of the instances exactly. Consequently, we strongly recommend that pretraining datasets be aggressively filtered and anonymized to minimize PI parroting.

### 40. Inner Speech as Behavior Guides: Steerable Imitation of Diverse Behaviors for Human-AI coordination

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Rakshit Trivedi, Kartik Sharma, David C Parkes
- **URL**: <http://arxiv.org/abs/2602.20517v1>
- **Submitted**: 2026-02-24 03:37:42
- **Comment**: Spotlight paper at NeurIPS 2025
- **Topic Keywords**: search
- **Reason**: This paper focuses on human-AI coordination and imitation learning, which is not directly related to your core research interests in Information Retrieval, Search technologies, and Natural Language Processing. While it involves some NLP aspects, the primary application is in robotics and human-AI collaboration, making it somewhat tangential to your research areas.

#### Abstract
> Effective human-AI coordination requires artificial agents capable of exhibiting and responding to human-like behaviors while adapting to changing contexts. Imitation learning has emerged as one of the prominent approaches to build such agents by training them to mimic human-demonstrated behaviors. However, current methods struggle to capture the inherent diversity and non-Markovian nature of human behavior and lack the ability to steer behavior at inference time. Drawing inspiration from the theory of human cognitive processes, where inner speech guides action selection before execution, we propose MIMIC (Modeling Inner Motivations for Imitation and Control), a framework that uses language as an internal representation of behavioral intent. MIMIC employs the novel use of vision-language models as linguistic scaffolding to train a conditional variational autoencoder capable of generating inner speech from observations. A diffusion-based behavior cloning policy then selects actions conditioned on current observations and the generated inner speech. MIMIC enables fine-grained steering of behavior at inference time by conditioning the agent on behavior-specific speech. Experiments across robotic manipulation tasks and human-AI collaboration games demonstrate that MIMIC significantly enhances both behavior diversity and fidelity to human demonstrations while enabling nuanced behavioral steering without training on additional demonstrations. We open source our code and provide pre-trained MIMIC agents and qualitative demos at: https://mimic-research.github.io.

### 41. How communicatively optimal are exact numeral systems? Once more on lexicon size and morphosyntactic complexity

- **LLM Score**: 0
- **Keyword Score**: 3
- **Authors**: Chundra Cathcart, Arne Rubehn, Katja Bocklage, Luca Ciucci, Kellen Parker van Dam, Al≈æbƒõta Kuƒçerov√°, Jekaterina Ma≈æara, Carlo Y. Meloni, David Snee, Johann-Mattis List
- **URL**: <http://arxiv.org/abs/2602.20372v1>
- **Submitted**: 2026-02-23 21:19:07
- **Topic Keywords**: rag, search
- **Reason**: This paper is not related to Information Retrieval, Search technologies, query understanding, ranking models, user behavior modeling, or Natural Language Processing, which are the primary areas of interest. The focus on linguistic evolution and numeral systems in languages is outside the scope of the user's research.

#### Abstract
> Recent research argues that exact recursive numeral systems optimize communicative efficiency by balancing a tradeoff between the size of the numeral lexicon and the average morphosyntactic complexity (roughly length in morphemes) of numeral terms. We argue that previous studies have not characterized the data in a fashion that accounts for the degree of complexity languages display. Using data from 52 genetically diverse languages and an annotation scheme distinguishing between predictable and unpredictable allomorphy (formal variation), we show that many of the world's languages are decisively less efficient than one would expect. We discuss the implications of our findings for the study of numeral systems and linguistic evolution more generally.

### 42. Aletheia tackles FirstProof autonomously

- **LLM Score**: 0
- **Keyword Score**: 1
- **Authors**: Tony Feng, Junehyuk Jung, Sang-hyun Kim, Carlo Pagano, Sergei Gukov, Chiang-Chiang Tsai, David Woodruff, Adel Javanmard, Aryan Mokhtari, Dawsen Hwang, Yuri Chervonyi, Jonathan N. Lee, Garrett Bingham, Trieu H. Trinh, Vahab Mirrokni, Quoc V. Le, Thang Luong
- **URL**: <http://arxiv.org/abs/2602.21201v1>
- **Submitted**: 2026-02-24 18:56:10
- **Comment**: 34 pages. Project page: https://github.com/google-deepmind/superhuman/tree/main/aletheia
- **Topic Keywords**: search
- **Reason**: The paper appears to be about a mathematics research agent and its performance on a challenge, which is unrelated to Information Retrieval, Search technologies, or Natural Language Processing. The focus on mathematics and problem-solving does not align with the user's research interests.

#### Abstract
> We report the performance of Aletheia (Feng et al., 2026b), a mathematics research agent powered by Gemini 3 Deep Think, on the inaugural FirstProof challenge. Within the allowed timeframe of the challenge, Aletheia autonomously solved 6 problems (2, 5, 7, 8, 9, 10) out of 10 according to majority expert assessments; we note that experts were not unanimous on Problem 8 (only). For full transparency, we explain our interpretation of FirstProof and disclose details about our experiments as well as our evaluation. Raw prompts and outputs are available at https://github.com/google-deepmind/superhuman/tree/main/aletheia.

---

