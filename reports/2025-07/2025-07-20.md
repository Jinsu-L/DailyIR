# Daily Papers Report - 2025-07-20

## üåü Top 5 Papers with Summaries

ÏÑ†Ï†ïÎêú Top 5Í∞ú ÎÖºÎ¨∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÏöîÏïΩÏûÖÎãàÎã§.

### 1. PARK: Personalized academic retrieval with knowledge-graphs

- **LLM Score**: 7
- **Keyword Score**: 7
- **Authors**: Pranav Kasela, Gabriella Pasi, Raffaele Perego
- **URL**: <http://arxiv.org/abs/2507.13910v1>
- **Submitted**: 2025-07-18 13:41:01
- **Comment**: Accepted in Information Systems. [17 May 2025]
  https://doi.org/10.1016/j.is.2025.102574
- **Topic Keywords**: rag, retrieval, recommend, personalization, search
- **Reason**: The paper explores personalized academic retrieval with knowledge-graphs, which is related to information retrieval and search technologies. The use of neural language models and translational embedding techniques is also relevant to query understanding and ranking models. However, the focus on academic search and citation graphs is somewhat specific and may not directly align with the user's interests in e-commerce and real-time relevance optimization.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Personalized Academic Retrieval System using Knowledge Graphs
- **Aim**: To develop a personalized academic retrieval system that leverages knowledge graphs to improve search effectiveness and reduce information overload
- **Rationale**: Integrating knowledge graph embeddings with neural language models can capture both semantic and structural aspects of academic documents, leading to improved personalized search results
- **Ground**: The system uses a two-step approach: training a neural language model and converting the academic graph into a knowledge graph, and integrates collaborative filtering by modeling user preferences based on relationships derived from the citation network
- **Experiment**: The approach is evaluated on a semi-synthetic dataset comprising 1.9 million training queries and documents, and the results show that PARK-E and PARK-H significantly outperform the baseline methods across nearly all domains
- **Takeaway**: The PARK system demonstrates the effectiveness of integrating knowledge graph embeddings with neural language models to capture both semantic and structural aspects of academic documents, leading to improved personalized search results

#### Abstract
> Academic Search is a search task aimed to manage and retrieve scientific
documents like journal articles and conference papers. Personalization in this
context meets individual researchers' needs by leveraging, through user
profiles, the user related information (e.g. documents authored by a
researcher), to improve search effectiveness and to reduce the information
overload. While citation graphs are a valuable means to support the outcome of
recommender systems, their use in personalized academic search (with, e.g.
nodes as papers and edges as citations) is still under-explored.
  Existing personalized models for academic search often struggle to fully
capture users' academic interests. To address this, we propose a two-step
approach: first, training a neural language model for retrieval, then
converting the academic graph into a knowledge graph and embedding it into a
shared semantic space with the language model using translational embedding
techniques. This allows user models to capture both explicit relationships and
hidden structures in citation graphs and paper content. We evaluate our
approach in four academic search domains, outperforming traditional graph-based
and personalized models in three out of four, with up to a 10\% improvement in
MAP@100 over the second-best model. This highlights the potential of knowledge
graph-based user models to enhance retrieval effectiveness.

---

### 2. Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models

- **LLM Score**: 6
- **Keyword Score**: 7
- **Authors**: Hosein Azarbonyad, Zi Long Zhu, Georgios Cheirmpos, Zubair Afzal, Vikrant Yadav, Georgios Tsatsaronis
- **URL**: <http://arxiv.org/abs/2507.13827v1>
- **Submitted**: 2025-07-18 11:31:52
- **Comment**: SIGIR 2025
- **Topic Keywords**: ranking, rag, rank, search
- **Reason**: The paper explores question-answer extraction from scientific articles using knowledge graphs and large language models, which is somewhat related to my interests in information retrieval and natural language processing. However, the focus on scientific articles and knowledge graphs is not directly aligned with my primary focus on query understanding, ranking models, and user behavior modeling in the e-commerce domain.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Streamlining the process of understanding academic articles by generating Question-Answer (QA) pairs
- **Aim**: To propose a novel approach for generating QA pairs that encapsulate the main ideas and contributions of scientific articles
- **Rationale**: To enhance the accessibility and utility of scientific literature, supporting researchers in quickly identifying pertinent research insights
- **Ground**: The authors introduce two approaches for generating QAs from full-text articles: Core Context-based QA Generation (CCQG) and Knowledge Graph (KG)-based approach
- **Experiment**: The authors evaluate the quality of both questions and answers generated using both approaches, demonstrating that the KG-based approach effectively captures the main ideas discussed in the articles
- **Takeaway**: The KG-based approach produces QAs that more comprehensively cover the main content of the articles, outperforming the CCQG approach in terms of SME scores for all metrics in both Computer Science and Life Sciences domains

#### Abstract
> When deciding to read an article or incorporate it into their research,
scholars often seek to quickly identify and understand its main ideas. In this
paper, we aim to extract these key concepts and contributions from scientific
articles in the form of Question and Answer (QA) pairs. We propose two distinct
approaches for generating QAs. The first approach involves selecting salient
paragraphs, using a Large Language Model (LLM) to generate questions, ranking
these questions by the likelihood of obtaining meaningful answers, and
subsequently generating answers. This method relies exclusively on the content
of the articles. However, assessing an article's novelty typically requires
comparison with the existing literature. Therefore, our second approach
leverages a Knowledge Graph (KG) for QA generation. We construct a KG by
fine-tuning an Entity Relationship (ER) extraction model on scientific articles
and using it to build the graph. We then employ a salient triplet extraction
method to select the most pertinent ERs per article, utilizing metrics such as
the centrality of entities based on a triplet TF-IDF-like measure. This measure
assesses the saliency of a triplet based on its importance within the article
compared to its prevalence in the literature. For evaluation, we generate QAs
using both approaches and have them assessed by Subject Matter Experts (SMEs)
through a set of predefined metrics to evaluate the quality of both questions
and answers. Our evaluations demonstrate that the KG-based approach effectively
captures the main ideas discussed in the articles. Furthermore, our findings
indicate that fine-tuning the ER extraction model on our scientific corpus is
crucial for extracting high-quality triplets from such documents.

---

### 3. Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models

- **LLM Score**: 6
- **Keyword Score**: 1
- **Authors**: Sergio E. Zanotto, Segun Aroyehun
- **URL**: <http://arxiv.org/abs/2507.13614v1>
- **Submitted**: 2025-07-18 02:46:55
- **Comment**: arXiv admin note: text overlap with arXiv:2412.03025
- **Topic Keywords**: search
- **Reason**: The paper explores the linguistic characteristics of texts generated by humans and large language models, which is related to query understanding and ranking models in Information Retrieval. However, the focus on linguistic features and text classification is not directly aligned with my primary research interests in real-time relevance optimization and deep semantic understanding.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Characterizing Human-Written and Machine-Generated Texts using Linguistic Features
- **Aim**: To analyze and distinguish human-written texts (HWT) and machine-generated texts (MGT) using linguistic features across different linguistic levels
- **Rationale**: To understand the linguistic differences between HWT and MGT, and to develop more accurate detection methods for machine-generated texts
- **Ground**: Analysis of a dataset of 8 domains and 11 large language models, generating 467,985 texts under four decoding strategies
- **Experiment**: Extracted various linguistic features from the texts, trained a binary logistic classifier to distinguish between HWT and MGT, and performed feature importance analysis
- **Takeaway**: HWT tend to exhibit longer texts, simpler syntactic structures, and more diverse semantic content compared to MGT, and the study highlights the challenges in distinguishing MGT from HWT

#### Abstract
> The rapid advancements in large language models (LLMs) have significantly
improved their ability to generate natural language, making texts generated by
LLMs increasingly indistinguishable from human-written texts. While recent
research has primarily focused on using LLMs to classify text as either
human-written and machine-generated texts, our study focus on characterizing
these texts using a set of linguistic features across different linguistic
levels such as morphology, syntax, and semantics. We select a dataset of
human-written and machine-generated texts spanning 8 domains and produced by 11
different LLMs. We calculate different linguistic features such as dependency
length and emotionality and we use them for characterizing human-written and
machine-generated texts along with different sampling strategies, repetition
controls and model release date. Our statistical analysis reveals that
human-written texts tend to exhibit simpler syntactic structures and more
diverse semantic content. Furthermore, we calculate the variability of our set
of features across models and domains. Both human and machine texts show
stylistic diversity across domains, with humans displaying greater variation in
our features. Finally, we apply style embeddings to further test variability
among human-written and machine-generated texts. Notably, newer models output
text that is similarly variable, pointing to an homogenization of
machine-generated texts.

---

### 4. Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Brian Ondov, William Xia, Kush Attal, Ishita Unde, Jerry He, Hoa Dang, Ian Soboroff, Dina Demner-Fushman
- **URL**: <http://arxiv.org/abs/2507.14096v1>
- **Submitted**: 2025-07-18 17:23:52
- **Topic Keywords**: retrieval, search, trec
- **Reason**: The paper is somewhat related to information retrieval, specifically in the context of adapting biomedical literature for the general public. However, it does not directly address query understanding, ranking models, or user behavior modeling, which are core areas of interest. The focus on language models and biomedical literature is not directly applicable to the user's research themes.

#### T.A.R.G.E.T. Summary (from Abstract)
- **Topic**: Plain Language Adaptation of Biomedical Abstracts (PLABA) track
- **Aim**: evaluate the performance of language models in adapting professional biomedical literature to plain language
- **Rationale**: to make biomedical literature accessible to the general public
- **Ground**: Twelve teams from twelve countries participated in the track, submitting models ranging from multilayer perceptrons to large pretrained transformers
- **Experiment**: two tasks: rewriting abstracts at the sentence level (Task 1) and identifying and replacing difficult terms (Task 2)
- **Takeaway**: Large Language Models demonstrated potential in adapting biomedical literature, but also highlighted limitations and the need for improved automatic benchmarking tools

#### Abstract
> Objective: Recent advances in language models have shown potential to adapt
professional-facing biomedical literature to plain language, making it
accessible to patients and caregivers. However, their unpredictability,
combined with the high potential for harm in this domain, means rigorous
evaluation is necessary. Our goals with this track were to stimulate research
and to provide high-quality evaluation of the most promising systems.
  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts
(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included
complete, sentence-level, rewriting of abstracts (Task 1) as well as
identifying and replacing difficult terms (Task 2). For automatic evaluation of
Task 1, we developed a four-fold set of professionally-written references.
Submissions for both Tasks 1 and 2 were provided extensive manual evaluation
from biomedical experts.
  Results: Twelve teams spanning twelve countries participated in the track,
with models from multilayer perceptrons to large pretrained transformers. In
manual judgments of Task 1, top-performing models rivaled human levels of
factual accuracy and completeness, but not simplicity or brevity. Automatic,
reference-based metrics generally did not correlate well with manual judgments.
In Task 2, systems struggled with identifying difficult terms and classifying
how to replace them. When generating replacements, however, LLM-based systems
did well in manually judged accuracy, completeness, and simplicity, though not
in brevity.
  Conclusion: The PLABA track showed promise for using Large Language Models to
adapt biomedical literature for the general public, while also highlighting
their deficiencies and the need for improved automatic benchmarking tools.

---

### 5. Exploiting Primacy Effect To Improve Large Language Models

- **LLM Score**: 4
- **Keyword Score**: 5
- **Authors**: Bianca Raimondi, Maurizio Gabbrielli
- **URL**: <http://arxiv.org/abs/2507.13949v1>
- **Submitted**: 2025-07-18 14:18:18
- **Comment**: Accepted by RANLP 2025
- **Topic Keywords**: query, rag
- **Reason**: The paper explores the primacy effect in Large Language Models, which is a topic in NLP, but it does not directly relate to Information Retrieval, query understanding, ranking models, or user behavior modeling, which are the user's primary research interests. While the paper touches on bias-aware model design, it does not specifically address real-time relevance optimization or deep semantic understanding, which are key aspects of the user's research focus.

#### T.A.R.G.E.T. Summary (from Full Text)
- **Topic**: Mitigating the Primacy Effect in Large Language Models for Multiple-Choice Question Answering
- **Aim**: To develop a technique to reduce the primacy effect in large language models (LLMs) and improve their performance in multiple-choice question answering (MCQA) tasks
- **Rationale**: The primacy effect, where models favor the first items presented, can lead to incorrect results in MCQA; fine-tuning LLMs amplifies this bias, and reordering answer options based on semantic similarity can guide models towards more accurate predictions
- **Ground**: The study evaluates the effectiveness of a similarity-based reordering method in improving the positioning of correct answers within candidate lists, comparing different similarity metrics and model architectures
- **Experiment**: The authors experiment with various datasets (CLINC, BANKING, HWU) and models (Mistral-7B, Llama family), demonstrating the robustness of the technique across different models and datasets
- **Takeaway**: The study demonstrates a simple, training-free method that reorders answer options by their similarity to the query, improving accuracy without requiring labeled data, and contributing to a deeper understanding of LLMs' strengths and weaknesses

#### Abstract
> Large Language Models (LLMs) have become essential in many Natural Language
Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to
achieve high accuracy. However, like humans, LLMs exhibit biases, particularly
positional biases such as primacy and recency effects, which can influence the
accuracy of the answers. The primacy effect-where items presented first are
more likely to be remembered or selected-plays a key role in Multiple Choice
Question Answering (MCQA), where the order of answer options can affect
prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We
first show that fine-tuning amplifies this bias, probably due to exposure to
human-like patterns. Hence, we strategically leverage this effect by reordering
response options based on semantic similarity to the query, without requiring
knowledge of the correct answer. Our experimental results show that this
approach significantly improves performance in MCQA. More generally, our
findings underscore the dual nature of biases as both challenges and
opportunities, offering insights for bias-aware model design and NLP
applications.

---

## üìù Other Noteworthy Papers

LLMÏù¥ Ïä§ÏΩîÏñ¥ÎßÅÌñàÏßÄÎßå, Top 5Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ ÎÖºÎ¨∏Îì§ÏûÖÎãàÎã§.

### 6. DUALRec: A Hybrid Sequential and Language Model Framework for Context-Aware Movie Recommendation

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Yitong Li, Raoul Grasman
- **URL**: <http://arxiv.org/abs/2507.13957v1>
- **Submitted**: 2025-07-18 14:22:05
- **Comment**: 10 pages, 5 figures
- **Topic Keywords**: rag, recommend, search
- **Reason**: The paper proposes a hybrid recommender system that combines sequential and language models, which is somewhat related to my interests in Information Retrieval and Search technologies. However, the focus on movie recommendation and user behavior modeling in the e-commerce domain is not directly aligned with my primary research themes, which are query understanding, ranking models, and user behavior modeling in a broader context.

#### Abstract
> The modern recommender systems are facing an increasing challenge of
modelling and predicting the dynamic and context-rich user preferences.
Traditional collaborative filtering and content-based methods often struggle to
capture the temporal patternings and evolving user intentions. While Large
Language Models (LLMs) have gained gradual attention in recent years, by their
strong semantic understanding and reasoning abilities, they are not inherently
designed to model chronologically evolving user preference and intentions. On
the other hand, for sequential models like LSTM (Long-Short-Term-Memory) which
is good at capturing the temporal dynamics of user behaviour and evolving user
preference over time, but still lacks a rich semantic understanding for
comprehensive recommendation generation. In this study, we propose DUALRec
(Dynamic User-Aware Language-based Recommender), a novel recommender that
leverages the complementary strength of both models, which combines the
temporal modelling abilities of LSTM networks with semantic reasoning power of
the fine-tuned Large Language Models. The LSTM component will capture users
evolving preference through their viewing history, while the fine-tuned LLM
variants will leverage these temporal user insights to generate next movies
that users might enjoy. Experimental results on MovieLens-1M dataset shows that
the DUALRec model outperforms a wide range of baseline models, with
comprehensive evaluation matrices of Hit Rate (HR@k), Normalized Discounted
Cumulative Gain (NDCG@k), and genre similarity metrics. This research proposes
a novel architecture that bridges the gap between temporal sequence modeling
and semantic reasoning, and offers a promising direction for developing more
intelligent and context-aware recommenders.

### 7. SPARQL Query Generation with LLMs: Measuring the Impact of Training Data Memorization and Knowledge Injection

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Aleksandr Gashkov, Aleksandr Perevalov, Maria Eltsova, Andreas Both
- **URL**: <http://arxiv.org/abs/2507.13859v1>
- **Submitted**: 2025-07-18 12:28:08
- **Comment**: Winner of Best Paper Award at the 25th International Conference on
  Web Engineering (ICWE 2025)
- **Topic Keywords**: query, search
- **Reason**: The paper explores the application of Large Language Models (LLMs) in Query Answering systems, focusing on SPARQL query generation. While it touches on the topic of query understanding, it does not specifically address ranking models or user behavior modeling, which are key areas of interest for you. The paper's focus on LLMs and knowledge graphs is somewhat related to your research in NLP and data mining, but it does not align with your primary focus on information retrieval and real-time relevance optimization.

#### Abstract
> Nowadays, the importance of software with natural-language user interfaces
cannot be underestimated. In particular, in Question Answering (QA) systems,
generating a SPARQL query for a given natural-language question (often named
Query Building) from the information retrieved from the same question is the
central task of QA systems working over Knowledge Graphs (KGQA). Due to the
rise of Large Language Models (LLMs), they are considered a well-suited method
to increase the quality of the question-answering functionality, as there is
still a lot of room for improvement, aiming for enhanced quality and
trustworthiness. However, LLMs are trained on web data, where researchers have
no control over whether the benchmark or the knowledge graph was already
included in the training data. In this paper, we introduce a novel method that
evaluates the quality of LLMs by generating a SPARQL query from a
natural-language question under various conditions: (1) zero-shot SPARQL
generation, (2) with knowledge injection, and (3) with "anonymized" knowledge
injection. This enables us, for the first time, to estimate the influence of
the training data on the QA quality improved by LLMs. Ultimately, this will
help to identify how portable a method is or whether good results might mostly
be achieved because a benchmark was already included in the training data (cf.
LLM memorization). The developed method is portable, robust, and supports any
knowledge graph; therefore, it could be easily applied to any KGQA or LLM,
s.t., generating consistent insights into the actual LLM capabilities is
possible.

### 8. Point of Interest Recommendation: Pitfalls and Viable Solutions

- **LLM Score**: 4
- **Keyword Score**: 4
- **Authors**: Alejandro Bellog√≠n, Linus W. Dietz, Francesco Ricci, Pablo S√°nchez
- **URL**: <http://arxiv.org/abs/2507.13725v1>
- **Submitted**: 2025-07-18 08:10:09
- **Topic Keywords**: user behavior, recommend, search
- **Reason**: The paper focuses on Point of Interest (POI) recommendation, which is a topic in recommender systems, but it does not directly relate to the user's primary interests in Information Retrieval (IR), query understanding, ranking models, and user behavior modeling. While the paper discusses challenges and future directions, it does not seem to address the user's core research themes.

#### Abstract
> Point of interest (POI) recommendation can play a pivotal role in enriching
tourists' experiences by suggesting context-dependent and preference-matching
locations and activities, such as restaurants, landmarks, itineraries, and
cultural attractions. Unlike some more common recommendation domains (e.g.,
music and video), POI recommendation is inherently high-stakes: users invest
significant time, money, and effort to search, choose, and consume these
suggested POIs. Despite the numerous research works in the area, several
fundamental issues remain unresolved, hindering the real-world applicability of
the proposed approaches. In this paper, we discuss the current status of the
POI recommendation problem and the main challenges we have identified. The
first contribution of this paper is a critical assessment of the current state
of POI recommendation research and the identification of key shortcomings
across three main dimensions: datasets, algorithms, and evaluation
methodologies. We highlight persistent issues such as the lack of standardized
benchmark datasets, flawed assumptions in the problem definition and model
design, and inadequate treatment of biases in the user behavior and system
performance. The second contribution is a structured research agenda that,
starting from the identified issues, introduces important directions for future
work related to multistakeholder design, context awareness, data collection,
trustworthiness, novel interactions, and real-world evaluation.

### 9. Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Cedric Waterschoot, Nava Tintarev, Francesco Barile
- **URL**: <http://arxiv.org/abs/2507.13705v1>
- **Submitted**: 2025-07-18 07:20:52
- **Comment**: Short paper accepted at the Nineteenth ACM Conference on Recommender
  Systems (RecSys '25). Cedric Waterschoot, Nava Tintarev, and Francesco
  Barile. 2025. Consistent Explainers or Unreliable Narrators? Understanding
  LLM-generated Group Recommendations. Proceedings of the Nineteenth ACM
  Conference on Recommender Systems (RecSys '25), Prague, Czech Republic. doi:
  10.1145/3705328.3748015
- **Topic Keywords**: rag, recommend
- **Reason**: The paper explores the use of Large Language Models (LLMs) in Group Recommender Systems (GRS), which is related to search technologies and query understanding. However, the focus on LLM-generated group recommendations and explanations is not directly aligned with my primary research interests in information retrieval, ranking models, and user behavior modeling. While the paper touches on some relevant topics, such as aggregation strategies and explanation generation, it does not deeply engage with the core themes of my research.

#### Abstract
> Large Language Models (LLMs) are increasingly being implemented as joint
decision-makers and explanation generators for Group Recommender Systems (GRS).
In this paper, we evaluate these recommendations and explanations by comparing
them to social choice-based aggregation strategies. Our results indicate that
LLM-generated recommendations often resembled those produced by Additive
Utilitarian (ADD) aggregation. However, the explanations typically referred to
averaging ratings (resembling but not identical to ADD aggregation). Group
structure, uniform or divergent, did not impact the recommendations.
Furthermore, LLMs regularly claimed additional criteria such as user or item
similarity, diversity, or used undefined popularity metrics or thresholds. Our
findings have important implications for LLMs in the GRS pipeline as well as
standard aggregation strategies. Additional criteria in explanations were
dependent on the number of ratings in the group scenario, indicating potential
inefficiency of standard aggregation methods at larger item set sizes.
Additionally, inconsistent and ambiguous explanations undermine transparency
and explainability, which are key motivations behind the use of LLMs for GRS.

### 10. IP2: Entity-Guided Interest Probing for Personalized News Recommendation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Youlin Wu, Yuanyuan Sun, Xiaokun Zhang, Haoxi Zhan, Bo Xu, Liang Yang, Hongfei Lin
- **URL**: <http://arxiv.org/abs/2507.13622v1>
- **Submitted**: 2025-07-18 03:35:58
- **Comment**: Accepted in RecSys 2025
- **Topic Keywords**: click, recommend
- **Reason**: The paper focuses on news recommendation, which is a specific application of information retrieval. While it involves entity-guided interest probing, the approach is not directly related to query understanding, ranking models, or user behavior modeling, which are core areas of interest in my research. The paper's emphasis on news recommendation and entity-based methods makes it somewhat relevant, but not a central match for my research themes.

#### Abstract
> News recommender systems aim to provide personalized news reading experiences
for users based on their reading history. Behavioral science studies suggest
that screen-based news reading contains three successive steps: scanning, title
reading, and then clicking. Adhering to these steps, we find that intra-news
entity interest dominates the scanning stage, while the inter-news entity
interest guides title reading and influences click decisions. Unfortunately,
current methods overlook the unique utility of entities in news recommendation.
To this end, we propose a novel method called IP2 to probe entity-guided
reading interest at both intra- and inter-news levels. At the intra-news level,
a Transformer-based entity encoder is devised to aggregate mentioned entities
in the news title into one signature entity. Then, a signature entity-title
contrastive pre-training is adopted to initialize entities with proper meanings
using the news story context, which in the meantime facilitates us to probe for
intra-news entity interest. As for the inter-news level, a dual tower user
encoder is presented to capture inter-news reading interest from both the title
meaning and entity sides. In addition to highlighting the contribution of
inter-news entity guidance, a cross-tower attention link is adopted to
calibrate title reading interest using inter-news entity interest, thus further
aligning with real-world behavior. Extensive experiments on two real-world
datasets demonstrate that our IP2 achieves state-of-the-art performance in news
recommendation.

### 11. Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based Personalized Recommendation

- **LLM Score**: 4
- **Keyword Score**: 3
- **Authors**: Genki Kusano, Kosuke Akimoto, Kunihiro Takeoka
- **URL**: <http://arxiv.org/abs/2507.13525v1>
- **Submitted**: 2025-07-17 20:26:00
- **Comment**: Accepted to ACM RecSys2025 reproducibility
- **Topic Keywords**: user behavior, recommend
- **Reason**: The paper focuses on prompt engineering for LLM-based personalized recommendation, which is related to information retrieval and search technologies. However, the primary focus is on recommendation systems rather than information retrieval, and the paper does not explicitly address query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user.

#### Abstract
> Large language models (LLMs) can perform recommendation tasks by taking
prompts written in natural language as input. Compared to traditional methods
such as collaborative filtering, LLM-based recommendation offers advantages in
handling cold-start, cross-domain, and zero-shot scenarios, as well as
supporting flexible input formats and generating explanations of user behavior.
In this paper, we focus on a single-user setting, where no information from
other users is used. This setting is practical for privacy-sensitive or
data-limited applications. In such cases, prompt engineering becomes especially
important for controlling the output generated by the LLM. We conduct a
large-scale comparison of 23 prompt types across 8 public datasets and 12 LLMs.
We use statistical tests and linear mixed-effects models to evaluate both
accuracy and inference cost. Our results show that for cost-efficient LLMs,
three types of prompts are especially effective: those that rephrase
instructions, consider background knowledge, and make the reasoning process
easier to follow. For high-performance LLMs, simple prompts often outperform
more complex ones while reducing cost. In contrast, commonly used prompting
styles in natural language processing, such as step-by-step reasoning, or the
use of reasoning models often lead to lower accuracy. Based on these findings,
we provide practical suggestions for selecting prompts and LLMs depending on
the required balance between accuracy and cost.

### 12. Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Lautaro Estienne, Gabriel Ben Zenou, Nona Naderi, Jackie Cheung, Pablo Piantanida
- **URL**: <http://arxiv.org/abs/2507.14063v1>
- **Submitted**: 2025-07-18 16:42:22
- **Topic Keywords**: rag
- **Reason**: The paper explores a novel approach to pragmatic reasoning in multi-turn dialog, which is related to query understanding and user behavior modeling in information retrieval. However, the focus on dialog systems and language generation is not directly aligned with the user's primary interest in information retrieval and search technologies.

#### Abstract
> As AI systems take on collaborative roles, they must reason about shared
goals and beliefs-not just generate fluent language. The Rational Speech Act
(RSA) framework offers a principled approach to pragmatic reasoning, but
existing extensions face challenges in scaling to multi-turn, collaborative
scenarios. In this paper, we introduce Collaborative Rational Speech Act
(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn
dialog by optimizing a gain function adapted from rate-distortion theory. This
gain is an extension of the gain model that is maximized in the original RSA
model but takes into account the scenario in which both agents in a
conversation have private information and produce utterances conditioned on the
dialog. We demonstrate the effectiveness of CRSA on referential games and
template-based doctor-patient dialogs in the medical domain. Empirical results
show that CRSA yields more consistent, interpretable, and collaborative
behavior than existing baselines-paving the way for more pragmatic and socially
aware language agents.

### 13. Preprint: Did I Just Browse A Website Written by LLMs?

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Sichang "Steven" He, Ramesh Govindan, Harsha V. Madhyastha
- **URL**: <http://arxiv.org/abs/2507.13933v1>
- **Submitted**: 2025-07-18 14:09:04
- **Comment**: In submission. 2 pages. 3 figures
- **Topic Keywords**: rank, search
- **Reason**: The paper's focus on detecting automatically generated web content using large language models (LLMs) is somewhat related to information retrieval and search technologies. However, the specific problem domain and methodology are not directly aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Increasingly, web content is automatically generated by large language models
(LLMs) with little human input. We call this "LLM-dominant" content. Since LLMs
plagiarize and hallucinate, LLM-dominant content can be unreliable and
unethical. Yet, websites rarely disclose such content, and human readers
struggle to distinguish it. Thus, we must develop reliable detectors for
LLM-dominant content. However, state-of-the-art LLM detectors are insufficient,
because they perform well mainly on clean, prose-like text, while web content
has complex markup and diverse genres.
  We propose a highly reliable, scalable pipeline that classifies entire
websites. Instead of naively classifying text extracted from each page, we
classify each site based on an LLM text detector's outputs of multiple
prose-like pages. We train and evaluate our detector by collecting 2 distinct
ground truth datasets totaling 120 sites, and obtain 100% accuracies testing
across them. In the wild, we detect a sizable portion of sites as LLM-dominant
among 10k sites in search engine results and 10k in Common Crawl archives. We
find LLM-dominant sites are growing in prevalence and rank highly in search
results, raising questions about their impact on end users and the overall Web
ecosystem.

### 14. KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Woo-Chan Kim, Ji-Hoon Park, Seong-Whan Lee
- **URL**: <http://arxiv.org/abs/2507.13666v1>
- **Submitted**: 2025-07-18 05:34:36
- **Topic Keywords**: rag
- **Reason**: The paper proposes a novel framework for cost-efficient free-form text generation, using a cascade approach with keyword-inspired selection. While it touches on natural language processing and language models, the focus is on text generation rather than information retrieval or search technologies. The relevance to the user's interests is limited, as it does not directly address query understanding, ranking models, or user behavior modeling.

#### Abstract
> Large language models (LLMs) have demonstrated state-of-the-art performance
across a wide range of natural language processing tasks. However,
high-performing models are typically accessible only via APIs, incurring
substantial inference costs. Cascade methods address this by initially
employing a cheaper model and escalating to a stronger one only when necessary.
Nevertheless, existing cascade approaches struggle to select a reliable
representative response and assess the overall reliability of free-form
outputs, as they rely on exact text matching. To overcome these limitations, we
propose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient
free-form text generation. KiC identifies the most representative answer among
multiple outputs from a weaker model and evaluates the semantic alignment of
other responses with it. Based on the degree of alignment, KiC determines
whether to accept the weaker model's output or escalate to a stronger model.
Experiments on three free-form text generation benchmarks show that KiC
achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81
percent on average, and even outperforms GPT-4 in a specific benchmark.

### 15. Off-Policy Evaluation and Learning for Matching Markets

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Yudai Hayashi, Shuhei Goda, Yuta Saito
- **URL**: <http://arxiv.org/abs/2507.13608v1>
- **Submitted**: 2025-07-18 02:23:37
- **Comment**: RecSys'25
- **Topic Keywords**: recommend, search
- **Reason**: The paper focuses on off-policy evaluation and learning for matching markets, which is a specific application of recommender systems. While it touches on some relevant topics like user behavior modeling and ranking models, the primary focus is on a different domain (matching markets) and does not directly address query understanding, ranking models, or user behavior modeling in the context of information retrieval.

#### Abstract
> Matching users based on mutual preferences is a fundamental aspect of
services driven by reciprocal recommendations, such as job search and dating
applications. Although A/B tests remain the gold standard for evaluating new
policies in recommender systems for matching markets, it is costly and
impractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays
a crucial role by enabling the evaluation of recommendation policies using only
offline logged data naturally collected on the platform. However, unlike
conventional recommendation settings, the large scale and bidirectional nature
of user interactions in matching platforms introduce variance issues and
exacerbate reward sparsity, making standard OPE methods unreliable. To address
these challenges and facilitate effective offline evaluation, we propose novel
OPE estimators, \textit{DiPS} and \textit{DPR}, specifically designed for
matching markets. Our methods combine elements of the Direct Method (DM),
Inverse Propensity Score (IPS), and Doubly Robust (DR) estimators while
incorporating intermediate labels, such as initial engagement signals, to
achieve better bias-variance control in matching markets. Theoretically, we
derive the bias and variance of the proposed estimators and demonstrate their
advantages over conventional methods. Furthermore, we show that these
estimators can be seamlessly extended to offline policy learning methods for
improving recommendation policies for making more matches. We empirically
evaluate our methods through experiments on both synthetic data and A/B testing
logs from a real job-matching platform. The empirical results highlight the
superiority of our approach over existing methods in off-policy evaluation and
learning tasks for a variety of configurations.

### 16. A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows

- **LLM Score**: 4
- **Keyword Score**: 2
- **Authors**: Mohamed Achref Ben Ammar, Mohamed Taha Bennani
- **URL**: <http://arxiv.org/abs/2507.13544v1>
- **Submitted**: 2025-07-17 21:34:13
- **Topic Keywords**: user behavior
- **Reason**: The paper focuses on conversational systems and dialogue analysis, which is not directly related to the user's primary research interests in Information Retrieval and Search technologies. While the paper mentions large language models, it does not specifically address query understanding, ranking models, or user behavior modeling. The connection to the user's background in e-commerce is also tenuous.

#### Abstract
> The analysis of conversational dynamics has gained increasing importance with
the rise of large language model-based systems, which interact with users
across diverse contexts. In this work, we propose a novel computational
framework for constructing conversational graphs that capture the flow and
structure of loosely organized dialogues, referred to as quasi-patterned
conversations. We introduce the Filter & Reconnect method, a novel graph
simplification technique that minimizes noise while preserving semantic
coherence and structural integrity of conversational graphs. Through
comparative analysis, we demonstrate that the use of large language models
combined with our graph simplification technique has resulted in semantic
metric S increasing by a factor of 2.06 compared to previous approaches while
simultaneously enforcing a tree-like structure with 0 {\delta}-hyperbolicity,
ensuring optimal clarity in conversation modeling. This work provides a
computational method for analyzing large-scale dialogue datasets, with
practical applications related to monitoring automated systems such as
chatbots, dialogue management tools, and user behavior analytics.

### 17. Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions

- **LLM Score**: 4
- **Keyword Score**: 1
- **Authors**: Pu Jian, Donglei Yu, Wen Yang, Shuo Ren, Jiajun Zhang
- **URL**: <http://arxiv.org/abs/2507.13773v1>
- **Submitted**: 2025-07-18 09:31:43
- **Comment**: ACL2025 Main
- **Topic Keywords**: search
- **Reason**: The paper focuses on visual question answering, which is not directly related to my primary research interests in Information Retrieval and Search technologies. While it touches on query understanding and ambiguity resolution, the context is specific to visual language models and does not address ranking models or user behavior modeling, which are key areas of interest for me.

#### Abstract
> In visual question answering (VQA) context, users often pose ambiguous
questions to visual language models (VLMs) due to varying expression habits.
Existing research addresses such ambiguities primarily by rephrasing questions.
These approaches neglect the inherently interactive nature of user interactions
with VLMs, where ambiguities can be clarified through user feedback. However,
research on interactive clarification faces two major challenges: (1)
Benchmarks are absent to assess VLMs' capacity for resolving ambiguities
through interaction; (2) VLMs are trained to prefer answering rather than
asking, preventing them from seeking clarification. To overcome these
challenges, we introduce \textbf{ClearVQA} benchmark, which targets three
common categories of ambiguity in VQA context, and encompasses various VQA
scenarios.

### 18. DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits

- **LLM Score**: 2
- **Keyword Score**: 6
- **Authors**: Garapati Keerthana, Manik Gupta
- **URL**: <http://arxiv.org/abs/2507.14079v1>
- **Submitted**: 2025-07-18 17:00:27
- **Topic Keywords**: rag, ctr, retrieval
- **Reason**: The paper focuses on generating progress notes in the healthcare domain using a system called DENSE, which leverages a clinically informed retrieval strategy and a large language model. While it involves information retrieval and natural language processing, the context is quite different from the user's interests in search technologies, query understanding, and user behavior modeling, and does not seem to require deep semantic understanding or real-time relevance optimization.

#### Abstract
> Progress notes are among the most clinically meaningful artifacts in an
Electronic Health Record (EHR), offering temporally grounded insights into a
patient's evolving condition, treatments, and care decisions. Despite their
importance, they are severely underrepresented in large-scale EHR datasets. For
instance, in the widely used Medical Information Mart for Intensive Care III
(MIMIC-III) dataset, only about $8.56\%$ of hospital visits include progress
notes, leaving gaps in longitudinal patient narratives. In contrast, the
dataset contains a diverse array of other note types, each capturing different
aspects of care.
  We present DENSE (Documenting Evolving Progress Notes from Scattered
Evidence), a system designed to align with clinical documentation workflows by
simulating how physicians reference past encounters while drafting progress
notes. The system introduces a fine-grained note categorization and a temporal
alignment mechanism that organizes heterogeneous notes across visits into
structured, chronological inputs. At its core, DENSE leverages a clinically
informed retrieval strategy to identify temporally and semantically relevant
content from both current and prior visits. This retrieved evidence is used to
prompt a large language model (LLM) to generate clinically coherent and
temporally aware progress notes.
  We evaluate DENSE on a curated cohort of patients with multiple visits and
complete progress note documentation. The generated notes demonstrate strong
longitudinal fidelity, achieving a temporal alignment ratio of $1.089$,
surpassing the continuity observed in original notes. By restoring narrative
coherence across fragmented documentation, our system supports improved
downstream tasks such as summarization, predictive modeling, and clinical
decision support, offering a scalable solution for LLM-driven note synthesis in
real-world healthcare settings.

### 19. Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support

- **LLM Score**: 2
- **Keyword Score**: 5
- **Authors**: Jan Trienes, Anastasiia Derzhanskaia, Roland Schwarzkopf, Markus M√ºhling, J√∂rg Schl√∂tterer, Christin Seifert
- **URL**: <http://arxiv.org/abs/2507.13937v1>
- **Submitted**: 2025-07-18 14:09:45
- **Topic Keywords**: retriever, retrieval
- **Reason**: The paper focuses on a conversational agent for university student support, which is not directly related to the user's primary research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions retrieval-augmented generation and an FAQ retriever, the context is specific to university admissions and does not align with the user's broader interests.

#### Abstract
> We present Marcel, a lightweight and open-source conversational agent
designed to support prospective students with admission-related inquiries. The
system aims to provide fast and personalized responses, while reducing workload
of university staff. We employ retrieval-augmented generation to ground answers
in university resources and to provide users with verifiable, contextually
relevant information. To improve retrieval quality, we introduce an FAQ
retriever that maps user questions to knowledge-base entries, allowing
administrators to steer retrieval, and improving over standard dense/hybrid
retrieval strategies. The system is engineered for easy deployment in
resource-constrained academic settings. We detail the system architecture,
provide a technical evaluation of its components, and report insights from a
real-world deployment.

### 20. Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Viraj Nishesh Darji, Callie C. Liao, Duoduo Liao
- **URL**: <http://arxiv.org/abs/2507.14107v1>
- **Submitted**: 2025-07-18 17:39:03
- **Topic Keywords**: rag, recommend, search
- **Reason**: The paper is not relevant to the user's research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The topic of bridge condition assessment using Large Language Models is outside the user's primary focus and expertise.

#### Abstract
> Bridge maintenance and safety are essential for transportation authorities,
and Non-Destructive Evaluation (NDE) techniques are critical to assessing
structural integrity. However, interpreting NDE data can be time-consuming and
requires expertise, potentially delaying decision-making. Recent advancements
in Large Language Models (LLMs) offer new ways to automate and improve this
analysis. This pilot study introduces a holistic assessment of LLM capabilities
for interpreting NDE contour maps and demonstrates the effectiveness of LLMs in
providing detailed bridge condition analyses. It establishes a framework for
integrating LLMs into bridge inspection workflows, indicating that LLM-assisted
analysis can enhance efficiency without compromising accuracy. In this study,
several LLMs are explored with prompts specifically designed to enhance the
quality of image descriptions, which are applied to interpret five different
NDE contour maps obtained through technologies for assessing bridge conditions.
Each LLM model is evaluated based on its ability to produce detailed
descriptions, identify defects, provide actionable recommendations, and
demonstrate overall accuracy. The research indicates that four of the nine
models provide better image descriptions, effectively covering a wide range of
topics related to the bridge's condition. The outputs from these four models
are summarized using five different LLMs to form a comprehensive overview of
the bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more
effective summaries. The findings suggest that LLMs have the potential to
significantly improve efficiency and accuracy. This pilot study presents an
innovative approach that leverages LLMs for image captioning in parallel and
summarization, enabling faster decision-making in bridge maintenance and
enhancing infrastructure management and safety assessments.

### 21. RAG-based Architectures for Drug Side Effect Retrieval in LLMs

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Shad Nygren, Pinar Avci, Andre Daniels, Reza Rassol, Afshin Beheshti, Diego Galeano
- **URL**: <http://arxiv.org/abs/2507.13822v1>
- **Submitted**: 2025-07-18 11:20:52
- **Topic Keywords**: rag, retrieval
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on drug side effect retrieval in Large Language Models, which is outside your primary area of interest.

#### Abstract
> Drug side effects are a major global health concern, necessitating advanced
methods for their accurate detection and analysis. While Large Language Models
(LLMs) offer promising conversational interfaces, their inherent limitations,
including reliance on black-box training data, susceptibility to
hallucinations, and lack of domain-specific knowledge, hinder their reliability
in specialized fields like pharmacovigilance. To address this gap, we propose
two architectures: Retrieval-Augmented Generation (RAG) and GraphRAG, which
integrate comprehensive drug side effect knowledge into a Llama 3 8B language
model. Through extensive evaluations on 19,520 drug side effect associations
(covering 976 drugs and 3,851 side effect terms), our results demonstrate that
GraphRAG achieves near-perfect accuracy in drug side effect retrieval. This
framework offers a highly accurate and scalable solution, signifying a
significant advancement in leveraging LLMs for critical pharmacovigilance
applications.

### 22. Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers

- **LLM Score**: 2
- **Keyword Score**: 4
- **Authors**: Liang Lin, Zhihao Xu, Xuehai Tang, Shi Liu, Biyu Zhou, Fuqing Zhu, Jizhong Han, Songlin Hu
- **URL**: <http://arxiv.org/abs/2507.13474v1>
- **Submitted**: 2025-07-17 18:33:50
- **Topic Keywords**: query, search
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, query understanding, ranking models, and user behavior modeling. The paper focuses on the safety of large language models and proposes a novel attack method, which is not related to your areas of interest.

#### Abstract
> The safety of large language models (LLMs) has garnered significant research
attention. In this paper, we argue that previous empirical studies demonstrate
LLMs exhibit a propensity to trust information from authoritative sources, such
as academic papers, implying new possible vulnerabilities. To verify this
possibility, a preliminary analysis is designed to illustrate our two findings.
Based on this insight, a novel jailbreaking method, Paper Summary Attack
(\llmname{PSA}), is proposed. It systematically synthesizes content from either
attack-focused or defense-focused LLM safety paper to construct an adversarial
prompt template, while strategically infilling harmful query as adversarial
payloads within predefined subsections. Extensive experiments show significant
vulnerabilities not only in base LLMs, but also in state-of-the-art reasoning
model like Deepseek-R1. PSA achieves a 97\% attack success rate (ASR) on
well-aligned models like Claude3.5-Sonnet and an even higher 98\% ASR on
Deepseek-R1. More intriguingly, our work has further revealed diametrically
opposed vulnerability bias across different base models, and even between
different versions of the same model, when exposed to either attack-focused or
defense-focused papers. This phenomenon potentially indicates future research
clues for both adversarial methodologies and safety alignment.Code is available
at https://github.com/233liang/Paper-Summary-Attack

### 23. EdgeVLA: Efficient Vision-Language-Action Models

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Pawe≈Ç Budzianowski, Wesley Maa, Matthew Freed, Jingxiang Mo, Winston Hsiao, Aaron Xie, Tomasz M≈Çoduchowski, Viraj Tipnis, Benjamin Bolte
- **URL**: <http://arxiv.org/abs/2507.14049v1>
- **Submitted**: 2025-07-18 16:15:09
- **Topic Keywords**: rag, search
- **Reason**: The paper focuses on Vision-Language-Action models for robotics, which is not directly related to Information Retrieval, Search technologies, or Natural Language Processing. While it mentions small language models, the context is different from the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Vision-Language Models (VLMs) have emerged as a promising approach to address
the data scarcity challenge in robotics, enabling the development of
generalizable visuomotor control policies. While models like OpenVLA showcase
the potential of this paradigm, deploying large-scale VLMs on
resource-constrained mobile manipulation systems remains a significant hurdle.
This paper introduces Edge VLA (EVLA), a novel approach designed to
significantly enhance the inference speed of Vision-Language-Action (VLA)
models. EVLA maintains the representational power of these models while
enabling real-time performance on edge devices. We achieve this through two key
innovations: 1) Eliminating the autoregressive requirement for end-effector
position prediction, leading to a 7x speedup in inference, and 2) Leveraging
the efficiency of Small Language Models (SLMs), demonstrating comparable
training performance to larger models with significantly reduced computational
demands. Our early results demonstrate that EVLA achieves comparable training
characteristics to OpenVLA while offering substantial gains in inference speed
and memory efficiency. We release our model checkpoints and training
\href{https://github.com/kscalelabs/evla }{codebase} to foster further
research.

### 24. CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Jianfei Li, Kevin Kam Fung Yuen
- **URL**: <http://arxiv.org/abs/2507.14022v1>
- **Submitted**: 2025-07-18 15:41:53
- **Comment**: 35 pages, 33 tables, 6 Figures
- **Topic Keywords**: pairwise
- **Reason**: The paper focuses on document-level sentiment analysis, using a framework for selecting the best classification model. While it involves classification and evaluation metrics, it is not directly related to information retrieval, search technologies, or query understanding, which are the user's primary research interests.

#### Abstract
> This study proposes the Cognitive Pairwise Comparison Classification Model
Selection (CPC-CMS) framework for document-level sentiment analysis. The CPC,
based on expert knowledge judgment, is used to calculate the weights of
evaluation criteria, including accuracy, precision, recall, F1-score,
specificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and
efficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random
Forest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long
Short-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from
Transformers (ALBERT) are chosen as classification baseline models. A weighted
decision matrix consisting of classification evaluation scores with respect to
criteria weights, is formed to select the best classification model for a
classification problem. Three open datasets of social media are used to
demonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,
for evaluation results excluding the time factor, ALBERT is the best for the
three datasets; if time consumption is included, no single model always
performs better than the other models. The CPC-CMS can be applied to the other
classification applications in different areas.

### 25. Label Unification for Cross-Dataset Generalization in Cybersecurity NER

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Maciej Jalocha, Johan Hausted Schmidt, William Michelseen
- **URL**: <http://arxiv.org/abs/2507.13870v1>
- **Submitted**: 2025-07-18 12:47:20
- **Comment**: 5 pages, 5 figures
- **Topic Keywords**: pairwise
- **Reason**: The paper focuses on cybersecurity Named Entity Recognition (NER) and label unification, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's abstract does not mention query understanding, ranking models, or user behavior modeling, making it irrelevant to the user's core research themes.

#### Abstract
> The field of cybersecurity NER lacks standardized labels, making it
challenging to combine datasets. We investigate label unification across four
cybersecurity datasets to increase data resource usability. We perform a
coarse-grained label unification and conduct pairwise cross-dataset evaluations
using BiLSTM models. Qualitative analysis of predictions reveals errors,
limitations, and dataset differences. To address unification limitations, we
propose alternative architectures including a multihead model and a graph-based
transfer model. Results show that models trained on unified datasets generalize
poorly across datasets. The multihead model with weight sharing provides only
marginal improvements over unified training, while our graph-based transfer
model built on BERT-base-NER shows no significant performance gains compared
BERT-base-NER.

### 26. DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Ye Tian, Xiaoyuan Ren, Zihao Wang, Onat Gungor, Xiaofan Yu, Tajana Rosing
- **URL**: <http://arxiv.org/abs/2507.13737v1>
- **Submitted**: 2025-07-18 08:33:30
- **Topic Keywords**: user behavior, search
- **Reason**: The paper focuses on activity log generation using multi-modal sensors and LLMs, which is not directly related to information retrieval, search technologies, or query understanding. While it touches on semantic understanding, it is primarily concerned with activity log generation and summarization, which is outside the scope of the user's research interests.

#### Abstract
> Rich and context-aware activity logs facilitate user behavior analysis and
health monitoring, making them a key research focus in ubiquitous computing.
The remarkable semantic understanding and generation capabilities of Large
Language Models (LLMs) have recently created new opportunities for activity log
generation. However, existing methods continue to exhibit notable limitations
in terms of accuracy, efficiency, and semantic richness. To address these
challenges, we propose DailyLLM. To the best of our knowledge, this is the
first log generation and summarization system that comprehensively integrates
contextual activity information across four dimensions: location, motion,
environment, and physiology, using only sensors commonly available on
smartphones and smartwatches. To achieve this, DailyLLM introduces a
lightweight LLM-based framework that integrates structured prompting with
efficient feature extraction to enable high-level activity understanding.
Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art
(SOTA) log generation methods and can be efficiently deployed on personal
computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM
achieves a 17% improvement in log generation BERTScore precision compared to
the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference
speed.

### 27. LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues

- **LLM Score**: 2
- **Keyword Score**: 3
- **Authors**: Haoyang Li, Zhanchao Xu, Yiming Li, Xuejia Chen, Darian Li, Anxin Tian, Qingfa Xiao, Cheng Deng, Jun Wang, Qing Li, Lei Chen, Mingxuan Yuan
- **URL**: <http://arxiv.org/abs/2507.13681v1>
- **Submitted**: 2025-07-18 06:12:08
- **Topic Keywords**: query
- **Reason**: The paper focuses on large language models and multi-turn dialogues, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. Although it mentions query positions, the context is different from the user's focus on query understanding and ranking models.

#### Abstract
> Multi-turn dialogues are essential in many real-world applications of large
language models, such as chatbots and virtual assistants. As conversation
histories become longer, existing large language models face increasing
computational and memory challenges, which hinder their ability to provide
efficient and responsive interactions. Most current acceleration methods either
compress the context or optimize key value caching, but they often rely on
fixed or position-based heuristics that do not adapt well to the dynamic and
unpredictable patterns found in actual multi-turn conversations. In this paper,
we present LoopServe, an adaptive dual-phase inference acceleration framework
for large language models in multi-turn dialogues. LoopServe introduces two
main innovations. First, it performs online sparsification during the
prefilling phase by dynamically selecting the most important parts of the
attention matrix for each new input. Second, it uses progressive key value
compression during decoding by adaptively maintaining a relevant and efficient
cache based on the most recently generated output tokens. We also propose a
\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new
benchmark} with eleven multi-turn datasets that reflect realistic query
positions and conversational dependencies. Extensive experiments demonstrate
that LoopServe consistently achieves superior effectiveness compared to
existing baselines and significantly accelerates LLM inference across a wide
range of long-context dialogue tasks.

### 28. Efficient Temporal Tokenization for Mobility Prediction with Large Language Models

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Haoyu He, Haozheng Luo, Yan Chen, Qi R. Wang
- **URL**: <http://arxiv.org/abs/2507.14017v1>
- **Submitted**: 2025-07-18 15:31:16
- **Topic Keywords**: rag
- **Reason**: This paper focuses on mobility prediction using large language models, which is not directly related to information retrieval, search technologies, or query understanding. While it leverages language models, the application is in a different domain and does not involve ranking models, user behavior modeling, or real-time relevance optimization, which are key areas of interest for your research.

#### Abstract
> We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for
Human Mobility), a framework that leverages large language models (LLMs) as
spatio-temporal predictors and trajectory reasoners. RHYTHM partitions
trajectories into daily segments encoded as discrete tokens with hierarchical
attention, capturing both daily and weekly dependencies while substantially
reducing the sequence length. Token representations are enriched with
pre-computed prompt embeddings via a frozen LLM, enhancing the model's ability
to capture interdependencies without extensive computational overhead. By
freezing the LLM backbone, RHYTHM achieves significant computational
efficiency. Evaluation on three real-world datasets demonstrates a 2.4%
improvement in accuracy, 5.0% increase on weekends, and 24.6% reduction in
training time compared to state-of-the-art methods.

### 29. Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Carlos Mena, Pol Serra, Jacobo Romero, Abir Messaoudi, Jose Giraldo, Carme Armentano-Oller, Rodolfo Zevallos, Ivan Meza, Javier Hernando
- **URL**: <http://arxiv.org/abs/2507.13875v1>
- **Submitted**: 2025-07-18 12:54:41
- **Comment**: Accepted at Interspeech 2025
- **Topic Keywords**: rag
- **Reason**: The paper focuses on optimizing Automatic Speech Recognition (ASR) for code-switching in Catalan-Spanish, which is not directly related to Information Retrieval, Search technologies, or query understanding. The paper's emphasis on ASR and language processing is more relevant to Natural Language Processing (NLP) and speech recognition, but it does not align with the user's primary focus on IR, ranking models, and user behavior modeling.

#### Abstract
> Code-switching (CS), the alternating use of two or more languages, challenges
automatic speech recognition (ASR) due to scarce training data and linguistic
similarities. The lack of dedicated CS datasets limits ASR performance, as most
models rely on monolingual or mixed-language corpora that fail to reflect
real-world CS patterns. This issue is critical in multilingual societies where
CS occurs in informal and formal settings. A key example is Catalan-Spanish CS,
widely used in media and parliamentary speeches. In this work, we improve ASR
for Catalan-Spanish CS by exploring three strategies: (1) generating synthetic
CS data, (2) concatenating monolingual audio, and (3) leveraging real CS data
with language tokens. We extract CS data from Catalan speech corpora and
fine-tune OpenAI's Whisper models, making them available on Hugging Face.
Results show that combining a modest amount of synthetic CS data with the
dominant language token yields the best transcription performance.

### 30. CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Teerapong Panboonyuen
- **URL**: <http://arxiv.org/abs/2507.13655v1>
- **Submitted**: 2025-07-18 04:49:41
- **Comment**: 12 pages
- **Topic Keywords**: rag
- **Reason**: This paper focuses on customizing language models for healthcare datasets, specifically ICU datasets, using the Text-to-Text Transfer Transformer architecture. While it involves fine-tuning language models, which is related to query understanding and ranking models, the paper's primary focus is on domain adaptation and clinical decision support, which is not directly aligned with the user's research interests in Information Retrieval and Search technologies.

#### Abstract
> Integrating large language models into specialized domains like healthcare
presents unique challenges, including domain adaptation and limited labeled
data. We introduce CU-ICU, a method for customizing unsupervised
instruction-finetuned language models for ICU datasets by leveraging the
Text-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse
fine-tuning approach that combines few-shot prompting with selective parameter
updates, enabling efficient adaptation with minimal supervision. Our evaluation
across critical ICU tasks--early sepsis detection, mortality prediction, and
clinical note generation--demonstrates that CU-ICU consistently improves
predictive accuracy and interpretability over standard fine-tuning methods.
Notably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and
a 20% enhancement in generating clinically relevant explanations while updating
fewer than 1% of model parameters in its most efficient configuration. These
results establish CU-ICU as a scalable, low-overhead solution for delivering
accurate and interpretable clinical decision support in real-world ICU
environments.

### 31. CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Yanan Wang, Julio Vizcarra, Zhi Li, Hao Niu, Mori Kurokawa
- **URL**: <http://arxiv.org/abs/2507.13609v1>
- **Submitted**: 2025-07-18 02:29:19
- **Topic Keywords**: rag
- **Reason**: The paper focuses on video instruction tuning tasks, chain-of-thought reasoning, and video understanding, which are not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper's emphasis on video understanding and object-level video analysis is not aligned with the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Despite recent progress in video large language models (VideoLLMs), a key
open challenge remains: how to equip models with chain-of-thought (CoT)
reasoning abilities grounded in fine-grained object-level video understanding.
Existing instruction-tuned models, such as the Qwen and LLaVA series, are
trained on high-level video-text pairs, often lacking structured annotations
necessary for compositional, step-by-step reasoning. We propose CoTasks:
Chain-of-Thought based Video Instruction Tuning Tasks, a new framework that
decomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)
into four entity-level foundational tasks: frame localization, entity tracking,
spatial and temporal relation extraction. By embedding these intermediate
CoT-style reasoning steps into the input, CoTasks enables models to explicitly
perform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA
benchmark show that CoTasks significantly enhance inference performance:
LLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and
Qwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal
(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the
effectiveness of CoTasks as a structured CoT-style supervision framework for
improving compositional video reasoning.

### 32. Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder

- **LLM Score**: 2
- **Keyword Score**: 2
- **Authors**: Feng Chen, Weizhe Xu, Changye Li, Serguei Pakhomov, Alex Cohen, Simran Bhola, Sandy Yin, Sunny X Tang, Michael Mackinley, Lena Palaniyappan, Dror Ben-Zeev, Trevor Cohen
- **URL**: <http://arxiv.org/abs/2507.13551v1>
- **Submitted**: 2025-07-17 22:00:16
- **Topic Keywords**: ctr
- **Reason**: The paper is not relevant to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. The paper focuses on speech analysis and assessment of thought disorder in schizophrenia spectrum disorders, which is outside the user's area of expertise.

#### Abstract
> Formal thought disorder (FTD), a hallmark of schizophrenia spectrum
disorders, manifests as incoherent speech and poses challenges for clinical
assessment. Traditional clinical rating scales, though validated, are
resource-intensive and lack scalability. Automated speech analysis with
automatic speech recognition (ASR) allows for objective quantification of
linguistic and temporal features of speech, offering scalable alternatives. The
use of utterance timestamps in ASR captures pause dynamics, which are thought
to reflect the cognitive processes underlying speech production. However, the
utility of integrating these ASR-derived features for assessing FTD severity
requires further evaluation. This study integrates pause features with semantic
coherence metrics across three datasets: naturalistic self-recorded diaries
(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream
narratives (PsyCL, n = 43). We evaluated pause related features alongside
established coherence measures, using support vector regression (SVR) to
predict clinical FTD scores. Key findings demonstrate that pause features alone
robustly predict the severity of FTD. Integrating pause features with semantic
coherence metrics enhanced predictive performance compared to semantic-only
models, with integration of independent models achieving correlations up to
\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best
\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance
gains from semantic and pause features integration held consistently across all
contexts, though the nature of pause patterns was dataset-dependent. These
findings suggest that frameworks combining temporal and semantic analyses
provide a roadmap for refining the assessment of disorganized speech and
advance automated speech analysis in psychosis.

### 33. NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Maksim Kuprashevich, Grigorii Alekseenko, Irina Tolstykh, Georgii Fedorov, Bulat Suleimanov, Vladimir Dokholyan, Aleksandr Gordeev
- **URL**: <http://arxiv.org/abs/2507.14119v1>
- **Submitted**: 2025-07-18 17:50:00
- **Topic Keywords**: search
- **Reason**: The paper focuses on image editing and triplet mining, which is not directly related to information retrieval, search technologies, or query understanding. While it involves natural language instructions, the context is image editing rather than search or retrieval. The paper's emphasis on generative models and automated validation is also not aligned with the user's interests in ranking models and user behavior modeling.

#### Abstract
> Recent advances in generative modeling enable image editing assistants that
follow natural language instructions without additional user input. Their
supervised training requires millions of triplets: original image, instruction,
edited image. Yet mining pixel-accurate examples is hard. Each edit must affect
only prompt-specified regions, preserve stylistic coherence, respect physical
plausibility, and retain visual appeal. The lack of robust automated
edit-quality metrics hinders reliable automation at scale. We present an
automated, modular pipeline that mines high-fidelity triplets across domains,
resolutions, instruction complexities, and styles. Built on public generative
models and running without human intervention, our system uses a task-tuned
Gemini validator to score instruction adherence and aesthetics directly,
removing any need for segmentation or grounding models. Inversion and
compositional bootstrapping enlarge the mined set by approximately 2.2x,
enabling large-scale high-fidelity training data. By automating the most
repetitive annotation steps, the approach allows a new scale of training
without human labeling effort. To democratize research in this
resource-intensive area, we release NHR-Edit: an open dataset of 358k
high-quality triplets. In the largest cross-dataset evaluation, it surpasses
all public alternatives. We also release Bagel-NHR-Edit, an open-source
fine-tuned Bagel model, which achieves state-of-the-art metrics in our
experiments.

### 34. The Levers of Political Persuasion with Conversational AI

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Kobi Hackenburg, Ben M. Tappin, Luke Hewitt, Ed Saunders, Sid Black, Hause Lin, Catherine Fist, Helen Margetts, David G. Rand, Christopher Summerfield
- **URL**: <http://arxiv.org/abs/2507.13919v1>
- **Submitted**: 2025-07-18 13:50:09
- **Comment**: 19 pages, 4 figures. Our supplementary materials file can be found at
  https://github.com/kobihackenburg/scaling-conversational-AI
- **Topic Keywords**: personalization
- **Reason**: This paper is not relevant to your research interests in Information Retrieval, Search technologies, and Natural Language Processing. The focus on conversational AI and persuasion in a political context is outside the scope of your expertise and interests.

#### Abstract
> There are widespread fears that conversational AI could soon exert
unprecedented influence over human beliefs. Here, in three large-scale
experiments (N=76,977), we deployed 19 LLMs-including some post-trained
explicitly for persuasion-to evaluate their persuasiveness on 707 political
issues. We then checked the factual accuracy of 466,769 resulting LLM claims.
Contrary to popular concerns, we show that the persuasive power of current and
near-future AI is likely to stem more from post-training and prompting
methods-which boosted persuasiveness by as much as 51% and 27%
respectively-than from personalization or increasing model scale. We further
show that these methods increased persuasion by exploiting LLMs' unique ability
to rapidly access and strategically deploy information and that, strikingly,
where they increased AI persuasiveness they also systematically decreased
factual accuracy.

### 35. InTraVisTo: Inside Transformer Visualisation Tool

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Nicol√≤ Brunello, Davide Rigamonti, Andrea Sassella, Vincenzo Scotti, Mark James Carman
- **URL**: <http://arxiv.org/abs/2507.13858v1>
- **Submitted**: 2025-07-18 12:23:47
- **Comment**: 8 pages
- **Topic Keywords**: search
- **Reason**: This paper focuses on visualizing the internal workings of Large Language Models, which is not directly related to Information Retrieval, Search technologies, or query understanding. While it may have some tangential relevance to NLP, the paper's scope and methodology are not aligned with the user's primary research interests.

#### Abstract
> The reasoning capabilities of Large Language Models (LLMs) have increased
greatly over the last few years, as have their size and complexity.
Nonetheless, the use of LLMs in production remains challenging due to their
unpredictable nature and discrepancies that can exist between their desired
behavior and their actual model output. In this paper, we introduce a new tool,
InTraVisTo (Inside Transformer Visualisation Tool), designed to enable
researchers to investigate and trace the computational process that generates
each token in a Transformer-based LLM. InTraVisTo provides a visualization of
both the internal state of the Transformer model (by decoding token embeddings
at each layer of the model) and the information flow between the various
components across the different layers of the model (using a Sankey diagram).
With InTraVisTo, we aim to help researchers and practitioners better understand
the computations being performed within the Transformer model and thus to shed
some light on internal patterns and reasoning processes employed by LLMs.

### 36. PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Maluna Menke, Thilo Hagendorff
- **URL**: <http://arxiv.org/abs/2507.13743v1>
- **Submitted**: 2025-07-18 08:44:27
- **Topic Keywords**: rank
- **Reason**: The paper focuses on reducing biases in Large Language Models (LLMs) and fine-tuning techniques, which is not directly related to Information Retrieval (IR) or Search technologies. Although it mentions 'evaluation' and 'benchmarks', the context is not relevant to the user's interests in query understanding, ranking models, and user behavior modeling.

#### Abstract
> Large Language Models (LLMs) frequently reproduce the gender- and
sexual-identity prejudices embedded in their training corpora, leading to
outputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of
great importance. To achieve this, we evaluate two parameter-efficient
fine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt
tuning - as lightweight alternatives to full-model fine-tuning for mitigating
such biases. Using the WinoQueer benchmark, we quantify bias in three
open-source LLMs and observe baseline bias scores reaching up to 98 (out of
100) across a range of queer identities defined by gender and/or sexual
orientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%
additional parameters) on a curated QueerNews corpus reduces those scores by up
to 50 points and raises neutrality from virtually 0% to as much as 36%.
Soft-prompt tuning (10 virtual tokens) delivers only marginal improvements.
These findings show that LoRA can deliver meaningful fairness gains with
minimal computation. We advocate broader adoption of community-informed PEFT,
the creation of larger queer-authored corpora, and richer evaluation suites
beyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.

### 37. Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Shanbo Cheng, Yu Bao, Qian Cao, Luyang Huang, Liyan Kang, Zhicheng Liu, Yu Lu, Wenhao Zhu, Zhichao Huang, Tao Li, Sitong Liu, Ningxin Peng, Shuaijie She, Lu Xu, Nuo Xu, Sen Yang, Runsheng Yu, Yiming Yu, Liehao Zou, Hang Li, Lu Lu, Yuxuan Wang, Yonghui Wu
- **URL**: <http://arxiv.org/abs/2507.13618v1>
- **Submitted**: 2025-07-18 03:19:43
- **Topic Keywords**: search
- **Reason**: The paper focuses on building a multilingual translation model, which is not directly related to the user's research interests in Information Retrieval, Search technologies, and Natural Language Processing. While the paper mentions large language models, it does not explore query understanding, ranking models, or user behavior modeling, which are key areas of interest for the user.

#### Abstract
> Multilingual translation stands as a challenging task for large language
models (LLMs) to handle intricate language patterns and stilted translations
that arise in automated translations. In this paper, we introduce Seed-X, a
family of open-source LLMs comprising instruct and reasoning models, pushing
the limits of translation capability with 7B parameter size. The base model is
pre-trained on a diverse, high-quality dataset encompassing both monolingual
and bilingual content across 28 languages, harnessing the full potential of
multilingual data. The instruct model is then finetuned to translate by
Chain-of-Thought (CoT) reasoning and further enhanced through reinforcement
learning (RL) to achieve better generalization across diverse language pairs.
Seed-X achieves performance comparable to leading closed-source models,
including Gemini-2.5 and GPT-4o, across 28 languages, and significantly
outperforms larger open-source models in both automatic metrics and human
evaluations. We share the best practices through our optimization process, and
make the parameter public available for advancing translation research and
applications.

### 38. Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?

- **LLM Score**: 2
- **Keyword Score**: 1
- **Authors**: Siqi Shen, Mehar Singh, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Rada Mihalcea
- **URL**: <http://arxiv.org/abs/2507.13490v1>
- **Submitted**: 2025-07-17 18:56:41
- **Topic Keywords**: search
- **Reason**: The paper focuses on Large Language Models (LLMs) and value probing strategies, which is not directly related to Information Retrieval, Search technologies, or query understanding. The topics of NLP, data mining, and recommender systems are also not addressed in this paper.

#### Abstract
> There has been extensive research on assessing the value orientation of Large
Language Models (LLMs) as it can shape user experiences across demographic
groups. However, several challenges remain. First, while the Multiple Choice
Question (MCQ) setting has been shown to be vulnerable to perturbations, there
is no systematic comparison of probing methods for value probing. Second, it is
unclear to what extent the probed values capture in-context information and
reflect models' preferences for real-world actions. In this paper, we evaluate
the robustness and expressiveness of value representations across three widely
used probing strategies. We use variations in prompts and options, showing that
all methods exhibit large variances under input perturbations. We also
introduce two tasks studying whether the values are responsive to demographic
context, and how well they align with the models' behaviors in value-related
scenarios. We show that the demographic context has little effect on the
free-text generation, and the models' values only weakly correlate with their
preference for value-based actions. Our work highlights the need for a more
careful examination of LLM value probing and awareness of its limitations.

---

